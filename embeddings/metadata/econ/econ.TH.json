[
    {
        "title": "Payoff Information and Learning in Signaling Games",
        "authors": [
            "Drew Fudenberg",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2017",
        "summary": "  We add the assumption that players know their opponents' payoff functions and\nrationality to a model of non-equilibrium learning in signaling games. Agents\nare born into player roles and play against random opponents every period.\nInexperienced agents are uncertain about the prevailing distribution of\nopponents' play, but believe that opponents never choose conditionally\ndominated strategies. Agents engage in active learning and update beliefs based\non personal observations. Payoff information can refine or expand learning\npredictions, since patient young senders' experimentation incentives depend on\nwhich receiver responses they deem plausible. We show that with payoff\nknowledge, the limiting set of long-run learning outcomes is bounded above by\nrationality-compatible equilibria (RCE), and bounded below by uniform RCE. RCE\nrefine the Intuitive Criterion (Cho and Kreps, 1987) and include all divine\nequilibria (Banks and Sobel, 1987). Uniform RCE sometimes but not always\nexists, and implies universally divine equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.01024v5"
    },
    {
        "title": "Player-Compatible Learning and Player-Compatible Equilibrium",
        "authors": [
            "Drew Fudenberg",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2017",
        "summary": "  Player-Compatible Equilibrium (PCE) imposes cross-player restrictions on the\nmagnitudes of the players' \"trembles\" onto different strategies. These\nrestrictions capture the idea that trembles correspond to deliberate\nexperiments by agents who are unsure of the prevailing distribution of play.\nPCE selects intuitive equilibria in a number of examples where trembling-hand\nperfect equilibrium (Selten, 1975) and proper equilibrium (Myerson, 1978) have\nno bite. We show that rational learning and weighted fictitious play imply our\ncompatibility restrictions in a steady-state setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.08954v8"
    },
    {
        "title": "Completeness and Transitivity of Preferences on Mixture Sets",
        "authors": [
            "Tsogbadral Galaabaatar",
            "M. Ali Khan",
            "Metin Uyanık"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  In this paper, we show that the presence of the Archimedean and the\nmixture-continuity properties of a binary relation, both empirically\nnon-falsifiable in principle, foreclose the possibility of consistency\n(transitivity) without decisiveness (completeness), or decisiveness without\nconsistency, or in the presence of a weak consistency condition, neither. The\nbasic result can be sharpened when specialized from the context of a\ngeneralized mixture set to that of a mixture set in the sense of\nHerstein-Milnor (1953). We relate the results to the antecedent literature, and\nview them as part of an investigation into the interplay of the structure of\nthe choice space and the behavioral assumptions on the binary relation defined\non it; the ES research program due to Eilenberg (1941) and Sonnenschein (1965),\nand one to which Schmeidler (1971) is an especially influential contribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02454v1"
    },
    {
        "title": "The Model Selection Curse",
        "authors": [
            "Kfir Eliaz",
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  A \"statistician\" takes an action on behalf of an agent, based on the agent's\nself-reported personal data and a sample involving other people. The action\nthat he takes is an estimated function of the agent's report. The estimation\nprocedure involves model selection. We ask the following question: Is\ntruth-telling optimal for the agent given the statistician's procedure? We\nanalyze this question in the context of a simple example that highlights the\nrole of model selection. We suggest that our simple exercise may have\nimplications for the broader issue of human interaction with \"machine learning\"\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02888v1"
    },
    {
        "title": "Optimal policy design for the sugar tax",
        "authors": [
            "Kelly Geyskens",
            "Alexander Grigoriev",
            "Niels Holtrop",
            "Anastasia Nedelko"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Healthy nutrition promotions and regulations have long been regarded as a\ntool for increasing social welfare. One of the avenues taken in the past decade\nis sugar consumption regulation by introducing a sugar tax. Such a tax\nincreases the price of extensive sugar containment in products such as soft\ndrinks. In this article we consider a typical problem of optimal regulatory\npolicy design, where the task is to determine the sugar tax rate maximizing the\nsocial welfare. We model the problem as a sequential game represented by the\nthree-level mathematical program. On the upper level, the government decides\nupon the tax rate. On the middle level, producers decide on the product\npricing. On the lower level, consumers decide upon their preferences towards\nthe products. While the general problem is computationally intractable, the\nproblem with a few product types is polynomially solvable, even for an\narbitrary number of heterogeneous consumers. This paper presents a simple,\nintuitive and easily implementable framework for computing optimal sugar tax in\na market with a few products. This resembles the reality as the soft drinks,\nfor instance, are typically categorized in either regular or no-sugar drinks,\ne.g. Coca-Cola and Coca-Cola Zero. We illustrate the algorithm using an example\nbased on the real data and draw conclusions for a specific local market.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.07243v1"
    },
    {
        "title": "The Losses from Integration in Matching Markets can be Large",
        "authors": [
            "Josué Ortega"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Although the integration of two-sided matching markets using stable\nmechanisms generates expected gains from integration, I show that there are\nworst-case scenarios in which these are negative. The losses from integration\ncan be large enough that the average rank of an agent's spouse decreases by\n37.5% of the length of their preference list in any stable matching mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.10287v1"
    },
    {
        "title": "Revealed Stochastic Preference: A One-Paragraph Proof and Generalization",
        "authors": [
            "Jörg Stoye"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  McFadden and Richter (1991) and later McFadden (2005) show that the Axiom of\nRevealed Stochastic Preference characterizes rationalizability of choice\nprobabilities through random utility models on finite universal choice spaces.\nThis note proves the result in one short, elementary paragraph and extends it\nto set valued choice. The latter requires a different axiom than is reported in\nMcFadden (2005).\n",
        "pdf_link": "http://arxiv.org/pdf/1810.10604v2"
    },
    {
        "title": "Strategically Simple Mechanisms",
        "authors": [
            "Tilman Borgers",
            "Jiangtao Li"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We define and investigate a property of mechanisms that we call \"strategic\nsimplicity,\" and that is meant to capture the idea that, in strategically\nsimple mechanisms, strategic choices require limited strategic sophistication.\nWe define a mechanism to be strategically simple if choices can be based on\nfirst-order beliefs about the other agents' preferences and first-order\ncertainty about the other agents' rationality alone, and there is no need for\nagents to form higher-order beliefs, because such beliefs are irrelevant to the\noptimal strategies. All dominant strategy mechanisms are strategically simple.\nBut many more mechanisms are strategically simple. In particular, strategically\nsimple mechanisms may be more flexible than dominant strategy mechanisms in the\nbilateral trade problem and the voting problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.00849v1"
    },
    {
        "title": "The Income Fluctuation Problem with Capital Income Risk: Optimality and\n  Stability",
        "authors": [
            "Qingyin Ma",
            "John Stachurski",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper studies the income fluctuation problem with capital income risk\n(i.e., dispersion in the rate of return to wealth). Wealth returns and labor\nearnings are allowed to be serially correlated and mutually dependent. Rewards\ncan be bounded or unbounded. Under rather general conditions, we develop a set\nof new results on the existence and uniqueness of solutions, stochastic\nstability of the model economy, as well as efficient computation of the ergodic\nwealth distribution. A variety of applications are discussed. Quantitative\nanalysis shows that both stochastic volatility and mean persistence in wealth\nreturns have nontrivial impact on wealth inequality.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.01320v1"
    },
    {
        "title": "Mutual Conversion Between Preference Maps And Cook-Seiford Vectors",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  In group decision making, the preference map and Cook-Seiford vector are two\nconcepts as ways of describing ties-permitted ordinal rankings. This paper\nshows that they are equivalent for representing ties-permitted ordinal\nrankings. Transformation formulas from one to the other are given and the\ninherent consistency of the mutual conversion is discussed. The proposed\nmethods are illustrated by some examples. Some possible future applications of\nthe proposed formulas are also pointed out.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.03566v1"
    },
    {
        "title": "The Cost of Information: The Case of Constant Marginal Costs",
        "authors": [
            "Luciano Pomatto",
            "Philipp Strack",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We develop an axiomatic theory of information acquisition that captures the\nidea of constant marginal costs in information production: the cost of\ngenerating two independent signals is the sum of their costs, and generating a\nsignal with probability half costs half its original cost. Together with\nBlackwell monotonicity and a continuity condition, these axioms determine the\ncost of a signal up to a vector of parameters. These parameters have a clear\neconomic interpretation and determine the difficulty of distinguishing states.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.04211v4"
    },
    {
        "title": "A theoretical framework to consider energy transfers within growth\n  theory",
        "authors": [
            "Benjamin Leiva",
            "Octavio Ramirez",
            "John R. Schramski"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Growth theory has rarely considered energy despite its invisible hand in all\nphysical systems. We develop a theoretical framework that places energy\ntransfers at centerstage of growth theory based on two principles: (1) goods\nare material rearrangements and (2) such rearrangements are done by energy\ntransferred by prime movers (e.g. workers, engines). We derive the implications\nof these principles for an autarkic agent that maximizes utility subject to an\nenergy budget constraint and maximizes energy surplus to relax such constraint.\nThe solution to these problems shows that growth is driven by positive marginal\nenergy surplus of energy goods (e.g. rice, oil), yet materializes through prime\nmover accumulation. This perspective brings under one framework several results\nfrom previous attempts to insert energy within growth theory, reconciles\neconomics with natural sciences, and provides a basis for a general\nreinterpretation of economics and growth as the interplay between human desires\nand thermodynamic processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.05091v1"
    },
    {
        "title": "Causality: a decision theoretic approach",
        "authors": [
            "Pablo Schenone"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We propose a decision theoretic framework that allows a decision maker to\nexpress its causal model of the world. We extend the model of Savage (1972) by\nallowing the decision maker (DM) to choose policy interventions prior to\nchoosing acts over the nonintervened variables. We define what it means for the\nDM's choices to express the DM's belief that the relation between some\nvariables is causal. We provide axioms characterizing when the DM's causal\nmodel, as expressed through the DM's choices, is represented as a directed\nacyclic graph. A final axiom characterizes when the DM's causal model has a\nrepresentation like the one in Pearl (1995). Consequently, under this\nadditional axiom one can apply Pearl's results to identify the DM's causal\nmodel from the DM's probabilistic model.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.07414v6"
    },
    {
        "title": "Duesenberry's Theory of Consumption: Habit, Learning, and Ratcheting",
        "authors": [
            "Kyoung Jin Choi",
            "Junkee Jeon",
            "Hyeng Keun Koo"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper investigates the consumption and risk taking decision of an\neconomic agent with partial irreversibility of consumption decision by\nformalizing the theory proposed by Duesenberry (1949). The optimal policies\nexhibit a type of the (s, S) policy: there are two wealth thresholds within\nwhich consumption stays constant. Consumption increases or decreases at the\nthresholds and after the adjustment new thresholds are set. The share of risky\ninvestment in the agent's total investment is inversely U-shaped within the (s,\nS) band, which generates time-varying risk aversion that can fluctuate widely\nover time. This property can explain puzzles and questions on asset pricing and\nhouseholds' portfolio choices, e.g., why aggregate consumption is so smooth\nwhereas the high equity premium is high and the equity return has high\nvolatility, why the risky share is so low whereas the estimated risk aversion\nby the micro-level data is small, and whether and when an increase in wealth\nhas an impact on the risky share. Also, the partial irreversibility model can\nexplain both the excess sensitivity and the excess smoothness of consumption.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.10038v1"
    },
    {
        "title": "Cartel Stability under Quality Differentiation",
        "authors": [
            "Iwan Bos",
            "Marco Marini"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This note considers cartel stability when the cartelized products are\nvertically differentiated. If market shares are maintained at pre-collusive\nlevels, then the firm with the lowest competitive price-cost margin has the\nstrongest incentive to deviate from the collusive agreement. The lowest-quality\nsupplier has the tightest incentive constraint when the difference in unit\nproduction costs is sufficiently small.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.10293v1"
    },
    {
        "title": "Equivalent Choice Functions and Stable Mechanisms",
        "authors": [
            "Jan Christoph Schlegel"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We study conditions for the existence of stable and group-strategy-proof\nmechanisms in a many-to-one matching model with contracts if students'\npreferences are monotone in contract terms. We show that \"equivalence\",\nproperly defined, to a choice profile under which contracts are substitutes and\nthe law of aggregate holds is a necessary and sufficient condition for the\nexistence of a stable and group-strategy-proof mechanism.\n  Our result can be interpreted as a (weak) embedding result for choice\nfunctions under which contracts are observable substitutes and the observable\nlaw of aggregate demand holds.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.10326v3"
    },
    {
        "title": "Interdistrict School Choice: A Theory of Student Assignment",
        "authors": [
            "Isa E. Hafalir",
            "Fuhito Kojima",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Interdistrict school choice programs-where a student can be assigned to a\nschool outside of her district-are widespread in the US, yet the market-design\nliterature has not considered such programs. We introduce a model of\ninterdistrict school choice and present two mechanisms that produce stable or\nefficient assignments. We consider three categories of policy goals on\nassignments and identify when the mechanisms can achieve them. By introducing a\nnovel framework of interdistrict school choice, we provide a new avenue of\nresearch in market design.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11297v2"
    },
    {
        "title": "Optimal Insurance with Limited Commitment in a Finite Horizon",
        "authors": [
            "Junkee Jeon",
            "Hyeng Keun Koo",
            "Kyunghyun Park"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We study a finite horizon optimal contracting problem of a risk-neutral\nprincipal and a risk-averse agent who receives a stochastic income stream when\nthe agent is unable to make commitments. The problem involves an infinite\nnumber of constraints at each time and each state of the world. Miao and Zhang\n(2015) have developed a dual approach to the problem by considering a\nLagrangian and derived a Hamilton-Jacobi-Bellman equation in an infinite\nhorizon. We consider a similar Lagrangian in a finite horizon, but transform\nthe dual problem into an infinite series of optimal stopping problems. For each\noptimal stopping problem we provide an analytic solution by providing an\nintegral equation representation for the free boundary. We provide a\nverification theorem that the value function of the original principal's\nproblem is the Legender-Fenchel transform of the integral of the value\nfunctions of the optimal stopping problems. We also provide some numerical\nsimulation results of optimal contracting strategies\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11669v3"
    },
    {
        "title": "Persuading part of an audience",
        "authors": [
            "Bruno Salcedo"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  I propose a cheap-talk model in which the sender can use private messages and\nonly cares about persuading a subset of her audience. For example, a candidate\nonly needs to persuade a majority of the electorate in order to win an\nelection. I find that senders can gain credibility by speaking truthfully to\nsome receivers while lying to others. In general settings, the model admits\ninformation transmission in equilibrium for some prior beliefs. The sender can\napproximate her preferred outcome when the fraction of the audience she needs\nto persuade is sufficiently small. I characterize the sender-optimal\nequilibrium and the benefit of not having to persuade your whole audience in\nseparable environments. I also analyze different applications and verify that\nthe results are robust to some perturbations of the model, including\nnon-transparent motives as in Crawford and Sobel (1982), and full commitment as\nin Kamenica and Gentzkow (2011).\n",
        "pdf_link": "http://arxiv.org/pdf/1903.00129v1"
    },
    {
        "title": "Exact Solution for the Portfolio Diversification Problem Based on\n  Maximizing the Risk Adjusted Return",
        "authors": [
            "Abdulnasser Hatemi-J",
            "Mohamed Ali Hajji",
            "Youssef El-Khatib"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  The potential benefits of portfolio diversification have been known to\ninvestors for a long time. Markowitz (1952) suggested the seminal approach for\noptimizing the portfolio problem based on finding the weights as budget shares\nthat minimize the variance of the underlying portfolio. Hatemi-J and El-Khatib\n(2015) suggested finding the weights that will result in maximizing the risk\nadjusted return of the portfolio. This approach seems to be preferred by the\nrational investors since it combines risk and return when the optimal budget\nshares are sought for. The current paper provides a general solution for this\nrisk adjusted return problem that can be utilized for any potential number of\nassets that are included in the portfolio.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.01082v1"
    },
    {
        "title": "Price competition with uncertain quality and cost",
        "authors": [
            "Sander Heinsalu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Consumers in many markets are uncertain about firms' qualities and costs, so\nbuy based on both the price and the quality inferred from it. Optimal pricing\ndepends on consumer heterogeneity only when firms with higher quality have\nhigher costs, regardless of whether costs and qualities are private or public.\nIf better quality firms have lower costs, then good quality is sold cheaper\nthan bad under private costs and qualities, but not under public. However, if\nhigher quality is costlier, then price weakly increases in quality under both\ninformational environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03987v2"
    },
    {
        "title": "J. S. Mill's Liberal Principle and Unanimity",
        "authors": [
            "Edward J. Green"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  The broad concept of an individual's welfare is actually a cluster of related\nspecific concepts that bear a \"family resemblance\" to one another. One might\ncare about how a policy will affect people both in terms of their subjective\npreferences and also in terms of some notion of their objective interests. This\npaper provides a framework for evaluation of policies in terms of welfare\ncriteria that combine these two considerations. Sufficient conditions are\nprovided for such a criterion to imply the same ranking of social states as\ndoes Pareto's unanimity criterion. Sufficiency is proved via study of a\ncommunity of agents with interdependent ordinal preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.07769v1"
    },
    {
        "title": "Slow persuasion",
        "authors": [
            "Matteo Escudé",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  What are the value and form of optimal persuasion when information can be\ngenerated only slowly? We study this question in a dynamic model in which a\n'sender' provides public information over time subject to a graduality\nconstraint, and a decision-maker takes an action in each period. Using a novel\n'viscosity' dynamic programming principle, we characterise the sender's\nequilibrium value function and information provision. We show that the\ngraduality constraint inhibits information provision relative to unconstrained\npersuasion. The gap can be substantial, but closes as the constraint slackens.\nContrary to unconstrained persuasion, less-than-full information may be\nprovided even if players have aligned preferences but different prior beliefs.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09055v6"
    },
    {
        "title": "On the core of normal form games with a continuum of players : a\n  correction",
        "authors": [
            "Youcef Askoura"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the core of normal form games with a continuum of players and\nwithout side payments. We consider the weak-core concept, which is an\napproximation of the core, introduced by Weber, Shapley and Shubik. For payoffs\ndepending on the players' strategy profile, we prove that the weak-core is\nnonempty. The existence result establishes a weak-core element as a limit of\nelements in weak-cores of appropriate finite games. We establish by examples\nthat our regularity hypotheses are relevant in the continuum case and the\nweak-core can be strictly larger than the Aumann's $\\alpha$-core. For games\nwhere payoffs depend on the distribution of players' strategy profile, we prove\nthat analogous regularity conditions ensuring the existence of pure strategy\nNash equilibria are irrelevant for the non-vacuity of the weak-core.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09819v1"
    },
    {
        "title": "An interim core for normal form games and exchange economies with\n  incomplete information: a correction",
        "authors": [
            "Youcef Askoura"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We consider the interim core of normal form cooperative games and exchange\neconomies with incomplete information based on the partition model. We develop\na solution concept that we can situate roughly between Wilson's coarse core and\nYannelis's private core. We investigate the interim negotiation of contracts\nand address the two situations of contract delivery: interim and ex post. Our\nsolution differs from Wilson's concept because the measurability of strategies\nin our solution is postponed until the consumption date (assumed with respect\nto the information that will be known by the players at the consumption date).\nFor interim consumption, our concept differs from Yannelis's private core\nbecause players can negotiate conditional on proper common knowledge events in\nour solution, which strengthens the interim aspect of the game, as we will\nillustrate with examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09867v1"
    },
    {
        "title": "Fair Allocation of Vaccines, Ventilators and Antiviral Treatments:\n  Leaving No Ethical Value Behind in Health Care Rationing",
        "authors": [
            "Parag A. Pathak",
            "Tayfun Sönmez",
            "M. Utku Ünver",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A priority system has traditionally been the protocol of choice for the\nallocation of scarce life-saving resources during public health emergencies.\nCovid-19 revealed the limitations of this allocation rule. Many argue that\npriority systems abandon ethical values such as equity by discriminating\nagainst disadvantaged communities. We show that a restrictive feature of the\ntraditional priority system largely drives these limitations. Following\nminimalist market design, an institution design paradigm that integrates\nresearch and policy efforts, we formulate pandemic allocation of scarce\nlife-saving resources as a new application of market design. Interfering only\nwith the restrictive feature of the priority system to address its\nshortcomings, we formulate a reserve system as an alternative allocation rule.\nOur theoretical analysis develops a general theory of reserve design. We relate\nour analysis to debates during Covid-19 and describe the impact of our paper on\npolicy and practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.00374v3"
    },
    {
        "title": "Robust Sequential Search",
        "authors": [
            "Karl H. Schlag",
            "Andriy Zapechelnyuk"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study sequential search without priors. Our interest lies in decision\nrules that are close to being optimal under each prior and after each history.\nWe call these rules dynamically robust. The search literature employs optimal\nrules based on cutoff strategies that are not dynamically robust. We derive\ndynamically robust rules and show that their performance exceeds 1/2 of the\noptimum against binary environments and 1/4 of the optimum against all\nenvironments. This performance improves substantially with the outside option\nvalue, for instance, it exceeds 2/3 of the optimum if the outside option\nexceeds 1/6 of the highest possible alternative.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.00502v1"
    },
    {
        "title": "Existence and uniqueness of recursive utilities without boundedness",
        "authors": [
            "Timothy M. Christensen"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper derives primitive, easily verifiable sufficient conditions for\nexistence and uniqueness of (stochastic) recursive utilities for several\nimportant classes of preferences. In order to accommodate models commonly used\nin practice, we allow both the state-space and per-period utilities to be\nunbounded. For many of the models we study, existence and uniqueness is\nestablished under a single, primitive \"thin tail\" condition on the distribution\nof growth in per-period utilities. We present several applications to robust\npreferences, models of ambiguity aversion and learning about hidden states, and\nEpstein-Zin preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.00963v3"
    },
    {
        "title": "Connected Incomplete Preferences",
        "authors": [
            "Leandro Gorno",
            "Alessandro Rivello"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The standard model of choice in economics is the maximization of a complete\nand transitive preference relation over a fixed set of alternatives. While\ncompleteness of preferences is usually regarded as a strong assumption,\nweakening it requires care to ensure that the resulting model still has enough\nstructure to yield interesting results. This paper takes a step in this\ndirection by studying the class of \"connected preferences\", that is,\npreferences that may fail to be complete but have connected maximal domains of\ncomparability. We offer four new results. Theorem 1 identifies a basic\nnecessary condition for a continuous preference to be connected in the sense\nabove, while Theorem 2 provides sufficient conditions. Building on the latter,\nTheorem 3 characterizes the maximal domains of comparability. Finally, Theorem\n4 presents conditions that ensure that maximal domains are arc-connected.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.04401v1"
    },
    {
        "title": "Exact solutions for a Solow-Swan model with non-constant returns to\n  scale",
        "authors": [
            "Nicolò Cangiotti",
            "Mattia Sensi"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The Solow-Swan model is shortly reviewed from a mathematical point of view.\nBy considering non-constant returns to scale, we obtain a general solution\nstrategy. We then compute the exact solution for the Cobb-Douglas production\nfunction, for both the classical model and the von Bertalanffy model. Numerical\nsimulations are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.05875v1"
    },
    {
        "title": "Mobility and Social Efficiency",
        "authors": [
            "Ryan Steven Kostiuk"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This is a general competitive analysis paper. A model is presented that\ndescribes how an individual with a physical disability, or mobility impairment,\nwould go about utility maximization. These results are then generalized.\nSubsequently, a selection of disability policies from Canada and the United\nStates are compared to the insights of the model, and it is shown that there\nare sources of inefficiency in many North American disability support systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.07650v1"
    },
    {
        "title": "Competing Persuaders in Zero-Sum Games",
        "authors": [
            "Dilip Ravindran",
            "Zhihan Cui"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study Bayesian Persuasion with multiple senders who have access to\nconditionally independent experiments (and possibly others). Senders have\nzero-sum preferences over information revealed. We characterize when any set of\nstates can be pooled in equilibrium and when all equilibria are fully\nrevealing. The state is fully revealed in every equilibrium if and only if\nsender utility functions are `globally nonlinear'. With two states, this is\nequivalent to some sender having nontrivial preferences. The upshot is that\n`most' zero-sum sender preferences result in full revelation. We explore what\nconditions are important for competition to result in such stark information\nrevelation.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.08517v2"
    },
    {
        "title": "A theoretical look at ELECTRE TRI-nB and related sorting models",
        "authors": [
            "Denis Bouyssou",
            "Thierry Marchant",
            "Marc Pirlot"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Electre Tri is a set of methods designed to sort alternatives evaluated on\nseveral criteria into ordered categories. In these methods, alternatives are\nassigned to categories by comparing them with reference profiles that represent\neither the boundary or central elements of the category. The original Electre\nTri-B method uses one limiting profile for separating a category from the\ncategory below. A more recent method, Electre Tri-nB, allows one to use several\nlimiting profiles for the same purpose. We investigate the properties of\nElectre Tri-nB using a conjoint measurement framework. When the number of\nlimiting profiles used to define each category is not restricted, Electre\nTri-nB is easy to characterize axiomatically and is found to be equivalent to\nseveral other methods proposed in the literature. We extend this result in\nvarious directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.09484v3"
    },
    {
        "title": "Optimal Rating Design under Moral Hazard",
        "authors": [
            "Maryam Saeedi",
            "Ali Shourideh"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We examine the design of optimal rating systems in the presence of moral\nhazard. First, an intermediary commits to a rating scheme. Then, a\ndecision-maker chooses an action that generates value for the buyer. The\nintermediary then observes a noisy signal of the decision-maker's choice and\nsends the buyer a signal consistent with the rating scheme. Here we fully\ncharacterize the set of allocations that can arise in equilibrium under any\narbitrary rating system. We use this characterization to study various design\naspects of optimal rating systems. Specifically, we study the properties of\noptimal ratings when the decision-maker's effort is productive and when the\ndecision-maker can manipulate the intermediary's signal with a noise. With\nmanipulation, rating uncertainty is a fairly robust feature of optimal rating\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.09529v3"
    },
    {
        "title": "Lindahl Equilibrium as a Collective Choice Rule",
        "authors": [
            "Faruk Gul",
            "Wolfgang Pesendorfer"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A collective choice problem is a finite set of social alternatives and a\nfinite set of economic agents with vNM utility functions. We associate a public\ngoods economy with each collective choice problem and establish the existence\nand efficiency of (equal income) Lindahl equilibrium allocations. We interpret\ncollective choice problems as cooperative bargaining problems and define a\nset-valued solution concept, {\\it the equitable solution} (ES). We provide\naxioms that characterize ES and show that ES contains the Nash bargaining\nsolution. Our main result shows that the set of ES payoffs is the same a the\nset of Lindahl equilibrium payoffs. We consider two applications: in the first,\nwe show that in a large class of matching problems without transfers the set of\nLindahl equilibrium payoffs is the same as the set of (equal income) Walrasian\nequilibrium payoffs. In our second application, we show that in any discrete\nexchange economy without transfers every Walrasian equilibrium payoff is a\nLindahl equilibrium payoff of the corresponding collective choice market.\nMoreover, for any cooperative bargaining problem, it is possible to define a\nset of commodities so that the resulting economy's utility possibility set is\nthat bargaining problem {\\it and} the resulting economy's set of Walrasian\nequilibrium payoffs is the same as the set of Lindahl equilibrium payoffs of\nthe corresponding collective choice market.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.09932v2"
    },
    {
        "title": "Transaction Costs: Economies of Scale, Optimum, Equilibrium and\n  Efficiency",
        "authors": [
            "László Kállay",
            "Tibor Takács",
            "László Trautmann"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The aim of this article is to propose a core game theory model of transaction\ncosts wherein it is indicated how direct costs determine the probability of\nloss and subsequent transaction costs. The existence of optimum is proven, and\nthe way in which exposure influences the location of the optimum is\ndemonstrated. The decisions are described as a two-player game and it is\ndiscussed how the transaction cost sharing rule determines whether the optimum\npoint of transaction costs is the same as the equilibrium of the game. A game\nmodelling dispute between actors regarding changing the share of transaction\ncosts to be paid by each party is also presented. Requirements of efficient\ntransaction cost sharing rules are defined, and it is posited that a solution\nexists which is not unique. Policy conclusions are also devised based on\nprinciples of design of institutions to influence the nature of transaction\ncosts.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.10348v1"
    },
    {
        "title": "\"Near\" Weighted Utilitarian Characterizations of Pareto Optima",
        "authors": [
            "Yeon-Koo Che",
            "Jinwoo Kim",
            "Fuhito Kojima",
            "Christopher Thomas Ryan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We characterize Pareto optimality via \"near\" weighted utilitarian welfare\nmaximization. One characterization sequentially maximizes utilitarian welfare\nfunctions using a finite sequence of nonnegative and eventually positive\nwelfare weights. The other maximizes a utilitarian welfare function with a\ncertain class of positive hyperreal weights. The social welfare ordering\nrepresented by these \"near\" weighted utilitarian welfare criteria is\ncharacterized by the standard axioms for weighted utilitarianism under a\nsuitable weakening of the continuity axiom.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.10819v2"
    },
    {
        "title": "All-Pay Auctions with Different Forfeits",
        "authors": [
            "Benjamin Kang",
            "James Unwin"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In an auction each party bids a certain amount and the one which bids the\nhighest is the winner. Interestingly, auctions can also be used as models for\nother real-world systems. In an all pay auction all parties must pay a forfeit\nfor bidding. In the most commonly studied all pay auction, parties forfeit\ntheir entire bid, and this has been considered as a model for expenditure on\npolitical campaigns. Here we consider a number of alternative forfeits which\nmight be used as models for different real-world competitions, such as\npreparing bids for defense or infrastructure contracts.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.02599v1"
    },
    {
        "title": "All-Pay Auctions as Models for Trade Wars and Military Annexation",
        "authors": [
            "Benjamin Kang",
            "James Unwin"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We explore an application of all-pay auctions to model trade wars and\nterritorial annexation. Specifically, in the model we consider the expected\nresource, production, and aggressive (military/tariff) power are public\ninformation, but actual resource levels are private knowledge. We consider the\nresource transfer at the end of such a competition which deprives the weaker\ncountry of some fraction of its original resources. In particular, we derive\nthe quasi-equilibria strategies for two country conflicts under different\nscenarios. This work is relevant for the ongoing US-China trade war, and the\nrecent Russian capture of Crimea, as well as historical and future conflicts.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03492v1"
    },
    {
        "title": "The structure of two-valued strategy-proof social choice functions with\n  indifference",
        "authors": [
            "Achille Basile",
            "Surekha Rao",
            "K. P. S. Bhaskara Rao"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We give a structure theorem for all coalitionally strategy-proof social\nchoice functions whose range is a subset of cardinality two of a given larger\nset of alternatives.\n  We provide this in the case where the voters/agents are allowed to express\nindifference and the domain consists of profiles of preferences over a society\nof arbitrary cardinality. The theorem, that takes the form of a representation\nformula, can be used to construct all functions under consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06341v2"
    },
    {
        "title": "Convex Combinatorial Auction of Pipeline Network Capacities",
        "authors": [
            "Dávid Csercsik"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In this paper we propose a mechanism for the allocation of pipeline\ncapacities, assuming that the participants bidding for capacities do have\nsubjective evaluation of various network routes. The proposed mechanism is\nbased on the concept of bidding for route-quantity pairs. Each participant\ndefines a limited number of routes and places multiple bids, corresponding to\nvarious quantities, on each of these routes. The proposed mechanism assigns a\nconvex combination of the submitted bids to each participant, thus its called\nconvex combinatorial auction. The capacity payments in the proposed model are\ndetermined according to the Vickrey-Clarke-Groves principle. We compare the\nefficiency of the proposed algorithm with a simplified model of the method\ncurrently used for pipeline capacity allocation in the EU (simultaneous\nascending clock auction of pipeline capacities) via simulation, according to\nvarious measures, such as resulting utility of players, utilization of network\ncapacities, total income of the auctioneer and fairness.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06554v1"
    },
    {
        "title": "VAT Compliance Incentives",
        "authors": [
            "Maria-Augusta Miceli"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In this work I clarify VAT evasion incentives through a game theoretical\napproach. Traditionally, evasion has been linked to the decreasing risk\naversion in higher revenues (Allingham and Sandmo (1972), Cowell (1985)\n(1990)). I claim tax evasion to be a rational choice when compliance is\nstochastically more expensive than evading, even in absence of controls and\nsanctions. I create a framework able to measure the incentives for taxpayers to\ncomply. The incentives here are deductions of specific VAT documented expenses\nfrom the income tax. The issue is very well known and deduction policies at\nwork in many countries. The aim is to compute the right parameters for each\nprecise class of taxpayers. VAT evasion is a collusive conduct between the two\ncounterparts of the transaction. I therefore first explore the convenience for\nthe two private counterparts to agree on the joint evasion and to form a\ncoalition. Crucial is that compliance incentives break the agreement among the\ntransaction participants' coalition about evading. The game solution leads to\nboundaries for marginal tax rates or deduction percentages, depending on\nparameters, able to create incentives to comply The stylized example presented\nhere for VAT policies, already in use in many countries, is an attempt to\nestablish a more general method for tax design, able to make compliance the\n\"dominant strategy\", satisfying the \"outside option\" constraint represented by\nevasion, even in absence of audit and sanctions. The theoretical results\nderived here can be easily applied to real data for precise tax design\nengineering.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.07862v3"
    },
    {
        "title": "Lattice structure of the random stable set in many-to-many matching\n  market",
        "authors": [
            "Noelia Juarez",
            "Pablo A. Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  For a many-to-many matching market, we study the lattice structure of the set\nof random stable matchings. We define a partial order on the random stable set\nand present two intuitive binary operations to compute the least upper bound\nand the greatest lower bound for each side of the matching market. Then, we\nprove that with these binary operations the set of random stable matchings\nforms two dual lattices.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08156v5"
    },
    {
        "title": "Conventions and Coalitions in Repeated Games",
        "authors": [
            "S. Nageeb Ali",
            "Ce Liu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We develop a theory of repeated interaction for coalitional behavior. We\nconsider stage games where both individuals and coalitions may deviate.\nHowever, coalition members cannot commit to long-run behavior, and anticipate\nthat today's actions influence tomorrow's behavior. We evaluate the degree to\nwhich history-dependence can deter coalitional deviations. If monitoring is\nperfect, every feasible and strictly individually rational payoff can be\nsupported by history-dependent conventions. By contrast, if players can make\nsecret side-payments to each other, every coalition achieves a coalitional\nminmax value, potentially reducing the set of supportable payoffs to the core\nof the stage game.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.00280v2"
    },
    {
        "title": "The interplay between migrants and natives as a determinant of migrants'\n  assimilation: A coevolutionary approach",
        "authors": [
            "Jakub Bielawski",
            "Marcin Jakubek"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the migrants' assimilation, which we conceptualize as forming human\ncapital productive on the labor market of a developed host country, and we link\nthe observed frequent lack of assimilation with the relative deprivation that\nthe migrants start to feel when they move in social space towards the natives.\nIn turn, we presume that the native population is heterogenous and consists of\nhigh-skill and low-skill workers. The presence of assimilated migrants might\nshape the comparison group of the natives, influencing the relative deprivation\nof the low-skill workers and, in consequence, the choice to form human capital\nand become highly skilled. To analyse this interrelation between assimilation\nchoices of migrants and skill formation of natives, we construct a\ncoevolutionary model of the open-to-migration economy. Showing that the economy\nmight end up in a non-assimilation equilibrium, we discuss welfare consequences\nof an assimilation policy funded from tax levied on the native population. We\nidentify conditions under which such costly policy can bring the migrants to\nassimilation and at the same time increase the welfare of the natives, even\nthough the incomes of the former take a beating.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.02657v1"
    },
    {
        "title": "Addictive Auctions: using lucky-draw and gambling addiction to increase\n  participation during auctioning",
        "authors": [
            "Ravin Kumar"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Auction theories are believed to provide a better selling opportunity for the\nresources to be allocated. Various organizations have taken measures to\nincrease trust among participants towards their auction system, but trust alone\ncannot ensure a high level of participation. We propose a new type of auction\nsystem which takes advantage of lucky draw and gambling addictions to increase\nthe engagement level of candidates in an auction. Our system makes use of\nsecurity features present in existing auction systems for ensuring fairness and\nmaintaining trust among participants.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.03237v1"
    },
    {
        "title": "On the Equilibrium Uniqueness in Cournot Competition with Demand\n  Uncertainty",
        "authors": [
            "Stefanos Leonardos",
            "Costis Melolidakis"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We revisit the linear Cournot model with uncertain demand that is studied in\nLagerl\\\"of (2006)* and provide sufficient conditions for equilibrium uniqueness\nthat complement the existing results. We show that if the distribution of the\ndemand intercept has the decreasing mean residual demand (DMRD) or the\nincreasing generalized failure rate (IGFR) property, then uniqueness of\nequilibrium is guaranteed. The DMRD condition implies log-concavity of the\nexpected profits per unit of output without additional assumptions on the\nexistence or the shape of the density of the demand intercept and, hence,\nanswers in the affirmative the conjecture of Lagerl\\\"of (2006)* that such\nconditions may not be necessary.\n  *Johan Lagerl\\\"of, Equilibrium uniqueness in a Cournot model with demand\nuncertainty. The B.E. Journal in Theoretical Economics, Vol. 6: Iss 1.\n(Topics), Article 19:1--6, 2006.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.03558v3"
    },
    {
        "title": "General equilibrium in a heterogeneous-agent incomplete-market economy\n  with many consumption goods and a risk-free bond",
        "authors": [
            "Bar Light"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a pure-exchange incomplete-market economy with heterogeneous agents.\nIn each period, the agents choose how much to save (i.e., invest in a risk-free\nbond), how much to consume, and which bundle of goods to consume while their\nendowments are fluctuating. We focus on a competitive stationary equilibrium\n(CSE) in which the wealth distribution is invariant, the agents maximize their\nexpected discounted utility, and both the prices of consumption goods and the\ninterest rate are market-clearing. Our main contribution is to extend some\ngeneral equilibrium results to an incomplete-market Bewley-type economy with\nmany consumption goods. Under mild conditions on the agents' preferences, we\nshow that the aggregate demand for goods depends only on their relative prices\nand that the aggregate demand for savings is homogeneous of degree in prices,\nand we prove the existence of a CSE. When the agents' preferences can be\nrepresented by a CES (constant elasticity of substitution) utility function\nwith an elasticity of substitution that is higher than or equal to one, we\nprove that the CSE is unique. Under the same preferences, we show that a higher\ninequality of endowments does not change the equilibrium prices of goods, and\ndecreases the equilibrium interest rate. Our results shed light on the impact\nof market incompleteness on the properties of general equilibrium models.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.06810v2"
    },
    {
        "title": "Informed Principal Problems in Bilateral Trading",
        "authors": [
            "Takeshi Nishimura"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study bilateral trade with interdependent values as an informed-principal\nproblem. The mechanism-selection game has multiple equilibria that differ with\nrespect to principal's payoff and trading surplus. We characterize the\nequilibrium that is worst for every type of principal, and characterize the\nconditions under which there are no equilibria with different payoffs for the\nprincipal. We also show that this is the unique equilibrium that survives the\nintuitive criterion.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.10311v6"
    },
    {
        "title": "Dynamically Stable Matching",
        "authors": [
            "Laura Doval"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  I introduce a stability notion, dynamic stability, for two-sided dynamic\nmatching markets where (i) matching opportunities arrive over time, (ii)\nmatching is one-to-one, and (iii) matching is irreversible. The definition\naddresses two conceptual issues. First, since not all agents are available to\nmatch at the same time, one must establish which agents are allowed to form\nblocking pairs. Second, dynamic matching markets exhibit a form of externality\nthat is not present in static markets: an agent's payoff from remaining\nunmatched cannot be defined independently of what other contemporaneous agents'\noutcomes are. Dynamically stable matchings always exist. Dynamic stability is a\nnecessary condition to ensure timely participation in the economy by ensuring\nthat agents do not strategically delay the time at which they are available to\nmatch.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.11391v5"
    },
    {
        "title": "Electoral Accountability and Selection with Personalized Information\n  Aggregation",
        "authors": [
            "Anqi Li",
            "Lin Hu"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study a model of electoral accountability and selection whereby\nheterogeneous voters aggregate incumbent politician's performance data into\npersonalized signals through paying limited attention. Extreme voters' signals\nexhibit an own-party bias, which hampers their ability to discern the good and\nbad performances of the incumbent. While this effect alone would undermine\nelectoral accountability and selection, there is a countervailing effect\nstemming from partisan disagreement, which makes the centrist voter more likely\nto be pivotal. In case the latter's unbiased signal is very informative about\nthe incumbent's performance, the combined effect on electoral accountability\nand selection can actually be a positive one. For this reason, factors that\ncarry a negative connotation in every political discourse -- such as increasing\nmass polarization and shrinking attention span -- have ambiguous accountability\nand selection effects in general. Correlating voters' signals, if done\nappropriately, unambiguously improves electoral accountability and selection\nand, hence, voter welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.03761v7"
    },
    {
        "title": "Random Non-Expected Utility: Non-Uniqueness",
        "authors": [
            "Yi-Hsuan Lin"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In random expected utility (Gul and Pesendorfer, 2006), the distribution of\npreferences is uniquely recoverable from random choice. This paper shows\nthrough two examples that such uniqueness fails in general if risk preferences\nare random but do not conform to expected utility theory. In the first,\nnon-uniqueness obtains even if all preferences are confined to the betweenness\nclass (Dekel, 1986) and are suitably monotone. The second example illustrates\nrandom choice behavior consistent with random expected utility that is also\nconsistent with random non-expected utility. On the other hand, we find that if\nrisk preferences conform to weighted utility theory (Chew, 1983) and are\nmonotone in first-order stochastic dominance, random choice again uniquely\nidentifies the distribution of preferences. Finally, we argue that, depending\non the domain of risk preferences, uniqueness may be restored if joint\ndistributions of choice across a limited number of feasible sets are available.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.04173v1"
    },
    {
        "title": "Reforms meet fairness concerns in school and college admissions",
        "authors": [
            "Somouaoga Bonkoungou",
            "Alexander Nesterov"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Recently, many matching systems around the world have been reformed. These\nreforms responded to objections that the matching mechanisms in use were unfair\nand manipulable. Surprisingly, the mechanisms remained unfair even after the\nreforms: the new mechanisms may induce an outcome with a blocking student who\ndesires and deserves a school which she did not receive. However, as we show in\nthis paper, the reforms introduced matching mechanisms which are more fair\ncompared to the counterfactuals. First, most of the reforms introduced\nmechanisms that are more fair by stability: whenever the old mechanism does not\nhave a blocking student, the new mechanism does not have a blocking student\neither. Second, some reforms introduced mechanisms that are more fair by\ncounting: the old mechanism always has at least as many blocking students as\nthe new mechanism. These findings give a novel rationale to the reforms and\ncomplement the recent literature showing that the same reforms have introduced\nless manipulable matching mechanisms. We further show that the fairness and\nmanipulability of the mechanisms are strongly logically related.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.05245v4"
    },
    {
        "title": "Strategy-proof allocation with outside option",
        "authors": [
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Strategy-proof mechanisms are widely used in market design. In an abstract\nallocation framework where outside options are available to agents, we obtain\ntwo results for strategy-proof mechanisms. They provide a unified foundation\nfor several existing results in distinct models and imply new results in some\nmodels. The first result proves that, for individually rational and\nstrategy-proof mechanisms, pinning down every agent's probability of choosing\nhis outside option is equivalent to pinning down a mechanism. The second result\nprovides a sufficient condition for two strategy-proof mechanisms to be\nequivalent when the number of possible allocations is finite.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.05311v2"
    },
    {
        "title": "Stochastic Stability of a Recency Weighted Sampling Dynamic",
        "authors": [
            "Alexander Aurell",
            "Gustav Karreskog"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We introduce and study a model of long-run convention formation for rare\ninteractions. Players in this model form beliefs by observing a\nrecency-weighted sample of past interactions, to which they noisily best\nrespond. We propose a continuous state Markov model, well-suited for our\nsetting, and develop a methodology that is relevant for a larger class of\nsimilar learning models. We show that the model admits a unique asymptotic\ndistribution which concentrates its mass on some minimal CURB block\nconfiguration. In contrast to existing literature of long-run convention\nformation, we focus on behavior inside minimal CURB blocks and provide\nconditions for convergence to (approximate) mixed equilibria conventions inside\nminimal CURB blocks.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12910v2"
    },
    {
        "title": "Necessity of Hyperbolic Absolute Risk Aversion for the Concavity of\n  Consumption Functions",
        "authors": [
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Carroll and Kimball (1996) have shown that, in the class of utility functions\nthat are strictly increasing, strictly concave, and have nonnegative third\nderivatives, hyperbolic absolute risk aversion (HARA) is sufficient for the\nconcavity of consumption functions in general consumption-saving problems. This\npaper shows that HARA is necessary, implying the concavity of consumption is\nnot a robust prediction outside the HARA class.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.13564v2"
    },
    {
        "title": "Bayesian Elicitation",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study how a decision-maker can acquire more information from an agent by\nreducing her own ability to observe what the agent transmits. In a large class\nof binary-action games, opacity design is just as good as full commitment to\nactions and also guarantees that ex ante information acquisition always\nbenefits the receiver, even though without opacity design this learning might\nactually lower the receiver's expected payoff.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.00976v3"
    },
    {
        "title": "Persuasion Meets Delegation",
        "authors": [
            "Anton Kolotilin",
            "Andriy Zapechelnyuk"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  A principal can restrict an agent's information (the persuasion problem) or\nrestrict an agent's discretion (the delegation problem). We show that these\nproblems are generally equivalent - solving one solves the other. We use tools\nfrom the persuasion literature to generalize and extend many results in the\ndelegation literature, as well as to address novel delegation problems, such as\nmonopoly regulation with a participation constraint.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.02628v1"
    },
    {
        "title": "The preference lattice",
        "authors": [
            "Gregorio Curello",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Most comparisons of preferences are instances of single-crossing dominance.\nWe examine the lattice structure of single-crossing dominance, proving\ncharacterisation, existence and uniqueness results for minimum upper bounds of\narbitrary sets of preferences. We apply these theorems to derive new\ncomparative statics theorems for collective choice and under analyst\nuncertainty, and to characterise a general 'maxmin' class of uncertainty-averse\npreferences over Savage acts.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.07260v6"
    },
    {
        "title": "Compactification of Extensive Game Structures and Backward Dominance\n  Procedure",
        "authors": [
            "Shuige Liu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the relationship between invariant transformations on extensive game\nstructures and backward dominance procedure (BD), a generalization of the\nclassical backward induction introduced in Perea (2014). We show that\nbehavioral equivalence with unambiguous orderings of information sets, a\ncritical property that guarantees BD's applicability, can be characterized by\nthe classical Coalescing and a modified Interchange/Simultanizing in Battigalli\net al. (2020). We also give conditions on transformations that improve BD's\nefficiency. In addition, we discuss the relationship between transformations\nand Bonanno (2014)'s generalized backward induction.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.00355v3"
    },
    {
        "title": "Public goods in networks with constraints on sharing",
        "authors": [
            "Stefanie Gerke",
            "Gregory Gutin",
            "Sung-Ha Hwang",
            "Philip Neary"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper considers incentives to provide goods that are partially shareable\nalong social links. We introduce a model in which each individual in a social\nnetwork not only decides how much of a shareable good to provide, but also\ndecides which subset of neighbours to nominate as co-beneficiaries. An outcome\nof the model specifies an endogenously generated subnetwork of the original\nnetwork and a public goods game occurring over the realised subnetwork. We\nprove the existence of specialised pure strategy Nash equilibria: those in\nwhich some individuals contribute while the remaining individuals free ride. We\nthen consider how the set of efficient specialised equilibria vary as the\nconstraints on sharing are relaxed and we show that, paradoxically, an increase\nin shareability may decrease efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01693v4"
    },
    {
        "title": "When abstinence increases prevalence",
        "authors": [
            "Sander Heinsalu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In the pool of people seeking partners, a uniformly greater preference for\nabstinence increases the prevalence of infection and worsens everyone's\nwelfare. In contrast, prevention and treatment reduce prevalence and improve\npayoffs. The results are driven by adverse selection: people who prefer more\npartners are likelier disease carriers. A given decrease in the number of\nmatches is a smaller proportional reduction for people with many partners, thus\nincreases the fraction of infected in the pool. The greater disease risk\nfurther decreases partner-seeking and payoffs.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02073v1"
    },
    {
        "title": "Spherical Preferences",
        "authors": [
            "Christopher P. Chambers",
            "Federico Echenique"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We introduce and study the property of orthogonal independence, a restricted\nadditivity axiom applying when alternatives are orthogonal. The axiom requires\nthat the preference for one marginal change over another should be maintained\nafter each marginal change has been shifted in a direction that is orthogonal\nto both.\n  We show that continuous preferences satisfy orthogonal independence if and\nonly if they are spherical: their indifference curves are spheres with the same\ncenter, with preference being \"monotone\" either away or towards the center.\nSpherical preferences include linear preferences as a special (limiting) case.\nWe discuss different applications to economic and political environments. Our\nresult delivers Euclidean preferences in models of spatial voting, quadratic\nwelfare aggregation in social choice, and expected utility in models of choice\nunder uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02917v3"
    },
    {
        "title": "The paradox of monotone structural QRE",
        "authors": [
            "Rodrigo A. Velez",
            "Alexander L. Brown"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  McKelvey and Palfrey (1995)'s monotone structural Quantal Response\nEquilibrium theory may be misspecified for the study of monotone behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.05814v2"
    },
    {
        "title": "Empirical bias of extreme-price auctions: analysis",
        "authors": [
            "Rodrigo A. Velez",
            "Alexander L. Brown"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We advance empirical equilibrium analysis (Velez and Brown, 2020,\narXiv:1907.12408) of the winner-bid and loser-bid auctions for the dissolution\nof a partnership. We show, in a complete information environment, that even\nthough these auctions are essentially equivalent for the Nash equilibrium\nprediction, they can be expected to differ in fundamental ways when they are\noperated. Besides the direct policy implications, two general consequences\nfollow. First, a mechanism designer who accounts for the empirical plausibility\nof equilibria may not be constrained by Maskin invariance. Second, a mechanism\ndesigner who does not account for the empirical plausibility of equilibria may\ninadvertently design biased mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.08234v2"
    },
    {
        "title": "Credit Scoring by Incorporating Dynamic Networked Information",
        "authors": [
            "Yibei Li",
            "Ximei Wang",
            "Boualem Djehiche",
            "Xiaoming Hu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this paper, the credit scoring problem is studied by incorporating\nnetworked information, where the advantages of such incorporation are\ninvestigated theoretically in two scenarios. Firstly, a Bayesian optimal filter\nis proposed to provide risk prediction for lenders assuming that published\ncredit scores are estimated merely from structured financial data. Such\nprediction can then be used as a monitoring indicator for the risk management\nin lenders' future decisions. Secondly, a recursive Bayes estimator is further\nproposed to improve the precision of credit scoring by incorporating the\ndynamic interaction topology of clients. It is shown that under the proposed\nevolution framework, the designed estimator has a higher precision than any\nefficient estimator, and the mean square errors are strictly smaller than the\nCram\\'er-Rao lower bound for clients within a certain range of scores. Finally,\nsimulation results for a special case illustrate the feasibility and\neffectiveness of the proposed algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11795v2"
    },
    {
        "title": "On the many-to-one strongly stable fractional matching set",
        "authors": [
            "Pablo A. Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  For a many-to-one matching market where firms have strict and\n$\\boldsymbol{q}$-responsive preferences, we give a characterization of the set\nof strongly stable fractional matchings as the union of the convex hull of all\nconnected sets of stable matchings. Also, we prove that a strongly stable\nfractional matching is represented as a convex combination of stable matchings\nthat are ordered in the common preferences of all firms.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.12500v2"
    },
    {
        "title": "Detectability, Duality, and Surplus Extraction",
        "authors": [
            "Giuseppe Lopomo",
            "Luca Rigotti",
            "Chris Shannon"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study surplus extraction in the general environment of McAfee and Reny\n(1992), and provide two alternative proofs of their main theorem. The first is\nan analogue of the classic argument of Cremer and McLean (1985, 1988), using\ngeometric features of the set of agents' beliefs to construct a menu of\ncontracts extracting the desired surplus. This argument, which requires a\nfinite state space, also leads to a counterexample showing that full extraction\nis not possible without further significant conditions on agents' beliefs or\nsurplus, even if the designer offers an infinite menu of contracts. The second\nargument uses duality and applies for an infinite state space, thus yielding\nthe general result of McAfee and Reny (1992). Both arguments suggest methods\nfor studying surplus extraction in settings beyond the standard model, in which\nthe designer or agents might have objectives other than risk neutral expected\nvalue maximization.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.12788v2"
    },
    {
        "title": "Characterizing Shadow Price via Lagrangian Multiplier for Nonsmooth\n  Problem",
        "authors": [
            "Yan Gao"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this paper, a relation between shadow price and the Lagrangian multiplier\nfor nonsmooth problem is explored. It is shown that the Lagrangian Multiplier\nis the upper bound of shadow price for convex optimization and a class of\nLipschtzian optimizations. This work can be used in shadow pricing for\nnonsmooth situation. The several nonsmooth functions involved in this class of\nLipschtzian optimizations is listed. Finally, an application to electricity\npricing is discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.13622v2"
    },
    {
        "title": "Super-Nash performance in games",
        "authors": [
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Since the 1990s, artificial intelligence (AI) systems have achieved\n'superhuman performance' in major zero-sum games, where winning has an\nunambiguous definition. However, most economic and social interactions are\nnon-zero-sum, where measuring 'performance' is a non-trivial task. In this\npaper, I introduce a novel benchmark, super-Nash performance, and a solution\nconcept, optimin, whereby every player maximizes their minimal payoff under\nunilateral profitable deviations of the others. Optimin achieves super-Nash\nperformance in that, for every Nash equilibrium, there exists an optimin where\neach player not only receives but also guarantees super-Nash payoffs, even if\nother players deviate unilaterally and profitably from the optimin. Further,\noptimin generalizes and unifies several key results across domains: it\ncoincides with (i) the maximin strategies in zero-sum games, and (ii) the core\nin cooperative games when the core is nonempty, though it exists even if the\ncore is empty; additionally, optimin generalizes (iii) Nash equilibrium in\n$n$-person constant-sum games. Finally, optimin is consistent with the\ndirection of non-Nash deviations in games in which cooperation has been\nextensively studied, including the finitely repeated prisoner's dilemma, the\ncentipede game, the traveler's dilemma, and the finitely repeated public goods\ngame.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.00211v5"
    },
    {
        "title": "Refuting Samuelson's Capitulation on the Re-switching of Techniques in\n  the Cambridge Capital Controversy",
        "authors": [
            "Carlo Milana"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Paul A. Samuelson's (1966) capitulation during the so-called Cambridge\ncontroversy on the re-switching of techniques in capital theory had\nimplications not only in pointing at supposed internal contradiction of the\nmarginal theory of production and distribution, but also in preserving vested\ninterests in the academic and political world. Based on a new non-switching\ntheorem, the present paper demonstrates that Samuelson's capitulation was\nlogically groundless from the point of view of the economic theory of\nproduction.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01250v3"
    },
    {
        "title": "Perfect bidder collusion through bribe and request",
        "authors": [
            "Jingfeng Lu",
            "Zongwei Lu",
            "Christian Riis"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study collusion in a second-price auction with two bidders in a dynamic\nenvironment. One bidder can make a take-it-or-leave-it collusion proposal,\nwhich consists of both an offer and a request of bribes, to the opponent. We\nshow that there always exists a robust equilibrium in which the collusion\nsuccess probability is one. In the equilibrium, for each type of initiator the\nexpected payoff is generally higher than the counterpart in any robust\nequilibria of the single-option model (Es\\\"{o} and Schummer (2004)) and any\nother separating equilibria in our model.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.03607v2"
    },
    {
        "title": "Voluntary Disclosure and Personalized Pricing",
        "authors": [
            "S. Nageeb Ali",
            "Greg Lewis",
            "Shoshana Vasserman"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Central to privacy concerns is that firms may use consumer data to price\ndiscriminate. A common policy response is that consumers should be given\ncontrol over which firms access their data and how. Since firms learn about a\nconsumer's preferences based on the data seen and the consumer's disclosure\nchoices, the equilibrium implications of consumer control are unclear. We study\nwhether such measures improve consumer welfare in monopolistic and competitive\nmarkets. We find that consumer control can improve consumer welfare relative to\nboth perfect price discrimination and no personalized pricing. First, consumers\ncan use disclosure to amplify competitive forces. Second, consumers can\ndisclose information to induce even a monopolist to lower prices. Whether\nconsumer control improves welfare depends on the disclosure technology and\nmarket competitiveness. Simple disclosure technologies suffice in competitive\nmarkets. When facing a monopolist, a consumer needs partial disclosure\npossibilities to obtain any welfare gains.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.04774v2"
    },
    {
        "title": "Fuzzy Group Identification Problems",
        "authors": [
            "Federico Fioravanti",
            "Fernando Tohmé"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We present a fuzzy version of the Group Identification Problem (\"Who is a\nJ?\") introduced by Kasher and Rubinstein (1997). We consider a class $N =\n\\{1,2,\\ldots,n\\}$ of agents, each one with an opinion about the membership to a\ngroup J of the members of the society, consisting in a function $\\pi : N \\to\n[0; 1]$, indicating for each agent, including herself, the degree of membership\nto J. We consider the problem of aggregating those functions, satisfying\ndifferent sets of axioms and characterizing different aggregators. While some\nresults are analogous to those of the originally crisp model, the fuzzy version\nis able to overcome some of the main impossibility results of Kasher and\nRubinstein.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05540v2"
    },
    {
        "title": "A Bilateral River Bargaining Problem with Negative Externality",
        "authors": [
            "Shivshanker Singh Patel",
            "Parthasarathy Ramachandran"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This article is addressing the problem of river sharing between two agents\nalong a river in the presence of negative externalities. Where, each agent\nclaims river water based on the hydrological characteristics of the\nterritories. The claims can be characterized by some international framework\n(principles) of entitlement. These international principles are appears to be\ninequitable by the other agents in the presence of negative externalities. The\nnegotiated treaties address sharing water along with the issue of negative\nexternalities imposed by the upstream agent on the downstream agents. The\nmarket based bargaining mechanism is used for modeling and for characterization\nof agreement points.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05844v1"
    },
    {
        "title": "Alternative Axioms in Group Identification Problems",
        "authors": [
            "Federico Fioravanti",
            "Fernando Tohmé"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Kasher and Rubinstein (1997) introduced the problem of classifying the\nmembers of a group in terms of the opinions of their potential members. This\ninvolves a finite set of agents $N = \\{1,2,\\ldots,n\\}$, each one having an\nopinion about which agents should be classified as belonging to a specific\nsubgroup J. A Collective Identity Function (CIF) aggregates those opinions\nyielding the class of members deemed $J$. Kasher and Rubinstein postulate\naxioms, intended to ensure fair and socially desirable outcomes, characterizing\ndifferent CIFs. We follow their lead by replacing their liberal axiom by other\naxioms, constraining the spheres of influence of the agents. We show that some\nof them lead to different CIFs while in another instance we find an\nimpossibility result.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05961v1"
    },
    {
        "title": "Efficient allocations in double auction markets",
        "authors": [
            "Teemu Pennanen"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper proposes a simple descriptive model of discrete-time double\nauction markets for divisible assets. As in the classical models of exchange\neconomies, we consider a finite set of agents described by their initial\nendowments and preferences. Instead of the classical Walrasian-type market\nmodels, however, we assume that all trades take place in a centralized double\nauction where the agents communicate through sealed limit orders for buying and\nselling. We find that, under nonstrategic bidding, the double auction clears\nwith zero trades precisely when the agents' current holdings are on the Pareto\nfrontier. More interestingly, the double auctions implement Adam Smith's\n\"invisible hand\" in the sense that, when starting from disequilibrium, repeated\ndouble auctions lead to a sequence of allocations that converges to\nindividually rational Pareto allocations.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.02071v2"
    },
    {
        "title": "Bilateral Tariffs Under International Competition",
        "authors": [
            "Tsotne Kutalia",
            "Revaz Tevzadze"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper explores the gain maximization problem of two nations engaging in\nnon-cooperative bilateral trade. Probabilistic model of an exchange of\ncommodities under different price systems is considered. Volume of commodities\nexchanged determines the demand each nation has over the counter party's\ncurrency. However, each nation can manipulate this quantity by imposing a\ntariff on imported commodities. As long as the gain from trade is determined by\nthe balance between imported and exported commodities, such a scenario results\nin a two party game where Nash equilibrium tariffs are determined for various\nforeign currency demand functions and ultimately, the exchange rate based on\noptimal tariffs is obtained.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.02426v1"
    },
    {
        "title": "Targeting in social networks with anonymized information",
        "authors": [
            "Francis Bloch",
            "Shaden Shabayek"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper studies whether a planner who only has information about the\nnetwork topology can discriminate among agents according to their network\nposition. The planner proposes a simple menu of contracts, one for each\nlocation, in order to maximize total welfare, and agents choose among the menu.\nThis mechanism is immune to deviations by single agents, and to deviations by\ngroups of agents of sizes 2, 3 and 4 if side-payments are ruled out. However,\nif compensations are allowed, groups of agents may have an incentive to jointly\ndeviate from the optimal contract in order to exploit other agents. We identify\nnetwork topologies for which the optimal contract is group incentive compatible\nwith transfers: undirected networks and regular oriented trees, and network\ntopologies for which the planner must assign uniform quantities: single root\nand nested neighborhoods directed networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03122v1"
    },
    {
        "title": "In Simple Communication Games, When Does Ex Ante Fact-Finding Benefit\n  the Receiver?",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Always, if the number of states is equal to two; or if the number of receiver\nactions is equal to two and i. The number of states is three or fewer, or ii.\nThe game is cheap talk, or ii. There are just two available messages for the\nsender. A counterexample is provided for each failure of these conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.09387v1"
    },
    {
        "title": "Agenda-manipulation in ranking",
        "authors": [
            "Gregorio Curello",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the susceptibility of committee governance (e.g. by boards of\ndirectors), modelled as the collective determination of a ranking of a set of\nalternatives, to manipulation of the order in which pairs of alternatives are\nvoted on -- agenda-manipulation. We exhibit an agenda strategy called insertion\nsort that allows a self-interested committee chair with no knowledge of how\nvotes will be cast to do as well as if she had complete knowledge. Strategies\nwith this 'regret-freeness' property are characterised by their efficiency, and\nby their avoidance of two intuitive errors. What distinguishes regret-free\nstrategies from each other is how they prioritise among alternatives; insertion\nsort prioritises lexicographically.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11341v5"
    },
    {
        "title": "What are we weighting for? A mechanistic model for probability weighting",
        "authors": [
            "Ole Peters",
            "Alexander Adamou",
            "Mark Kirstein",
            "Yonatan Berman"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Behavioural economics provides labels for patterns in human economic\nbehaviour. Probability weighting is one such label. It expresses a mismatch\nbetween probabilities used in a formal model of a decision (i.e. model\nparameters) and probabilities inferred from real people's decisions (the same\nparameters estimated empirically). The inferred probabilities are called\n\"decision weights.\" It is considered a robust experimental finding that\ndecision weights are higher than probabilities for rare events, and\n(necessarily, through normalisation) lower than probabilities for common\nevents. Typically this is presented as a cognitive bias, i.e. an error of\njudgement by the person. Here we point out that the same observation can be\ndescribed differently: broadly speaking, probability weighting means that a\ndecision maker has greater uncertainty about the world than the observer. We\noffer a plausible mechanism whereby such differences in uncertainty arise\nnaturally: when a decision maker must estimate probabilities as frequencies in\na time series while the observer knows them a priori. This suggests an\nalternative presentation of probability weighting as a principled response by a\ndecision maker to uncertainties unaccounted for in an observer's model.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.00056v1"
    },
    {
        "title": "On the Equivalence of Neural and Production Networks",
        "authors": [
            "Roy Gernhardt",
            "Bjorn Persson"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper identifies the mathematical equivalence between economic networks\nof Cobb-Douglas agents and Artificial Neural Networks. It explores two\nimplications of this equivalence under general conditions. First, a burgeoning\nliterature has established that network propagation can transform microeconomic\nperturbations into large aggregate shocks. Neural network equivalence amplifies\nthe magnitude and complexity of this phenomenon. Second, if economic agents\nadjust their production and utility functions in optimal response to local\nconditions, market pricing is a sufficient and robust channel for information\nfeedback leading to macro learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.00510v2"
    },
    {
        "title": "Dynamic Reserves in Matching Markets",
        "authors": [
            "Orhan Aygün",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study a school choice problem under affirmative action policies where\nauthorities reserve a certain fraction of the slots at each school for specific\nstudent groups, and where students have preferences not only over the schools\nthey are matched to but also the type of slots they receive. Such reservation\npolicies might cause waste in instances of low demand from some student groups.\nTo propose a solution to this issue, we construct a family of choice functions,\ndynamic reserves choice functions, for schools that respect within-group\nfairness and allow the transfer of otherwise vacant slots from low-demand\ngroups to high-demand groups. We propose the cumulative offer mechanism (COM)\nas an allocation rule where each school uses a dynamic reserves choice function\nand show that it is stable with respect to schools' choice functions, is\nstrategy-proof, and respects improvements. Furthermore, we show that\ntransferring more of the otherwise vacant slots leads to strategy-proof Pareto\nimprovement under the COM.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01103v1"
    },
    {
        "title": "A Theory of the Saving Rate of the Rich",
        "authors": [
            "Qingyin Ma",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Empirical evidence suggests that the rich have higher propensity to save than\ndo the poor. While this observation may appear to contradict the homotheticity\nof preferences, we theoretically show that that is not the case. Specifically,\nwe consider an income fluctuation problem with homothetic preferences and\ngeneral shocks and prove that consumption functions are asymptotically linear,\nwith an exact analytical characterization of asymptotic marginal propensities\nto consume (MPC). We provide necessary and sufficient conditions for the\nasymptotic MPCs to be zero. We calibrate a model with standard constant\nrelative risk aversion utility and show that zero asymptotic MPCs are\nempirically plausible, implying that our mechanism has the potential to\naccommodate a large saving rate of the rich and high wealth inequality (small\nPareto exponent) as observed in the data.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02379v5"
    },
    {
        "title": "Choice with Endogenous Categorization",
        "authors": [
            "Andrew Ellis",
            "Yusufcan Masatlioglu"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose and axiomatize the categorical thinking model (CTM) in which the\nframing of the decision problem affects how agents categorize alternatives,\nthat in turn affects their evaluation of it. Prominent models of salience,\nstatus quo bias, loss-aversion, inequality aversion, and present bias all fit\nunder the umbrella of CTM. This suggests categorization is an underlying\nmechanism of key departures from the neoclassical model of choice. We\nspecialize CTM to provide a behavioral foundation for the salient thinking\nmodel of Bordalo et al. (2013) that highlights its strong predictions and\ndistinctions from other models.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05196v3"
    },
    {
        "title": "Communication, Renegotiation and Coordination with Private Values",
        "authors": [
            "Yuval Heller",
            "Christoph Kuzmics"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  An equilibrium is communication-proof if it is unaffected by new\nopportunities to communicate and renegotiate. We characterize the set of\nequilibria of coordination games with pre-play communication in which players\nhave private preferences over the coordinated outcomes. The set of\ncommunication-proof equilibria is a small and relatively homogeneous subset of\nthe set of qualitatively diverse Bayesian Nash equilibria. Under a\ncommunication-proof equilibrium, players never miscoordinate, play their\njointly preferred outcome whenever there is one, and communicate only the\nordinal part of their preferences. Moreover, such equilibria are robust to\nchanges in players' beliefs and interim Pareto efficient\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05713v4"
    },
    {
        "title": "Information Validates the Prior: A Theorem on Bayesian Updating and\n  Applications",
        "authors": [
            "Navin Kartik",
            "Frances Lee",
            "Wing Suen"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We develop a result on expected posteriors for Bayesians with heterogenous\npriors, dubbed information validates the prior (IVP). Under familiar ordering\nrequirements, Anne expects a (Blackwell) more informative experiment to bring\nBob's posterior mean closer to Anne's prior mean. We apply the result in two\ncontexts of games of asymmetric information: voluntary testing or\ncertification, and costly signaling or falsification. IVP can be used to\ndetermine how an agent's behavior responds to additional exogenous or\nendogenous information. We discuss economic implications.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05714v3"
    },
    {
        "title": "Instability of Defection in the Prisoner's Dilemma Under Best\n  Experienced Payoff Dynamics",
        "authors": [
            "Srinivas Arigapudi",
            "Yuval Heller",
            "Igal Milchtaich"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study population dynamics under which each revising agent tests each\nstrategy k times, with each trial being against a newly drawn opponent, and\nchooses the strategy whose mean payoff was highest. When k = 1, defection is\nglobally stable in the prisoner`s dilemma. By contrast, when k > 1 we show that\nthere exists a globally stable state in which agents cooperate with probability\nbetween 28% and 50%. Next, we characterize stability of strict equilibria in\ngeneral games. Our results demonstrate that the empirically plausible case of k\n> 1 can yield qualitatively different predictions than the case of k = 1 that\nis commonly studied in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05779v3"
    },
    {
        "title": "Efficient and fair trading algorithms in market design environments",
        "authors": [
            "Jingsheng Yu",
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose a new method to define trading algorithms in market design\nenvironments. Dropping the traditional idea of clearing cycles in generated\ngraphs, we use parameterized linear equations to define trading algorithms. Our\nmethod has two advantages. First, our method avoids discussing the details of\nwho trades with whom and how, which can be a difficult question in complex\nenvironments. Second, by controlling parameter values in our equations, our\nmethod is flexible and transparent to satisfy various fairness criteria. We\napply our method to several models and obtain new trading algorithms that are\nefficient and fair.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06878v3"
    },
    {
        "title": "Exploring Weak Strategy-Proofness in Voting Theory",
        "authors": [
            "Anne Carlstein"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Voting is the aggregation of individual preferences in order to select a\nwinning alternative. Selection of a winner is accomplished via a voting rule,\ne.g., rank-order voting, majority rule, plurality rule, approval voting. Which\nvoting rule should be used? In social choice theory, desirable properties of\nvoting rules are expressed as axioms to be satisfied. This thesis focuses on\naxioms concerning strategic manipulation by voters. Sometimes, voters may\nintentionally misstate their true preferences in order to alter the outcome for\ntheir own advantage. For example, in plurality rule, if a voter knows that\ntheir top-choice candidate will lose, then they might instead vote for their\nsecond-choice candidate just to avoid an even less desirable result. When no\ncoalition of voters can strategically manipulate, then the voting rule is said\nto satisfy the axiom of Strategy-Proofness. A less restrictive axiom is Weak\nStrategy-Proofness (as defined by Dasgupta and Maskin (2019)), which allows for\nstrategic manipulation by all but the smallest coalitions. Under certain\nintuitive conditions, Dasgupta and Maskin (2019) proved that the only voting\nrules satisfying Strategy-Proofness are rank-order voting and majority rule. In\nmy thesis, I generalize their result, by proving that rank-order voting and\nmajority rule are surprisingly still the only voting rules satisfying Weak\nStrategy-Proofness.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07521v1"
    },
    {
        "title": "Optimal Trade-Off Between Economic Activity and Health During an\n  Epidemic",
        "authors": [
            "Tommy Andersson",
            "Albin Erlanson",
            "Daniel Spiro",
            "Robert Östling"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper considers a simple model where a social planner can influence the\nspread-intensity of an infection wave, and, consequently, also the economic\nactivity and population health, through a single parameter. Population health\nis assumed to only be negatively affected when the number of simultaneously\ninfected exceeds health care capacity. The main finding is that if (i) the\nplanner attaches a positive weight on economic activity and (ii) it is more\nharmful for the economy to be locked down for longer than shorter time periods,\nthen the optimal policy is to (weakly) exceed health care capacity at some\ntime.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07590v1"
    },
    {
        "title": "Fractional Top Trading Cycle on the Full Preference Domain",
        "authors": [
            "Jingsheng Yu",
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Efficiency and fairness are two desiderata in market design. Fairness\nrequires randomization in many environments. Observing the inadequacy of Top\nTrading Cycle (TTC) to incorporate randomization, Yu and Zhang (2020) propose\nthe class of Fractional TTC mechanisms to solve random allocation problems\nefficiently and fairly. The assumption of strict preferences in the paper\nrestricts the application scope. This paper extends Fractional TTC to the full\npreference domain in which agents can be indifferent between objects.\nEfficiency and fairness of Fractional TTC are preserved. As a corollary, we\nobtain an extension of the probabilistic serial mechanism in the house\nallocation model to the full preference domain. Our extension does not require\nany knowledge beyond elementary computation.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.09340v1"
    },
    {
        "title": "Communication and Cooperation in Markets",
        "authors": [
            "S. Nageeb Ali",
            "David A. Miller"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Many markets rely on traders truthfully communicating who has cheated in the\npast and ostracizing those traders from future trade. This paper investigates\nwhen truthful communication is incentive compatible. We find that if each side\nhas a myopic incentive to deviate, then communication incentives are satisfied\nonly when the volume of trade is low. By contrast, if only one side has a\nmyopic incentive to deviate, then communication incentives do not constrain the\nvolume of supportable trade. Accordingly, there are strong gains from\nstructuring trade so that one side either moves first or has its cooperation\nguaranteed by external enforcement.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.09839v1"
    },
    {
        "title": "On Sustainable Equilibria",
        "authors": [
            "Srihari Govindan",
            "Rida Laraki",
            "Lucas Pahl"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Following the ideas laid out in Myerson (1996), Hofbauer (2000) defined a\nNash equilibrium of a finite game as sustainable if it can be made the unique\nNash equilibrium of a game obtained by deleting/adding a subset of the\nstrategies that are inferior replies to it. This paper proves two results about\nsustainable equilibria. The first concerns the Hofbauer-Myerson conjecture\nabout the relationship between the sustainability of an equilibrium and its\nindex: for a generic class of games, an equilibrium is sustainable iff its\nindex is $+1$. Von Schemde and von Stengel (2008) proved this conjecture for\nbimatrix games; we show that the conjecture is true for all finite games. More\nprecisely, we prove that an isolated equilibrium has index +1 if and only if it\ncan be made unique in a larger game obtained by adding finitely many strategies\nthat are inferior replies to that equilibrium. Our second result gives an\naxiomatic extension of sustainability to all games and shows that only the Nash\ncomponents with positive index can be sustainable.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.14094v2"
    },
    {
        "title": "Investigating Wheat Price with a Multi-Agent Model",
        "authors": [
            "Gianfranco Giulioni",
            "Edmondo Di Giuseppe",
            "Massimiliano Pasqui",
            "Piero Toscano",
            "Francesco Miglietta"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  In this paper, we build a computational model for the analysis of\ninternational wheat spot price formation, its dynamics and the dynamics of\ninternationally exchanged quantities. The model has been calibrated using\nFAOSTAT data to evaluate its in-sample predictive power. The model is able to\ngenerate wheat prices in twelve international markets and wheat used quantities\nin twenty-four world regions. The time span considered goes from 1992 to 2013.\nIn our study, a particular attention was paid to the impact of Russian\nFederation's 2010 grain export ban on wheat price and internationally traded\nquantities. Among other results, we find that wheat average weighted world\nprice in 2013 would have been 3.55\\% lower than the observed one if the Russian\nFederation would not have imposed the export ban in 2010.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.10537v1"
    },
    {
        "title": "Exceeding Expectations: Stochastic Dominance as a General Decision\n  Theory",
        "authors": [
            "Christian Tarsney"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  The principle that rational agents should maximize expected utility or\nchoiceworthiness is intuitively plausible in many ordinary cases of\ndecision-making under uncertainty. But it is less plausible in cases of\nextreme, low-probability risk (like Pascal's Mugging), and intolerably\nparadoxical in cases like the St. Petersburg and Pasadena games. In this paper\nI show that, under certain conditions, stochastic dominance reasoning can\ncapture most of the plausible implications of expectational reasoning while\navoiding most of its pitfalls. Specifically, given sufficient background\nuncertainty about the choiceworthiness of one's options, many\nexpectation-maximizing gambles that do not stochastically dominate their\nalternatives \"in a vacuum\" become stochastically dominant in virtue of that\nbackground uncertainty. But, even under these conditions, stochastic dominance\nwill not require agents to accept options whose expectational superiority\ndepends on sufficiently small probabilities of extreme payoffs. The sort of\nbackground uncertainty on which these results depend looks unavoidable for any\nagent who measures the choiceworthiness of her options in part by the total\namount of value in the resulting world. At least for such agents, then,\nstochastic dominance offers a plausible general principle of choice under\nuncertainty that can explain more of the apparent rational constraints on such\nchoices than has previously been recognized.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.10895v5"
    },
    {
        "title": "Banking Stability System: Does it Matter if the Rate of Return is Fixed\n  or Stochastic?",
        "authors": [
            "Hassan Ghassan"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  The purpose is to compare the perfect Stochastic Return (SR) model like\nIslamic banks to the Fixed Return (FR) model as in conventional banks by\nmeasuring up their impacts at the macroeconomic level. We prove that if the\noptimal choice of investor share in SR model {\\alpha}* realizes the\nindifference of the financial institution toward SR and FR models, there exists\n{\\alpha} less than {\\alpha}* such that the banks strictly prefers the SR model.\nAlso, there exists {\\alpha}, {\\gamma} and {\\lambda} verifying the conditions of\n{\\alpha}-sharing such that each party in economy can be better under the SR\nmodel and the economic welfare could be improved in a Pareto-efficient way.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.11102v1"
    },
    {
        "title": "Preference Identification",
        "authors": [
            "Christopher P. Chambers",
            "Federico Echenique",
            "Nicolas S. Lambert"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  An experimenter seeks to learn a subject's preference relation. The\nexperimenter produces pairs of alternatives. For each pair, the subject is\nasked to choose. We argue that, in general, large but finite data do not give\nclose approximations of the subject's preference, even when the limiting\n(countably infinite) data are enough to infer the preference perfectly. We\nprovide sufficient conditions on the set of alternatives, preferences, and\nsequences of pairs so that the observation of finitely many choices allows the\nexperimenter to learn the subject's preference with arbitrary precision. While\npreferences can be identified under our sufficient conditions, we show that it\nis harder to identify utility functions. We illustrate our results with several\nexamples, including consumer choice, expected utility, and preferences in the\nAnscombe-Aumann model.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.11585v1"
    },
    {
        "title": "Strictly strategy-proof auctions",
        "authors": [
            "Matteo Escudé",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  A strictly strategy-proof mechanism is one that asks agents to use strictly\ndominant strategies. In the canonical one-dimensional mechanism design setting\nwith private values, we show that strict strategy-proofness is equivalent to\nstrict monotonicity plus the envelope formula, echoing a well-known\ncharacterisation of (weak) strategy-proofness. A consequence is that\nstrategy-proofness can be made strict by an arbitrarily small modification, so\nthat strictness is 'essentially for free'.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.11864v4"
    },
    {
        "title": "Herding driven by the desire to differ",
        "authors": [
            "Sander Heinsalu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Observational learning often involves congestion: an agent gets lower payoff\nfrom an action when more predecessors have taken that action. This preference\nto act differently from previous agents may paradoxically increase all but one\nagent's probability of matching the actions of the predecessors. The reason is\nthat when previous agents conform to their predecessors despite the preference\nto differ, their actions become more informative. The desire to match\npredecessors' actions may reduce herding by a similar reasoning.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.00454v1"
    },
    {
        "title": "Optimal mechanism for the sale of a durable good",
        "authors": [
            "Laura Doval",
            "Vasiliki Skreta"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  A buyer wishes to purchase a durable good from a seller who in each period\nchooses a mechanism under limited commitment. The buyer's valuation is binary\nand fully persistent. We show that posted prices implement all equilibrium\noutcomes of an infinite-horizon, mechanism selection game. Despite being able\nto choose mechanisms, the seller can do no better and no worse than if he chose\nprices in each period, so that he is subject to Coase's conjecture. Our\nanalysis marries insights from information and mechanism design with those from\nthe literature on durable goods. We do so by relying on the revelation\nprinciple in Doval and Skreta (2020).\n",
        "pdf_link": "http://arxiv.org/pdf/1904.07456v7"
    },
    {
        "title": "Limits to green growth and the dynamics of innovation",
        "authors": [
            "Salvador Pueyo"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Central to the official \"green growth\" discourse is the conjecture that\nabsolute decoupling can be achieved with certain market instruments. This paper\nevaluates this claim focusing on the role of technology, while changes in GDP\ncomposition are treated elsewhere. Some fundamental difficulties for absolute\ndecoupling, referring specifically to thermodynamic costs, are identified\nthrough a stylized model based on empirical knowledge on innovation and\nlearning. Normally, monetary costs decrease more slowly than production grows,\nand this is unlikely to change should monetary costs align with thermodynamic\ncosts, except, potentially, in the transition after the price reform.\nFurthermore, thermodynamic efficiency must eventually saturate for physical\nreasons. While this model, as usual, introduces technological innovation just\nas a source of efficiency, innovation also creates challenges: therefore,\nattempts to sustain growth by ever-accelerating innovation collide also with\nthe limited reaction capacity of people and institutions. Information\ntechnology could disrupt innovation dynamics in the future, permitting quicker\ngains in eco-efficiency, but only up to saturation and exacerbating the\ndownsides of innovation. These observations suggest that long-term\nsustainability requires much deeper transformations than the green growth\ndiscourse presumes, exposing the need to rethink scales, tempos and\ninstitutions, in line with ecological economics and the degrowth literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.09586v2"
    },
    {
        "title": "Tax Mechanisms and Gradient Flows",
        "authors": [
            "Stefan Steinerberger",
            "Aleh Tsyvinski"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We demonstrate how a static optimal income taxation problem can be analyzed\nusing dynamical methods. Specifically, we show that the taxation problem is\nintimately connected to the heat equation. Our first result is a new property\nof the optimal tax which we call the fairness principle. The optimal tax at any\nincome is invariant under a family of properly adjusted Gaussian averages (the\nheat kernel) of the optimal taxes at other incomes. That is, the optimal tax at\na given income is equal to the weighted by the heat kernels average of optimal\ntaxes at other incomes and income densities. Moreover, this averaging happens\nat every scale tightly linked to each other providing a unified weighting\nscheme at all income ranges. The fairness principle arises not due to equality\nconsiderations but rather it represents an efficient way to smooth the burden\nof taxes and generated revenues across incomes. Just as nature wants to\ndistribute heat evenly, the optimal way for a government to raise revenues is\nto distribute the tax burden and raised revenues evenly among individuals. We\nthen construct a gradient flow of taxes -- a dynamic process changing the\nexisting tax system in the direction of the increase in tax revenues -- and\nshow that it takes the form of a heat equation. The fairness principle holds\nalso for the short-term asymptotics of the gradient flow, where the averaging\nis done over the current taxes. The gradient flow we consider can be viewed as\na continuous process of a reform of the nonlinear income tax schedule and thus\nunifies the variational approach to taxation and optimal taxation. We present\nseveral other characteristics of the gradient flow focusing on its smoothing\nproperties.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.13276v1"
    },
    {
        "title": "Dynamic Information Design with Diminishing Sensitivity Over News",
        "authors": [
            "Jetlir Duraj",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  A Bayesian agent experiences gain-loss utility each period over changes in\nbelief about future consumption (\"news utility\"), with diminishing sensitivity\nover the magnitude of news. Diminishing sensitivity induces a preference over\nnews skewness: gradual bad news, one-shot good news is worse than one-shot\nresolution, which is in turn worse than gradual good news, one-shot bad news.\nSo, the agent's preference between gradual information and one-shot resolution\ncan depend on his consumption ranking of different states. In a dynamic\ncheap-talk framework where a benevolent sender communicates the state over\nmultiple periods, the babbling equilibrium is essentially unique without loss\naversion. More loss-averse agents may enjoy higher news utility in equilibrium,\ncontrary to the commitment case. We characterize the family of gradual good\nnews equilibria that exist with high enough loss aversion, and find the sender\nconveys progressively larger pieces of good news. We discuss applications to\nmedia competition and game shows.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.00084v5"
    },
    {
        "title": "The interest rate for saving as a possibilistic risk",
        "authors": [
            "Irina Georgescu",
            "Jani Kinnunen"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In the paper there is studied an optimal saving model in which the\ninterest-rate risk for saving is a fuzzy number. The total utility of\nconsumption is defined by using a concept of possibilistic expected utility. A\nnotion of possibilistic precautionary saving is introduced as a measure of the\nvariation of optimal saving level when moving from a sure saving model to a\npossibilistic risk model. A first result establishes a necessary and sufficient\ncondition that the presence of a possibilistic interest-rate risk generates an\nextra-saving. This result can be seen as a possibilistic version of a\nRothschilld and Stiglitz theorem on a probabilistic model of saving. A second\nresult of the paper studies the variation of the optimal saving level when\nmoving from a probabilistic model (the interest-rate risk is a random variable)\nto a possibilistic model (the interest-rate risk is a fuzzy number).\n",
        "pdf_link": "http://arxiv.org/pdf/1908.00445v1"
    },
    {
        "title": "Third person enforcement in a prisoner's dilemma game",
        "authors": [
            "Tatsuhiro Shichijo"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We theoretically study the effect of a third person enforcement on a one-shot\nprisoner's dilemma game played by two persons, with whom the third person plays\nrepeated prisoner's dilemma games. We find that the possibility of the third\nperson's future punishment causes them to cooperate in the one-shot game.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.04971v1"
    },
    {
        "title": "Equilibrium in Production Chains with Multiple Upstream Partners",
        "authors": [
            "Meng Yu",
            "Junnan Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this paper, we extend and improve the production chain model introduced by\nKikuchi et al. (2018). Utilizing the theory of monotone concave operators, we\nprove the existence, uniqueness, and global stability of equilibrium price,\nhence improving their results on production networks with multiple upstream\npartners. We propose an algorithm for computing the equilibrium price function\nthat is more than ten times faster than successive evaluations of the operator.\nThe model is then generalized to a stochastic setting that offers richer\nimplications for the distribution of firms in a production network.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.08208v1"
    },
    {
        "title": "Improving Information from Manipulable Data",
        "authors": [
            "Alex Frankel",
            "Navin Kartik"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Data-based decisionmaking must account for the manipulation of data by agents\nwho are aware of how decisions are being made and want to affect their\nallocations. We study a framework in which, due to such manipulation, data\nbecomes less informative when decisions depend more strongly on data. We\nformalize why and how a decisionmaker should commit to underutilizing data.\nDoing so attenuates information loss and thereby improves allocation accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.10330v5"
    },
    {
        "title": "A Cardinal Comparison of Experts",
        "authors": [
            "Itay Kavaler",
            "Rann Smorodinsky"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In various situations, decision makers face experts that may provide\nconflicting advice. This advice may be in the form of probabilistic forecasts\nover critical future events. We consider a setting where the two forecasters\nprovide their advice repeatedly and ask whether the decision maker can learn to\ncompare and rank the two forecasters based on past performance. We take an\naxiomatic approach and propose three natural axioms that a comparison test\nshould comply with. We propose a test that complies with our axioms. Perhaps,\nnot surprisingly, this test is closely related to the likelihood ratio of the\ntwo forecasts over the realized sequence of events. More surprisingly, this\ntest is essentially unique. Furthermore, using results on the rate of\nconvergence of supermartingales, we show that whenever the two\nexperts\\textquoteright{} advice are sufficiently distinct, the proposed test\nwill detect the informed expert in any desired degree of precision in some\nfixed finite time.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.10649v3"
    },
    {
        "title": "Rational Inattention and Perceptual Distance",
        "authors": [
            "David Walker-Jones"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper uses an axiomatic foundation to create a new measure for the cost\nof learning that allows for multiple perceptual distances in a single choice\nenvironment so that some events can be harder to differentiate between than\nothers. The new measure maintains the tractability of Shannon's classic measure\nbut produces richer choice predictions and identifies a new form of\ninformational bias significant for welfare and counterfactual analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.00888v2"
    },
    {
        "title": "Scoring Strategic Agents",
        "authors": [
            "Ian Ball"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  I introduce a model of predictive scoring. A receiver wants to predict a\nsender's quality. An intermediary observes multiple features of the sender and\naggregates them into a score. Based on the score, the receiver makes a\ndecision. The sender prefers \"higher\" decisions, and she can distort each\nfeature at a privately known cost. I characterize the scoring rule that\nmaximizes decision accuracy. This rule underweights some features to deter\nsender distortion, and overweights other features so that the score is correct\non average. The receiver prefers this scoring rule to full disclosure because\nit mitigates his commitment problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01888v6"
    },
    {
        "title": "Illiquid Financial Markets and Monetary Policy",
        "authors": [
            "Athanasios Geromichalos",
            "Juan M. Licari",
            "Jose Suarez-Lledo"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper analyzes the role of money in asset markets characterized by\nsearch frictions. We develop a dynamic framework that brings together a model\nfor illiquid financial assets `a la Duffie, Garleanu, and Pedersen, and a\nsearch-theoretic model of monetary exchange `a la Lagos and Wright. The\npresence of decentralized financial markets generates an essential role for\nmoney, which helps investors re-balance their portfolios. We provide conditions\nthat guarantee the existence of a monetary equilibrium. In this case, asset\nprices are always above their fundamental value, and this differential\nrepresents a liquidity premium. We are able to derive an asset pricing theory\nthat delivers an explicit connection between monetary policy, asset prices, and\nwelfare. We obtain a negative relationship between inflation and equilibrium\nasset prices. This key result stems from the complementarity between money and\nassets in our framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01889v1"
    },
    {
        "title": "Constrained Pseudo-market Equilibrium",
        "authors": [
            "Federico Echenique",
            "Antonio Miralles",
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We propose a pseudo-market solution to resource allocation problems subject\nto constraints. Our treatment of constraints is general: including\nbihierarchical constraints due to considerations of diversity in school choice,\nor scheduling in course allocation; and other forms of constraints needed to\nmodel, for example, the market for roommates, and combinatorial assignment\nproblems. Constraints give rise to pecuniary externalities, which are\ninternalized via prices. Agents pay to the extent that their purchases affect\nthe value of relevant constraints at equilibrium prices. The result is a\nconstrained efficient market equilibrium outcome. The outcome is fair whenever\nthe constraints do not single out individual agents. Our result can be extended\nto economies with endowments, and address participation constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.05986v4"
    },
    {
        "title": "Overconfidence and Prejudice",
        "authors": [
            "Paul Heidhues",
            "Botond Kőszegi",
            "Philipp Strack"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We explore conclusions a person draws from observing society when he allows\nfor the possibility that individuals' outcomes are affected by group-level\ndiscrimination. Injecting a single non-classical assumption, that the agent is\noverconfident about himself, we explain key observed patterns in social\nbeliefs, and make a number of additional predictions. First, the agent believes\nin discrimination against any group he is in more than an outsider does,\ncapturing widely observed self-centered views of discrimination. Second, the\nmore group memberships the agent shares with an individual, the more positively\nhe evaluates the individual. This explains one of the most basic facts about\nsocial judgments, in-group bias, as well as \"legitimizing myths\" that justify\nan arbitrary social hierarchy through the perceived superiority of the\nprivileged group. Third, biases are sensitive to how the agent divides society\ninto groups when evaluating outcomes. This provides a reason why some\nethnically charged questions should not be asked, as well as a potential\nchannel for why nation-building policies might be effective. Fourth, giving the\nagent more accurate information about himself increases all his biases. Fifth,\nthe agent is prone to substitute biases, implying that the introduction of a\nnew outsider group to focus on creates biases against the new group but lowers\nbiases vis a vis other groups. Sixth, there is a tendency for the agent to\nagree more with those in the same groups. As a microfoundation for our model,\nwe provide an explanation for why an overconfident agent might allow for\npotential discrimination in evaluating outcomes, even when he initially did not\nconceive of this possibility.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.08497v1"
    },
    {
        "title": "Time-consistent decisions and rational expectation equilibrium existence\n  in DSGE models",
        "authors": [
            "Minseong Kim"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Under some initial conditions, it is shown that time consistency requirements\nprevent rational expectation equilibrium (REE) existence for dynamic stochastic\ngeneral equilibrium models induced by consumer heterogeneity, in contrast to\nstatic models. However, one can consider REE-prohibiting initial conditions as\nlimits of other initial conditions. The REE existence issue then is overcome by\nusing a limit of economies. This shows that significant care must be taken of\nwhen dealing with rational expectation equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.10915v4"
    },
    {
        "title": "The converse envelope theorem",
        "authors": [
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  I prove an envelope theorem with a converse: the envelope formula is\nequivalent to a first-order condition. Like Milgrom and Segal's (2002) envelope\ntheorem, my result requires no structure on the choice set. I use the converse\nenvelope theorem to extend to general outcomes and preferences the canonical\nresult in mechanism design that any increasing allocation is implementable, and\napply this to selling information.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11219v5"
    },
    {
        "title": "Undiscounted Bandit Games",
        "authors": [
            "Godfrey Keller",
            "Sven Rady"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We analyze undiscounted continuous-time games of strategic experimentation\nwith two-armed bandits. The risky arm generates payoffs according to a L\\'{e}vy\nprocess with an unknown average payoff per unit of time which nature draws from\nan arbitrary finite set. Observing all actions and realized payoffs, plus a\nfree background signal, players use Markov strategies with the common posterior\nbelief about the unknown parameter as the state variable. We show that the\nunique symmetric Markov perfect equilibrium can be computed in a simple closed\nform involving only the payoff of the safe arm, the expected current payoff of\nthe risky arm, and the expected full-information payoff, given the current\nbelief. In particular, the equilibrium does not depend on the precise\nspecification of the payoff-generating processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.13323v4"
    },
    {
        "title": "Time discounting under uncertainty",
        "authors": [
            "Lorenzo Bastianello",
            "José Heleno Faro"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study intertemporal decision making under uncertainty. We fully\ncharacterize discounted expected utility in a framework \\`a la Savage. Despite\nthe popularity of this model, no characterization is available in this setting.\nThe concept of stationarity, introduced by Koopmans for deterministic\ndiscounted utility, plays a central role for both attitudes towards time and\ntowards uncertainty. We show that a strong stationarity axiom characterizes\ndiscounted expected utility. When hedging considerations are taken into\naccount, a weaker stationarity axiom generalizes discounted expected utility to\nChoquet discounted expected utility, allowing for non-neutral attitudes towards\nuncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.00370v2"
    },
    {
        "title": "Aggregation for potentially infinite populations without continuity or\n  completeness",
        "authors": [
            "David McCarthy",
            "Kalle Mikkola",
            "Teruji Thomas"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We present an abstract social aggregation theorem. Society, and each\nindividual, has a preorder that may be interpreted as expressing values or\nbeliefs. The preorders are allowed to violate both completeness and continuity,\nand the population is allowed to be infinite. The preorders are only assumed to\nbe represented by functions with values in partially ordered vector spaces, and\nwhose product has convex range. This includes all preorders that satisfy strong\nindependence. Any Pareto indifferent social preorder is then shown to be\nrepresented by a linear transformation of the representations of the individual\npreorders. Further Pareto conditions on the social preorder correspond to\npositivity conditions on the transformation. When all the Pareto conditions\nhold and the population is finite, the social preorder is represented by a sum\nof individual preorder representations. We provide two applications. The first\nyields an extremely general version of Harsanyi's social aggregation theorem.\nThe second generalizes a classic result about linear opinion pooling.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.00872v1"
    },
    {
        "title": "Relative Maximum Likelihood Updating of Ambiguous Beliefs",
        "authors": [
            "Xiaoyu Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper proposes and axiomatizes a new updating rule: Relative Maximum\nLikelihood (RML) for ambiguous beliefs represented by a set of priors (C). This\nrule takes the form of applying Bayes' rule to a subset of C. This subset is a\nlinear contraction of C towards its subset ascribing a maximal probability to\nthe observed event. The degree of contraction captures the extent of\nwillingness to discard priors based on likelihood when updating. Two well-known\nupdating rules of multiple priors, Full Bayesian (FB) and Maximum Likelihood\n(ML), are included as special cases of RML. An axiomatic characterization of\nconditional preferences generated by RML updating is provided when the\npreferences admit Maxmin Expected Utility representations. The axiomatization\nrelies on weakening the axioms characterizing FB and ML. The axiom\ncharacterizing ML is identified for the first time in this paper, addressing a\nlong-standing open question in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.02678v6"
    },
    {
        "title": "Behavioral Equivalence of Extensive Game Structures",
        "authors": [
            "Pierpaolo Battigalli",
            "Paolo Leonetti",
            "Fabio Maccheroni"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Two extensive game structures with imperfect information are said to be\nbehaviorally equivalent if they share the same map (up to relabelings) from\nprofiles of structurally reduced strategies to induced terminal paths. We show\nthat this is the case if and only if one can be transformed into the other\nthrough a composition of two elementary transformations, commonly known as\n\\textquotedblleft Interchanging of Simultaneous Moves\\textquotedblright\\ and\n\\textquotedblleft Coalescing Moves/Sequential Agent\nSplitting.\\textquotedblright\n",
        "pdf_link": "http://arxiv.org/pdf/1911.02918v1"
    },
    {
        "title": "Distributionally Robust Optimal Auction Design under Mean Constraints",
        "authors": [
            "Ethan Che"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a seller who sells a single good to multiple bidders with\nuncertainty over the joint distribution of bidders' valuations, as well as\nbidders' higher-order beliefs about their opponents. The seller only knows the\n(possibly asymmetric) means of the marginal distributions of each bidder's\nvaluation and the range. An adversarial nature chooses the worst-case\ndistribution within this ambiguity set along with the worst-case information\nstructure. We find that a second-price auction with a symmetric, random reserve\nprice obtains the optimal revenue guarantee within a broad class of mechanisms\nwe refer to as competitive mechanisms, which include standard auction formats,\nincluding the first-price auction, with or without reserve prices. The optimal\nmechanism possesses two notable characteristics. First, the mechanism treats\nall bidders identically even in the presence of ex-ante asymmetries. Second,\nwhen bidders are identical and the number of bidders $n$ grows large, the\nseller's optimal reserve price converges in probability to a non-binding\nreserve price and the revenue guarantee converges to the best possible revenue\nguarantee at rate $O(1/n)$.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07103v3"
    },
    {
        "title": "Information Disclosure and Promotion Policy Design for Platforms",
        "authors": [
            "Yonatan Gur",
            "Gregory Macnamara",
            "Ilan Morgenstern",
            "Daniela Saban"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We consider a platform facilitating trade between sellers and buyers with the\nobjective of maximizing consumer surplus. Even though in many such marketplaces\nprices are set by revenue-maximizing sellers, platforms can influence prices\nthrough (i) price-dependent promotion policies that can increase demand for a\nproduct by featuring it in a prominent position on the webpage and (ii) the\ninformation revealed to sellers about the value of being promoted. Identifying\neffective joint information design and promotion policies is a challenging\ndynamic problem as sellers can sequentially learn the promotion value from\nsales observations and update prices accordingly. We introduce the notion of\nconfounding promotion policies, which are designed to prevent a Bayesian seller\nfrom learning the promotion value (at the expense of the short-run loss of\ndiverting some consumers from the best product offering). Leveraging these\npolicies, we characterize the maximum long-run average consumer surplus that is\nachievable through joint information design and promotion policies when the\nseller sets prices myopically. We then construct a Bayesian Nash equilibrium in\nwhich the seller's best response to the platform's optimal policy is to price\nmyopically in every period. Moreover, the equilibrium we identify is\nplatform-optimal within the class of horizon-maximin equilibria, in which\nstrategies are not predicated on precise knowledge of the horizon length, and\nare designed to maximize payoff over the worst-case horizon. Our analysis\nallows one to identify practical long-run average optimal platform policies in\na broad range of demand models.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.09256v5"
    },
    {
        "title": "Guarantees in Fair Division: general or monotone preferences",
        "authors": [
            "Anna bogomolnaia",
            "Herve Moulin"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  To divide a \"manna\" {\\Omega} of private items (commodities, workloads, land,\ntime intervals) between n agents, the worst case measure of fairness is the\nwelfare guaranteed to each agent, irrespective of others' preferences. If the\nmanna is non atomic and utilities are continuous (not necessarily monotone or\nconvex), we can guarantee the minMax utility: that of our agent's best share in\nher worst partition of the manna; and implement it by Kuhn's generalisation of\nDivide and Choose. The larger Maxmin utility -- of her worst share in her best\npartition -- cannot be guaranteed, even for two agents. If for all agents more\nmanna is better than less (or less is better than more), our Bid & Choose rules\nimplement guarantees between minMax and Maxmin by letting agents bid for the\nsmallest (or largest) size of a share they find acceptable.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.10009v3"
    },
    {
        "title": "A Contribution to Theory of Factor Income Distribution, Cambridge\n  Capital Controversy and Equity Premium Puzzle",
        "authors": [
            "Xiaofeng Liu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Under very general conditions, we construct a micro-macro model for closed\neconomy with a large number of heterogeneous agents. By introducing both\nfinancial capital (i.e. valued capital---- equities of firms) and physical\ncapital (i.e. capital goods), our framework gives a logically consistent,\ncomplete factor income distribution theory with micro-foundation. The model\nshows factor incomes obey different distribution rules at the micro and macro\nlevels, while marginal distribution theory and no-arbitrage princi-ple are\nunified into a common framework. Our efforts solve the main problems of\nCambridge capital controversy, and reasonably explain the equity premium\npuzzle. Strong empirical evidences support our results.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12490v2"
    },
    {
        "title": "Evaluating the Properties of a First Choice Weighted Approval Voting\n  System",
        "authors": [
            "Peter Butler",
            "Jerry Lin"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Plurality and approval voting are two well-known voting systems with\ndifferent strengths and weaknesses. In this paper we consider a new voting\nsystem we call beta(k) which allows voters to select a single first-choice\ncandidate and approve of any other number of candidates, where k denotes the\nrelative weight given to a first choice; this system is essentially a hybrid of\nplurality and approval. Our primary goal is to characterize the behavior of\nbeta(k) for any value of k. Under certain reasonable assumptions, beta(k) can\nbe made to mimic plurality or approval voting in the event of a single winner\nwhile potentially breaking ties otherwise. Under the assumption that voters are\nhonest, we show that it is possible to find the values of k for which a given\ncandidate will win the election if the respective approval and plurality votes\nare known. Finally, we show how some of the commonly used voting system\ncriteria are satisfied by beta(k).\n",
        "pdf_link": "http://arxiv.org/pdf/2006.00368v1"
    },
    {
        "title": "Extractive contest design",
        "authors": [
            "Tomohiko Kawamori"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider contest success functions (CSFs) that extract contestants' prize\nvalues. In the common-value case, there exists a CSF extractive in any\nequilibrium. In the observable-private-value case, there exists a CSF\nextractive in some equilibrium; there exists a CSF extractive in any\nequilibrium if and only if the number of contestants is greater than or equal\nto three or the values are homogeneous. In the unobservable-private-value case,\nthere exists no CSF extractive in some equilibrium. When extractive CSFs exist,\nwe explicitly present one of them.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.01808v3"
    },
    {
        "title": "The importance of being discrete: on the inaccuracy of continuous\n  approximations in auction theory",
        "authors": [
            "Itzhak Rasooly",
            "Carlos Gavidia-Calderon"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  While auction theory views bids and valuations as continuous variables,\nreal-world auctions are necessarily discrete. In this paper, we use a\ncombination of analytical and computational methods to investigate whether\nincorporating discreteness substantially changes the predictions of auction\ntheory, focusing on the case of uniformly distributed valuations so that our\nresults bear on the majority of auction experiments. In some cases, we find\nthat introducing discreteness changes little. For example, the first-price\nauction with two bidders and an even number of values has a symmetric\nequilibrium that closely resembles its continuous counterpart and converges to\nits continuous counterpart as the discretisation goes to zero. In others,\nhowever, we uncover discontinuity results. For instance, introducing an\narbitrarily small amount of discreteness into the all-pay auction makes its\nsymmetric, pure-strategy equilibrium disappear; and appears (based on\ncomputational experiments) to rob the game of pure-strategy equilibria\naltogether. These results raise questions about the continuity approximations\non which auction theory is based and prompt a re-evaluation of the experimental\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.03016v3"
    },
    {
        "title": "Innovation and imitation",
        "authors": [
            "Jess Benhabib",
            "Éric Brunet",
            "Mildred Hager"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study several models of growth driven by innovation and imitation by a\ncontinuum of firms, focusing on the interaction between the two. We first\ninvestigate a model on a technology ladder where innovation and imitation\ncombine to generate a balanced growth path (BGP) with compact support, and with\nproductivity distributions for firms that are truncated power-laws. We start\nwith a simple model where firms can adopt technologies of other firms with\nhigher productivities according to exogenous probabilities. We then study the\ncase where the adoption probabilities depend on the probability distribution of\nproductivities at each time. We finally consider models with a finite number of\nfirms, which by construction have firm productivity distributions with bounded\nsupport. Stochastic imitation and innovation can make the distance of the\nproductivity frontier to the lowest productivity level fluctuate, and this\ndistance can occasionally become large. Alternatively, if we fix the length of\nthe support of the productivity distribution because firms too far from the\nfrontier cannot survive, the number of firms can fluctuate randomly.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06315v2"
    },
    {
        "title": "Delegation in Veto Bargaining",
        "authors": [
            "Navin Kartik",
            "Andreas Kleiner",
            "Richard Van Weelden"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A proposer requires the approval of a veto player to change a status quo.\nPreferences are single peaked. Proposer is uncertain about Vetoer's ideal\npoint. We study Proposer's optimal mechanism without transfers. Vetoer is given\na menu, or a delegation set, to choose from. The optimal delegation set\nbalances the extent of Proposer's compromise with the risk of a veto. Under\nreasonable conditions, \"full delegation\" is optimal: Vetoer can choose any\naction between the status quo and Proposer's ideal action. This outcome largely\nnullifies Proposer's bargaining power; Vetoer frequently obtains her ideal\npoint, and there is Pareto efficiency despite asymmetric information. More\ngenerally, we identify when \"interval delegation\" is optimal. Optimal interval\ndelegation can be a Pareto improvement over cheap talk. We derive comparative\nstatics. Vetoer receives less discretion when preferences are more likely to be\naligned, by contrast to expertise-based delegation. Methodologically, our\nanalysis handles stochastic mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06773v3"
    },
    {
        "title": "Incentives and Efficiency in Constrained Allocation Mechanisms",
        "authors": [
            "Joseph Root",
            "David S. Ahn"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study private-good allocation under general constraints. Several prominent\nexamples are special cases, including house allocation, roommate matching,\nsocial choice, and multiple assignment. Every individually strategy-proof and\nPareto efficient two-agent mechanism is an \"adapted local dictatorship.\" Every\ngroup strategy-proof N-agent mechanism has two-agent marginal mechanisms that\nare adapted local dictatorships. These results yield new characterizations and\nunifying insights for known characterizations. We find all group strategy-proof\nand Pareto efficient mechanisms for the roommates problem. We give a related\nresult for multiple assignment. We prove the Gibbard--Satterthwaite Theorem and\ngive a partial converse.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06776v2"
    },
    {
        "title": "Optimal Attention Management: A Tractable Framework",
        "authors": [
            "Elliot Lipnowski",
            "Laurent Mathevet",
            "Dong Wei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A well-intentioned principal provides information to a rationally inattentive\nagent without internalizing the agent's cost of processing information.\nWhatever information the principal makes available, the agent may choose to\nignore some. We study optimal information provision in a tractable model with\nquadratic payoffs where full disclosure is not optimal. We characterize\nincentive-compatible information policies, that is, those to which the agent\nwillingly pays full attention. In a leading example with three states, optimal\ndisclosure involves information distortion at intermediate costs of attention.\nAs the cost increases, optimal information abruptly changes from downplaying\nthe state to exaggerating the state.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.07729v2"
    },
    {
        "title": "Reputation Building under Observational Learning",
        "authors": [
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  I study a social learning model in which the object to learn is a strategic\nplayer's endogenous actions rather than an exogenous state. A patient seller\nfaces a sequence of buyers and decides whether to build a reputation for\nsupplying high quality products. Each buyer does not have access to the\nseller's complete records, but can observe all previous buyers' actions, and\nsome informative private signal about the seller's actions. I examine how the\nbuyers' private signals affect the speed of social learning and the seller's\nincentives to establish reputations. When each buyer privately observes a\nbounded subset of the seller's past actions, the speed of learning is strictly\npositive but can vanish to zero as the seller becomes patient. As a result,\nreputation building can lead to low payoff for the patient seller and low\nsocial welfare. When each buyer observes an unboundedly informative private\nsignal about the seller's current-period action, the speed of learning is\nuniformly bounded from below and a patient seller can secure high returns from\nbuilding reputations. My results shed light on the effectiveness of various\npolicies in accelerating social learning and encouraging sellers to establish\ngood reputations.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.08068v6"
    },
    {
        "title": "Repeated Communication with Private Lying Cost",
        "authors": [
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  I study repeated communication games between a patient sender and a sequence\nof receivers. The sender has persistent private information about his\npsychological cost of lying, and in every period, can privately observe the\nrealization of an i.i.d. state before communication takes place. I characterize\nevery type of sender's highest equilibrium payoff. When the highest lying cost\nin the support of the receivers' prior belief approaches the sender's benefit\nfrom lying, every type's highest equilibrium payoff in the repeated\ncommunication game converges to his equilibrium payoff in a one-shot Bayesian\npersuasion game. I also show that in every sender-optimal equilibrium, no type\nof sender mixes between telling the truth and lying at every history. When\nthere exist ethical types whose lying costs outweigh their benefits, I provide\nnecessary and sufficient conditions for all non-ethical type senders to attain\ntheir optimal commitment payoffs. I identify an outside option effect through\nwhich the possibility of being ethical decreases every non-ethical type's\npayoff.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.08069v1"
    },
    {
        "title": "Trust and Betrayals: Reputational Payoffs and Behaviors without\n  Commitment",
        "authors": [
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  I study a repeated game in which a patient player (e.g., a seller) wants to\nwin the trust of some myopic opponents (e.g., buyers) but can strictly benefit\nfrom betraying them. Her benefit from betrayal is strictly positive and is her\npersistent private information. I characterize every type of patient player's\nhighest equilibrium payoff. Her persistent private information affects this\npayoff only through the lowest benefit in the support of her opponents' prior\nbelief. I also show that in every equilibrium which is optimal for the patient\nplayer, her on-path behavior is nonstationary, and her long-run action\nfrequencies are pinned down for all except two types. Conceptually, my\npayoff-type approach incorporates a realistic concern that no type of\nreputation-building player is immune to reneging temptations. Compared to\ncommitment-type models, the incentive constraints for all types of patient\nplayer lead to a sharp characterization of her highest attainable payoff and\nnovel predictions on her behaviors.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.08071v1"
    },
    {
        "title": "Nash SIR: An Economic-Epidemiological Model of Strategic Behavior During\n  a Viral Epidemic",
        "authors": [
            "David McAdams"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper develops a Nash-equilibrium extension of the classic SIR model of\ninfectious-disease epidemiology (\"Nash SIR\"), endogenizing people's decisions\nwhether to engage in economic activity during a viral epidemic and allowing for\ncomplementarity in social-economic activity. An equilibrium epidemic is one in\nwhich Nash equilibrium behavior during the epidemic generates the epidemic.\nThere may be multiple equilibrium epidemics, in which case the epidemic\ntrajectory can be shaped through the coordination of expectations, in addition\nto other sorts of interventions such as stay-at-home orders and accelerated\nvaccine development. An algorithm is provided to compute all equilibrium\nepidemics.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.10109v1"
    },
    {
        "title": "Mechanism of Instrumental Game Theory in The Legal Process via\n  Stochastic Options Pricing Induction",
        "authors": [
            "Kwadwo Osei Bonsu",
            "Shoucan Chen"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Economic theory has provided an estimable intuition in understanding the\nperplexing ideologies in law, in the areas of economic law, tort law, contract\nlaw, procedural law and many others. Most legal systems require the parties\ninvolved in a legal dispute to exchange information through a process called\ndiscovery. The purpose is to reduce the relative optimisms developed by\nasymmetric information between the parties. Like a head or tail phenomenon in\nstochastic processes, uncertainty in the adjudication affects the decisions of\nthe parties in a legal negotiation. This paper therefore applies the principles\nof aleatory analysis to determine how negotiations fail in the legal process,\nintroduce the axiological concept of optimal transaction cost and formulates a\nnumerical methodology based on backwards induction and stochastic options\npricing economics in estimating the reasonable and fair bargain in order to\ninduce settlements thereby increasing efficiency and reducing social costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.11061v1"
    },
    {
        "title": "The uniqueness of dynamic Groves mechanisms on restricted domains",
        "authors": [
            "Kiho Yoon"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper examines necessary and sufficient conditions for the uniqueness of\ndynamic Groves mechanisms when the domain of valuations is restricted. Our\napproach is to appropriately define the total valuation function, which is the\nexpected discounted sum of each period's valuation function from the allocation\nand thus a dynamic counterpart of the static valuation function, and then to\nport the results for static Groves mechanisms to the dynamic setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14190v1"
    },
    {
        "title": "Comparative Statics in Multicriteria Search Models",
        "authors": [
            "Veli Safak"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  McCall (1970) examines the search behaviour of an infinitely-lived and\nrisk-neutral job seeker maximizing her lifetime earnings by accepting or\nrejecting real-valued scalar wage offers. In practice, job offers have multiple\nattributes, and job seekers solve a multicriteria search problem. This paper\npresents a multicriteria search model and new comparative statics results.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14452v1"
    },
    {
        "title": "Social Welfare in Search Games with Asymmetric Information",
        "authors": [
            "Gilad Bavly",
            "Yuval Heller",
            "Amnon Schreiber"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider games in which players search for a hidden prize, and they have\nasymmetric information about the prize location. We study the social payoff in\nequilibria of these games. We present sufficient conditions for the existence\nof an equilibrium that yields the first-best payoff (i.e., the highest social\npayoff under any strategy profile), and we characterize the first-best payoff.\nThe results have interesting implications for innovation contests and R&D\nraces.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14860v2"
    },
    {
        "title": "Revealing Choice Bracketing",
        "authors": [
            "Andrew Ellis",
            "David J. Freeman"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Experiments suggest that people fail to take into account interdependencies\nbetween their choices -- they do not broadly bracket. Researchers often instead\nassume that people narrowly bracket, but existing designs do not test it. We\ndesign a novel experiment and revealed preference tests for how someone\nbrackets their choices. In portfolio allocation under risk, social allocation,\nand induced-value shopping experiments, 40-43% of subjects are consistent with\nnarrow bracketing and 0-16% with broad bracketing. Adjusting for each model's\npredictive precision, 74% of subjects are best described by narrow bracketing,\n13% by broad bracketing, and 6% by intermediate cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14869v4"
    },
    {
        "title": "Biased-Belief Equilibrium",
        "authors": [
            "Yuval Heller",
            "Eyal Winter"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We investigate how distorted, yet structured, beliefs can persist in\nstrategic situations. Specifically, we study two-player games in which each\nplayer is endowed with a biased-belief function that represents the discrepancy\nbetween a player's beliefs about the opponent's strategy and the actual\nstrategy. Our equilibrium condition requires that (i) each player choose a\nbest-response strategy to his distorted belief about the opponent's strategy,\nand (ii) the distortion functions form best responses to one another. We obtain\nsharp predictions and novel insights into the set of stable outcomes and their\nsupporting stable biases in various classes of games.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15306v1"
    },
    {
        "title": "Coevolution of deception and preferences: Darwin and Nash meet\n  Machiavelli",
        "authors": [
            "Yuval Heller",
            "Erik Mohlin"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We develop a framework in which individuals' preferences coevolve with their\nabilities to deceive others about their preferences and intentions.\nSpecifically, individuals are characterised by (i) a level of cognitive\nsophistication and (ii) a subjective utility function. Increased cognition is\ncostly, but higher-level individuals have the advantage of being able to\ndeceive lower-level opponents about their preferences and intentions in some of\nthe matches. In the remaining matches, the individuals observe each other's\npreferences. Our main result shows that, essentially, only efficient outcomes\ncan be stable. Moreover, under additional mild assumptions, we show that an\nefficient outcome is stable if and only if the gain from unilateral deviation\nis smaller than the effective cost of deception in the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15308v1"
    },
    {
        "title": "A closed-form solution to the risk-taking motivation of subordinated\n  debtholders",
        "authors": [
            "Yuval Heller",
            " SharonPeleg-Lazar",
            "Alon Raviv"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Black and Cox (1976) claim that the value of junior debt is increasing in\nasset risk when the firm's value is low. We show, using closed-form solution,\nthat the junior debt's value is hump-shaped. This has interesting implications\nfor the market-discipline role of banks' junior debt.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15309v1"
    },
    {
        "title": "Observations on Cooperation",
        "authors": [
            "Yuval Heller",
            "Erik Mohlin"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study environments in which agents are randomly matched to play a\nPrisoner's Dilemma, and each player observes a few of the partner's past\nactions against previous opponents. We depart from the existing related\nliterature by allowing a small fraction of the population to be commitment\ntypes. The presence of committed agents destabilizes previously proposed\nmechanisms for sustaining cooperation. We present a novel intuitive combination\nof strategies that sustains cooperation in various environments. Moreover, we\nshow that under an additional assumption of stationarity, this combination of\nstrategies is essentially the unique mechanism to support full cooperation, and\nit is robust to various perturbations. Finally, we extend the results to a\nsetup in which agents also observe actions played by past opponents against the\ncurrent partner, and we characterize which observation structure is optimal for\nsustaining cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15310v1"
    },
    {
        "title": "Reputation for Playing Mixed Actions: A Characterization Theorem",
        "authors": [
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A patient player privately observes a persistent state that directly affects\nhis myopic opponents' payoffs, and can be one of the several commitment types\nthat plays the same mixed action in every period. I characterize the set of\nenvironments under which the patient player obtains at least his commitment\npayoff in all equilibria regardless of his stage-game payoff function. Due to\ninterdependent values, the patient player cannot guarantee his mixed commitment\npayoff by imitating the mixed-strategy commitment type, and small perturbations\nto a pure commitment action can significantly reduce the patient player's\nguaranteed equilibrium payoff.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.16206v2"
    },
    {
        "title": "Mediated Persuasion",
        "authors": [
            "Andrew Kosenko"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study a game of strategic information design between a sender, who chooses\nstate-dependent information structures, a mediator who can then garble the\nsignals generated from these structures, and a receiver who takes an action\nafter observing the signal generated by the first two players. We characterize\nsufficient conditions for information revelation, compare outcomes with and\nwithout a mediator and provide comparative statics with regard to the\npreferences of the sender and the mediator. We also provide novel conceptual\nand computational insights about the set of feasible posterior beliefs that the\nsender can induce, and use these results to obtain insights about equilibrium\noutcomes. The sender never benefits from mediation, while the receiver might.\nStrikingly, the receiver benefits when the mediator's preferences are not\nperfectly aligned with hers; rather the mediator should prefer more information\nrevelation than the sender, but less than perfect revelation.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.00098v2"
    },
    {
        "title": "Strategy-proof Popular Mechanisms",
        "authors": [
            "Mustafa Oğuz Afacan",
            "Inácio Bó"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider the allocation of indivisible objects when agents have\npreferences over their own allocations, but share the ownership of the\nresources to be distributed. Examples might include seats in public schools,\nfaculty offices, and time slots in public tennis courts. Given an allocation,\ngroups of agents who would prefer an alternative allocation might challenge it.\nAn assignment is popular if it is not challenged by another one. By assuming\nthat agents' ability to challenge allocations can be represented by weighted\nvotes, we characterize the conditions under which popular allocations might\nexist and when these can be implemented via strategy-proof mechanisms. Serial\ndictatorships that use orderings consistent with the agents' weights are not\nonly strategy-proof and Pareto efficient, but also popular, whenever these\nassignments exist. We also provide a new characterization for serial\ndictatorships as the only mechanisms that are popular, strategy-proof,\nnon-wasteful, and satisfy a consistency condition.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.01004v2"
    },
    {
        "title": "Assignment Maximization",
        "authors": [
            "Mustafa Oğuz Afacan",
            "Inácio Bó",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We evaluate the goal of maximizing the number of individuals matched to\nacceptable outcomes. We show that it implies incentive, fairness, and\nimplementation impossibilities. Despite that, we present two classes of\nmechanisms that maximize assignments. The first are Pareto efficient, and\nundominated -- in terms of number of assignments -- in equilibrium. The second\nare fair for unassigned students and assign weakly more students than stable\nmechanisms in equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.01011v1"
    },
    {
        "title": "Pick-an-object Mechanisms",
        "authors": [
            "Inácio Bó",
            "Rustamdjan Hakimov"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We introduce a new family of mechanisms for one-sided matching markets,\ndenoted pick-an-object (PAO) mechanisms. When implementing an allocation rule\nvia PAO, agents are asked to pick an object from individualized menus. These\nchoices may be rejected later on, and these agents are presented with new\nmenus. When the procedure ends, agents are assigned the last object they\npicked. We characterize the allocation rules that can be sequentialized by PAO\nmechanisms, as well as the ones that can be implemented in a robust truthful\nequilibrium. We justify the use of PAO as opposed to direct mechanisms by\nshowing that its equilibrium behavior is closely related to the one in\nobviously strategy-proof (OSP) mechanisms, but implements commonly used rules,\nsuch as Gale-Shapley DA and top trading cycles, which are not\nOSP-implementable. We run laboratory experiments comparing truthful behavior\nwhen using PAO, OSP, and direct mechanisms to implement different rules. These\nindicate that agents are more likely to behave in line with the theoretical\nprediction under PAO and OSP implementations than their direct counterparts.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.01025v4"
    },
    {
        "title": "Extended Gini Index",
        "authors": [
            "Ram Sewak Dubey",
            "Giorgio Laguzzi"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose an extended version of Gini index defined on the set of infinite\nutility streams, $X=Y^\\mathbb{N}$ where $Y\\subset \\mathbb{R}$. For $Y$\ncontaining at most finitely many elements, the index satisfies the generalized\nPigou-Dalton transfer principles in addition to the anonymity axiom.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.04141v2"
    },
    {
        "title": "How Covid-19 Pandemic Changes the Theory of Economics?",
        "authors": [
            "Matti Estola"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  During its history, the ultimate goal of economics has been to develop\nsimilar frameworks for modeling economic behavior as invented in physics. This\nhas not been successful, however, and current state of the process is the\nneoclassical framework that bases on static optimization. By using a static\nframework, however, we cannot model and forecast the time paths of economic\nquantities because for a growing firm or a firm going into bankruptcy, a\npositive profit maximizing flow of production does not exist. Due to these\nproblems, we present a dynamic theory for the production of a profit-seeking\nfirm where the adjustment may be stable or unstable. This is important,\ncurrently, because we should be able to forecast the possible future\nbankruptcies of firms due to the Covid-19 pandemic. By using the model, we can\nsolve the time moment of bankruptcy of a firm as a function of several\nparameters. The proposed model is mathematically identical with Newtonian model\nof a particle moving in a resisting medium, and so the model explains the\nreasons that stop the motion too. The frameworks for modeling dynamic events in\nphysics are thus applicable in economics, and we give reasons why physics is\nmore important for the development of economics than pure mathematics. (JEL\nD21, O12)\n  Keywords: Limitations of neoclassical framework, Dynamics of production,\nEconomic force, Connections between economics and physics.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.04571v1"
    },
    {
        "title": "Liability Design with Information Acquisition",
        "authors": [
            "Francisco Poggi",
            "Bruno Strulovici"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  How to guarantee that firms perform due diligence before launching\npotentially dangerous products? We study the design of liability rules when (i)\nlimited liability prevents firms from internalizing the full damage they may\ncause, (ii) penalties are paid only if damage occurs, regardless of the\nproduct's inherent riskiness, (iii) firms have private information about their\nproducts' riskiness before performing due diligence. We show that (i) any\nliability mechanism can be implemented by a tariff that depends only on the\nevidence acquired by the firm if a damage occurs, not on any initial report by\nthe firm about its private information, (ii) firms that assign a higher prior\nto product riskiness always perform more due diligence but less than is\nsocially optimal, and (iii) under a simple and intuitive condition, any\ntype-specific launch thresholds can be implemented by a monotonic tariff.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.05066v1"
    },
    {
        "title": "Hiring from a pool of workers",
        "authors": [
            "Azar Abizada",
            "Inácio Bó"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In many countries and institutions around the world, the hiring of workers is\nmade through open competitions. In them, candidates take tests and are ranked\nbased on scores in exams and other predetermined criteria. Those who satisfy\nsome eligibility criteria are made available for hiring from a \"pool of\nworkers.\" In each of an ex-ante unknown number of rounds, vacancies are\nannounced, and workers are then hired from that pool. When the scores are the\nonly criterion for selection, the procedure satisfies desired fairness and\nindependence properties. We show that when affirmative action policies are\nintroduced, the established methods of reserves and procedures used in Brazil,\nFrance, and Australia, fail to satisfy those properties. We then present a new\nrule, which we show to be the unique rule that extends static notions of\nfairness to problems with multiple rounds while satisfying aggregation\nindependence, a consistency requirement. Finally, we show that if multiple\ninstitutions hire workers from a single pool, even minor consistency\nrequirements are incompatible with variations in the institutions' rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.09541v1"
    },
    {
        "title": "Minority games played by arbitrageurs on the energy market",
        "authors": [
            "Tim Ritmeester",
            "Hildegard Meyer-Ortmanns"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Along with the energy transition, the energy markets change their\norganization toward more decentralized and self-organized structures, striving\nfor locally optimal profits. These tendencies may endanger the physical grid\nstability. One realistic option is the exhaustion of reserve energy due to an\nabuse by arbitrageurs. We map the energy market to different versions of a\nminority game and determine the expected amount of arbitrage as well as its\nfluctuations as a function of the model parameters. Of particular interest are\nthe impact of heterogeneous contributions of arbitrageurs, the interplay\nbetween external stochastic events and nonlinear price functions of reserve\npower, and the effect of risk aversion due to suspected penalties. The\nnon-monotonic dependence of arbitrage on the control parameters reveals an\nunderlying phase transition that is the counterpart to replica symmetry\nbreaking in spin glasses. As conclusions from our results we propose economic\nand statutory measures to counteract a detrimental effect of arbitrage.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10475v2"
    },
    {
        "title": "The role of time estimation in decreased impatience in Intertemporal\n  Choice",
        "authors": [
            "Camila S. Agostino Peter M. E. Claessens",
            "Fuat Balci",
            "Yossi Zana"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The role of specific cognitive processes in deviations from constant\ndiscounting in intertemporal choice is not well understood. We evaluated\ndecreased impatience in intertemporal choice tasks independent of discounting\nrate and non-linearity in long-scale time representation; nonlinear time\nrepresentation was expected to explain inconsistencies in discounting rate.\nParticipants performed temporal magnitude estimation and intertemporal choice\ntasks. Psychophysical functions for time intervals were estimated by fitting\nlinear and power functions, while discounting functions were estimated by\nfitting exponential and hyperbolic functions. The temporal magnitude estimates\nof 65% of the participants were better fit with power functions (mostly\ncompression). 63% of the participants had intertemporal choice patterns\ncorresponding best to hyperbolic functions. Even when the perceptual bias in\nthe temporal magnitude estimations was compensated in the discounting rate\ncomputation, the data of 8 out of 14 participants continued exhibiting temporal\ninconsistency. The results suggest that temporal inconsistency in discounting\nrate can be explained to different degrees by the bias in temporal\nrepresentations. Non-linearity in temporal representation and discounting rate\nshould be evaluated on an individual basis. Keywords: Intertemporal choice,\ntemporal magnitude, model comparison, impatience, time inconsistency\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10735v1"
    },
    {
        "title": "Expanding on Repeated Consumer Search Using Multi-Armed Bandits and\n  Secretaries",
        "authors": [
            "Tung Yu Marco Chan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We seek to take a different approach in deriving the optimal search policy\nfor the repeated consumer search model found in Fishman and Rob (1995) with the\nmain motivation of dropping the assumption of prior knowledge of the price\ndistribution $F(p)$ in each period. We will do this by incorporating the famous\nmulti-armed bandit problem (MAB). We start by modifying the MAB framework to\nfit the setting of the repeated consumer search model and formulate the\nobjective as a dynamic optimization problem. Then, given any sequence of\nexploration, we assign a value to each store in that sequence using Bellman\nequations. We then proceed to break down the problem into individual optimal\nstopping problems for each period which incidentally coincides with the\nframework of the famous secretary problem where we proceed to derive the\noptimal stopping policy. We will see that implementing the optimal stopping\npolicy in each period solves the original dynamic optimization by `forward\ninduction' reasoning.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.11900v2"
    },
    {
        "title": "A Theory of Updating Ambiguous Information",
        "authors": [
            "Rui Tang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We introduce a new updating rule, the conditional maximum likelihood rule\n(CML) for updating ambiguous information. The CML formula replaces the\nlikelihood term in Bayes' rule with the maximal likelihood of the given signal\nconditional on the state. We show that CML satisfies a new axiom, increased\nsensitivity after updating, while other updating rules do not. With CML, a\ndecision maker's posterior is unaffected by the order in which independent\nsignals arrive. CML also accommodates recent experimental findings on updating\nsignals of unknown accuracy and has simple predictions on learning with such\nsignals. We show that an information designer can almost achieve her maximal\npayoff with a suitable ambiguous information structure whenever the agent\nupdates according to CML.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.13650v1"
    },
    {
        "title": "Local Dominance",
        "authors": [
            "Emiliano Catonini",
            "Jingyi Xue"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We define notions of dominance between two actions in a dynamic game. Local\ndominance considers players who have a blurred view of the future and compare\nthe two actions by first focusing on the outcomes that may realize at the\ncurrent stage. When considering the possibility that the game may continue,\nthey can only check that the local comparison is not overturned under the\nassumption of \"continuing in the same way\" after the two actions (in a newly\ndefined sense). Despite the lack of forward planning, local dominance solves\ndynamic mechanisms that were found easy to play and implements social choice\nfunctions that cannot be implemented in obviously-dominant strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.14432v5"
    },
    {
        "title": "Twofold Multiprior Preferences and Failures of Contingent Reasoning",
        "authors": [
            "Federico Echenique",
            "Masaki Miyashita",
            "Yuta Nakamura",
            "Luciano Pomatto",
            "Jamie Vinson"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose a model of incomplete \\textit{twofold multiprior preferences}, in\nwhich an act $f$ is ranked above an act $g$ only when $f$ provides higher\nutility in a worst-case scenario than what $g$ provides in a best-case\nscenario. The model explains failures of contingent reasoning, captured through\na weakening of the state-by-state monotonicity (or dominance) axiom. Our model\ngives rise to rich comparative statics results, as well as extension exercises,\nand connections to choice theory. We present an application to second-price\nauctions.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.14557v3"
    },
    {
        "title": "Dynamic Random Choice",
        "authors": [
            "Ricky Li"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I study dynamic random utility with finite choice sets and exogenous total\nmenu variation, which I refer to as stochastic utility (SU). First, I\ncharacterize SU when each choice set has three elements. Next, I prove several\nmathematical identities for joint, marginal, and conditional Block--Marschak\nsums, which I use to obtain two characterizations of SU when each choice set\nbut the last has three elements. As a corollary under the same cardinality\nrestrictions, I sharpen an axiom to obtain a characterization of SU with full\nsupport over preference tuples. I conclude by characterizing SU without\ncardinality restrictions. All of my results hold over an arbitrary finite\ndiscrete time horizon.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00143v2"
    },
    {
        "title": "Conservative Updating",
        "authors": [
            "Matthew Kovach"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper provides a behavioral analysis of conservatism in beliefs. I\nintroduce a new axiom, Dynamic Conservatism, that relaxes Dynamic Consistency\nwhen information and prior beliefs \"conflict.\" When the agent is a subjective\nexpected utility maximizer, Dynamic Conservatism implies that conditional\nbeliefs are a convex combination of the prior and the Bayesian posterior.\nConservatism may result in belief dynamics consistent with confirmation bias,\nrepresentativeness, and the good news-bad news effect, suggesting a deeper\nbehavioral connection between these biases. An index of conservatism and a\nnotion of comparative conservatism are characterized. Finally, I extend\nconservatism to the case of an agent with incomplete preferences that admit a\nmultiple priors representation.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00152v1"
    },
    {
        "title": "Robust double auction mechanisms",
        "authors": [
            "Kiho Yoon"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the robust double auction mechanisms, that is, the double auction\nmechanisms that satisfy dominant strategy incentive compatibility, ex-post\nindividual rationality and ex-post budget balance. We first establish that the\nprice in any robust mechanism does not depend on the valuations of the trading\nplayers. We next establish that, with a non-bossiness assumption, the price in\nany robust mechanism does not depend on players' valuations at all, whether\ntrading or non-trading. Our main result is the characterization result that,\nwith a non-bossy assumption along with other assumptions on the properties of\nthe mechanism, the generalized posted mechanism in which a constant price is\nposted for each possible set of traders is the only robust double auction\nmechanism. We also show that, even without the non-bossiness assumption, it is\nquite difficult to find a reasonable robust double auction mechanism other than\nthe generalized posted price mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00669v3"
    },
    {
        "title": "Dual theory of choice with multivariate risks",
        "authors": [
            "Alfred Galichon",
            "Marc Henry"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose a multivariate extension of Yaari's dual theory of choice under\nrisk. We show that a decision maker with a preference relation on\nmultidimensional prospects that preserves first order stochastic dominance and\nsatisfies comonotonic independence behaves as if evaluating prospects using a\nweighted sum of quantiles. Both the notions of quantiles and of comonotonicity\nare extended to the multivariate framework using optimal transportation maps.\nFinally, risk averse decision makers are characterized within this framework\nand their local utility functions are derived. Applications to the measurement\nof multi-attribute inequality are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02578v2"
    },
    {
        "title": "The Refined Assortment Optimization Problem",
        "authors": [
            "Gerardo Berbeglia",
            "Alvaro Flores",
            "Guillermo Gallego"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We introduce the refined assortment optimization problem where a firm may\ndecide to make some of its products harder to get instead of making them\nunavailable as in the traditional assortment optimization problem. Airlines,\nfor example, offer fares with severe restrictions rather than making them\nunavailable. This is a more subtle way of handling the trade-off between demand\ninduction and demand cannibalization. For the latent class MNL model, a firm\nthat engages in refined assortment optimization can make up to $\\min(n,m)$\ntimes more than one that insists on traditional assortment optimization, where\n$n$ is the number of products and $m$ the number of customer types.\nSurprisingly, the revenue-ordered assortment heuristic has the same performance\nguarantees relative to {\\em personalized} refined assortment optimization as it\ndoes to traditional assortment optimization. Based on this finding, we\nconstruct refinements of the revenue-order heuristic and measure their improved\nperformance relative to the revenue-ordered assortment and the optimal\ntraditional assortment optimization problem. We also provide tight bounds on\nthe ratio of the expected revenues for the refined versus the traditional\nassortment optimization for some well known discrete choice models.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03043v1"
    },
    {
        "title": "Can Economic Theory Be Informative for the Judiciary? Affirmative Action\n  in India via Vertical and Horizontal Reservations",
        "authors": [
            "Tayfun Sönmez",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Sanctioned by its constitution, India is home to the world's most\ncomprehensive affirmative action program, where historically discriminated\ngroups are protected with vertical reservations implemented as \"set asides,\"\nand other disadvantaged groups are protected with horizontal reservations\nimplemented as \"minimum guarantees.\" A mechanism mandated by the Supreme Court\nin 1995 suffers from important anomalies, triggering countless litigations in\nIndia. Foretelling a recent reform correcting the flawed mechanism, we propose\nthe 2SMG mechanism that resolves all anomalies, and characterize it with\ndesiderata reflecting laws of India. Subsequently rediscovered with a high\ncourt judgment and enforced in Gujarat, 2SMG is also endorsed by Saurav Yadav\nv. State of UP (2020), in a Supreme Court ruling that rescinded the flawed\nmechanism. While not explicitly enforced, 2SMG is indirectly enforced for an\nimportant subclass of applications in India, because no other mechanism\nsatisfies the new mandates of the Supreme Court.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03186v2"
    },
    {
        "title": "Non-rationalizable Individuals, Stochastic Rationalizability, and\n  Sampling",
        "authors": [
            "Changkuk Im",
            "John Rehbeck"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Experimental work regularly finds that individual choices are not\ndeterministically rationalized by well-defined preferences. Nonetheless, recent\nwork shows that data collected from many individuals can be stochastically\nrationalized by a distribution of well-defined preferences. We study the\nrelationship between deterministic and stochastic rationalizability. We show\nthat a population can be stochastically rationalized even when half of the\nindividuals in the population cannot be deterministically rationalized. We also\nfind the ability to detect individuals who are not deterministically\nrationalized from population level data can decrease as the number of\nobservations increases.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03436v3"
    },
    {
        "title": "Comonotonic measures of multivariate risks",
        "authors": [
            "Ivar Ekeland",
            "Alfred Galichon",
            "Marc Henry"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose a multivariate extension of a well-known characterization by S.\nKusuoka of regular and coherent risk measures as maximal correlation\nfunctionals. This involves an extension of the notion of comonotonicity to\nrandom vectors through generalized quantile functions. Moreover, we propose to\nreplace the current law invariance, subadditivity and comonotonicity axioms by\nan equivalent property we call strong coherence and that we argue has more\nnatural economic interpretation. Finally, we reformulate the computation of\nregular and coherent risk measures as an optimal transportation problem, for\nwhich we provide an algorithm and implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04175v1"
    },
    {
        "title": "Matching in Closed-Form: Equilibrium, Identification, and Comparative\n  Statics",
        "authors": [
            "Raicho Bojilov",
            "Alfred Galichon"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper provides closed-form formulas for a multidimensional two-sided\nmatching problem with transferable utility and heterogeneity in tastes. When\nthe matching surplus is quadratic, the marginal distributions of the\ncharacteristics are normal, and when the heterogeneity in tastes is of the\ncontinuous logit type, as in Choo and Siow (J Polit Econ 114:172-201, 2006), we\nshow that the optimal matching distribution is also jointly normal and can be\ncomputed in closed form from the model primitives. Conversely, the quadratic\nsurplus function can be identified from the optimal matching distribution, also\nin closed-form. The closed-form formulas make it computationally easy to solve\nproblems with even a very large number of matches and allow for quantitative\npredictions about the evolution of the solution as the technology and the\ncharacteristics of the matching populations change.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04295v2"
    },
    {
        "title": "Identification in the Random Utility Model",
        "authors": [
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The random utility model is known to be unidentified, but there are times\nwhen the model admits a unique representation. We offer two characterizations\nfor the existence of a unique random utility representation. Our first\ncharacterization puts conditions on a graphical representation of the data set.\nNon-uniqueness arises when multiple inflows can be assigned to multiple\noutflows on this graph. Our second characterization provides a direct test for\nuniqueness given a random utility representation. We also show that the support\nof a random utility representation is identified if and only if the\nrepresentation itself is identified.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.05570v5"
    },
    {
        "title": "Local Utility and Multivariate Risk Aversion",
        "authors": [
            "Arthur Charpentier",
            "Alfred Galichon",
            "Marc Henry"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We revisit Machina's local utility as a tool to analyze attitudes to\nmultivariate risks. We show that for non-expected utility maximizers choosing\nbetween multivariate prospects, aversion to multivariate mean preserving\nincreases in risk is equivalent to the concavity of the local utility\nfunctions, thereby generalizing Machina's result in Machina (1982). To analyze\ncomparative risk attitudes within the multivariate extension of rank dependent\nexpected utility of Galichon and Henry (2011), we extend Quiggin's monotone\nmean and utility preserving increases in risk and show that the useful\ncharacterization given in Landsberger and Meilijson (1994) still holds in the\nmultivariate case.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06075v2"
    },
    {
        "title": "An Axiom for Concavifiable Preferences in View of Alt's Theory",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present a necessary and sufficient condition for Alt's system to be\nrepresented by a continuous utility function. Moreover, we present a necessary\nand sufficient condition for this utility function to be concave. The latter\ncondition can be seen as an extension of Gossen's first law, and thus has an\neconomic interpretation. Together with the above results, we provide a\nnecessary and sufficient condition for Alt's utility to be continuously\ndifferentiable.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07237v3"
    },
    {
        "title": "A Theory of Choice Bracketing under Risk",
        "authors": [
            "Mu Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Aggregating risks from multiple sources can be complex and demanding, and\ndecision makers usually adopt heuristics to simplify the evaluation process.\nThis paper axiomatizes two closed related and yet different heuristics, narrow\nbracketing and correlation neglect, by relaxing the independence axiom in the\nexpected utility theory. The flexibility of our framework allows for\napplications in various economic problems. First, our model can explain the\nexperimental evidence of narrow bracketing over monetary gambles. Second, when\none source represents background risk, we can accommodate Rabin (2000)'s\ncritique and explain risk aversion over small gambles. Finally, when different\nsources represent consumptions in different periods, we unify three seemingly\ndistinct models of time preferences and propose a novel model that\nsimultaneously satisfies indifference to temporal resolution of uncertainty,\nseparation of time and risk preferences, and recursivity in the domain of\nlotteries. As a direct application to macroeconomics and finance, we provide an\nalternative to Epstein and Zin (1989) which avoids the unreasonably high timing\npremium discussed in Epstein, Farhi, and Strzalecki (2014).\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07286v2"
    },
    {
        "title": "On the Basis of the Hamilton-Jacobi-Bellman Equation in Economic\n  Dynamics",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider the classical Ramsey-Cass-Koopmans capital accumulation model and\npresent three examples in which the Hamilton-Jacobi-Bellman (HJB) equation is\nneither necessary nor sufficient for a function to be the value function. Next,\nwe present assumptions under which the HJB equation becomes a necessary and\nsufficient condition for a function to be the value function, and using this\nresult, we propose a new method for solving the original problem using the\nsolution to the HJB equation. Our assumptions are so mild that many\nmacroeconomic growth models satisfy them. Therefore, our results ensure that\nthe solution to the HJB equation is rigorously the value function in many\nmacroeconomic models, and present a new solving method for these models.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07431v6"
    },
    {
        "title": "Generalized Social Marginal Welfare Weights Imply Inconsistent\n  Comparisons of Tax Policies",
        "authors": [
            "Itai Sher"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper concerns Saez and Stantcheva's (2016) generalized social marginal\nwelfare weights, which aggregate losses and gains due to tax policies, while\nincorporating non-utilitarian ethical considerations. The approach evaluates\nlocal tax changes without a global social objective. I show that local tax\npolicy comparisons implicitly entail global comparisons. Moreover, whenever\nwelfare weights do not have a utilitarian structure, these implied global\ncomparisons are inconsistent. I argue that broader ethical values cannot in\ngeneral be represented simply by modifying the weights placed on benefits to\ndifferent people, and a more thoroughgoing modification of the utilitarian\napproach is required.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07702v4"
    },
    {
        "title": "Dynamic Pricing with Limited Commitment",
        "authors": [
            "Martino Banchio",
            "Frank Yang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A monopolist wants to sell one item per period to a consumer with evolving\nand persistent private information. The seller sets a price each period\ndepending on the history so far, but cannot commit to future prices. We show\nthat, regardless of the degree of persistence, any equilibrium under a D1-style\nrefinement gives the seller revenue no higher than what she would get from\nposting all prices in advance.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07742v3"
    },
    {
        "title": "Minimal entropy and uniqueness of price equilibria in a pure exchange\n  economy",
        "authors": [
            "Andrea Loi",
            "Stefano Matta"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We introduce uncertainty into a pure exchange economy and establish a\nconnection between Shannon's differential entropy and uniqueness of price\nequilibria. The following conjecture is proposed under the assumption of a\nuniform probability distribution: entropy is minimal if and only if the price\nis unique for every economy. We show the validity of this conjecture for an\narbitrary number of goods and two consumers and, under certain conditions, for\nan arbitrary number of consumers and two goods.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.09827v1"
    },
    {
        "title": "Ambiguity and Partial Bayesian Updating",
        "authors": [
            "Matthew Kovach"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Models of updating a set of priors either do not allow a decision maker to\nmake inference about her priors (full bayesian updating or FB) or require an\nextreme degree of selection (maximum likelihood updating or ML). I characterize\na general method for updating a set of priors, partial bayesian updating (PB),\nin which the decision maker (i) utilizes an event-dependent threshold to\ndetermine whether a prior is likely enough, conditional on observed\ninformation, and then (ii) applies Bayes' rule to the sufficiently likely\npriors. I show that PB nests FB and ML and explore its behavioral properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.11429v3"
    },
    {
        "title": "A Quest for Knowledge",
        "authors": [
            "Christoph Carnehl",
            "Johannes Schneider"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Is more novel research always desirable? We develop a model in which\nknowledge shapes society's policies and guides the search for discoveries.\nResearchers select a question and how intensely to study it. The novelty of a\nquestion determines both the value and difficulty of discovering its answer. We\nshow that the benefits of discoveries are nonmonotone in novelty. Knowledge\nexpands endogenously step-by-step over time. Through a dynamic externality,\nmoonshots -- research on questions more novel than what is myopically optimal\n-- can improve the evolution of knowledge. Moonshots induce research cycles in\nwhich subsequent researchers connect the moonshot to previous knowledge.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.13434v9"
    },
    {
        "title": "Information Design in Multi-stage Games",
        "authors": [
            "Miltiadis Makris",
            "Ludovic Renou"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper generalizes the concept of Bayes correlated equilibrium (Bergemann\nand Morris, 2016) to multi-stage games. We demonstrate the power of our\ncharacterization results by applying them to a number of illustrative examples\nand applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.13482v2"
    },
    {
        "title": "Cross-verification and Persuasive Cheap Talk",
        "authors": [
            "Alp Atakan",
            "Mehmet Ekmekci",
            "Ludovic Renou"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study a cheap-talk game where two experts first choose what information to\nacquire and then offer advice to a decision-maker whose actions affect the\nwelfare of all. The experts cannot commit to reporting strategies. Yet, we show\nthat the decision-maker's ability to cross-verify the experts' advice acts as a\ncommitment device for the experts. We prove the existence of an equilibrium,\nwhere an expert's equilibrium payoff is equal to what he would obtain if he\ncould commit to truthfully revealing his information.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.13562v2"
    },
    {
        "title": "Informational Robustness of Common Belief in Rationality",
        "authors": [
            "Gabriel Ziegler"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this note, I explore the implications of informational robustness under\nthe assumption of common belief in rationality. That is, predictions for\nincomplete-information games which are valid across all possible information\nstructures. First, I address this question from a global perspective and then\ngeneralize the analysis to allow for localized informational robustness.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.02402v2"
    },
    {
        "title": "Decreasing Impatience",
        "authors": [
            "Christopher P. Chambers",
            "Federico Echenique",
            "Alan D. Miller"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We characterize decreasing impatience, a common behavioral phenomenon in\nintertemporal choice. Discount factors that display decreasing impatience are\ncharacterized through a convexit y axiom for investments at fixed interest\nrates. Then we show that they are equivalent to a geometric average of\ngeneralized quasi-hype rbolic discount rates. Finally, they emerge through\nparimutuel preference aggregation of exponential discount factors.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.03290v4"
    },
    {
        "title": "Mechanism Design under Approximate Incentive Compatibility",
        "authors": [
            "Santiago Balseiro",
            "Omar Besbes",
            "Francisco Castro"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A fundamental assumption in classical mechanism design is that buyers are\nperfect optimizers. However, in practice, buyers may be limited by their\ncomputational capabilities or a lack of information, and may not be able to\nperfectly optimize. This has motivated the introduction of approximate\nincentive compatibility (IC) as an appealing solution concept for practical\nmechanism design. While most of the literature focuses on the analysis of\nparticular approximate IC mechanisms, this paper is the first to study the\ndesign of optimal mechanisms in the space of approximate IC mechanisms and to\nexplore how much revenue can be garnered by moving from exact to approximate\nincentive constraints. We study the problem of a seller facing one buyer with\nprivate values and analyze optimal selling mechanisms under\n$\\varepsilon$-incentive compatibility. We establish that the gains that can be\ngarnered depend on the local curvature of the seller's revenue function around\nthe optimal posted price when the buyer is a perfect optimizer. If the revenue\nfunction behaves locally like an $\\alpha$-power for $\\alpha \\in (1,\\infty)$,\nthen no mechanism can garner gains higher than order\n$\\varepsilon^{\\alpha/(2\\alpha-1)}$. This improves upon state-of-the-art results\nwhich imply maximum gains of $\\varepsilon^{1/2}$ by providing the first\nparametric bounds that capture the impact of revenue function's curvature on\nrevenue gains. Furthermore, we establish that an optimal mechanism needs to\nrandomize as soon as $\\varepsilon>0$ and construct a randomized mechanism that\nis guaranteed to achieve order $\\varepsilon^{\\alpha/(2\\alpha-1)}$ additional\nrevenues, leading to a tight characterization of the revenue implications of\napproximate IC constraints. Our work brings forward the need to optimize not\nonly over allocations and payments but also over best responses, and we develop\na new framework to address this challenge.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.03403v2"
    },
    {
        "title": "Stable matching: an integer programming approach",
        "authors": [
            "Chao Huang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper develops an integer programming approach to two-sided many-to-one\nmatching by investigating stable integral matchings of a fictitious market\nwhere each worker is divisible. We show that stable matchings exist in a\ndiscrete matching market when firms' preference profile satisfies a total\nunimodularity condition that is compatible with various forms of\ncomplementarities. We provide a class of firms' preference profiles that\nsatisfy this condition.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.03418v2"
    },
    {
        "title": "Contracts for acquiring information",
        "authors": [
            "Aubrey Clark",
            "Giovanni Reggiani"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the provision of incentives for information acquisition.\nInformation is costly for an agent to acquire and unobservable to a principal.\nWe show that any Pareto optimal contract has a decomposition into a fraction of\noutput, a state-dependent transfer, and an optimal distortion. Under this\ndecomposition: 1) the fraction of output paid is increasing in the set of\nexperiments available to the agent, 2) the state-dependent transfer indexes\ncontract payments to account for differences in output between states, 3) the\noptimal distortion exploits complementarities in the cost of information\nacquisition: experiment probabilities unalterable via contract payments stuck\nagainst liability limits are substituted for, the substitution occurring\naccording to complementarities in the cost of information acquisition, and 4)\nif and only if the agent's cost of experimentation is mutual information, the\noptimal distortion takes the form of a decision-dependent transfer.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.03911v1"
    },
    {
        "title": "A note on local uniqueness of equilibria: How isolated is a local\n  equilibrium?",
        "authors": [
            "Stefano Matta"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The motivation of this note is to show how singular values affect local\nuniqueness. More precisely, Theorem 3.1 shows how to construct a neighborhood\n(a ball) of a regular equilibrium whose diameter represents an estimate of\nlocal uniqueness, hence providing a measure of how isolated a (local) unique\nequilibrium can be. The result, whose relevance in terms of comparative statics\nis evident, is based on reasonable and natural assumptions and hence is\napplicable in many different settings, ranging from pure exchange economies to\nnon-cooperative games.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.04968v1"
    },
    {
        "title": "Correlated Choice",
        "authors": [
            "Christopher P. Chambers",
            "Yusufcan Masatlioglu",
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study random joint choice rules, allowing for interdependence of choice\nacross agents. These capture random choice by multiple agents, or a single\nagent across goods or time periods. Our interest is in separable choice rules,\nwhere each agent can be thought of as acting independently of the other. A\nrandom joint choice rule satisfies marginality if for every individual choice\nset, we can determine the individual's choice probabilities over alternatives\nindependently of the other individual's choice set. We offer two\ncharacterizations of random joint choice rules satisfying marginality in terms\nof separable choice rules. While marginality is a necessary condition for\nseparability, we show that it fails to be sufficient. We provide an additional\ncondition on the marginal choice rules which, along with marginality, is\nsufficient for separability.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.05084v5"
    },
    {
        "title": "Core equivalence with large agents",
        "authors": [
            "Aubrey Clark"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the relationship between core and competitive equilibira\nin economies that consist of a continuum of agents and some large agents. We\nconstruct a class of these economies in which the core and competitive\nallocations do not coincide.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.05136v1"
    },
    {
        "title": "Competition in Costly Talk",
        "authors": [
            "Federico Vaccari"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies a communication game between an uninformed decision maker\nand two perfectly informed senders with conflicting interests. Senders can\nmisreport information at a cost that increases with the size of the\nmisrepresentation. The main results show that equilibria where the decision\nmaker obtains the complete-information payoff hinge on beliefs with undesirable\nproperties. The imposition of a minimal and sensible belief structure is\nsufficient to generate a robust and essentially unique equilibrium with partial\ninformation transmission. A complete characterization of this equilibrium\nunveils the language senders use to communicate.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.05317v2"
    },
    {
        "title": "How to De-Reserves Reserves: Admissions to Technical Colleges in India",
        "authors": [
            "Orhan Aygün",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study joint implementation of reservation and de-reservation policies in\nIndia that has been enforcing a comprehensive affirmative action since 1950.\nThe landmark judgement of the Supreme Court of India in 2008 mandated that\nwhenever OBC category (with 27 percent reservation) has unfilled positions they\nmust be reverted to general category applicants in admissions to public schools\nwithout specifying how to implement it. We disclose the drawbacks of recently\nreformed allocation procedure in admissions to technical colleges and offer a\nsolution through de-reservation via choice rules. We propose a novel priority\ndesign, Backward Transfers (BT) choice rule, for institutions and the deferred\nacceptance mechanism under these rules (DA-BT) for centralized clearinghouses.\nWe show that DA-BT corrects the shortcomings of existing mechanisms. By\nformulating the legal requirements and policy goals in India as formal axioms,\nwe show that the DA-BT mechanism is the unique mechanism for concurrent\nimplementation of reservation and de-reservation policies.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.05899v5"
    },
    {
        "title": "Conditional strategy equilibrium",
        "authors": [
            "Lorenzo Bastianello",
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this note, we prove the existence of an equilibrium concept, dubbed\nconditional strategy equilibrium, for non-cooperative games in which a strategy\nof a player is a function from the other players' actions to her own actions.\nWe study the properties of efficiency and coalition-proofness of the\nconditional strategy equilibrium in $n$-person games.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.06928v3"
    },
    {
        "title": "Price and Fulfillment Strategies in Omnichannel Retailing",
        "authors": [
            "Yasuyuki Kusuda"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Omnichannel retailing, a new form of distribution system, seamlessly\nintegrates the Internet and physical stores. This study considers the pricing\nand fulfillment strategies of a retailer that has two sales channels: online\nand one physical store. The retailer offers consumers three purchasing options:\ndelivery from the fulfillment center, buy online and pick up in-store (BOPS),\nand purchasing at the store. Consumers choose one of these options to maximize\ntheir utility, dividing them into several segments. Given the retailer can\ninduce consumers to the profitable segment by adjusting the online and store\nprices, our analysis shows that it has three optimal strategies: (1) The\nretailer excludes consumers far from the physical store from the market and\nlets the others choose BOPS or purchasing at the store. (2) It lets consumers\nfar from the physical store choose delivery from the fulfillment center and the\nothers choose BOPS or purchasing at the store. (3) It lets all consumers choose\ndelivery from the fulfillment center. Finally, we present simple dynamic\nsimulations that considers how the retailer's optimal strategy changes as\nconsumers' subjective probability of believing the product is in stock\ndecreases. The results show that the retailer should offer BOPS in later\nperiods of the selling season to maximize its profit as the subjective\nprobability decreases.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.07214v1"
    },
    {
        "title": "Advisors with Hidden Motives",
        "authors": [
            "Paula Onuchic"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I study a model of advisors with hidden motives: a seller discloses\ninformation about an object's value to a potential buyer, who doesn't know the\nobject's value or how profitable the object's sale is to the seller (the\nseller's motives). I characterize optimal disclosure rules, used by the seller\nto steer sales from lower- to higher-profitability objects. I investigate the\neffects of a mandated transparency policy, which reveals the seller's motives\nto the buyer. I show that, by removing the seller's steering incentive,\ntransparency can dissuade the seller from disclosing information about the\nobject's value, and from acquiring that information in the first place. This\nresult refines our understanding of effective regulation in advice markets, and\nlinks it to the commitment protocol in the advisor-advisee relation.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.07446v4"
    },
    {
        "title": "On the Approximate Purification of Mixed Strategies in Games with\n  Infinite Action Sets",
        "authors": [
            "Yuhki Hosoya",
            "Chaowen Yu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider a game in which the action set of each player is uncountable, and\nshow that, from weak assumptions on the common prior, any mixed strategy has an\napproximately equivalent pure strategy. The assumption of this result can be\nfurther weakened if we consider the purification of a Nash equilibrium.\nCombined with the existence theorem for a Nash equilibrium, we derive an\nexistence theorem for a pure strategy approximated Nash equilibrium under\nsufficiently weak assumptions. All of the pure strategies we derive in this\npaper can take a finite number of possible actions.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.07736v4"
    },
    {
        "title": "Optimism and Pessimism in Strategic Interactions under Ignorance",
        "authors": [
            "Pierfrancesco Guarino",
            "Gabriel Ziegler"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study players interacting under the veil of ignorance, who have -- coarse\n-- beliefs represented as subsets of opponents' actions. We analyze when these\nplayers follow $\\max \\min$ or $\\max\\max$ decision criteria, which we identify\nwith pessimistic or optimistic attitudes, respectively. Explicitly formalizing\nthese attitudes and how players reason interactively under ignorance, we\ncharacterize the behavioral implications related to common belief in these\nevents: while optimism is related to Point Rationalizability, a new algorithm\n-- Wald Rationalizability -- captures pessimism. Our characterizations allow us\nto uncover novel results: ($i$) regarding optimism, we relate it to wishful\nthinking \\'a la Yildiz (2007) and we prove that dropping the (implicit)\n\"belief-implies-truth\" assumption reverses an existence failure described\ntherein; ($ii$) we shed light on the notion of rationality in ordinal games;\n($iii$) we clarify the conceptual underpinnings behind a discontinuity in\nRationalizability hinted in the analysis of Weinstein (2016).\n",
        "pdf_link": "http://arxiv.org/pdf/2103.08319v4"
    },
    {
        "title": "A production function with variable elasticity of substitution greater\n  than one",
        "authors": [
            "Constantin Chilarescu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The idea of this paper comes from the famous remark of Piketty and Zuckman:\n\"It is natural to imagine that $\\sigma$ was much less than one in the\neighteenth and nineteenth centuries and became larger than one in the twentieth\nand twenty-first centuries. One expects a higher elasticity of substitution in\nhigh-tech economies where there are lots of alternative uses and forms for\ncapital.\" The main aim of this paper is to prove the existence of a production\nfunction of variable elasticity of substitution with values greater than one.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.08679v1"
    },
    {
        "title": "Screening $p$-Hackers: Dissemination Noise as Bait",
        "authors": [
            "Federico Echenique",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We show that adding noise before publishing data effectively screens\n$p$-hacked findings: spurious explanations produced by fitting many statistical\nmodels (data mining). Noise creates \"baits\" that affect two types of\nresearchers differently. Uninformed $p$-hackers, who are fully ignorant of the\ntrue mechanism and engage in data mining, often fall for baits. Informed\nresearchers, who start with an ex-ante hypothesis, are minimally affected. We\nshow that as the number of observations grows large, dissemination noise\nasymptotically achieves optimal screening. In a tractable special case where\nthe informed researchers' theory can identify the true causal mechanism with\nvery little data, we characterize the optimal level of dissemination noise and\nhighlight the relevant trade-offs. Dissemination noise is a tool that\nstatistical agencies currently use to protect privacy. We argue this existing\npractice can be repurposed to screen $p$-hackers and thus improve research\ncredibility.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.09164v6"
    },
    {
        "title": "Conveying Value via Categories",
        "authors": [
            "Paula Onuchic",
            "Debraj Ray"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A sender sells an object of unknown quality to a receiver who pays his\nexpected value for it. Sender and receiver might hold different priors over\nquality. The sender commits to a monotonic categorization of quality. We\ncharacterize the sender's optimal monotonic categorization. Using our\ncharacterization, we study the optimality of full pooling or full separation,\nthe alternation of pooling and separation, and make precise a sense in which\npooling is dominant relative to separation. We discuss applications, extensions\nand generalizations, among them the design of a grading scheme by a\nprofit-maximizing school which seeks to signal student qualities and\nsimultaneously incentivize students to learn. Such incentive constraints force\nmonotonicity, and can also be embedded as a distortion of the school's prior\nover student qualities, generating a categorization problem with distinct\nsender and receiver priors.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.12804v1"
    },
    {
        "title": "Efficiency and Stability in a Process of Teams Formation",
        "authors": [
            "Leonardo Boncinelli",
            "Alessio Muscillo",
            "Paolo Pin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Motivated by data on coauthorships in scientific publications, we analyze a\nteam formation process that generalizes matching models and network formation\nmodels, allowing for overlapping teams of heterogeneous size. We apply\ndifferent notions of stability: myopic team-wise stability, which extends to\nour setup the concept of pair-wise stability, coalitional stability, where\nagents are perfectly rational and able to coordinate, and stochastic stability,\nwhere agents are myopic and errors occur with vanishing probability. We find\nthat, in many cases, coalitional stability in no way refines myopic team-wise\nstability, while stochastically stable states are feasible states that maximize\nthe overall number of activities performed by teams.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.13712v2"
    },
    {
        "title": "The Formation of Global Free Trade Agreement",
        "authors": [
            "Akira Okada",
            "Yasuhiro Shirata"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We investigate the formation of Free Trade Agreement (FTA) in a competing\nimporters framework with $n$ countries. We show that (i) FTA formation causes a\nnegative externality to non-participants, (ii) a non-participant is willing to\njoin an FTA, and (iii) new participation may decrease the welfare of incumbent\nparticipants. A unique subgame perfect equilibrium of a sequential FTA\nformation game does not achieve global free trade under an open-access rule\nwhere a new applicant needs consent of members for accession, currently\nemployed by many open regionalism agreements including APEC. We further show\nthat global FTA is a unique subgame perfect equilibrium under an open-access\nrule without consent.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.16118v2"
    },
    {
        "title": "The lattice of worker-quasi-stable matchings",
        "authors": [
            "Agustin G. Bonifacio",
            "Nadia Guinazu",
            "Noelia Juarez",
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In a many-to-one matching model in which firms' preferences satisfy\nsubstitutability, we study the set of worker-quasi-stable matchings.\nWorker-quasi-stability is a relaxation of stability that allows blocking pairs\ninvolving a firm and an unemployed worker. We show that this set has a lattice\nstructure and define a Tarski operator on this lattice that models a\nre-equilibration process and has the set of stable matchings as its fixed\npoints.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.16330v4"
    },
    {
        "title": "Efficient Market Design with Distributional Objectives",
        "authors": [
            "Isa E. Hafalir",
            "Fuhito Kojima",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Given an initial matching and a policy objective on the distribution of agent\ntypes to institutions, we study the existence of a mechanism that weakly\nimproves the distributional objective and satisfies constrained efficiency,\nindividual rationality, and strategy-proofness. We show that such a mechanism\nneed not exist in general. We introduce a new notion of discrete concavity,\nwhich we call pseudo M$^{\\natural}$-concavity, and construct a mechanism with\nthe desirable properties when the distributional objective satisfies this\nnotion. We provide several practically relevant distributional objectives that\nare pseudo M$^{\\natural}$-concave.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00232v2"
    },
    {
        "title": "Design on Matroids: Diversity vs. Meritocracy",
        "authors": [
            "Isa E. Hafalir",
            "Fuhito Kojima",
            "M. Bumin Yenmez",
            "Koji Yokote"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We provide optimal solutions to an institution that has dual goals of\ndiversity and meritocracy when choosing from a set of applications. For\nexample, in college admissions, administrators may want to admit a diverse\nclass in addition to choosing students with the highest qualifications. We\nprovide a class of choice rules that maximize merit subject to attaining a\ndiversity level. Using this class, we find all subsets of applications on the\ndiversity-merit Pareto frontier. In addition, we provide two novel\ncharacterizations of matroids.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00237v1"
    },
    {
        "title": "A Bertrand duopoly game with differentiated products reconsidered",
        "authors": [
            "Xiaoliang Li",
            "Bo Li"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we explore a dynamic Bertrand duopoly game with differentiated\nproducts, where firms are boundedly rational and consumers are assumed to\npossess an underlying CES utility function. We mainly focus on two distinct\ndegrees of product substitutability. Several tools based on symbolic\ncomputations such as the triangular decomposition method and the PCAD method\nare employed in the analytical investigation of the model. The uniqueness of\nthe non-vanishing equilibrium is proved and rigorous conditions for the local\nstability of this equilibrium are established for the first time. Most\nimportantly, we find that increasing the substitutability degree or decreasing\nthe product differentiation has an effect of destabilization for our Bertrand\nmodel, which is in contrast with the relative conclusions for the Cournot\nmodels. This finding could be conducive to the revelation of the essential\ndifference between dynamic Cournot and Bertrand oligopolies with differentiated\ngoods. In the special case of identical marginal costs, we derive that lower\ndegrees of product differentiation mean lower prices, higher supplies, lower\nprofits, and lower social welfare. Furthermore, complex dynamics such as\nperiodic orbits and chaos are reported through our numerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01007v1"
    },
    {
        "title": "Preferences on Ranked-Choice Ballots",
        "authors": [
            "Brian Duricy"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper formalizes the lattice structure of the ballot voters cast in a\nranked-choice election and the preferences that this structure induces. These\npreferences are shown to be counter to previous assumptions about the\npreferences of voters, which indicate that ranked-choice elections require\ndifferent considerations for voters and candidates alike. While this model\nassumes that voters vote sincerely, the model of ranked-choice elections this\npaper presents allows for considerations of strategic voting in future work.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02697v1"
    },
    {
        "title": "A responsibility value for digraphs",
        "authors": [
            "Rosa van den Ende",
            "Dylan Laplace Mermoud"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  There is an increasing need to hold players responsible for negative or\npositive impact that take place elsewhere in a value chain or a network. For\nexample, countries or companies are held more and more responsible for their\nindirect carbon emissions. We introduce a responsibility value that allocates\nthe total impact of the value chain among the players, taking into account\ntheir direct impact and their indirect impact through the underlying graph.\nMoreover, we show that the responsibility value satisfies a set of natural yet\nimportant properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02728v1"
    },
    {
        "title": "Strategic Environmental Corporate Social Responsibility (ECSR)\n  Certification and Endogenous Market Structure",
        "authors": [
            "Ajay Sharma",
            "Siddhartha Rastogi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper extends the findings of Liu et al. (2015, Strategic environmental\ncorporate social responsibility in a differentiated duopoly market, Economics\nLetters), along two dimensions. First, we consider the case of endogenous\nmarket structure a la Vives and Singh (1984, Price and quantity competition in\na differentiated duopoly, The Rand Journal of Economics). Second, we refine the\nECSR certification standards in differentiated duopoly with rankings. We find\nthat optimal ECSR certification standards by NGO are the highest in Bertrand\ncompetition, followed by mixed markets and the lowest in Cournot competition.\nNext, NGO certifier will set the ECSR standards below the optimal level. Also,\nwe show that given the ECSR certification standards, there is a possibility of\nboth price and quantity contracts choices by the firms in endogenous market\nstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.03291v1"
    },
    {
        "title": "Randomization advice and ambiguity aversion",
        "authors": [
            "Christoph Kuzmics",
            "Brian W. Rogers",
            "Xiannong Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We design and implement lab experiments to evaluate the normative appeal of\nbehavior arising from models of ambiguity-averse preferences. We report two\nmain empirical findings. First, we demonstrate that behavior reflects an\nincomplete understanding of the problem, providing evidence that subjects do\nnot act on the basis of preferences alone. Second, additional clarification of\nthe decision making environment pushes subjects' choices in the direction of\nambiguity aversion models, regardless of whether or not the choices are also\nconsistent with subjective expected utility, supporting the position that\nsubjects find such behavior normatively appealing.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.03304v2"
    },
    {
        "title": "Filtering Down to Size: A Theory of Consideration",
        "authors": [
            "Tonna Emenuga"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The standard rational choice model describes individuals as making choices by\nselecting the best option from a menu. A wealth of evidence instead suggests\nthat individuals often filter menus into smaller sets - consideration sets -\nfrom which choices are then made. I provide a theoretical foundation for this\nphenomenon, developing a formal language of axioms to characterize how\nconsideration sets are formed from menus. I posit that consideration filters -\nmappings that translate a menu into one of its subsets - capture this process,\nand I introduce several properties that consideration filters can have. I then\nextend this core model to provide linkages with the sequential choice and\nrational attention literatures. Finally, I explore whether utility\nrepresentation is feasible under this consideration model, conjecturing\nnecessary and sufficient conditions for consideration-mediated choices to be\nrationalizable.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.05649v1"
    },
    {
        "title": "Efficiency in Collective Decision-Making via Quadratic Transfers",
        "authors": [
            "Jon X. Eguia",
            "Nicole Immorlica",
            "Steven P. Lalley",
            "Katrina Ligett",
            "Glen Weyl",
            "Dimitrios Xefteris"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Consider the following collective choice problem: a group of budget\nconstrained agents must choose one of several alternatives. Is there a budget\nbalanced mechanism that: i) does not depend on the specific characteristics of\nthe group, ii) does not require unaffordable transfers, and iii) implements\nutilitarianism if the agents' preferences are quasilinear and their private\ninformation? We study the following procedure: every agent can express any\nintensity of support or opposition to each alternative, by transferring to the\nrest of the agents wealth equal to the square of the intensity expressed; and\nthe outcome is determined by the sums of the expressed intensities. We prove\nthat as the group grows large, in every equilibrium of this quadratic-transfers\nmechanism, each agent's transfer converges to zero, and the probability that\nthe efficient outcome is chosen converges to one.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.06206v1"
    },
    {
        "title": "Turkish Inflation, Private Debt & how to overcome it",
        "authors": [
            "Mahmood Abdullah"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The thing about inflation is that it ravages your income if you don not keep\nup with it and you do not know when it will stop.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.07064v1"
    },
    {
        "title": "Haves and Have-Nots: A Theory of Economic Sufficientarianism",
        "authors": [
            "Christopher P. Chambers",
            "Siming Ye"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We introduce a generalization of the concept of sufficientarianism, intended\nto rank allocations involving multiple consumption goods. In ranking\nallocations of goods for a fixed society of agents, sufficientarianism posits\nthat allocations are compared according to the number of individuals whose\nconsumption is deemed sufficient. We base our analysis on a novel ethical\nconcept, which we term sufficientarian judgment. Sufficientarian judgment\nasserts that if in starting from an allocation in which all agents have\nidentical consumption, a change in one agent's consumption hurts society, then\nthere is no change in any other agent's consumption which could subsequently\nbenefit society. Sufficientarianism is shown to be equivalent to\nsufficientarian judgment, symmetry, and separability. We investigate our axioms\nin an abstract environment, and in specific economic environments. Finally, we\nargue formally that sufficientarian judgment is closely related to the leximin\nprinciple.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08666v2"
    },
    {
        "title": "Corporate Culture and Organizational Fragility",
        "authors": [
            "Matthew Elliott",
            "Benjamin Golub",
            "Matthieu V. Leduc"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Complex organizations accomplish tasks through many steps of collaboration\namong workers. Corporate culture supports collaborations by establishing norms\nand reducing misunderstandings. Because a strong corporate culture relies on\ncostly, voluntary investments by many workers, we model it as an organizational\npublic good, subject to standard free-riding problems, which become severe in\nlarge organizations. Our main finding is that voluntary contributions to\nculture can nevertheless be sustained, because an organization's equilibrium\nproductivity is endogenously highly sensitive to individual contributions.\nHowever, the completion of complex tasks is then necessarily fragile to small\nshocks that damage the organization's culture.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08907v1"
    },
    {
        "title": "Recovering utility",
        "authors": [
            "Christopher P. Chambers",
            "Federico Echenique",
            "Nicolas S. Lambert"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We provide sufficient conditions under which a utility function may be\nrecovered from a finite choice experiment. Identification, as is commonly\nunderstood in decision theory, is not enough. We provide a general\nrecoverability result that is widely applicable to modern theories of choice\nunder uncertainty. Key is to allow for a monetary environment, in which an\nobjective notion of monotonicity is meaningful. In such environments, we show\nthat subjective expected utility, as well as variational preferences, and other\nparametrizations of utilities over uncertain acts are recoverable. We also\nconsider utility recovery in a statistical model with noise and random\ndeviations from utility maximization.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.11492v1"
    },
    {
        "title": "Cursed Sequential Equilibrium",
        "authors": [
            "Meng-Jhang Fong",
            "Po-Hsuan Lin",
            "Thomas R. Palfrey"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper develops a framework to extend the strategic form analysis of\ncursed equilibrium (CE) developed by Eyster and Rabin (2005) to multi-stage\ngames. The approach uses behavioral strategies rather than normal form mixed\nstrategies, and imposes sequential rationality. We define cursed sequential\nequilibrium (CSE) and compare it to sequential equilibrium and standard\nnormal-form CE. We provide a general characterization of CSE and establish its\nproperties. We apply CSE to five applications in economics and political\nscience. These applications illustrate a wide range of differences between CSE\nand Bayesian Nash equilibrium or CE: in signaling games; games with preplay\ncommunication; reputation building; sequential voting; and the dirty faces game\nwhere higher order beliefs play a key role. A common theme in several of these\napplications is showing how and why CSE implies systematically different\nbehavior than Bayesian Nash equilibrium in dynamic games of incomplete\ninformation with private values, while CE coincides with Bayesian Nash\nequilibrium for such games.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.11971v2"
    },
    {
        "title": "Fair congested assignment problem",
        "authors": [
            "Anna Bogomolnaia",
            "Herve Moulin"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We propose a fair and efficient solution for assigning agents to m posts\nsubject to congestion, when agents care about both their post and its\ncongestion. Examples include assigning jobs to busy servers, students to\ncrowded schools or crowded classes, commuters to congested routes, workers to\ncrowded office spaces or to team projects etc... Congestion is anonymous (it\nonly depends on the number n of agents in a given post). A canonical\ninterpretation of ex ante fairness allows each agent to choose m post-specific\ncaps on the congestion they tolerate: these requests are mutually feasible if\nand only if the sum of the caps is n. For ex post fairness we impose a\ncompetitive requirement close to envy freeness: taking the congestion profile\nas given each agent is assigned to one of her best posts. If a competitive\nassignment exists, it delivers unique congestion and welfare profiles and is\nalso efficient and ex ante fair. In a fractional (randomised or time sharing)\nversion of our model, a unique competitive congestion profile always exists. It\nis approximately implemented by a mixture of ex post deterministic assignments:\nwith an approxination factor equal to the largest utility loss from one more\nunit of congestion, the latter deliver identical welfare profiles and are\nweakly efficient. Our approach to ex ante fairness generalises to the model\nwhere each agent's congestion is weighted. Now the caps on posts depend only\nupon own weight and total congestion, not on the number of other agents\ncontributing to it. Remarkably in both models these caps are feasible if and\nonly if they give to each agent the right to veto all but (1/m) of their\nfeasible allocations.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.12163v4"
    },
    {
        "title": "Royal Processions: Incentives, Efficiency and Fairness in Two-sided\n  Matching",
        "authors": [
            "Sophie Bade",
            "Joseph Root"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the set of incentive compatible and efficient two-sided matching\nmechanisms. We classify all such mechanisms under an additional assumption --\n\"gender-neutrality\" -- which guarantees that the two sides be treated\nsymmetrically. All group strategy-proof, efficient and gender-neutral\nmechanisms are recursive and the outcome is decided in a sequence of rounds. In\neach round, two agents are selected, one from each side. These agents are\neither \"matched-by-default\" or \"unmatched-by-default.\" In the former case\neither of the selected agents can unilaterally force the other to match with\nthem while in the latter case they may only match together if both agree. In\neither case, if this pair of agents is not matched together, each gets their\ntop choice among the set of remaining agents. As an important step in the\ncharacterization, we first show that in one-sided matching all group\nstrategy-proof and efficient mechanisms are sequential dictatorships. An\nimmediate corollary is that there are no individually rational, group\nstrategy-proof and efficient one-sided matching mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13037v1"
    },
    {
        "title": "Opaque Contracts",
        "authors": [
            "Andreas Haupt",
            "Zoe Hitzig"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Firms have access to abundant data on market participants. They use these\ndata to target contracts to agents with specific characteristics, and describe\nthese contracts in opaque terms. In response to such practices, recent proposed\nregulations aim to increase transparency, especially in digital markets. In\norder to understand when opacity arises in contracting and the potential\neffects of proposed regulations, we study a moral hazard model in which a\nrisk-neutral principal faces a continuum of weakly risk-averse agents. The\nagents differ in an observable characteristic that affects the payoff of the\nprincipal. In a described contract, the principal sorts the agents into groups,\nand to each group communicates a distribution of output-contingent payments.\nWithin each group, the realized distribution of payments must be consistent\nwith the communicated contract. A described contract is transparent if the\nprincipal communicates the realized contract to the agent ex-ante, and\notherwise it is opaque. We provide a geometric characterization of the\nprincipal's optimal described contract as well as conditions under which the\noptimal described mechanism is transparent and opaque. We apply our results to\nthe design and description of driver payment schemes on ride-hailing platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13404v1"
    },
    {
        "title": "The Optimality of Constant Mark-Up Pricing",
        "authors": [
            "Dirk Bergemann",
            "Tibor Heumann",
            "Stephen Morris"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider a nonlinear pricing environment with private information. We\nprovide profit guarantees (and associated mechanisms) that the seller can\nachieve across all possible distributions of willingness to pay of the buyers.\nWith a constant elasticity cost function, constant markup pricing provides the\noptimal revenue guarantee across all possible distributions of willingness to\npay and the lower bound is attained under a Pareto distribution. We\ncharacterize how profits and consumer surplus vary with the distribution of\nvalues and show that Pareto distributions are extremal. We also provide a\nrevenue guarantee for general cost functions. We establish equivalent results\nfor optimal procurement policies that support maximal surplus guarantees for\nthe buyer given all possible cost distributions of the sellers.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13827v1"
    },
    {
        "title": "Dynamic Random Subjective Expected Utility",
        "authors": [
            "Jetlir Duraj"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Dynamic Random Subjective Expected Utility (DR-SEU) allows to model choice\ndata observed from an agent or a population of agents whose beliefs about\nobjective payoff-relevant states and tastes can both evolve stochastically. Our\nobservable, the augmented Stochastic Choice Function (aSCF) allows, in contrast\nto previous work in decision theory, for a direct test of whether the agent's\nbeliefs reflect the true data-generating process conditional on their private\ninformation as well as identification of the possibly incorrect beliefs. We\ngive an axiomatic characterization of when an agent satisfies the model, both\nin a static as well as in a dynamic setting. We look at the case when the agent\nhas correct beliefs about the evolution of objective states as well as at the\ncase when her beliefs are incorrect but unforeseen contingencies are\nimpossible.\n  We also distinguish two subvariants of the dynamic model which coincide in\nthe static setting: Evolving SEU, where a sophisticated agent's utility evolves\naccording to a Bellman equation and Gradual Learning, where the agent is\nlearning about her taste. We prove easy and natural comparative statics results\non the degree of belief incorrectness as well as on the speed of learning about\ntaste.\n  Auxiliary results contained in the online appendix extend previous decision\ntheory work in the menu choice and stochastic choice literature from a\ntechnical as well as a conceptual perspective.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.00296v1"
    },
    {
        "title": "A characterization of \"Phelpsian\" statistical discrimination",
        "authors": [
            "Christopher P. Chambers",
            "Federico Echenique"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We establish that statistical discrimination is possible if and only if it is\nimpossible to uniquely identify the signal structure observed by an employer\nfrom a realized empirical distribution of skills. The impossibility of\nstatistical discrimination is shown to be equivalent to the existence of a\nfair, skill-dependent, remuneration for workers. Finally, we connect the\nstatistical discrimination literature to Bayesian persuasion, establishing that\nif discrimination is absent, then the optimal signaling problem results in a\nlinear payoff function (as well as a kind of converse).\n",
        "pdf_link": "http://arxiv.org/pdf/1808.01351v1"
    },
    {
        "title": "Existence of Equilibrium Prices: A Pedagogical Proof",
        "authors": [
            "Simone Tonin"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Under the same assumptions made by Mas-Colell et al. (1995), I develop a\nshort, simple, and complete proof of existence of equilibrium prices based on\nexcess demand functions. The result is obtained by applying the Brouwer fixed\npoint theorem to a trimmed simplex which does not contain prices equal to zero.\nThe mathematical techniques are based on some results obtained in Neuefeind\n(1980) and Geanakoplos (2003).\n",
        "pdf_link": "http://arxiv.org/pdf/1808.03129v2"
    },
    {
        "title": "Mechanism Design with News Utility",
        "authors": [
            "Jetlir Duraj"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  News utility is the idea that the utility of an agent depends on changes in\nher beliefs over consumption and money. We introduce news utility into\notherwise classical static Bayesian mechanism design models. We show that a key\nrole is played by the timeline of the mechanism, i.e. whether there are delays\nbetween the announcement stage, the participation stage, the play stage and the\nrealization stage of a mechanism. Depending on the timing, agents with news\nutility can experience two additional news utility effects: a surprise effect\nderived from comparing to pre-mechanism beliefs, as well as a realization\neffect derived from comparing post-play beliefs with the actual outcome of the\nmechanism.\n  We look at two distinct mechanism design settings reflecting the two main\nstrands of the classical literature. In the first model, a monopolist screens\nan agent according to the magnitude of her loss aversion. In the second model,\nwe consider a general multi-agent Bayesian mechanism design setting where the\nuncertainty of each player stems from not knowing the intrinsic types of the\nother agents. We give applications to auctions and public good provision which\nillustrate how news utility changes classical results.\n  For both models we characterize the optimal design of the timeline. A\ntimeline featuring no delay between participation and play but a delay in\nrealization is never optimal in either model. In the screening model the\noptimal timeline is one without delays. In auction settings, under fairly\nnatural assumptions the optimal timeline has delays between all three stages of\nthe mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.04020v1"
    },
    {
        "title": "$k$th price auctions and Catalan numbers",
        "authors": [
            "Abdel-Hameed Nawar",
            "Debapriya Sen"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper establishes an interesting link between $k$th price auctions and\nCatalan numbers by showing that for distributions that have linear density, the\nbid function at any symmetric, increasing equilibrium of a $k$th price auction\nwith $k\\geq 3$ can be represented as a finite series of $k-2$ terms whose\n$\\ell$th term involves the $\\ell$th Catalan number. Using an integral\nrepresentation of Catalan numbers, together with some classical combinatorial\nidentities, we derive the closed form of the unique symmetric, increasing\nequilibrium of a $k$th price auction for a non-uniform distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.05996v1"
    },
    {
        "title": "The Structure of Equilibria in Trading Networks with Frictions",
        "authors": [
            "Jan Christoph Schlegel"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Several structural results for the set of competitive equilibria in trading\nnetworks with frictions are established: The lattice theorem, the rural\nhospitals theorem, the existence of side-optimal equilibria, and a\ngroup-incentive-compatibility result hold with imperfectly transferable utility\nand in the presence of frictions. While our results are developed in a trading\nnetwork model, they also imply analogous (and new) results for exchange\neconomies with combinatorial demand and for two-sided matching markets with\ntransfers.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.07924v6"
    },
    {
        "title": "Repeated Coordination with Private Learning",
        "authors": [
            "Pathikrit Basu",
            "Kalyan Chatterjee",
            "Tetsuya Hoshino",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We study a repeated game with payoff externalities and observable actions\nwhere two players receive information over time about an underlying\npayoff-relevant state, and strategically coordinate their actions. Players\nlearn about the true state from private signals, as well as the actions of\nothers. They commonly learn the true state (Cripps et al., 2008), but do not\ncoordinate in every equilibrium. We show that there exist stable equilibria in\nwhich players can overcome unfavorable signal realizations and eventually\ncoordinate on the correct action, for any discount factor. For high discount\nfactors, we show that in addition players can also achieve efficient payoffs.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.00051v1"
    },
    {
        "title": "The Indirect Cost of Information",
        "authors": [
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We study the indirect cost of information from sequential information cost\nminimization. A key sub-additivity condition, together with monotonicity\nequivalently characterizes the class of indirect cost functions generated from\nany direct information cost. Adding an extra (uniform) posterior separability\ncondition equivalently characterizes the indirect cost generated from any\ndirect cost favoring incremental evidences. We also provide the necessary and\nsufficient condition when prior independent direct cost generates posterior\nseparable indirect cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.00697v2"
    },
    {
        "title": "The Core of an Economy with an Endogenous Social Division of Labour",
        "authors": [
            "Robert P. Gilles"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper considers the core of a competitive market economy with an\nendogenous social division of labour. The theory is founded on the notion of a\n\"consumer-producer\", who consumes as well as produces commodities. First, we\nshow that the Core of such an economy with an endogenous social division of\nlabour can be founded on deviations of coalitions of arbitrary size, extending\nthe seminal insights of Vind and Schmeidler for pure exchange economies.\nFurthermore, we establish the equivalence between the Core and the set of\ncompetitive equilibria for continuum economies with an endogenous social\ndivision of labour. Our analysis also concludes that self-organisation in a\nsocial division of labour can be incorporated into the Edgeworthian barter\nprocess directly. This is formulated as a Core equivalence result stated for a\nStructured Core concept based on renegotiations among fully specialised\neconomic agents, i.e., coalitions that use only fully developed internal\ndivisions of labour. Our approach bridges the gap between standard economies\nwith social production and coalition production economies. Therefore, a more\nstraightforward and natural interpretation of coalitional improvement and the\nCore can be developed than for coalition production economies.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01470v1"
    },
    {
        "title": "A note on contests with a constrained choice set of effort",
        "authors": [
            "Doron Klunover",
            "John Morgan"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We consider a symmetric two-player contest, in which the choice set of effort\nis constrained. We apply a fundamental property of the payoff function to show\nthat, under standard assumptions, there exists a unique Nash equilibrium in\npure strategies. It is shown that all equilibria are near the unconstrained\nequilibrium. Perhaps surprisingly, this is not the case when players have\ndifferent prize evaluations.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.04436v11"
    },
    {
        "title": "Information Acquisition and Time-Risk Preference",
        "authors": [
            "Daniel Chen",
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  An agent acquires information dynamically until her belief about a binary\nstate reaches an upper or lower threshold. She can choose any signal process\nsubject to a constraint on the rate of entropy reduction. Strategies are\nordered by \"time risk\"-the dispersion of the distribution of threshold-hitting\ntimes. We construct a strategy maximizing time risk (Greedy Exploitation) and\none minimizing it (Pure Accumulation). Under either strategy, beliefs follow a\ncompensated Poisson process. In the former, beliefs jump to the threshold that\nis closer in Bregman divergence. In the latter, beliefs jump to the unique\npoint with the same entropy as the current belief.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05120v3"
    },
    {
        "title": "Sorting and filtering as effective rational choice procedures",
        "authors": [
            "Paulo Oliva",
            "Philipp Zahn"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Many online shops offer functionality that help their customers navigate the\navailable alternatives. For instance, options to filter and to sort goods are\nwide-spread. In this paper we show that sorting and filtering can be used by\nrational consumers to find their most preferred choice -- quickly. We\ncharacterize the preferences which can be expressed through filtering and\nsorting and show that these preferences exhibit a simple and intuitive logical\nstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06766v3"
    },
    {
        "title": "Selling Information",
        "authors": [
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  I consider the monopolistic pricing of informational good. A buyer's\nwillingness to pay for information is from inferring the unknown payoffs of\nactions in decision making. A monopolistic seller and the buyer each observes a\nprivate signal about the payoffs. The seller's signal is binary and she can\ncommit to sell any statistical experiment of her signal to the buyer. Assuming\nthat buyer's decision problem involves rich actions, I characterize the profit\nmaximizing menu. It contains a continuum of experiments, each containing\ndifferent amount of information. I also find a complementarity between buyer's\nprivate information and information provision: when buyer's private signal is\nmore informative, the optimal menu contains more informative experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06770v2"
    },
    {
        "title": "Matching in Dynamic Imbalanced Markets",
        "authors": [
            "Itai Ashlagi",
            "Afshin Nikzad",
            "Philipp Strack"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We study dynamic matching in exchange markets with easy- and hard-to-match\nagents. A greedy policy, which attempts to match agents upon arrival, ignores\nthe positive externality that waiting agents generate by facilitating future\nmatchings. We prove that this trade-off between a ``thicker'' market and faster\nmatching vanishes in large markets; A greedy policy leads to shorter waiting\ntimes, and more agents matched than any other policy. We empirically confirm\nthese findings in data from the National Kidney Registry. Greedy matching\nachieves as many transplants as commonly-used policies (1.6\\% more than\nmonthly-batching), and shorter patient waiting times.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06824v2"
    },
    {
        "title": "Corrigendum to \"Managerial Incentive Problems: A Dynamic Perspective\"",
        "authors": [
            "Sander Heinsalu"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper corrects some mathematical errors in Holmstr\\\"om (1999) and\nclarifies the assumptions that are sufficient for the results of Holmstr\\\"om\n(1999). The results remain qualitatively the same.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.00455v2"
    },
    {
        "title": "Uncertainty and Robustness of Surplus Extraction",
        "authors": [
            "Giuseppe Lopomo",
            "Luca Rigotti",
            "Chris Shannon"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper studies a robust version of the classic surplus extraction\nproblem, in which the designer knows only that the beliefs of each type belong\nto some set, and designs mechanisms that are suitable for all possible beliefs\nin that set. We derive necessary and sufficient conditions for full extraction\nin this setting, and show that these are natural set-valued analogues of the\nclassic convex independence condition identified by Cremer and McLean (1985,\n1988). We show that full extraction is neither generically possible nor\ngenerically impossible, in contrast to the standard setting in which full\nextraction is generic. When full extraction fails, we show that natural\nadditional conditions can restrict both the nature of the contracts a designer\ncan offer and the surplus the designer can obtain.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01320v2"
    },
    {
        "title": "Characterizing Permissibility, Proper Rationalizability, and Iterated\n  Admissibility by Incomplete Information",
        "authors": [
            "Shuige Liu"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We characterize three interrelated concepts in epistemic game theory:\npermissibility, proper rationalizability, and iterated admissibility. We define\nthe lexicographic epistemic model for a game with incomplete information. Based\non it, we give two groups of characterizations. The first group characterizes\npermissibility and proper rationalizability. The second group characterizes\npermissibility in an alternative way and iterated admissibility. In each group,\nthe conditions for the latter are stronger than those for the former, which\ncorresponds to the fact that proper rationalizability and iterated\nadmissibility are two (compatible) refinements of permissibility within the\ncomplete information framework. The intrinsic difference between the two groups\nare the role of rationality: the first group does not need it, while the second\ngroup does.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01933v1"
    },
    {
        "title": "Mechanism Design with Limited Commitment",
        "authors": [
            "Laura Doval",
            "Vasiliki Skreta"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We develop a tool akin to the revelation principle for dynamic\nmechanism-selection games in which the designer can only commit to short-term\nmechanisms. We identify a canonical class of mechanisms rich enough to\nreplicate the outcomes of any equilibrium in a mechanism-selection game between\nan uninformed designer and a privately informed agent. A cornerstone of our\nmethodology is the idea that a mechanism should encode not only the rules that\ndetermine the allocation, but also the information the designer obtains from\nthe interaction with the agent. Therefore, how much the designer learns, which\nis the key tension in design with limited commitment, becomes an explicit part\nof the design. Our result simplifies the search for the designer-optimal\noutcome by reducing the agent's behavior to a series of participation,\ntruthtelling, and Bayes' plausibility constraints the mechanisms must satisfy.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.03579v6"
    },
    {
        "title": "Constrained Information Design",
        "authors": [
            "Laura Doval",
            "Vasiliki Skreta"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We provide tools to analyze information design problems subject to\nconstraints. We do so by extending the insight in Le Treust and Tomala (2019)\nto the case of multiple inequality and equality constraints. Namely, that an\ninformation design problem subject to constraints can be represented as an\nunconstrained information design problem with a additional states, one for each\nconstraint. Thus, without loss of generality, optimal solutions induce as many\nposteriors as the number of states and constraints. We provide results that\nrefine this upper bound. Furthermore, we provide conditions under which there\nis no duality gap in constrained information design, thus validating a\nLagrangian approach. We illustrate our results with applications to mechanism\ndesign with limited commitment (Doval and Skreta, 2022a) and persuasion of a\nprivately informed receiver (Kolotilin et al., 2017).\n",
        "pdf_link": "http://arxiv.org/pdf/1811.03588v3"
    },
    {
        "title": "A Model of Competing Narratives",
        "authors": [
            "Kfir Eliaz",
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We formalize the argument that political disagreements can be traced to a\n\"clash of narratives\". Drawing on the \"Bayesian Networks\" literature, we model\na narrative as a causal model that maps actions into consequences, weaving a\nselection of other random variables into the story. An equilibrium is defined\nas a probability distribution over narrative-policy pairs that maximizes a\nrepresentative agent's anticipatory utility, capturing the idea that public\nopinion favors hopeful narratives. Our equilibrium analysis sheds light on the\nstructure of prevailing narratives, the variables they involve, the policies\nthey sustain and their contribution to political polarization.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.04232v1"
    },
    {
        "title": "Measuring Knowledge for Recognition and Knowledge Entropy",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  People employ their knowledge to recognize things. This paper is concerned\nwith how to measure people's knowledge for recognition and how it changes. The\ndiscussion is based on three assumptions. Firstly, we construct two evolution\nprocess equations, of which one is for uncertainty and knowledge, and the other\nfor uncertainty and ignorance. Secondly, by solving the equations, formulas for\nmeasuring the levels of knowledge and the levels of ignorance are obtained in\ntwo particular cases. Thirdly, a new concept of knowledge entropy is\nintroduced. Its similarity with Boltzmann's entropy and its difference with\nShannon's Entropy are examined. Finally, it is pointed out that the obtained\nformulas of knowledge and knowledge entropy reflect two fundamental principles:\n(1) The knowledge level of a group is not necessarily a simple sum of the\nindividuals' knowledge levels; and (2) An individual's knowledge entropy never\nincreases if the individual's thirst for knowledge never decreases.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06135v1"
    },
    {
        "title": "Fairness for Multi-Self Agents",
        "authors": [
            "Sophie Bade",
            "Erel Segal-Halevi"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We investigate whether fairness is compatible with efficiency in economies\nwith multi-self agents, who may not be able to integrate their multiple\nobjectives into a single complete and transitive ranking. We adapt\nenvy-freeness, egalitarian-equivalence and the fair-share guarantee in two\ndifferent ways. An allocation is unambiguously-fair if it satisfies the chosen\ncriterion of fairness according to every objective of any agent; it is\naggregate-fair if it satisfies the criterion for some aggregation of each\nagent's objectives.\n  While efficiency is always compatible with the unambiguous fair-share\nguarantee, it is incompatible with unambiguous envy-freeness in economics with\nat least three agents. Two agents are enough for efficiency and unambiguous\negalitarian-equivalence to clash. Efficiency and the unambiguous fair-share\nguarantee can be attained together with aggregate envy-freeness, or aggregate\negalitarian-equivalence.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06684v4"
    },
    {
        "title": "Why are prices proportional to embodied energies?",
        "authors": [
            "Benjamin Leiva"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  The observed proportionality between nominal prices and average embodied\nenergies cannot be interpreted with conventional economic theory. A model is\npresented that places energy transfers as the focal point of scarcity based on\nthe idea that (1) goods are material rearrangements, and (2) humans can only\nrearrange matter with energy transfers. Modified consumer and producer problems\nfor an autarkic agent show that the opportunity cost of goods are given by\ntheir marginal energy transfers, which depend on subjective and objective\nfactors (e.g. consumer preferences and direct energy transfers). Allowing for\nexchange and under perfect competition, nominal prices arise as social\nmanifestations of goods' marginal energy transfers. The proportionality between\nnominal prices and average embodied energy follows given the relation between\nthe latter and marginal energy transfers.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.12502v1"
    },
    {
        "title": "Fair Odds for Noisy Probabilities",
        "authors": [
            "Ulrik W. Nash"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We suggest that one individual holds multiple degrees of belief about an\noutcome, given the evidence. We then investigate the implications of such noisy\nprobabilities for a buyer and a seller of binary options and find the odds\nagreed upon to ensure zero-expectation betting, differ from those consistent\nwith the relative frequency of outcomes. More precisely, the buyer and the\nseller agree to odds that are higher (lower) than the reciprocal of their\naveraged unbiased probabilities when this average indicates the outcome is more\n(less) likely to occur than chance. The favorite-longshot bias thereby emerges\nto establish the foundation of an equitable market. As corollaries, our work\nsuggests the old-established way of revealing someone's degree of belief\nthrough wagers may be more problematic than previously thought, and implies\nthat betting markets cannot generally promise to support rational decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.12516v1"
    },
    {
        "title": "Credit Cycles, Securitization, and Credit Default Swaps",
        "authors": [
            "Juan Ignacio Peña"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We present a limits-to-arbitrage model to study the impact of securitization,\nleverage and credit risk protection on the cyclicity of bank credit. In a\nstable bank credit situation, no cycles of credit expansion or contraction\nappear. Unlevered securitization together with mis-pricing of securitized\nassets increases lending cyclicality, favoring credit booms and busts. Leverage\nchanges the state of affairs with respect to the simple securitization. First,\nthe volume of real activity and banking profits increases. Second, banks sell\nsecurities when markets decline. This selling puts further pressure on falling\nprices. The mis-pricing of credit risk protection or securitized assets\ninfluences the real economy. Trading in these contracts reduces the amount of\nfunding available to entrepreneurs, particularly to high-credit-risk borrowers.\nThis trading decreases the liquidity of the securitized assets, and especially\nthose based on investments with high credit risk.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.00177v1"
    },
    {
        "title": "Conditions for the uniqueness of the Gately point for cooperative games",
        "authors": [
            "Jochen Staudacher",
            "Johannes Anwander"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We are studying the Gately point, an established solution concept for\ncooperative games. We point out that there are superadditive games for which\nthe Gately point is not unique, i.e. in general the concept is rather\nset-valued than an actual point. We derive conditions under which the Gately\npoint is guaranteed to be a unique imputation and provide a geometric\ninterpretation. The Gately point can be understood as the intersection of a\nline defined by two points with the set of imputations. Our uniqueness\nconditions guarantee that these two points do not coincide. We provide\ndemonstrative interpretations for negative propensities to disrupt. We briefly\nshow that our uniqueness conditions for the Gately point include quasibalanced\ngames and discuss the relation of the Gately point to the $\\tau$-value in this\ncontext. Finally, we point out relations to cost games and the ACA method and\nend upon a few remarks on the implementation of the Gately point and an\nupcoming software package for cooperative game theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.01485v1"
    },
    {
        "title": "RPS(1) Preferences",
        "authors": [
            "Misha Perepelitsa"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We consider a model for decision making based on an adaptive, k-period,\nlearning process where the priors are selected according to Von\nNeumann-Morgenstern expected utility principle. A preference relation between\ntwo prospects is introduced, defined by the condition which prospect is\nselected more often. We show that the new preferences have similarities with\nthe preferences obtained by Kahneman and Tversky (1979) in the context of the\nprospect theory. Additionally, we establish that in the limit of large learning\nperiod, the new preferences coincide with the expected utility principle.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.04995v3"
    },
    {
        "title": "Relational Communication",
        "authors": [
            "Anton Kolotilin",
            "Hongyi Li"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a communication game between an informed sender and an uninformed\nreceiver with repeated interactions and voluntary transfers. Transfers motivate\nthe receiver's decision-making and signal the sender's information. Although\nfull separation can always be supported in equilibrium, partial or complete\npooling is optimal if the receiver's decision-making is highly responsive to\ninformation. In this case, the receiver's decision-making is disciplined by\npooling extreme states where she is most tempted to defect.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.05645v3"
    },
    {
        "title": "A Noncooperative Model of Contest Network Formation",
        "authors": [
            "Kenan Huremovic"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this paper we study a model of weighted network formation. The bilateral\ninteraction is modeled as a Tullock contest game with the possibility of a\ndraw. We describe stable networks under different concepts of stability. We\nshow that a Nash stable network is either the empty network or the complete\nnetwork. The complete network is not immune to bilateral deviations. When we\nallow for limited farsightedness, stable networks immune to bilateral\ndeviations must be complete $M$-partite networks, with partitions of different\nsizes. The empty network is the efficient network. We provide several\ncomparative statics results illustrating the importance of network structure in\nmediating the effects of shocks and interventions. In particular, we show that\nan increase in the likelihood of a draw has a non-monotonic effect on the level\nof wasteful contest spending in the society. To the best of our knowledge, this\npaper is the first attempt to model weighted network formation when the actions\nof individuals are neither strategic complements nor strategic substitutes.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.07605v4"
    },
    {
        "title": "Theories and Practice of Agent based Modeling: Some practical\n  Implications for Economic Planners",
        "authors": [
            "Hossein Sabzian",
            "Mohammad Ali Shafia",
            "Ali Maleki",
            "Seyeed Mostapha Seyeed Hashemi",
            "Ali Baghaei",
            "Hossein Gharib"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Nowadays, we are surrounded by a large number of complex phenomena ranging\nfrom rumor spreading, social norms formation to rise of new economic trends and\ndisruption of traditional businesses. To deal with such phenomena,Complex\nAdaptive System (CAS) framework has been found very influential among social\nscientists,especially economists. As the most powerful methodology of CAS\nmodeling, Agent-based modeling (ABM) has gained a growing application among\nacademicians and practitioners. ABMs show how simple behavioral rules of agents\nand local interactions among them at micro-scale can generate surprisingly\ncomplex patterns at macro-scale. Despite a growing number of ABM publications,\nthose researchers unfamiliar with this methodology have to study a number of\nworks to understand (1) the why and what of ABMs and (2) the ways they are\nrigorously developed. Therefore, the major focus of this paper is to help\nsocial sciences researchers,especially economists get a big picture of ABMs and\nknow how to develop them both systematically and rigorously.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.08932v1"
    },
    {
        "title": "Modelling transfer profits as externalities in a cooperative\n  game-theoretic model of natural gas networks",
        "authors": [
            "Dávid Csercsik",
            "Franz Hubert",
            "Balázs R. Sziklai",
            "László Á. Kóczy"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Existing cooperative game theoretic studies of bargaining power in gas\npipeline systems are based on the so called characteristic function form (CFF).\nThis approach is potentially misleading if some pipelines fall under regulated\nthird party access (TPA). TPA, which is by now the norm in the EU, obliges the\nowner of a pipeline to transport gas for others, provided they pay a regulated\ntransport fee. From a game theoretic perspective, this institutional setting\ncreates so called \"externalities,\" the description of which requires partition\nfunction form (PFF) games. In this paper we propose a method to compute\npayoffs, reflecting the power structure, for a pipeline system with regulated\nTPA. The method is based on an iterative flow mechanism to determine gas flows\nand transport fees for individual players and uses the recursive core and the\nminimal claim function to convert the PPF game back into a CFF game, which can\nbe solved by standard methods. We illustrate the approach with a simple\nstylized numerical example of the gas network in Central Eastern Europe with a\nfocus on Ukraine's power index as a major transit country.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11435v2"
    },
    {
        "title": "Ordinal Imitative Dynamics",
        "authors": [
            "George Loginov"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper introduces an evolutionary dynamics based on imitate the better\nrealization (IBR) rule. Under this rule, agents in a population game imitate\nthe strategy of a randomly chosen opponent whenever the opponent`s realized\npayoff is higher than their own. Such behavior generates an ordinal mean\ndynamics which is polynomial in strategy utilization frequencies. We\ndemonstrate that while the dynamics does not possess Nash stationarity or\npayoff monotonicity, under it pure strategies iteratively strictly dominated by\npure strategies are eliminated and strict equilibria are locally stable. We\ninvestigate the relationship between the dynamics based on the IBR rule and the\nreplicator dynamics. In trivial cases, the two dynamics are topologically\nequivalent. In Rock-Paper-Scissors games we conjecture that both dynamics\nexhibit the same types of behavior, but the partitions of the game set do not\ncoincide. In other cases, the IBR dynamics exhibits behaviors that are\nimpossible under the replicator dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04272v1"
    },
    {
        "title": "Existence and Uniqueness of Solutions to the Stochastic Bellman Equation\n  with Unbounded Shock",
        "authors": [
            "Juan Pablo Rincón-Zapatero"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this paper we develop a general framework to analyze stochastic dynamic\nproblems with unbounded utility functions and correlated and unbounded shocks.\nWe obtain new results of the existence and uniqueness of solutions to the\nBellman equation through a general fixed point theorem that generalizes known\nresults for Banach contractions and local contractions. We study an endogenous\ngrowth model as well as the Lucas asset pricing model in an exchange economy,\nsignificantly expanding their range of applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.07343v1"
    },
    {
        "title": "Contract Design with Costly Convex Self-Control",
        "authors": [
            "Yusufcan Masatlioglu",
            "Daisuke Nakajima",
            "Emre Ozdenoren"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this note, we consider the pricing problem of a profit-maximizing\nmonopolist who faces naive consumers with convex self-control preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.07628v1"
    },
    {
        "title": "Competing to Persuade a Rationally Inattentive Agent",
        "authors": [
            "Vasudha Jain",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Firms strategically disclose product information in order to attract\nconsumers, but recipients often find it costly to process all of it, especially\nwhen products have complex features. We study a model of competitive\ninformation disclosure by two senders, in which the receiver may garble each\nsender's experiment, subject to a cost increasing in the informativeness of the\ngarbling. For a large class of parameters, it is an equilibrium for the senders\nto provide the receiver's first best level of information - i.e. as much as she\nwould learn if she herself controlled information provision. Information on one\nsender substitutes for information on the other, which nullifies the\nprofitability of a unilateral provision of less information. Thus, we provide a\nnovel channel through which competition with attention costs encourages\ninformation disclosure.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.09255v2"
    },
    {
        "title": "The method of Eneström and Phragmén for parliamentary elections by\n  means of approval voting",
        "authors": [
            "Rosa Camps",
            "Xavier Mora",
            "Laia Saumell"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a method for proportional representation that was proposed at the\nturn from the nineteenth to the twentieth century by Gustav Enestr\\\"om and\nEdvard Phragm\\'en. Like Phragm\\'en's better-known iterative minimax method, it\nis assumed that the voters express themselves by means of approval voting. In\ncontrast to the iterative minimax method, however, here one starts by fixing a\nquota, i.e. the number of votes that give the right to a seat. As a matter of\nfact, the method of Enestr\\\"om and Phragm\\'en can be seen as an extension of\nthe method of largest remainders from closed lists to open lists, or also as an\nadaptation of the single transferable vote to approval rather than preferential\nvoting. The properties of this method are studied and compared with those of\nother methods of the same kind.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10590v2"
    },
    {
        "title": "Closed form solutions of Lucas Uzawa model with externalities via\n  partial Hamiltonian approach. Some Clarifications",
        "authors": [
            "Constantin Chilarescu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  The main aim of this paper is to give some clarifications to the recent paper\npublished in Computational and Applied Mathematics by Naz and Chaudhry.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12623v1"
    },
    {
        "title": "A Production Function with Variable Elasticity of Factor Substitution",
        "authors": [
            "Constantin Chilarescu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  The main aim of this paper is to prove the existence of a new production\nfunction with variable elasticity of factor substitution. This production\nfunction is a more general form which includes the Cobb-Douglas production\nfunction and the CES production function as particular cases. The econometric\nestimates presented in the paper confirm some other results and reinforces the\nconclusion that the sigma is well-below the Cobb-Douglas value of one.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12624v1"
    },
    {
        "title": "On the Solutions of the Lucas-Uzawa Model",
        "authors": [
            "Constantin Chilarescu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In a recent paper, Naz and Chaudry provided two solutions for the model of\nLucas-Uzawa, via the Partial Hamiltonian Approach. The first one of these\nsolutions coincides exactly with that determined by Chilarescu. For the second\none, they claim that this is a new solution, fundamentally different than that\nobtained by Chilarescu. We will prove in this paper, using the existence and\nuniqueness theorem of nonlinear differential equations, that this is not at all\ntrue.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12658v1"
    },
    {
        "title": "Reversals of signal-posterior monotonicity imply a bias of screening",
        "authors": [
            "Sander Heinsalu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This note strengthens the main result of Lagziel and Lehrer (2019) (LL) \"A\nbias in screening\" using Chambers Healy (2011) (CH) \"Reversals of\nsignal-posterior monotonicity for any bounded prior\". LL show that the\nconditional expectation of an unobserved variable of interest, given that a\nnoisy signal of it exceeds a cutoff, may decrease in the cutoff. CH prove that\nthe distribution of a variable conditional on a lower signal may first order\nstochastically dominate the distribution conditional on a higher signal.\n  The nonmonotonicity result is also extended to the empirically relevant\nexponential and Pareto distributions, and to a wide range of signals.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.03117v6"
    },
    {
        "title": "Transboundary Pollution Externalities: Think Globally, Act Locally?",
        "authors": [
            "Davide La Torre",
            "Danilo Liuzzi",
            "Simone Marsiglio"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We analyze the implications of transboundary pollution externalities on\nenvironmental policymaking in a spatial and finite time horizon setting. We\nfocus on a simple regional optimal pollution control problem in order to\ncompare the global and local solutions in which, respectively, the\ntransboundary externality is and is not taken into account in the determination\nof the optimal policy by individual local policymakers. We show that the local\nsolution is suboptimal and as such a global approach to environmental problems\nis effectively needed. Our conclusions hold true in different frameworks,\nincluding situations in which the spatial domain is either bounded or\nunbounded, and situations in which macroeconomic-environmental feedback effects\nare taken into account. We also show that if every local economy implements an\nenvironmental policy stringent enough, then the global average level of\npollution will fall. If this is the case, over the long run the entire global\neconomy will be able to achieve a completely pollution-free status.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.04469v1"
    },
    {
        "title": "Necessary and sufficient condition for equilibrium of the Hotelling\n  model on a circle",
        "authors": [
            "Satoshi Hayashi",
            "Naoki Tsuge"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a model of vendors competing to sell a homogeneous product to\ncustomers spread evenly along a circular city. This model is based on\nHotelling's celebrated paper in 1929. Our aim in this paper is to present a\nnecessary and sufficient condition for the equilibrium. This yields a\nrepresentation for the equilibrium. To achieve this, we first formulate the\nmodel mathematically. Next, we prove that the condition holds if and only if\nvendors are equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11154v2"
    },
    {
        "title": "The Persuasion Duality",
        "authors": [
            "Piotr Dworczak",
            "Anton Kolotilin"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We present a unified duality approach to Bayesian persuasion. The optimal\ndual variable, interpreted as a price function on the state space, is shown to\nbe a supergradient of the concave closure of the objective function at the\nprior belief. Strong duality holds when the objective function is Lipschitz\ncontinuous.\n  When the objective depends on the posterior belief through a set of moments,\nthe price function induces prices for posterior moments that solve the\ncorresponding dual problem. Thus, our general approach unifies known results\nfor one-dimensional moment persuasion, while yielding new results for the\nmulti-dimensional case. In particular, we provide a necessary and sufficient\ncondition for the optimality of convex-partitional signals, derive structural\nproperties of solutions, and characterize the optimal persuasion scheme in the\ncase when the state is two-dimensional and the objective is quadratic.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11392v3"
    },
    {
        "title": "Lexicographic Choice Under Variable Capacity Constraints",
        "authors": [
            "Battal Dogan",
            "Serhat Dogan",
            "Kemal Yildiz"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In several matching markets, in order to achieve diversity, agents'\npriorities are allowed to vary across an institution's available seats, and the\ninstitution is let to choose agents in a lexicographic fashion based on a\npredetermined ordering of the seats, called a (capacity-constrained)\nlexicographic choice rule. We provide a characterization of lexicographic\nchoice rules and a characterization of deferred acceptance mechanisms that\noperate based on a lexicographic choice structure under variable capacity\nconstraints. We discuss some implications for the Boston school choice system\nand show that our analysis can be helpful in applications to select among\nplausible choice rules.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13237v1"
    },
    {
        "title": "Persuasion with Coarse Communication",
        "authors": [
            "Yunus C. Aybas",
            "Eray Turkel"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In many real-world scenarios, experts must convey complex information with\nlimited message capacity. This paper explores how the availability of messages\ninfluences an expert's persuasive ability. We develop a geometric\nrepresentation of the expert's payoff with limited message capacity and\nidentify bounds on the value of an additional signal for the sender. In a\nspecial class of games, the marginal value of a signal increases as the\nreceiver becomes more difficult to persuade. Moreover, we show that access to\nan additional signal does not necessarily translate into more information\ntransmitted in equilibrium, and the receiver might prefer coarser\ncommunication. This suggests that regulations on communication capacity have\nthe potential to shift the balance of power from the expert to the\ndecision-maker, ultimately improving welfare. Finally, we study the geometric\nproperties of optimal information structures and show that the complexity of\nthe sender's problem can be simplified to a finite algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13547v7"
    },
    {
        "title": "Disclosure Games with Large Evidence Spaces",
        "authors": [
            "Shaofei Jiang"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a disclosure game with a large evidence space. There is an unknown\nbinary state. A sender observes a sequence of binary signals about the state\nand discloses a left truncation of the sequence to a receiver in order to\nconvince him that the state is good. We focus on truth-leaning equilibria (cf.\nHart et al. (2017)), where the sender discloses truthfully when doing so is\noptimal, and the receiver takes off-path disclosure at face value. In\nequilibrium, seemingly sub-optimal truncations are disclosed, and the\ndisclosure contains the longest truncation that yields the maximal difference\nbetween the number of good and bad signals. We also study a general framework\nof disclosure games which is compatible with large evidence spaces, a wide\nrange of disclosure technologies, and finitely many states. We characterize the\nunique equilibrium value function of the sender and propose a method to\nconstruct equilibria for a broad class of games.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13633v3"
    },
    {
        "title": "Costly Verification in Collective Decisions",
        "authors": [
            "Albin Erlanson",
            "Andreas Kleiner"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study how a principal should optimally choose between implementing a new\npolicy and maintaining the status quo when information relevant for the\ndecision is privately held by agents. Agents are strategic in revealing their\ninformation; the principal cannot use monetary transfers to elicit this\ninformation, but can verify an agent's claim at a cost. We characterize the\nmechanism that maximizes the expected utility of the principal. This mechanism\ncan be implemented as a cardinal voting rule, in which agents can either cast a\nbaseline vote, indicating only whether they are in favor of the new policy, or\nthey make specific claims about their type. The principal gives more weight to\nspecific claims and verifies a claim whenever it is decisive.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13979v2"
    },
    {
        "title": "Compromise, Don't Optimize: Generalizing Perfect Bayesian Equilibrium to\n  Allow for Ambiguity",
        "authors": [
            "Karl Schlag",
            "Andriy Zapechelnyuk"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We introduce a solution concept for extensive-form games of incomplete\ninformation in which players need not assign likelihoods to what they do not\nknow about the game. This is embedded in a model in which players can hold\nmultiple priors. Players make choices by looking for compromises that yield a\ngood performance under each of their updated priors. Our solution concept is\ncalled perfect compromise equilibrium. It generalizes perfect Bayesian\nequilibrium. We show how it deals with ambiguity in Cournot and Bertrand\nmarkets, public good provision, Spence's job market signaling, bilateral trade\nwith common value, and forecasting.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.02539v2"
    },
    {
        "title": "A Model of Justification",
        "authors": [
            "Sarah Ridout"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  I consider decision-making constrained by considerations of morality,\nrationality, or other virtues. The decision maker (DM) has a true preference\nover outcomes, but feels compelled to choose among outcomes that are top-ranked\nby some preference that he considers \"justifiable.\" This model unites a broad\nclass of empirical work on distributional preferences, charitable donations,\nprejudice/discrimination, and corruption/bribery. I provide a behavioral\ncharacterization of the model. I also show that the set of justifications can\nbe identified from choice behavior when the true preference is known, and that\nchoice behavior substantially restricts both the true preference and\njustifications when neither is known. I argue that the justifiability model\nrepresents an advancement over existing models of rationalization because the\nstructure it places on possible \"rationales\" improves tractability,\ninterpretation and identification.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.06844v1"
    },
    {
        "title": "Game Theoretic Consequences of Resident Matching",
        "authors": [
            "Yue Wu"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The resident matching algorithm, Gale-Shapley, currently used by SF Match and\nthe National Residency Match Program (NRMP), has been in use for over 50 years\nwithout fundamental alteration. The algorithm is a 'stable-marriage' method\nthat favors applicant outcomes. However, in these 50 years, there has been a\nbig shift in the supply and demand of applicants and programs. These changes\nalong with the way the Match is implemented have induced a costly race among\napplicants to apply and interview at as many programs as possible. Meanwhile\nprograms also incur high costs as they maximize their probability of matching\nby interviewing as many candidates as possible.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07205v2"
    },
    {
        "title": "Keeping the Listener Engaged: a Dynamic Model of Bayesian Persuasion",
        "authors": [
            "Yeon-Koo Che",
            "Kyungmin Kim",
            "Konrad Mierendorff"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a dynamic model of Bayesian persuasion in which information takes\ntime and is costly for the sender to generate and for the receiver to process,\nand neither player can commit to their future actions. Persuasion may totally\ncollapse in a Markov perfect equilibrium (MPE) of this game. However, for\npersuasion costs sufficiently small, a version of a folk theorem holds:\noutcomes that approximate Kamenica and Gentzkow (2011)'s sender-optimal\npersuasion as well as full revelation and everything in between are obtained in\nMPE, as the cost vanishes.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07338v5"
    },
    {
        "title": "Bemerkungen zum paarweisen Vergleich",
        "authors": [
            "Stefan Lörcks"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The simple pairwise comparison is a method to provide different criteria with\nweights. We show that the values of those weights (in particular the maximum)\ndepend just on the number of criteria. Additionally, it is shown that the\ndistance between the weights is always the same.\n  -----\n  Der einfache paarweise Vergleich ist ein Verfahren verschiedene Kriterien mit\neiner Gewichtung zu versehen. Wir zeigen, dass die Werte dieser Gewichte\n(insbesondere auch der maximale Wert) ausschlie{\\ss}lich von der Anzahl der\nKriterien abh\\\"angt. Dar\\\"uber hinaus wird gezeigt, dass der Abstand der\nGewichtungen stets gleich ist.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.10978v1"
    },
    {
        "title": "Final Topology for Preference Spaces",
        "authors": [
            "Pablo Schenone"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We say a model is continuous in utilities (resp., preferences) if small\nperturbations of utility functions (resp., preferences) generate small changes\nin the model's outputs. While similar, these two questions are different. They\nare only equivalent when the following two sets are isomorphic: the set of\ncontinuous mappings from preferences to the model's outputs, and the set of\ncontinuous mappings from utilities to the model's outputs. In this paper, we\nstudy the topology for preference spaces defined by such an isomorphism. This\nstudy is practically significant, as continuity analysis is predominantly\nconducted through utility functions, rather than the underlying preference\nspace. Our findings enable researchers to infer continuity in utility as\nindicative of continuity in underlying preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.02357v3"
    },
    {
        "title": "A Search Model of Statistical Discrimination",
        "authors": [
            "Jiadong Gu",
            "Peter Norman"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We offer a search-theoretic model of statistical discrimination, in which\nfirms treat identical groups unequally based on their occupational choices. The\nmodel admits symmetric equilibria in which the group characteristic is ignored,\nbut also asymmetric equilibria in which a group is statistically discriminated\nagainst, even when symmetric equilibria are unique. Moreover, a robust\npossibility is that symmetric equilibria become unstable when the group\ncharacteristic is introduced. Unlike most previous literature, our model can\njustify affirmative action since it eliminates asymmetric equilibria without\ndistorting incentives.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.06645v2"
    },
    {
        "title": "A geometric characterization of VES and Kadiyala-type production\n  functions",
        "authors": [
            "Nicolò Cangiotti",
            "Mattia Sensi"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The basic concepts of the differential geometry are shortly reviewed and\napplied to the study of VES production function in the spirit of the works of\nV\\^ilcu and collaborators. A similar characterization is given for a more\ngeneral production function, namely the Kadiyala production function, in the\ncase of developable surfaces.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09617v1"
    },
    {
        "title": "Dynamically Consistent Objective and Subjective Rationality",
        "authors": [
            "Lorenzo Bastianello",
            "José Heleno Faro",
            "Ana Santos"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A group of experts, for instance climate scientists, is to choose among two\npolicies $f$ and $g$. Consider the following decision rule. If all experts\nagree that the expected utility of $f$ is higher than the expected utility of\n$g$, the unanimity rule applies, and $f$ is chosen. Otherwise the precautionary\nprinciple is implemented and the policy yielding the highest minimal expected\nutility is chosen.\n  This decision rule may lead to time inconsistencies when an intermediate\nperiod of partial resolution of uncertainty is added. We provide axioms that\nenlarge the initial group of experts with veto power, which leads to a set of\nprobabilistic beliefs that is \"rectangular\" in a minimal sense. This makes this\ndecision rule dynamically consistent and provides, as a byproduct, a novel\nbehavioral characterization of rectangularity.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.12347v1"
    },
    {
        "title": "Matching with Generalized Lexicographic Choice Rules",
        "authors": [
            "Orhan Aygün",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Motivated by the need for real-world matching problems, this paper formulates\na large class of practical choice rules, Generalized Lexicographic Choice Rules\n(GLCR), for institutions that consist of multiple divisions. Institutions fill\ntheir divisions sequentially, and each division is endowed with a sub-choice\nrule that satisfies classical substitutability and size monotonicity in\nconjunction with a new property that we introduce, quota monotonicity. We allow\nrich interactions between divisions in the form of capacity transfers. The\noverall choice rule of an institution is defined as the union of the\nsub-choices of its divisions. The cumulative offer mechanism (COM) with respect\nto GLCR is the unique stable and strategy-proof mechanism. We define a\nchoice-based improvement notion and show that the COM respects improvements. We\nemploy the theory developed in this paper in our companion paper, Ayg\\\"un and\nTurhan (2020), to design satisfactory matching mechanisms for India with\ncomprehensive affirmative action constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.13261v2"
    },
    {
        "title": "Designing Direct Matching Mechanism for India with Comprehensive\n  Affirmative Action",
        "authors": [
            "Orhan Aygün",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Since 1950, India has been implementing the most comprehensive affirmative\naction program in the world. Vertical reservations are provided to members of\nhistorically discriminated Scheduled Castes (SC), Scheduled Tribes (ST), and\nOther Backward Classes (OBC). Horizontal reservations are provided for other\ndisadvantaged groups, such as women and disabled people, within each vertical\ncategory. There is no well-defined procedure to implement horizontal\nreservations jointly with vertical reservation and OBC de-reservations.\nSequential processes currently in use for OBC de-reservations and meritorious\nreserve candidates lead to severe shortcomings. Most importantly, indirect\nmechanisms currently used in practice do not allow reserve category applicants\nto fully express their preferences. To overcome these and other related issues,\nwe design several different choice rules for institutions that take\nmeritocracy, vertical and horizontal reservations, and OBC de-reservations into\naccount. We propose a centralized mechanism to satisfactorily clear matching\nmarkets in India.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.13264v5"
    },
    {
        "title": "Slot-specific Priorities with Capacity Transfers",
        "authors": [
            "Michelle Avataneo",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In many real-world matching applications, there are restrictions for\ninstitutions either on priorities of their slots or on the transferability of\nunfilled slots over others (or both). Motivated by the need in such real-life\nmatching problems, this paper formulates a family of practical choice rules,\nslot-specific priorities with capacity transfers (SSPwCT). These practical\nrules invoke both slot-specific priorities structure and transferability of\nvacant slots. We show that the cumulative offer mechanism (COM) is stable,\nstrategy-proof and respects improvements with regards to SSPwCT choice rules.\nTransferring the capacity of one more unfilled slot, while all else is\nconstant, leads to strategy-proof Pareto improvement of the COM. Following\nKominer's (2020) formulation, we also provide comparative static results for\nexpansion of branch capacity and addition of new contracts in the SSPwCT\nframework. Our results have implications for resource allocation problems with\ndiversity considerations.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.13265v2"
    },
    {
        "title": "Project selection with partially verifiable information",
        "authors": [
            "Sumit Goel",
            "Wade Hann-Caruthers"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a principal agent project selection problem with asymmetric\ninformation. There are $N$ projects and the principal must select exactly one\nof them. Each project provides some profit to the principal and some payoff to\nthe agent and these profits and payoffs are the agent's private information. We\nconsider the principal's problem of finding an optimal mechanism for two\ndifferent objectives: maximizing expected profit and maximizing the probability\nof choosing the most profitable project. Importantly, we assume partial\nverifiability so that the agent cannot report a project to be more profitable\nto the principal than it actually is. Under this no-overselling constraint, we\ncharacterize the set of implementable mechanisms. Using this characterization,\nwe find that in the case of two projects, the optimal mechanism under both\nobjectives takes the form of a simple cutoff mechanism. The simple structure of\nthe optimal mechanism also allows us to find evidence in support of the\nwell-known ally-principle which says that principal delegates more authority to\nan agent who shares their preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.00907v2"
    },
    {
        "title": "Anonymous, non-manipulable, binary social choice",
        "authors": [
            "Achille Basile",
            "Surekha Rao",
            "K. P. S. Bhaskara Rao"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Let V be a finite society whose members express weak orderings (hence also\nindifference, possibly) about two alternatives. We show a simple representation\nformula that is valid for all, and only, anonymous, non-manipulable, binary\nsocial choice functions on V . The number of such functions is $2^{n+1}$ if V\ncontains $n$ agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.01552v1"
    },
    {
        "title": "Contracting over persistent information",
        "authors": [
            "Wei Zhao",
            "Claudio Mezzetti",
            "Ludovic Renou",
            "Tristan Tomala"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a dynamic moral hazard problem between a principal and an agent,\nwhere the sole instrument the principal has to incentivize the agent is the\ndisclosure of information. The principal aims at maximizing the (discounted)\nnumber of times the agent chooses a particular action, e.g., to work hard. We\nshow that there exists an optimal contract, where the principal stops\ndisclosing information as soon as its most preferred action is a static best\nreply for the agent or else continues disclosing information until the agent\nperfectly learns the principal's private information. If the agent perfectly\nlearns the state, he learns it in finite time with probability one; the more\npatient the agent, the later he learns it.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.05983v3"
    },
    {
        "title": "Equilibrium Refinement in Finite Action Evidence Games",
        "authors": [
            "Shaofei Jiang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Evidence games study situations where a sender persuades a receiver by\nselectively disclosing hard evidence about an unknown state of the world.\nEvidence games often have multiple equilibria. Hart et al. (2017) propose to\nfocus on truth-leaning equilibria, i.e., perfect Bayesian equilibria where the\nsender discloses truthfully when indifferent, and the receiver takes off-path\ndisclosure at face value. They show that a truth-leaning equilibrium is an\nequilibrium of a perturbed game where the sender has an infinitesimal reward\nfor truth-telling. We show that, when the receiver's action space is finite,\ntruth-leaning equilibrium may fail to exist, and it is not equivalent to\nequilibrium of the perturbed game. To restore existence, we introduce a\ndisturbed game with a small uncertainty about the receiver's payoff. A\npurifiable truthful equilibrium is the limit of a sequence of truth-leaning\nequilibria in the disturbed games as the disturbances converge to zero. It\nexists and features a simple characterization. A truth-leaning equilibrium that\nis also purifiable truthful is an equilibrium of the perturbed game. Moreover,\npurifiable truthful equilibria are receiver optimal and give the receiver the\nsame payoff as the optimal deterministic mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.06403v2"
    },
    {
        "title": "Time-Equitable Dynamic Tolling Scheme For Single Bottlenecks",
        "authors": [
            "John W Helsel",
            "Venktesh Pandey",
            "Stephen D. Boyles"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Dynamic tolls present an opportunity for municipalities to eliminate\ncongestion and fund infrastructure. Imposing tolls that regulate travel along a\npublic highway through monetary fees raise worries of inequity. In this\narticle, we introduce the concept of time poverty, emphasize its value in\npolicy-making in the same ways income poverty is already considered, and argue\nthe potential equity concern posed by time-varying tolls that produce time\npoverty. We also compare the cost burdens of a no-toll, system optimal toll,\nand a proposed ``time-equitable\" toll on heterogeneous traveler groups using an\nanalytical Vickrey bottleneck model where travelers make departure time\ndecisions to arrive at their destination at a fixed time. We show that the\ntime-equitable toll is able to eliminate congestion while creating equitable\ntravel patterns amongst traveler groups.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.07091v1"
    },
    {
        "title": "Learning from Manipulable Signals",
        "authors": [
            "Mehmet Ekmekci",
            "Leandro Gorno",
            "Lucas Maestri",
            "Jian Sun",
            "Dong Wei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study a dynamic stopping game between a principal and an agent. The agent\nis privately informed about his type. The principal learns about the agent's\ntype from a noisy performance measure, which can be manipulated by the agent\nvia a costly and hidden action. We fully characterize the unique Markov\nequilibrium of this game. We find that terminations/market crashes are often\npreceded by a spike in (expected) performance. Our model also predicts that,\ndue to endogenous signal manipulation, too much transparency can inhibit\nlearning. As the players get arbitrarily patient, the principal elicits no\nuseful information from the observed signal.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.08762v4"
    },
    {
        "title": "Only Time Will Tell: Credible Dynamic Signaling",
        "authors": [
            "Egor Starkov"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper characterizes informational outcomes in a model of dynamic\nsignaling with vanishing commitment power. It shows that contrary to popular\nbelief, informative equilibria with payoff-relevant signaling can exist without\nrequiring unreasonable off-path beliefs. The paper provides a sharp\ncharacterization of possible separating equilibria: all signaling must take\nplace through attrition, when the weakest type mixes between revealing own type\nand pooling with the stronger types. The framework explored in the paper is\ngeneral, imposing only minimal assumptions on payoff monotonicity and\nsingle-crossing. Applications to bargaining, monopoly price signaling, and\nlabor market signaling are developed to demonstrate the results in specific\ncontexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09568v3"
    },
    {
        "title": "A Canon of Probabilistic Rationality",
        "authors": [
            "Simone Cerreia-Vioglio",
            "Per Olov Lindberg",
            "Fabio Maccheroni",
            "Massimo Marinacci",
            "Aldo Rustichini"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We prove that a random choice rule satisfies Luce's Choice Axiom if and only\nif its support is a choice correspondence that satisfies the Weak Axiom of\nRevealed Preference, thus it consists of alternatives that are optimal\naccording to some preference, and random choice then occurs according to a tie\nbreaking among such alternatives that satisfies Renyi's Conditioning Axiom. Our\nresult shows that the Choice Axiom is, in a precise formal sense, a\nprobabilistic version of the Weak Axiom. It thus supports Luce's view of his\nown axiom as a \"canon of probabilistic rationality.\"\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11386v2"
    },
    {
        "title": "Generating Empirical Core Size Distributions of Hedonic Games using a\n  Monte Carlo Method",
        "authors": [
            "Andrew J. Collins",
            "Sheida Etemadidavan",
            "Wael Khallouli"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Data analytics allows an analyst to gain insight into underlying populations\nthrough the use of various computational approaches, including Monte Carlo\nmethods. This paper discusses an approach to apply Monte Carlo methods to\nhedonic games. Hedonic games have gain popularity over the last two decades\nleading to several research articles that are concerned with the necessary,\nsufficient, or both conditions of the existence of a core partition.\nResearchers have used analytical methods for this work. We propose that using a\nnumerical approach will give insights that might not be available through\ncurrent analytical methods. In this paper, we describe an approach to\nrepresenting hedonic games, with strict preferences, in a matrix form that can\neasily be generated; that is, a hedonic game with randomly generated\npreferences for each player. Using this generative approach, we were able to\ncreate and solve, i.e., find any core partitions, of millions of hedonic games.\nOur Monte Carlo experiment generated games with up to thirteen players. The\nresults discuss the distribution form of the core size of the games of a given\nnumber of players. We also discuss computational considerations. Our numerical\nstudy of hedonic games gives insight into the underlying properties of hedonic\ngames.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.12127v1"
    },
    {
        "title": "Equilibrium Behaviors in Repeated Games",
        "authors": [
            "Yingkai Li",
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We examine a patient player's behavior when he can build reputations in front\nof a sequence of myopic opponents. With positive probability, the patient\nplayer is a commitment type who plays his Stackelberg action in every period.\nWe characterize the patient player's action frequencies in equilibrium. Our\nresults clarify the extent to which reputations can refine the patient player's\nbehavior and provide new insights to entry deterrence, business transactions,\nand capital taxation. Our proof makes a methodological contribution by\nestablishing a new concentration inequality.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.14002v4"
    },
    {
        "title": "Signaling with Private Monitoring",
        "authors": [
            "Gonzalo Cisternas",
            "Aaron Kolb"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study dynamic signaling when the informed party does not observe the\nsignals generated by her actions. A long-run player signals her type\ncontinuously over time to a myopic second player who privately monitors her\nbehavior; in turn, the myopic player transmits his private inferences back\nthrough an imperfect public signal of his actions. Preferences are\nlinear-quadratic and the information structure is Gaussian. We construct linear\nMarkov equilibria using belief states up to the long-run player's\n$\\textit{second-order belief}$. Because of the private monitoring, this state\nis an explicit function of the long-run player's past play. A novel separation\neffect then emerges through this second-order belief channel, altering the\ntraditional signaling that arises when beliefs are public. Applications to\nmodels of leadership, reputation, and trading are examined.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.15514v1"
    },
    {
        "title": "Truthful Equilibria in Generalized Common Agency Models",
        "authors": [
            "Ilias Boultzis"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In this paper I discuss truthful equilibria in common agency models.\nSpecifically, I provide general conditions under which truthful equilibria are\nplausible, easy to calculate and efficient. These conditions generalize similar\nresults in the literature and allow the use of truthful equilibria in novel\neconomic applications. Moreover, I provide two such applications. The first\napplication is a market game in which multiple sellers sell a uniform good to a\nsingle buyer. The second application is a lobbying model in which there are\nexternalities in contributions between lobbies. This last example indicates\nthat externalities between principals do not necessarily prevent efficient\nequilibria. In this regard, this paper provides a set of conditions, under\nwhich, truthful equilibria in common agency models with externalities are\nefficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.15942v1"
    },
    {
        "title": "Optimal Echo Chambers",
        "authors": [
            "Gabriel Martinez",
            "Nicholas H. Tenev"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  When learning from others, people tend to focus their attention on those with\nsimilar views. This is often attributed to flawed reasoning, and thought to\nslow learning and polarize beliefs. However, we show that echo chambers are a\nrational response to uncertainty about the accuracy of information sources, and\ncan improve learning and reduce disagreement. Furthermore, overextending the\nrange of views someone is exposed to can backfire, slowing their learning by\nmaking them less responsive to information from others. We model a Bayesian\ndecision maker who chooses a set of information sources and then observes a\nsignal from one. With uncertainty about which sources are accurate, focusing\nattention on signals close to one's own expectation can be beneficial, as their\nexpected accuracy is higher. The optimal echo chamber balances the credibility\nof views similar to one's own against the usefulness of those further away.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.01249v10"
    },
    {
        "title": "Debreu's open gap lemma for semiorders",
        "authors": [
            "A. Estevan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The problem of finding a (continuous) utility function for a semiorder has\nbeen studied since in 1956 R.D. Luce introduced in \\emph{Econometrica} the\nnotion. There was almost no results on the continuity of the representation. A\nsimilar result to Debreu's Lemma, but for semiorders, was never achieved.\nRecently, some necessary conditions for the existence of a continuous\nrepresentation as well as some conjectures were presented by A. Estevan. In the\npresent paper we prove these conjectures, achieving the desired version of\nDebreu's Open Gap Lemma for bounded semiorders. This result allows to remove\nthe open-closed and closed-open gaps of a subset $S\\subseteq \\mathbb{R}$, but\nnow keeping the constant threshold, so that $x+1<y$ if and only if $g(x)+1<g(y)\n\\, (x,y\\in S)$. Therefore, the continuous representation (in the sense of\nScott-Suppes) of bounded semiorders is characterized. These results are\nachieved thanks to the key notion of $\\epsilon$-continuity, which generalizes\nthe idea of continuity for semiorders.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.04265v1"
    },
    {
        "title": "Proportional resource allocation in dynamic n-player Blotto games",
        "authors": [
            "Nejat Anbarcı",
            "Kutay Cingiz",
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A variety of social, economic, and political interactions have long been\nmodelled after Blotto games. In this paper, we introduce a general model of\ndynamic $n$-player Blotto contests. The players have asymmetric resources, and\nthe battlefield prizes are not necessarily homogeneous. Each player's\nprobability of winning the prize in a battlefield is governed by a contest\nsuccess function and players' resource allocation on that battlefield. We show\nthat there exists a subgame perfect equilibrium in which players allocate their\nresources proportional to the battlefield prizes for every history. This result\nis robust to exogenous resource shocks throughout the game.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.05087v2"
    },
    {
        "title": "Ambiguous Persuasion: An Ex-Ante Formulation",
        "authors": [
            "Xiaoyu Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Consider a persuasion game where both the sender and receiver are ambiguity\naverse with maxmin expected utility (MEU) preferences and the sender can choose\nto design an ambiguous information structure. This paper studies the game with\nan ex-ante formulation: The sender first commits to a (possibly ambiguous)\ninformation structure and then the receiver best responds by choosing an\nex-ante message-contingent action plan. Under this formulation, I show it is\nnever strictly beneficial for the sender to use an ambiguous information\nstructure as opposed to a standard (unambiguous) information structure. This\nresult is shown to be robust to the receiver having non-MEU Uncertainty Averse\npreferences but not to the sender having non-MEU preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.05376v3"
    },
    {
        "title": "Non-Additive Axiologies in Large Worlds",
        "authors": [
            "Christian Tarsney",
            "Teruji Thomas"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Is the overall value of a world just the sum of values contributed by each\nvalue-bearing entity in that world? Additively separable axiologies (like total\nutilitarianism, prioritarianism, and critical level views) say 'yes', but\nnon-additive axiologies (like average utilitarianism, rank-discounted\nutilitarianism, and variable value views) say 'no'. This distinction is\npractically important: additive axiologies support 'arguments from astronomical\nscale' which suggest (among other things) that it is overwhelmingly important\nfor humanity to avoid premature extinction and ensure the existence of a large\nfuture population, while non-additive axiologies need not. We show, however,\nthat when there is a large enough 'background population' unaffected by our\nchoices, a wide range of non-additive axiologies converge in their implications\nwith some additive axiology -- for instance, average utilitarianism converges\nto critical-level utilitarianism and various egalitarian theories converge to\nprioritiarianism. We further argue that real-world background populations may\nbe large enough to make these limit results practically significant. This means\nthat arguments from astronomical scale, and other arguments in practical ethics\nthat seem to presuppose additive separability, may be truth-preserving in\npractice whether or not we accept additive separability as a basic axiological\nprinciple.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.06842v1"
    },
    {
        "title": "Background risk and small-stakes risk aversion",
        "authors": [
            "Xiaosheng Mu",
            "Luciano Pomatto",
            "Philipp Strack",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We show that under plausible levels of background risk, no theory of choice\nunder risk -- such as expected utility theory, prospect theory, or rank\ndependent utility -- can simultaneously satisfy the following three economic\npostulates: (i) Decision makers are risk-averse over small gambles, (ii) they\nrespect stochastic dominance, and (iii) they account for background risk.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08033v2"
    },
    {
        "title": "An Application of Hölder's Inequality to Economics",
        "authors": [
            "James Otterson"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We use H\\\"older's inequality to get simple derivations of certain economic\nformulas involving CES, Armington, or $n$-stage Armington functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08122v1"
    },
    {
        "title": "The Large Core of College Admission Markets: Theory and Evidence",
        "authors": [
            "Péter Biró",
            "Avinatan Hassidim",
            "Assaf Romm",
            "Ran I. Shorrer",
            "Sándor Sóvágó"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study stable allocations in college admissions markets where students can\nattend the same college under different financial terms. The deferred\nacceptance algorithm identifies a stable allocation where funding is allocated\nbased on merit. While merit-based stable allocations assign the same students\nto college, non-merit-based stable allocations may differ in the number of\nstudents assigned to college. In large markets, this possibility requires\nheterogeneity in applicants' sensitivity to financial terms. In Hungary, where\nsuch heterogeneity is present, a non-merit-based stable allocation would\nincrease the number of assigned applicants by 1.9%, and affect 8.3% of the\napplicants relative to any merit-based stable allocation. These findings\ncontrast sharply with findings from the matching (without contracts)\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08631v2"
    },
    {
        "title": "A Model of Choice with Minimal Compromise",
        "authors": [
            "Mario Vazquez Corte"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  I formulate and characterize the following two-stage choice behavior. The\ndecision maker is endowed with two preferences. She shortlists all maximal\nalternatives according to the first preference. If the first preference is\ndecisive, in the sense that it shortlists a unique alternative, then that\nalternative is the choice. If multiple alternatives are shortlisted, then, in a\nsecond stage, the second preference vetoes its minimal alternative in the\nshortlist, and the remaining members of the shortlist form the choice set. Only\nthe final choice set is observable. I assume that the first preference is a\nweak order and the second is a linear order. Hence the shortlist is fully\nrationalizable but one of its members can drop out in the second stage, leading\nto bounded rational behavior. Given the asymmetric roles played by the\nunderlying binary relations, the consequent behavior exhibits a minimal\ncompromise between two preferences. To our knowledge it is the first Choice\nfunction that satisfies Sen's $\\beta$ axiom of choice,but not $\\alpha$.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08771v3"
    },
    {
        "title": "Information Design in Optimal Auctions",
        "authors": [
            "Yi-Chun Chen",
            "Xiangqian Yang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the information design problem in a single-unit auction setting. The\ninformation designer controls independent private signals according to which\nthe buyers infer their binary private values. Assuming that the seller adopts\nthe optimal auction due to Myerson (1981) in response, we characterize both the\nbuyer-optimal information structure, which maximizes the buyers' surplus, and\nthe sellerworst information structure, which minimizes the seller's revenue. We\ntranslate both information design problems into finite-dimensional, constrained\noptimization problems in which one can explicitly solve for the optimal\ninformation structures. In contrast to the case with one buyer (Roesler and\nSzentes, 2017), we show that with two or more buyers, the symmetric\nbuyer-optimal information structure is different from the symmetric\nseller-worst information structure. The good is always sold under the\nseller-worst information structure but not under the buyer-optimal information\nstructure. Nevertheless, as the number of buyers goes to infinity, both\nsymmetric information structures converge to no disclosure. We also show that\nin an ex ante symmetric setting, an asymmetric information structure is never\nseller-worst but can generate a strictly higher surplus for the buyers than the\nsymmetric buyer-optimal information structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08990v2"
    },
    {
        "title": "The Duopoly Analysis of Graphics Card Market",
        "authors": [
            "Nan Miles Xi"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  By analyzing the duopoly market of computer graphics cards, we categorized\nthe effects of enterprise's technological progress into two types, namely, cost\nreduction and product diversification. Our model proved that technological\nprogress is the most effective means for enterprises in this industry to\nincrease profits. Due to the technology-intensive nature of this industry,\nmonopolistic enterprises face more intense competition compared with\ntraditional manufacturing. Therefore, they have more motivation for\ntechnological innovation. Enterprises aiming at maximizing profits have\nincentives to reduce costs and achieve a higher degree of product\ndifferentiation through technological innovation.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.09074v1"
    },
    {
        "title": "Naive analytics equilibrium",
        "authors": [
            "Ron Berman",
            "Yuval Heller"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study interactions with uncertainty about demand sensitivity. In our\nsolution concept (1) firms choose seemingly-optimal strategies given the level\nof sophistication of their data analytics, and (2) the levels of sophistication\nform best responses to one another. Under the ensuing equilibrium firms\nunderestimate price elasticities and overestimate advertising effectiveness, as\nobserved empirically. The misestimates cause firms to set prices too high and\nto over-advertise. In games with strategic complements (substitutes), profits\nPareto dominate (are dominated by) those of the Nash equilibrium. Applying the\nmodel to team production games explains the prevalence of overconfidence among\nentrepreneurs and salespeople.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.15810v2"
    },
    {
        "title": "Strategy-proof and Envy-free Mechanisms for House Allocation",
        "authors": [
            "Priyanka Shende",
            "Manish Purohit"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider the problem of allocating indivisible objects to agents when\nagents have strict preferences over objects. There are inherent trade-offs\nbetween competing notions of efficiency, fairness and incentives in assignment\nmechanisms. It is, therefore, natural to consider mechanisms that satisfy two\nof these three properties in their strongest notions, while trying to improve\non the third dimension. In this paper, we are motivated by the following\nquestion: Is there a strategy-proof and envy-free random assignment mechanism\nmore efficient than equal division?\n  Our contributions in this paper are twofold. First, we further explore the\nincompatibility between efficiency and envy-freeness in the class of\nstrategy-proof mechanisms. We define a new notion of efficiency that is weaker\nthan ex-post efficiency and prove that any strategy-proof and envy-free\nmechanism must sacrifice efficiency even in this very weak sense. Next, we\nintroduce a new family of mechanisms called Pairwise Exchange mechanisms and\nmake the surprising observation that strategy-proofness is equivalent to\nenvy-freeness within this class. We characterize the set of all neutral and\nstrategy-proof (and hence, also envy-free) mechanisms in this family and show\nthat they admit a very simple linear representation.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.16384v1"
    },
    {
        "title": "The Frequency of Convergent Games under Best-Response Dynamics",
        "authors": [
            "Samuel C. Wiese",
            "Torsten Heinrich"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Generating payoff matrices of normal-form games at random, we calculate the\nfrequency of games with a unique pure strategy Nash equilibrium in the ensemble\nof $n$-player, $m$-strategy games. These are perfectly predictable as they must\nconverge to the Nash equilibrium. We then consider a wider class of games that\nconverge under a best-response dynamic, in which each player chooses their\noptimal pure strategy successively. We show that the frequency of convergent\ngames goes to zero as the number of players or the number of strategies goes to\ninfinity. In the $2$-player case, we show that for large games with at least\n$10$ strategies, convergent games with multiple pure strategy Nash equilibria\nare more likely than games with a unique Nash equilibrium. Our novel approach\nuses an $n$-partite graph to describe games.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.01052v1"
    },
    {
        "title": "Constrained Serial Rule on the Full Preference Domain",
        "authors": [
            "Priyanka Shende"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the problem of assigning objects to agents in the presence of\narbitrary linear constraints when agents are allowed to be indifferent between\nobjects. Our main contribution is the generalization of the (Extended)\nProbabilistic Serial mechanism via a new mechanism called the Constrained\nSerial Rule. This mechanism is computationally efficient and maintains\ndesirable efficiency and fairness properties namely constrained ordinal\nefficiency and envy-freeness among agents of the same type. Our mechanism is\nbased on a linear programming approach that accounts for all constraints and\nprovides a re-interpretation of the bottleneck set of agents that form a\ncrucial part of the Extended Probabilistic Serial mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.01178v1"
    },
    {
        "title": "Evolution of Risk-Taking Behaviour and Status Preferences in\n  Anti-Coordination Games",
        "authors": [
            "Manuel Staab"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper analyses how risk-taking behaviour and preferences over\nconsumption rank can emerge as a neutrally stable equilibrium when individuals\nface an anti-coordination task. If in an otherwise homogeneous society\ninformation about relative consumption becomes available, this cannot be\nignored. Despite concavity in the objective function, stable types must be\nwilling to accept risky gambles to differentiate themselves, and thus allow for\ncoordination. Relative consumption acts as a form of costly communication. This\nsuggests status preferences to be salient in settings where miscoordination is\nparticularly costly.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.02740v2"
    },
    {
        "title": "Platform-Mediated Competition",
        "authors": [
            "Quitzé Valenzuela-Stookey"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Cross-group externalities and network effects in two-sided platform markets\nshape market structure and competition policy, and are the subject of extensive\nstudy. Less understood are the within-group externalities that arise when the\nplatform designs many-to-many matchings: the value to agent $i$ of matching\nwith agent $j$ may depend on the set of agents with which $j$ is matched. These\neffects are present in a wide range of settings in which firms compete for\nindividuals' custom or attention. I characterize platform-optimal matchings in\na general model of many-to-many matching with within-group externalities. I\nprove a set of comparative statics results for optimal matchings, and show how\nthese can be used to analyze the welfare effects various changes, including\nvertical integration by the platform, horizontal mergers between firms on one\nside of the market, and changes in the platform's information structure. I then\nexplore market structure and regulation in two in-depth applications. The first\nis monopolistic competition between firms on a retail platform such as Amazon.\nThe second is a multi-channel video program distributor (MVPD) negotiating\ntransfer fees with television channels and bundling these to sell to\nindividuals.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.03879v1"
    },
    {
        "title": "Screening and Information-Sharing Externalities",
        "authors": [
            "Quitzé Valenzuela-Stookey"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In many settings, multiple uninformed agents bargain simultaneously with a\nsingle informed agent in each of multiple periods. For example, workers and\nfirms negotiate each year over salaries, and the firm has private information\nabout the value of workers' output. I study the effects of transparency in\nthese settings; uninformed agents may observe others' past bargaining outcomes,\ne.g. wages. I show that in equilibrium, each uninformed agent will choose in\neach period whether to try to separate the informed agent's types (screen) or\nreceive the same outcome regardless of type (pool). In other words, the agents\nengage in a form of experimentation via their bargaining strategies. There are\ntwo main theoretical insights. First, there is a complementary screening\neffect: the more agents screen in equilibrium, the lower the information rents\nthat each will have to pay. Second, the payoff of the informed agent will have\na certain supermodularity property, which implies that equilibria with\nscreening are \"fragile\" to deviations by uninformed agents. I apply the results\nto study pay-secrecy regulations and anti-discrimination policy. I show that,\nsurprisingly, penalties for pay discrimination have no impact on bargaining\noutcomes. I discuss how this result depends on the legal framework for\ndiscrimination cases, and suggest changes to enhance the efficacy of\nanti-discrimination regulations. In particular, anti-discrimination law should\npreclude the so-called \"salary negotiation defense\".\n",
        "pdf_link": "http://arxiv.org/pdf/2011.04013v1"
    },
    {
        "title": "Intensinist Social Welfare and Ordinal Intensity-Efficient Allocations",
        "authors": [
            "Georgios Gerasimou"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study social welfare and allocation efficiency in situations where, in\naddition to having ordinal preferences, agents also have `ordinal intensities':\nthey can make comparisons such as `I prefer a to b more than I prefer c to d'\nwithout necessarily being able to quantify them. In this new informational\nenvironment for social choice we first introduce a rank-based criterion for\ninterpersonal comparisons of such ordinal intensities. Building on it, we\nintroduce the `intensinist' social welfare function. This maps intensity\nprofiles to weak orders over social alternatives using a scoring criterion that\ngeneralizes the one in the classic Borda method in a way that allows for\ndifferences in agents' intensities to be reflected in preference aggregation\nmore accurately and in a much richer class of situations. Building on the same\ncomparability postulate we also study the classic assignment problem by\ndefining an allocation to be `intensity-efficient' if it is Pareto efficient\nwith respect to the preferences induced by the agents' intensities and also\nsuch that, when another allocation assigns the same pairs of items to the same\npairs of agents but in a `flipped' way, the former allocation assigns the\ncommonly preferred item in every such pair to the agent who prefers it more. We\npresent some first results on the (non-)existence of such allocations without\nimposing restrictions on preferences or intensities other than strictness, and\nalso study the relation -- or lack thereof -- between intensity-efficient and\nclassical utilitarian allocations.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.04306v3"
    },
    {
        "title": "Selling two complementary goods",
        "authors": [
            "Komal Malik",
            "Kolagani Paramahamsa"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A seller is selling a pair of divisible complementary goods to an agent. The\nagent consumes the goods only in a specific ratio and freely disposes of excess\nin either goods. The value of the bundle and the ratio are private information\nof the agent. In this two-dimensional type space model, we characterize the\nincentive constraints and show that the optimal (expected revenue-maximizing)\nmechanism is a ratio-dependent posted price or a posted price mechanism for a\nclass of distributions. We also show that the optimal mechanism is a posted\nprice mechanism when the value and the ratio are independently distributed.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.05840v4"
    },
    {
        "title": "A Reputation for Honesty",
        "authors": [
            "Drew Fudenberg",
            "Ying Gao",
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We analyze situations in which players build reputations for honesty rather\nthan for playing particular actions. A patient player facing a sequence of\nshort-run opponents makes an announcement about their intended action after\nobserving an idiosyncratic shock, and before players act. The patient player is\neither an honest type whose action coincides with their announcement, or an\nopportunistic type who can freely choose their actions. We show that the\npatient player can secure a high payoff by building a reputation for being\nhonest when the short-run players face uncertainty about which of the patient\nplayer's actions are currently feasible, but may receive a low payoff when\nthere is no such uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.07159v1"
    },
    {
        "title": "Double blind vs. open review: an evolutionary game logit-simulating the\n  behavior of authors and reviewers",
        "authors": [
            "Mantas Radzvilas",
            "Francesco De Pretis",
            "William Peden",
            "Daniele Tortoli",
            "Barbara Osimani"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Despite the tremendous successes of science in providing knowledge and\ntechnologies, the Replication Crisis has highlighted that scientific\ninstitutions have much room for improvement. Peer-review is one target of\ncriticism and suggested reforms. However, despite numerous controversies peer\nreview systems, plus the obvious complexity of the incentives affecting the\ndecisions of authors and reviewers, there is very little systematic and\nstrategic analysis of peer-review systems. In this paper, we begin to address\nthis feature of the peer-review literature by applying the tools of game\ntheory. We use simulations to develop an evolutionary model based around a game\nplayed by authors and reviewers, before exploring some of its tendencies. In\nparticular, we examine the relative impact of double-blind peer-review and open\nreview on incentivising reviewer effort under a variety of parameters. We also\ncompare (a) the impact of one review system versus another with (b) other\nalterations, such as higher costs of reviewing. We find that is no reliable\ndifference between peer-review systems in our model. Furthermore, under some\nconditions, higher payoffs for good reviewing can lead to less (rather than\nmore) author effort under open review. Finally, compared to the other\nparameters that we vary, it is the exogenous utility of author effort that\nmakes an important and reliable difference in our model, which raises the\npossibility that peer-review might not be an important target for institutional\nreforms.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.07797v1"
    },
    {
        "title": "Screening for breakthroughs",
        "authors": [
            "Gregorio Curello",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We identify a new dynamic agency problem: that of incentivising the prompt\ndisclosure of productive information. To study it, we introduce a general model\nin which a technological breakthrough occurs at an uncertain time and is\nprivately observed by an agent, and a principal must incentivise disclosure via\nher control of a payoff-relevant physical allocation. We uncover a deadline\nstructure of optimal mechanisms: they have a simple deadline form in an\nimportant special case, and a graduated deadline structure in general. We apply\nour results to the design of unemployment insurance schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10090v8"
    },
    {
        "title": "Persuading a Wishful Thinker",
        "authors": [
            "Victor Augias",
            "Daniel M. A. Barreto"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study a persuasion problem in which a sender designs an information\nstructure to induce a non-Bayesian receiver to take a particular action. The\nreceiver, who is privately informed about his preferences, is a wishful\nthinker: he is systematically overoptimistic about the most favorable outcomes.\nWe show that wishful thinking can lead to a qualitative shift in the structure\nof optimal persuasion compared to the Bayesian case, whenever the sender is\nuncertain about what the receiver perceives as the best-case outcome in his\ndecision problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.13846v5"
    },
    {
        "title": "On Absolute and Relative Change",
        "authors": [
            "Silvan Brauen",
            "Philipp Erpf",
            "Micha Wasem"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Based on an axiomatic approach we propose two related novel one-parameter\nfamilies of indicators of change which put in a relation classical indicators\nof change such as absolute change, relative change and the log-ratio.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.14807v1"
    },
    {
        "title": "Bus operators in competition: a directed location approach",
        "authors": [
            "Fernanda Herrera",
            "Sergio I. López"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present a directed variant of Salop (1979) model to analyze bus transport\ndynamics. The players are operators competing in cooperative and\nnon-cooperative games. Utility, like in most bus concession schemes in emerging\ncountries, is proportional to the total fare collection. Competition for\npicking up passengers leads to well documented and dangerous driving practices\nthat cause road accidents, traffic congestion and pollution. We obtain\ntheoretical results that support the existence and implementation of such\npractices, and give a qualitative description of how they come to occur. In\naddition, our results allow to compare the current or base transport system\nwith a more cooperative one.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.01155v2"
    },
    {
        "title": "Strength in Numbers: Robust Mechanisms for Public Goods with Many Agents",
        "authors": [
            "Jin Xi",
            "Haitian Xie"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This study examines the mechanism design problem for public goods provision\nin a large economy with $n$ independent agents. We propose a class of\ndominant-strategy incentive compatible and ex-post individually rational\nmechanisms, which we call the adjusted mean-thresholding (AMT) mechanisms. We\nshow that when the cost of provision grows slower than the $\\sqrt{n}$-rate, the\nAMT mechanisms are both eventually ex-ante budget balanced and asymptotically\nefficient. When the cost grows faster than the $\\sqrt{n}$-rate, in contrast, we\nshow that any incentive compatible, individually rational, and eventually\nex-ante budget balanced mechanism must have provision probability converging to\nzero and hence cannot be asymptotically efficient. The AMT mechanisms have a\nsimple form and are more informationally robust when compared to, for example,\nthe second-best mechanism. This is because the construction of an AMT mechanism\ndepends only on the first moment of the valuation distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.02423v4"
    },
    {
        "title": "Assignment mechanisms: common preferences and information acquisition",
        "authors": [
            "Georgy Artemov"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I study costly information acquisition in a two-sided matching problem, such\nas matching applicants to schools. An applicant's utility is a sum of common\nand idiosyncratic components. The idiosyncratic component is unknown to the\napplicant but can be learned at a cost. When applicants are assigned using an\nordinal strategy-proof mechanism, too few acquire information, generating a\nsignificant welfare loss. Affirmative action and other realistic policies may\nlead to a Pareto improvement. As incentives to acquire information differ\nacross mechanisms, ignoring such incentives may lead to incorrect welfare\nassessments, for example, in comparing a popular Immediate Assignment and an\nordinal strategy-proof mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.06885v2"
    },
    {
        "title": "DKPRG or how to succeed in the Kolkata Paise Restaurant gamevia TSP",
        "authors": [
            "Kalliopi Kastampolidou",
            "Christos Papalitsas",
            "Theodore Andronikos"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The Kolkata Paise Restaurant Problem is a challenging game, in which $n$\nagents must decide where to have lunch during their lunch break. The game is\nvery interesting because there are exactly $n$ restaurants and each restaurant\ncan accommodate only one agent. If two or more agents happen to choose the same\nrestaurant, only one gets served and the others have to return back to work\nhungry. In this paper we tackle this problem from an entirely new angle. We\nabolish certain implicit assumptions, which allows us to propose a novel\nstrategy that results in greater utilization for the restaurants. We emphasize\nthe spatially distributed nature of our approach, which, for the first time,\nperceives the locations of the restaurants as uniformly distributed in the\nentire city area. This critical change in perspective has profound\nramifications in the topological layout of the restaurants, which now makes it\ncompletely realistic to assume that every agent has a second chance. Every\nagent now may visit, in case of failure, more than one restaurants, within the\npredefined time constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.07760v1"
    },
    {
        "title": "Leadership and Institutional Reforms",
        "authors": [
            "Matata Ponyo Mapon",
            "Jean-Paul K. Tsasa"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Large-scale institutional changes require strong commitment and involvement\nof all stakeholders. We use the standard framework of cooperative game theory\ndeveloped by Ichiishi (1983, pp. 78-149) to: (i) establish analytically the\ndifference between policy maker and political leader; (ii) formally study\ninteractions between a policy maker and his followers; (iii) examine the role\nof leadership in the implementation of structural reforms. We show that a\npolicy maker can be both partisan and non-partisan, while a political leader\ncan only be non-partisan. Following this distinction, we derive the probability\nof success of an institutional change, as well as the nature of the gain that\nsuch a change would generate on the beneficiary population. Based on the\nrestrictions of this simple mathematical model and using some evidence from the\nCongolese experience between 2012 and 2016, we show that institutional changes\ncan indeed benefit the majority of the population, when policy makers are truly\npartisan.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.08702v1"
    },
    {
        "title": "Machine Learning for Strategic Inference",
        "authors": [
            "In-Koo Cho",
            "Jonathan Libgober"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study interactions between strategic players and markets whose behavior is\nguided by an algorithm. Algorithms use data from prior interactions and a\nlimited set of decision rules to prescribe actions. While as-if rational play\nneed not emerge if the algorithm is constrained, it is possible to guide\nbehavior across a rich set of possible environments using limited details.\nProvided a condition known as weak learnability holds, Adaptive Boosting\nalgorithms can be specified to induce behavior that is (approximately) as-if\nrational. Our analysis provides a statistical perspective on the study of\nendogenous model misspecification.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.09613v1"
    },
    {
        "title": "Optimal Disclosure of Information to a Privately Informed Receiver",
        "authors": [
            "Ozan Candogan",
            "Philipp Strack"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study information design settings where the designer controls information\nabout a state, and there are multiple agents interacting in a game who are\nprivately informed about their types. Each agent's utility depends on all\nagents' types and actions, as well as (linearly) on the state. To optimally\nscreen the agents, the designer first asks agents to report their types and\nthen sends a private action recommendation to each agent whose distribution\ndepends on all reported types and the state. We show that there always exists\nan optimal mechanism which is laminar partitional. Such a mechanism partitions\nthe state space for each type profile and recommends the same action profile\nfor states that belong to the same partition element. Furthermore, the convex\nhulls of any two partition elements are such that either one contains the other\nor they have an empty intersection. In the single-agent case, each state is\neither perfectly revealed or lies in an interval in which the number of\ndifferent signal realizations is at most the number of different types of the\nagent plus two. A similar result is established for the multi-agent case.\n  We also highlight the value of screening: without screening the best\nachievable payoff could be as low as one over the number of types fraction of\nthe optimal payoff. Along the way, we shed light on the solutions of\noptimization problems over distributions subject to a mean-preserving\ncontraction constraint and additional side constraints, which might be of\nindependent interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.10431v5"
    },
    {
        "title": "Structural Interventions in Networks",
        "authors": [
            "Yang Sun",
            "Wei Zhao",
            "Junjie Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Two types of interventions are commonly implemented in networks:\ncharacteristic intervention, which influences individuals' intrinsic\nincentives, and structural intervention, which targets the social links among\nindividuals. In this paper we provide a general framework to evaluate the\ndistinct equilibrium effects of both types of interventions. We identify a\nhidden equivalence between a structural intervention and an endogenously\ndetermined characteristic intervention. Compared with existing approaches in\nthe literature, the perspective from such an equivalence provides several\nadvantages in the analysis of interventions that target network structure. We\npresent a wide range of applications of our theory, including identifying the\nmost wanted criminal(s) in delinquent networks and targeting the key connector\nfor isolated communities.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.12420v2"
    },
    {
        "title": "A Pricing Mechanism to Jointly Mitigate Market Power and Environmental\n  Externalities in Electricity Markets",
        "authors": [
            "Lamia Varawala",
            "Mohammad Reza Hesamzadeh",
            "György Dán",
            "Derek Bunn",
            "Juan Rosellón"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The electricity industry has been one of the first to face technological\nchanges motivated by sustainability concerns. Whilst efficiency aspects of\nmarket design have tended to focus upon market power concerns, the new policy\nchallenges emphasise sustainability. We argue that market designs need to\ndevelop remedies for market conduct integrated with regard to environmental\nexternalities. Accordingly, we develop an incentive-based market clearing\nmechanism using a power network representation with a distinctive feature of\nincomplete information regarding generation costs. The shortcomings of price\ncaps to mitigate market power, in this context, are overcome with the proposed\nmechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.00578v2"
    },
    {
        "title": "Screening for breakthroughs: Omitted proofs",
        "authors": [
            "Gregorio Curello",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This document contains all proofs omitted from our working paper 'Screening\nfor breakthroughs'; specifically, the February 2024 version of the paper\n(arXiv:2011.10090v8).\n",
        "pdf_link": "http://arxiv.org/pdf/2104.02044v5"
    },
    {
        "title": "Wost Case in Voting and Bargaining",
        "authors": [
            "Anna bogomolnaia Ron Holzman Herve Moulin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The guarantee of an anonymous mechanism is the worst case welfare an agent\ncan secure against unanimously adversarial others. How high can such a\nguarantee be, and what type of mechanism achieves it? We address the worst case\ndesign question in the n-person probabilistic voting/bargaining model with p\ndeterministic outcomes. If n is no less than p the uniform lottery is the only\nmaximal (unimprovable) guarantee; there are many more if p>n, in particular the\nones inspired by the random dictator mechanism and by voting by veto. If n=2\nthe maximal set M(n,p) is a simple polytope where each vertex combines a round\nof vetoes with one of random dictatorship. For p>n>2, we show that the dual\nveto and random dictator guarantees, together with the uniform one, are the\nbuilding blocks of 2 to the power d simplices of dimension d in M(n,p), where d\nis the quotient of p-1 by n. Their vertices are guarantees easy to interpret\nand implement. The set M(n,p) may contain other guarantees as well; what we can\nsay in full generality is that it is a finite union of polytopes, all sharing\nthe uniform guarantee.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.02316v1"
    },
    {
        "title": "Fiscal Stimulus of Last Resort",
        "authors": [
            "Alessandro Piergallini"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I examine global dynamics in a monetary model with overlapping generations of\nfinite-horizon agents and a binding lower bound on nominal interest rates. Debt\ntargeting rules exacerbate the possibility of self-fulfilling liquidity traps,\nfor agents expect austerity following deflationary slumps. Conversely, activist\nbut sustainable fiscal policy regimes - implementing intertemporally balanced\ntax cuts and/or transfer increases in response to disinflationary trajectories\n- are capable of escaping liquidity traps and embarking inflation into a\nglobally stable path that converges to the target. Should fiscal stimulus of\nlast resort be overly aggressive, however, spiral dynamics around the\nliquidity-trap steady state exist, causing global indeterminacy.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.02753v1"
    },
    {
        "title": "Projection Bias in Effort Choices",
        "authors": [
            "Marc Kaufmann"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Working becomes harder as we grow tired or bored. I model individuals who\nunderestimate these changes in marginal disutility -- as implied by \"projection\nbias\" -- when deciding whether or not to continue working. This bias causes\npeople's plans to change: early in the day when they are rested, they plan to\nwork more than late in the day when they are rested. Despite initially\noverestimating how much they will work, people facing a single task with\ndecreasing returns to effort work optimally. However, when facing multiple\ntasks, they misprioritize urgent but unimportant over important but non-urgent\ntasks. And when they face a single task with all-or-nothing rewards (such as\nbeing promoted) they start, and repeatedly work on, some overly ambitious tasks\nthat they later abandon. Each day they stop working once they have grown tired,\nwhich can lead to large daily welfare losses. Finally, when they have either\nincreasing or decreasing productivity, people work less each day than\npreviously planned. This moves people closer to optimal effort for decreasing,\nand further away from optimal effort for increasing productivity.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.04327v1"
    },
    {
        "title": "Echo Chambers: Voter-to-Voter Communication and Political Competition",
        "authors": [
            "Monica Anna Giovanniello"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I study how strategic communication among voters shapes both political\noutcomes and parties' advertising strategies in a model of informative campaign\nadvertising. Two main results are derived. First, echo chambers arise\nendogenously. Surprisingly, a small ideological distance between voters is not\nsufficient to guarantee that a chamber is created, bias direction plays a\ncrucial role. Second, when voters' network entails a significant waste of\ninformation, parties tailor their advertising to the opponent's supporters\nrather than to their own.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.04703v1"
    },
    {
        "title": "Mechanism Design Approach to School Choice: One versus Many",
        "authors": [
            "Battal Dogan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A vast majority of the school choice literature focuses on designing\nmechanisms to simultaneously assign students to many schools, and employs a\n\"make it up as you go along\" approach when it comes to each school's admissions\npolicy. An alternative approach is to focus on the admissions policy for one\nschool. This is especially relevant for effectively communicating policy\nobjectives such as achieving a diverse student body or implementing affirmative\naction. I argue that the latter approach is relatively under-examined and\ndeserves more attention in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.08485v1"
    },
    {
        "title": "Costlier switching strengthens competition even without advertising",
        "authors": [
            "Sander Heinsalu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Consumers only discover at the first seller which product best fits their\nneeds, then check its price online, then decide on buying. Switching sellers is\ncostly. Equilibrium prices fall in the switching cost, eventually to the\nmonopoly level, despite the exit of lower-value consumers when changing sellers\nbecomes costlier. More expensive switching makes some buyers exit the market,\nleaving fewer inframarginal buyers to the sellers. Marginal buyers may change\nin either direction, so for a range of parameters, all firms cut prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.08934v1"
    },
    {
        "title": "Pareto Optimality, Functional Dependence and Collective Agency",
        "authors": [
            "Chenwei Shi",
            "Yiyang Wang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper approaches the problem of understanding collective agency from a\nlogical and game-theoretical perspective. Instead of collective intentionality,\nour analysis highlights the role of Pareto optimality. To facilitate the\nanalysis, we propose a logic of preference and functional dependence by\nextending the logic of functional dependence. In this logic, we can express\nPareto optimality and thus reason about collective agency.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.09112v1"
    },
    {
        "title": "New axioms for top trading cycles",
        "authors": [
            "Siwei Chen",
            "Yajing Chen",
            "Chia-Ling Hsu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  School choice is of great importance both in theory and practice. This paper\nstudies the (student-optimal) top trading cycles mechanism (TTCM) in an\naxiomatic way. We introduce two new axioms: MBG (mutual best\ngroup)-quota-rationality and MBG-robust efficiency. While stability implies\nMBG-quota-rationality, MBG-robust efficiency is weaker than robust efficiency,\nwhich is stronger than the combination of efficiency and group\nstrategy-proofness. The TTCM is characterized by MBG-quota-rationality and\nMBG-robust efficiency. Our results construct a new basis to compare the TTCM\nwith the other school choice mechanisms, especially the student-optimal stable\nmechanism under Ergin but not Kesten-acyclic priority structures.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.09157v3"
    },
    {
        "title": "The probabilistic rank random assignment rule and its axiomatic\n  characterization",
        "authors": [
            "Yajing Chen",
            "Patrick Harless",
            "Zhenhua Jiao"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper considers the problem of randomly assigning a set of objects to a\nset of agents based on the ordinal preferences of agents. We generalize the\nwell-known immediate acceptance algorithm to the afore-mentioned random\nenvironments and define the probabilistic rank rule (PR rule). We introduce two\nnew axioms: sd-rank-fairness, and equal-rank envy-freeness. Sd-rank-fairness\nimplies sd-efficiency. Equal-rank envy-freeness implies equal treatment of\nequals. Sd-rank-fairness and equal-rank envy-freeness are enough to\ncharacterize the PR rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.09165v1"
    },
    {
        "title": "On the relation between Preference Reversal and Strategy-Proofness",
        "authors": [
            "K. P. S. Bhaskara Rao",
            "Achille Basile",
            "Surekha Rao"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We analyze the relation between strategy-proofness and preference reversal in\nthe case that agents may declare indifference. Interestingly, Berga and Moreno\n(2020), have recently derived preference reversal from group strategy-proofness\nof social choice functions on strict preferences domains if the range has no\nmore than three elements. We extend this result and at the same time simplify\nit. Our analysis points out the role of individual strategy-proofness in\nderiving the preference reversal property, giving back to the latter its\noriginal individual nature (cfr. Eliaz, 2004).\n  Moreover, we show that the difficulties Berga and Moreno highlighted relaxing\nthe assumption on the cardinality of the range, disappear under a proper\nassumption on the domain. We introduce the concept of complete sets of\npreferences and show that individual strategy-proofness is sufficient to obtain\nthe preference reversal property when the agents' feasible set of orderings is\ncomplete. This covers interesting cases like single peaked preferences, rich\ndomains admitting regular social choice functions, and universal domains. The\nfact that we use individual rather than group strategy-proofness, allows to get\nimmediately some of the known, and some new, equivalences between individual\nand group strategy-proofness. Finally, we show that group strategy-proofness is\nonly really needed to obtain preference reversal if there are infinitely many\nvoters.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.10205v2"
    },
    {
        "title": "Policy with stochastic hysteresis",
        "authors": [
            "Georgii Riabov",
            "Aleh Tsyvinski"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The paper develops a general methodology for analyzing policies with\npath-dependency (hysteresis) in stochastic models with forward looking\noptimizing agents. Our main application is a macro-climate model with a\npath-dependent climate externality. We derive in closed form the dynamics of\nthe optimal Pigouvian tax, that is, its drift and diffusion coefficients. The\ndynamics of the present marginal damages is given by the recently developed\nfunctional It\\^o formula. The dynamics of the conditional expectation process\nof the future marginal damages is given by a new total derivative formula that\nwe prove. The total derivative formula represents the evolution of the\nconditional expectation process as a sum of the expected dynamics of hysteresis\nwith respect to time, a form of a time derivative, and the expected dynamics of\nhysteresis with the shocks to the trajectory of the stochastic process, a form\nof a stochastic derivative. We then generalize the results. First, we propose a\ngeneral class of hysteresis functionals that permits significant tractability.\nSecond, we characterize in closed form the dynamics of the stochastic\nhysteresis elasticity that represents the change in the whole optimal policy\nprocess with an introduction of small hysteresis effects. Third, we determine\nthe optimal policy process.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.10225v1"
    },
    {
        "title": "A Graph-based Similarity Function for CBDT: Acquiring and Using New\n  Information",
        "authors": [
            "Federico E. Contiggiani",
            "Fernando Delbianco",
            "Fernando Tohmé"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  One of the consequences of persistent technological change is that it force\nindividuals to make decisions under extreme uncertainty. This means that\ntraditional decision-making frameworks cannot be applied. To address this issue\nwe introduce a variant of Case-Based Decision Theory, in which the solution to\na problem obtains in terms of the distance to previous problems. We formalize\nthis by defining a space based on an orthogonal basis of features of problems.\nWe show how this framework evolves upon the acquisition of new information,\nnamely features or values of them arising in new problems. We discuss how this\ncan be useful to evaluate decisions based on not yet existing data.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.14268v1"
    },
    {
        "title": "Contracts in Electricity Markets under EU ETS: A Stochastic Programming\n  Approach",
        "authors": [
            "Arega Getaneh Abate",
            "Rossana Riccardi",
            "Carlos Ruiz"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The European Union Emission Trading Scheme (EU ETS) is a cornerstone of the\nEU's strategy to fight climate change and an important device for plummeting\ngreenhouse gas (GHG) emissions in an economically efficient manner. The power\nindustry has switched to an auction-based allocation system at the onset of\nPhase III of the EU ETS to bring economic efficiency by negating windfall\nprofits that have been resulted from grandfathered allocation of allowances in\nthe previous phases. In this work, we analyze and simulate the interaction of\noligopolistic generators in an electricity market with a game-theoretical\nframework where the electricity and the emissions markets interact in a\ntwo-stage electricity market. For analytical simplicity, we assume a single\nfutures market where the electricity is committed at the futures price, and the\nemissions allowance is contracted in advance, prior to a spot market where the\nenergy and allowances delivery takes place. Moreover, a coherent risk measure\nis applied (Conditional Value at Risk) to model both risk averse and risk\nneutral generators and a two-stage stochastic optimization setting is\nintroduced to deal with the uncertainty of renewable capacity, demand,\ngeneration, and emission costs. The performance of the proposed equilibrium\nmodel and its main properties are examined through realistic numerical\nsimulations. Our results show that renewable generators are surging and\nsubstituting conventional generators without compromising social welfare.\nHence, both renewable deployment and emission allowance auctioning are\neffectively reducing GHG emissions and promoting low-carbon economic path.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.15062v1"
    },
    {
        "title": "Is More Precise Word of Mouth Better for a High Quality Firm? ... Not\n  Always",
        "authors": [
            "Mohsen Foroughifar",
            "David Soberman"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Consumers often resort to third-party information such as word of mouth,\ntestimonials and reviews to learn more about the quality of a new product.\nHowever, it may be difficult for consumers to assess the precision of such\ninformation. We use a monopoly setting to investigate how the precision of\nthird-party information and consumers' ability to recognize precision impact\nfirm profits. Conventional wisdom suggests that when a firm is high quality, it\nshould prefer a market where consumers are better at recognizing precise\nsignals. Yet in a broad range of conditions, we show that when the firm is high\nquality, it is more profitable to sell to consumers who do not recognize\nprecise signals. Given the ability of consumers to assess precision, we show a\nlow quality firm always suffers from more precise information. However, a high\nquality firm can also suffer from more precise information. The precision range\nin which a high quality firm gains or suffers from better information depends\non how skilled consumers are at recognizing precision.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.01040v2"
    },
    {
        "title": "Revenue Adequate Prices for Chance-Constrained Electricity Markets with\n  Variable Renewable Energy Sources",
        "authors": [
            "Xin Shi",
            "Alberto J. Lamadrid L.",
            "Luis F. Zuluaga"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In a commodity market, revenue adequate prices refer to compensations that\nensure that a market participant has a non-negative profit. In this article, we\nstudy the problem of deriving revenue adequate prices for an electricity\nmarket-clearing model with uncertainties resulting from the use of variable\nrenewable energy sources (VRES). To handle the uncertain nature of the problem,\nwe use a chance-constrained optimization (CCO) approach, which has recently\nbecome very popular choice when constructing dispatch electricity models with\npenetration of VRES (or other sources of uncertainty). Then, we show how prices\nthat satisfy revenue adequacy in expectation for the market administrator, and\ncost recovery in expectation for all conventional and VRES generators, can be\nobtained from the optimal dual variables associated with the deterministic\nequivalent of the CCO market-clearing model. These results constitute a novel\ncontribution to the research of research on revenue adequate, equilibrium, and\nother types of pricing schemes that have been derived in the literature when\nthe market uncertainties are modeled using stochastic or robust optimization\napproaches. Unlike in the stochastic approach, the CCO market-clearing model\nstudied here produces uncertainty uniform real-time prices that do not depend\non the real-time realization of the VRES generation outcomes. To illustrate our\nresults, we consider a case study electricity market, and contrast the market\nprices obtained using a revenue adequate stochastic approach and the proposed\nrevenue adequate CCO approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.01233v1"
    },
    {
        "title": "Designing Heaven's Will: The job assignment in the Chinese imperial\n  civil service",
        "authors": [
            "Inácio Bó",
            "Li Chen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We provide an original analysis of historical documents to describe the\nassignment procedures used to allocate entry-level civil service jobs in China\nfrom the tenth to the early twentieth century. The procedures tried to take\ndifferent objectives into account through trial and error. By constructing a\nformal model that combines these procedures into a common framework, we compare\ntheir effectiveness in minimizing unfilled jobs and prioritizing high-level\nposts. We show that the problem was inherently complex such that changes made\nto improve the outcome could have the opposite effect. Based on a small\nmodification of the last procedure used, we provide a new mechanism for\nproducing maximum matchings under constraints in a transparent and public way.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.02457v2"
    },
    {
        "title": "Robustly Optimal Mechanisms for Selling Multiple Goods",
        "authors": [
            "Yeon-Koo Che",
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study robustly optimal mechanisms for selling multiple items. The seller\nmaximizes revenue against a worst-case distribution of a buyer's valuations\nwithin a set of distributions, called an \"ambiguity\" set. We identify the exact\nforms of robustly optimal selling mechanisms and the worst-case distributions\nwhen the ambiguity set satisfies various moment conditions on the values of\nsubsets of goods. The analysis reveals general properties of the ambiguity set\nthat justifies categorical bundling, which includes separate sales and pure\nbundling as special cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.02828v4"
    },
    {
        "title": "Dynamic Choices and Common Learning",
        "authors": [
            "Rahul Deb",
            "Ludovic Renou"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A researcher observes a finite sequence of choices made by multiple agents in\na binary-state environment. Agents maximize expected utilities that depend on\ntheir chosen alternative and the unknown underlying state. Agents learn about\nthe time-varying state from the same information and their actions change\nbecause of the evolving common belief. The researcher does not observe agents'\npreferences, the prior, the common information and the stochastic process for\nthe state. We characterize the set of choices that are rationalized by this\nmodel and generalize the information environments to allow for private\ninformation. We discuss the implications of our results for uncovering\ndiscrimination and committee decision making.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03683v1"
    },
    {
        "title": "Correlation-Robust Optimal Auctions",
        "authors": [
            "Wanchang Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I study the design of auctions in which the auctioneer is assumed to have\ninformation only about the marginal distribution of a generic bidder's\nvaluation, but does not know the correlation structure of the joint\ndistribution of bidders' valuations. I assume that a generic bidder's valuation\nis bounded and $\\bar{v}$ is the maximum valuation of a generic bidder. The\nperformance of a mechanism is evaluated in the worst case over the uncertainty\nof joint distributions that are consistent with the marginal distribution. For\nthe two-bidder case, the second-price auction with the uniformly distributed\nrandom reserve maximizes the worst-case expected revenue across all\ndominant-strategy mechanisms under certain regularity conditions. For the\n$N$-bidder ($N\\ge3$) case, the second-price auction with the $\\bar{v}-$scaled\n$Beta (\\frac{1}{N-1},1)$ distributed random reserve maximizes the worst-case\nexpected revenue across standard (a bidder whose bid is not the highest will\nnever be allocated) dominant-strategy mechanisms under certain regularity\nconditions. When the probability mass condition (part of the regularity\nconditions) does not hold, the second-price auction with the $s^*-$scaled $Beta\n(\\frac{1}{N-1},1)$ distributed random reserve maximizes the worst-case expected\nrevenue across standard dominant-strategy mechanisms, where $s^*\\in\n(0,\\bar{v})$.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.04697v2"
    },
    {
        "title": "Random Double Auction: A Robust Bilateral Trading Mechanism",
        "authors": [
            "Wanchang Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I construct a novel random double auction as a robust bilateral trading\nmechanism for a profit-maximizing intermediary who facilitates trade between a\nbuyer and a seller. It works as follows. The intermediary publicly commits to\ncharging a fixed commission fee and randomly drawing a spread from a uniform\ndistribution. Then the buyer submits a bid price and the seller submits an ask\nprice simultaneously. If the difference between the bid price and the ask price\nis greater than the realized spread, then the asset is transacted at the\nmidpoint price, and each pays the intermediary half of the fixed commission\nfee. Otherwise, no trade takes place, and no one pays or receives anything. I\nshow that the random double auction maximizes the worst-case expected profit\nacross all dominant-strategy incentive compatible and ex-post individually\nrational mechanisms for the symmetric case. I also construct a robust trading\nmechanism with similar properties for the asymmetric case.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.05427v2"
    },
    {
        "title": "Learning to agree over large state spaces",
        "authors": [
            "Michele Crescenzi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study how a consensus emerges in a finite population of like-minded\nindividuals who are asymmetrically informed about the realization of the true\nstate of the world. Agents observe a private signal about the state and then\nstart exchanging messages. Generalizing the classical model of rational\ndialogues of Geanakoplos and Polemarchakis (1982) and its subsequent\nextensions, we dispense with the standard assumption that the state space is a\nprobability space and we do not put any bound on the cardinality of the state\nspace itself or the information partitions. We show that a class of rational\ndialogues can be found that always lead to consensus provided that three main\nconditions are met. First, everybody must be able to send messages to everybody\nelse, either directly or indirectly. Second, communication must be reciprocal.\nFinally, agents need to have the opportunity to engage in dialogues of\ntransfinite length.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.06313v2"
    },
    {
        "title": "Heterogeneously Perceived Incentives in Dynamic Environments:\n  Rationalization, Robustness and Unique Selections",
        "authors": [
            "Evan Piermont",
            "Peio Zuazo-Garin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In dynamic settings each economic agent's choices can be revealing of her\nprivate information. This elicitation via the rationalization of observable\nbehavior depends each agent's perception of which payoff-relevant contingencies\nother agents persistently deem as impossible. We formalize the potential\nheterogeneity of these perceptions as disagreements at higher-orders about the\nset of payoff states of a dynamic game. We find that apparently negligible\ndisagreements greatly affect how agents interpret information and assess the\noptimality of subsequent behavior: When knowledge of the state space is only\n'almost common', strategic uncertainty may be greater when choices are\nrationalized than when they are not--forward and backward induction\npredictions, respectively, and while backward induction predictions are robust\nto small disagreements about the state space, forward induction predictions are\nnot. We also prove that forward induction predictions always admit unique\nselections a la Weinstein and Yildiz (2007) (also for spaces not satisfying\nrichness) and backward induction predictions do not.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.06772v1"
    },
    {
        "title": "Identifying Wisdom (of the Crowd): A Regression Approach",
        "authors": [
            "Jonathan Libgober"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Experts in a population hold (a) beliefs over a state (call these state\nbeliefs), as well as (b) beliefs over the distribution of beliefs in the\npopulation (call these hypothetical beliefs). If these are generated via\nupdating a common prior using a fixed information structure, then the\ninformation structure can (generically) be derived by regressing hypothetical\nbeliefs on state beliefs, provided there are at least as many signals as\nstates. In addition, the prior solves an eigenvector equation derived from a\nmatrix determined by the state beliefs and the hypothetical beliefs. Thus, the\nex-ante informational environment (i.e., how signals are generated) can be\ndetermined using ex-post data (i.e., the beliefs in the population). I discuss\nimplications of this finding, as well as what is identified when there are more\nstates than signals.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07097v2"
    },
    {
        "title": "When to sell an indivisible object: Optimal timing with Markovian buyers",
        "authors": [
            "Kiho Yoon"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the problem of when to sell an indivisible object. There is a\nmonopolistic seller who owns an indivisible object and plans to sell it over a\ngiven span of time to the set of potential buyers whose valuations for the\nobject evolve over time. We formulate the seller's problem as a dynamic\nmechanism design problem. We provide a procedure for finding the optimal\nsolution and show how to check incentive compatibility. We also discuss the\nthreshold rule from the perspective of optimal stopping.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07649v5"
    },
    {
        "title": "Improvements to Modern Portfolio Theory based models applied to\n  electricity systems",
        "authors": [
            "Gabriel Malta Castro",
            "Claude Klöckl",
            "Peter Regner",
            "Johannes Schmidt",
            "Amaro Olimpio Pereira Jr"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  With the increase of variable renewable energy sources (VRES) share in\nelectricity systems, manystudies were developed in order to determine their\noptimal technological and spatial mix. Modern PortfolioTheory (MPT) has been\nfrequently applied in this context. However, some crucial aspects, important\ninenergy planning, are not addressed by these analyses. We, therefore, propose\nseveral improvements andevaluate how each change in formulation impacts\nresults. More specifically, we address generation costs, system demand, and\nfirm energy output, present a formal model and apply it to the case of Brazil.\nWefound that, after including our proposed modifications, the resulting\nefficient frontier differs strongly fromthe one obtained in the original\nformulation. Portfolios with high output standard deviation are not ableto\nprovide a firm output level at competitive costs. Furthermore, we show that\ndiversification plays animportant role in smoothing output from VRES portfolios\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08182v1"
    },
    {
        "title": "Anabolic Persuasion",
        "authors": [
            "Kfir Eliaz",
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present a model of optimal training of a rational, sluggish agent. A\ntrainer commits to a discrete-time, finite-state Markov process that governs\nthe evolution of training intensity. Subsequently, the agent monitors the state\nand adjusts his capacity at every period. Adjustments are incremental: the\nagent's capacity can only change by one unit at a time. The trainer's objective\nis to maximize the agent's capacity - evaluated according to its lowest value\nunder the invariant distribution - subject to an upper bound on average\ntraining intensity. We characterize the trainer's optimal policy, and show how\nstochastic, time-varying training intensity can dramatically increase the\nlong-run capacity of a rational, sluggish agent. We relate our theoretical\nfindings to \"periodization\" training techniques in exercise physiology.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08786v1"
    },
    {
        "title": "A Simple Model of Monetary Policy under Phillips-Curve Causal\n  Disagreements",
        "authors": [
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I study a static textbook model of monetary policy and relax the conventional\nassumption that the private sector has rational expectations. Instead, the\nprivate sector forms inflation forecasts according to a misspecified subjective\nmodel that disagrees with the central bank's (true) model over the causal\nunderpinnings of the Phillips Curve. Following the AI/Statistics literature on\nBayesian Networks, I represent the private sector's model by a direct acyclic\ngraph (DAG). I show that when the private sector's model reverses the direction\nof causality between inflation and output, the central bank's optimal policy\ncan exhibit an attenuation effect that is sensitive to the noisiness of the\ntrue inflation-output equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08988v1"
    },
    {
        "title": "State-Promoted Investment for Industrial Reforms: an Information Design\n  Approach",
        "authors": [
            "Keeyoung Rhee",
            "Myungkyu Shim",
            "Ji Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We analyze the optimal strategy for a government to promote large-scale\ninvestment projects under information frictions. Specifically, we propose a\nmodel where the government collects information on probability of each\ninvestment and discloses it to private investors a la Kamenica and Gentzkow\n(2011). We derive the government's optimal information policy, which is\ncharacterized as threshold values for the unknown probability of the projects\nreleased to the private investors, and study how the underlying features of the\neconomy affect the optimal policies. We find that when multiple projects are\navailable, the government promotes the project with a bigger spillover effect\nby fully revealing the true state of the economy only when its probability is\nsubstantially high. Moreover, the development of the financial/information\nmarket also affects the optimal rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.09576v1"
    },
    {
        "title": "Probabilistic Fixed Ballot Rules and Hybrid Domains",
        "authors": [
            "Shurojit Chatterji",
            "Souvik Roy",
            "Soumyarup Sadhukhan",
            "Arunava Sen",
            "Huaxia Zeng"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study a class of preference domains that satisfies the familiar properties\nof minimal richness, diversity and no-restoration. We show that a specific\npreference restriction, hybridness, has been embedded in these domains so that\nthe preferences are single-peaked at the \"extremes\" and unrestricted in the\n\"middle\". We also study the structure of strategy-proof and unanimous Random\nSocial Choice Functions on these domains. We show them to be special cases of\nprobabilistic fixed ballot rules (introduced by Ehlers, Peters, and Storcken\n(2002)).\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10677v2"
    },
    {
        "title": "Information Cascades and Social Learning",
        "authors": [
            "Sushil Bikhchandani",
            "David Hirshleifer",
            "Omer Tamuz",
            "Ivo Welch"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We review the theory of information cascades and social learning. Our goal is\nto describe in a relatively integrated and accessible way the more important\nthemes, insights and applications of the literature as it has developed over\nthe last thirty years. We also highlight open questions and promising\ndirections for further theoretical and empirical exploration.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11044v1"
    },
    {
        "title": "A Random Attention and Utility Model",
        "authors": [
            "Nail Kashaev",
            "Victor H. Aguiar"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We generalize the stochastic revealed preference methodology of McFadden and\nRichter (1990) for finite choice sets to settings with limited consideration.\nOur approach is nonparametric and requires partial choice set variation. We\nimpose a monotonicity condition on attention first proposed by Cattaneo et al.\n(2020) and a stability condition on the marginal distribution of preferences.\nOur framework is amenable to statistical testing. These new restrictions extend\nwidely known parametric models of consideration with heterogeneous preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11268v3"
    },
    {
        "title": "The Giving Game",
        "authors": [
            "Peter Weijland"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper describes a basic model of a gift economy in the shape of a Giving\nGame and reveals the fundamental structure of such a game. Main result is that\nthe game shows a community effect in that a small subgroup of players\neventually keeps all circulating goods for themselves. Example applications are\nwhere computers are sharing processing power for complex calculations, or when\ncommodity traders are making transactions in some professional community. The\nGiving Game may equally well be viewed as a basic model of clientelism or\ncorruption. Keywords in this paper are giving, gift economy, community effect,\nstabilization, computational complexity, corruption, micro-economics, game\ntheory, stock trading, distributed computing, crypto currency, blockchain.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11761v1"
    },
    {
        "title": "Direct Implementation with Evidence",
        "authors": [
            "Soumen Banerjee",
            "Yi-Chun Chen",
            "Yifei Sun"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study full implementation with evidence in an environment with bounded\nutilities. We show that a social choice function is Nash implementable in a\ndirect revelation mechanism if and only if it satisfies the measurability\ncondition proposed by <cite>BL2012</cite>. Building on a novel classification\nof lies according to their refutability with evidence, the mechanism requires\nonly two agents, accounts for mixed-strategy equilibria and accommodates\nevidentiary costs. While monetary transfers are used, they are off the\nequilibrium and can be balanced with three or more agents. In a richer model of\nevidence due to <cite>KT2012</cite>, we establish pure-strategy implementation\nwith two or more agents in a direct revelation mechanism. We also obtain a\nnecessary and sufficient condition on the evidence structure for\nrenegotiation-proof bilateral contracts, based on the classification of lies.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.12298v6"
    },
    {
        "title": "Correlation Concern",
        "authors": [
            "Andrew Ellis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In many choice problems, the interaction between several distinct variables\ndetermines the payoff of each alternative. I propose and axiomatize a model of\na decision maker who recognizes that she may not accurately perceive the\ncorrelation between these variables, and who takes this into account when\nmaking her decision. She chooses as if she calculates each alternative's\nexpected outcome under multiple possible correlation structures, and then\nevaluates it according to the worst expected outcome.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.13341v1"
    },
    {
        "title": "An Implementation Approach to Rotation Programs",
        "authors": [
            "Ville Korpela",
            "Michele Lombardi",
            "Riccardo D. Saulle"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study rotation programs within the standard implementation frame-work\nunder complete information. A rotation program is a myopic stableset whose\nstates are arranged circularly, and agents can effectively moveonly between two\nconsecutive states. We provide characterizing conditionsfor the implementation\nof efficient rules in rotation programs. Moreover,we show that the conditions\nfully characterize the class of implementablemulti-valued and efficient rules\n",
        "pdf_link": "http://arxiv.org/pdf/2105.14560v1"
    },
    {
        "title": "Robust Aggregation of Correlated Information",
        "authors": [
            "Henrique de Oliveira",
            "Yuhta Ishii",
            "Xiao Lin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  An agent makes decisions based on multiple sources of information. In\nisolation, each source is well understood, but their correlation is unknown. We\nstudy the agent's robustly optimal strategies -- those that give the best\npossible guaranteed payoff, even under the worst possible correlation. With two\nstates and two actions, we show that a robustly optimal strategy uses a single\ninformation source, ignoring all others. In general decision problems, robustly\noptimal strategies combine multiple sources of information, but the number of\ninformation sources that are needed has a bound that only depends on the\ndecision problem. These findings provide a new rationale for why information is\nignored.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.00088v2"
    },
    {
        "title": "Justice as a Social Bargain and Optimization Problem",
        "authors": [
            "Andreas Siemoneit"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The question of \"Justice\" still divides social research and moral philosophy.\nSeveral Theories of Justice and conceptual approaches compete here, and\ndistributive justice remains a major societal controversy. From an evolutionary\npoint of view, fair and just exchange can be nothing but \"equivalent\", and this\nmakes \"strict\" reciprocity (merit, equity) the foundational principle of\njustice, both theoretically and empirically. But besides being just, justice\nmust be effective, efficient, and communicable. Moral reasoning is a\ncommunicative strategy for resolving conflict, enhancing status, and\nmaintaining cooperation, thereby making justice rather a social bargain and an\noptimization problem. Social psychology (intuitions, rules of thumb,\nself-bindings) can inform us when and why the two auxiliary principles equality\nand need are more likely to succeed than merit would. Nevertheless, both\nequality and need are governed by reciprocal considerations, and self-bindings\nhelp to interpret altruism as \"very generalized reciprocity\". The Meritocratic\nPrinciple can be implemented, and its controversy avoided, by concentrating on\n\"non-merit\", i.e., institutionally draining the wellsprings of undeserved\nincomes (economic rents). Avoiding or taxing away economic rents is an\neffective implementation of justice in liberal democracies. This would enable\nmarket economies to bring economic achievement and income much more in line,\nthus becoming more just.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.00830v1"
    },
    {
        "title": "The Origin of Corporate Control Power",
        "authors": [
            "Jie He",
            "Min Wang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  How does the control power of corporate shareholder arise? On the fundamental\nprinciples of economics, we discover that the probability of a shareholder\npossessing optimal control power evolves in Fibonacci series pattern and\nemerges as the wave between 1/2 and 2/3 along with time in period of 12h (h is\nthe time interval between the state and state of the evolution). This novel\nfeature suggests the efficiency of the allocation of corporate shareholders'\nright and power. Data on the Chinese stock market support this prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.01681v17"
    },
    {
        "title": "Dynamic mechanism design: An elementary introduction",
        "authors": [
            "Kiho Yoon"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper introduces dynamic mechanism design in an elementary fashion. We\nfirst examine optimal dynamic mechanisms: We find necessary and sufficient\nconditions for perfect Bayesian incentive compatibility and formulate the\noptimal dynamic mechanism problem. We next examine efficient dynamic\nmechanisms: We establish the uniqueness of Groves mechanism and investigate\nbudget balance of the dynamic pivot mechanism in some detail for a bilateral\ntrading environment. This introduction reveals that many results and techniques\nof static mechanism design can be straightforwardly extended and adapted to the\nanalysis of dynamic settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.04850v1"
    },
    {
        "title": "Subjective Causality in Choice",
        "authors": [
            "Andrew Ellis",
            "Heidi Christina Thysen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  When making a decision based on observational data, a person's choice depends\non her beliefs about which correlations reflect causality and which do not. We\nmodel an agent who predicts the outcome of each available action from\nobservational data using a subjective causal model represented by a directed\nacyclic graph (DAG). An analyst can identify the agent's DAG from her random\nchoice rule. Her choices reveal the chains of causal reasoning that she\nundertakes and the confounding variables she adjusts for, and these objects pin\ndown her model. When her choices determine the data available, her behavior\naffects her inferences, which in turn affect her choices. We provide necessary\nand sufficient conditions for testing whether such an agent's behavior is\ncompatible with the model.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.05957v3"
    },
    {
        "title": "Mechanism Design meets Priority Design: Redesigning the US Army's\n  Branching Process",
        "authors": [
            "Kyle Greenberg",
            "Parag A. Pathak",
            "Tayfun Sonmez"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Army cadets obtain occupations through a centralized process. Three\nobjectives -- increasing retention, aligning talent, and enhancing trust --\nhave guided reforms to this process since 2006. West Point's mechanism for the\nClass of 2020 exacerbated challenges implementing Army policy aims. We\nformulate these desiderata as axioms and study their implications theoretically\nand with administrative data. We show that the Army's objectives not only\ndetermine an allocation mechanism, but also a specific priority policy, a\nuniqueness result that integrates mechanism and priority design. These results\nled to a re-design of the mechanism, now adopted at both West Point and ROTC.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06582v1"
    },
    {
        "title": "Fragility of Confounded Learning",
        "authors": [
            "Xuanye Wang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider an observational learning model with exogenous public payoff\nshock. We show that confounded learning doesn't arise for almost all private\nsignals and almost all shocks, even if players have sufficiently divergent\npreferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.07712v1"
    },
    {
        "title": "Cyclical behavior of evolutionary dynamics in coordination games with\n  changing payoffs",
        "authors": [
            "George Loginov"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The paper presents a model of two-speed evolution in which the payoffs in the\npopulation game (or, alternatively, the individual preferences) slowly adjust\nto changes in the aggregate behavior of the population. The model investigates\nhow, for a population of myopic agents with homogeneous preferences, changes in\nthe environment caused by current aggregate behavior may affect future payoffs\nand hence alter future behavior. The interaction between the agents is based on\na symmetric two-strategy game with positive externalities and negative feedback\nfrom aggregate behavior to payoffs, so that at every point in time the\npopulation has an incentive to coordinate, whereas over time the more popular\nstrategy becomes less appealing. Under the best response dynamics and the logit\ndynamics with small noise levels the joint trajectories of preferences and\nbehavior converge to closed orbits around the unique steady state, whereas for\nlarge noise levels the steady state of the logit dynamics becomes a sink. Under\nthe replicator dynamics the unique steady state of the system is repelling and\nthe trajectories are unbounded unstable spirals.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.08224v1"
    },
    {
        "title": "Asymmetric All-Pay Auctions with Spillovers",
        "authors": [
            "Maria Betto",
            "Matthew W. Thomas"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  When opposing parties compete for a prize, the sunk effort players exert\nduring the conflict can affect the value of the winner's reward. These\nspillovers can have substantial influence on the equilibrium behavior of\nparticipants in applications such as lobbying, warfare, labor tournaments,\nmarketing, and R&D races. To understand this influence, we study a general\nclass of asymmetric, two-player all-pay auctions where we allow for spillovers\nin each player's reward. The link between participants' efforts and rewards\nyields novel effects -- in particular, players with higher costs and lower\nvalues than their opponent sometimes extract larger payoffs.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.08496v2"
    },
    {
        "title": "Defying Gravity: The Economic Effects of Social Distancing",
        "authors": [
            "Alfredo D. Garcia",
            "Christopher A. Hartwell",
            "Martín Andrés Szybisz"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The COVID-19 pandemic has forced changes in production and especially in\nhuman interaction, with \"social distancing\" a standard prescription for slowing\ntransmission of the disease. This paper examines the economic effects of social\ndistancing at the aggregate level, weighing both the benefits and costs to\nprolonged distancing. Specifically we fashion a model of economic recovery when\nthe productive capacity of factors of production is restricted by social\ndistancing, building a system of equations where output growth and social\ndistance changes are interdependent. The model attempts to show the complex\ninteractions between output levels and social distancing, developing cycle\npaths for both variables. Ultimately, however, defying gravity via prolonged\nsocial distancing shows that a lower growth path is inevitable as a result.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.09361v1"
    },
    {
        "title": "Multi-activity Influence and Intervention",
        "authors": [
            "Ryan Kor",
            "Junjie Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Using a general network model with multiple activities, we analyse a\nplanner's welfare maximising interventions taking into account within-activity\nnetwork spillovers and cross-activity interdependence. We show that the\ndirection of the optimal intervention, under sufficiently large budgets,\ncritically depends on the spectral properties of two matrices: the first matrix\ndepicts the social connections among agents, while the second one quantifies\nthe strategic interdependence among different activities. In particular, the\nfirst principal component of the interdependence matrix determines budget\nresource allocation across different activities, while the first (last)\nprincipal component of the network matrix shapes the resource allocation across\ndifferent agents when network effects are strategic complements (substitutes).\nWe explore some comparative statics analysis with respective to model\nprimitives and discuss several applications and extensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.09410v2"
    },
    {
        "title": "A Concavification Approach to Ambiguous Persuasion",
        "authors": [
            "Xiaoyu Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This note shows that the value of ambiguous persuasion characterized in\nBeauchene, Li and Li(2019) can be given by a concavification program as in\nBayesian persuasion (Kamenica and Gentzkow, 2011). In addition, it implies that\nan ambiguous persuasion game can be equivalently formalized as a Bayesian\npersuasion game by distorting the utility functions. This result is obtained\nunder a novel construction of ambiguous persuasion.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.11270v2"
    },
    {
        "title": "Robust Misspecified Models and Paradigm Shifts",
        "authors": [
            "Cuimin Ba"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Individuals use models to guide decisions, but many models are wrong. This\npaper studies which misspecified models are likely to persist when individuals\nalso entertain alternative models. Consider an agent who uses her model to\nlearn the relationship between action choices and outcomes. The agent exhibits\nsticky model switching, captured by a threshold rule such that she switches to\nan alternative model when it is a sufficiently better fit for the data she\nobserves. The main result provides a characterization of whether a model\npersists based on two key features that are straightforward to derive from the\nprimitives of the learning environment, namely, the model's asymptotic accuracy\nin predicting the equilibrium pattern of observed outcomes and the 'tightness'\nof the prior around this equilibrium. I show that misspecified models can be\nrobust in that they persist against a wide range of competing models --\nincluding the correct model -- despite individuals observing an infinite amount\nof data. Moreover, simple misspecified models with entrenched priors can be\neven more robust than correctly specified models. I use this characterization\nto provide a learning foundation for the persistence of systemic biases in two\napplications. First, in an effort-choice problem, I show that overconfidence in\none's ability is more robust than underconfidence. Second, a simplistic binary\nview of politics is more robust than the more complex correct view when\nindividuals consume media without fully recognizing the reporting bias.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.12727v3"
    },
    {
        "title": "Unique Stable Matchings",
        "authors": [
            "Gregory Z. Gutin",
            "Philip R. Neary",
            "Anders Yeo"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper we consider the issue of a unique prediction in one to one two\nsided matching markets, as defined by Gale and Shapley (1962), and we prove the\nfollowing. Theorem. Let P be a one-to-one two-sided matching market and let P\nbe its associated normal form, a (weakly) smaller matching market with the same\nset of stable matchings, that can be obtained using procedures introduced in\nIrving and Leather (1986) and Balinski and Ratier (1997). The following three\nstatements are equivalent (a) P has a unique stable matching. (b) Preferences\non P* are acyclic, as defined by Chung (2000). (c) In P* every market\nparticipant's preference list is a singleton.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.12977v4"
    },
    {
        "title": "Reference Dependence and Random Attention",
        "authors": [
            "Matthew Kovach",
            "Elchin Suleymanov"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We explore the ways that a reference point may direct attention. Utilizing a\nstochastic choice framework, we provide behavioral foundations for the\nReference-Dependent Random Attention Model (RD-RAM). Our characterization\nresult shows that preferences may be uniquely identified even when the\nattention process depends arbitrarily on both the menu and the reference point.\nThe RD-RAM is able to capture rich behavioral patterns, including frequency\nreversals among non-status quo alternatives and choice overload. We also\nanalyze specific attention processes, characterizing reference-dependent\nversions of several prominent models of stochastic consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.13350v3"
    },
    {
        "title": "The Machiavellian frontier of top trading cycles",
        "authors": [
            "Yajing Chen",
            "Zhenhua Jiao",
            "Chenfeng Zhang",
            "Luosai Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the housing market problem introduced by Shapley and Scarf\n(1974). We probe the Machiavellian frontier of the well-known top trading\ncycles (TTC) rule by weakening strategy-proofness and providing new\ncharacterizations for this rule. Specifically, our contribution lies in three\naspects. First, we weaken the concept of strategy-proofness and introduce a new\nincentive notion called truncation-invariance, where the truthful\npreference-reporting assignment cannot be altered by any agent through\nmisreporting a truncation of the true preference at the assignment produced by\nthe true preference unilaterally. Second, we characterize the TTC rule by the\nfollowing three groups of axioms: individual rationality, pair-efficiency,\ntruncation-invariance; individual rationality, Pareto efficiency,\ntruncation-invariance; individual rationality, endowments-swapping-proofness,\ntruncation-invariance.1 The new characterizations refine several previous\nresults.2 Third, we show through examples that the characterization results of\nTakamiya (2001) and Miyagawa (2002) can no longer be obtained if\nstrategy-proofness is replaced with truncation-invariance.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.14456v2"
    },
    {
        "title": "Behavioral Mistakes Support Cooperation in an N-Person Repeated Public\n  Goods Game",
        "authors": [
            "Jung-Kyoo Choi",
            "Jun Sok Huhh"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This study investigates the effect of behavioral mistakes on the evolutionary\nstability of the cooperative equilibrium in a repeated public goods game. Many\nstudies show that behavioral mistakes have detrimental effects on cooperation\nbecause they reduce the expected length of mutual cooperation by triggering the\nconditional retaliation of the cooperators. However, this study shows that\nbehavioral mistakes could have positive effects. Conditional cooperative\nstrategies are either neutrally stable or are unstable in a mistake-free\nenvironment, but we show that behavioral mistakes can make \\textit{all} of the\nconditional cooperative strategies evolutionarily stable. We show that\nbehavioral mistakes stabilize the cooperative equilibrium based on the most\nintolerant cooperative strategy by eliminating the behavioral\nindistinguishability between conditional cooperators in the cooperative\nequilibrium. We also show that mistakes make the tolerant conditional\ncooperative strategies evolutionarily stable by preventing the defectors from\naccumulating the free-rider's advantages. Lastly, we show that the behavioral\nmistakes could serve as a criterion for the equilibrium selection among\ncooperative equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.15994v1"
    },
    {
        "title": "Quantal Response Equilibrium and Rationalizability: Inside the Black Box",
        "authors": [
            "Shuige Liu",
            "Fabio Maccheroni"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper aims to connect epistemic and behavioral game theory by examining\nthe epistemic foundations of quantal response equilibrium (QRE) in static\ngames. We focus on how much information agents possess about the probability\ndistributions of idiosyncratic payoff shocks, in addition to the standard\nassumptions of rationality and common belief in rationality. When these\ndistributions are transparent, we obtain a solution concept called\n$\\Delta^p$-rationalizability, which includes action distributions derived from\nQRE; we also give a condition under which this relationship holds true in\nreverse. When agents only have common belief in the monotonicity of these\ndistributions (for example, extreme value distributions), we obtain another\nsolution concept called $\\Delta^M$-rationalizability, which includes action\ndistributions derived from rank-dependent choice equilibrium, a parameter-free\nvariant of QRE. Our solution concepts also provide insights for interpreting\nexperimental and empirical data.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.16081v3"
    },
    {
        "title": "Collective Progress: Dynamics of Exit Waves",
        "authors": [
            "Doruk Cetemen",
            "Can Urgun",
            "Leeat Yariv"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study a model of collective search by teams. Discoveries beget discoveries\nand correlated search results are governed by a Brownian path. Search results'\nvariation at any point -- the search scope -- is jointly controlled. Agents\nindividually choose when to cease search and implement their best discovery. We\ncharacterize equilibrium and optimal policies. Search scope is constant and\nindependent of search outcomes as long as no member leaves. It declines after\ndepartures. A simple drawdown stopping boundary governs each agent's search\ntermination. We show the emergence of endogenous exit waves, whereby possibly\nheterogeneous agents cease search all at once.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00406v1"
    },
    {
        "title": "Fiscal policy and inequality in a model with endogenous positional\n  concerns",
        "authors": [
            "Kirill Borissov",
            "Nigar Hashimzade"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We investigate the dynamics of wealth inequality in an economy where\nhouseholds have positional preferences, with the strength of the positional\nconcern determined endogenously by inequality of wealth distribution in the\nsociety. We demonstrate that in the long run such an economy converges to a\nunique egalitarian steady-state equilibrium, with all households holding equal\npositive wealth, when the initial inequality is sufficiently low. Otherwise,\nthe steady state is characterised by polarisation of households into rich, who\nown all the wealth, and poor, whose wealth is zero. A fiscal policy with\ngovernment consumption funded by taxes on labour income and wealth can move the\neconomy from any initial state towards an egalitarian equilibrium with a higher\naggregate wealth.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00410v1"
    },
    {
        "title": "Auction Design with Data-Driven Misspecifications",
        "authors": [
            "Philippe Jehiel",
            "Konrad Mierendorff"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider auction environments in which at the time of the auction bidders\nobserve signals about their ex-post value. We introduce a model of novice\nbidders who do not know know the joint distribution of signals and instead\nbuild a statistical model relating others' bids to their own ex post value from\nthe data sets accessible from past similar auctions. Crucially, we assume that\nonly ex post values and bids are accessible while signals observed by bidders\nin past auctions remain private. We consider steady-states in such\nenvironments, and importantly we allow for correlation in the signal\ndistribution. We first observe that data-driven bidders may behave suboptimally\nin classical auctions such as the second-price or first-price auctions whenever\nthere are correlations. Allowing for a mix of rational (or experienced) and\ndata-driven (novice) bidders results in inefficiencies in such auctions, and we\nshow the inefficiency extends to all auction-like mechanisms in which bidders\nare restricted to submit one-dimensional (real-valued) bids.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00640v1"
    },
    {
        "title": "Habits and demand changes after COVID-19",
        "authors": [
            "Mauro Bambi",
            "Daria Ghilli",
            "Fausto Gozzi",
            "Marta Leocata"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper, we investigate how the COVID-19 pandemics and more precisely\nthe lockdown of a sector of the economy may have changed our habits and,\nthere-fore, altered the demand of some goods even after the re-opening. In a\ntwo-sector infinite horizon economy, we show that the demand of the goods\nproduced by the sector closed during the lockdown could shrink or expand with\nrespect to their pre-pandemic level depending on the length of the lockdown and\nthe relative strength of the satiation effect and the substitutability effect.\nWe also provide conditions under which this sector could remain inactive even\nafter the lockdown as well as an insight on the policy which should be adopted\nto avoid this outcome.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00909v2"
    },
    {
        "title": "The effects of incentives, social norms, and employees' values on work\n  performance",
        "authors": [
            "Michael Roos",
            "Jessica Reale",
            "Frederik Banning"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This agent-based model contributes to a theory of corporate culture in which\ncompany performance and employees' behaviour result from the interaction\nbetween financial incentives, motivational factors and endogenous social norms.\nEmployees' personal values are the main drivers of behaviour. They shape\nagents' decisions about how much of their working time to devote to individual\ntasks, cooperative, and shirking activities. The model incorporates two aspects\nof the management style, analysed both in isolation and combination: (i)\nmonitoring efforts affecting intrinsic motivation, i.e. the firm is either\ntrusting or controlling, and (ii) remuneration schemes affecting extrinsic\nmotivation, i.e. individual or group rewards. The simulations show that\nfinancial incentives can (i) lead to inefficient levels of cooperation, and\n(ii) reinforce value-driven behaviours, amplified by emergent social norms. The\ncompany achieves the highest output with a flat wage and a trusting management.\nEmployees that value self-direction highly are pivotal, since they are strongly\n(de-)motivated by the management style.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01139v3"
    },
    {
        "title": "Characterizing nonatomic admissions markets",
        "authors": [
            "Max Kapur"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This article proposes a characterization of admissions markets that can\npredict the distribution of students at each school or college under both\ncentralized and decentralized admissions paradigms. The characterization builds\non recent research in stable assignment, which models students as a probability\ndistribution over the set of ordinal preferences and scores. Although stable\nassignment mechanisms presuppose a centralized admissions process, I show that\nstable assignments coincide with equilibria of a decentralized, iterative\nmarket in which schools adjust their admissions standards in pursuit of a\ntarget class size. Moreover, deferred acceptance algorithms for stable\nassignment are a special case of a well-understood price dynamic called\nt\\^{a}tonnement. The second half of the article turns to a parametric\ndistribution of student types that enables explicit computation of the\nequilibrium and is invertible in the schools' preferability parameters.\nApplying this model to a public dataset produces an intuitive ranking of the\npopularity of American universities and a realistic estimate of each school's\ndemand curve, and does so without imposing an equilibrium assumption or\nrequiring the granular student information used in conventional logistic\nregressions.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01340v1"
    },
    {
        "title": "Risk aversion and uniqueness of equilibrium: a polynomial approach",
        "authors": [
            "Andrea Loi",
            "Stefano Matta"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the connection between risk aversion, number of consumers and\nuniqueness of equilibrium. We consider an economy with two goods and $c$\nimpatience types, where each type has additive separable preferences with HARA\nBernoulli utility function,\n$u_H(x):=\\frac{\\gamma}{1-\\gamma}\\left(b+\\frac{a}{\\gamma}x\\right)^{1-\\gamma}$.\nWe show that if $\\gamma\\in \\left(1, \\frac{c}{c-1}\\right]$, the equilibrium is\nunique. Moreover, the methods used, involving Newton's symmetric polynomials\nand Descartes' rule of signs, enable us to offer new sufficient conditions for\nuniqueness in a closed-form expression highlighting the role played by\nendowments, patience and specific HARA parameters. Finally, new necessary and\nsufficient conditions in ensuring uniqueness are derived for the particular\ncase of CRRA Bernoulli utility functions with $\\gamma =3$.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01947v3"
    },
    {
        "title": "The Near Miss Effect and the Framing of Lotteries",
        "authors": [
            "Michael Crystal"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present a framework for analyzing the near miss effect in lotteries. A\ndecision maker (DM) facing a lottery, falsely interprets losing outcomes that\nare close to winning ones, as a sign that success is within reach. As a result\nof this false belief, the DM will prefer lotteries that induce a higher\nfrequency of near misses, even if the underlying probability of winning is\nconstant. We define a near miss index that measures the near miss effect\ninduced by a given lottery and analyze the optimal lottery design in terms of\nnear miss. This analysis leads us to establish a fruitful connection between\nour near miss framework and the field of coding theory. Building on this\nconnection we compare different lottery frames and the near miss effect they\ninduce. Analyzing an interaction between a seller and a buyer of lotteries\nallows us to gain further insight into the optimal framing of lotteries and\nmight offer a potential explanation as to why lotteries with a very small\nprobability of winning are commonplace and attractive.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.02478v2"
    },
    {
        "title": "a theoretical look at ordinal classification methods based on comparing\n  actions with limiting boundaries between adjacent classes",
        "authors": [
            "Eduardo Fernandez",
            "Jose Rui Figueira",
            "Jorge Navarro"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper addresses the general problem of designing ordinal classification\nmethods based on comparing actions with limiting boundaries of ordered classes\n(categories). The fundamental requirement of the method consists of setting a\nrelational system (D,S), where S and D are reflexive and transitive relations,\nrespectively, S should be compatible with the order of the set of classes, and\nD is a subset of S. An asymmetric preference relation P is defined from S.\nOther requirements are imposed on the actions which compose the limiting\nboundaries between adjacent classes, in such a way that each class is closed\nbelow and above. The paper proposes S-based and P-based assignment procedures.\nEach of them is composed of two complementary assignment procedures, which\ncorrespond through the transposition operation and should be used conjointly.\nThe methods work under several basic conditions on the set of limiting\nboundaries. Under other more demanding separability requirements, each\nprocedure fulfills the set of structural properties established for other\noutranking-based ordinal classification methods. Our proposal avoids the\nconflict between the required correspondence through the transposition\noperation and the assignment of limiting actions to the classes to which they\nbelong. We thus propose very diverse S and P-based ordinal classification\napproaches with desirable properties, which can be designed by using decision\nmodels with the capacity to build preference relations fulfilling the basic\nrequirements to S and D.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.03440v1"
    },
    {
        "title": "A theoretical look at ordinal classification methods based on reference\n  sets composed of characteristic actions",
        "authors": [
            "Eduardo Fernandez",
            "Jorge Navarro",
            "Efrain Solares"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  From a theoretical view, this paper addresses the general problem of\ndesigning ordinal classification methods based on comparing actions with subset\nof actions, which are representative of their classes (categories). The basic\ndemand of the proposal consists in setting a relational system (D, S), where S\nis a reflexive relation compatible with the preferential order of the set of\nclasses, and D is a transitive relation such that D is a subset of S. Different\nordinal classification methods can be derived from diverse model of preferences\nfulfilling the basic conditions on S and D. Two complementary assignment\nprocedures compose each method, which correspond through the transposition\noperation and should be used complementarily. The methods work under relatively\nslight conditions on the representative actions and satisfy several fundamental\nproperties. ELECTRE TRI-nC, INTERCLASS-nC, and the hierarchical ELECTRE TRI-nC\nwith interacting criteria, can be considered as particular cases of this\ngeneral framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04656v1"
    },
    {
        "title": "Axiomatic Formulation of the Optimal Transaction Cost Theory in the\n  Legal Process through Cobb-Douglas Optimization",
        "authors": [
            "Kwadwo Osei Bonsu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In a legal dispute, parties engage in a series of negotiations so as to\narrive at a reasonable settlement. The parties need to present a fair and\nreasonable bargain in order to induce the WTA, willingness to accept of the\nplaintiff and the WTP, willingness to pay of the defendant. Cooperation can\nonly be attained when the WTA of the plaintiff is less than or equal to the WTP\nof the defendant. From an economic perspective, the legal process can\nconsidered as market place of buying and selling claims. High transaction costs\ndecrease the reasonable bargain, thereby making cooperation more appealing to\nthe defendant. On the other hand, low or zero transaction costs means the\nreasonable bargain is only dependent on the expected gain from winning at trial\nand the settlement benefit thereby making cooperation more appealing to the\nplaintiff. Hence, we need to find a way of adjusting the number of settlements\nwith the number of trials in order to maximize the social utility value. This\npaper uses Cobb-Douglas optimization to formulate an optimal transaction cost\nalgorithm considering the confinement of a generalized legal framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.07168v1"
    },
    {
        "title": "Exact inference from finite market data",
        "authors": [
            "Felix Kübler",
            "Raghav Malhotra",
            "Herakles Polemarchakis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We develop conditions under which individual choices and Walrasian\nequilibrium prices and allocations can be exactly inferred from finite market\ndata. First, we consider market data that consist of individual demands as\nprices and incomes change. Second, we show that finitely many observations of\nindividual endowments and associated Walrasian equilibrium prices, and only\nprices, suffice to identify individual demands and, as a consequence,\nequilibrium comparative statics.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.07294v1"
    },
    {
        "title": "A Theory of Ex Post Rationalization",
        "authors": [
            "Erik Eyster",
            "Shengwu Li",
            "Sarah Ridout"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  People rationalize their past choices, even those that were mistakes in\nhindsight. We propose a formal theory of this behavior. The theory predicts\nthat sunk costs affect later choices. Its model primitives are identified by\nchoice behavior and it yields tractable comparative statics.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.07491v9"
    },
    {
        "title": "Monotone Comparative Statics in the Calvert-Wittman Model",
        "authors": [
            "Francisco Rodríguez",
            "Eduardo Zambrano"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper, we show that when policy-motivated parties can commit to a\nparticular platform during a uni-dimensional electoral contest where valence\nissues do not arise there must be a positive association between the policies\npreferred by candidates and the policies adopted in expectation in the lowest\nand the highest equilibria of the electoral contest. We also show that this\nneed not be so if the parties cannot commit to a particular policy. The\nimplication is that evidence of a negative relationship between enacted and\npreferred policies is suggestive of parties that hold positions from which they\nwould like to move from yet are unable to do so.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.07910v2"
    },
    {
        "title": "Sampling dynamics and stable mixing in hawk-dove games",
        "authors": [
            "Srinivas Arigapudi",
            "Yuval Heller",
            "Amnon Schreiber"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The hawk-dove game admits two types of equilibria: an asymmetric pure\nequilibrium in which players in one population play hawk and players in the\nother population play dove, and an inefficient symmetric mixed equilibrium, in\nwhich hawks are frequently matched against each other. The existing literature\nshows that populations will converge to playing one of the pure equilibria from\nalmost any initial state. By contrast, we show that plausible sampling\ndynamics, in which agents occasionally revise their actions by observing either\nopponents' behavior or payoffs in a few past interactions, can induce the\nopposite result: global convergence to one of the inefficient mixed stationary\nstates.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.08423v4"
    },
    {
        "title": "A mathematical definition of property rights in a Debreu economy",
        "authors": [
            "Abhimanyu Pallavi Sudhir"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present mathematical definitions for rights structures, government and\nnon-attenuation in a generalized N-person game (Debreu abstract economy), thus\nproviding a formal basis for property rights theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09651v1"
    },
    {
        "title": "A Free and Fair Economy: A Game of Justice and Inclusion",
        "authors": [
            "Ghislain H. Demeze-Jouatsa",
            "Roland Pongou",
            "Jean-Baptiste Tondji"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Frequent violations of fair principles in real-life settings raise the\nfundamental question of whether such principles can guarantee the existence of\na self-enforcing equilibrium in a free economy. We show that elementary\nprinciples of distributive justice guarantee that a pure-strategy Nash\nequilibrium exists in a finite economy where agents freely (and\nnon-cooperatively) choose their inputs and derive utility from their pay. Chief\namong these principles is that: 1) your pay should not depend on your name, and\n2) a more productive agent should not earn less. When these principles are\nviolated, an equilibrium may not exist. Moreover, we uncover an intuitive\ncondition -- technological monotonicity -- that guarantees equilibrium\nuniqueness and efficiency. We generalize our findings to economies with social\njustice and inclusion, implemented in the form of progressive taxation and\nredistribution, and guaranteeing a basic income to unproductive agents. Our\nanalysis uncovers a new class of strategic form games by incorporating\nnormative principles into non-cooperative game theory. Our results rely on no\nparticular assumptions, and our setup is entirely non-parametric. Illustrations\nof the theory include applications to exchange economies, surplus distribution\nin a firm, contagion and self-enforcing lockdown in a networked economy, and\nbias in the academic peer-review system.\n  Keywords: Market justice; Social justice; Inclusion; Ethics; Discrimination;\nSelf-enforcing contracts; Fairness in non-cooperative games; Pure strategy Nash\nequilibrium; Efficiency.\n  JEL Codes: C72, D30, D63, J71, J38\n",
        "pdf_link": "http://arxiv.org/pdf/2107.12870v1"
    },
    {
        "title": "On the probability of the Condorcet Jury Theorem or the Miracle of\n  Aggregation",
        "authors": [
            "Álvaro Romaniega"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The Condorcet Jury Theorem or the Miracle of Aggregation are frequently\ninvoked to ensure the competence of some aggregate decision-making processes.\nIn this article we explore an estimation of the prior probability of the thesis\npredicted by the theorem (if there are enough voters, majority rule is a\ncompetent decision procedure). We use tools from measure theory to conclude\nthat, prima facie, it will fail almost surely. To update this prior either more\nevidence in favor of competence would be needed or a modification of the\ndecision rule. Following the latter, we investigate how to obtain an almost\nsure competent information aggregation mechanism for almost any evidence on\nvoter competence (including the less favorable ones). To do so, we substitute\nsimple majority rule by weighted majority rule based on some weights correlated\nwith epistemic rationality such that every voter is guaranteed a minimal weight\nequal to one.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.00733v4"
    },
    {
        "title": "Regret theory under fear of the unknown",
        "authors": [
            "Fang Liu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  It is common to encounter the situation with uncertainty for decision makers\n(DMs) in dealing with a complex decision making problem. The existing evidence\nshows that people usually fear the extreme uncertainty named as the unknown.\nThis paper reports the modified version of the typical regret theory by\nconsidering the fear experienced by DMs for the unknown. Based on the responses\nof undergraduate students to the hypothetical choice problems with an unknown\noutcome, some experimental evidences are observed and analyzed. The framework\nof the modified regret theory is established by considering the effects of an\nunknown outcome. A fear function is equipped and some implications are proved.\nThe behavioral foundation of the modified regret theory is further developed by\nmodifying the axiomatic properties of the existing one as those based on the\nutility function; and it is recalled as the utility-based behavioral foundation\nfor convenience. The application to the medical decision making with an unknown\nrisk is studied and the effects of the fear function are investigated. The\nobservations reveal that the existence of an unknown outcome could enhance,\nimpede or reverse the preference relation of people in a choice problem, which\ncan be predicted by the developed regret theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.01825v1"
    },
    {
        "title": "Empirical Welfare Economics",
        "authors": [
            "Christopher P Chambers",
            "Federico Echenique"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Welfare economics relies on access to agents' utility functions: we revisit\nclassical questions in welfare economics, assuming access to data on agents'\npast choices instead of their utilities. Our main result considers the\nexistence of utilities that render a given allocation Pareto optimal. We show\nthat a candidate allocation is efficient for some utilities consistent with the\nchoice data if and only if it is efficient for an incomplete relation derived\nfrom the revealed preference relations and convexity. Similar ideas are used to\nmake counterfactual choices for a single consumer, policy comparisons by the\nKaldor criterion, and offer bounds on the degree of inefficiency in a Pareto\nsuboptimal allocation.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.03277v5"
    },
    {
        "title": "A characterization of lexicographic preferences",
        "authors": [
            "Mridu Prabal Goswami",
            "Manipushpak Mitra",
            "Debapriya Sen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper characterizes lexicographic preferences over alternatives that are\nidentified by a finite number of attributes. Our characterization is based on\ntwo key concepts: a weaker notion of continuity called 'mild continuity'\n(strict preference order between any two alternatives that are different with\nrespect to every attribute is preserved around their small neighborhoods) and\nan 'unhappy set' (any alternative outside such a set is preferred to all\nalternatives inside). Three key aspects of our characterization are: (i) use of\ncontinuity arguments, (ii) the stepwise approach of looking at two attributes\nat a time and (iii) in contrast with the previous literature, we do not impose\nnoncompensation on the preference and consider an alternative weaker condition.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.03280v1"
    },
    {
        "title": "Stable and extremely unequal",
        "authors": [
            "Alfred Galichon",
            "Octavia Ghelfi",
            "Marc Henry"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We highlight the tension between stability and equality in non transferable\nutility matching. We consider many to one matchings and refer to the two sides\nof the market as students and schools. The latter have aligned preferences,\nwhich in this context means that a school's utility is the sum of its students'\nutilities. We show that the unique stable allocation displays extreme\ninequality between matched pairs.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.06587v2"
    },
    {
        "title": "Strategic Exploration for Innovation",
        "authors": [
            "Shangen Li"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper introduces a framework to study innovation in a strategic setting,\nin which innovators allocate their resources between exploration and\nexploitation in continuous time. Exploration creates public knowledge, while\nexploitation delivers private benefits. Through the analysis of a class of\nMarkov equilibria, we demonstrate that knowledge spillovers accelerate\nknowledge creation and expedite its availability, thereby encouraging\ninnovators to increase exploration. The prospect of the ensuing superior\nlong-term innovations further motivates exploration, giving rise to a positive\nfeedback loop. This novel feedback loop can substantially mitigate the\nfree-riding problem arising from knowledge spillovers.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.07218v3"
    },
    {
        "title": "Choice by Rejection",
        "authors": [
            "Bhavook Bhardwaj",
            "Kriti Manocha"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose a boundedly rational model of choice where agents eliminate\ndominated alternatives using a transitive rationale before making a choice\nusing a complete rationale. This model is related to the seminal two-stage\nmodel of Manzini and Mariotti (2007), the Rational Shortlist Method (RSM). We\nanalyze the model through reversals in choice and provide its behavioral\ncharacterization. The procedure satisfies a weaker version of the Weak Axiom of\nRevealed Preference (WARP) allowing for at most two reversals in choice in\nterms of set inclusion for any pair of alternatives. We show that the\nunderlying rationales can be identified from the observable reversals in the\nchoice. We also characterize a variant of this model in which both the\nrationales are transitive\n",
        "pdf_link": "http://arxiv.org/pdf/2108.07424v1"
    },
    {
        "title": "A Partial Order on Preference Profiles",
        "authors": [
            "Wayne Yuan Gao"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose a theoretical framework under which preference profiles can be\nmeaningfully compared. Specifically, given a finite set of feasible allocations\nand a preference profile, we first define a ranking vector of an allocation as\nthe vector of all individuals' rankings of this allocation. We then define a\npartial order on preference profiles and write \"$P \\geq P^{'}$\", if there\nexists an onto mapping $\\psi$ from the Pareto frontier of $P^{'}$ onto the\nPareto frontier of $P$, such that the ranking vector of any Pareto efficient\nallocation $x$ under $P^{'}$ is weakly dominated by the ranking vector of the\nimage allocation $\\psi(x)$ under $P$. We provide a characterization of the\nmaximal and minimal elements under the partial order. In particular, we\nillustrate how an individualistic form of social preferences can be maximal in\na specific setting. We also discuss how the framework can be further\ngeneralized to incorporate additional economic ingredients.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.08465v2"
    },
    {
        "title": "Ex-post implementation with interdependent values",
        "authors": [
            "Saurav Goyal",
            "Aroon Narayanan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We characterize ex-post implementable allocation rules for single object\nauctions under quasi-linear preferences with convex interdependent value\nfunctions. We show that requiring ex-post implementability is equivalent to\nrequiring that the allocation rule must satisfy a condition that we call\neventual monotonicity (EM), which is a weakening of monotonicity, a familiar\ncondition used to characterize dominant strategy implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.09580v1"
    },
    {
        "title": "Fritz John's equation in mechanism design",
        "authors": [
            "Alfred Galichon"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We show the role that an important equation first studied by Fritz John plays\nin mechanism design.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.10538v1"
    },
    {
        "title": "Single-peaked domains with designer uncertainty",
        "authors": [
            "Aroon Narayanan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies single-peaked domains where the designer is uncertain\nabout the underlying alignment according to which the domain is single-peaked.\nThe underlying alignment is common knowledge amongst agents, but preferences\nare private knowledge. Thus, the state of the world has both a public and\nprivate element, with the designer uninformed of both. I first posit a relevant\nsolution concept called implementation in mixed information equilibria, which\nrequires Nash implementation in the public information and dominant strategy\nimplementation in the private information given the public information. I then\nidentify necessary and sufficient conditions for social rules to be\nimplementable. The characterization is used to identify unanimous and anonymous\nimplementable social rules for various belief structures of the designer, which\nbasically boils down to picking the right rules from the large class of median\nrules identified by Moulin (1980), and hence this result can be seen as\nidentifying which median rules are robust to designer uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.11268v1"
    },
    {
        "title": "Who Cares More? Allocation with Diverse Preference Intensities",
        "authors": [
            "Pietro Ortoleva",
            "Evgenii Safonov",
            "Leeat Yariv"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Goods and services -- public housing, medical appointments, schools -- are\noften allocated to individuals who rank them similarly but differ in their\npreference intensities. We characterize optimal allocation rules when\nindividual preferences are known and when they are not. Several insights\nemerge. First-best allocations may involve assigning some agents \"lotteries\"\nbetween high- and low-ranked goods. When preference intensities are private\ninformation, second-best allocations always involve such lotteries and,\ncrucially, may coincide with first-best allocations. Furthermore, second-best\nallocations may entail disposal of services. We discuss a market-based\nalternative and show how it differs.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12025v1"
    },
    {
        "title": "An economic decision-making model of anticipated surprise with dynamic\n  expectation",
        "authors": [
            "Ho Ka Chan",
            "Taro Toyoizumi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  When making decisions under risk, people often exhibit behaviors that\nclassical economic theories cannot explain. Newer models that attempt to\naccount for these irrational behaviors often lack neuroscience bases and\nrequire the introduction of subjective and problem-specific constructs. Here,\nwe present a decision-making model inspired by the prediction error signals and\nintrospective neuronal replay reported in the brain. In the model, decisions\nare chosen based on anticipated surprise, defined by a nonlinear average of the\ndifferences between individual outcomes and a reference point. The reference\npoint is determined by the expected value of the possible outcomes, which can\ndynamically change during the mental simulation of decision-making problems\ninvolving sequential stages. Our model elucidates the contribution of each\nstage to the appeal of available options in a decision-making problem. This\nallows us to explain several economic paradoxes and gambling behaviors. Our\nwork could help bridge the gap between decision-making theories in economics\nand neurosciences.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12347v2"
    },
    {
        "title": "Unidirectional substitutes and complements",
        "authors": [
            "Chao Huang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In discrete matching markets, substitutes and complements can be\nunidirectional between two groups of workers when members of one group are more\nimportant or competent than those of the other group for firms. We show that a\nstable matching exists and can be found by a two-stage Deferred Acceptance\nmechanism when firms' preferences satisfy a unidirectional substitutes and\ncomplements condition. This result applies to both firm-worker matching and\ncontrolled school choice. Under the framework of matching with continuous\nmonetary transfers and quasi-linear utilities, we show that substitutes and\ncomplements are bidirectional for a pair of workers.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12572v1"
    },
    {
        "title": "Fuzzy Conventions",
        "authors": [
            "Marcin Pęski"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study binary coordination games with random utility played in networks. A\ntypical equilibrium is fuzzy -- it has positive fractions of agents playing\neach action. The set of average behaviors that may arise in an equilibrium\ntypically depends on the network. The largest set (in the set inclusion sense)\nis achieved by a network that consists of a large number of copies of a large\ncomplete graph. The smallest set (in the set inclusion sense) is achieved on a\nlattice-type network. It consists of a single outcome that corresponds to a\nnovel version of risk dominance that is appropriate for games with random\nutility.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.13474v1"
    },
    {
        "title": "The Game Theory of Fake News",
        "authors": [
            "Alexander J. Stewart",
            "Antonio A. Arechar",
            "David G. Rand",
            "Joshua B. Plotkin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A great deal of empirical research has examined who falls for misinformation\nand why. Here, we introduce a formal game-theoretic model of engagement with\nnews stories that captures the strategic interplay between (mis)information\nconsumers and producers. A key insight from the model is that observed patterns\nof engagement do not necessarily reflect the preferences of consumers. This is\nbecause producers seeking to promote misinformation can use strategies that\nlead moderately inattentive readers to engage more with false stories than true\nones -- even when readers prefer more accurate over less accurate information.\nWe then empirically test people's preferences for accuracy in the news. In\nthree studies, we find that people strongly prefer to click and share news they\nperceive as more accurate -- both in a general population sample, and in a\nsample of users recruited through Twitter who had actually shared links to\nmisinformation sites online. Despite this preference for accurate news -- and\nconsistent with the predictions of our model -- we find markedly different\nengagement patterns for articles from misinformation versus mainstream news\nsites. Using 1,000 headlines from 20 misinformation and 20 mainstream news\nsites, we compare Facebook engagement data with 20,000 accuracy ratings\ncollected in a survey experiment. Engagement with a headline is negatively\ncorrelated with perceived accuracy for misinformation sites, but positively\ncorrelated with perceived accuracy for mainstream sites. Taken together, these\ntheoretical and empirical results suggest that consumer preferences cannot be\nstraightforwardly inferred from empirical patterns of engagement.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.13687v6"
    },
    {
        "title": "Risk measures induced by efficient insurance contracts",
        "authors": [
            "Qiuqi Wang",
            "Ruodu Wang",
            "Ricardas Zitikis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The Expected Shortfall (ES) is one of the most important regulatory risk\nmeasures in finance, insurance, and statistics, which has recently been\ncharacterized via sets of axioms from perspectives of portfolio risk management\nand statistics. Meanwhile, there is large literature on insurance design with\nES as an objective or a constraint. A visible gap is to justify the special\nrole of ES in insurance and actuarial science. To fill this gap, we study\ncharacterization of risk measures induced by efficient insurance contracts,\ni.e., those that are Pareto optimal for the insured and the insurer. One of our\nmajor results is that we characterize a mixture of the mean and ES as the risk\nmeasure of the insured and the insurer, when contracts with deductibles are\nefficient. Characterization results of other risk measures, including the mean\nand distortion risk measures, are also presented by linking them to different\nsets of contracts.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.00314v2"
    },
    {
        "title": "Costly Multidimensional Screening",
        "authors": [
            "Frank Yang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A screening instrument is costly if it is socially wasteful and productive\notherwise. A principal screens an agent with multidimensional private\ninformation and quasilinear preferences that are additively separable across\ntwo components: a one-dimensional productive component and a multidimensional\ncostly component. Can the principal improve upon simple one-dimensional\nmechanisms by also using the costly instruments? We show that if the agent has\npreferences between the two components that are positively correlated in a\nsuitably defined sense, then simply screening the productive component is\noptimal. The result holds for general type and allocation spaces, and allows\nfor nonlinear and interdependent valuations. We discuss applications to\nmultiproduct pricing (including bundling, quality discrimination, and upgrade\npricing), intertemporal price discrimination, and labor market screening.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.00487v3"
    },
    {
        "title": "Deliberative Democracy with Dilutive Voting Power Sharing",
        "authors": [
            "Dimitrios Karoukis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present a deliberation model where a group of individuals with\nheterogeneous preferences iteratively forms expert committees whose members are\ntasked with the updating of an exogenously given status quo change proposal.\nEvery individual holds some initial voting power that is represented by a\nfinite amount of indivisible units with some underlying value. Iterations\nhappen in three stages. In the first stage, everyone decides which units to\nkeep for themselves and where to distribute the rest. With every ownership\nmutation, a unit's underlying value diminishes by some exogenously given\namount. In the second stage, the deliberative committee is formed by the\nindividuals with the most accumulated voting power. These experts can author\ncorrections to the proposal which are proportional to their accumulated power.\nIn the third stage, if an individual outside of the committee disagrees with a\ncorrection, she can vote against it with their remaining voting power. A\ncorrection is discarded if more than half of the total voting power outside of\nthe committee is against it. If either the committee or the proposal remain\nunchanged for two consecutive iterations, the process stops. We show that this\nwill happen in finite time.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.01436v2"
    },
    {
        "title": "Infinite utility: counterparts and ultimate locations",
        "authors": [
            "Adam Jonsson"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The locations problem in infinite ethics concerns the relative moral status\nof different categories of potential bearers of value, the primary examples of\nwhich are people and points in time. The challenge is to determine which\ncategory of value bearers are of ultimate moral significance: the ultimate\nlocations, for short. This paper defends the view that the ultimate locations\nare 'people at times'. A person at a time is not a specific person, but the\nperson born at a specific point in time (de dicto). The main conclusion of the\npaper is that the unsettling implications of the time- and person-centered\napproaches to infinite ethics can be avoided. Most notably, a broad class of\nworlds that person-centered views deem incomparable can be strictly ranked.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.01852v2"
    },
    {
        "title": "Incentives for Collective Innovation",
        "authors": [
            "Gregorio Curello"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Agents exert hidden effort to produce randomly-sized innovations in a\ntechnology they share. Returns from using the technology grow as it develops,\nbut so does the opportunity cost of effort, due to an\n'exploration-exploitation' trade-off. As monitoring is imperfect, there exists\na unique (strongly) symmetric equilibrium, and effort in any equilibrium ceases\nno later than in the single-agent problem. Small innovations may hurt all\nagents in the symmetric equilibrium, as they severely reduce effort. Allowing\nagents to discard innovations increases effort and payoffs, preserving\nuniqueness. Under natural conditions, payoffs rise above those of all\nequilibria with forced disclosure.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.01885v7"
    },
    {
        "title": "Extended Relative Maximum Likelihood Updating of Choquet Beliefs",
        "authors": [
            "Xiaoyu Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Cheng(2021) proposes and characterizes Relative Maximum Likelihood (RML)\nupdating rule when the ambiguous beliefs are represented by a set of priors.\nRelatedly, this note proposes and characterizes Extended RML updating rule when\nthe ambiguous beliefs are represented by a convex capacity. Two classical\nupdating rules for convex capacities, Dempster-Shafer (Shafer, 1976) and\nFagin-Halpern rules (Fagin and Halpern, 1990) are included as special cases of\nExtended RML.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.02597v1"
    },
    {
        "title": "Monotone Equilibrium in Matching Markets with Signaling",
        "authors": [
            "Seungjin Han",
            "Alex Sam",
            "Youngki Shin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We introduce a notion of competitive signaling equilibrium (CSE) in\none-to-one matching markets with a continuum of heterogeneous senders and\nreceivers. We then study monotone CSE where equilibrium outcomes - sender\nactions, receiver reactions, beliefs, and matching - are all monotone in the\nstronger set order. We show that if the sender utility is monotone-supermodular\nand the receiver's utility is weakly monotone-supermodular, a CSE is stronger\nmonotone if and only if it passes Criterion D1 (Cho and Kreps (1987), Banks and\nSobel (1987)). Given any interval of feasible reactions that receivers can\ntake, we fully characterize a unique stronger monotone CSE and establishes its\nexistence with quasilinear utility functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.03370v5"
    },
    {
        "title": "Fair Compensation",
        "authors": [
            "John E. Stovall"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We introduce a novel framework that considers how a firm could fairly\ncompensate its workers. A firm has a group of workers, each of whom has varying\nproductivities over a set of tasks. After assigning workers to tasks, the firm\nmust then decide how to distribute its output to the workers. We first consider\nthree compensation rules and various fairness properties they may satisfy. We\nshow that among efficient and symmetric rules: the Egalitarian rule is the only\nrule that does not decrease a worker's compensation when every worker becomes\nweakly more productive (Group Productivity Monotonicity); the Shapley Value\nrule is the only rule that, for any two workers, equalizes the impact one\nworker has on the other worker's compensation (Balanced Impact); and the\nIndividual Contribution rule is the only rule that is invariant to the removal\nof workers and their assigned tasks (Consistency). We introduce other rules and\naxioms, and relate each rule to each axiom.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.04583v3"
    },
    {
        "title": "On the meaning of the Critical Cost Efficiency Index",
        "authors": [
            "Federico Echenique"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This note provides a critical discussion of the \\textit{Critical\nCost-Efficiency Index} (CCEI) as used to assess deviations from\nutility-maximizing behavior. I argue that the CCEI is hard to interpret, and\nthat it can disagree with other plausible measures of \"irrational\" behavior.\nThe common interpretation of CCEI as wasted income is questionable. Moreover, I\nshow that one agent may have more unstable preferences than another, but seem\nmore rational according to the CCEI. This calls into question the (now common)\nuse of CCEI as an ordinal and cardinal measure of degrees of rationality.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.06354v4"
    },
    {
        "title": "The Empirical Content of Bayesianism",
        "authors": [
            "Pooya Molavi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper characterizes the conditions under which the observed beliefs of a\ngroup of agents are consistent with Bayesian updating. Beliefs are consistent\nwith Bayesianism if they arise from the application of Bayes' rule given some\nsubjective distribution for the state and the signals agents observe between\nperiods. The paper's main finding is that beliefs are consistent with\nBayesianism if and only if the mean of the distribution of posteriors is\nuniformly absolutely continuous with respect to the prior. Furthermore, the\npaper shows that the existing results on the empirical content of Bayesianism\nrely on additional restrictions on permissible subjective distributions, such\nas the requirement that agents have correct beliefs about the distribution of\nsignals.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.07007v4"
    },
    {
        "title": "Endogenous Growth Under Multiple Uses of Data",
        "authors": [
            "Lin William Cong",
            "Wenshi Wei",
            "Danxia Xie",
            "Longtian Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We model a dynamic data economy with fully endogenous growth where agents\ngenerate data from consumption and share them with innovation and production\nfirms. Different from other productive factors such as labor or capital, data\nare nonrival in their uses across sectors which affect both the level and\ngrowth of economic outputs. Despite the vertical nonrivalry, the innovation\nsector dominates the production sector in data usage and contribution to growth\nbecause (i) data are dynamically nonrival and add to knowledge accumulation,\nand (ii) innovations \"desensitize\" raw data and enter production as knowledge,\nwhich allays consumers' privacy concerns. Data uses in both sectors interact to\ngenerate spillover of allocative distortion and exhibit an apparent\nsubstitutability due to labor's rivalry and complementarity with data.\nConsequently, growth rates under a social planner and a decentralized\nequilibrium differ, which is novel in the literature and has policy\nimplications. Specifically, consumers' failure to fully internalize knowledge\nspillover when bearing privacy costs, combined with firms' market power,\nunderprice data and inefficiently limit their supply, leading to\nunderemployment in the innovation sector and a suboptimal long-run growth.\nImproving data usage efficiency is ineffective in mitigating the\nunderutilization of data, but interventions in the data market and direct\nsubsidies hold promises.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.10027v1"
    },
    {
        "title": "Knowledge Accumulation, Privacy, and Growth in a Data Economy",
        "authors": [
            "Lin William Cong",
            "Danxia Xie",
            "Longtian Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We build an endogenous growth model with consumer-generated data as a new key\nfactor for knowledge accumulation. Consumers balance between providing data for\nprofit and potential privacy infringement. Intermediate good producers use data\nto innovate and contribute to the final good production, which fuels economic\ngrowth. Data are dynamically nonrival with flexible ownership while their\nproduction is endogenous and policy-dependent. Although a decentralized economy\ncan grow at the same rate (but are at different levels) as the social optimum\non the Balanced Growth Path, the R&D sector underemploys labor and overuses\ndata -- an inefficiency mitigated by subsidizing innovators instead of direct\ndata regulation. As a data economy emerges and matures, consumers' data\nprovision endogenously declines after a transitional acceleration, allaying\nlong-run privacy concerns but portending initial growth traps that call for\ninterventions.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.10028v1"
    },
    {
        "title": "Persuasion with Ambiguous Receiver Preferences",
        "authors": [
            "Eitan Sapiro-Gheiler"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I describe a Bayesian persuasion problem where Receiver has a private type\nrepresenting a cutoff for choosing Sender's preferred action, and Sender has\nmaxmin preferences over all Receiver type distributions with known mean and\nbounds. This problem can be represented as a zero-sum game where Sender chooses\na distribution of posterior mean beliefs that is a mean-preserving contraction\nof the prior over states, and an adversarial Nature chooses a Receiver type\ndistribution with the known mean; the player with the higher realization from\ntheir chosen distribution wins. I formalize the connection between maxmin\npersuasion and similar games used to model political spending, all-pay\nauctions, and competitive persuasion. In both a standard binary-state setting\nand a new continuous-state setting, Sender optimally linearizes the prior\ndistribution over states to create a distribution of posterior means that is\nuniform on a known interval with an atom at the lower bound of its support.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.11536v5"
    },
    {
        "title": "Robust Equilibria in General Competing Mechanism Games",
        "authors": [
            "Seungjin Han"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper proposes the notion of robust PBE in a general competing mechanism\ngame of incomplete information where a mechanism allows its designer to send a\nmessage to himself at the same time agents send messages. It identifies the\nutility environments where the notion of robust PBE coincides with that of\nstrongly robust PBE (Epstein and Peters (1999), Han (2007)) and with that of\nrobust PBE respectively. If each agent's utility function is additively\nseparable with respect to principals' actions, it is possible to provide the\nfull characterization of equilibrium allocations under the notion of robust PBE\nand its variations, in terms of Bayesian incentive compatible (BIC) direct\nmechanisms, without reference to the set of arbitrary general mechanisms\nallowed in the game. However, in the standard competing mechanism agme, the\nadoption of robust PBE as the solution concept does not lead to the full\ncharacterization of equilibrium allocations in terms of BIC direct mechanisms\neven with agents' separable utility functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.13177v3"
    },
    {
        "title": "New Solution based on Hodge Decomposition for Abstract Games",
        "authors": [
            "Yihao Luo",
            "Jinhui Pang",
            "Weibin Han",
            "Huafei Sun"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper proposes Hodge Potential Choice (HPC), a new solution for abstract\ngames with irreflexive dominance relations. This solution is formulated by\ninvolving geometric tools like differential forms and Hodge decomposition onto\nabstract games. We provide a workable algorithm for the proposed solution with\na new data structure of abstract games. From the view of gaming, HPC overcomes\nseveral weaknesses of conventional solutions. HPC coincides with Copeland\nChoice in complete cases and can be extended to slove games with marginal\nstrengths. It will be proven that the Hodge potential choice possesses three\nprevalent axiomatic properties: neutrality, strong monotonicity, dominance\ncycle s reversing independence, and sensitivity to mutual dominance. To compare\nthe HPC with Copeland Choice in large samples of games, we design digital\nexperiments with randomly generated abstract games with different sizes and\ncompleteness. The experimental results present the advantage of HPC in the\nstatistical sense.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14539v5"
    },
    {
        "title": "The Limits of Personalization in Assortment Optimization",
        "authors": [
            "Guillermo Gallego",
            "Gerardo Berbeglia"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  To study the limits of personalization, we introduce the notion of a\nclairvoyant firm that can read the mind of consumers and sell them the highest\nrevenue product that they are willing to buy. We show how to compute the\nexpected revenue of the clairvoyant firm for a class of rational discrete\nchoice models, and develop prophet-type inequalities that provide performance\nguarantees for the expected revenue of the traditional assortment optimization\nfirm (a TAOP firm) relative to the clairvoyant firm, and therefore to any\neffort to personalize assortments. In particular, we show that the expected\nrevenue of the clairvoyant firm cannot exceed twice the expected revenue of the\nTAOP for the RCS model, the MNL, the GAM and the Nested Logit Model. On the\nother hand, there are random utility models for which personalized assortments\ncan earn up to $n$ times more than a TAOP firm, where $n$ is the number of\nproducts. Our numerical studies indicate that when the mean utilities of the\nproducts are heterogeneous among consumer types, and the variance of the\nutilities is small, firms can gain substantial benefits from personalized\nassortments. We support these observations, and others, with theoretical\nfindings. While the consumers surplus can potentially be larger under\npersonalized assortments, clairvoyant firms with pricing power can extract all\nsurplus, and earn arbitrarily more than traditional firms that optimize over\nprices but do not personalize them. For the price-aware MNL, however, a\nclairvoyant firm can earn at most $e$ times more than a traditional firm.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14861v5"
    },
    {
        "title": "Money Creation and Banking: Theory and Evidence",
        "authors": [
            "Heon Lee"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the role of banks' money creation in monetary\ntransmission. I develop a monetary-search model where demand for the monetary\nbase and the money multiplier are endogenously determined through banks' money\ncreation. The model and data show that reserves are not independent of interest\nrate policy, even with ample reserves. Furthermore, short-term rates and\ninterest on reserves play distinct roles in monetary transmission. I evaluate\nthe theory by matching it with data, and the calibrated model can account for\nthe evolution of reserves, excess reserves, and the money multiplier\n",
        "pdf_link": "http://arxiv.org/pdf/2109.15096v2"
    },
    {
        "title": "Nonlinear Prices, Homogeneous Goods, Search",
        "authors": [
            "Atabek Atayev"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We analyze competition on nonlinear prices in homogeneous goods markets with\nconsumer search. In equilibrium firms offer two-part tariffs consisting of a\nlinear price and lump-sum fee. The equilibrium production is socially efficient\nas the linear price of equilibrium two-part tariffs equals to the production\nmarginal cost. Firms thus compete in lump-sum fees, which are dispersed in\nequilibrium. We show that sellers enjoy higher profit, whereas consumers are\nworse-off with two-part tariffs than with linear prices. The competition\nsoftens because with two-part tariffs firms can make effective per-consumer\ndemand less elastic than the actual demand.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.15198v1"
    },
    {
        "title": "Uncertain Product Availability in Search Markets",
        "authors": [
            "Atabek Atayev"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In many markets buyers are poorly informed about which firms sell the product\n(product availability) and prices, and therefore have to spend time to obtain\nthis information. In contrast, sellers typically have a better idea about which\nrivals offer the product. Information asymmetry between buyers and sellers on\nproduct availability, rather than just prices, has not been scrutinized in the\nliterature on consumer search. We propose a theoretical model that incorporates\nthis kind of information asymmetry into a simultaneous search model. Our key\nfinding is that greater product availability may harm buyers by mitigating\ntheir willingness to search and, thus, softening competition.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.15211v1"
    },
    {
        "title": "Information Acquisition and Diffusion in Markets",
        "authors": [
            "Atabek Atayev",
            "Maarten Janssen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Consumers can acquire information through their own search efforts or through\ntheir social network. Information diffusion via word-of-mouth communication\nleads to some consumers free-riding on their \"friends\" and less information\nacquisition via active search. Free-riding also has an important positive\neffect, however, in that consumers that do not actively search themselves are\nmore likely to be able to compare prices before purchase, imposing competitive\npressure on firms. We show how market prices depend on the characteristics of\nthe network and on search cost. For example, if the search cost becomes small,\nprice dispersion disappears, while the price level converges to the monopoly\nlevel, implying that expected prices are decreasing for small enough search\ncost. More connected societies have lower market prices, while price dispersion\nremains even in fully connected societies.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.15288v1"
    },
    {
        "title": "Truly Costly Search and Word-of-Mouth Communication",
        "authors": [
            "Atabek Atayev"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In markets with search frictions, consumers can acquire information about\ngoods either through costly search or from friends via word-of-mouth (WOM)\ncommunication. How do sellers' market power react to a very large increase in\nthe number of consumers' friends with whom they engage in WOM? The answer to\nthe question depends on whether consumers are freely endowed with price\ninformation. If acquiring price quotes is costly, equilibrium prices are\ndispersed and the expected price is higher than the marginal cost of\nproduction. This implies that firms retain market power even if price\ninformation is disseminated among a very large number of consumers due to\ntechnological progress, such as social networking websites.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00032v1"
    },
    {
        "title": "The emergence of cooperation from shared goals in the Systemic\n  Sustainability Game of common pool resources",
        "authors": [
            "Chengyi Tu",
            "Paolo DOdorico",
            "Zhe Li",
            "Samir Suweis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The sustainable use of common-pool resources (CPRs) is a major environmental\ngovernance challenge because of their possible over-exploitation. Research in\nthis field has overlooked the feedback between user decisions and resource\ndynamics. Here we develop an online game to perform a set of experiments in\nwhich users of the same CPR decide on their individual harvesting rates, which\nin turn depend on the resource dynamics. We show that, if users share common\ngoals, a high level of self-organized cooperation emerges, leading to long-term\nresource sustainability. Otherwise, selfish/individualistic behaviors lead to\nresource depletion (\"Tragedy of the Commons\"). To explain these results, we\ndevelop an analytical model of coupled resource-decision dynamics based on\noptimal control theory and show how this framework reproduces the empirical\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00474v1"
    },
    {
        "title": "Moral Hazard with Heterogeneous Beliefs",
        "authors": [
            "Martin Dumav",
            "Urmee Khan",
            "Luca Rigotti"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study a model of moral hazard with heterogeneous beliefs where each of\nagent's actions gives rise to a pair of probability distributions over output\nlevels, one representing the beliefs of the agent and the other those of the\nprincipal. The agent's relative optimism or pessimism dictates whether the\ncontract is high-powered (i.e. with high variability between wage levels) or\nlow-powered. When the agent is sufficiently more optimistic than the principal,\nthe trade-off between risk-sharing and incentive provision may be eliminated.\nUsing Monotone Likelihood Ratio ranking to model disagreement in the parties'\nbeliefs, we show that incentives move in the direction of increasing\ndisagreement. In general, the shape of the wage scheme is sensitive to the\ndifferences in beliefs. Thereby, key features of optimal incentive contracts\nunder common beliefs do not readily generalize to the case of belief\nheterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.04368v1"
    },
    {
        "title": "Motivating Effort with Information about Future Rewards",
        "authors": [
            "Chang Liu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the optimal mechanism to motivate effort in a dynamic\nprincipal-agent model without transfers. An agent is engaged in a task with\nuncertain future rewards and can shirk irreversibly at any time. The principal\nknows the reward of the task and provides information to the agent over time in\norder to motivate effort. We derive the optimal information policy in closed\nform and thus identify two conditions, each of which guarantees that delayed\ndisclosure is valuable. First, if the principal is impatient compared to the\nagent, she prefers the front-loaded effort schedule induced by delayed\ndisclosure. In a stationary environment, delayed disclosure is beneficial if\nand only if the principal is less patient than the agent. Second, if the\nenvironment makes the agent become pessimistic over time in absence of any\ninformation disclosure, then providing delayed news can counteract this\ndownward trend in the agent's belief and encourage the agent to work longer.\nNotably, the level of patience remains a crucial determinant of the optimal\npolicy structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.05643v3"
    },
    {
        "title": "Group network effects in price competition",
        "authors": [
            "Renato Soeiro",
            "Alberto Pinto"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The partition of society into groups, polarization, and social networks are\npart of most conversations today. How do they influence price competition? We\ndiscuss Bertrand duopoly equilibria with demand subject to network effects.\nContrary to models where network effects depend on one aggregate variable\n(demand for each choice), partitioning the dependence into groups creates a\nwealth of pure price equilibria with profit for both price setters, even if\npositive network effects are the dominant element of the game. If there is some\nasymmetry in how groups interact, two groups are sufficient. If network effects\nare based on undirected and unweighted graphs, at least five groups are\nrequired but, without other differentiation, outcomes are symmetric.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.05891v1"
    },
    {
        "title": "Maskin Meets Abreu and Matsushima",
        "authors": [
            "Yi-Chun Chen",
            "Takashi Kunimoto",
            "Yifei Sun",
            "Siyang Xiong"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The theory of full implementation has been criticized for using\ninteger/modulo games which admit no equilibrium (Jackson (1992)). To address\nthe critique, we revisit the classical Nash implementation problem due to\nMaskin (1999) but allow for the use of lotteries and monetary transfers as in\nAbreu and Matsushima (1992, 1994). We unify the two well-established but\nsomewhat orthogonal approaches in full implementation theory. We show that\nMaskin monotonicity is a necessary and sufficient condition for (exact)\nmixed-strategy Nash implementation by a finite mechanism. In contrast to\nprevious papers, our approach possesses the following features: finite\nmechanisms (with no integer or modulo game) are used; mixed strategies are\nhandled explicitly; neither undesirable outcomes nor transfers occur in\nequilibrium; the size of transfers can be made arbitrarily small; and our\nmechanism is robust to information perturbations. Finally, our result can be\nextended to infinite/continuous settings and ordinal settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.06551v3"
    },
    {
        "title": "Group Identity, Social Learning and Opinion Dynamics",
        "authors": [
            "Sebastiano Della Lena",
            "Luca Paolo Merlino"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper, we study opinion dynamics in a balanced social structure\nconsisting of two groups. Agents learn the true state of the world naively\nlearning from their neighbors and from an unbiased source of information.\nAgents want to agree with others of the same group--in-group identity -- but to\ndisagree with those of the opposite group--out-group conflict. We characterize\nthe long-run opinions, and show that agents' influence depends on their\nBonacich centrality in the signed network of opinion exchange. Finally, we\nstudy the effect of group size, the weight given to unbiased information and\nhomophily when agents in the same group are homogeneous.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.07226v2"
    },
    {
        "title": "Auction design with ambiguity: Optimality of the first-price and all-pay\n  auctions",
        "authors": [
            "Sosung Baik",
            "Sung-Ha Hwang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the optimal auction design problem when bidders' preferences follow\nthe maxmin expected utility model. We suppose that each bidder's set of priors\nconsists of beliefs close to the seller's belief, where \"closeness\" is defined\nby a divergence. For a given allocation rule, we identify a class of optimal\ntransfer candidates, named the win-lose dependent transfers, with the following\nproperty: each type of bidder's transfer conditional on winning or losing is\nindependent of the competitor's type report. Our result reduces the\ninfinite-dimensional optimal transfer problem to a two-dimensional optimization\nproblem. By solving the reduced problem, we find that: (i) among efficient\nmechanisms with no premiums for losers, the first-price auction is optimal;\nand, (ii) among efficient winner-favored mechanisms where each bidder pays\nsmaller amounts when she wins than loses: the all-pay auction is optimal. Under\na simplifying assumption, these two auctions remain optimal under the\nendogenous allocation rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08563v1"
    },
    {
        "title": "Optimally Targeting Interventions in Networks during a Pandemic: Theory\n  and Evidence from the Networks of Nursing Homes in the United States",
        "authors": [
            "Roland Pongou",
            "Guy Tchuente",
            "Jean-Baptiste Tondji"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This study develops an economic model for a social planner who prioritizes\nhealth over short-term wealth accumulation during a pandemic. Agents are\nconnected through a weighted undirected network of contacts, and the planner's\nobjective is to determine the policy that contains the spread of infection\nbelow a tolerable incidence level, and that maximizes the present discounted\nvalue of real income, in that order of priority. The optimal unique policy\ndepends both on the configuration of the contact network and the tolerable\ninfection incidence. Comparative statics analyses are conducted: (i) they\nreveal the tradeoff between the economic cost of the pandemic and the infection\nincidence allowed; and (ii) they suggest a correlation between different\nmeasures of network centrality and individual lockdown probability with the\ncorrelation increasing with the tolerable infection incidence level. Using\nunique data on the networks of nursing and long-term homes in the U.S., we\ncalibrate our model at the state level and estimate the tolerable COVID-19\ninfection incidence level. We find that laissez-faire (more tolerance to the\nvirus spread) pandemic policy is associated with an increased number of deaths\nin nursing homes and higher state GDP growth. In terms of the death count,\nlaissez-faire is more harmful to nursing homes than more peripheral in the\nnetworks, those located in deprived counties, and those who work for a profit.\nWe also find that U.S. states with a Republican governor have a higher level of\ntolerable incidence, but policies tend to converge with high death count.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.10230v1"
    },
    {
        "title": "Algebraic Properties of Blackwell's Order and A Cardinal Measure of\n  Informativeness",
        "authors": [
            "Andrew Kosenko"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I establish a translation invariance property of the Blackwell order over\nexperiments, show that garbling experiments bring them closer together, and use\nthese facts to define a cardinal measure of informativeness. Experiment $A$ is\ninf-norm more informative (INMI) than experiment $B$ if the infinity norm of\nthe difference between a perfectly informative structure and $A$ is less than\nthe corresponding difference for $B$. The better experiment is \"closer\" to the\nfully revealing experiment; distance from the identity matrix is interpreted as\na measure of informativeness. This measure coincides with Blackwell's order\nwhenever possible, is complete, order invariant, and prior-independent, making\nit an attractive and computationally simple extension of the Blackwell order to\neconomic contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.11399v1"
    },
    {
        "title": "Free Riding in Networks",
        "authors": [
            "Markus Kinateder",
            "Luca Paolo Merlino"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Players allocate their budget to links, a local public good and a private\ngood. A player links to free ride on others' public good provision. We derive\nsufficient conditions for the existence of a Nash equilibrium. In equilibrium,\nlarge contributors link to each other, while others link to them. Poorer\nplayers can be larger contributors if linking costs are sufficiently high. In\nlarge societies, free riding reduces inequality only in networks in which it is\ninitially low; otherwise, richer players benefit more, as they can afford more\nlinks. Finally, we study the policy implications, deriving income\nredistribution that increases welfare and personalized prices that implement\nthe efficient solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.11651v1"
    },
    {
        "title": "Cycles to compute the full set of many-to-many stable matchings",
        "authors": [
            "Agustin G. Bonifacio",
            "Noelia Juarez",
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In a many-to-many matching model in which agents' preferences satisfy\nsubstitutability and the law of aggregate demand, we present an algorithm to\ncompute the full set of stable matchings. This algorithm relies on the idea of\n\"cycles in preferences\" and generalizes the algorithm presented in Roth and\nSotomayor (1990) for the one-to-one model.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.11846v2"
    },
    {
        "title": "On the Behavioral Consequences of Reverse Causality",
        "authors": [
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Reverse causality is a common causal misperception that distorts the\nevaluation of private actions and public policies. This paper explores the\nimplications of this error when a decision maker acts on it and therefore\naffects the very statistical regularities from which he draws faulty\ninferences. Using a quadratic-normal parameterization and applying the\nBayesian-network approach of Spiegler (2016), I demonstrate the subtle\nequilibrium effects of a certain class of reverse-causality errors, with\nillustrations in diverse areas: development psychology, social policy, monetary\neconomics and IO. In particular, the decision context may protect the decision\nmaker from his own reverse-causality causal error. That is, the cost of\nreverse-causality errors can be lower for everyday decision makers than for an\noutside observer who evaluates their choices.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.12218v1"
    },
    {
        "title": "How To Sell (or Procure) in a Sequential Auction",
        "authors": [
            "Kenneth Hendricks",
            "Thomas Wiseman"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A seller with one unit of a good faces N\\geq3 buyers and a single competitor\nwho sells one other identical unit in a second-price auction with a reserve\nprice. Buyers who do not get the seller's good will compete in the competitor's\nsubsequent auction. We characterize the optimal mechanism for the seller in\nthis setting. The first-order approach typically fails, so we develop new\ntechniques. The optimal mechanism features transfers from buyers with the two\nhighest valuations, allocation to the buyer with the second-highest valuation,\nand a withholding rule that depends on the highest two or three valuations. It\ncan be implemented by a modified third-price auction or a pay-your-bid auction\nwith a rebate. This optimal withholding rule raises significantly more revenue\nthan would a standard reserve price. Our analysis also applies to procurement\nauctions. Our results have implications for sequential competition in\nmechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.13121v1"
    },
    {
        "title": "Buy It Now or Later, or Not: Loss Aversion in Advance Purchasing",
        "authors": [
            "Senran Lin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the advance-purchase game when a consumer has belief-based\nloss-averse preferences, introducing a novel perspective by incorporating\nreference updating. It demonstrates that loss aversion increases the consumer's\nwillingness to pre-purchase. Moreover, the paper endogenizes the seller's\nprice-commitment behavior in the advance-purchase problem. The analysis reveals\nthat the seller will commit to his spot price even with no obligation to do so,\na behavior previously assumed in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.14929v5"
    },
    {
        "title": "Choice and Market Design",
        "authors": [
            "Samson Alva",
            "Battal Doğan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A textbook chapter on modeling choice behavior and designing institutional\nchoice functions for matching and market design. The chapter is to appear in:\nOnline and Matching-Based Market Design. Federico Echenique, Nicole Immorlica\nand Vijay V. Vazirani, Editors. Cambridge University Press. 2021\n",
        "pdf_link": "http://arxiv.org/pdf/2110.15446v2"
    },
    {
        "title": "Surplus Extraction with Behavioral Types",
        "authors": [
            "Nicolas Pastrian"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We examine the surplus extraction problem in a mechanism design setting with\nbehavioral types. In our model behavioral types always perfectly reveal their\nprivate information. We characterize the sufficient conditions that guarantee\nfull extraction in a finite version of the reduced form environment of McAfee\nand Reny (1992). We found that the standard convex independence condition\nidentified in Cremer and McLean (1988) is required only among the beliefs of\nstrategic types, while a weaker condition is required for the beliefs of\nbehavioral types.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.00061v2"
    },
    {
        "title": "Fuzzy Arrovian Theorems when preferences are complete",
        "authors": [
            "Armajac Raventós-Pujol"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper we study the aggregation of fuzzy preferences on\nnon-necessarily finite societies. We characterize in terms of possibility and\nimpossibility a family of models of complete preferences in which the\ntransitivity is defined for any t-norm. For that purpose, we have described\neach model by means of some crisp binary relations and we have applied the\nresults obtained by Kirman and Sondermann.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.03010v1"
    },
    {
        "title": "Marriage through friends",
        "authors": [
            "Ugo Bolletta",
            "Luca Paolo Merlino"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper, we propose a model of the marriage market in which individuals\nmeet potential partners either directly or through their friends. When\nsocialization is exogenous, a higher arrival rate of direct meetings also\nimplies more meetings through friends. When individuals decide how much to\ninvest in socialization, meetings through friends are first increasing and then\ndecreasing in the arrival rate of direct offers. Hence, our model can\nrationalize the negative correlation between the advent of online dating and\nthe decrease of marriages through friends observed in the US over the past\ndecades.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.03825v2"
    },
    {
        "title": "Concavity and Convexity of Order Statistics in Sample Size",
        "authors": [
            "Mitchell Watt"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We show that the expectation of the $k^{\\mathrm{th}}$-order statistic of an\ni.i.d. sample of size $n$ from a monotone reverse hazard rate (MRHR)\ndistribution is convex in $n$ and that the expectation of the\n$(n-k+1)^{\\mathrm{th}}$-order statistic from a monotone hazard rate (MHR)\ndistribution is concave in $n$ for $n\\ge k$. We apply this result to the\nanalysis of independent private value auctions in which the auctioneer faces a\nconvex cost of attracting bidders. In this setting, MHR valuation distributions\nlead to concavity of the auctioneer's objective. We extend this analysis to\nauctions with reserve values, in which concavity is assured for sufficiently\nsmall reserves or for a sufficiently large number of bidders.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.04702v3"
    },
    {
        "title": "Long Run Law and Entropy",
        "authors": [
            "Weidong Tian"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper demonstrates the additive and multiplicative version of a long-run\nlaw of unexpected shocks for any economic variable. We derive these long-run\nlaws by the martingale theory without relying on the stationary and ergodic\nconditions. We apply these long-run laws to asset return, risk-adjusted asset\nreturn, and the pricing kernel process and derive new asset pricing\nimplications. Moreover, we introduce several dynamic long-term measures on the\npricing kernel process, which relies on the sample data of asset return.\nFinally, we use these long-term measures to diagnose leading asset pricing\nmodels.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.06238v1"
    },
    {
        "title": "Non-Standard Choice in Matching Markets",
        "authors": [
            "Gian Caspari",
            "Manshu Khanna"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We explore the possibility of designing matching mechanisms that can\naccommodate non-standard choice behavior. We pin down the necessary and\nsufficient conditions on participants' choice behavior for the existence of\nstable and incentive compatible mechanisms. Our results imply that\nwell-functioning matching markets can be designed to adequately accommodate a\nplethora of choice behaviors, including the standard behavior consistent with\npreference maximization. To illustrate the significance of our results in\npractice, we show that a simple modification in a commonly used matching\nmechanism enables it to accommodate non-standard choice behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.06815v2"
    },
    {
        "title": "On Risk and Time Pressure: When to Think and When to Do",
        "authors": [
            "Christoph Carnehl",
            "Johannes Schneider"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the tradeoff between fundamental risk and time. A time-constrained\nagent has to solve a problem. She dynamically allocates effort between\nimplementing a risky initial idea and exploring alternatives. Discovering an\nalternative implies progress that has to be converted to a solution. As time\nruns out, the chances of converting it in time shrink. We show that the agent\nmay return to the initial idea after having left it in the past to explore\nalternatives. Our model helps explain so-called false starts. To finish fast,\nthe agent delays exploring alternatives reducing the overall success\nprobability.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.07451v2"
    },
    {
        "title": "Obstacles to Redistribution Through Markets and One Solution",
        "authors": [
            "Roy Allen",
            "John Rehbeck"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Dworczak et al. (2021) study when certain market structures are optimal in\nthe presence of heterogeneous preferences. A key assumption is that the social\nplanner knows the joint distribution of the value of the good and marginal\nvalue of money. This paper studies whether relevant features of this\ndistribution are identified from choice data. We show that the features of the\ndistribution needed to characterize optimal market structure cannot be\nidentified when demand is known for all prices. While this is a negative\nresult, we show that the distribution of good value and marginal utility of\nmoney is fully identified when there is an observed measure of quality that\nvaries. Thus, while Dworczak et al. (2021) abstract from quality, we show how\nincluding quality is crucial for potential applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09910v1"
    },
    {
        "title": "Whose Bias?",
        "authors": [
            "Vasudha Jain",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Law enforcement acquires costly evidence with the aim of securing the\nconviction of a defendant, who is convicted if a decision-maker's belief\nexceeds a certain threshold. Either law enforcement or the decision-maker is\nbiased and is initially overconfident that the defendant is guilty. Although an\ninnocent defendant always prefers an unbiased decision-maker, he may prefer\nthat law enforcement have some bias to none. Nevertheless, fixing the level of\nbias, an innocent defendant may prefer that the decision-maker, not law\nenforcement, is biased.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.10335v1"
    },
    {
        "title": "Affirmative Action's Cumulative Fractional Assignments",
        "authors": [
            "Haydar Evren",
            "Manshu Khanna"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The Central Educational Institutions (Reservation in Teachers' Cadre) Act,\n2019 provides for reserving teaching vacancies in India's central educational\ninstitutions for beneficiaries of its affirmative action policy. Reservation of\nteaching vacancies had been a contentious issue, and the act was introduced to\nresolve it after the Supreme Court's solution was met with protests from the\nTeachers' Union. Our paper demonstrates an impossibility result in the Supreme\nCourt's solution and the act, which are flawed in reserving seats\nsimultaneously at both the university and within its departments. To overcome\nthis impossibility, we propose an alternative solution based on approximate\nimplementation of fractional assignments, offering a promising middle-ground\nbetween the two disputed solutions practiced in India. This novel application\ndemonstrates the practical relevance of the approximate implementation approach\n(Akbarpourand Nikzad(2020)) beyond the constraint structures examined in the\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.11963v2"
    },
    {
        "title": "Coexistence of Centralized and Decentralized Markets",
        "authors": [
            "Berk Idem"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper, I introduce a profit-maximizing centralized marketplace into a\ndecentralized market with search frictions. Agents choose between the\ncentralized marketplace and the decentralized bilateral trade. I characterize\nthe optimal marketplace in this market choice game using a mechanism design\napproach. In the unique equilibrium, the centralized marketplace and the\ndecentralized trade coexist. The profit of the marketplace decreases as the\nsearch frictions in the decentralized market are reduced. However, it is always\nhigher than the half of the profit when the frictions are prohibitively high\nfor decentralized trade. I also show that the ratio of the reduction in the\nprofit depends only on the degree of search frictions and not on the\ndistribution of valuations. The thickness of the centralized marketplace does\nnot depend on the search frictions. I derive conditions under which, this\nequilibrium results in higher welfare than either institution on its own.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.12767v1"
    },
    {
        "title": "Markovian Persuasion",
        "authors": [
            "Ehud Lehrer",
            "Dimitry Shaiderman"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In the classical Bayesian persuasion model an informed player and an\nuninformed one engage in a static interaction. The informed player, the sender,\nknows the state of nature, while the uninformed one, the receiver, does not.\nThe informed player partially shares his private information with the receiver\nand the latter then, based on her belief about the state, takes an action. This\naction determines, together with the state of nature, the utility of both\nplayers. We consider a dynamic Bayesian persuasion situation where the state of\nnature evolves according to a Markovian law. In this repeated persuasion model\nan optimal disclosure strategy of the sender should, at any period, balance\nbetween getting high stage payoff and future implications on the receivers'\nbeliefs. We discuss optimal strategies under different discount factors and\ncharacterize when the asymptotic value achieves the maximal value possible.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.14365v1"
    },
    {
        "title": "Eliciting and Distinguishing Between Weak and Incomplete Preferences:\n  Theory, Experiment and Computation",
        "authors": [
            "Georgios Gerasimou"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Recovering and distinguishing between the strict-preference, indifference\nand/or indecisiveness parts of a decision maker's preferences is a challenging\ntask but also important for testing theory and conducting welfare analysis.\nThis paper contributes towards this goal by reporting on data from a lab\nexperiment on riskless choice that were analyzed with novel theory-guided\ncomputational methods. The experiment included both Forced- and Free-Choice\ntreatments. Its primary novelty consisted of allowing all subjects to select\nmultiple alternatives at each menu. Based on a non-parametric goodness-of-fit\ncriterion that we introduce, which generalizes intuitively a widely used\npre-existing method to environments of multi-valued choices, each subjects'\ndecision data were tested against three structured general-choice models that\nfeature maximization of stable but potentially weak and/or incomplete\npreferences. Nearly 60% of all subjects' are well-explained by one of these\nmodels, typically with a unique model-optimal preference relation per subject.\nImportantly, preferences usually (80%) had a non-trivial indifference part and,\nwhere applicable, a clearly distinct indecisiveness part. The achieved\nuncoupling of revealed indifference and indecisiveness is documented\nempirically for the first time.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.14431v5"
    },
    {
        "title": "A Response to Economics as Gauge Theory",
        "authors": [
            "Timothy Nguyen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We provide an analysis of the recent work by Malaney-Weinstein on \"Economics\nas Gauge Theory\" presented on November 10, 2021 at the Money and Banking\nWorkshop hosted by University of Chicago. In particular, we distill the\ntechnical mathematics used in their work into a form more suitable to a wider\naudience. Furthermore, we resolve the conjectures posed by Malaney-Weinstein,\nrevealing that they provide no discernible value for the calculation of index\nnumbers or rates of inflation. Our conclusion is that the main contribution of\nthe Malaney-Weinstein work is that it provides a striking example of how to\nobscure simple concepts through an uneconomical use of gauge theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.03460v2"
    },
    {
        "title": "A collective blueprint, not a crystal ball: How expectations and\n  participation shape long-term energy scenarios",
        "authors": [
            "Leonard Göke",
            "Jens Weibezahn",
            "Christian von Hirschhausen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The development of energy systems is not a technocratic process but equally\nshaped by societal and cultural forces. Key instruments in this process are\nmodel-based scenarios describing a future energy system. Applying the concept\nof fictional expectations from social economics, we show how energy scenarios\nare tools to channel political, economic, and academic efforts into a common\ndirection. To impact decision-making, scenarios do not have to be accurate --\nbut credible and evoke coherent expectations in diverse stakeholders. To gain\ncredibility, authors of scenarios engage with stakeholders and appeal to the\nauthority of institutions or quantitative methods.\n  From these insights on energy scenarios, we draw consequences for developing\nand applying planning models, the quantitative tool energy scenarios build on.\nPlanning models should be open and accessible to facilitate stakeholder\nparticipation, avoid needlessly complex methods to minimize expert bias and aim\nfor a large scope to be policy relevant. Rather than trying to simulate social\npreferences and convictions within engineering models, scenario development\nshould pursue broad and active participation of all stakeholders, including\ncitizens.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.04821v2"
    },
    {
        "title": "Robust Implementation with Costly Information",
        "authors": [
            "Harry Pei",
            "Bruno Strulovici"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study whether a planner can robustly implement a state-contingent social\nchoice function when (i) agents must incur a cost to learn the state and (ii)\nthe planner faces uncertainty regarding agents' preferences over outcomes,\ninformation costs, and beliefs and higher-order beliefs about one another's\npayoffs. We propose mechanisms that can approximately implement any desired\nsocial choice function when the perturbations concerning agents' payoffs have\nsmall ex ante probability. The mechanism is also robust to trembles in agents'\nstrategies and when agents receive noisy information about the state.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.06032v1"
    },
    {
        "title": "Ex-post moral hazard and manipulation-proof contracts",
        "authors": [
            "Jean-Gabriel Lauzier"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We examine the trade-off between the provision of incentives to exert costly\neffort (ex-ante moral hazard) and the incentives needed to prevent the agent\nfrom manipulating the profit observed by the principal (ex-post moral hazard).\nFormally, we build a model of two-stage hidden actions where the agent can both\ninfluence the expected revenue of a business and manipulate its observed\nprofit. We show that manipulation-proofness is sensitive to the interaction\nbetween the manipulation technology and the probability distribution of the\nstochastic output. The optimal contract is manipulation-proof whenever the\nmanipulation technology is linear. However, a convex manipulation technology\nsometimes leads to contracts with manipulations in equilibrium. Whenever the\ndistribution satisfies the monotone likelihood ratio property, we can always\nfind a manipulation technology for which the optimal contract is not\nmanipulation-proof.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.06811v1"
    },
    {
        "title": "Envelope theorem and discontinuous optimisation: the case of positioning\n  choice problems",
        "authors": [
            "Jean-Gabriel Lauzier"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This article examines differentiability properties of the value function of\npositioning choice problems, a class of optimisation problems in\nfinite-dimensional Euclidean spaces. We show that positioning choice problems'\nvalue function is always almost everywhere differentiable even when the\nobjective function is discontinuous. To obtain this result we first show that\nthe Dini superdifferential is always well-defined for the maxima of positioning\nchoice problems. This last property allows to state first-order necessary\nconditions in terms of Dini supergradients. We then prove our main result,\nwhich is an ad-hoc envelope theorem for positioning choice problems. Lastly,\nafter discussing necessity of some key assumptions, we conjecture that similar\ntheorems might hold in other spaces as well.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.06815v1"
    },
    {
        "title": "Insurance design and arson-type risks",
        "authors": [
            "Jean-Gabriel Lauzier"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We design the insurance contract when the insurer faces arson-type risks. The\noptimal contract must be manipulation-proof. It is therefore continuous, it has\na bounded slope, and it satisfies the no-sabotage condition when arson-type\nactions are free. Any contract that mixes a deductible, coinsurance and an\nupper limit is manipulation-proof. We also show that the ability to perform\narson-type actions reduces the insured's welfare as less coverage is offered in\nequilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.06817v1"
    },
    {
        "title": "Taxes and Market Power: A Principal Components Approach",
        "authors": [
            "Andrea Galeotti",
            "Benjamin Golub",
            "Sanjeev Goyal",
            "Eduard Talamàs",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Suppliers of differentiated goods make simultaneous pricing decisions, which\nare strategically linked. Because of market power, the equilibrium is\ninefficient. We study how a policymaker should target a budget-balanced\ntax-and-subsidy policy to increase welfare. A key tool is a certain basis for\nthe goods space, determined by the network of interactions among suppliers. It\nconsists of eigenbundles -- orthogonal in the sense that a tax on any\neigenbundle passes through only to its own price -- with pass-through\ncoefficients determined by associated eigenvalues. Our basis permits a simple\ncharacterization of optimal interventions. A planner maximizing consumer\nsurplus should tax eigenbundles with low pass-through and subsidize ones with\nhigh pass-through. The Pigouvian leverage of the system -- the gain in consumer\nsurplus achievable by an optimal tax scheme -- depends only on the dispersion\nof the eigenvalues of the matrix of strategic interactions. We interpret these\nresults in terms of the network structure of the market.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.08153v2"
    },
    {
        "title": "Distance Functions and Generalized Means: Duality and Taxonomy",
        "authors": [
            "Walter Briec"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper introduces in production theory a large class of efficiency\nmeasures that can be derived from the notion of utility function. This article\nalso establishes a relation between these distance functions and Stone-Geary\nutility functions. More specifically, the paper focusses on new distance\nfunction that generalizes several existing efficiency measures. The new\ndistance function is inspired from the Atkinson inequality index and maximizes\nthe sum of the netput expansions required to reach an efficient point. A\ngeneralized duality theorem is proved and a duality result linking the new\ndistance functions and the profit function is obtained. For all feasible\nproduction vectors, it includes as special cases most of the dual\ncorrespondences previously established in the literature. Finally, we identify\na large class of measures for which these duality results can be obtained\nwithout convexity.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.09443v2"
    },
    {
        "title": "Algorithm Design: A Fairness-Accuracy Frontier",
        "authors": [
            "Annie Liang",
            "Jay Lu",
            "Xiaosheng Mu",
            "Kyohei Okumura"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Algorithm designers increasingly optimize not only for accuracy, but also for\nthe fairness of the algorithm across pre-defined groups. We study the tradeoff\nbetween fairness and accuracy for any given set of inputs to the algorithm. We\npropose and characterize a fairness-accuracy frontier, which consists of the\noptimal points across a broad range of preferences over fairness and accuracy.\nOur results identify a simple property of the inputs, group-balance, which\nqualitatively determines the shape of the frontier. We further study an\ninformation-design problem where the designer flexibly regulates the inputs\n(e.g., by coarsening an input or banning its use) but the algorithm is chosen\nby another agent. Whether it is optimal to ban an input generally depends on\nthe designer's preferences. But when inputs are group-balanced, then excluding\ngroup identity is strictly suboptimal for all designers, and when the designer\nhas access to group identity, then it is strictly suboptimal to exclude any\ninformative input.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.09975v5"
    },
    {
        "title": "Contextually Private Mechanisms",
        "authors": [
            "Andreas Haupt",
            "Zoë Hitzig"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We introduce a framework for comparing the privacy of different mechanisms. A\nmechanism designer employs a dynamic protocol to elicit agents' private\ninformation. Protocols produce a set of contextual privacy violations --\ninformation learned about agents that may be superfluous given the context. A\nprotocol is maximally contextually private if there is no protocol that\nproduces a subset of the violations it produces, while still implementing the\nchoice rule. We show that selecting a maximally contextually private protocol\ninvolves a deliberate decision about whose privacy is most important to\nprotect, and these protocols delay questions to those they aim to protect.\nTaking the second-price auction rule as an instructive example, we derive two\nnovel designs that are maximally contextually private: the ascending-join and\noverdescending-join protocols.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10812v7"
    },
    {
        "title": "Bidding in Multi-Unit Auctions under Limited Information",
        "authors": [
            "Bernhard Kasberger",
            "Kyle Woodward"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study multi-unit auctions in which bidders have limited knowledge of\nopponent strategies and values. We characterize optimal prior-free bids; these\nbids minimize the maximal loss in expected utility resulting from uncertainty\nsurrounding opponent behavior. Optimal bids are readily computable despite\nbidders having multi-dimensional private information, and in certain cases\nadmit closed-form solutions. In the pay-as-bid auction the minimax-loss bid is\nunique; in the uniform-price auction the minimax-loss bid is unique if the\nbidder is allowed to determine the quantities for which they bid, as in many\npractical applications. We compare minimax-loss bids and auction outcomes\nacross auction formats, and derive testable predictions.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.11320v2"
    },
    {
        "title": "Identification of misreported beliefs",
        "authors": [
            "Elias Tsakas"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  It is well-known that subjective beliefs cannot be identified with\ntraditional choice data unless we impose the strong assumption that preferences\nare state-independent. This is seen as one of the biggest pitfalls of\nincentivized belief elicitation. The two common approaches are either to\nexogenously assume that preferences are state-independent, or to use\nintractable elicitation mechanisms that require an awful lot of hard-to-get\nnon-traditional choice data. In this paper we use a third approach, introducing\na novel methodology that retains the simplicity of standard elicitation\nmechanisms without imposing the awkward state-independence assumption. The cost\nis that instead of insisting on full identification of beliefs, we seek\nidentification of misreporting. That is, we elicit beliefs with a standard\nsimple elicitation mechanism, and then by means of a single additional\nobservation we can tell whether the reported beliefs deviate from the actual\nbeliefs, and if so, in which direction they do.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.12975v1"
    },
    {
        "title": "Uniformly Self-Justified Equilibria",
        "authors": [
            "Felix Kubler",
            "Simon Scheidegger"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider dynamic stochastic economies with heterogeneous agents and\nintroduce the concept of uniformly self-justified equilibria (USJE) --\ntemporary equilibria for which forecasts are best uniform approximations to a\nselection of the equilibrium correspondence. In a USJE, individuals'\nforecasting functions for the next period's endogenous variables are assumed to\nlie in a compact, finite-dimensional set of functions, and the forecasts\nconstitute the best approximation within this set. We show that USJE always\nexist and develop a simple algorithm to compute them. Therefore, they are more\ntractable than rational expectations equilibria that do not always exist. As an\napplication, we discuss a stochastic overlapping generations exchange economy\nand provide numerical examples to illustrate the concept of USJE and the\ncomputational method.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.14054v1"
    },
    {
        "title": "On the Equivalence of Two Competing Affirmative Actions in School Choice",
        "authors": [
            "Yun Liu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This note analyzes the outcome equivalence conditions of two popular\naffirmative action policies, majority quota and minority reserve, under the\nstudent optimal stable mechanism. These two affirmative actions generate an\nidentical matching outcome, if the market either is effectively competitive or\ncontains a sufficiently large number of schools.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.14074v3"
    },
    {
        "title": "The Inflation Game",
        "authors": [
            "Wolfgang Kuhle"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study a game where households convert paper assets, such as money, into\nconsumption goods, to preempt inflation. The game features a unique equilibrium\nwith high (low) inflation, if money supply is high (low). For intermediate\nlevels of money supply, there exist multiple equilibria with either high or low\ninflation. Equilibria with moderate inflation, however, do not exist, and can\nthus not be targeted by a central bank. That is, depending on agents'\nequilibrium play, money supply is always either too high or too low for\nmoderate inflation. We also show that inflation rates of long-lived goods, such\nas houses, cars, expensive watches, furniture, or paintings, are a leading\nindicator for broader, economy wide, inflation.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.14697v1"
    },
    {
        "title": "Fuzzy Core Equivalence in Large Economies: A Role for the\n  Infinite-Dimensional Lyapunov Theorem",
        "authors": [
            "M. Ali Khan",
            "Nobusumi Sagara"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present the equivalence between the fuzzy core and the core under minimal\nassumptions. Due to the exact version of the Lyapunov convexity theorem in\nBanach spaces, we clarify that the additional structure of commodity spaces and\npreferences is unnecessary whenever the measure space of agents is \"saturated\".\nAs a spin-off of the above equivalence, we obtain the coincidence of the core,\nthe fuzzy core, and the Schmeidler's restricted core under minimal assumptions.\nThe coincidence of the fuzzy core and the restricted core has not been\narticulated anywhere.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.15539v1"
    },
    {
        "title": "A Taxonomy of Non-dictatorial Unidimensional Domains",
        "authors": [
            "Shurojit Chatterji",
            "Huaxia Zeng"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A preference domain is called a non-dictatorial domain if it allows the\ndesign of unanimous social choice functions (henceforth, rules) that are\nnon-dictatorial and strategy-proof. We study a class of preference domains\ncalled unidimensional domains and establish that the unique seconds property\n(introduced by Aswal, Chatterji, and Sen (2003)) characterizes all\nnon-dictatorial domains. The principal contribution is the subsequent\nexhaustive classification of all non-dictatorial, unidimensional domains and\ncanonical strategy-proof rules on these domains, based on a simple property of\ntwo-voter rules called invariance. The preference domains that constitute the\nclassification are semi-single-peaked domains (introduced by Chatterji, Sanver,\nand Sen (2013)) and semi-hybrid domains (introduced here) which are two\nappropriate weakenings of single-peaked domains and are shown to allow\nstrategy-proof rules to depend on non-peak information of voters' preferences;\nthe canonical rules for these domains are the projection rule and the hybrid\nrule respectively. As a refinement of the classification, single-peaked domains\nand hybrid domains emerge as the only unidimensional domains that force\nstrategy-proof rules to be determined completely by voters' preference peaks.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.00496v3"
    },
    {
        "title": "Observability, Dominance, and Induction in Learning Models",
        "authors": [
            "Daniel Clark",
            "Drew Fudenberg",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Learning models do not in general imply that weakly dominated strategies are\nirrelevant or justify the related concept of \"forward induction,\" because\nrational agents may use dominated strategies as experiments to learn how\nopponents play, and may not have enough data to rule out a strategy that\nopponents never use. Learning models also do not support the idea that the\nselected equilibria should only depend on a game's normal form, even though two\ngames with the same normal form present players with the same decision problems\ngiven fixed beliefs about how others play. However, playing the extensive form\nof a game is equivalent to playing the normal form augmented with the\nappropriate terminal node partitions so that two games are information\nequivalent, i.e., the players receive the same feedback about others'\nstrategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.00776v1"
    },
    {
        "title": "Robust Private Supply of a Public Good",
        "authors": [
            "Wanchang Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the mechanism design problem of selling a public good to a group of\nagents by a principal in the correlated private value environment. We assume\nthe principal only knows the expectations of the agents' values, but does not\nknow the joint distribution of the values. The principal evaluates a mechanism\nby the worst-case expected revenue over joint distributions that are consistent\nwith the known expectations. We characterize maxmin public good mechanisms\namong dominant-strategy incentive compatible and ex-post individually rational\nmechanisms for the two-agent case and for a special $N$-agent ($N>2$) case.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.00923v2"
    },
    {
        "title": "Reputation, Learning and Project Choice in Frictional Economies",
        "authors": [
            "Farzad Pourbabaee"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I introduce a dynamic model of learning and random meetings between a\nlong-lived agent with unknown ability and heterogeneous projects with\nobservable qualities. The outcomes of the agent's matches with the projects\ndetermine her posterior belief about her ability (i.e., her reputation). In a\nself-type learning framework with endogenous outside option, I find the optimal\nproject selection strategy of the agent, that determines what types of projects\nthe agent with a certain level of reputation will accept. Sections of the\noptimal matching set become increasing intervals, with different cutoffs across\ndifferent types of the projects. Increasing the meeting rate has asymmetric\neffects on the sections of the matching sets: it unambiguously expands the\nsection for the high type projects, while on some regions, it initially expands\nand then shrinks the section of the low type projects.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01813v4"
    },
    {
        "title": "Reputational Bargaining and Inefficient Technology Adoption",
        "authors": [
            "Harry Pei",
            "Maren Vairo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A buyer and a seller bargain over the price of an object. Both players can\nbuild reputations for being obstinate by offering the same price over time.\nBefore players bargain, the seller decides whether to adopt a new technology\nthat can lower his cost of production. We show that even when the buyer cannot\nobserve the seller's adoption decision, players' reputational incentives can\nlead to inefficient under-adoption and significant delays in reaching\nagreement, and that these inefficiencies arise in equilibrium if and only if\nthe social benefit from adoption is large enough. Our result implies that an\nincrease in the benefit from adoption may lower the probability of adoption and\nthat the seller's opportunity to adopt a cost-saving technology may lower\nsocial welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01827v6"
    },
    {
        "title": "Stationary social learning in a changing environment",
        "authors": [
            "Raphaël Lévy",
            "Marcin Pęski",
            "Nicolas Vieille"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider social learning in a changing world. Society can remain\nresponsive to state changes only if agents regularly act upon fresh\ninformation, which limits the value of social learning. When the state is close\nto persistent, a consensus whereby most agents choose the same action typically\nemerges. The consensus action is not perfectly correlated with the state\nthough, because the society exhibits inertia following state changes. Phases of\ninertia may be longer when signals are more precise, even if agents draw large\nsamples of past actions, as actions then become too correlated within samples,\nthereby reducing informativeness and welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02122v1"
    },
    {
        "title": "The component-wise egalitarian Myerson value for Network Games",
        "authors": [
            "Surajit Borkotokey",
            "Sujata Goala",
            "Niharika Kakoty",
            "Parishmita Boruah"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We introduce the component-wise egalitarian Myerson value for network games.\nThis new value being a convex combination of the Myerson value and the\ncomponent-wise equal division rule is a player-based allocation rule. In\nnetwork games under the cooperative framework, the Myerson value is an extreme\nexample of marginalism, while the equal division rule signifies egalitarianism.\nIn the proposed component-wise egalitarian Myerson value, a convexity parameter\ncombines these two attributes and determines the degree of solidarity to the\nplayers. Here, by solidarity, we mean the mutual support or compensation among\nthe players in a network. We provide three axiomatic characterizations of the\nvalue. Further, we propose an implementation mechanism for the component-wise\negalitarian Myerson value under subgame perfect Nash equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02793v1"
    },
    {
        "title": "A study on bribery networks with a focus on harassment bribery and ways\n  to control corruption",
        "authors": [
            "Chanchal Pramanik"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The paper focuses on the bribery network emphasizing harassment bribery. A\nbribery network ends with the police officer whose utility from the bribe is\npositive and the approving officer in the network. The persistent nature of\ncorruption is due to colluding behavior of the bribery networks. The\nprobability of detection of bribery incidents will help in improving\ncontrolling corruption in society. The asymmetric form of punishment and award\nequivalent to the amount of punishment to the network can enhance the\nprobability of detection of harassment bribery $(p_{h})$ and thus increasing\nthe probability of detection of overall bribery $(p_{h} \\in p)$.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02804v1"
    },
    {
        "title": "Price Heterogeneity as a source of Heterogenous Demand",
        "authors": [
            "John K. -H. Quah",
            "Gerelt Tserenjigmid"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We explore heterogenous prices as a source of heterogenous or stochastic\ndemand. Heterogenous prices could arise either because there is actual price\nvariation among consumers or because consumers (mis)perceive prices\ndifferently. Our main result says the following: if heterogenous prices have a\ndistribution among consumers that is (in a sense) stable across observations,\nthen a model where consumers have a common utility function but face\nheterogenous prices has precisely the same implications as a heterogenous\npreference/random utility model (with no price heterogeneity).\n",
        "pdf_link": "http://arxiv.org/pdf/2201.03784v2"
    },
    {
        "title": "Referral Hiring and Social Network Structure",
        "authors": [
            "Yoshitaka Ogisu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  It is well known that differences in the average number of friends among\nsocial groups can cause inequality in the average wage and/or unemployment\nrate. However, the impact of social network structure on inequality is not\nevident. In this paper, we show that not only the average number of friends but\nalso the heterogeneity of degree distribution can affect inter-group\ninequality. A worker group with a scale-free network tends to be disadvantaged\nin the labor market compared to a group with an Erd\\H{o}s-R\\'{e}nyi network\nstructure. This feature becomes strengthened as the skewness of the degree\ndistribution increases in scale-free networks. We show that the government's\npolicy of discouraging referral hiring worsens social welfare and can\nexacerbate inequality.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06020v2"
    },
    {
        "title": "Consolidating Marginalism and Egalitarianism: A New Value for\n  Transferable Utility Games",
        "authors": [
            "D. Choudhury",
            "S. Borkotokey",
            "Rajnish Kumar",
            "Sudipta Sarangi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In cooperative games with transferable utilities, the Shapley value is an\nextreme case of marginalism while the Equal Division rule is an extreme case of\negalitarianism. The Shapley value does not assign anything to the\nnon-productive players and the Equal Division rule does not concern itself to\nthe relative efficiency of the players in generating a resource. However, in\nreal life situations neither of them is a good fit for the fair distribution of\nresources as the society is neither devoid of solidarity nor it can be\nindifferent to rewarding the relatively more productive players. Thus a\ntrade-off between these two extreme cases has caught attention from many\nresearchers. In this paper, we obtain a new value for cooperative games with\ntransferable utilities that adopts egalitarianism in smaller coalitions on one\nhand and on the other hand takes care of the players' marginal productivity in\nsufficiently large coalitions. Our value is identical with the Shapley value on\none extreme and the Equal Division rule on the other extreme. We provide four\ncharacterizations of the value using variants of standard axioms in the\nliterature. We have also developed a strategic implementation mechanism of our\nvalue in sub-game perfect Nash equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.09182v1"
    },
    {
        "title": "The Benefits of Coarse Preferences",
        "authors": [
            "Joseph Y. Halpern",
            "Yuval Heller",
            "Eyal Winter"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the strategic advantages of coarsening one's utility by clustering\nnearby payoffs together (i.e., classifying them the same way). Our solution\nconcept, coarse-utility equilibrium (CUE) requires that (1) each player\nmaximizes her coarse utility, given the opponent's strategy, and (2) the\nclassifications form best replies to one another. We characterize CUEs in\nvarious games. In particular, we show that there is a qualitative difference\nbetween CUEs in which only one of the players clusters payoffs, and those in\nwhich all players cluster their payoffs, and that the latter type induce\nplayers to treat co-players better than in Nash equilibria in the large class\nof games with monotone externalities.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.10141v5"
    },
    {
        "title": "Relaxed Notions of Condorcet-Consistency and Efficiency for\n  Strategyproof Social Decision Schemes",
        "authors": [
            "Felix Brandt",
            "Patrick Lederer",
            "René Romen"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Social decision schemes (SDSs) map the preferences of a group of voters over\nsome set of $m$ alternatives to a probability distribution over the\nalternatives. A seminal characterization of strategyproof SDSs by Gibbard\nimplies that there are no strategyproof Condorcet extensions and that only\nrandom dictatorships satisfy ex post efficiency and strategyproofness. The\nlatter is known as the random dictatorship theorem. We relax\nCondorcet-consistency and ex post efficiency by introducing a lower bound on\nthe probability of Condorcet winners and an upper bound on the probability of\nPareto-dominated alternatives, respectively. We then show that the SDS that\nassigns probabilities proportional to Copeland scores is the only anonymous,\nneutral, and strategyproof SDS that can guarantee the Condorcet winner a\nprobability of at least 2/m. Moreover, no strategyproof SDS can exceed this\nbound, even when dropping anonymity and neutrality. Secondly, we prove a\ncontinuous strengthening of Gibbard's random dictatorship theorem: the less\nprobability we put on Pareto-dominated alternatives, the closer to a random\ndictatorship is the resulting SDS. Finally, we show that the only anonymous,\nneutral, and strategyproof SDSs that maximize the probability of Condorcet\nwinners while minimizing the probability of Pareto-dominated alternatives are\nmixtures of the uniform random dictatorship and the randomized Copeland rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.10418v1"
    },
    {
        "title": "Robust Comparative Statics for the Elasticity of Intertemporal\n  Substitution",
        "authors": [
            "Joel P. Flynn",
            "Lawrence D. W. Schmidt",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a general class of consumption-savings problems with recursive\npreferences. We characterize the sign of the consumption response to arbitrary\nshocks in terms of the product of two sufficient statistics: the elasticity of\nintertemporal substitution between contemporaneous consumption and continuation\nutility (EIS), and the relative elasticity of the marginal value of wealth\n(REMV). Under homotheticity, the REMV always equals one, so the propensity of\nthe agent to save or dis-save is always signed by the relationship of the EIS\nwith unity. We apply our results to derive comparative statics in classical\nproblems of portfolio allocation, consumption-savings with income risk, and\nentrepreneurial investment. Our results suggest empirical identification\nstrategies for both the value of the EIS and its relationship with unity.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.10673v1"
    },
    {
        "title": "Stochastic Consensus and the Shadow of Doubt",
        "authors": [
            "Emilien Macault"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We propose a stochastic model of opinion exchange in networks. A finite set\nof agents is organized in a fixed network structure. There is a binary state of\nthe world and each agent receives a private signal on the state. We model\nbeliefs as urns where red balls represent one possible value of the state and\nblue balls the other value. The model revolves purely around communication and\nbeliefs dynamics. Communication happens in discrete time and, at each period,\nagents draw and display one ball from their urn with replacement. Then, they\nreinforce their urns by adding balls of the colors drawn by their neighbors. We\nshow that for any network structure, this process converges almost-surely to a\nstable state. Futher, we show that if the communication network is connected,\nthis stable state is such that all urns have the same proportion of balls. This\nresult strengthens the main convergence properties of non-Bayesian learning\nmodels. Yet, contrary to those models, we show that this limit proportion is a\nfull-support random variable. This implies that an arbitrarily small proportion\nof misinformed agents can substantially change the value of the limit\nconsensus. We propose a set of conjectures on the distribution of this limit\nproportion based on simulations. In particular, we show evidence that the limit\nbelief follows a beta distribution and that its average value is independent\nfrom the network structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.12100v1"
    },
    {
        "title": "The Impact of Connectivity on the Production and Diffusion of Knowledge",
        "authors": [
            "Gustavo Manso",
            "Farzad Pourbabaee"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a social bandit problem featuring production and diffusion of\nknowledge. While higher connectivity enhances knowledge diffusion, it may\nreduce knowledge production as agents shy away from experimentation with new\nideas and free ride on the observation of other agents. As a result, under some\nconditions, greater connectivity can lead to homogeneity and lower social\nwelfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.00729v1"
    },
    {
        "title": "On Sustainability and Survivability in the Matchbox Two-Sector Model: A\n  Complete Characterization of Optimal Extinction",
        "authors": [
            "Liuchun Deng",
            "Minako Fujio",
            "M. Ali Khan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We provide a complete characterization of optimal extinction in a two-sector\nmodel of economic growth through three results, surprising in both their\nsimplicity and intricacy. (i) When the discount factor is below a threshold\nidentified by the well-known $\\delta$-normality condition for the existence of\na stationary optimal stock, the economy's capital becomes extinct in the long\nrun. (ii) This extinction may be staggered if and only if the investment-good\nsector is capital intensive. (iii) We uncover a sequence of thresholds of the\ndiscount factor, identified by a family of rational functions, that represent\nbifurcations for optimal postponements on the path to extinction. We also\nreport various special cases of the model having to do with unsustainable\ntechnologies and equal capital intensities that showcase long-term optimal\ngrowth, all of topical interest and all neglected in the antecedent literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.02209v1"
    },
    {
        "title": "Sequential Veto Bargaining with Incomplete Information",
        "authors": [
            "S. Nageeb Ali",
            "Navin Kartik",
            "Andreas Kleiner"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study sequential bargaining between a proposer and a veto player. Both\nhave single-peaked preferences, but the proposer is uncertain about the veto\nplayer's ideal point. The proposer cannot commit to future proposals. When\nplayers are patient, there can be equilibria with Coasian dynamics: the veto\nplayer's private information can largely nullify proposer's bargaining power.\nOur main result, however, is that under some conditions there are also\nequilibria in which the proposer obtains the high payoff that he would with\ncommitment power. The driving force is that the veto player's single-peaked\npreferences give the proposer an option to \"leapfrog\", i.e., to secure\nagreement from only low-surplus types early on to credibly extract surplus from\nhigh types later. Methodologically, we exploit the connection between\nsequential bargaining and static mechanism design.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.02462v3"
    },
    {
        "title": "On the Asymptotic Performance of Affirmative Actions in School Choice",
        "authors": [
            "Di Feng",
            "Yun Liu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper analyzes the asymptotic performance of two popular affirmative\naction policies, majority quota and minority reserve, under the immediate\nacceptance mechanism (IAM) and the top trading cycles mechanism (TTCM) in the\ncontest of school choice. The matching outcomes of these two affirmative\nactions are asymptotically equivalent under the IAM when all students are\nsincere. Given the possible preference manipulations under the IAM, we\ncharacterize the asymptotically equivalent sets of Nash equilibrium outcomes of\nthe IAM with these two affirmative actions. However, these two affirmative\nactions induce different matching outcomes under the TTCM with non-negligible\nprobability even in large markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.03927v5"
    },
    {
        "title": "Efficiency with(out) intermediation in repeated bilateral trade",
        "authors": [
            "Rohit Lamba"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper analyzes repeated version of the bilateral trade model where the\nindependent payoff relevant private information of the buyer and the seller is\ncorrelated across time. Using this setup it makes the following five\ncontributions. First, it derives necessary and sufficient conditions on the\nprimitives of the model as to when efficiency can be attained under ex post\nbudget balance and participation constraints. Second, in doing so, it\nintroduces an intermediate notion of budget balance called interim budget\nbalance that allows for the extension of liquidity but with participation\nconstraints for the issuing authority interpreted here as an intermediary.\nThird, it pins down the class of all possible mechanisms that can implement the\nefficient allocation with and without an intermediary. Fourth, it provides a\nfoundation for the role of an intermediary in a dynamic mechanism design model\nunder informational constraints. And, fifth, it argues for a careful\ninterpretation of the \"folk proposition\" that less information is better for\nefficiency in dynamic mechanisms under ex post budget balance and observability\nof transfers.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04201v1"
    },
    {
        "title": "On the Uniqueness and Stability of the Equilibrium Price in Quasi-Linear\n  Economies",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper, we show that if every consumer in an economy has a\nquasi-linear utility function, then the normalized equilibrium price is unique,\nand is locally stable with respect to the t\\^atonnement process. Our study can\nbe seen as that extends the results in partial equilibrium theory to economies\nwith more than two dimensional consumption space. Moreover, we discuss the\nsurplus analysis in such economies.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04573v5"
    },
    {
        "title": "Sequentially Optimal Pricing under Informational Robustness",
        "authors": [
            "Zihao Li",
            "Jonathan Libgober",
            "Xiaosheng Mu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A seller sells an object over time but is uncertain how the buyer learns\ntheir willingness-to-pay. We consider informational robustness under\n\\textit{limited commitment}, where the seller offers a price \\textit{each\nperiod} to maximize continuation profit against worst-case information arrival.\nOur formulation maintains dynamic consistency by considering the worst case\n\\textit{sequentially}. Under general conditions, we characterize an essentially\nunique equilibrium where the buyer does not delay to learn more later.\nFurthermore, we identify a condition that ensures the equilibrium price path is\n``reinforcing,'' so even dynamically inconsistent information arrival would not\nlower the seller's payoff below the equilibrium level.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04616v3"
    },
    {
        "title": "Stable allocations in discrete exchange economies",
        "authors": [
            "Federico Echenique",
            "Sumit Goel",
            "SangMok Lee"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study stable allocations in an exchange economy with indivisible goods.\nThe problem is well-known to be challenging, and rich enough to encode\nfundamentally unstable economies, such as the roommate problem. Our approach\nstems from generalizing the original study of an exchange economy with unit\ndemand and unit endowments, the \\emph{housing model}. Our first approach uses\nScarf's theorem, and proposes sufficient conditions under which a ``convexify\nthen round'' technique ensures that the core is nonempty. The upshot is that a\ncore allocation exists in categorical economies with dichotomous preferences.\nOur second approach uses a generalization of the TTC: it works under general\nconditions, and finds a solution that is a version of the stable set.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04706v3"
    },
    {
        "title": "Rationalizable Implementation of Social Choice Functions: Complete\n  Characterization",
        "authors": [
            "Siyang Xiong"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We provide a necessary and sufficient condition for rationalizable\nimplementation of social choice functions, i.e., we offer a complete answer\nregarding what social choice functions can be rationalizably implemented.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04885v1"
    },
    {
        "title": "How rare are the properties of binary relations?",
        "authors": [
            "Ram Sewak Dubey",
            "Giorgio Laguzzi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Knoblauch (2014) and Knoblauch (2015) investigate the relative size of the\ncollection of binary relations with desirable features as compared to the set\nof all binary relations using symmetric difference metric (Cantor) topology and\nHausdorff metric topology. We consider Ellentuck and doughnut topologies to\nfurther this line of investigation. We report the differences among the size of\nthe useful binary relations in Cantor, Ellentuck and doughnut topologies. It\nturns out that the doughnut topology admits binary relations with more general\nproperties in contrast to the other two. We further prove that among the\ninduced Cantor and Ellentuck topologies, the latter captures the relative size\nof partial orders among the collection of all quasi-orders. Finally we show\nthat the class of ethical binary relations is small in Ellentuck (and therefore\nin Cantor) topology but is not small in doughnut topology. In essence, the\nEllentuck topology fares better compared to Cantor topology in capturing the\nrelative size of collections of binary relations.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05229v1"
    },
    {
        "title": "Buying Opinions",
        "authors": [
            "Mark Whitmeyer",
            "Kun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A principal hires an agent to acquire soft information about an unknown\nstate. Even though neither how the agent learns nor what the agent discovers\nare contractible, we show the principal is unconstrained as to what information\nthe agent can be induced to acquire and report honestly. When the agent is risk\nneutral, and a) is not asked to learn too much, b) can acquire information\nsufficiently cheaply, or c) can face sufficiently large penalties, the\nprincipal can attain the first-best outcome. We discuss the effect of risk\naversion (on the part of the agent) and characterize the second-best contracts.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05249v5"
    },
    {
        "title": "Observational Learning with Competitive Prices",
        "authors": [
            "Zikai Xu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Will people eventually learn the value of an asset through observable\ninformation? This paper studies observational learning in a market with\ncompetitive prices. Comparing a market with public signals and a market with\nprivate signals in a sequential trading model, we find that Pairwise\nInformativeness (PI) is the sufficient and necessary learning condition for a\nmarket with public signals; and Avery and Zemsky Condition (AZC) is the\nsufficient and necessary learning condition for a market with private signals.\nMoreover, when the number of states is 2 or 3, PI and AZC are equivalent. And\nwhen the number of states is greater than 3, PI and Monotonic Likelihood Ratio\nProperty (MLRP) together imply asymptotic learning in the private signal case.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06425v3"
    },
    {
        "title": "Order of Commitments in Bayesian Persuasion with Partial-informed\n  Senders",
        "authors": [
            "Shih-Tang Su",
            "Vijay G. Subramanian"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The commitment power of senders distinguishes Bayesian persuasion problems\nfrom other games with (strategic) communication. Persuasion games with multiple\nsenders have largely studied simultaneous commitment and signalling settings.\nHowever, many real-world instances with multiple senders have sequential\nsignalling. In such contexts, commitments can also be made sequentially, and\nthen the order of commitment by the senders -- the sender signalling last\ncommitting first or last -- could significantly impact the equilibrium payoffs\nand strategies. For a two-sender persuasion game where the senders are\npartially aware of the state of the world, we find necessary and sufficient\nconditions to determine when different commitment orders yield different payoff\nprofiles. In particular, for the two-sender setting, we show that different\npayoff profiles arise if two properties hold: 1) the two senders are willing to\ncollaborate in persuading the receiver in some state(s); and 2) the sender\nsignalling second can carry out a credible threat when committing first such\nthat the other sender's room to design signals gets constrained.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06479v1"
    },
    {
        "title": "Simple Models and Biased Forecasts",
        "authors": [
            "Pooya Molavi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper proposes a framework in which agents are constrained to use simple\nmodels to forecast economic variables and characterizes the resulting biases.\nIt considers agents who can only entertain state-space models with no more than\nd states, where d measures the intertemporal complexity of a model. Agents are\nboundedly rational in that they can only consider models that are too simple to\ncapture the true process, yet they use the best model among those considered.\nUsing simple models adds persistence to forward-looking decisions and increases\nthe comovement among them. This mechanism narrows the gap between\nbusiness-cycle theory and data. In a new neoclassical synthesis model, the\nassumption that agents use simple models fits the data much better than the\nrational-expectations hypothesis. Moreover, simple models simultaneously\nresolve the Barro-King and forward guidance puzzles while improving the\npropagation of TFP shocks.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06921v5"
    },
    {
        "title": "On the optimality of full disclosure",
        "authors": [
            "Emiliano Catonini",
            "Sergey Stepanov"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A privately-informed sender can commit to any disclosure policy towards a\nreceiver. We show that full disclosure is optimal under a sufficient condition\nwith some desirable properties. First, it speaks directly to the utility\nfunctions of the parties, as opposed to the indirect utility function of the\nsender; this makes it easily interpretable and verifiable. Second, it does not\nrequire the sender's payoff to be a function of the posterior mean. Third, it\nis weaker than the known conditions for some special cases. With this, we show\nthat full disclosure is optimal under modeling assumptions commonly used in\nprincipal-agent papers.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07944v4"
    },
    {
        "title": "Fair Division with Money and Prices",
        "authors": [
            "Anna Bogomolnaia",
            "Herve Moulin"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We must divide a finite number of indivisible goods and cash transfers\nbetween agents with quasi-linear but otherwise arbitrary utilities over the\nsubsets of goods. We compare two division rules with cognitively feasible and\nprivacy preserving individual messages. In Sell&Buy agents bid for the role of\nSeller or Buyer: with two agents the smallest bid defines the Seller who then\ncharges any a price constrained only by her winning bid. In Divide&Choose\nagents bid for the role of Divider, then everyone bids on the shares of the\nDivider's partition. S&B dominates D&C on two counts: its guaranteed utility in\nthe worst case rewards (resp. penalises) more subadditive (resp. superadditive)\nutilities; playing safe is never ambiguous and is also better placed to collect\na larger share of the efficient surplus.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.08117v1"
    },
    {
        "title": "Preference Learning in School Choice Problems",
        "authors": [
            "SangMok Lee"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In school choice, students make decisions based on their expectations of\nparticular schools' suitability, and the decision to gather information about\nschools is influenced by the acceptance odds determined by the mechanism in\nplace. We study a school choice model where students can obtain information\nabout their preferences by incurring a cost. We demonstrate greater homogeneity\nin rank-order reports and reduced information acquisition under the\nDeferred-Acceptance (DA) mechanism, resulting in an increased reliance on\nrandom tie-breaking and ultimately inefficient outcomes. Thus, it is critical\nfor the DA mechanism to have easy access to school information in order to\nmaintain its efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.08366v2"
    },
    {
        "title": "Continuity Postulates and Solvability Axioms in Economic Theory and in\n  Mathematical Psychology: A Consolidation of the Theory of Individual Choice",
        "authors": [
            "Aniruddha Ghosh",
            "M. Ali Khan",
            "Metin Uyanik"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper presents four theorems that connect continuity postulates in\nmathematical economics to solvability axioms in mathematical psychology, and\nranks them under alternative supplementary assumptions. Theorem 1 connects\nnotions of continuity (full, separate, Wold, weak Wold, Archimedean, mixture)\nwith those of solvability (restricted, unrestricted) under the completeness and\ntransitivity of a binary relation. Theorem 2 uses the primitive notion of a\nseparately-continuous function to answer the question when an analogous\nproperty on a relation is fully continuous. Theorem 3 provides a portmanteau\ntheorem on the equivalence between restricted solvability and various notions\nof continuity under weak monotonicity. Finally, Theorem 4 presents a variant of\nTheorem 3 that follows Theorem 1 in dispensing with the dimensionality\nrequirement and in providing partial equivalences between solvability and\ncontinuity notions. These theorems are motivated for their potential use in\nrepresentation theorems.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.08415v2"
    },
    {
        "title": "Monopoly, Product Quality, and Flexible Learning",
        "authors": [
            "Jeffrey Mensch",
            "Doron Ravid"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A seller offers a buyer a schedule of transfers and associated product\nqualities. After observing this schedule, the buyer chooses a flexible costly\nsignal about his type. We show it is without loss to focus on a class of\nmechanisms that compensate the buyer for his learning costs. Using these\nmechanisms, we prove that when marginal costs of quality are strictly\nincreasing, quality always lies strictly below the efficient level at all types\nstrictly below the highest possible type under the prior. When learning costs\nare sufficiently steep, it follows the monopolist optimum distorts quality\ndownward even \"at the top\" of the buyer's chosen signal structure. Moreover,\nwhen marginal costs of quality are constant, interior buyer types obtain\ninterior qualities. These results stand in contrast to the exogenous\ninformation case, which features \"no distortion at the top\" when marginal\nproduction costs are increasing, and serving the maximal quality to all types\nabove some threshold when marginal product costs are constant. We also show\nthat when learning costs are steep, the monopolist finds it optimal to offer a\nsimple menu that contains at most two purchasing options. Under appropriate\ncurvature conditions, offering a single purchasing option is optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09985v5"
    },
    {
        "title": "Equilibria of Attacker-Defender Games",
        "authors": [
            "Zsombor Z. Méder",
            "Carsten K. W. de Dreu",
            "Jörg Gross"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Attempts at predatory capture may provoke a defensive response that reduces\nthe very value of the predated resource. We provide a game-theoretic analysis\nof simultaneous-move, two-player Attacker-Defender games that model such\ninteractions. When initial endowments are equal, Attackers win about a third of\nsuch games in equilibrium. Under power disparities, Attackers become\nparticularly aggressive when they are approximately one-third poorer than\nDefenders. With non-conflictual outside options Attackers become exceptionally\naggressive when their opponent has access to high-benefit, low-cost production,\nand refrain from attack most when they are unilaterally provided with a\nhigh-benefit, high-cost production option.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10072v2"
    },
    {
        "title": "A Dutch book argument for belief consistency",
        "authors": [
            "Emiliano Catonini"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  An agent progressively learns about a state of the world. A bookmaker is\nready to offer one bet after every new discovery. I say that the agent is\nDutch-booked when she is willing to accept every single bet, but her expected\npayoff is negative under each state, where the expected payoff is computed with\nthe objective probabilities of different discoveries conditional on the state.\nI introduce a rule of coherence among beliefs after counterfactual discoveries\nthat is necessary and sufficient to avoid being Dutch-booked. This rule\ncharacterizes an agent who derives all her beliefs with Bayes rule from the\nsame Lexicographic Conditional Probability System (Blume, Brandenburger and\nDekel, 1991).\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10121v1"
    },
    {
        "title": "Information Design in Smooth Games",
        "authors": [
            "Alex Smolin",
            "Takuro Yamashita"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study information design in games in which each player has a continuum of\nactions. We show that an information structure is designer-optimal whenever the\nequilibrium play it induces can also be implemented in a principal-agent\ncontracting problem. We use this observation to solve three novel applications.\nIn an investment game, the optimal structure fully informs a single investor\nwhile providing no information to others. In an expectation polarization game,\nthe optimal structure fully informs half of the players while providing no\ninformation to the other half. In a price competition game, the optimal\nstructure is noise-free Gaussian and recommends prices linearly in the states.\nOur analysis further informs on the robustness and uniqueness of the optimal\ninformation structures.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10883v4"
    },
    {
        "title": "The outcome of the restabilization process in matching markets",
        "authors": [
            "Millán Guerra Beatriz Alejandra"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  For a many-to-one matching model, we study the matchings obtained through the\nrestabilization of stable matchings that had been disrupted by a change in the\npopulation. We include a simple representation of the stable matching obtained\nin terms of the initial stable matching (i.e., before being disrupted by\nchanges in the population) and the firm-optimal stable matching. (We used\nLattice Theory to characterize the outcome of the restabilization process.) We\nalso describe the connection between the original stable matching and the one\nobtained after the restabilization process in the new market.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.12452v1"
    },
    {
        "title": "Social Learning under Platform Influence: Consensus and Persistent\n  Disagreement",
        "authors": [
            "Ozan Candogan",
            "Nicole Immorlica",
            "Bar Light",
            "Jerry Anunrojwong"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Individuals increasingly rely on social networking platforms to form\nopinions. However, these platforms typically aim to maximize engagement, which\nmay not align with social good. In this paper, we introduce an opinion dynamics\nmodel where agents are connected in a social network, and update their opinions\nbased on their neighbors' opinions and on the content shown to them by the\nplatform. We focus on a stochastic block model with two blocks, where the\ninitial opinions of the individuals in different blocks are different. We prove\nthat for large and dense enough networks the trajectory of opinion dynamics in\nsuch networks can be approximated well by a simple two-agent system. The latter\nadmits tractable analytical analysis, which we leverage to provide interesting\ninsights into the platform's impact on the social learning outcome in our\noriginal two-block model. Specifically, by using our approximation result, we\nshow that agents' opinions approximately converge to some limiting opinion,\nwhich is either: consensus, where all agents agree, or persistent disagreement,\nwhere agents' opinions differ. We find that when the platform is weak and there\nis a high number of connections between agents with different initial opinions,\na consensus equilibrium is likely. In this case, even if a persistent\ndisagreement equilibrium arises, the polarization in this equilibrium, i.e.,\nthe degree of disagreement, is low. When the platform is strong, a persistent\ndisagreement equilibrium is likely and the equilibrium polarization is high. A\nmoderate platform typically leads to a persistent disagreement equilibrium with\nmoderate polarization. We analyze the effect of initial polarization on\nconsensus and explore numerically various extensions including a three block\nstochastic model and a correlation between initial opinions and agents'\nconnection probabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.12453v2"
    },
    {
        "title": "Optimal Defaults, Limited Enforcement and the Regulation of Contracts",
        "authors": [
            "Zoë Hitzig",
            "Benjamin Niswonger"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study how governments promote social welfare through the design of\ncontracting environments. We model the regulation of contracting as default\ndelegation: the government chooses a delegation set of contract terms it is\nwilling to enforce, and influences the default terms that serve as outside\noptions in parties' negotiations. Our analysis shows that limiting the\ndelegation set principally mitigates externalities, while default terms\nprimarily achieve distributional objectives. Applying our model to the\nregulation of labor contracts, we derive comparative statics on the optimal\ndefault delegation policy. As equity concerns or externalities increase,\nin-kind support for workers increases (e.g. through benefits requirements and\npublic health insurance). Meanwhile, when worker bargaining power decreases\naway from parity, support for workers increases in cash (e.g. through cash\ntransfers and minimum wage laws).\n",
        "pdf_link": "http://arxiv.org/pdf/2203.01233v2"
    },
    {
        "title": "Constitutional Implementation of Affirmative Action Policies in India",
        "authors": [
            "Tayfun Sonmez",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  India is home to a comprehensive affirmative action program that reserves a\nfraction of positions at governmental institutions for various disadvantaged\ngroups. While there is a Supreme Court-endorsed mechanism to implement these\nreservation policies when all positions are identical, courts have refrained\nfrom endorsing explicit mechanisms when positions are heterogeneous. This\nlacunae has resulted in widespread adoption of unconstitutional mechanisms,\ncountless lawsuits, and inconsistent court rulings. Formulating mandates in the\nlandmark Supreme Court judgment Saurav Yadav (2020) as technical axioms, we\nshow that the 2SMH-DA mechanism is uniquely suited to overcome these\nchallenges.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.01483v3"
    },
    {
        "title": "Speculation in Procurement Auctions",
        "authors": [
            "Shanglyu Deng"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A speculator can take advantage of a procurement auction by acquiring items\nfor sale before the auction. The accumulated market power can then be exercised\nin the auction and may lead to a large enough gain to cover the acquisition\ncosts. I show that speculation always generates a positive expected profit in\nsecond-price auctions but could be unprofitable in first-price auctions. In the\ncase where speculation is profitable in first-price auctions, it is more\nprofitable in second-price auctions. This comparison in profitability is driven\nby different competition patterns in the two auction mechanisms. In terms of\nwelfare, speculation causes private value destruction and harms efficiency.\nSellers benefit from the acquisition offer made by the speculator. Therefore,\nspeculation comes at the expense of the auctioneer.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.03044v3"
    },
    {
        "title": "Choice and Attention across Time",
        "authors": [
            "Xi Zhi Lim"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I study how past and future choices are linked in the framework of attention.\nAttention cannot be observed but past choices are necessarily considered in\nfuture decisions. This link connects two types of rationality violations,\ncounterfactual and realized, where the former results from inattention and the\nlatter fully pins down preferences. Results show that the necessary traces of\nlimited attention lie within choice sequences because they enable and compel a\ndecision maker to correct their \"mistakes\". The framework accommodates\ndifferent attention structures and extends to framing, introducing choice\nsequences as an important channel to formulate, identify, and scrutinize\nlimited attention.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.03243v3"
    },
    {
        "title": "Non-Smooth Integrability Theory",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a method for calculating the utility function from a candidate of a\ndemand function that is not differentiable, but is locally Lipschitz. Using\nthis method, we obtain two new necessary and sufficient conditions for a\ncandidate of a demand function to be a demand function. The first concerns the\nSlutsky matrix, and the second is the existence of a concave solution to a\npartial differential equation. Moreover, we show that the upper semi-continuous\nweak order that corresponds to the demand function is unique, and that this\nweak order is represented by our calculated utility function. We provide\napplications of these results to econometric theory. First, we show that, under\nseveral requirements, if a sequence of demand functions converges to some\nfunction with respect to the metric of compact convergence, then the limit is\nalso a demand function. Second, the space of demand functions that have uniform\nLipschitz constants on any compact set is compact under the above metric.\nThird, the mapping from a demand function to the calculated utility function\nbecomes continuous. We also show a similar result on the topology of pointwise\nconvergence.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04770v5"
    },
    {
        "title": "Innovation Diffusion among Case-based Decision-makers",
        "authors": [
            "Benson Tsz Kin Leung"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper analyzes a model of innovation diffusion with case-based\nindividuals a la Gilboa and Schmeidler (1995,1996,1997), who decide whether to\nconsume an incumbent or a new product based on their and their social\nneighbors' previous consumption experiences. I analyze how diffusion pattern\nchanges with individual characteristics, innovation characteristics and social\nnetwork. In particular, radical innovation leads to higher initial speed but\nlower acceleration compared to increment innovation. Social network with\nstronger overall social tie, lower degree of homophily or higher exposure of\nreviews from early adopters speed up diffusion of innovation.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.05785v2"
    },
    {
        "title": "Keeping up with \"The Joneses\": reference dependent choice with social\n  comparisons",
        "authors": [
            "Alastair Langtry"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Keeping up with \"The Joneses\" matters. This paper examines a model of\nreference dependent choice where reference points are determined by social\ncomparisons. An increase in the strength of social comparisons, even by only a\nfew agents, increases consumption and decreases welfare for everyone.\nStrikingly, a higher marginal cost of consumption can increase welfare. In a\nlabour market, social comparisons with co-workers create a big fish in a small\npond effect, inducing incomplete labour market sorting. Further, it is the\nskilled workers with the weakest social networks who are induced to give up\nincome to become the big fish.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.10305v2"
    },
    {
        "title": "Belief identification with state-dependent utilities",
        "authors": [
            "Elias Tsakas"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  It is well known that individual beliefs cannot be identified using\ntraditional choice data, unless we impose the practically restrictive and\nconceptually awkward assumption that utilities are state-independent. In this\npaper, we propose a novel methodology that solves this long-standing\nidentification problem in a simple way, using a variant of the strategy method.\nOur method relies on the concept of a suitable proxy. The crucial property is\nthat the agent does not have any stakes in the proxy conditional on the\nrealization of the original state space. Then, instead of trying to identify\ndirectly the agent's beliefs about the state space, we elicit her conditional\nbeliefs about the proxy given each state realization. The latter can be easily\ndone with existing elicitation tools and without worrying about the\nidentification problem. It turns out that this is enough to uniquely identify\nthe agent's beliefs. We present different classes of proxies that one can\nreasonably use, and we show that it is almost always possible to find one which\nis easy to implement. Such flexibility makes our method, not only\ntheoretically-sound, but also empirically appealing. We also show how our new\nmethod allows us to provide a novel well-founded definition of a utility\nfunction over states. Last but not least, it also allows us to cleanly identify\nmotivated beliefs, freed from confounding distortions caused by the\nidentification problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.10505v3"
    },
    {
        "title": "Informational Autocrats, Diverse Societies",
        "authors": [
            "A. Arda Gitmez",
            "Pooya Molavi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper presents a theoretical model of an autocrat who controls the media\nin an attempt to persuade society of his competence. We base our analysis on a\nBayesian persuasion framework in which citizens have heterogeneous preferences\nand beliefs about the autocrat. We characterize the autocrat's information\nmanipulation strategy when society is monolithic and when it is divided. When\nthe preferences and beliefs in society are more diverse, the autocrat engages\nin less information manipulation. Our findings thus suggest that the diversity\nof attitudes and opinions can act as a bulwark against information manipulation\nby hostile actors.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.12698v3"
    },
    {
        "title": "Put-Call Parities, absence of arbitrage opportunities and non-linear\n  pricing rules",
        "authors": [
            "Lorenzo Bastianello",
            "Alain Chateauneuf",
            "Bernard Cornet"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  If prices of assets traded in a financial market are determined by non-linear\npricing rules, different versions of the Call-Put Parity have been considered.\nWe show that, under monotonicity, parities between call and put options and\ndiscount certificates characterize ambiguity-sensitive (Choquet and/or Sipos)\npricing rules, i.e., pricing rules that can be represented via discounted\nexpectations with respect to non-additive probability measures. We analyze how\nnon-additivity relates to arbitrage opportunities and we give necessary and\nsufficient conditions for Choquet and Sipos pricing rules to be arbitrage-free.\nFinally, we identify violations of the Call-Put Parity with the presence of\nbid-ask spreads.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.16292v1"
    },
    {
        "title": "Core and stability notions in many-to-one matching markets with\n  indifferences",
        "authors": [
            "Agustín G. Bonifacio",
            "Noelia Juarez",
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In a many-to-one matchingmodel with responsive preferences in which\nindifferences are allowed, we study three notions of core, three notions of\nstability, and their relationships. We show that (i) the core contains the\nstable set, (ii) the strong core coincides with the strongly stable set, and\n(iii) the super core coincides with the super stable set. We also show how the\ncore and the strong core in markets with indifferences relate to the stable\nmatchings of their associated tie-breaking strict markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.16293v1"
    },
    {
        "title": "Optimal and Robust Disclosure of Public Information",
        "authors": [
            "Takashi Ui"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A policymaker discloses public information to interacting agents who also\nacquire costly private information. More precise public information reduces the\nprecision and cost of acquired private information. Considering this effect,\nwhat disclosure rule should the policymaker adopt? We address this question\nunder two alternative assumptions using a linear quadratic Gaussian game with\narbitrary quadratic material welfare and convex information costs. First, the\npolicymaker knows the cost of private information and adopts an optimal\ndisclosure rule to maximize the expected welfare. Second, the policymaker is\nuncertain about the cost and adopts a robust disclosure rule to maximize the\nworst-case welfare. Depending on the elasticity of marginal cost, an optimal\nrule is qualitatively the same as that in the case of either a linear\ninformation cost or exogenous private information. The worst-case welfare is\nstrictly increasing if and only if full disclosure is optimal under some\ninformation costs, which provides a new rationale for central bank\ntransparency.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.16809v2"
    },
    {
        "title": "Insuring uninsurable income",
        "authors": [
            "Michiko Ogaku"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper presents a method to avoid the ominous prediction of the previous\nwork: if insured incomes of infinitely lived individuals are unobservable, then\nefficient allocations lead to permanent welfare inequality between individuals\nand immiseration of society. This paper proposes a mechanism that (i) promises\nwithin-period full insurance by postponing risks ; (ii) does not lead to social\nranking among the same age groups; and (iii) could be sustainable.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00347v11"
    },
    {
        "title": "Simple dominance of fixed priority top trading cycles",
        "authors": [
            "Pinaki Mandal"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the implementation of fixed priority top trading cycles (FPTTC)\nrules via simply dominant mechanisms (Pycia and Troyan, 2019) in the context of\nassignment problems, where agents are to be assigned at most one indivisible\nobject and monetary transfers are not allowed. We consider both models - with\nand without outside options, and characterize all simply dominant FPTTC rules\nin both models. We further introduce the notion of simple strategy-proofness to\nresolve the issue with agents being concerned about having time-inconsistent\npreferences, and discuss its relation with simple dominance.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.02154v3"
    },
    {
        "title": "Causal Discovery of Macroeconomic State-Space Models",
        "authors": [
            "Emmet Hall-Hoffarth"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper presents a set of tests and an algorithm for agnostic, data-driven\nselection among macroeconomic DSGE models inspired by structure learning\nmethods for DAGs. As the log-linear state-space solution to any DSGE model is\nalso a DAG it is possible to use associated concepts to identify a unique\nground-truth state-space model which is compatible with an underlying DGP,\nbased on the conditional independence relationships which are present in that\nDGP. In order to operationalise search for this ground-truth model, the\nalgorithm tests feasible analogues of these conditional independence criteria\nagainst the set of combinatorially possible state-space models over observed\nvariables. This process is consistent in large samples. In small samples the\nresult may not be unique, so conditional independence tests can be combined\nwith likelihood maximisation in order to select a single optimal model. The\nefficacy of this algorithm is demonstrated for simulated data, and results for\nreal data are also provided and discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.02374v1"
    },
    {
        "title": "Finding all stable matchings with assignment constraints",
        "authors": [
            "Gregory Gutin",
            "Philip R. Neary",
            "Anders Yeo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper we consider stable matchings subject to assignment constraints.\nThese are matchings that require certain assigned pairs to be included, insist\nthat some other assigned pairs are not, and, importantly, are stable. Our main\ncontribution is an algorithm, based on the iterated deletion of unattractive\nalternatives, that determines if assignment constraints are compatible with\nstability. Whenever there is a stable matching that satisfies the assignment\nconstraints, our algorithm outputs all of them (each in polynomial time per\nsolution). This provides market designers with (i) a tool to test the\nfeasibility of stable matchings subject to assignment constraints, and (ii) a\ntool to implement them when feasible.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.03989v4"
    },
    {
        "title": "On Locally Rationalizable Social Choice Functions",
        "authors": [
            "Felix Brandt",
            "Chris Dong"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider a notion of rationalizability, where the rationalizing relation\nmay depend on the set of feasible alternatives. More precisely, we say that a\nchoice function is locally rationalizable if it is rationalized by a family of\nrationalizing relations such that a strict preference between two alternatives\nin some feasible set is preserved when removing other alternatives. Tyson\n(2008) has shown that a choice function is locally rationalizable if and only\nif it satisfies Sen's $\\gamma$. We expand the theory of local rationalizability\nby proposing a natural strengthening of $\\gamma$ that precisely characterizes\nlocal rationalizability via PIP-transitive relations and by introducing the\n$\\gamma$-hull of a choice function as its finest coarsening that satisfies\n$\\gamma$. Local rationalizability permits a unified perspective on social\nchoice functions that satisfy $\\gamma$, including classic ones such as the top\ncycle and the uncovered set as well as new ones such as two-stage majoritarian\nchoice and split cycle. We give simple axiomatic characterizations of some of\nthese using local rationalizability and propose systematic procedures to define\nsocial choice functions that satisfy $\\gamma$.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.05062v3"
    },
    {
        "title": "Inference from Selectively Disclosed Data",
        "authors": [
            "Ying Gao"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider the disclosure problem of a sender with a large data set of hard\nevidence who wants to persuade a receiver to take higher actions. Because the\nreceiver will make inferences based on the distribution of the data they see,\nthe sender has an incentive to drop observations to mimic the distributions\nthat would be observed under better states. We predict which observations the\nsender discloses using a model that approximates large datasets with a\ncontinuum of data. It is optimal for the sender to play an imitation strategy,\nunder which they submit evidence that imitates the natural distribution under\nsome more desirable target state. We characterize the partial-pooling outcomes\nunder these imitation strategies, and show that they are supported by data on\nthe outcomes that maximally distinguish higher states. Relative to full\ninformation, the equilibrium with voluntary disclosure reduces the welfare of\nsenders with little data or a favorable state, who fully disclose their data\nbut suffer the receiver's skepticism, and benefits senders with access to large\ndatasets, who can profitably drop observations under low states.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.07191v3"
    },
    {
        "title": "Nonparametric Analysis of Dynamic Random Utility Models",
        "authors": [
            "Nail Kashaev",
            "Victor H. Aguiar"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a dynamic generalization of stochastic rationality in consumer\nbehavior, the Dynamic Random Utility Model (DRUM). Under DRUM, a consumer draws\na utility function from a stochastic utility process and maximizes this utility\nsubject to her budget constraint in each time period. Utility is random, with\nunrestricted correlation across time periods and unrestricted heterogeneity in\na cross-section. We provide a revealed preference characterization of DRUM when\nwe observe a panel of choices from budgets. This characterization is amenable\nto statistical testing. Our result unifies Afriat's (1967) theorem that works\nwith time-series data and the static random utility framework of\nMcFadden-Richter (1990) that works with cross-sections of choice.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.07220v1"
    },
    {
        "title": "The cost of strategy-proofness in school choice",
        "authors": [
            "Josue Ortega",
            "Thilo Klein"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We compare the outcomes of the most prominent strategy-proof and stable\nalgorithm (Deferred Acceptance, DA) and the most prominent strategy-proof and\nPareto optimal algorithm (Top Trading Cycles, TTC) to the allocation generated\nby the rank-minimizing mechanism (RM). While one would expect that RM improves\nupon both DA and TTC in terms of rank efficiency, the size of the improvement\nis nonetheless surprising. Moreover, while it is not explicitly designed to do\nso, RM also significantly improves the placement of the worst-off student.\nFurthermore, RM generates less justified envy than TTC. We corroborate our\nfindings using data on school admissions in Budapest.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.07255v6"
    },
    {
        "title": "The comparative statics of persuasion",
        "authors": [
            "Gregorio Curello",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In the persuasion model, apart from a few special cases, comparative statics\nhas been an open question. We answer it, delineating which shifts of the\nsender's interim payoff lead her optimally to choose a more informative signal.\nOur first theorem identifies a coarse notion of 'increased convexity' that we\nshow characterises those shifts of the sender's interim payoff that lead her\noptimally to choose no less informative signals. To strengthen this conclusion\nto 'more informative' requires further assumptions: our second theorem\nidentifies the necessary and sufficient condition on the sender's interim\npayoff, which strictly generalises the convex-concave ('S') shape commonly\nimposed in the literature. We identify conditions under which increased\nalignment of interests between sender and receiver leads to comparative\nstatics, and study a number of applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.07474v6"
    },
    {
        "title": "Eigen mode selection in human subject game experiment",
        "authors": [
            "Zhijian Wang",
            "Qinmei Yao",
            "Yijia Wang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Eigen mode selection ought to be a practical issue in some real game systems,\nas it is a practical issue in the dynamics behaviour of a building, bridge, or\nmolecular, because of the mathematical similarity in theory. However, its\nreality and accuracy have not been known in real games. We design a 5-strategy\ngame which, in the replicator dynamics theory, is predicted to exist two eigen\nmodes. Further, in behaviour game theory, the game is predicted that the mode\nselection should depends on the game parameter. We conduct human subject game\nexperiments by controlling the parameter. The data confirm that, the\npredictions on the mode existence as well as the mode selection are\nsignificantly supported. This finding suggests that, like the equilibrium\nselection concept in classical game theory, eigen mode selection is an issue in\ngame dynamics theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08071v1"
    },
    {
        "title": "Axiomatic Characterizations of Draft Rules",
        "authors": [
            "Jacob Coreno",
            "Ivan Balbuzanov"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Drafts are sequential allocation procedures for distributing heterogeneous\nand indivisible objects among agents subject to some priority order (e.g.,\nallocating players' contract rights to teams in professional sports leagues).\nAgents report ordinal preferences over objects and bundles are partially\nordered by pairwise comparison. We provide a simple characterization of draft\nrules: they are the only allocation rules which are respectful of a priority\n(RP), envy-free up to one object (EF1), non-wasteful (NW) and resource\nmonotonic (RM). RP and EF1 are crucial for competitive balance in sports\nleagues. We also prove three related impossibility theorems showing that the\ncompetitive-balance axioms RP and EF1 are generally incompatible with\nstrategy-proofness. However, draft rules satisfy maxmin strategy-proofness. If\nagents may declare some objects unacceptable, then draft rules are\ncharacterized by RP, EF1, NW, and RM, in conjunction with individual\nrationality and truncation invariance. In a model with variable populations,\ndraft rules are characterized by EF1, EFF, and RM, together with (population)\nconsistency, top-object consistency, and neutrality.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08300v6"
    },
    {
        "title": "Markovian Persuasion with Stochastic Revelations",
        "authors": [
            "Ehud Lehrer",
            "Dimitry Shaiderman"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In the classical Bayesian persuasion model an informed player and an\nuninformed one engage in a static interaction. The informed player, the sender,\nknows the state of nature, while the uninformed one, the receiver, does not.\nThe informed player partially shares his private information with the receiver\nand the latter then, based on her belief about the state, takes an action. This\naction, together with the state of nature, determines the utility of both\nplayers. This paper analyzes a dynamic Bayesian persuasion model where the\nstate of nature evolves according to a Markovian law. Here, the sender always\nknows the realized state, while the receiver randomly gets to know it. We\ndiscuss the value of the sender when he becomes more and more patient and its\nrelation to the revelation rate, namely the probability at which the true state\nis revealed to the receiver at any stage.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08659v2"
    },
    {
        "title": "Data Provision to an Informed Seller",
        "authors": [
            "Shota Ichihashi",
            "Alex Smolin"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A monopoly seller is privately and imperfectly informed about the buyer's\nvalue of the product. The seller uses information to price discriminate the\nbuyer. A designer offers a mechanism that provides the seller with additional\ninformation based on the seller's report about her type. We establish the\nimpossibility of screening for welfare purposes, i.e., the designer can attain\nany implementable combination of buyer surplus and seller profit by providing\nthe same signal to all seller types. We use this result to characterize the set\nof implementable welfare outcomes, study the seller's incentive to acquire\nthird-party data, and demonstrate the trade-off between buyer surplus and\nefficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08723v2"
    },
    {
        "title": "Semantics meets attractiveness: Choice by salience",
        "authors": [
            "Alfio Giarlotta",
            "Angelo Petralia",
            "Stephen Watson"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We describe a context-sensitive model of choice, in which the selection\nprocess is shaped not only by the attractiveness of items but also by their\nsemantics ('salience'). All items are ranked according to a relation of\nsalience, and a linear order is associated to each item. The selection of a\nsingle element from a menu is justified by one of the linear orders indexed by\nthe most salient items in the menu. The general model provides a structured\nexplanation for any observed behavior, and allows us to to model the\n'moodiness' of a decision maker, which is typical of choices requiring as many\ndistinct rationales as items. Asymptotically all choices are moody. We single\nout a model of linear salience, in which the salience order is transitive and\ncomplete, and characterize it by a behavioral property, called WARP(S). Choices\nrationalizable by linear salience can only exhibit non-conflicting violations\nof WARP. We also provide numerical estimates, which show the high selectivity\nof this testable model of bounded rationality.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08798v2"
    },
    {
        "title": "On the Robustness of Second-Price Auctions in Prior-Independent\n  Mechanism Design",
        "authors": [
            "Jerry Anunrojwong",
            "Santiago R. Balseiro",
            "Omar Besbes"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Classical Bayesian mechanism design relies on the common prior assumption,\nbut such prior is often not available in practice. We study the design of\nprior-independent mechanisms that relax this assumption: the seller is selling\nan indivisible item to $n$ buyers such that the buyers' valuations are drawn\nfrom a joint distribution that is unknown to both the buyers and the seller;\nbuyers do not need to form beliefs about competitors, and the seller assumes\nthe distribution is adversarially chosen from a specified class. We measure\nperformance through the worst-case regret, or the difference between the\nexpected revenue achievable with perfect knowledge of buyers' valuations and\nthe actual mechanism revenue.\n  We study a broad set of classes of valuation distributions that capture a\nwide spectrum of possible dependencies: independent and identically distributed\n(i.i.d.) distributions, mixtures of i.i.d. distributions, affiliated and\nexchangeable distributions, exchangeable distributions, and all joint\ndistributions. We derive in quasi closed form the minimax values and the\nassociated optimal mechanism. In particular, we show that the first three\nclasses admit the same minimax regret value, which is decreasing with the\nnumber of competitors, while the last two have the same minimax regret equal to\nthat of the single buyer case. Furthermore, we show that the minimax optimal\nmechanisms have a simple form across all settings: a second-price auction with\nrandom reserve prices, which shows its robustness in prior-independent\nmechanism design. En route to our results, we also develop a principled\nmethodology to determine the form of the optimal mechanism and worst-case\ndistribution via first-order conditions that should be of independent interest\nin other minimax problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.10478v5"
    },
    {
        "title": "Dynamic screening",
        "authors": [
            "David Lagziel",
            "Ehud Lehrer"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study dynamic screening problems where elements are subjected to noisy\nevaluations and, in every stage, some of the elements are rejected while the\nremaining ones are independently re-evaluated in subsequent stages. We prove\nthat, ceteris paribus, the quality of a dynamic screening process is not\nmonotonic in the number of stages. Specifically, we examine the accepted\nelements' values and show that adding a single stage to a screening process may\nproduce inferior results, in terms of stochastic dominance, whereas increasing\nthe number of stages substantially leads to a first-best outcome.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.13392v1"
    },
    {
        "title": "Auctioning Multiple Goods without Priors",
        "authors": [
            "Wanchang Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I consider a mechanism design problem of selling multiple goods to multiple\nbidders when the designer has minimal amount of information. I assume that the\ndesigner only knows the upper bounds of bidders' values for each good and has\nno additional distributional information. The designer takes a minimax regret\napproach. The expected regret from a mechanism given a joint distribution over\nvalue profiles and an equilibrium is defined as the difference between the full\nsurplus and the expected revenue. The designer seeks a mechanism, referred to\nas a minimax regret mechanism, that minimizes her worst-case expected regret\nacross all possible joint distributions over value profiles and all equilibria.\nI find that a separate second-price auction with random reserves is a minimax\nregret mechanism for general upper bounds. Under this mechanism, the designer\nholds a separate auction for each good; the formats of these auctions are\nsecond-price auctions with random reserves.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.13726v1"
    },
    {
        "title": "Improving the Deferred Acceptance with Minimal Compromise",
        "authors": [
            "Mustafa Oguz Afacan",
            "Umut Dur",
            "A. Arda Gitmez",
            "Özgür Yılmaz"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In school choice problems, the motivation for students' welfare (efficiency)\nis restrained by concerns to respect schools' priorities (fairness). Among the\nfair matchings, even the best one in terms of welfare (SOSM) is inefficient.\nMoreover, any mechanism that improves welfare over the SOSM is manipulable by\nthe students. First, we characterize the \"least manipulable\" mechanisms in this\nclass: monotonically-promoting transformation proofness ensures that no student\nis better off by promoting their assigned school under the true preferences.\nSecond, we use the notion that a matching is less unfair if it yields a smaller\nset of students whose priorities are violated, and define minimal unfairness\naccordingly. We then show that the Efficiency Adjusted Deferred Acceptance\n(EADA) mechanism is minimally unfair in the class of efficient and\nmonotonically-promoting transformation proof mechanisms. When the objective is\nto improve students' welfare over the SOSM, this characterization implies an\nimportant insight into the frontier of the main axioms in school choice.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00032v3"
    },
    {
        "title": "Mentors and Recombinators: Multi-Dimensional Social Learning",
        "authors": [
            "Srinivas Arigapudi",
            "Omer Edhan",
            "Yuval Heller",
            "Ziv Hellman"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study games in which the set of strategies is multi-dimensional, and new\nagents might learn various strategic dimensions from different mentors. We\nintroduce a new family of dynamics, the recombinator dynamics, which is\ncharacterised by a single parameter, the recombination rate r in [0,1]. The\ncase of r = 0 coincides with the standard replicator dynamics. The opposite\ncase of r = 1 corresponds to a setup in which each new agent learns each new\nstrategic dimension from a different mentor, and combines these dimensions into\nher adopted strategy. We fully characterise stationary states and stable states\nunder these dynamics, and we show that they predict novel behaviour in various\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00278v2"
    },
    {
        "title": "Strategic Behavior under Context Misalignment",
        "authors": [
            "Pierfrancesco Guarino",
            "Gabriel Ziegler"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the behavioral implications of Rationality and Common Strong Belief\nin Rationality (RCSBR) with contextual assumptions allowing players to\nentertain misaligned beliefs, i.e., players can hold beliefs concerning their\nopponents' beliefs where there is no opponent holding those very beliefs.\nTaking the analysts' perspective, we distinguish the infinite hierarchies of\nbeliefs actually held by players (\"real types\") from those that are a byproduct\nof players' hierarchies (\"imaginary types\") by introducing the notion of\nseparating type structure. We characterize the behavioral implications of RCSBR\nfor the real types across all separating type structures via a family of\nsubsets of Full Strong Best-Reply Sets of Battigalli & Friedenberg (2012). By\nallowing misalignment, in dynamic games we can obtain behavioral predictions\ninconsistent with RCSBR (in the standard framework), contrary to the case of\nbelief-based analyses for static games--a difference due to the dichotomy\n\"non-monotonic vs. monotonic\" reasoning.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00564v1"
    },
    {
        "title": "A Model of Financial Market Control",
        "authors": [
            "Yoshihiro Ohashi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This study investigates the prevention of market manipulation using a\nprice-impact model of financial market trading as a linear system. First, I\ndefine a trading game between speculators such that they implement a\nmanipulation trading strategy that exploits momentum traders. Second, I\nidentify market intervention by a controller (e.g., a central bank) with a\ncontrol of the system. The main result shows that there is a control strategy\nthat prevents market manipulation as a subgame perfect equilibrium outcome of\nthe trading game. On the equilibrium path, no intervention is realized. This\nstudy also characterizes the set of manipulation-proof linear pricing rules of\nthe system. The set is very restrictive if there is no control, while the\npresence of control drastically expands the set.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.01260v1"
    },
    {
        "title": "Integration of Behavioral Economic Models to Optimize ML performance and\n  interpretability: a sandbox example",
        "authors": [
            "Emilio Soria-Olivas",
            "José E. Vila Gisbert",
            "Regino Barranquero Cardeñosa",
            "Yolanda Gomez"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper presents a sandbox example of how the integration of models\nborrowed from Behavioral Economic (specifically Protection-Motivation Theory)\ninto ML algorithms (specifically Bayesian Networks) can improve the performance\nand interpretability of ML algorithms when applied to Behavioral Data. The\nintegration of Behavioral Economics knowledge to define the architecture of the\nBayesian Network increases the accuracy of the predictions in 11 percentage\npoints. Moreover, it simplifies the training process, making unnecessary\ntraining computational efforts to identify the optimal structure of the\nBayesian Network. Finally, it improves the explicability of the algorithm,\navoiding illogical relations among variables that are not supported by previous\nbehavioral cybersecurity literature. Although preliminary and limited to 0ne\nsimple model trained with a small dataset, our results suggest that the\nintegration of behavioral economics and complex ML models may open a promising\nstrategy to improve the predictive power, training costs and explicability of\ncomplex ML models. This integration will contribute to solve the scientific\nissue of ML exhaustion problem and to create a new ML technology with relevant\nscientific, technological and market implications.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.01387v1"
    },
    {
        "title": "A counter example to the theorems of social preference transitivity and\n  social choice set existence under the majority rule",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I present an example in which the individuals' preferences are strict\norderings, and under the majority rule, a transitive social ordering can be\nobtained and thus a non-empty choice set can also be obtained. However, the\nindividuals' preferences in that example do not satisfy any conditions\n(restrictions) of which at least one is required by Inada (1969) for social\npreference transitivity under the majority rule. Moreover, the considered\nindividuals' preferences satisfy none of the conditions of value restriction\n(VR), extremal restriction (ER) or limited agreement (LA), some of which is\nrequired by Sen and Pattanaik (1969) for the existence of a non-empty social\nchoice set. Therefore, the example is an exception to a number of theorems of\nsocial preference transitivity and social choice set existence under the\nmajority rule. This observation indicates that the collection of the conditions\nlisted by Inada (1969) is not as complete as might be supposed. This is also\nthe case for the collection of conditions VR, ER and LA considered by Sen and\nPattanaik (1969). This observation is a challenge to some necessary conditions\nin the current social choice theory. In addition to seeking new conditions, one\npossible way to deal with this challenge may be, from a theoretical\nprospective, to represent the identified conditions (such as the VR, ER and LA)\nin terms of a common mathematical tool, and then, people may find more.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.02040v2"
    },
    {
        "title": "Knowledge is non-fungible",
        "authors": [
            "César A. Hidalgo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  What would you do if you were asked to \"add\" knowledge? Would you say that\n\"one plus one knowledge\" is two \"knowledges\"? Less than that? More? Or\nsomething in between? Adding knowledge sounds strange, but it brings to the\nforefront questions that are as fundamental as they are eclectic. These are\nquestions about the nature of knowledge and about the use of mathematics to\nmodel reality. In this chapter, I explore the mathematics of adding knowledge\nstarting from what I believe is an overlooked but key observation: the idea\nthat knowledge is non-fungible.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.02167v1"
    },
    {
        "title": "Comment on Jackson and Sonnenschein (2007) \"Overcoming Incentive\n  Constraints by Linking Decisions\"",
        "authors": [
            "Ian Ball",
            "Matt O. Jackson",
            "Deniz Kattwinkel"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We correct a bound in the definition of approximate truthfulness used in the\nbody of the paper of Jackson and Sonnenschein (2007). The proof of their main\ntheorem uses a different permutation-based definition, implicitly claiming that\nthe permutation-version implies the bound-based version. We show that this\nclaim holds only if the bound is loosened. The new bound is still strong enough\nto guarantee that the fraction of lies vanishes as the number of problems\ngrows, so the theorem is correct as stated once the bound is loosened.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.03352v1"
    },
    {
        "title": "Credible Persuasion",
        "authors": [
            "Xiao Lin",
            "Ce Liu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We propose a new notion of credibility for Bayesian persuasion problems. A\ndisclosure policy is credible if the sender cannot profit from tampering with\nher messages while keeping the message distribution unchanged. We show that the\ncredibility of a disclosure policy is equivalent to a cyclical monotonicity\ncondition on its induced distribution over states and actions. We also\ncharacterize how credibility restricts the Sender's ability to persuade under\ndifferent payoff structures. In particular, when the sender's payoff is\nstate-independent, all disclosure policies are credible. We apply our results\nto the market for lemons, and show that no useful information can be credibly\ndisclosed by the seller, even though a seller who can commit to her disclosure\npolicy would perfectly reveal her private information to maximize profit.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.03495v1"
    },
    {
        "title": "International cooperation and competition in orbit-use management",
        "authors": [
            "Aditya Jain",
            "Akhil Rao"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Orbit-use management efforts can be structured as binding national regulatory\npolicies or as self-enforcing international treaties. New treaties to control\nspace debris growth appear unlikely in the near future. Spacefaring nations can\npursue national regulatory policies, though regulatory competition and open\naccess to orbit make their effectiveness unclear. We develop a game-theoretic\nmodel of national regulatory policies and self-enforcing international treaties\nfor orbit-use management in the face of open access, regulatory competition,\nand catastrophe. While open access limits the effectiveness of national\npolicies, market-access control ensures the policies can improve environmental\nquality. A large enough stock of legacy debris ensures existence of a global\nregulatory equilibrium where all nations choose to levy environmental\nregulations on all satellites. The global regulatory equilibrium supports a\nself-enforcing treaty to avert catastrophe by making it costlier to leave the\ntreaty and free ride.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.03926v2"
    },
    {
        "title": "Information-Robust Optimal Auctions",
        "authors": [
            "Wanchang Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A single unit of a good is sold to one of two bidders. Each bidder has either\na high prior valuation or a low prior valuation for the good. Their prior\nvaluations are independently and identically distributed. Each bidder may\nobserve an independently and identically distributed signal about her prior\nvaluation. The seller knows the distribution of the prior valuation profile and\nknows that signals are independently and identically distributed, but does not\nknow the signal distribution. In addition, the seller knows that bidders play\nundominated strategies. I find that a second-price auction with a random\nreserve maximizes the worst-case expected revenue over all possible signal\ndistributions and all equilibria in undominated strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04137v1"
    },
    {
        "title": "Pricing with algorithms",
        "authors": [
            "Rohit Lamba",
            "Sergey Zhuk"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies Markov perfect equilibria in a repeated duopoly model\nwhere sellers choose algorithms. An algorithm is a mapping from the\ncompetitor's price to own price. Once set, algorithms respond quickly.\nCustomers arrive randomly and so do opportunities to revise the algorithm. In\nthe simple game with two possible prices, monopoly outcome is the unique\nequilibrium for standard functional forms of the profit function. More\ngenerally, with multiple prices, exercise of market power is the rule -- in all\nequilibria, the expected payoff of both sellers is above the competitive\noutcome, and that of at least one seller is close to or above the monopoly\noutcome. Sustenance of such collusion seems outside the scope of standard\nantitrust laws for it does not involve any direct communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04661v2"
    },
    {
        "title": "The Limits of Limited Commitment",
        "authors": [
            "Jacopo Bizzotto",
            "Toomas Hinnosaar",
            "Adrien Vigier"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study limited strategic leadership. A collection of subsets covering the\nleader's action space determines her commitment opportunities. We characterize\nthe outcomes resulting from all possible commitment structures of this kind. If\nthe commitment structure is an interval partition, then the leader's payoff is\nbounded by her Stackelberg and Cournot payoffs. However, under more general\ncommitment structures the leader may obtain a payoff that is less than her\nminimum Cournot payoff. We apply our results to study information design\nproblems in leader-follower games where a mediator communicates information\nabout the leader's action to the follower.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05546v4"
    },
    {
        "title": "Two-sided matching with firms' complementary preferences",
        "authors": [
            "Chao Huang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies two-sided many-to-one matching in which firms have\ncomplementary preferences. We show that stable matchings exist under a\nbalancedness condition that rules out a specific type of odd-length cycles\nformed by firms' acceptable sets. We also provide a class of preference\nprofiles that satisfy this condition. Our results indicate that stable matching\nis compatible with a wide range of firms' complementary preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05599v2"
    },
    {
        "title": "Recent Contributions to Theories of Discrimination",
        "authors": [
            "Paula Onuchic"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper surveys the literature on theories of discrimination, focusing\nmainly on new contributions. Recent theories expand on the traditional\ntaste-based and statistical discrimination frameworks by considering specific\nfeatures of learning and signaling environments, often using novel information-\nand mechanism-design language; analyzing learning and decision making by\nalgorithms; and introducing agents with behavioral biases and misspecified\nbeliefs. This survey also attempts to narrow the gap between the economic\nperspective on ``theories of discrimination'' and the broader study of\ndiscrimination in the social science literature. In that respect, I first\ncontribute by identifying a class of models of discriminatory institutions,\nmade up of theories of discriminatory social norms and discriminatory\ninstitutional design. Second, I discuss issues relating to the measurement of\ndiscrimination, and the classification of discrimination as bias or\nstatistical, direct or systemic, and accurate or inaccurate.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05994v3"
    },
    {
        "title": "The Value of Information in Stopping Problems",
        "authors": [
            "Ehud Lehrer",
            "Tao Wang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider stopping problems in which a decision maker (DM) faces an unknown\nstate of nature and decides sequentially whether to stop and take an\nirreversible action; pay a fee and obtain additional information; or wait\nwithout acquiring information. We discuss the value and quality of information.\nThe former is the maximal discounted expected revenue the DM can generate. We\nshow that among all history-dependent fee schemes, the upfront scheme (as\nopposed, for instance, to pay-for-use) is optimal: it generates the highest\npossible value of information. The effects on the optimal strategy of obtaining\ninformation from a more accurate source and of having a higher discount factor\nare distinct, as far as expected stopping time and its distribution are\nconcerned. However, these factors have a similar effect in that they both\nenlarge the set of cases in which the optimal strategy prescribes waiting.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.06583v1"
    },
    {
        "title": "Statistical discrimination and statistical informativeness",
        "authors": [
            "Matteo Escudé",
            "Paula Onuchic",
            "Ludvig Sinander",
            "Quitzé Valenzuela-Stookey"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the link between Phelps-Aigner-Cain-type statistical discrimination\nand familiar notions of statistical informativeness. Our central insight is\nthat Blackwell's Theorem, suitably relabeled, characterizes statistical\ndiscrimination in terms of statistical informativeness. This delivers one-half\nof Chambers and Echenique's (2021) characterization of statistical\ndiscrimination as a corollary, and suggests a different interpretation of it:\nthat discrimination is inevitable. In addition, Blackwell's Theorem delivers a\nnumber of finer-grained insights into the nature of statistical discrimination.\nWe argue that the discrimination-informativeness link is quite general,\nillustrating with an informativeness characterization of a different type of\ndiscrimination.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.07128v2"
    },
    {
        "title": "Reformulating the Value Restriction and the Not-Strict Value Restriction\n  in Terms of Possibility Preference Map",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In social choice theory, Sen's value restriction and Pattanaik's not-strict\nvalue restriction are both attractive conditions for testing social preference\ntransitivity and/or non-empty social choice set existence. This article\nintroduces a novel mathematical representation tool, called possibility\npreference map (PPM), for weak orderings, and then reformulates the value\nrestriction and the not-strict value restriction in terms of PPM. The\nreformulations all appear elegant since they take the form of minmax.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.07400v1"
    },
    {
        "title": "Asymptotically stable matchings and evolutionary dynamics of preference\n  revelation games in marriage problems",
        "authors": [
            "Hidemasa Ishii",
            "Nariaki Nishino"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The literature on centralized matching markets often assumes that a true\npreference of each player is known to herself and fixed, but empirical evidence\ncasts doubt on its plausibility. To circumvent the problem, we consider\nevolutionary dynamics of preference revelation games in marriage problems. We\nformulate the asymptotic stability of a matching, indicating the dynamical\nrobustness against sufficiently small changes in players' preference reporting\nstrategies, and show that asymptotically stable matchings are stable when they\nexist. The simulation results of replicator dynamics are presented to\ndemonstrate the asymptotic stability. We contribute a practical insight for\nmarket designers that a stable matching may be realized by introducing a\nlearning period in which participants find appropriate reporting strategies\nthrough trial and error. We also open doors to a novel area of research by\ndemonstrating ways to employ evolutionary game theory in studies on centralized\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08079v1"
    },
    {
        "title": "Conditions for Social Preference Transitivity When Cycle Involved and A\n  $\\hat{O}\\mbox{-}\\hat{I}$ Framework",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We present some conditions for social preference transitivity under the\nmajority rule when the individual preferences include cycles. First, our\nconcern is with the restriction on the preference orderings of individuals\nexcept those (called cycle members) whose preferences constitute the cycles,\nbut the considered transitivity is, of course, of the society as a whole. In\nour discussion, the individual preferences are assumed concerned and the cycle\nmembers' preferences are assumed as strict orderings. Particularly, for an\nalternative triple when one cycle is involved and the society is sufficient\nlarge (at least 5 individuals in the society), we present a sufficient\ncondition for social transitivity; when two antagonistic cycles are involved\nand the society has at least 9 individuals, necessary and sufficient conditions\nare presented which are merely restricted on the preferences of those\nindividuals except the cycle members. Based on the work due to Slutsky (1977)\nand Gaertner \\& Heinecke (1978), we then outline a conceptual\n$\\hat{O}\\mbox{-}\\hat{I}$ framework of social transitivity in an axiomatic\nmanner. Connections between some already identified conditions and the\n$\\hat{O}\\mbox{-}\\hat{I}$ framework is examined.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08223v2"
    },
    {
        "title": "The Blocker Postulates for Measures of Voting Power",
        "authors": [
            "Arash Abizadeh",
            "Adrian Vetta"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A proposed measure of voting power should satisfy two conditions to be\nplausible: first, it must be conceptually justified, capturing the intuitive\nmeaning of what voting power is; second, it must satisfy reasonable postulates.\nThis paper studies a set of postulates, appropriate for a priori voting power,\nconcerning blockers (or vetoers) in a binary voting game. We specify and\nmotivate five such postulates, namely, two subadditivity blocker postulates,\ntwo minimum-power blocker postulates, each in weak and strong versions, and the\nadded-blocker postulate. We then test whether three measures of voting power,\nnamely the classic Penrose-Banzhaf measure, the classic Shapley-Shubik index,\nand the newly proposed Recursive Measure, satisfy these postulates. We find\nthat the first measure fails four of the postulates, the second fails two,\nwhile the third alone satisfies all five postulates. This work consequently\nadds to the plausibility of the Recursive Measure as a reasonable measure of\nvoting power.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08368v1"
    },
    {
        "title": "Marx after Okishio: Falling Rate of Profit with Constant Rate of\n  Exploitation",
        "authors": [
            "Deepankar Basu",
            "Oscar Orellana"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Can cost-reducing technical change lead to a fall in the long run rate of\nprofit if class struggle manages to keep the rate of exploitation constant? In\na general circulating capital model, we derive sufficient conditions for\ncost-reducing technical change to both keep the rate of exploitation constant\nand lead to a fall in the equilibrium rate of profit. Further, if the real wage\nbundle is such that the maximum price-value ratio is larger than 1 plus the\nrate of exploitation, then starting from any configuration of technology and\nreal wage, we can always find a viable, CU-LS technical change that satisfies\nthe sufficient conditions for the previous result. Taken together, these\nresults vindicate Marx's claim in Volume III of Capital, that if the rate of\nexploitation remains unchanged then viable, CU-LS technical change in\ncapitalist economies can lead to a fall in the long run rate of profit.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08956v2"
    },
    {
        "title": "Predicting Choice from Information Costs",
        "authors": [
            "Elliot Lipnowski",
            "Doron Ravid"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  An agent acquires a costly flexible signal before making a decision. We\nexplore to what degree knowledge of the agent's information costs helps predict\nher behavior. We establish an impossibility result: learning costs alone\ngenerate no testable restrictions on choice without also imposing constraints\non actions' state-dependent utilities. By contrast, choices from a menu often\nuniquely pin down the agent's decisions in all submenus. To prove the latter\nresult, we define iteratively differentiable cost functions, a tractable class\namenable to first-order techniques. Finally, we construct tight tests for a\nmulti-menu data set to be consistent with a given cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10434v2"
    },
    {
        "title": "A Simple Characterization of Supply Correspondences",
        "authors": [
            "Alexey Kushnir",
            "Vinod Krishnamoorthy"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We prove that supply correspondences are characterized by two properties: the\nlaw of supply and being homogeneous of degree zero.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10472v1"
    },
    {
        "title": "Information Design of Dynamic Mechanisms",
        "authors": [
            "Soo Hong Chew",
            "Wenqian Wang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Two dynamic game forms are said to be behaviorally equivalent if they share\nthe \"same\" profiles of structurally reduced strategies (Battigalli et al.,\n2020). In the context of dynamic implementation, behaviorally equivalent game\nforms are interchangeable under a wide range of solution concepts for the\npurpose of implementing a social choice function. A gradual mechanism (Chew and\nWang, 2022), which designs a procedure of information transmission mediated by\na central administrator, enables a formal definition of information flow. We\nprovide a characterization of behavioral equivalence between gradual mechanisms\nin terms of their informational equivalence -- each agent is designed the\n\"same\" information flow. Information flow also helps in defining an intuitive\nnotion of immediacy for gradual mechanisms which is equivalent to their game\nstructures being minimal. Given that the class of gradual mechanisms serves as\na revelation principle for dynamic implementation (Li, 2017; Akbarpour and Li,\n2020; Mackenzie, 2020; Chew and Wang, 2022), the class of immediate gradual\nmechanisms provides a refined revelation principle.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10844v1"
    },
    {
        "title": "Mechanisms without transfers for fully biased agents",
        "authors": [
            "Deniz Kattwinkel",
            "Axel Niemeyer",
            "Justus Preusser",
            "Alexander Winter"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A principal must decide between two options. Which one she prefers depends on\nthe private information of two agents. One agent always prefers the first\noption; the other always prefers the second. Transfers are infeasible. One\napplication of this setting is the efficient division of a fixed budget between\ntwo competing departments. We first characterize all implementable mechanisms\nunder arbitrary correlation. Second, we study when there exists a mechanism\nthat yields the principal a higher payoff than she could receive by choosing\nthe ex-ante optimal decision without consulting the agents. In the budget\nexample, such a profitable mechanism exists if and only if the information of\none department is also relevant for the expected returns of the other\ndepartment. We generalize this insight to derive necessary and sufficient\nconditions for the existence of a profitable mechanism in the n-agent\nallocation problem with independent types.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10910v1"
    },
    {
        "title": "Desirable Rankings: A New Method for Ranking Outcomes of a Competitive\n  Process",
        "authors": [
            "Thayer Morrill",
            "Peter Troyan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider the problem of aggregating individual preferences over\nalternatives into a social ranking. A key feature of the problems that we\nconsider - and the one that allows us to obtain positive results, in contrast\nto negative results such as Arrow's Impossibililty Theorem - is that the\nalternatives to be ranked are outcomes of a competitive process. Examples\ninclude rankings of colleges or academic journals. The foundation of our\nranking method is that alternatives that agents rank higher than the one they\nreceive (and thus have been rejected by) should also be ranked higher in the\naggregate ranking. We introduce axioms to formalize this idea, and call any\nranking that satisfies our axioms a desirable ranking. We show that as the\nmarket grows large, any desirable ranking coincides with the true underlying\nranking of colleges by quality. Last, we provide an algorithm for constructing\ndesirable rankings, and show that the outcome of this algorithm is the unique\nranking of the colleges that satisfy our axioms.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.11684v2"
    },
    {
        "title": "Incentive-compatible public transportation fares with random inspection",
        "authors": [
            "Inácio Bó",
            "Chiu Yu Ko"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider the problem of designing prices for public transport where\npayment enforcing is done through random inspection of passengers' tickets as\nopposed to physically blocking their access. Passengers are fully strategic\nsuch that they may choose different routes or buy partial tickets in their\noptimizing decision. We derive expressions for the prices that make every\npassenger choose to buy the full ticket. Using travel and pricing data from the\nWashington DC metro, we show that a switch to a random inspection method for\nticketing while keeping current prices could lead to more than 59% of revenue\nloss due to fare evasion, while adjusting prices to take incentives into\nconsideration would reduce that loss to less than 20%, without any increase in\nprices.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.11858v1"
    },
    {
        "title": "Statistical inference in social networks: how sampling bias and\n  uncertainty shape decisions",
        "authors": [
            "Andreas Bjerre-Nielsen",
            "Martin Benedikt Busch"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We investigate how individuals form expectations about population behavior\nusing statistical inference based on observations of their social relations.\nMisperceptions about others' connectedness and behavior arise from sampling\nbias stemming from the friendship paradox and uncertainty from small samples.\nIn a game where actions are strategic complements, we characterize the\nequilibrium and analyze equilibrium behavior. We allow for agent sophistication\nto account for the sampling bias and demonstrate how sophistication affects the\nequilibrium. We show how population behavior depends on both sources of\nmisperceptions and illustrate when sampling uncertainty plays a critical role\ncompared to sampling bias.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.13046v1"
    },
    {
        "title": "Asymmetric Equilibria in Symmetric Multiplayer Prisoners Dilemma\n  Supergames",
        "authors": [
            "Davidson Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We propose a finite automaton-style solution concept for supergames. In our\nmodel, we define an equilibrium to be a cycle of state switches and a supergame\nto be an infinite walk on states of a finite stage game. We show that if the\nstage game is locally non-cooperative, and the utility function is monotonously\ndecreasing as the number of defective agents increases, the symmetric\nmultiagent prisoners' dilemma supergame must contain one symmetric equilibrium\nand can contain asymmetric equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.13772v1"
    },
    {
        "title": "Content Filtering with Inattentive Information Consumers",
        "authors": [
            "Ian Ball",
            "James Bono",
            "Justin Grana",
            "Nicole Immorlica",
            "Brendan Lucier",
            "Aleksandrs Slivkins"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We develop a model of content filtering as a game between the filter and the\ncontent consumer, where the latter incurs information costs for examining the\ncontent. Motivating examples include censoring misinformation, spam/phish\nfiltering, and recommender systems. When the attacker is exogenous, we show\nthat improving the filter's quality is weakly Pareto improving, but has no\nimpact on equilibrium payoffs until the filter becomes sufficiently accurate.\nFurther, if the filter does not internalize the information costs, its lack of\ncommitment power may render it useless and lead to inefficient outcomes. When\nthe attacker is also strategic, improvements to filter quality may sometimes\ndecrease equilibrium payoffs.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.14060v4"
    },
    {
        "title": "Assortativity in cognition",
        "authors": [
            "Ennio Bilancini",
            "Leonardo Boncinelli",
            "Eugenio Vicario"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In pairwise interactions assortativity in cognition means that pairs where\nboth decision-makers use the same cognitive process are more likely to occur\nthan what happens under random matching. In this paper we study both the\nmechanisms determining assortativity in cognition and its effects. In\nparticular, we analyze an applied model where assortativity in cognition helps\nexplain the emergence of cooperation and the degree of prosociality of\nintuition and deliberation, which are the typical cognitive processes\npostulated by the dual process theory in psychology. Our findings rely on\nagent-based simulations, but analytical results are also obtained in a special\ncase. We conclude with examples showing that assortativity in cognition can\nhave different implications in terms of its societal desirability.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.15114v1"
    },
    {
        "title": "Uniqueness of Equilibria in Interactive Networks",
        "authors": [
            "Chien-Hsiang Yeh"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper extends the unified network model, proposed by Acemoglu et al.\n(2016b), such that interaction functions can be heterogeneous, and the\nsensitivity matrix has less than or equal to one spectral radius. We show the\nexistence and (almost surely) uniqueness of equilibrium under both eventually\ncontracting and noncontracting assumptions. Applying the equilibrium in the\nstudy of systemic risk, we provide a measure to determine the key player who\ncauses the most significant impact if removed from the network.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00158v1"
    },
    {
        "title": "Comparative statics with adjustment costs and the Le Chatelier principle",
        "authors": [
            "Eddie Dekel",
            "John K. -H. Quah",
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We develop a theory of monotone comparative statics for models with\nadjustment costs. We show that comparative-statics conclusions may be drawn\nunder the usual ordinal complementarity assumptions on the objective function,\nassuming very little about costs: only a mild monotonicity condition is\nrequired. We use this insight to prove a general Le Chatelier principle: under\nthe ordinal complementarity assumptions, if short-run adjustment is subject to\na monotone cost, then the long-run response to a shock is greater than the\nshort-run response. We extend these results to a fully dynamic model of\nadjustment over time: the Le Chatelier principle remains valid, and under\nslightly stronger assumptions, optimal adjustment follows a monotone path. We\napply our results to models of saving, production, pricing, labor supply and\ninvestment.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00347v5"
    },
    {
        "title": "Welfare and Distributional Effects of Joint Intervention in Networks",
        "authors": [
            "Ryan Kor",
            "Junjie Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a planner's optimal interventions in both the standalone marginal\nutilities of players on a network and weights on the links that connect\nplayers. The welfare-maximizing joint intervention exhibits the following\nproperties: (a) when the planner's budget is moderate (so that optimal\ninterventions are interior), the change in weight on any link connecting a pair\nof players is proportional to the product of eigen-centralities of the pair;\n(b) when the budget is sufficiently large, the optimal network takes a simple\nform: It is either a complete network under strategic complements or a complete\nbalanced bipartite network under strategic substitutes. We show that the\nwelfare effect of joint intervention is shaped by the principal eigenvalue,\nwhile the distributional effect is captured by the dispersion of the\ncorresponding eigenvalues, i.e., the eigen-centralities. Comparing joint\nintervention in our setting with single intervention solely on the standalone\nmarginal utilities, as studied by Galeotti et al. (2020), we find that joint\nintervention always yields a higher aggregate welfare, but may lead to greater\ninequality, which highlights a possible trade-off between the welfare and\ndistributional impacts of joint intervention.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.03863v1"
    },
    {
        "title": "Information Asymmetry and Search Intensity",
        "authors": [
            "Atabek Atayev"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The existing studies on consumer search agree that consumers are worse-off\nwhen they do not observe sellers' production marginal cost than when they do.\nIn this paper we challenge this conclusion. Employing a canonical model of\nsimultaneous search, we show that it may be favorable for consumer to not\nobserve the production marginal cost. The reason is that, in expectation,\nconsumer search more intensely when they do not know sellers' production\nmarginal cost than when they know it. More intense search imposes higher\ncompetitive pressure on sellers, which in turn benefits consumers through lower\nprices.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.04576v1"
    },
    {
        "title": "Discrimination in Heterogeneous Games",
        "authors": [
            "Annick Laruelle",
            "André Rocha"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper, we consider coordination and anti-coordination heterogeneous\ngames played by a finite population formed by different types of individuals\nwho fail to recognize their own type but do observe the type of their opponent.\nWe show that there exists symmetric Nash equilibria in which players\ndiscriminate by acting differently according to the type of opponent that they\nface in anti-coordination games, while no such equilibrium exists in\ncoordination games. Moreover, discrimination has a limit: the maximum number of\ngroups where the treatment differs is three. We then discuss the theoretical\nresults in light of the observed behavior of people in some specific\npsychological contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.05087v1"
    },
    {
        "title": "Classes of Aggregation Rules for Ethical Decision Making in Automated\n  Systems",
        "authors": [
            "Federico Fioravanti",
            "Iyad Rahwan",
            "Fernando Abel Tohmé"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a class of {\\em aggregation rules} that could be applied to ethical\nAI decision-making. These rules yield the decisions to be made by automated\nsystems based on the information of profiles of preferences over possible\nchoices. We consider two different but very intuitive notions of preferences of\nan alternative over another one, namely {\\it pairwise majority} and {\\it\nposition} dominance. Preferences are represented by permutation processes over\nalternatives and aggregation rules are applied to obtain results that are\nsocially considered to be ethically correct. In this setting, we find many\naggregation rules that satisfy desirable properties for an autonomous system.\nWe also address the problem of the stability of the aggregation process, which\nis important when the information is variable. These results are a contribution\nfor an AI designer that wants to justify the decisions made by an autonomous\nsystem.\\\\ \\textit{Keywords:} Aggregation Operators; Permutation Process;\nDecision Analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.05160v3"
    },
    {
        "title": "On the number of non-isomorphic choices on four elements",
        "authors": [
            "Alfio Giarlotta",
            "Angelo Petralia",
            "Stephen Watson"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We use a combinatorial approach to compute the number of non-isomorphic\nchoices on four elements that can be explained by models of bounded\nrationality.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.06840v1"
    },
    {
        "title": "On Existence of Berk-Nash Equilibria in Misspecified Markov Decision\n  Processes with Infinite Spaces",
        "authors": [
            "Robert M. Anderson",
            "Haosui Duanmu",
            "Aniruddha Ghosh",
            "M. Ali Khan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Model misspecification is a critical issue in many areas of theoretical and\nempirical economics. In the specific context of misspecified Markov Decision\nProcesses, Esponda and Pouzo (2021) defined the notion of Berk-Nash equilibrium\nand established its existence in the setting of finite state and action spaces.\nHowever, many substantive applications (including two of the three motivating\nexamples presented by Esponda and Pouzo, as well as Gaussian and log-normal\ndistributions, and CARA, CRRA and mean-variance preferences) involve continuous\nstate or action spaces, and are thus not covered by the Esponda-Pouzo existence\ntheorem. We extend the existence of Berk-Nash equilibrium to compact action\nspaces and sigma-compact state spaces, with possibly unbounded payoff\nfunctions. A complication arises because the Berk-Nash equilibrium notion\ndepends critically on Radon-Nikodym derivatives, which are necessarily bounded\nin the finite case but typically unbounded in misspecified continuous models.\nThe proofs rely on nonstandard analysis and, relative to previous applications\nof nonstandard analysis in economic theory, draw on novel argumentation\ntraceable to work of the second author on nonstandard representations of Markov\nprocesses.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.08437v3"
    },
    {
        "title": "Persuasion with Non-Linear Preferences",
        "authors": [
            "Anton Kolotilin",
            "Roberto Corrao",
            "Alexander Wolitzky"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In persuasion problems where the receiver's action is one-dimensional and his\nutility is single-peaked, optimal signals are characterized by duality, based\non a first-order approach to the receiver's problem. A signal is optimal iff\nthe induced joint distribution over states and actions is supported on a\ncompact set (the contact set) where the dual constraint binds. A signal that\npools at most two states in each realization is always optimal, and such\npairwise signals are the only solutions under a non-singularity condition on\nutilities (the twist condition). We provide conditions under which higher\nactions are induced at more or less extreme pairs of states. Finally, we\nprovide conditions for the optimality of either full disclosure or negative\nassortative disclosure, where signal realizations can be ordered from least to\nmost extreme. Optimal negative assortative disclosure is characterized as the\nsolution to a pair of ordinary differential equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09164v2"
    },
    {
        "title": "The Winner-Take-All Dilemma",
        "authors": [
            "Kazuya Kikuchi",
            "Yukio Koriyama"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider collective decision making when the society consists of groups\nendowed with voting weights. Each group chooses an internal rule that specifies\nthe allocation of its weight to the alternatives as a function of its members'\npreferences. Under fairly general conditions, we show that the winner-take-all\nrule is a dominant strategy, while the equilibrium is Pareto dominated,\nhighlighting the dilemma structure between optimality for each group and for\nthe whole society. We also develop a technique for asymptotic analysis and show\nPareto dominance of the proportional rule. Our numerical computation for the US\nElectoral College verifies its sensibility.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09574v1"
    },
    {
        "title": "Evolutionary rationality of risk preference",
        "authors": [
            "Songjia Fan",
            "Yi Tao",
            "Cong Li"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Selection shapes all kinds of behaviors, including how we make decisions\nunder uncertainty. The risk attitude reflected from it should be simple,\nflexible, yet consistent. In this paper we engaged evolutionary dynamics to\nfind the decision making rule concerning risk that is evolutionarily superior,\nand developed the theory of evolutionary rationality. We highlight the\nimportance of selection intensity and fitness, as well as their equivalents in\nthe human mind, named as attention degree and meta-fitness, in the decision\nmaking process. Evolutionary rationality targets the maximization of the\ngeometric mean of meta-fitness (or fitness), and attention degree (or selection\nintensity) holds the key in the change of attitude of the same individual\ntowards different events and under varied situations. Then as an example, the\nAllais paradox is presented to show the application of evolutionary\nrationality, in which the anomalous choices made by the majority of people can\nbe well justified by a simple change in the attention degree.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09813v1"
    },
    {
        "title": "Withholding Verifiable Information",
        "authors": [
            "Kun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I study a class of verifiable disclosure games where the sender's payoff is\nstate independent and the receiver's optimal action only depends on the\nexpected state. The sender's messages are verifiable in the sense that they can\nbe vague but can never be wrong. What is the sender's preferred equilibrium?\nWhen does the sender gain nothing from having commitment power? I identify\nconditions for an information design outcome to be an equilibrium outcome of\nthe verifiable disclosure game, and give simple sufficient conditions under\nwhich the sender does not benefit from commitment power. These results help in\ncharacterizing the sender's preferred equilibria and her equilibrium payoff set\nin a class of verifiable disclosure games. I apply these insights to study\ninfluencing voters and selling with quality disclosure.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09918v3"
    },
    {
        "title": "Mechanism Design Approaches to Blockchain Consensus",
        "authors": [
            "Joshua S. Gans",
            "Richard Holden"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Blockchain consensus is a state whereby each node in a network agrees on the\ncurrent state of the blockchain. Existing protocols achieve consensus via a\ncontest or voting procedure to select one node as a dictator to propose new\nblocks. However, this procedure can still lead to potential attacks that make\nconsensus harder to achieve or lead to coordination issues if multiple,\ncompeting chains (i.e., forks) are created with the potential that an\nuntruthful fork might be selected. We explore the potential for mechanisms to\nbe used to achieve consensus that are triggered when there is a dispute\nimpeding consensus. Using the feature that nodes stake tokens in proof of stake\n(POS) protocols, we construct revelation mechanisms in which the unique\n(subgame perfect) equilibrium involves validating nodes propose truthful blocks\nusing only the information that exists amongst all nodes. We construct\noperationally and computationally simple mechanisms under both Byzantine Fault\nTolerance and a Longest Chain Rule, and discuss their robustness to attacks.\nOur perspective is that the use of simple mechanisms is an unexplored area of\nblockchain consensus and has the potential to mitigate known trade-offs and\nenhance scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.10065v1"
    },
    {
        "title": "The lattice of envy-free many-to-many matchings with contracts",
        "authors": [
            "Agustin G. Bonifacio",
            "Nadia Guinazu",
            "Noelia Juarez",
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study envy-free allocations in a many-to-many matching model with\ncontracts in which agents on one side of the market (doctors) are endowed with\nsubstitutable choice functions and agents on the other side of the market\n(hospitals) are endowed with responsive preferences. Envy-freeness is a\nweakening of stability that allows blocking contracts involving a hospital with\na vacant position and a doctor that does not envy any of the doctors that the\nhospital currently employs. We show that the set of envy-free allocations has a\nlattice structure. Furthermore, we define a Tarski operator on this lattice and\nuse it to model a vacancy chain dynamic process by which, starting from any\nenvy-free allocation, a stable one is reached.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.10758v1"
    },
    {
        "title": "Non-Obvious Manipulability of the Rank-Minimizing Mechanism",
        "authors": [
            "Peter Troyan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In assignment problems, the rank distribution of assigned objects is often\nused to evaluate match quality. Rank-minimizing (RM) mechanisms directly\noptimize for average rank. While appealing, a drawback is RM mechanisms are not\nstrategyproof. This paper investigates whether RM satisfies the weaker\nincentive notion of non-obvious manipulability (NOM, Troyan and Morrill, 2020).\nI show any RM mechanism with full support - placing positive probability on all\nrank-minimizing allocations - is NOM. In particular, uniform randomization\nsatisfies this condition. Without full support, whether an RM mechanism is NOM\nor not depends on the details of the selection rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.11359v2"
    },
    {
        "title": "A core-selecting auction for portfolio's packages",
        "authors": [
            "Lamprirni Zarpala",
            "Dimitris Voliotis"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We introduce the \"local-global\" approach for a divisible portfolio and\nperform an equilibrium analysis for two variants of core-selecting auctions.\nOur main novelty is extending the Nearest-VCG pricing rule in a dynamic\ntwo-round setup, mitigating bidders' free-riding incentives and further\nreducing the sellers' costs. The two-round setup admits an\ninformation-revelation mechanism that may offset the \"winner's curse\", and it\nis in accord with the existing iterative procedure of combinatorial auctions.\nWith portfolio trading becoming an increasingly important part of investment\nstrategies, our mechanism contributes to increasing interest in portfolio\nauction protocols.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.11516v3"
    },
    {
        "title": "False Narratives and Political Mobilization",
        "authors": [
            "Kfir Eliaz",
            "Simone Galperti",
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We present an equilibrium model of politics in which political platforms\ncompete over public opinion. A platform consists of a policy, a coalition of\nsocial groups with diverse intrinsic attitudes to policies, and a narrative. We\nconceptualize narratives as subjective models that attribute a commonly valued\noutcome to (potentially spurious) postulated causes. When quantified against\nempirical observations, these models generate a shared belief among coalition\nmembers over the outcome as a function of its postulated causes. The intensity\nof this belief and the members' intrinsic attitudes to the policy determine the\nstrength of the coalition's mobilization. Only platforms that generate maximal\nmobilization prevail in equilibrium. Our equilibrium characterization\ndemonstrates how false narratives can be detrimental for the common good, and\nhow political fragmentation leads to their proliferation. The false narratives\nthat emerge in equilibrium attribute good outcomes to the exclusion of social\ngroups from ruling coalitions.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.12621v1"
    },
    {
        "title": "Spinoza, Leibniz, Kant, and Weyl",
        "authors": [
            "Michael H. Freedman"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The paper describes a funding mechanism called Quadratic Finance (QF) and\ndeploys a bit of calculus to show that within a very clean and simple linear\nmodel QF maximizes social utility. They differentiate the social utility\nfunction. The mathematical content of this note is that by taking one further\nderivative, one may also deduce that QF is the unique solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.14711v2"
    },
    {
        "title": "Engagement Maximization",
        "authors": [
            "Benjamin Hébert",
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a Bayesian agent receiving signals over time and then acting. The\nagent chooses when to stop and act, and prefers to act earlier all else equal.\nThe signals are determined by a principal, who maximizes engagement (the total\nattention paid by the agent). We show that engagement maximization minimizes\nthe agent's welfare, induces excessive information acquisition (relative to an\nagent-optimal benchmark), and leads to extreme beliefs. The principal optimally\nsends only \"suspensive signals\" that lead the agent to become \"less certain\nthan the prior\" and \"decisive signals\" that lead the agent to stop immediately.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00685v4"
    },
    {
        "title": "Inside the West Wing: Lobbying as a contest",
        "authors": [
            "Alastair Langtry"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  When a government makes many different policy decisions, lobbying can be\nviewed as a contest between the government and many different special interest\ngroups. The government fights lobbying by interest groups with its own\npolitical capital. In this world, we find that a government wants to `sell\nprotection' -- give favourable treatment in exchange for contributions -- to\ncertain interest groups. It does this in order to build its own `war chest' of\npolitical capital, which improves its position in fights with other interest\ngroups. And it does so until it wins all remaining contests with certainty.\nThis stands in contrast to existing models that often view lobbying as driven\nby information or agency problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00800v3"
    },
    {
        "title": "Reputation Effects under Short Memories",
        "authors": [
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I analyze a novel reputation game between a patient seller and a sequence of\nmyopic consumers, in which the consumers have limited memories and do not know\nthe exact sequence of the seller's actions. I focus on the case where each\nconsumer only observes the number of times that the seller took each of his\nactions in the last K periods. When payoffs are monotone-supermodular, I show\nthat the patient seller can approximately secure his commitment payoff in all\nequilibria as long as K is at least one. I also show that the consumers can\napproximately attain their first-best welfare in all equilibria if and only if\ntheir memory length K is lower than some cutoff. Although a longer memory\nenables more consumers to punish the seller once the seller shirks, it weakens\ntheir incentives to punish the seller once they observe him shirking\n",
        "pdf_link": "http://arxiv.org/pdf/2207.02744v4"
    },
    {
        "title": "Private Information Acquisition and Preemption: a Strategic Wald Problem",
        "authors": [
            "Guo Bai"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies a dynamic information acquisition model with payoff\nexternalities. Two players can acquire costly information about an unknown\nstate before taking a safe or risky action. Both information and the action\ntaken are private. The first player to take the risky action has an advantage\nbut whether the risky action is profitable depends on the state. The players\nface the tradeoff between being first and being right. In equilibrium, for\ndifferent priors, there exist three kinds of randomisation: when the players\nare pessimistic, they enter the competition randomly; when the players are less\npessimistic, they acquire information and then randomly stop; when the players\nare relatively optimistic, they randomly take an action without acquiring\ninformation.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.02898v1"
    },
    {
        "title": "Rawlsian Assignments",
        "authors": [
            "Tom Demeulemeester",
            "Juan S. Pereyra"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the assignment of indivisible goods to individuals without monetary\ntransfers. Previous literature has mainly focused on efficiency and\nindividually fair assignments; consequently, egalitarian concerns have been\noverlooked. Drawing inspiration from the allocation of apartments in housing\ncooperatives, where families prioritize egalitarianism in assignments, we\nintroduce the concept of Rawlsian assignment. We demonstrate the uniqueness,\nefficiency and anonymity of the Rawlsian rule. Our findings are validated using\ncooperative housing preference data, showing significant improvements in\negalitarian outcomes over both the probabilistic serial rule and the currently\nemployed rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.02930v6"
    },
    {
        "title": "Asset Trading in Continuous Time: A Cautionary Tale",
        "authors": [
            "William R. Zame"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The continuous time model of dynamic asset trading is the central model of\nmodern finance. Because trading cannot in fact take place at every moment of\ntime, it would seem desirable to show that the continuous time model can be\nviewed as the limit of models in which trading can occur only at (many)\ndiscrete moments of time. This paper demonstrates that, if we take terminal\nwealth constraints and self-financing constraints as seriously in the discrete\nmodel as in the continuous model, then the continuous trading model need not be\nthe limit of discrete trading models. This raises serious foundational\nquestions about the continuous time model.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.03397v1"
    },
    {
        "title": "A proposal for measuring the structure of economic ecosystems: a\n  mathematical and complex network analysis approach",
        "authors": [
            "M. S. Tedesco",
            "M. A. Nunez-Ochoa",
            "F. Ramos",
            "O. Medrano",
            "K Beuchot"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The benefits of using complex network analysis (CNA) to study complex\nsystems, such as an economy, have become increasingly evident in recent years.\nHowever, the lack of a single comparative index that encompasses the overall\nwellness of a structure can hinder the simultaneous analysis of multiple\necosystems. A formula to evaluate the structure of an economic ecosystem is\nproposed here, implementing a mathematical approach based on CNA metrics to\nconstruct a comparative measure that reflects the collaboration dynamics and\nits resultant structure. This measure provides the relevant actors with an\nenhanced sense of the social dynamics of an economic ecosystem, whether related\nto business, innovation, or entrepreneurship. Available graph metrics were\nanalysed, and 14 different formulas were developed. The efficiency of these\nformulas was evaluated on real networks from 11 different innovation-driven\nentrepreneurial economic ecosystems in six countries from Latin America and\nEurope and on 800 random graphs simulating similarly constructed networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.04346v1"
    },
    {
        "title": "Information Design in Cheap Talk",
        "authors": [
            "Qianjun Lyu",
            "Wing Suen"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  An uninformed sender publicly commits to an informative experiment about an\nuncertain state, privately observes its outcome, and sends a cheap-talk message\nto a receiver. We provide an algorithm valid for arbitrary state-dependent\npreferences that will determine the sender's optimal experiment and his\nequilibrium payoff under binary state space. We give sufficient conditions for\ninformative information transmission. These conditions depend more on marginal\nincentives -- how payoffs vary with the state -- than on the alignment of\nsender's and receiver's rankings over actions within a state. The algorithm can\nbe easily modified to study the canonical cheap talk game with a perfectly\ninformed sender.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.04929v3"
    },
    {
        "title": "Monotone Comparative Statics for Equilibrium Problems",
        "authors": [
            "Alfred Galichon",
            "Larry Samuelson",
            "Lucas Vernet"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We introduce a notion of substitutability for correspondences and establish a\nmonotone comparative static result, unifying results such as the inverse\nisotonicity of M-matrices, Berry, Gandhi and Haile's identification of demand\nsystems, monotone comparative statics, and results on the structure of the core\nof matching games without transfers (Gale and Shapley) and with transfers\n(Demange and Gale). More specifically, we introduce the notions of 'unified\ngross substitutes' and 'nonreversingness' and show that if Q is a supply\ncorrespondence defined on a set of prices P which is a sublattice of R^N, and Q\nsatisfies these two properties, then the set of prices yielding supply vector q\nis increasing (in the strong set order) in q; and it is a sublattice of P.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.06731v1"
    },
    {
        "title": "A Game-theoretic Model of the Consumer Behavior Under Pay-What-You-Want\n  Pricing Strategy",
        "authors": [
            "Vahid Ashrafimoghari",
            "Jordan W. Suchow"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In a digital age where companies face rapid changes in technology, consumer\ntrends, and business environments, there is a critical need for continual\nrevision of the business model in response to disruptive innovation. A pillar\nof innovation in business practices is the adoption of novel pricing schemes,\nsuch as Pay-What-You-Want (PWYW). In this paper, we employed game theory and\nbehavioral economics to model consumers' behavior in response to a PWYW pricing\nstrategy where there is an information asymmetry between the consumer and\nsupplier. In an effort to minimize the information asymmetry, we incorporated\nthe supplier's cost and the consumer's reference prices as two parameters that\nmight influence the consumer's payment decision. Our model shows that\nconsumers' behavior varies depending on the available information. As a result,\nwhen an external reference point is provided, the consumer tends to pay higher\namounts to follow the social herd or respect her self-image. However, the\nexternal reference price can also decrease her demand when, in the interest of\nfairness, she forgoes the purchase because the amount she is willing to pay is\nless that what she recognizes to be an unrecoverable cost to the supplier.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.08923v1"
    },
    {
        "title": "Symmetric reduced form voting",
        "authors": [
            "Xu Lang",
            "Debasis Mishra"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a model of voting with two alternatives in a symmetric environment.\nWe characterize the interim allocation probabilities that can be implemented by\na symmetric voting rule. We show that every such interim allocation\nprobabilities can be implemented as a convex combination of two families of\ndeterministic voting rules: qualified majority and qualified anti-majority. We\nalso provide analogous results by requiring implementation by a symmetric\nmonotone (strategy-proof) voting rule and by a symmetric unanimous voting rule.\nWe apply our results to show that an ex-ante Rawlsian rule is a convex\ncombination of a pair of qualified majority rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.09253v4"
    },
    {
        "title": "Greedy Allocations and Equitable Matchings",
        "authors": [
            "Quitzé Valenzuela-Stookey"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I provide a novel approach to characterizing the set of interim realizable\nallocations, in the spirit of Matthews (1984) and Border (1991). The approach\nallows me to identify precisely why exact characterizations are difficult to\nobtain in some settings. The main results of the paper then show how to adapt\nthe approach in order to obtain approximate characterizations of the interim\nrealizable set in such settings.\n  As an application, I study multi-item allocation problems when agents have\ncapacity constraints. I identify necessary conditions for interim\nrealizability, and show that these conditions are sufficient for realizability\nwhen the interim allocation in question is scaled by 1/2. I then characterize a\nsubset of the realizable polytope which contains all such scaled allocations.\nThis polytope is generated by a majorization relationship between the scaled\ninterim allocations and allocations induced by a certain ``greedy algorithm''.\nI use these results to study mechanism design with equity concerns and model\nambiguity. I also relate optimal mechanisms to the commonly used deferred\nacceptance and serial dictatorship matching algorithms. For example, I provide\nconditions on the principal's objective such that by carefully choosing school\npriorities and running deferred acceptance, the principal can guarantee at\nleast half of the optimal (full information) payoff.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.11322v2"
    },
    {
        "title": "Time-constrained Dynamic Mechanisms for College Admissions",
        "authors": [
            "Li Chen",
            "Juan S. Pereyra",
            "Min Zhu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Recent literature shows that dynamic matching mechanisms may outperform the\nstandard mechanisms to deliver desirable results. We highlight an\nunder-explored design dimension, the time constraints that students face under\nsuch a dynamic mechanism. First, we theoretically explore the effect of time\nconstraints and show that the outcome can be worse than the outcome produced by\nthe student-proposing deferred acceptance mechanism. Second, we present\nevidence from the Inner Mongolian university admissions that time constraints\ncan prevent dynamic mechanisms from achieving stable outcomes, creating losers\nand winners among students.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.12179v1"
    },
    {
        "title": "Loss aversion in strategy-proof school-choice mechanisms",
        "authors": [
            "Vincent Meisner",
            "Jonas von Wangenheim"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Evidence suggests that participants in strategy-proof matching mechanisms\nplay dominated strategies. To explain the data, we introduce expectation-based\nloss aversion into a school-choice setting and characterize choice-acclimating\npersonal equilibria. We find that non-truthful preference submissions can be\nstrictly optimal if and only if they are top-rank monotone. In equilibrium,\ninefficiency or justified envy may arise in seemingly stable or efficient\nmechanisms. Specifically, students who are more loss averse or less confident\nthan their peers obtain suboptimal allocations.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.14666v1"
    },
    {
        "title": "Input-Output Tables and Some Theory of Defective Matrices",
        "authors": [
            "Mohit Arora",
            "Deepankar Basu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Recent developments in the theory of production networks offer interesting\napplications and revival of input-output analysis. Some recent papers have\nstudied the propagation of a temporary, negative shock through an input-output\nnetwork. Such analyses of shock propagation relies on eigendecomposition of\nrelevant input-output matrices. It is well known that only diagonalizable\nmatrices can be eigendecomposed; those that are not diagonalizable, are known\nas defective matrices. In this paper, we provide necessary and sufficient\nconditions for diagonalizability of any square matrix using its rank and\neigenvalues. To apply our results, we offer examples of input-output tables\nfrom India in the 1950s that were not diagonalizable and were hence, defective.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.00226v1"
    },
    {
        "title": "The character of non-manipulable collective choices between two\n  alternatives",
        "authors": [
            "Achille Basile",
            "K. P. S. Bhaskara Rao",
            "Surekha Rao"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider classes of non-manipulable social choice functions with range of\ncardinality at most two within a set of at least two alternatives. We provide\nthe functional form for each of the classes we consider.\n  This functional form is a characterization that explicitly describes how a\nsocial choice function of that particular class selects the collective choice\ncorresponding to a profile.\n  We provide a unified formulation of these characterizations using the new\nconcept of \"character\". The choice of the character, depending on the class of\nsocial choice functions, gives the functional form of all social choice\nfunctions of the class.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.01594v3"
    },
    {
        "title": "A look back at the core of games in characteristic function form: some\n  new axiomatization results",
        "authors": [
            "Anindya Bhattacharya"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper we provide three new results axiomatizing the core of games in\ncharacteristic function form (not necessarily having transferable utility)\nobeying an innocuous condition (that the set of individually rational pay-off\nvectors is bounded). One novelty of this exercise is that our domain is the\n{\\em entire} class of such games: i.e., restrictions like \"non-levelness\" or\n\"balancedness\" are not required.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.01690v2"
    },
    {
        "title": "Agglomeration and welfare of the Krugman model in a continuous space",
        "authors": [
            "Kensuke Ohtake"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Two spatial equilibria, agglomeration and dispersion, in a continuous space\ncore-periphery model are examined to discuss which equilibrium is socially\npreferred. It is shown that when transport cost is lower than a critical value,\nthe agglomeration equilibrium is preferable in the sense of Scitovszky, while\nwhen the transport cost is above the critical value, the two equilibria can not\nbe ordered in the sense of Scitovszky.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.01972v3"
    },
    {
        "title": "Ordered Surprises and Conditional Probability Systems",
        "authors": [
            "Adam Dominiak",
            "Matthew Kovach",
            "Gerelt Tserenjigmid"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study conditioning on null events, or surprises, and behaviorally\ncharacterize the Ordered Surprises (OS) representation of beliefs. For feasible\nevents, our Decision Maker (DM) is Bayesian. For null events, our DM considers\na hierarchy of beliefs until one is consistent with the surprise. The DM adopts\nthis prior and applies Bayes' rule. Unlike Bayesian updating, OS is a complete\nupdating rule: conditional beliefs are well-defined for any event. OS is\n(behaviorally) equivalent to the Conditional Probability System (Myerson,\n1986b) and is a special case of Hypothesis Testing (Ortoleva, 2012), clarifying\nthe relationships between the various approaches to null events.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.02533v2"
    },
    {
        "title": "Subgame perfect Nash equilibrium for dynamic pricing competition with\n  finite planning horizon",
        "authors": [
            "Niloofar Fadavi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Having fixed capacities, homogeneous products and price sensitive customer\npurchase decision are primary distinguishing characteristics of numerous\nrevenue management systems. Even with two or three rivals, competition is still\nhighly fierce. This paper studies sub-game perfect Nash equilibrium of a price\ncompetition in an oligopoly market with perishable assets. Sellers each has one\nunit of a good that cannot be replenished, and they compete in setting prices\nto sell their good over a finite sales horizon. Each period, buyers desire one\nunit of the good and the number of buyers coming to the market in each period\nis random. All sellers' prices are accessible for buyers, and search is\ncostless. Using stochastic dynamic programming methods, the best response of\nsellers can be obtained from a one-shot price competition game regarding\nremained periods and the current-time demand structure. Assuming a binary\ndemand model, we demonstrate that the duopoly model has a unique Nash\nequilibrium and the oligopoly model does not reveal price dispersion with\nrespect to a particular metric. We illustrate that, when considering a\ngeneralized demand model, the duopoly model has a unique mixed strategy Nash\nequilibrium while the oligopoly model has a unique symmetric mixed strategy\nNash equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.02842v1"
    },
    {
        "title": "On the Distributional Robustness of Finite Rational Inattention Models",
        "authors": [
            "Emerson Melo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper we study a rational inattention model in environments where the\ndecision maker faces uncertainty about the true prior distribution over states.\nThe decision maker seeks to select a stochastic choice rule over a finite set\nof alternatives that is robust to prior ambiguity. We fully characterize the\ndistributional robustness of the rational inattention model in terms of a\ntractable concave program. We establish necessary and sufficient conditions to\nconstruct robust consideration sets. Finally, we quantify the impact of prior\nuncertainty, by introducing the notion of \\emph{Worst-Case Sensitivity}.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03370v2"
    },
    {
        "title": "Gacha Game: When Prospect Theory Meets Optimal Pricing",
        "authors": [
            "Tan Gan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I study the optimal pricing process for selling a unit good to a buyer with\nprospect theory preferences. In the presence of probability weighting, the\nbuyer is dynamically inconsistent and can be either sophisticated or naive\nabout her own inconsistency. If the buyer is naive, the uniquely optimal\nmechanism is to sell a ``loot box'' that delivers the good with some constant\nprobability in each period. In contrast, if the buyer is sophisticated, the\nuniquely optimal mechanism introduces worst-case insurance: after successive\nfailures in obtaining the good from all previous loot boxes, the buyer can\npurchase the good at full price.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03602v3"
    },
    {
        "title": "Pricing Novel Goods",
        "authors": [
            "Francesco Giovannoni",
            "Toomas Hinnosaar"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a bilateral trade problem where a principal has private information\nthat is revealed with delay, such as a seller who does not yet know her\nproduction cost. Postponing the contracting process incurs a costly delay,\nwhile early contracting with limited information can create incentive issues,\nas the principal might misrepresent private information that will be revealed\nlater. We show that the optimal mechanism can effectively address these\nchallenges by leveraging the sequential nature of the problem. The optimal\nmechanism is a menu of two-part tariffs, where the variable part is determined\nby the principal's incentives and the fixed part by the agent's incentives. As\ntwo-part tariffs might be impractical in some applications, we also study price\nmechanisms. We show that the optimal price mechanism often entails trade at\nboth the ex-ante and ex-post stages. Dynamic price mechanisms can lower the\ncost of delay by transacting with high-type agents early and relax the\nincentive constraints by postponing contracts with lower-type agents. We also\ngeneralize our analysis to costly learning and study ex-post efficiency in our\ncontext.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.04985v2"
    },
    {
        "title": "Conditions for none to be whipped by `Rank and Yank' under the majority\n  rule",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  `Rank and Yank' is practiced in many organizations. This paper is concerned\nwith the condtions for none to be whipped by `Rank and Yank' when the\nevaluation data under each criterion are assumed to be ordinal rankings and the\nmajority rule is used. Two sufficient conditions are set forth of which the\nfirst one formulates the alternatives indifference definition in terms of the\nelection matrix, while the second one specifies a certain balance in the\nprobabilities of alternatives being ranked at positions. In a sense, `none to\nbe whipped' means that the organization is of stability. Thus the second\nsufficient condition indicates an intrinsic relation of balance and\norganization stability. In addition, directions for future research are put\nforward.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05093v1"
    },
    {
        "title": "Welfare ordering of voting weight allocations",
        "authors": [
            "Kazuya Kikuchi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies the allocation of voting weights in a committee\nrepresenting groups of different sizes. We introduce a partial ordering of\nweight allocations based on stochastic comparison of social welfare. We show\nthat when the number of groups is sufficiently large, this ordering\nasymptotically coincides with the total ordering induced by the cosine\nproportionality between the weights and the group sizes. A corollary is that a\nclass of expectation-form objective functions, including expected welfare, the\nmean majority deficit and the probability of inversions, are asymptotically\nmonotone in the cosine proportionality.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05316v3"
    },
    {
        "title": "Pandora's Ballot Box: Electoral Politics of Direct Democracy",
        "authors": [
            "Peter Buisseret",
            "Richard Van Weelden"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study how office-seeking parties use direct democracy to shape elections.\nA party with a strong electoral base can benefit from using a binding\nreferendum to resolve issues that divide its core supporters. When referendums\ndo not bind, however, an electorally disadvantaged party may initiate a\nreferendum to elevate new issues in order to divide the supporters of its\nstronger opponent. We identify conditions under which direct democracy improves\ncongruence between policy outcomes and voter preferences, but also show that it\ncan lead to greater misalignment both on issues subject to direct democracy and\nthose that are not.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05535v1"
    },
    {
        "title": "On spatial majority voting with an even (vis-a-vis odd) number of\n  voters: a note",
        "authors": [
            "Anindya Bhattacharya",
            "Francesco Ciardiello"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this note we consider situations of (multidimensional) spatial majority\nvoting. We show that under some assumptions usual in this literature, with an\neven number of voters if the core of the voting situation is singleton (and in\nthe interior of the policy space) then the element in the core is never a\nCondorcet winner. This is in sharp contrast with what happens with an odd\nnumber of voters: in that case, under identical assumptions, it is well known\nthat if the core of the voting situation is non-empty then the single element\nin the core is the Condorcet winner as well.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.06849v1"
    },
    {
        "title": "Revealed Preference Analysis Under Limited Attention",
        "authors": [
            "Mikhail Freer",
            "Hassan Nosratabadi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  An observer wants to understand a decision-maker's welfare from her choice.\nShe believes that decisions are made under limited attention. We argue that the\nstandard model of limited attention cannot help the observer greatly. To\naddress this issue, we study a family of models of choice under limited\nattention by imposing an attention floor in the decision process. We construct\nan algorithm that recovers the revealed preference relation given an incomplete\ndata set in these models. Next, we take these models to the experimental data.\nWe first show that assuming that subjects make at least one comparison before\nfinalizing decisions (that is, an attention floor of 2) is almost costless in\nterms of describing the behavior when compared to the standard model of limited\nattention. In terms of revealed preferences, on the other hand, the amended\nmodel does significantly better. We can not recover any preferences for 63% of\nthe subjects in the standard model, while the amended model reveals some\npreferences for all subjects. In total, the amended model allows us to recover\none-third of the preferences that would be recovered under full attention.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07659v3"
    },
    {
        "title": "On Gale's Contribution in Revealed Preference Theory",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We investigate Gale's important paper published in 1960. This paper contains\nan example of a candidate of the demand function that satisfies the weak axiom\nof revealed preference and that is doubtful that it is a demand function of\nsome weak order. We examine this paper and first scrutinize what Gale proved.\nThen we identify a gap in Gale's proof and show that he failed to show that\nthis candidate of the demand function is not a demand function. Next, we\npresent three complete proofs of Gale's claim. First, we construct a proof that\nwas constructible in 1960 by a fact that Gale himself demonstrated. Second, we\nconstruct a modern and simple proof using Shephard's lemma. Third, we construct\na proof that follows the direction that Gale originally conceived. Our\nconclusion is as follows: although, in 1960, Gale was not able to prove that\nthe candidate of the demand function that he constructed is not a demand\nfunction, he substantially proved it, and therefore it is fair to say that the\ncredit for finding a candidate of the demand function that satisfies the weak\naxiom but is not a demand function is attributed to Gale.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07970v2"
    },
    {
        "title": "Marginal stochastic choice",
        "authors": [
            "Yaron Azrieli",
            "John Rehbeck"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Models of stochastic choice typically use conditional choice probabilities\ngiven menus as the primitive for analysis, but in the field these are often\nhard to observe. Moreover, studying preferences over menus is not possible with\nthis data. We assume that an analyst can observe marginal frequencies of choice\nand availability, but not conditional choice frequencies, and study the\ntestable implications of some prominent models of stochastic choice for this\ndataset. We also analyze whether parameters of these models can be identified.\nFinally, we characterize the marginal distributions that can arise under\ntwo-stage models in the spirit of Gul and Pesendorfer [2001] and of kreps\n[1979] where agents select the menu before choosing an alternative.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.08492v1"
    },
    {
        "title": "Coordinating charging request allocation between self-interested\n  navigation service platforms",
        "authors": [
            "Marianne Guillet",
            "Maximilian Schiffer"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Current electric vehicle market trends indicate an increasing adoption rate\nacross several countries. To meet the expected growing charging demand, it is\nnecessary to scale up the current charging infrastructure and to mitigate\ncurrent reliability deficiencies, e.g., due to broken connectors or misreported\ncharging station availability status. However, even within a properly\ndimensioned charging infrastructure, a risk for local bottlenecks remains if\nseveral drivers cannot coordinate their charging station visit decisions. Here,\nnavigation service platforms can optimally balance charging demand over\navailable stations to reduce possible station visit conflicts and increase user\nsatisfaction. While such fleet-optimized charging station visit recommendations\nmay alleviate local bottlenecks, they can also harm the system if\nself-interested navigation service platforms seek to maximize their own\ncustomers' satisfaction. To study these dynamics, we model fleet-optimized\ncharging station allocation as a resource allocation game in which navigation\nplatforms constitute players and assign potentially free charging stations to\ndrivers. We show that no pure Nash equilibrium guarantee exists for this game,\nwhich motivates us to study VCG mechanisms both in offline and online settings,\nto coordinate players' strategies toward a better social outcome. Extensive\nnumerical studies for the city of Berlin show that when coordinating players\nthrough VCG mechanisms, the social cost decreases on average by 42 % in the\nonline setting and by 52 % in the offline setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.09530v1"
    },
    {
        "title": "On mechanism design with expressive preferences: an aspect of the social\n  choice of Brexit",
        "authors": [
            "Anindya Bhattacharya",
            "Debapriya Sen"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study some problems of collective choice when individuals can have\nexpressive preferences, that is, where a decision-maker may care not only about\nthe material benefit from choosing an action but also about some intrinsic\nmorality of the action or whether the action conforms to some identity-marker\nof the decision-maker. We construct a simple framework for analyzing mechanism\ndesign problems with such preferences and present some results focussing on the\nphenomenon we call \"Brexit anomaly\". The main findings are that while\ndeterministic mechanisms are quite susceptible to Brexit anomaly, even with\nstringent domain restriction, random mechanisms assure more positive results.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.09851v1"
    },
    {
        "title": "Limit Orders and Knightian Uncertainty",
        "authors": [
            "Michael Greinecker",
            "Christoph Kuzmics"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A range of empirical puzzles in finance has been explained as a consequence\nof traders being averse to ambiguity. Ambiguity averse traders can behave in\nfinancial portfolio problems in ways that cannot be rationalized as maximizing\nsubjective expected utility. However, this paper shows that when traders have\naccess to limit orders, all investment behavior of an ambiguity-averse\ndecision-maker is observationally equivalent to the behavior of a subjective\nexpected utility maximizer with the same risk preferences; ambiguity aversion\nhas no additional explanatory power.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.10804v1"
    },
    {
        "title": "Equilibrium selection: a geometric approach",
        "authors": [
            "Andrea Loi",
            "Stefano Matta",
            "Daria Uccheddu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper we propose a geometric approach to the selection of the equi-\nlibrium price. After a perturbation of the parameters, the new price is\nselected thorough the composition of two maps: the projection on the\nlinearization of the equilibrium man- ifold, a method that underlies\neconometric modeling, and the exponential map, that associates a tangent vector\nwith a geodesic on the manifold. As a corollary of our main result, we prove\nthe equivalence between zero curvature and uniqueness of equilibrium in the\ncase of an arbitrary number of goods and two consumers, thus extending the\nprevious result by [6].\n",
        "pdf_link": "http://arxiv.org/pdf/2208.10860v1"
    },
    {
        "title": "Sorting and Grading",
        "authors": [
            "Jacopo Bizzotto",
            "Adrien Vigier"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We propose a framework to assess how to optimally sort and grade students of\nheterogenous ability. Potential employers face uncertainty regarding an\nindividual's productive value. Knowing which school an individual went to is\nuseful for two reasons: firstly, average student ability may differ across\nschools; secondly, different schools may use different grading rules and thus\nprovide varying incentives to exert effort. An optimal school system exhibits\ncoarse stratification with respect to ability, and more lenient grading at the\ntop-tier schools than at the bottom-tier schools. Our paper contributes to the\nongoing policy debate on tracking in secondary schools.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.10894v4"
    },
    {
        "title": "Cognitive Hierarchies in Multi-Stage Games of Incomplete Information:\n  Theory and Experiment",
        "authors": [
            "Po-Hsuan Lin"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Sequential equilibrium is the conventional approach for analyzing multi-stage\ngames of incomplete information. It relies on mutual consistency of beliefs. To\nrelax mutual consistency, I theoretically and experimentally explore the\ndynamic cognitive hierarchy (DCH) solution. One property of DCH is that the\nsolution can vary between two different games sharing the same reduced normal\nform, i.e., violation of invariance under strategic equivalence. I test this\nprediction in a laboratory experiment using two strategically equivalent\nversions of the dirty-faces game. The game parameters are calibrated to\nmaximize the expected difference in behavior between the two versions, as\npredicted by DCH. The experimental results indicate significant differences in\nbehavior between the two versions, and more importantly, the observed\ndifferences align with DCH. This suggests that implementing a dynamic game\nexperiment in reduced normal form (using the \"strategy method\") could lead to\ndistortions in behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.11190v3"
    },
    {
        "title": "Optimal Delegation in a Multidimensional World",
        "authors": [
            "Andreas Kleiner"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a model of delegation in which a principal takes a multidimensional\naction and an agent has private information about a multidimensional state of\nthe world. The principal can design any direct mechanism, including stochastic\nones. We provide necessary and sufficient conditions for an arbitrary mechanism\nto maximize the principal's expected payoff. We also discuss simple conditions\nwhich ensure that some convex delegation set is optimal. A key step of our\nanalysis shows that a mechanism is incentive compatible if and only if its\ninduced indirect utility is convex and lies below the agent's first-best\npayoff.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.11835v1"
    },
    {
        "title": "Strategy-proof aggregation rules in median semilattices with\n  applications to preference aggregation",
        "authors": [
            "Ernesto Savaglio",
            "Stefano Vannucci"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Two characterizations of the whole class of strategy-proof aggregation rules\non rich domains of locally unimodal preorders in finite median\njoin-semilattices are provided. In particular, it is shown that such a class\nconsists precisely of generalized weak sponsorship rules induced by certain\nfamilies of order filters of the coalition poset. It follows that the\nco-majority rule and many other inclusive aggregation rules belong to that\nclass. The co-majority rule for an odd number of agents is characterized and\nshown to be equivalent to a Condorcet-Kemeny median rule. Applications to\npreference aggregation rules including Arrowian social welfare functions are\nalso considered. The existence of strategy-proof anonymous, weakly neutral and\nunanimity-respecting social welfare functions which are defined on arbitrary\nprofiles of total preorders and satisfy a suitably relaxed independence\ncondition is shown to follow from our characterizations.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12732v1"
    },
    {
        "title": "Regret-free truth-telling voting rules",
        "authors": [
            "R. Pablo Arribillaga",
            "Agustín G. Bonifacio",
            "Marcelo Ariel Fernandez"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the ability of different classes of voting rules to induce agents to\nreport their preferences truthfully, if agents want to avoid regret. First, we\nshow that regret-free truth-telling is equivalent to strategy-proofness among\ntops-only rules. Then, we focus on three important families of (non-tops-only)\nvoting methods: maxmin, scoring, and Condorcet consistent ones. We prove\npositive and negative results for both neutral and anonymous versions of maxmin\nand scoring rules. In several instances we provide necessary and sufficient\nconditions. We also show that Condorcet consistent rules that satisfy a mild\nmonotonicity requirement are not regret-free truth-telling. Successive\nelimination rules fail to be regret-free truth-telling despite not satisfying\nthe monotonicity condition. Lastly, we provide two characterizations for the\ncase of three alternatives and two agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.13853v2"
    },
    {
        "title": "Prolonged Learning and Hasty Stopping: the Wald Problem with Ambiguity",
        "authors": [
            "Sarah Auster",
            "Yeon-Koo Che",
            "Konrad Mierendorff"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies sequential information acquisition by an ambiguity-averse\ndecision maker (DM), who decides how long to collect information before taking\nan irreversible action. The agent optimizes against the worst-case belief and\nupdates prior by prior. We show that the consideration of ambiguity gives rise\nto rich dynamics: compared to the Bayesian DM, the DM here tends to experiment\nexcessively when facing modest uncertainty and, to counteract it, may stop\nexperimenting prematurely when facing high uncertainty. In the latter case, the\nDM's stopping rule is non-monotonic in beliefs and features randomized\nstopping.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.14121v3"
    },
    {
        "title": "Optimal dynamic insurance contracts",
        "authors": [
            "Vitor Farinha Luz"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I analyze long-term contracting in insurance markets with asymmetric\ninformation. The buyer privately observes her risk type, which evolves\nstochastically over time. A long-term contract specifies a menu of insurance\npolicies, contingent on the history of type reports and contractable accident\ninformation. The optimal contract offers the consumer in each period a choice\nbetween a perpetual complete coverage policy with fixed premium and a risky\ncontinuation contract in which current period's accidents may affect not only\nwithin-period consumption (partial coverage) but also future policies.\n  The model allows for arbitrary restrictions to the extent to which firms can\nuse accident information in pricing. In the absence of pricing restrictions,\naccidents as well as choices of partial coverage are used in the efficient\nprovision of incentives. If firms are unable to use accident history, longer\nperiods of partial coverage choices are rewarded, leading to menus with cheaper\nfull-coverage options and more attractive partial-coverage options; and\nallocative inefficiency decreases along all histories.\n  These results are used to study a model of perfect competition, where the\nequilibrium is unique whenever it exists, as well as the monopoly problem,\nwhere necessary and sufficient conditions for the presence of information rents\nare given.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.14560v1"
    },
    {
        "title": "The Emergence of Fads in a Changing World",
        "authors": [
            "Wanying Huang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study how fads emerge under social learning in a changing environment. We\nconsider a simple sequential social learning model where rational agents arrive\nin order, each acting only once, and the underlying unknown state constantly\nevolves. Each agent receives a private signal, observes all past actions of\nothers, and chooses an action to match the current state. Because the state\nchanges over time, cascades cannot last forever, and actions also fluctuate. We\nshow that despite the rise of temporary information cascades, in the long run,\nactions change more often than the state. This result provides a theoretical\nfoundation for faddish behavior in which people often change their actions more\nfrequently than necessary.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.14570v2"
    },
    {
        "title": "The optimality of (stochastic) veto delegation",
        "authors": [
            "Xiaoxiao Hu",
            "Haoran Lei"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We analyze the optimal delegation problem between a principal and an agent,\nassuming that the latter has state-independent preferences. We demonstrate that\nif the principal is more risk-averse than the agent toward non-status quo\noptions, an optimal mechanism is a {\\em veto mechanism}. In a veto mechanism,\nthe principal uses veto (i.e., maintaining the status quo) to balance the\nagent's incentives and does not randomize among non-status quo options. We\ncharacterize the optimal veto mechanism in a one-dimensional setting. In the\nsolution, the principal uses veto only when the state surpasses a critical\nthreshold.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.14829v4"
    },
    {
        "title": "Learning by Consuming: Optimal Pricing with Endogenous Information\n  Provision",
        "authors": [
            "Huiyi Guo",
            "Wei He",
            "Bin Liu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the revenue-maximizing mechanism when a buyer's value evolves\nendogenously because of learning-by-consuming. A seller sells one unit of a\ndivisible good, while the buyer relies on his private, rough valuation to\nchoose his first-stage consumption level. Consuming more leads to a more\nprecise valuation estimate, after which the buyer determines the second-stage\nconsumption level. The optimum is a menu of try-and-decide contracts,\nconsisting of a first-stage price-quantity pair and a second-stage per-unit\nprice for the remaining quantity. In equilibrium, a higher first-stage\nvaluation buyer pays more for higher first-stage consumption and enjoys a lower\nsecond-stage per-unit price. Methodologically, we deal with the difficulty that\ndue to the failure of single-crossing condition, monotonicity in allocation\nplus the envelope condition is insufficient for incentive compatibility. Our\nresults help to understand contracts about sequential consumption with the\nlearning feature; e.g., leasing contracts for experience goods and trial\nsessions for certain courses.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01453v1"
    },
    {
        "title": "Risk and Intertemporal Preferences over Time Lotteries",
        "authors": [
            "Minghao Pan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies relations among axioms on individuals' intertemporal\nchoices under risk. The focus is on Risk Averse over Time Lotteries (RATL),\nmeaning that a fixed prize is preferred to a lottery with the same monetary\nprize but a random delivery time. Though surveys and lab experiments documented\nRATL choices, Expected Discounted Utility cannot accommodate any RATL. This\npaper's contribution is two-fold. First, under a very weak form of\nIndependence, we generalize the incompatibility of RATL with two axioms about\nintertemporal choices: Stochastic Impatience (SI) and No Future Bias. Next, we\nprove a representation theorem that gives a class of models satisfying RATL and\nSI everywhere. This illustrates that there is no fundamental conflict between\nRATL and SI, and leaves open possibility that RATL behavior is caused by Future\nBias.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01790v1"
    },
    {
        "title": "Invariance and hierarchy-equivalence",
        "authors": [
            "Nicodemo De Vito"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Two type structures are hierarchy-equivalent if they induce the same set of\nhierarchies of beliefs. This note shows that the behavioral implications of\n\"cautious rationality and common cautious belief in cautious rationality\"\n(Catonini and De Vito 2021) do not vary across hierarchy-equivalent type\nstructures.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01926v1"
    },
    {
        "title": "The Existence of Equilibrium Flows",
        "authors": [
            "Alfred Galichon",
            "Larry Samuelson",
            "Lucas Vernet"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Galichon, Samuelson and Vernet (2022) introduced a class of problems,\nequilibrium flow problems, that nests several classical economic models such as\nbipartite matching models, minimum-cost flow problems and hedonic pricing\nmodels. We establish conditions for the existence of equilibrium prices in the\nequilibrium flow problem, in the process generalizing Hall's theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04426v1"
    },
    {
        "title": "Attention Capture",
        "authors": [
            "Andrew Koh",
            "Sivakorn Sanguanmoo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We develop a unified analysis of how information captures attention. A\ndecision maker (DM) faces a dynamic information structure and decides when to\nstop paying attention. We characterize the convex$\\unicode{x2013}$order\nfrontier and extreme points of feasible stopping times, as well as dynamic\ninformation structures which implement them. This delivers the form of optimal\nattentional capture as a function of the designer and DM's relative time\npreferences. Intertemporal commitment is unnecessary: sequentially optimal\ninformation structures always exist by inducing stochastic interim beliefs. We\nfurther analyze optimal attention capture under non instrumental value of\ninformation. Our results speak directly to the attention economy.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05570v7"
    },
    {
        "title": "Markovian Persuasion with Two States",
        "authors": [
            "Galit Ashkenazi-Golan",
            "Penélope Hernández",
            "Zvika Neeman",
            "Eilon Solan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper addresses the question of how to best communicate information over\ntime in order to influence an agent's belief and induced actions in a model\nwith a binary state of the world that evolves according to a Markov process,\nand with a finite number of actions. We characterize the sender's optimal\nmessage strategy in the limit, as the length of each period decreases to zero.\nThe optimal strategy is not myopic. Depending on the agent's beliefs, sometimes\nno information is revealed, and sometimes the agent's belief is split into two\nwell-chosen posterior beliefs.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.06536v1"
    },
    {
        "title": "Market Design with Deferred Acceptance: A Recipe for Policymaking",
        "authors": [
            "Battal Doğan",
            "Kenzo Imamura",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We introduce a method to derive from a characterization of institutional\nchoice rules (or priority rules), a characterization of the Gale-Shapley\ndeferred-acceptance (DA) matching rule based on these choice rules. We apply\nour method to school choice in Chile, where we design choice rules for schools\nthat are uniquely compatible with the School Inclusion Law and derive a set of\nmatching properties, compatible with the law, that characterizes the DA rule\nbased on the designed choice rules. Our method provides a recipe for\nestablishing such results and can help policymakers decide on which allocation\nrule to use in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.06777v1"
    },
    {
        "title": "Competitive equilibrium and the double auction",
        "authors": [
            "Itzhak Rasooly"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper, we revisit the common claim that double auctions necessarily\ngenerate competitive equilibria. We begin by observing that competitive\nequilibrium has some counterintuitive implications: specifically, it predicts\nthat monotone shifts in the value distribution can leave prices unchanged.\nUsing experiments, we then test whether these implications are borne out by the\ndata. We find that in double auctions with stationary value distributions, the\nresulting prices can be far from competitive equilibria. We also show that the\neffectiveness of our counterexamples is blunted when traders can leave without\nreplacement as time progresses. Taken together, these findings suggest that the\n`Marshallian path' is crucial for generating equilibrium prices in double\nauctions.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.07532v1"
    },
    {
        "title": "Prospecting a Possible Quadratic Wormhole Between Quantum Mechanics and\n  Plurality",
        "authors": [
            "Michal Fabinger",
            "Michael H. Freedman",
            "E. Glen Weyl"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We illustrate some formal symmetries between Quadratic Funding (Buterin et\nal., 2019), a mechanism for the (approximately optimal) determination of public\ngood funding levels, and the Born (1926) rule in Quantum Mechanics, which\nconverts the wave representation into a probability distribution, through a\nbridging formulation we call \"Quantum Quartic Finance\". We suggest further\ndirections for investigating the practical utility of these symmetries. We\ndiscuss potential interpretations in greater depth in a companion blog post.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.08144v1"
    },
    {
        "title": "Ambiguous Cheap Talk",
        "authors": [
            "Longjian Li"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper explores how ambiguity affects communication. We consider a cheap\ntalk model in which the receiver evaluates the sender's message with respect to\nits worst-case expected payoff generated by multiplier preferences. We\ncharacterize the receiver's optimal strategy and show that the receiver's\nposterior action is consistent with his ex-ante action. We find that in some\nsituations, ambiguity improves communication by shifting the receiver's optimal\naction upwards, and these situations are not rare.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.08494v1"
    },
    {
        "title": "Lexicographic Composition of Choice Functions",
        "authors": [
            "Sean Horan",
            "Vikram Manjunath"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Lexicographic composition is a natural way to build an aggregate choice\nfunction from component choice functions. As the name suggests, the components\nare ordered and choose sequentially. The sets that subsequent components select\nfrom are constrained by the choices made by earlier choice functions. The\nspecific constraints affect whether properties like path independence are\npreserved. For several domains of inputs, we characterize the constraints that\nensure such preservation.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.09293v1"
    },
    {
        "title": "Implementation with Uncertain Evidence",
        "authors": [
            "Soumen Banerjee",
            "Yi-Chun Chen"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a full implementation problem with hard evidence where the state is\ncommon knowledge but agents face uncertainty about the evidence endowments of\nother agents. We identify a necessary and sufficient condition for\nimplementation in mixed-strategy Bayesian Nash equilibria called No Perfect\nDeceptions. The implementing mechanism requires only two agents and a finite\nmessage space, imposes transfers only off the equilibrium, and invoke no device\nwith \"...questionable features...\" such as integer or modulo games. Requiring\nonly implementation in pure-strategy equilibria weakens the necessary and\nsufficient condition to No Pure-Perfect Deceptions. In general type spaces\nwhere the state is not common knowledge, a condition called higher-order\nmeasurability is necessary and sufficient for rationalizable implementation\nwith arbitrarily small transfers alongside.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.10741v1"
    },
    {
        "title": "Why do experts give simple advice?",
        "authors": [
            "Benjamin Davies"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  An expert tells an advisee whether to take an action that may be good or bad.\nHe may provide a condition under which to take the action. This condition\npredicts whether the action is good if and only if the expert is competent.\nProviding the condition exposes the expert to reputational risk by allowing the\nadvisee to learn about his competence. He trades off the accuracy benefit and\nreputational risk induced by providing the condition. He prefers not to provide\nit -- i.e., to give \"simple advice\" -- when his payoff is sufficiently concave\nin the posterior belief about his competence.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.11710v1"
    },
    {
        "title": "The Signaling Role of Leaders in Global Games",
        "authors": [
            "Panagiotis Kyriazis",
            "Edmund Lou"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  How important are leaders' actions in facilitating coordination? In this\npaper, we investigate their signaling role in a global games framework. A\nperfectly informed leader and a team of followers face a coordination problem.\nDespite the endogenous information generated by the leader's action, we provide\na necessary and sufficient condition that makes the monotone equilibrium\nstrategy profile uniquely $\\Delta$-rationalizable and hence guarantees\nequilibrium uniqueness. Moreover, the unique equilibrium is fully efficient.\nThis result remains valid when the leader observes a noisy signal about the\ntrue state except full efficiency may not be obtained. We discuss the\nimplications of our results for a broad class of phenomena such as adoption of\ngreen technology, currency attacks and revolutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12426v2"
    },
    {
        "title": "Optimally Biased Expertise",
        "authors": [
            "Pavel Ilinov",
            "Andrei Matveenko",
            "Maxim Senkov",
            "Egor Starkov"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper shows that the principal can strictly benefit from delegating a\ndecision to an agent whose opinion differs from that of the principal. We\nconsider a \"delegated expertise\" problem, in which the agent has an advantage\nin information acquisition relative to the principal, as opposed to having\npreexisting private information. When the principal is ex ante predisposed\ntowards some action, it is optimal for her to hire an agent who is predisposed\ntowards the same action, but to a smaller extent, since such an agent would\nacquire more information, which outweighs the bias stemming from misalignment.\nWe show that belief misalignment between an agent and a principal is a viable\ninstrument in delegation, performing on par with contracting and communication\nin a class of problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.13689v1"
    },
    {
        "title": "Agenda manipulation-proofness, stalemates, and redundant elicitation in\n  preference aggregation. Exposing the bright side of Arrow's theorem",
        "authors": [
            "Stefano Vannucci"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper provides a general framework to explore the possibility of agenda\nmanipulation-proof and proper consensus-based preference aggregation rules, so\npowerfully called in doubt by a disputable if widely shared understanding of\nArrow's `general possibility theorem'. We consider two alternative versions of\nagenda manipulation-proofness for social welfare functions, that are\ndistinguished by `parallel' vs. `sequential' execution of agenda formation and\npreference elicitation, respectively. Under the `parallel' version, it is shown\nthat a large class of anonymous and idempotent social welfare functions that\nsatisfy both agenda manipulation-proofness and strategy-proofness on a natural\ndomain of single-peaked `meta-preferences' induced by arbitrary total\npreference preorders are indeed available. It is only under the second,\n`sequential' version that agenda manipulation-proofness on the same natural\ndomain of single-peaked `meta-preferences' is in fact shown to be tightly\nrelated to the classic Arrowian `independence of irrelevant alternatives' (IIA)\nfor social welfare functions. In particular, it is shown that using IIA to\nsecure such `sequential' version of agenda manipulation-proofness and combining\nit with a very minimal requirement of distributed responsiveness results in a\ncharacterization of the `global stalemate' social welfare function, the\nconstant function which invariably selects universal social indifference. It is\nalso argued that, altogether, the foregoing results provide new significant\ninsights concerning the actual content and the constructive implications of\nArrow's `general possibility theorem' from a mechanism-design perspective.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.03200v1"
    },
    {
        "title": "A solution for external costs beyond negotiation and taxation",
        "authors": [
            "Alexandre Magno de Melo Faria",
            "Helde A. D. Hdom"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This article aims to launch light on the limitations of the Coase and Pigou\napproach in the solution of externalities. After contextualizing the need for\nintegration of ecological and economic approaches, we are introducing a new\nconceptual proposal complementary to conventional economic approaches. Whose\nprocess is guaranteed by a set of diffuse agents in the economy that partially\nreverses entropy formation and marginal external costs generated by also\ndiffuse agents? The approach differs in six fundamentals from traditional\ntheory and proposes a new way of examining the actions of agents capable of\nreducing entropy and containing part of external costs in the market economy.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.04049v2"
    },
    {
        "title": "Making Information More Valuable",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study what changes to an agent's decision problem increase her value for\ninformation. We prove that information becomes more valuable if and only if the\nagent's reduced-form payoff in her belief becomes more convex. When the\ntransformation corresponds to the addition of an action, the requisite increase\nin convexity occurs if and only if a simple geometric condition holds, which\nextends in a natural way to the addition of multiple actions. We apply these\nfindings to two scenarios: a monopolistic screening problem in which the good\nis information and delegation with information acquisition.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.04418v5"
    },
    {
        "title": "An improved decomposition-based heuristic for truck platooning",
        "authors": [
            "Boshuai Zhao",
            "Roel Leus"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Truck platooning is a promising transportation mode in which several trucks\ndrive together and thus save fuel consumption by suffering less air resistance.\nIn this paper, we consider a truck platooning system for which we jointly\noptimize the truck routes and schedules from the perspective of a central\nplatform. We improve an existing decomposition-based heuristic by Luo and\nLarson (2022), which iteratively solves a routing and scheduling problem, with\na cost modification step after each scheduling run. We propose different\nformulations for the routing and the scheduling problem and embed these into\nLuo and Larson's framework, and we examine ways to improve their iterative\nprocess. In addition, we propose another scheduling heuristic to deal with\nlarge instances. The computational results show that our procedure achieves\nbetter performance than the existing one under certain realistic settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.05562v3"
    },
    {
        "title": "General Manipulability Theorem for a Matching Model",
        "authors": [
            "Paola B. Manasero",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In a many-to-many matching model in which agents' preferences satisfy\nsubstitutability and the law of aggregate demand, we proof the General\nManipulability Theorem. We result generalizes the presented in Sotomayor (1996\nand 2012) for the many-to-one model. In addition, we show General\nManipulability Theorem fail when agents' preferences satisfy only\nsubstitutability.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.06549v1"
    },
    {
        "title": "Setting Interim Deadlines to Persuade",
        "authors": [
            "Maxim Senkov"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A principal funds a multistage project and retains the right to cut the\nfunding if it stagnates at some point. An agent wants to convince the principal\nto fund the project as long as possible, and can design the flow of information\nabout the progress of the project in order to persuade the principal. If the\nproject is sufficiently promising ex ante, then the agent commits to providing\nonly the good news that the project is accomplished. If the project is not\npromising enough ex ante, the agent persuades the principal to start the\nfunding by committing to provide not only good news but also the bad news that\na project milestone has not been reached by an interim deadline. I demonstrate\nthat the outlined structure of optimal information disclosure holds\nirrespective of the agent's profit share, benefit from the flow of funding, and\nthe common discount rate.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.08294v3"
    },
    {
        "title": "A Group Public Goods Game with Position Uncertainty",
        "authors": [
            "Chowdhury Mohammad Sakib Anwar",
            "Jorge Bruno",
            "Sonali SenGupta"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We model a dynamic public good contribution game, where players are\n(naturally) formed into groups. The groups are exogenously placed in a\nsequence, with limited information available to players about their groups'\nposition in the sequence. Contribution decisions are made by players\nsimultaneously and independently, and the groups' total contribution is made\nsequentially. We try to capture both inter and intra-group behaviors and\nanalyze different situations where players observe partial history about total\ncontributions of their predecessor groups. Given this framework, we show that\neven when players observe a history of defection (no contribution), a\ncooperative outcome is achievable. This is particularly interesting in the\nsituation when players observe only their immediate predecessor groups'\ncontribution, where we observe that players play an important role in\nmotivating others to contribute.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.08328v1"
    },
    {
        "title": "Public Good Provision with a Distributor",
        "authors": [
            "Chowdhury Mohammad Sakib Anwar",
            "Alexander Matros",
            "Sonali SenGupta"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We present a model of public good provision with a distributor. Our main\nresult describes a symmetric mixed-strategy equilibrium, where all agents\ncontribute to a common fund with probability $p$ and the distributor provides\neither a particular amount of public goods or nothing. A corollary of this\nfinding is the efficient public good provision equilibrium where all agents\ncontribute to the common fund, all agents are expected to contribute, and the\ndistributor spends the entire common fund for the public good provision.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.10642v1"
    },
    {
        "title": "Never Say Never: Optimal Exclusion and Reserve Prices with\n  Expectations-Based Loss-Averse Buyers",
        "authors": [
            "Benjamin Balzer",
            "Antonio Rosato"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study reserve prices in auctions with independent private values when\nbidders are expectations-based loss averse. We find that the optimal public\nreserve price excludes fewer bidder types than under risk neutrality. Moreover,\nwe show that public reserve prices are not optimal as the seller can earn a\nhigher revenue with mechanisms that better leverage the ``attachment effect''.\nWe discuss two such mechanisms: i) an auction with a secrete and random reserve\nprice, and ii) a two-stage mechanism where an auction with a public reserve\nprice is followed by a negotiation if the reserve price is not met. Both of\nthese mechanisms expose more bidders to the attachment effect, thereby\nincreasing bids and ultimately revenue.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.10938v2"
    },
    {
        "title": "Obvious manipulations of tops-only voting rules",
        "authors": [
            "R. Pablo Arribillaga",
            "Agustin G. Bonifacio"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In a voting problem with a finite set of alternatives to choose from, we\nstudy the manipulation of tops-only rules. Since all non-dictatorial (onto)\nvoting rules are manipulable when there are more than two alternatives and all\npreferences are allowed, we look for rules in which manipulations are not\nobvious. First, we show that a rule does not have obvious manipulations if and\nonly if when an agent vetoes an alternative it can do so with any preference\nthat does not have such alternative in the top. Second, we focus on two classes\nof tops-only rules: (i) (generalized) median voter schemes, and (ii) voting by\ncommittees. For each class, we identify which rules do not have obvious\nmanipulations on the universal domain of preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.11627v1"
    },
    {
        "title": "Variable population manipulations of reallocation rules in economies\n  with single-peaked preferences",
        "authors": [
            "Agustin G. Bonifacio"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In a one-commodity economy with single-peaked preferences and individual\nendowments, we study different ways in which reallocation rules can be\nstrategically distorted by affecting the set of active agents. We introduce and\ncharacterize the family of monotonic reallocation rules and show that each rule\nin this class is withdrawal-proof and endowments-merging-proof, at least one is\nendowments-splitting-proof and that no such rule is pre-delivery-proof.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.12794v2"
    },
    {
        "title": "A Theory of Stable Market Segmentations",
        "authors": [
            "Nima Haghpanah",
            "Ron Siegel"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider a monopolistic seller in a market that may be segmented. The\nsurplus of each consumer in a segment depends on the price that the seller\noptimally charges, which depends on the set of consumers in the segment. We\nstudy which segmentations may result from the interaction among consumers and\nthe seller. Instead of studying the interaction as a non-cooperative game, we\ntake a reduced-form approach and introduce a notion of stability that any\nresulting segmentation must satisfy. A stable segmentation is one that, for any\nalternative segmentation, contains a segment of consumers that prefers the\noriginal segmentation to the alternative one. Our main result characterizes\nstable segmentations as efficient and saturated. A segmentation is saturated if\nno consumers can be shifted from a segment with a high price to a segment with\na low price without the seller optimally increasing the low price. We use this\ncharacterization to constructively show that stable segmentations always exist.\nEven though stable segmentations are efficient, they need not maximize average\nconsumer surplus, and segmentations that maximize average consumer surplus need\nnot be stable. Finally, we relate our notion of stability to solution concepts\nfrom cooperative game theory and show that stable segmentations satisfy many of\nthem.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.13194v1"
    },
    {
        "title": "Revealed Preferences of One-Sided Matching",
        "authors": [
            "Andrew Tai"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Consider the object allocation (one-sided matching) model of Shapley and\nScarf (1974). When final allocations are observed but agents' preferences are\nunknown, when might the allocation be in the core? This is a one-sided analogue\nof the model in Echenique, Lee, Shum, and Yenmez (2013). I build a model in\nwhich the strict core is testable -- an allocation is \"rationalizable\" if there\nis a preference profile putting it in the core. In this manner, I develop a\ntheory of the revealed preferences of one-sided matching. I study\nrationalizability in both non-transferrable and transferrable utility settings.\nIn the non-transferrable utility setting, an allocation is rationalizable if\nand only if: whenever agents with the same preferences are in the same\npotential trading cycle, they receive the same allocation. In the transferrable\nutility setting, an allocation is rationalizable if and only if: there exists a\nprice vector supporting the allocation as a competitive equilibrium; or\nequivalently, it satisfies a cyclic monotonicity condition. The proofs leverage\nsimple graph theory and combinatorial optimization and tie together classic\ntheories of consumer demand revealed preferences and competitive equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.14388v2"
    },
    {
        "title": "The Economy's Potential: Duality and Equilibrium",
        "authors": [
            "Jacob K Goeree"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I introduce a concave function of allocations and prices -- the economy's\npotential -- which measures the difference between utilitarian social welfare\nand its dual. I show that Walrasian equilibria correspond to roots of the\npotential: allocations maximize weighted utility and prices minimize weighted\nindirect utility. Walrasian prices are \"utility clearing\" in the sense that the\nutilities consumers expect at Walrasian prices are just feasible. I discuss the\nimplications of this simple duality for equilibrium existence, the welfare\ntheorems, and the interpretation of Walrasian prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.14437v1"
    },
    {
        "title": "Pricing and Electric Vehicle Charging Equilibria",
        "authors": [
            "Trivikram Dokka",
            "Jorge Bruno",
            "Sonali SenGupta",
            "Chowdhury Mohammad Sakib Anwar"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study equilibria in an Electric Vehicle (EV) charging game, a cost\nminimization game inherent to decentralized charging control strategy for EV\npower demand management. In our model, each user optimizes its total cost which\nis sum of direct power cost and the indirect dissatisfaction cost. We show\nthat, taking player specific price independent dissatisfaction cost in to\naccount, contrary to popular belief, herding only happens at lower EV uptake.\nMoreover, this is true for both linear and logistic dissatisfaction functions.\nWe study the question of existence of price profiles to induce a desired\nequilibrium. We define two types of equilibria, distributed and non-distributed\nequilibria, and show that under logistic dissatisfaction, only non-distributed\nequilibria are possible by feasibly setting prices. In linear case, both type\nof equilibria are possible but price discrimination is necessary to induce\ndistributed equilibria. Finally, we show that in the case of symmetric EV\nusers, mediation cannot improve upon Nash equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.15035v2"
    },
    {
        "title": "Optimal Mechanism Design for Agents with DSL Strategies: The Case of\n  Sybil Attacks in Combinatorial Auctions",
        "authors": [
            "Yotam Gafni",
            "Moshe Tennenholtz"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In robust decision making under uncertainty, a natural choice is to go with\nsafety (aka security) level strategies. However, in many important cases, most\nnotably auctions, there is a large multitude of safety level strategies, thus\nmaking the choice unclear. We consider two refined notions:\n  (i) a term we call DSL (distinguishable safety level), and is based on the\nnotion of ``discrimin'', which uses a pairwise comparison of actions while\nremoving trivial equivalencies. This captures the fact that when comparing two\nactions an agent should not care about payoffs in situations where they lead to\nidentical payoffs.\n  (ii) The well-known Leximin notion from social choice theory, which we apply\nfor robust decision-making. In particular, the leximin is always DSL but not\nvice-versa.\n  We study the relations of these notions to other robust notions, and\nillustrate the results of their use in auctions and other settings. Economic\ndesign aims to maximize social welfare when facing self-motivated participants.\nIn online environments, such as the Web, participants' incentives take a novel\nform originating from the lack of clear agent identity -- the ability to create\nSybil attacks, i.e., the ability of each participant to act using multiple\nidentities. It is well-known that Sybil attacks are a major obstacle for\nwelfare-maximization. Our main result proves that when DSL attackers face\nuncertainty over the auction's bids, the celebrated VCG mechanism is\nwelfare-maximizing even under Sybil attacks. Altogether, our work shows a\nsuccessful fundamental synergy between robustness under uncertainty, economic\ndesign, and agents' strategic manipulations in online multi-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.15181v3"
    },
    {
        "title": "Information Design in Allocation with Costly Verification",
        "authors": [
            "Yi-Chun Chen",
            "Gaoji Hu",
            "Xiangqian Yang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A principal who values an object allocates it to one or more agents. Agents\nlearn private information (signals) from an information designer about the\nallocation payoff to the principal. Monetary transfer is not available but the\nprincipal can costly verify agents' private signals. The information designer\ncan influence the agents' signal distributions, based upon which the principal\nmaximizes the allocation surplus. An agent's utility is simply the probability\nof obtaining the good. With a single agent, we characterize (i) the\nagent-optimal information, (ii) the principal-worst information, and (iii) the\nprincipal-optimal information. Even though the objectives of the principal and\nthe agent are not directly comparable, we find that any agent-optimal\ninformation is principal-worst. Moreover, there exists a robust mechanism that\nachieves the principal's payoff under (ii), which is therefore an optimal\nrobust mechanism. Many of our results extend to the multiple-agent case; if\nnot, we provide counterexamples.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.16001v1"
    },
    {
        "title": "Rationalization of indecisive choice behavior by majoritarian ballots",
        "authors": [
            "José Carlos R. Alcantud",
            "Domenico Cantone",
            "Alfio Giarlotta",
            "Stephen Watson"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We describe a model that explains possibly indecisive choice behavior, that\nis, quasi-choices (choice correspondences that may be empty on some menus). The\njustification is here provided by a proportion of ballots, which are\nquasi-choices rationalizable by an arbitrary binary relation. We call a\nquasi-choice $s$-majoritarian if all options selected from a menu are endorsed\nby a share of ballots larger than $s$. We prove that all forms of\nmajoritarianism are equivalent to a well-known behavioral property, namely\nChernoff axiom. Then we focus on two paradigms of majoritarianism, whereby\neither a simple majority of ballots justifies a quasi-choice, or the\nendorsement by a single ballot suffices - a liberal justification. These\nbenchmark explanations typically require a different minimum number of ballots.\nWe determine the asymptotic minimum size of a liberal justification.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.16885v1"
    },
    {
        "title": "Distortion risk measures in random environments: construction and\n  axiomatic characterization",
        "authors": [
            "Shuo Gong",
            "Yijun Hu",
            "Linxiao Wei"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The risk of a financial position shines through by means of the fluctuation\nof its market price. The factors affecting the price of a financial position\ninclude not only market internal factors, but also other various market\nexternal factors. The latter can be understood as sorts of environments to\nwhich financial positions have to expose. Motivated by this observation, this\npaper aims to design a novel axiomatic approach to risk measures in random\nenvironments. We construct a new distortion-type risk measure, which can\nappropriately evaluate the risk of financial positions in the presence of\nenvironments. After having studied its fundamental properties, we also\naxiomatically characterize it by proposing a novel set of axioms. Furthermore,\nits coherence and dual representation are investigated. The new class of risk\nmeasures in random environments is rich enough, for example, it not only can\nrecover some known risk measures such as the common weighted value at risk and\nrange value at risk, but also can induce other new specific risk measures such\nas risk measures in the presence of background risk. Examples are given to\nillustrate the new framework of risk measures. This paper gives some\ntheoretical results about risk measures in random environments, helping one to\nhave an insight look at the potential impact of environments on risk measures\nof positions.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.00520v3"
    },
    {
        "title": "Discovery through Trial Balloons",
        "authors": [
            "Eitan Sapiro-Gheiler"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A principal and an agent face symmetric uncertainty about the value of two\ncorrelated projects for the agent. The principal chooses which project values\nto publicly discover and makes a proposal to the agent, who accepts if and only\nif the expected sum of values is positive. We characterize optimal discovery\nfor various principal preferences: maximizing the probability of the grand\nbundle, of having at least one project approved, and of a weighted combination\nof projects. Our results highlight the usefulness of trial balloons: projects\nwhich are ex-ante disfavored but have higher variance than a more favored\nalternative. Discovering disfavored projects may be optimal even when their\nvariance is lower than that of the alternative, so long as their\ndisfavorability is neither too large nor too small. These conclusions\nrationalize the inclusion of controversial policies in omnibus bills and the\npresence of moonshot projects in organizations.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02743v2"
    },
    {
        "title": "On Existence of alpha-Core Solutions for Games with Finite or Infinite\n  Players",
        "authors": [
            "Qi-Qing Song",
            "Min Guo"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This gives two existence results of alpha-core solutions by introducing\nP-open conditions and strong P-open conditions into games without ordered\npreferences. The existence of alpha-core solutions is obtained for games with\ninfinite-players. Secondly, it provides a short proof of Kajii's (Journal of\nEconomic Theory 56, 194-205, 1992) existence theorem for alpha-core solutions,\nfurther, the Kajii's theorem is equivalent to the Browder fixed point theorem.\nIn addition, the obtained existence results can include many typical results\nfor alpha-core solutions and some recent existence results as special cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03112v3"
    },
    {
        "title": "Arbitrage from a Bayesian's Perspective",
        "authors": [
            "Ayan Bhattacharya"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper builds a model of interactive belief hierarchies to derive the\nconditions under which judging an arbitrage opportunity requires Bayesian\nmarket participants to exercise their higher-order beliefs. As a Bayesian, an\nagent must carry a complete recursion of priors over the uncertainty about\nfuture asset payouts, the strategies employed by other market participants that\nare aggregated in the price, other market participants' beliefs about the\nagent's strategy, other market participants beliefs about what the agent\nbelieves their strategies to be, and so on ad infinitum. Defining this infinite\nrecursion of priors -- the belief hierarchy so to speak -- along with how they\nupdate gives the Bayesian decision problem equivalent to the standard asset\npricing formulation of the question. The main results of the paper show that an\narbitrage trade arises only when an agent updates his recursion of priors about\nthe strategies and beliefs employed by other market participants. The paper\nthus connects the foundations of finance to the foundations of game theory by\nidentifying a bridge from market arbitrage to market participant belief\nhierarchies.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03244v1"
    },
    {
        "title": "Strategies in deterministic totally-ordered-time games",
        "authors": [
            "Tomohiko Kawamori"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider deterministic totally-ordered-time games. We present three axioms\nfor strategies. We show that for any tuple of strategies that satisfy the\naxioms, there exists a unique complete history that is consistent with the\nstrategy tuple.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03398v1"
    },
    {
        "title": "Coordination through ambiguous language",
        "authors": [
            "Michele Crescenzi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We provide a syntactic construction of correlated equilibrium. For any finite\ngame, we study how players coordinate their play on a signal by means of a\npublic strategy whose instructions are expressed in some natural language.\nLanguage can be ambiguous in that different players may assign different truth\nvalues to the very same formula in the same state of the world. We model\nambiguity using the player-dependent logic of Halpern and Kets (2015). We show\nthat, absent any ambiguity, self-enforcing coordination always induces a\ncorrelated equilibrium of the underlying game. When language ambiguity is\nallowed, self-enforcing coordination strategies induce subjective correlated\nequilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03426v1"
    },
    {
        "title": "Nash implementation by stochastic mechanisms: a simple full\n  characterization",
        "authors": [
            "Siyang Xiong"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study Nash implementation by stochastic mechanisms, and provide a\nsurprisingly simple full characterization, which is in sharp contrast to the\nclassical, albeit complicated, full characterization in Moore and Repullo\n(1990).\n",
        "pdf_link": "http://arxiv.org/pdf/2211.05431v1"
    },
    {
        "title": "Two-Person Bargaining when the Disagreement Point is Private Information",
        "authors": [
            "Eric van Damme",
            "Xu Lang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider two-person bargaining problems in which (only) the disagreement\noutcome is private (and possibly correlated) information and it is common\nknowledge that disagreement is inefficient. We show that if the Pareto frontier\nis linear, the outcome of an ex post efficient mechanism cannot depend on the\ndisagreement payoffs. If the frontier is non-linear, the result continues to\nhold when the disagreement payoffs are independent or there is a player with at\nmost two types. We discuss implications of these results for axiomatic\nbargaining theory and for full surplus extraction in mechanism design.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.06830v2"
    },
    {
        "title": "Firm-worker hypergraphs",
        "authors": [
            "Chao Huang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A firm-worker hypergraph consists of edges in which each edge joins a firm\nand its possible employees. We show that a stable matching exists in both\nmany-to-one matching with transferable utilities and discrete many-to-one\nmatching when the firm-worker hypergraph has no nontrivial odd-length cycle.\nFirms' preferences satisfying this condition arise in a problem of matching\nspecialized firms with specialists.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.06887v3"
    },
    {
        "title": "Optimal Pricing Schemes in the Presence of Social Learning and Costly\n  Reporting",
        "authors": [
            "Kaiwei Zhang",
            "Xi Weng",
            "Xienan Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A monopoly platform sells either a risky product (with unknown utility) or a\nsafe product (with known utility) to agents who sequentially arrive and learn\nthe utility of the risky product by the reporting of previous agents. It is\ncostly for agents to report utility; hence the platform has to design both the\nprices and the reporting bonus to motivate the agents to explore and generate\nnew information. By allowing sellers to set bonuses, we are essentially\nenabling them to dynamically control the supply of learning signals without\nsignificantly affecting the demand for the product. We characterize the optimal\nbonus and pricing schemes offered by the profit-maximizing platform. It turns\nout that the optimal scheme falls into one of four types: Full Coverage,\nPartial Coverage, Immediate Revelation, and Non-Bonus. In a model of\nexponential bandit, we find that there is a dynamical switch of the types along\nthe learning trajectory. Although learning stops efficiently, information is\nrevealed too slowly compared with the planner's optimal solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.07362v4"
    },
    {
        "title": "The Texas Shootout under Uncertainty",
        "authors": [
            "Gerrit Bauch",
            "Frank Riedel"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We investigate the allocation of a co-owned company to a single owner using\nthe Texas Shoot-Out mechanism with private valuations. We identify Knightian\nUncertainty about the peer's distribution as a reason for its deterrent effect\nof a premature dissolving. Modeling uncertainty by a distribution band around a\nreference distribution $F$, we derive the optimal price announcement for an\nambiguity averse divider. The divider hedges against uncertainty for valuations\nclose to the median of $F$, while extracting expected surplus for high and low\nvaluations. The outcome of the mechanism is efficient for valuations around the\nmedian. A risk neutral co-owner prefers to be the chooser, even strictly so for\nany valuation under low levels of uncertainty and for extreme valuations under\nhigh levels of uncertainty. If valuations are believed to be close, less\nuncertainty is required for the mechanism to always be efficient and reduce\npremature dissolvements.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.10089v1"
    },
    {
        "title": "Revenue Comparisons of Auctions with Ambiguity Averse Sellers",
        "authors": [
            "Sosung Baik",
            "Sung-Ha Hwang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the revenue comparison problem of auctions when the seller has a\nmaxmin expected utility preference. The seller holds a set of priors around\nsome reference belief, interpreted as an approximating model of the true\nprobability law or the focal point distribution. We develop a methodology for\ncomparing the revenue performances of auctions: the seller prefers auction X to\nauction Y if their transfer functions satisfy a weak form of the\nsingle-crossing condition. Intuitively, this condition means that a bidder's\npayment is more negatively associated with the competitor's type in X than in\nY. Applying this methodology, we show that when the reference belief is\nindependent and identically distributed (IID) and the bidders are ambiguity\nneutral, (i) the first-price auction outperforms the second-price and all-pay\nauctions, and (ii) the second-price and all-pay auctions outperform the war of\nattrition. Our methodology yields results opposite to those of the Linkage\nPrinciple.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.12669v1"
    },
    {
        "title": "Efficient Communication in Organizations",
        "authors": [
            "Federico Vaccari"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies the organization of communication between biased senders\nand a receiver. Senders can misreport their private information at a cost.\nEfficiency is achieved by clearing information asymmetries without incurring\ncosts. Results show that only one communication protocol is efficient, robust\nto collusion, and free from unnecessary complexities. This protocol has a\nsimple, adversarial, and public structure. It always induces efficient\nequilibria, for which a closed-form characterization is provided. The findings\nare relevant for the design of organizations that seek to improve\ndecision-making while limiting wasteful influence activities.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.13605v3"
    },
    {
        "title": "Distributionally Robust Optimal Allocation with Costly Verification",
        "authors": [
            "Halil İbrahim Bayrak",
            "Çağıl Koçyiğit",
            "Daniel Kuhn",
            "Mustafa Çelebi Pınar"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider the mechanism design problem of a principal allocating a single\ngood to one of several agents without monetary transfers. Each agent desires\nthe good and uses it to create value for the principal. We designate this value\nas the agent's private type. Even though the principal does not know the\nagents' types, she can verify them at a cost. The allocation of the good thus\ndepends on the agents' self-declared types and the results of any verification\nperformed, and the principal's payoff matches her value of the allocation minus\nthe costs of verification. It is known that if the agents' types are\nindependent, then a favored-agent mechanism maximizes her expected payoff.\nHowever, this result relies on the unrealistic assumptions that the agents'\ntypes follow known independent probability distributions. In contrast, we\nassume here that the agents' types are governed by an ambiguous joint\nprobability distribution belonging to a commonly known ambiguity set and that\nthe principal maximizes her worst-case expected payoff. We study support-only\nambiguity sets, which contain all distributions supported on a rectangle,\nMarkov ambiguity sets, which contain all distributions in a support-only\nambiguity set satisfying some first-order moment bounds, and Markov ambiguity\nsets with independent types, which contain all distributions in a Markov\nambiguity set under which the agents' types are mutually independent. In all\ncases we construct explicit favored-agent mechanisms that are not only optimal\nbut also Pareto-robustly optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.15122v3"
    },
    {
        "title": "Repeat Voting: Two-Vote May Lead More People To Vote",
        "authors": [
            "Sergiu Hart"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A \"repeat voting\" procedure is proposed, whereby voting is carried out in two\nidentical rounds. Every voter can vote in each round, the results of the first\nround are made public before the second round, and the final result is\ndetermined by adding up all the votes in both rounds. It is argued that this\nsimple modification of election procedures may well increase voter\nparticipation and result in more accurate and representative outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.16282v1"
    },
    {
        "title": "Robust Contracts with Exploration",
        "authors": [
            "Chang Liu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a two-period moral hazard problem; there are two agents, with action\nsets that are unknown to the principal. The principal contracts with each agent\nsequentially, and seeks to maximize the worst-case discounted sum of payoffs,\nwhere the worst case is over the possible action sets. The principal observes\nthe action chosen by the first agent, and then offers a new contract to the\nsecond agent based on this knowledge, thus having the opportunity to explore in\nthe first period. We introduce and compare three different notions of dynamic\nworst-case considerations. Within each notion, we define a suitable rule of\nupdating and characterize the principal's optimal payoff guarantee. We find\nthat linear contracts are robustly optimal not only in static settings, but\nalso in dynamic environments with exploration.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00157v2"
    },
    {
        "title": "Who Controls the Agenda Controls the Polity",
        "authors": [
            "S. Nageeb Ali",
            "B. Douglas Bernheim",
            "Alexander W. Bloedel",
            "Silvia Console Battilana"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper models legislative decision-making with an agenda setter who can\npropose policies sequentially, tailoring each proposal to the status quo that\nprevails after prior votes. Voters are sophisticated and the agenda setter\ncannot commit to her future proposals. Nevertheless, the agenda setter obtains\nher favorite outcome in every equilibrium regardless of the initial default\npolicy. Central to our results is a new condition on preferences,\nmanipulability, that holds in rich policy spaces, including spatial settings\nand distribution problems. Our results overturn the conventional wisdom that\nvoter sophistication alone constrains an agenda setter's power.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01263v1"
    },
    {
        "title": "Digital leisure and the gig economy: a two-sector model of growth",
        "authors": [
            "Francesco Angelini",
            "Luca V. Ballestra",
            "Massimiliano Castellani"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The process of market digitization at the world level and the increasing and\nextended usage of digital devices reshaped the way consumers employ their\nleisure time, with the emergence of what can be called digital leisure. This\nnew type of leisure produces data that firms can use, with no explicit cost\npaid by consumers. At the same time, the global digitalization process has\nallowed workers to allocate part of (or their whole) working time to the Gig\nEconomy sector, which strongly relies on data as a production factor. In this\npaper, we develop a two-sector growth model to study how the above mechanism\ncan shape the dynamics of growth, also assessing how shocks in either the\ntraditional or the Gig Economy sector can modify the equilibrium of the overall\neconomy. We find that shocks in the TFP can crowd out working time from a\nsector to the other, while shocks on the elasticity of production to data\ndetermines a change in the time allocated to digital leisure.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.02119v1"
    },
    {
        "title": "Bounded arbitrage and nearly rational behavior",
        "authors": [
            "Leandro Nascimento"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We establish the equivalence between a principle of almost absence of\narbitrage opportunities and nearly rational decision-making. The implications\nof such principle are considered in the context of the aggregation of\nprobabilistic opinions and of stochastic choice functions. In the former a\nbounded arbitrage principle and its equivalent form as an approximately Pareto\ncondition are shown to bound the difference between the collective\nprobabilistic assessment of a set of states and a linear aggregation rule on\nthe individual assessments. In the latter we show that our general principle of\nlimited arbitrage opportunities translates into a weakening of the\nMcFadden-Richter axiom of stochastic rationality, and gives an upper bound for\nthe minimum distance of a stochastic choice function to another in the class of\nrandom utility maximization models.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.02680v2"
    },
    {
        "title": "Respecting priorities versus respecting preferences in school choice:\n  When is there a trade-off?",
        "authors": [
            "Estelle Cantillon",
            "Li Chen",
            "Juan S. Pereyra"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A classic trade-off that school districts face when deciding which matching\nalgorithm to use is that it is not possible to always respect both priorities\nand preferences. The student-proposing deferred acceptance algorithm (DA)\nrespects priorities but can lead to inefficient allocations. We identify a new\ncondition on school choice markets under which DA is efficient. Our condition\ngeneralizes earlier conditions by placing restrictions on how preferences and\npriorities relate to one another only on the parts that are relevant for the\nassignment. Whenever there is a unique allocation that respects priorities, our\ncondition captures all the environments for which DA is efficient. We show\nthrough stylized examples and simulations that our condition significantly\nexpands the range of known environments for which DA is efficient. We also\ndiscuss how our condition sheds light on existing empirical findings.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.02881v3"
    },
    {
        "title": "Screening with Persuasion",
        "authors": [
            "Dirk Bergemann",
            "Tibor Heumann",
            "Stephen Morris"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider a general nonlinear pricing environment with private information.\nThe seller can control both the signal that the buyers receive about their\nvalue and the selling mechanism. We characterize the optimal menu and\ninformation structure that jointly maximize the seller's profits. The optimal\nscreening mechanism has finitely many items even with a continuum of values. We\nidentify sufficient conditions under which the optimal mechanism has a single\nitem. Thus the seller decreases the variety of items below the efficient level\nas a by-product of reducing the information rents of the buyer.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.03360v1"
    },
    {
        "title": "An Ellsberg paradox for ambiguity aversion",
        "authors": [
            "Christoph Kuzmics",
            "Brian W. Rogers",
            "Xiannong Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The 1961 Ellsberg paradox is typically seen as an empirical challenge to the\nsubjective expected utility framework. Experiments based on Ellsberg's design\nhave spawned a variety of new approaches, culminating in a new paradigm\nrepresented by, now classical, models of ambiguity aversion. We design and\nimplement a decision-theoretic lab experiment that is extremely close to the\noriginal Ellsberg design and in which, empirically, subjects make choices very\nsimilar to those in the Ellsberg experiments. In our environment, however,\nthese choices cannot be rationalized by any of the classical models of\nambiguity aversion.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.03603v2"
    },
    {
        "title": "Utility-Based Communication Requirements for Stable Matching in Large\n  Markets",
        "authors": [
            "Naveen Durvasula"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Results from the communication complexity literature have demonstrated that\nstable matching requires communication: one cannot find or verify a stable\nmatch without having access to essentially all of the ordinal preference\ninformation held privately by the agents in the market. Stated differently,\nthese results show that stable matching mechanisms are not robust to even a\nsmall number of labeled inaccuracies in the input preferences. In practice,\nthese results indicate that agents must go through the time-intensive process\nof accurately ranking each and every potential match candidate if they wish for\nthe resulting match to be guaranteedly stable. Thus, in large markets,\ncommunication requirements for stable matching may be impractically high.\n  A natural question to ask, given this result, is whether some higher-order\nstructure in the market can indicate which large markets have steeper\ncommunication requirements. In this paper, we perform such an analysis in a\nregime where agents have a utility-based notion of preference. We consider a\ndynamic model where agents only have access to an approximation of their\nutility that satisfies a universal multiplicative error bound. We apply\nguarantees from the theoretical computer science literature on low-distortion\nembeddings of finite metric spaces to understand the communication requirements\nof stable matching in large markets in terms of their structural properties.\nOur results show that for a broad family of markets, the error bound may not\ngrow faster than $n^2\\log(n)$ while maintaining a deterministic guarantee on\nthe behavior of stable matching mechanisms in the limit. We also show that a\nstronger probabilistic guarantee may be made so long as the bound grows at most\nlogarithmically in the underlying topological complexity of the market.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.04024v1"
    },
    {
        "title": "Price & Choose",
        "authors": [
            "Federico Echenique",
            "Matías Núñez"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We describe a two-stage mechanism that fully implements the set of efficient\noutcomes in two-agent environments with quasi-linear utilities. The mechanism\nasks one agent to set prices for each outcome, and the other agent to make a\nchoice, paying the corresponding price: Price \\& Choose. We extend our\nimplementation result in three main directions: an arbitrary number of players,\nnon-quasi linear utilities, and robustness to max-min behavior. Finally, we\ndiscuss how to reduce the payoff inequality between players while still\nachieving efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.05650v2"
    },
    {
        "title": "Sequential Cursed Equilibrium",
        "authors": [
            "Shani Cohen",
            "Shengwu Li"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We propose an extensive-form solution concept, with players that neglect\ninformation from hypothetical events, but make inferences from observed events.\nOur concept modifies cursed equilibrium (Eyster and Rabin, 2005), and allows\nthat players can be 'cursed about' endogenous information.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.06025v4"
    },
    {
        "title": "Topology-Free Type Structures with Conditioning Events",
        "authors": [
            "Pierfrancesco Guarino"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We establish the existence of the universal type structure in presence of\nconditioning events without any topological assumption, namely, a type\nstructure that is terminal, belief-complete, and non-redundant, by performing a\nconstruction \\`a la Heifetz & Samet (1998). In doing so, we answer\naffirmatively to a longstanding conjecture made by Battigalli & Siniscalchi\n(1999) concerning the possibility of performing such a construction with\nconditioning events. In particular, we obtain the result by exploiting\narguments from category theory and the theory of coalgebras, thus, making\nexplicit the mathematical structure underlining all the constructions of large\ninteractive structures and obtaining the belief-completeness of the structure\nas an immediate corollary of known results from these fields.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07246v4"
    },
    {
        "title": "Information and Learning in Economic Theory",
        "authors": [
            "Annie Liang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  These lecture notes accompany a one-semester graduate course on information\nand learning in economic theory. Topics include common knowledge, Bayesian\nupdating, monotone-likelihood ratio properties, affiliation, the Blackwell\norder, cost of information, learning and merging of beliefs, model uncertainty,\nmodel misspecification, and information design.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07521v2"
    },
    {
        "title": "Sequential Sampling Equilibrium",
        "authors": [
            "Duarte Gonçalves"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper introduces an equilibrium framework based on sequential sampling\nin which players face strategic uncertainty over their opponents' behavior and\nacquire informative signals to resolve it. Sequential sampling equilibrium\ndelivers a disciplined model featuring an endogenous distribution of choices,\nbeliefs, and decision times, that not only rationalizes well-known deviations\nfrom Nash equilibrium, but also makes novel predictions supported by existing\ndata. It grounds a relationship between empirical learning and strategic\nsophistication, and generates stochastic choice through randomness inherent to\nsampling, without relying on indifference or choice mistakes. Further, it\nprovides a rationale for Nash equilibrium when sampling costs vanish.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07725v2"
    },
    {
        "title": "Rationally Inattentive Statistical Discrimination: Arrow Meets Phelps",
        "authors": [
            "Federico Echenique",
            "Anqi Li"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  When information acquisition is costly but flexible, a principal may\nrationally acquire information that favors one group over another. The former\ngroup faces incentives to invest in becoming productive, while the latter is\ndiscouraged from such investments. The principal, in turn, ignores the\nproductivity difference between groups unless the underinvested group surprises\nhim with a genuinely outstanding outcome. We give conditions under which the\ndiscriminatory equilibrium is most preferred by the principal, despite all\ngroups being ex-ante identical. Our results inform the discussion of\naffirmative action, implicit bias, and occupational segregation and\nstereotypes.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.08219v4"
    },
    {
        "title": "Expected Growth Criterion: An Axiomatization",
        "authors": [
            "Joshua Lawson"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I provide necessary and sufficient conditions for an agent's preferences to\nbe represented by a unique ergodic transformation. Put differently, if an agent\nseeks to maximize the time average growth of their wealth, what axioms must\ntheir preferences obey? By answering this, I provide economic theorists a clear\nview of where \"Ergodicity Economics\" deviates from established models.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.09617v1"
    },
    {
        "title": "Strategic Observational Learning",
        "authors": [
            "Dimitri Migrow"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study learning by privately informed forward-looking agents in a simple\nrepeated-action setting of social learning. Under a symmetric signal structure,\nforward-looking agents behave myopically for any degrees of patience. Myopic\nequilibrium is unique in the class of symmetric threshold strategies, and the\nsimplest symmetric non-monotonic strategies. If the signal structure is\nasymmetric and the game is infinite, there is no equilibrium in myopic\nstrategies, for any positive degree of patience.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.09889v2"
    },
    {
        "title": "Single-Crossing Differences in Convex Environments",
        "authors": [
            "Navin Kartik",
            "SangMok Lee",
            "Daniel Rappoport"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  An agent's preferences depend on an ordered parameter or type. We\ncharacterize the set of utility functions with single-crossing differences\n(SCD) in convex environments. These include preferences over lotteries, both in\nexpected utility and rank-dependent utility frameworks, and preferences over\nbundles of goods and over consumption streams. Our notion of SCD does not\npresume an order on the choice space. This unordered SCD is necessary and\nsufficient for ''interval choice'' comparative statics. We present applications\nto cheap talk, observational learning, and collective choice, showing how\nconvex environments arise in these problems and how SCD/interval choice are\nuseful. Methodologically, our main characterization stems from a result on\nlinear aggregations of single-crossing functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.12009v2"
    },
    {
        "title": "The Simple Economics of Optimal Bundling",
        "authors": [
            "Frank Yang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study optimal bundling when consumers differ in one dimension. We\nintroduce a partial order on the set of bundles defined by (i) set inclusion\nand (ii) sales volumes (if sold alone and priced optimally). We show that if\nthe undominated bundles with respect to this partial order are nested, then\nnested bundling (tiered pricing) is optimal. We characterize which nested menu\nis optimal: Selling a given menu of nested bundles is optimal if a smaller\nbundle in (out of) the menu sells more (less) than a bigger bundle in the menu.\nWe present three applications of these insights: the first two connect optimal\nbundling and quality design to price elasticities and cost structures; the last\none establishes a necessary and sufficient condition for costly screening to be\noptimal when a principal can use both price and nonprice screening instruments.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.12623v2"
    },
    {
        "title": "Optimal Robust Mechanism in Bilateral Trading",
        "authors": [
            "Komal Malik"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider a model of bilateral trade with private values. The value of the\nbuyer and the cost of the seller are jointly distributed. The true joint\ndistribution is unknown to the designer, however, the marginal distributions of\nthe value and the cost are known to the designer. The designer wants to find a\ntrading mechanism that is robustly Bayesian incentive compatible, robustly\nindividually rational, budget-balanced and maximizes the expected gains from\ntrade over all such mechanisms. We refer to such a mechanism as an optimal\nrobust mechanism. We establish equivalence between Bayesian incentive\ncompatible mechanisms (BIC) and dominant strategy mechanisms (DSIC). We\ncharacterise the worst distribution for a given mechanism and use this\ncharacterisation to find an optimal robust mechanism. We show that there is an\noptimal robust mechanism that is deterministic (posted-price), dominant\nstrategy incentive compatible, and ex-post individually rational. We also\nderive an explicit expression of the posted-price of such an optimal robust\nmechanism. We also show the equivalence between the efficiency gains from the\noptimal robust mechanism (max-min problem) and guaranteed efficiency gains if\nthe designer could choose the mechanism after observing the true joint\ndistribution (min-max problem).\n",
        "pdf_link": "http://arxiv.org/pdf/2212.14367v1"
    },
    {
        "title": "Innovation through intra and inter-regional interaction in economic\n  geography",
        "authors": [
            "José M. Gaspar",
            "Minoru Osawa"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We develop a two-region economic geography model with vertical innovations\nthat improve the quality of manufactured varieties produced in each region. The\nchance of innovation depends on the \\emph{related variety}, i.e. the importance\nof interaction between researchers within the same region rather than across\ndifferent regions. As economic integration increases from a low level, a higher\nrelated variety is associated with more agglomerated spatial configurations.\nHowever, if the interaction with foreign scientists is relatively more\nimportant for innovation, economic activities may (completely) re-disperse\nafter an initial phase of agglomeration due to the increase in the relative\nimportance of a higher chance of innovation in the less industrialized region.\nThis non-monotonic relationship between economic integration and spatial\nimbalances may exhibit very diverse qualitative properties, not yet described\nin the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.14475v6"
    },
    {
        "title": "Identification of consideration sets from choice data",
        "authors": [
            "Davide Carpentiere",
            "Angelo Petralia"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We show that many bounded rationality patterns of choice can be alternatively\nrepresented as testable models of limited consideration, and we elicit the\nfeatures of the associated unobserved consideration sets from the observed\nchoice. Moreover, we characterize some testable choice procedures in which the\nDM considers as few alternatives as possible. These properties, compatible with\nthe empirical evidence, allow the experimenter to uniquely infer the DM's\nunobserved consideration sets from irrational features of the observed\nbehavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00978v8"
    },
    {
        "title": "Monotone Function Intervals: Theory and Applications",
        "authors": [
            "Kai Hao Yang",
            "Alexander K. Zentefis"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A monotone function interval is the set of monotone functions that lie\npointwise between two fixed monotone functions. We characterize the set of\nextreme points of monotone function intervals and apply this to a number of\neconomic settings. First, we leverage the main result to characterize the set\nof distributions of posterior quantiles that can be induced by a signal, with\napplications to political economy, Bayesian persuasion, and the psychology of\njudgment. Second, we combine our characterization with properties of convex\noptimization problems to unify and generalize seminal results in the literature\non security design under adverse selection and moral hazard.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03135v5"
    },
    {
        "title": "Regulating Oligopolistic Competition",
        "authors": [
            "Kai Hao Yang",
            "Alexander K. Zentefis"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider the problem of how to regulate an oligopoly when firms have\nprivate information about their costs. In the environment, consumers make\ndiscrete choices over goods, and minimal structure is placed on the manner in\nwhich firms compete. In the optimal regulatory policy, the regulator need only\nsolicit prices from firms, and based on those prices, charge them taxes or give\nthem subsidies, and impose on each firm a ``yardstick'' price cap that depends\non the posted prices of competing firms.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03185v3"
    },
    {
        "title": "Axiomatization of Random Utility Model with Unobservable Alternatives",
        "authors": [
            "Haruki Kono",
            "Kota Saito",
            "Alec Sandroni"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The random utility model is one of the most fundamental models in economics.\nFalmagne (1978) provides an axiomatization but his axioms can be applied only\nwhen choice frequencies of all alternatives from all subsets are observable. In\nreality, however, it is often the case that we do not observe choice\nfrequencies of some alternatives. For such a dataset, we obtain a finite system\nof linear inequalities that is necessary and sufficient for the dataset to be\nrationalized by a random utility model. Moreover, the necessary and sufficient\ncondition is tight in the sense that none of the inequalities is implied by the\nother inequalities, and dropping any one of the inequalities makes the\ncondition not sufficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03913v3"
    },
    {
        "title": "Dynamic and Stochastic Rational Behavior",
        "authors": [
            "Nail Kashaev",
            "Victor H. Aguiar",
            "Martin Plávala",
            "Charles Gauthier"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The (static) utility maximization model of Afriat (1967), which is the\nstandard in analysing choice behavior, is under scrutiny. We propose the\nDynamic Random Utility Model (DRUM) that is more flexible than the framework of\nAfriat (1967) and more informative than the static Random Utility Model (RUM)\nframework of McFadden and Richter (1990). Under DRUM, each decision-maker\nrandomly draws a utility function in each period and maximizes it subject to a\nmenu. DRUM allows for unrestricted time correlation and cross-section\nheterogeneity in preferences. We characterize DRUM for situations when panel\ndata on choices and menus are available. DRUM is linked to a finite mixture of\ndeterministic behaviors that can be represented as a product of static\nrationalizable behaviors. This link allows us to convert the characterizations\nof the static RUM to its dynamic form. In an application, we find that although\nthe static utility maximization model fails to explain population behavior,\nDRUM can explain it.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04417v3"
    },
    {
        "title": "Random Utility, Repeated Choice, and Consumption Dependence",
        "authors": [
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study consumption dependence in the context of random utility and repeated\nchoice. We show that, in the presence of consumption dependence, the random\nutility model is a misspecified model of repeated rational choice. This\nmisspecification leads to biased estimators and failures of standard random\nutility axioms. We characterize exactly when and by how much the random utility\nmodel is misspecified when utilities are consumption dependent. As one possible\nsolution to this problem, we consider time disaggregated data. We offer a\ncharacterization of consumption dependent random utility when we observe time\ndisaggregated data. Using this characterization, we develop a hypothesis test\nfor consumption dependent random utility that offers computational improvements\nover the natural extension of Kitamura and Stoye (2018) to our setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05806v5"
    },
    {
        "title": "Comparison Shopping: Learning Before Buying From Duopolists",
        "authors": [
            "Brian C. Albrecht",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We explore a model of duopolistic competition in which consumers learn about\nthe fit of each competitor's product. In equilibrium, consumers comparison\nshop: they learn only about the relative values of the products. When\ninformation is cheap, increasing the cost of information decreases consumer\nwelfare; but when information is expensive, this relationship flips. As\ninformation frictions vanish, there is a limiting equilibrium that is ex post\nefficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06580v2"
    },
    {
        "title": "Solidarity to achieve stability",
        "authors": [
            "Jorge Alcalde-Unzu",
            "Oihane Gallo",
            "Elena Inarra",
            "Juan D. Moreno-Ternero"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Agents may form coalitions. Each coalition shares its endowment among its\nagents by applying a sharing rule. The sharing rule induces a coalition\nformation problem by assuming that agents rank coalitions according to the\nallocation they obtain in the corresponding sharing problem. We characterize\nthe sharing rules that induce a class of stable coalition formation problems as\nthose that satisfy a natural axiom that formalizes the principle of solidarity.\nThus, solidarity becomes a sufficient condition to achieve stability.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.07618v2"
    },
    {
        "title": "Contest in Multitasking: An Evidence from Chinese County Officials'\n  Promotion Assessment",
        "authors": [
            "Yuanhao Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Real-world observed contests often take the form of multi-task contests\nrather than single-task contests, and existing theories are insufficient to\nexplain the incentive for extending the task dimension. This paper proposes a\nnew effect of multi-task contests compared to single-tasking contests: the\nspecialization effect (SE). By establishing a multi-task contest model with\nheterogeneous competitor costs, this paper shows that after expanding the new\ncompetition dimension, competitors will choose the dimension with greater\nrelative comparative advantage rather than absolute advantage and pay more\neffort, which eventually leads to competitors choosing higher effort levels in\nboth the original dimension and the extended dimension. The paper then uses\nstaggered Difference-in-Difference (DID) method on China's county officers'\npromotion assessment from 2001 to 2022 as an entry point to discuss the\nempirical evidence for specialization effect. Through models and empirical\nstudies, the specialization effect studied in this paper do exists in promotion\nassessments, and may also explain many other real-world scenarios, such as\nsports events, competition between corporate compensation and employee benefits\nand competition for R&D expenses.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.08691v1"
    },
    {
        "title": "Microfoundations of Expected Utility and Response Times",
        "authors": [
            "Valdes Salvador",
            "Gonzalo ValdesEdwards"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper builds a rule for decisionmaking from the physical behavior of\nsingle neurons, the well established neural circuitry of mutual inhibition, and\nthe evolutionary principle of natural selection. No axioms are used in the\nderivation of this rule. The paper provides a microfoundation to both Economics\nChoice Theory and Cognitive Psychologys Response Times Theory. The paper finds\nhow classical expected utility should be modified to account for much\nneuroscientific evidence, and how neuroscientific correlates of choice should\nbe linked to utility. In particular, the model implies the concept of utility\nis a network property and cannot be calculated as a function of frequencies in\none layer of neurons alone; it requires understanding how different layers work\ntogether. The resulting rule is simple enough to model markets and games as is\ncustomary in the social sciences. Utility maximization and inaction are\nendogenous to the model, cardinality and independence of irrelevant\nalternatives, properties present in classical and random utility theories, are\nonly met in limiting situations.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09421v1"
    },
    {
        "title": "Multiplayer War of Attrition with Asymmetric Private Information",
        "authors": [
            "Hongcheng Li",
            "Jialu Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies a war of attrition game in the setting of public good\nprovision that combines three elements: (i) multiple players, (ii) incomplete\ninformation, and (iii) ex-ante asymmetry. In the unique equilibrium, asymmetry\nleads to a stratified behavior pattern where one player provides the public\ngood instantly with a positive probability while each of the other players has\na player-specific strict waiting time, before which even his highest type will\nnot provide the good. Comparative statics show that a player with less\npatience, lower cost of provision, and higher reputation in value (expressed in\na form of hazard rate) provides the good type-wise uniformly faster. In large\nsocieties, the cost of delay is mainly determined by the highest type of the\ninstant-exit player.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09427v4"
    },
    {
        "title": "Legitimacy of collective decisions: a mechanism design approach",
        "authors": [
            "Kirneva Margarita",
            "Núñez Matías"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We design two mechanisms that ensure that the majority preferred option wins\nin all equilibria. The first one is a simultaneous game where agents choose\nother agents to cooperate with on top of the vote for an alternative, thus\novercoming recent impossibility results concerning the implementation of\nmajority rule. The second one adds sequential ratification to the standard\nmajority voting procedure allowing to reach the (correct) outcome in\nsignificantly fewer steps than the widely used roll call voting. Both\nmechanisms use off-equilibrium lotteries to incentivize truthful voting. We\ndiscuss different extensions, including the possibility for agents to abstain.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09548v3"
    },
    {
        "title": "Ignorance Is Bliss: The Screening Effect of (Noisy) Information",
        "authors": [
            "Felix Zhiyu Feng",
            "Wenyu Wang",
            "Yufeng Wu",
            "Gaoqing Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies the value of a firm's internal information when the firm\nfaces an adverse selection problem arising from unobservable managerial\nabilities. While more precise information allows the firm to make ex post more\nefficient investment decisions, noisier information has an ex ante screening\neffect that allows the firm to attract on-average better managers. The\ntrade-off between more effective screening of managers and more informed\ninvestment implies a non-monotonic relationship between firm value and\ninformation quality. A marginal improvement in information quality does not\nnecessarily lead to an overall improvement in firm value.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.11128v3"
    },
    {
        "title": "A rational measure of irrationality",
        "authors": [
            "Davide Carpentiere",
            "Alfio Giarlotta",
            "Stephen Watson"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  All possible types of deterministic choice behavior are classified by their\ndegree of irrationality. This classification is performed in three steps: (1)\nselect a benchmark of rationality, for which this degree is zero; (2) endow the\nset of choices with a metric to measure deviations from rationality; and (3)\ncompute the distance of any choice behavior from the selected benchmark. The\nnatural candidate for step 1 is the family of all rationalizable behaviors. A\npossible candidate for step 2 is a suitable variation of the metric described\nby Klamler (2008), which displays a sharp discerning power among different\ntypes of choice behaviors. In step 3 we use this new metric to establish the\nminimum distance of any choice behavior from the benchmark of rationality.\nFinally we describe a measure of stochastic irrationality, which employs the\nrandom utility model as a benchmark of rationality, and the Block-Marschak\npolynomials to measure deviations from it.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.13656v2"
    },
    {
        "title": "Blackwell-Monotone Updating Rules",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  An updating rule specifies how an agent reacts to information. An updating\nrule is Blackwell monotone if more information is always better for an agent in\na decision problem and strictly Blackwell monotone if, in addition, there is\nalways a decision problem in which more information is strictly better for an\nagent. Bayes' law is strictly Blackwell monotone, and I show that within a\nbroad class of updating rules--those that distort the Bayesian posteriors in a\nsignal-independent manner--it is the only strictly Blackwell-monotone updating\nrule. Moreover, when the state is non-binary, I show that Bayes' law and the\ntrivial updating rule in which an agent dogmatically holds a single belief are\nthe only continuous Blackwell-monotone updating rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.13956v5"
    },
    {
        "title": "Mr.Keynes and the... Complexity! A suggested agent-based version of the\n  General Theory of Employment, Interest and Money",
        "authors": [
            "Alessio Emanuele Biondo"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper presents a model with the aim to follow, as closely as possible,\nthe rationale of the macroeconomic model advanced by J.M. Keynes in his famous\n\"The General Theory of Employment, Interest and Money\", in order to provide a\nviable tool for macroeconomic research. Keynes' main result will be shown,\ni.e., to determine the level of income and employment starting from the\nmarginal efficiency of capital and the marginal propensity to consume, given\nthe interest rate. Elements of the model will be described by referring to the\noriginal text. The sequentiality in model operation will prove quintessential\nin order to describe the complex nature of macroeconomic systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00889v3"
    },
    {
        "title": "Rationalizing Path-Independent Choice Rules",
        "authors": [
            "Koji Yokote",
            "Isa E. Hafalir",
            "Fuhito Kojima",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Path independence is arguably one of the most important choice rule\nproperties in economic theory. We show that a choice rule is path independent\nif and only if it is rationalizable by a utility function satisfying ordinal\nconcavity, a concept closely related to concavity notions in discrete\nmathematics. We also provide a rationalization result for choice rules that\nsatisfy path independence and the law of aggregate demand.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00892v2"
    },
    {
        "title": "Combating Algorithmic Collusion: A Mechanism Design Approach",
        "authors": [
            "Soumen Banerjee"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Attention has recently been focused on the possibility of artificially\nintelligent sellers on platforms colluding to limit output and raise prices.\nSuch arrangements (cartels), however, feature an incentive for individual\nsellers to deviate to a lower price (cheat) to increase their own profits.\nStabilizing such cartels therefore requires credible threats of punishments,\nsuch as price wars. In this paper, I propose a mechanism to destabilize cartels\nby protecting any cheaters from a price war by guaranteeing a stream of profits\nwhich is unaffected by arbitrary punishments, only if such punishments actually\noccur. Equilibrium analysis of the induced game predicts a reversion to\nrepeated static Nash pricing. When implemented in a reinforcement learning\nframework, it provides substantial reductions in prices (reducing markups by\n40% or more), without affecting product variety or requiring the platform to\nmake any payments on path. This mechanism applies to both the sale of\ndifferentiated goods on platforms, and the sale of homogeneous goods through\ndirect sales. The mechanism operates purely off-path, thereby inducing no\nwelfare losses in practice, and does not depend on the choice of discount\nfactors.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.02576v2"
    },
    {
        "title": "Identifying the Distribution of Welfare from Discrete Choice",
        "authors": [
            "Bart Capéau",
            "Liebrecht De Sadeleer",
            "Sebastiaan Maes"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Empirical welfare analyses often impose stringent parametric assumptions on\nindividuals' preferences and neglect unobserved preference heterogeneity. We\ndevelop a framework to conduct individual and social welfare analysis for\ndiscrete choice that does not suffer from these drawbacks. We first adapt the\nclass of individual welfare measures introduced by Fleurbaey (2009) to settings\nwhere individual choice is discrete. Allowing for unrestricted, unobserved\npreference heterogeneity, these measures become random variables. We then\ndemonstrate that their distribution can be derived from choice probabilities,\nwhich can be estimated nonparametrically from cross-sectional data.\nAdditionally, we derive nonparametric results for the joint distribution of\nwelfare and welfare differences, and for social welfare. The former is an\nimportant tool in determining whether the winners of a price change belong\ndisproportionately to those groups who were initially well-off.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.02645v2"
    },
    {
        "title": "A Note on Invariant Extensions of Preorders",
        "authors": [
            "Peter Caradonna",
            "Christopher P. Chambers"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider the problem of extending an acyclic binary relation that is\ninvariant under a given family of transformations into an invariant preference.\nWe show that when a family of transformations is commutative, every acyclic\ninvariant binary relation extends. We find that, in general, the set of\nextensions agree on the ranking of many pairs that (i) are unranked by the\noriginal relation, and (ii) cannot be ranked by invariance or transitivity\nconsiderations alone. We interpret these additional implications as the\nout-of-sample predictions generated by invariance, and study their structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.04522v1"
    },
    {
        "title": "Complementarity in Demand-side Variables and Educational Participation",
        "authors": [
            "Anjan Ray Chaudhury",
            "Dipankar Das",
            "Sreemanta Sarkar"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Decision to participate in education depends on the circumstances individual\ninherits and on the returns to education she expects as well. If one person\nfrom any socio-economically disadvantaged social group inherits poor\ncircumstances measured in terms of family background, then she is having poor\nopportunities vis-\\`a-vis her capability set becomes confined. Accordingly, her\nfreedom to choose the best alternative from many is also less, and she fails to\nexpect the potential returns from educational participation. Consequently, a\ncomplementary relationship between the circumstances one inherits and the\nreturns to education she expects can be observed. This paper is an attempt to\nlook at this complementarity on the basis of theoretical logic and empirical\ninvestigation, which enables us to unearth the origin of inter-group disparity\nin educational participation, as is existed across the groups defined by taking\ncaste and gender together in Indian society. Furthermore, in the second piece\nof analysis, we assess the discrimination in the likelihood of educational\nparticipation by invoking the method of decomposition of disparity in the\nlikelihood of educational participation applicable in the logistic regression\nmodels, which enables us to re-establish the earlier mentioned complementary\nrelationship.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.04647v2"
    },
    {
        "title": "Equilibrium Selection in Pure Bubble Models by Dividend Injection",
        "authors": [
            "Tomohiro Hirano",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Rational pure bubble models feature multiple (and often a continuum of)\nequilibria, which makes model predictions and policy analyses non-robust. We\nshow that when the interest rate in the fundamental equilibrium is below the\neconomic growth rate ($R<G$), a bubbly equilibrium with $R=G$ exists. By\ninjecting dividends to the bubble asset that grow slower than the aggregate\neconomy, we can eliminate the fundamental steady state and resolve equilibrium\nindeterminacy. We show the general applicability of dividend injection through\nexamples in overlapping generations and infinite-horizon models with or without\nproduction or financial frictions.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.05636v3"
    },
    {
        "title": "Strategy-proofness with single-peaked and single-dipped preferences",
        "authors": [
            "Jorge Alcalde-Unzu",
            "Oihane Gallo",
            "Marc Vorsatz"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyze the problem of locating a public facility in a domain of\nsingle-peaked and single-dipped preferences when the social planner knows the\ntype of preference (single-peaked or single-dipped) of each agent. Our main\nresult characterizes all strategy-proof rules and shows that they can be\ndecomposed into two steps. In the first step, the agents with single-peaked\npreferences are asked about their peaks and, for each profile of reported\npeaks, at most two alternatives are preselected. In the second step, the agents\nwith single-dipped preferences are asked to reveal their dips to complete the\ndecision between the preselected alternatives. Our result generalizes the\nfindings of Moulin (1980) and Barber\\`a and Jackson (1994) for single-peaked\nand of Manjunath (2014) for single-dipped preferences. Finally, we show that\nall strategy-proof rules are also group strategy-proof and analyze the\nimplications of Pareto efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.05781v2"
    },
    {
        "title": "A General Impossibility Theorem on Pareto Efficiency and Bayesian\n  Incentive Compatibility",
        "authors": [
            "Kazuya Kikuchi",
            "Yukio Koriyama"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies a general class of social choice problems in which agents'\npayoff functions (or types) are privately observable random variables, and\nmonetary transfers are not available. We consider cardinal social choice\nfunctions which may respond to agents' preference intensities as well as\npreference rankings. We show that a social choice function is ex ante Pareto\nefficient and Bayesian incentive compatible if and only if it is dictatorial.\nThe result holds for arbitrary numbers of agents and alternatives, and under a\nfairly weak assumption on the joint distribution of types, which allows for\narbitrary correlations and asymmetries.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.05968v3"
    },
    {
        "title": "The Bounds of Mediated Communication",
        "authors": [
            "Roberto Corrao",
            "Yifan Dai"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the bounds of mediated communication in sender-receiver games in\nwhich the sender's payoff is state-independent. We show that the feasible\ndistributions over the receiver's beliefs under mediation are those that induce\nzero correlation, but not necessarily independence, between the sender's payoff\nand the receiver's belief. Mediation attains the upper bound on the sender's\nvalue, i.e., the Bayesian persuasion value, if and only if this value is\nattainable under unmediated communication, i.e., cheap talk. The lower bound is\ngiven by the cheap talk payoff. We provide a geometric characterization of when\nmediation strictly improves on this using the quasiconcave and quasiconvex\nenvelopes of the sender's value function. In canonical environments, mediation\nis strictly valuable when the sender has countervailing incentives in the space\nof the receiver's belief. We apply our results to asymmetric-information\nsettings such as bilateral trade and lobbying and explicitly construct\nmediation policies that increase the surplus of the informed and uninformed\nparties with respect to unmediated communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06244v2"
    },
    {
        "title": "Inertial Updating",
        "authors": [
            "Adam Dominiak",
            "Matthew Kovach",
            "Gerelt Tserenjigmid"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We introduce and characterize inertial updating of beliefs. Under inertial\nupdating, a decision maker (DM) chooses a belief that minimizes the subjective\ndistance between their prior belief and the set of beliefs consistent with the\nobserved event. Importantly, by varying the subjective notion of distance,\ninertial updating provides a unifying framework that nests three different\ntypes of belief updating: (i) Bayesian updating, (ii) non-Bayesian updating\nrules, and (iii) updating rules for events with zero probability, including the\nconditional probability system (CPS) of Myerson (1986a,b). We demonstrate that\nour model is behaviorally equivalent to the Hypothesis Testing model (HT) of\nOrtoleva (2012), clarifying the connection between HT and CPS. We apply our\nmodel to a persuasion game.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06336v2"
    },
    {
        "title": "Redesigning the US Army's Branching Process: A Case Study in Minimalist\n  Market Design",
        "authors": [
            "Kyle Greenberg",
            "Parag A. Pathak",
            "Tayfun Sönmez"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We present the proof-of-concept for minimalist market design (S\\\"{o}nmez,\n2023) as an effective methodology to enhance an institution based on the\ndesiderata of stakeholders with minimal interference. Four\nobjectives-respecting merit, increasing retention, aligning talent, and\nenhancing trust-guided reforms to US Army's centralized branching process of\ncadets to military specialties since 2006. USMA's mechanism for the Class of\n2020 exacerbated challenges implementing these objectives. Formulating the\nArmy's desiderata as rigorous axioms, we analyze their implications. Under our\nminimalist approach to institution redesign, the Army's objectives uniquely\nidentify a branching mechanism. Our design is now adopted at USMA and ROTC.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06564v2"
    },
    {
        "title": "Status substitution and conspicuous consumption",
        "authors": [
            "Alastair Langtry",
            "Christian Ghinglino"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper adapts ideas from social identity theory to set out a new\nframework for modelling conspicuous consumption. Agents derive status from\ntheir own conspicuous consumption and from belonging to an identity group with\nhigh conspicuous consumption. Importantly, these two sources of status are\nsubstitutes. Agents also feel pressure to conform with their neighbours in a\nnetwork. This framework can rationalise a set of seemingly conflicting stylised\nfacts about conspicuous consumption that are currently explained by different\nfamilies of models. In addition, our model delivers new testable predictions\nregarding the effect of network structure and income inequality on conspicuous\nconsumption.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07008v5"
    },
    {
        "title": "The Dynamics of Instability",
        "authors": [
            "César Barilla",
            "Duarte Gonçalves"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a model in which two players with opposing interests try to alter a\nstatus quo through instability-generating actions. We show that instability can\nbe used to secure longer-term durable changes, even if it is costly to generate\nand does not generate short-term gains. In equilibrium, instability generated\nby a player decreases when the status quo favors them more. Equilibrium always\nexhibits a region of stable states in which the status quo persists. As\nplayers' threat power increases, this region shrinks, ultimately collapsing to\na single stable state that is supported via a deterrence mechanism. There is\nlong-run path-dependency and inequity: although instability eventually leads to\na stable state, it typically selects the least favorable one for the initially\ndisadvantaged player.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07285v1"
    },
    {
        "title": "A Unified Theorem of the Alternative",
        "authors": [
            "Ian Ball"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This note presents a unified theorem of the alternative that explicitly\nallows for any combination of equality, componentwise inequality, weak\ndominance, strict dominance, and nonnegativity relations. The theorem nests 60\nspecial cases, some of which have been stated as separate theorems.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07471v1"
    },
    {
        "title": "A Story of Consistency: Bridging the Gap between Bentham and Rawls\n  Foundations",
        "authors": [
            "Stéphane Gonzalez",
            "Nikolaos Pnevmatikos"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The axiomatic foundations of Bentham and Rawls solutions are discussed within\nthe broader domain of cardinal preferences. It is unveiled that both solution\nconcepts share all four of the following axioms: Nonemptiness, Anonymity,\nUnanimity, and Continuity. In order to fully characterize the Bentham and Rawls\nsolutions, three variations of a consistency criterion are introduced and their\ncompatibility with the other axioms is assessed. Each expression of consistency\ncan be interpreted as a property of decision-making in uncertain environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07488v2"
    },
    {
        "title": "Measuring Stochastic Rationality",
        "authors": [
            "Efe A. Ok",
            "Gerelt Tserenjigmid"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Our goal is to develop a partial ordering method for comparing stochastic\nchoice functions on the basis of their individual rationality. To this end, we\nassign to any stochastic choice function a one-parameter class of deterministic\nchoice correspondences, and then check for the rationality (in the sense of\nrevealed preference) of these correspondences for each parameter value. The\nresulting ordering detects violations of (stochastic) transitivity as well as\ninconsistencies between choices from nested menus. We obtain a parameter-free\ncharacterization and apply it to some popular stochastic choice models. We also\nprovide empirical applications in terms of two well-known choice experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08202v2"
    },
    {
        "title": "Optimal Delegation in Markets for Matching with Signaling",
        "authors": [
            "Seungjin Han",
            "Alex Sam",
            "Youngki Shin"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies a delegation problem faced by the planner who wants to\nregulate receivers' reaction choices in markets for matching between receivers\nand senders with signaling. We provide a noble insight into the planner's\nwillingness to delegate and the design of optimal (reaction) interval\ndelegation as a solution to the planner's general mechanism design problem. The\nrelative heterogeneity of receiver types and the productivity of the sender'\nsignal are crucial in deriving optimal interval delegation in the presence of\nthe trade-off between matching efficiency and signaling costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.09415v1"
    },
    {
        "title": "Dynamic Information Provision: Rewarding the Past and Guiding the Future",
        "authors": [
            "Ian Ball"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I study the optimal provision of information in a long-term relationship\nbetween a sender and a receiver. The sender observes a persistent, evolving\nstate and commits to send signals over time to the receiver, who sequentially\nchooses public actions that affect the welfare of both players. I solve for the\nsender's optimal policy in closed form: the sender reports the value of the\nstate with a delay that shrinks over time and eventually vanishes. Even when\nthe receiver knows the current state, the sender retains leverage by\nthreatening to conceal the future evolution of the state.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.09675v1"
    },
    {
        "title": "Efficient Public Good Provision Between and Within Groups",
        "authors": [
            "Chowdhury Mohammad Sakib Anwar",
            "Jorge Bruno",
            "Renaud Foucart",
            "Sonali SenGupta"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We generalize the model of Gallice and Monzon (2019) to incorporate a public\ngoods game with groups, position uncertainty, and observational learning.\nContributions are simultaneous within groups, but groups play sequentially\nbased on their observation of an incomplete sample of past contributions. We\nshow that full cooperation between and within groups is possible with\nself-interested players on a fixed horizon. Position uncertainty implies the\nexistence of an equilibrium where groups of players conditionally cooperate in\nthe hope of influencing further groups. Conditional cooperation implies that\neach group member is pivotal, so that efficient simultaneous provision within\ngroups is an equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.10514v3"
    },
    {
        "title": "Decomposability and Strategy-proofness in Multidimensional Models",
        "authors": [
            "Shurojit Chatterji",
            "Huaxia Zeng"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We introduce the notion of a multidimensional hybrid preference domain on a\n(finite) set of alternatives that is a Cartesian product of finitely many\ncomponents. We demonstrate that in a model of public goods provision,\nmultidimensional hybrid preferences arise naturally through assembling marginal\npreferences under the condition of semi-separability - a weakening of\nseparability. The main result shows that under a suitable \"richness\" condition,\nevery strategy-proof rule on this domain can be decomposed into component-wise\nstrategy-proof rules, and more importantly every domain of preferences that\nreconciles decomposability of rules with strategy-proofness must be a\nmultidimensional hybrid domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.10889v4"
    },
    {
        "title": "Housing Bubbles with Phase Transitions",
        "authors": [
            "Tomohiro Hirano",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyze equilibrium housing prices in an overlapping generations model\nwith perfect housing and rental markets. The economy exhibits a two-stage phase\ntransition: as the income of home buyers rises, the equilibrium regime changes\nfrom fundamental to bubble possibility, where fundamental and bubbly equilibria\ncan coexist. With even higher incomes, fundamental equilibria disappear and\nhousing bubbles become a necessity. Even with low current incomes, housing\nbubbles may emerge if home buyers have access to credit or have high future\nincome expectations. Contrary to widely-held beliefs, fundamental equilibria in\nthe possibility regime are inefficient despite housing being a productive\nnon-reproducible asset.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11365v4"
    },
    {
        "title": "Both invariant principles implied by Marx's law of value are necessary\n  and sufficient to solve the transformation problem through Morishima's\n  formalism",
        "authors": [
            "Norbert Ankri",
            "Païkan Marcaggi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The unit value of a commodity that Michio Morishima's method and its\nvariations enable to determine correctly, is the sum of the value of the\ncommodities it contains (inputs) and the quantity of labor required for its\nproduction. However, goods are sold at their price of production only when they\nmeet a solvent social need that involves the entire economy with its\ninterconnections between the different industrial sectors. This condition gives\nfull meaning to Marx's fundamental equalities, which constitute invariants that\napply to the economy as a whole. These equalities are necessary to determine\nprices of production. We demonstrate that they also enable to solve the\ntransformation problem by starting from Morishima's formalism and returning to\na formalism closer to that used by Marx.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11471v2"
    },
    {
        "title": "Non-Market Allocation Mechanisms: Optimal Design and Investment\n  Incentives",
        "authors": [
            "Victor Augias",
            "Eduardo Perez-Richet"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study how to optimally design selection mechanisms, accounting for agents'\ninvestment incentives. A principal wishes to allocate a resource of homogeneous\nquality to a heterogeneous population of agents. The principal commits to a\npossibly random selection rule that depends on a one-dimensional characteristic\nof the agents she intrinsically values. Agents have a strict preference for\nbeing selected by the principal and may undertake a costly investment to\nimprove their characteristic before it is revealed to the principal. We show\nthat even if random selection rules foster agents' investments, especially at\nthe top of the characteristic distribution, deterministic \"pass-fail\" selection\nrules are in fact optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11805v1"
    },
    {
        "title": "Towards a Characterization of Random Serial Dictatorship",
        "authors": [
            "Felix Brandt",
            "Matthias Greger",
            "René Romen"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Random serial dictatorship (RSD) is a randomized assignment rule that - given\na set of $n$ agents with strict preferences over $n$ houses - satisfies equal\ntreatment of equals, ex post efficiency, and strategyproofness. For $n \\le 3$,\nBogomolnaia and Moulin (2001) have shown that RSD is characterized by these\naxioms. Extending this characterization to arbitrary $n$ is a long-standing\nopen problem. By weakening ex post efficiency and strategyproofness, we reduce\nthe question of whether RSD is characterized by these axioms for fixed $n$ to\ndetermining whether a matrix has rank $n^2 n!^n$. We provide computer-generated\ncounterexamples to show that two other approaches for proving the\ncharacterization (using deterministic extreme points or restricted domains of\npreferences) are inadequate.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11976v4"
    },
    {
        "title": "Strategic Ambiguity in Global Games",
        "authors": [
            "Takashi Ui"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In games with incomplete and ambiguous information, rational behavior depends\nnot only on fundamental ambiguity (ambiguity about states) but also on\nstrategic ambiguity (ambiguity about others' actions), which further induces\nhierarchies of ambiguous beliefs. We study the impacts of strategic ambiguity\nin global games and demonstrate the distinct effects of ambiguous-quality and\nlow-quality information. Ambiguous-quality information makes more players\nchoose an action yielding a constant payoff, whereas (unambiguous) low-quality\ninformation makes more players choose an ex-ante best response to the uniform\nbelief over the opponents' actions. If the ex-ante best-response action yields\na constant payoff, sufficiently ambiguous-quality information induces a unique\nequilibrium, whereas sufficiently low-quality information generates multiple\nequilibria. In applications to financial crises, we show that news of more\nambiguous quality triggers a debt rollover crisis, whereas news of less\nambiguous quality triggers a currency crisis.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.12263v4"
    },
    {
        "title": "Characterizing the Feasible Payoff Set of OLG Repeated Games",
        "authors": [
            "Daehyun Kim",
            "Chihiro Morooka"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the set of (stationary) feasible payoffs of overlapping generation\nrepeated games that can be achieved by action sequences in which every\ngeneration of players plays the same sequence of action profiles. First, we\ncompletely characterize the set of feasible payoffs given any fixed discount\nfactor of players and the length of interaction. This allows us to obtain the\nfeasible payoff set in closed form. Second, we provide novel comparative\nstatics of the feasible payoff set with respect to the discount factor and the\nlength of interaction. Interestingly, the feasible payoff set becomes smaller\nas players' discount factor becomes larger. Additionally, we identify a\nnecessary and sufficient condition for this monotonicity to be strict.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.12988v6"
    },
    {
        "title": "Information transmission in monopolistic credence goods markets",
        "authors": [
            "Xiaoxiao Hu",
            "Haoran Lei"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a general credence goods model with N problem types and N\ntreatments. Communication between the expert seller and the client is modeled\nas cheap talk. We find that the expert's equilibrium payoffs admit a geometric\ncharacterization, described by the quasiconcave envelope of his belief-based\nprofits function under discriminatory pricing. We establish the existence of\nclient-worst equilibria, apply the geometric characterization to previous\nresearch on credence goods, and provide a necessary and sufficient condition\nfor when communication benefits the expert. For the binary case, we solve for\nall equilibria and characterize client's possible welfare among all equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.13295v2"
    },
    {
        "title": "Persuaded Search",
        "authors": [
            "Teddy Mekonnen",
            "Zeky Murra-Anton",
            "Bobak Pakzad-Hurson"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider sequential search by an agent who cannot observe the quality of\ngoods but can acquire information by buying signals from a profit-maximizing\nprincipal with limited commitment power. The principal can charge higher prices\nfor more informative signals in any period, but high prices in the future\ndiscourage continued search by the agent, thereby reducing the principal's\nfuture profits. A unique stationary equilibrium outcome exists, and we show\nthat the principal $(i)$ induces the socially efficient stopping rule, $(ii)$\nextracts the full surplus, and $(iii)$ persuades the agent against settling for\nmarginal goods, extending the duration of surplus extraction. However,\nintroducing an additional, free source of information can lead to inefficiency\nin equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.13409v5"
    },
    {
        "title": "A New Production Function Approach",
        "authors": [
            "Samidh Pal"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper presents a new nested production function that is specifically\ndesigned for analyzing capital and labor intensity of manufacturing industries\nin developing and developed regions. The paper provides a rigorous theoretical\nfoundation for this production function, as well as an empirical analysis of\nits performance in a sample of industries. The analysis shows that the\nproduction function can be used to accurately estimate the level of capital and\nlabor intensity in industries, as well as to analyze the capacity utilization\nof these industries.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.14428v1"
    },
    {
        "title": "Redeeming Falsifiability?",
        "authors": [
            "Mark Whitmeyer",
            "Kun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We revisit Popper's falsifiability criterion. A tester hires a potential\nexpert to produce a theory, offering payments contingent on the observed\nperformance of the theory. We argue that if the informed expert can acquire\nadditional information, falsifiability does have the power to identify\nworthless theories.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.15723v1"
    },
    {
        "title": "Study on the risk-informed heuristic of decision-making on the\n  restoration of defaulted corporation networks",
        "authors": [
            "Jiajia Xia"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Government-run (Government-led) restoration has become a common and effective\napproach to the mitigation of financial risks triggered by corporation credit\ndefaults. However, in practice, it is often challenging to come up with the\noptimal plan of those restorations, due to the massive search space associated\nwith defaulted corporation networks (DCNs), as well as the dynamic and looped\ninterdependence among the recovery of those individual corporations. To address\nsuch a challenge, this paper proposes an array of viable heuristics of the\ndecision-making that drives those restoration campaigns. To examine their\napplicability and measure their performance, those heuristics have been applied\nto two real-work DCNs that consists of 100 listed Chinese A-share companies,\nwhose restoration has been modelled based on the 2021 financial data, in the\nwake of randomly generated default scenarios. The corresponding simulation\noutcome of the case-study shows that the restoration of the DCNs would be\nsignificantly influenced by the different heuristics adopted, and in\nparticular, the system-oriented heuristic is revealed to be significantly\noutperforming those individual corporation-oriented ones. Therefore, such a\nresearch has further highlighted that the interdependence-induced risk\npropagation shall be accounted for by the decision-makers, whereby a prompt and\neffective restoration campaign of DCNs could be shaped.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.15863v2"
    },
    {
        "title": "Critical Thinking Via Storytelling: Theory and Social Media Experiment",
        "authors": [
            "Brian Jabarian",
            "Elia Sartori"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In a stylized voting model, we establish that increasing the share of\ncritical thinkers -- individuals who are aware of the ambivalent nature of a\ncertain issue -- in the population increases the efficiency of surveys\n(elections) but might increase surveys' bias. In an incentivized online social\nmedia experiment on a representative US population (N = 706), we show that\ndifferent digital storytelling formats -- different designs to present the same\nset of facts -- affect the intensity at which individuals become critical\nthinkers. Intermediate-length designs (Facebook posts) are most effective at\ntriggering individuals into critical thinking. Individuals with a high need for\ncognition mostly drive the differential effects of the treatments.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16422v1"
    },
    {
        "title": "Anonymity in sharing the revenues from broadcasting sports leagues",
        "authors": [
            "Gustavo Bergantinos",
            "Juan D. Moreno-Ternero"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the problem of sharing the revenues from broadcasting sports leagues\naxiomatically. Our key axiom is anonymity, the classical impartiality axiom.\nOther impartiality axioms already studied in these problems are equal treatment\nof equals, weak equal treatment of equals and symmetry. We study the\nrelationship between all impartiality axioms. Besides we combine anonymity with\nother existing axioms in the literature. Some combinations give rise to new\ncharacterizations of well-known rules. The family of generalized split rules is\ncharacterized with anonymity, additivity and null team. The concede-and-divide\nrule is characterized with anonymity, additivity and essential team. Others\ncombinations characterize new rules that had not been considered before. We\nprovide three characterizations in which three axioms are the same (anonymity,\nadditivity, and order preservation) the fourth one is different (maximum\naspirations, weak upper bound, and non-negativity). Depending on the fourth\naxiom we obtain three different families of rules. In all of them\nconcede-and-divide plays a central role.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.17897v1"
    },
    {
        "title": "The Effects of Incentives on Choices and Beliefs in Games: An Experiment",
        "authors": [
            "Teresa Esteban-Casanelles",
            "Duarte Gonçalves"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  How and why do incentive levels affect strategic behavior? This paper\nexamines an experiment designed to identify the causal effect of scaling up\nincentives on choices and beliefs in strategic settings by holding fixed\nopponents' actions. In dominance-solvable games, higher incentives increase\naction sophistication and best-response rates and decrease mistake propensity.\nBeliefs tend to become more accurate with higher own incentives in simple\ngames. However, opponents with higher incentive levels are harder to predict:\nwhile beliefs track opponents' behavior when they have higher incentive levels,\nbeliefs about opponents also become more biased. We provide evidence that\nincentives affect cognitive effort and that greater effort increases\nperformance and predicts choice and belief sophistication. Overall, the data\nlends support to combining both payoff-dependent mistakes and costly reasoning.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.00412v1"
    },
    {
        "title": "The Focal Quantal Response Equilibrium",
        "authors": [
            "Matthew Kovach",
            "Gerelt Tserenjigmid"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We propose a generalization of Quantal Response Equilibrium (QRE) built on a\nsimple premise: some actions are more focal than others. In our model, which we\ncall the Focal Quantal Response Equilibrium (Focal QRE), each player plays a\nstochastic version of Nash equilibrium as in the QRE, but some strategies are\nfocal and thus are chosen relatively more frequently than other strategies\nafter accounting for expected utilities. The Focal QRE is able to systemically\naccount for various forms of bounded rationality of players, especially\nregret-aversion, salience, or limited consideration. The Focal QRE is also\nuseful to explain observed heterogeneity of bounded rationality of players\nacross different games. We show that regret-based focal sets perform relatively\nwell at predicting strategies that are chosen more frequently relative to their\nexpected utilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.00438v1"
    },
    {
        "title": "Inequality and Growth: A Two-Player Dynamic Game with Production and\n  Appropriation",
        "authors": [
            "Julio Huato"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper models a two-agent economy with production and appropriation as a\nnoncooperative dynamic game, and determines its closed-form Markovian Nash\nequilibrium. The analysis highlights the para-metric conditions that tip the\neconomy from a nonaggressive or \"co-operative\" equilibrium to outright\ndistributional conflict. The model includes parameters that capture the role of\nappropriation technology and destructiveness. The full dynamic implications of\nthe game are yet to be explored, but the model offers a promising general\nframework for thinking about different technological and economic conditions as\nmore or less conducive to cooperation or distributional conflict.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01855v1"
    },
    {
        "title": "Causes of Excess Capacity",
        "authors": [
            "Samidh Pal"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This study delves into the origins of excess capacity by examining the\nreactions of capital, labor, and capital intensity. To achieve this, we have\nemployed a novel three-layered production function model, estimating the\nelasticity of substitution between capital and labor as a nested layer,\nalongside capital intensity, for all industry groups. We have then selectively\nanalyzed a few industry groups for comparative purposes, taking into account\nthe current government policies and manufacturing plant realities. Ultimately,\nwe recommend that policymakers address the issue of excess capacity by\nstimulating the expansion of manufacturing plants with cutting-edge machinery.\nOur findings and recommendations are intended to appeal to academics and\npolicymakers alike.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02137v1"
    },
    {
        "title": "Covert learning and disclosure",
        "authors": [
            "Matteo Escudé"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I study a model of information acquisition and transmission in which the\nsender's ability to misreport her findings is limited. In equilibrium, the\nsender only influences the receiver by choosing to remain selectively ignorant,\nrather than by deceiving her about the discoveries. Although deception does not\noccur, I highlight how deception possibilities determine what information the\nsender chooses to acquire and transmit. I then turn to comparative statics,\ncharacterizing in which sense the sender benefits from her claims being more\nverifiable, showing this is akin to increasing her commitment power. Finally, I\ncharacterize sender- and receiver-optimal falsification environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02989v5"
    },
    {
        "title": "Waiting for Fake News",
        "authors": [
            "Raphael Boleslavsky"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies a dynamic model of information acquisition, in which\ninformation might be secretly manipulated. A principal must choose between a\nsafe action with known payoff and a risky action with uncertain payoff,\nfavoring the safe action under the prior belief. She may delay her decision to\nacquire additional news that reveals the risky action's payoff, without knowing\nexactly when such news will arrive. An uninformed agent with a misaligned\npreference may have the capability to generate a false arrival of news, which\nis indistinguishable from a real one, distorting the information content of\nnews and the principal's search. The analysis characterizes the positive and\nnormative distortions in the search for news arising from such manipulation,\nand it considers three remedies that increase the principal's payoff: a\ncommitment to naive search, transfer of authority to the agent, and delegation\nto an intermediary who is biased in the agent's favor.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.04053v2"
    },
    {
        "title": "A micro-founded comparison of fiscal policies between indirect and\n  direct job creation",
        "authors": [
            "Kensuke Ohtake"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The purpose of this paper is to provide a micro-economic foundation for an\nargument that the direct employment by the government is more desirable than\nthe government purchase of private goods to eliminate unemployment. A general\nequilibrium model with monopolistic competition is devised, and the effects of\npolicies (government purchase, tax rate operation, and government employment)\non macroeconomic variables (consumption, price, and profit) are investigated.\nIt is shown that 1) the government purchase is inflationary in the sense that\nadditional effective demand by the government not only increases private\nemployment but also raises prices; 2) the government employment can achieve\nfull employment without causing a rise in prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.04506v4"
    },
    {
        "title": "Recursive Preferences, Correlation Aversion, and the Temporal Resolution\n  of Uncertainty",
        "authors": [
            "Lorenzo Maria Stanca"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper investigates a novel behavioral feature of recursive preferences:\naversion to risks that persist over time, or simply correlation aversion.\nGreater persistence provides information about future consumption but reduces\nopportunities to hedge consumption risk. I show that, for recursive\npreferences, correlation aversion is equivalent to increasing relative risk\naversion. To quantify correlation aversion, I develop the concept of the\npersistence premium, which measures how much an individual is willing to pay to\neliminate persistence in consumption. I provide an approximation of the\npersistence premium in the spirit of Arrow-Pratt, which provides a quantitative\nrepresentation of the trade-off between information and hedging. I present\nseveral applications. The persistence premium helps create more realistic\ncalibrations for macro-finance models. In an optimal taxation model, I show\nthat recursive preferences unlike standard preferences-lead to more progressive\ntaxation when human capital persistence is greater. Finally, I show that\ncorrelation-averse preferences have a variational representation, linking\ncorrelation aversion to concerns about model misspecification.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.04599v4"
    },
    {
        "title": "Iterated Revelation: How to Incentive Experts to Complete Incomplete\n  Contracts",
        "authors": [
            "Evan Piermont"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper examines how a decision maker might incentivize an expert to\nreveal novel aspects of the decision problem, expanding the set of contracts\nfrom which the decision maker can choose. The chosen contract will determine,\nalong with the resolution of uncertainty, the payoffs to both players. I show\nthat the set of achievable outcomes under any (incentive compatible) mechanism\nis characterized by a small and tractable class of iterated revelation\nmechanisms (IRMs). An IRM is a dynamic interaction wherein each round the\nexpert chooses to reveal some novel contingencies and the decision maker\nproposes a contract that the expert can accept or reject; the IRM ends after\nrejection or when nothing novel is revealed. I then consider the set of robust\nIRMs -- those that maximize the worst case outcome across all types of expert\n-- and show these are characterized by a principle of myopic optimality: at\neach round, the decision maker maximizes his payoff as if the expert had\nnothing further to reveal. The set of robust IRMs also delineate the payoffs\nachievable by any efficient mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.05142v2"
    },
    {
        "title": "A Note on Cursed Sequential Equilibrium and Sequential Cursed\n  Equilibrium",
        "authors": [
            "Meng-Jhang Fong",
            "Po-Hsuan Lin",
            "Thomas R. Palfrey"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this short note, we compare the cursed sequential equilibrium (CSE) by\nFong et al. (2023) and the sequential cursed equilibrium (SCE) by Cohen and Li\n(2023). We identify eight main differences between CSE and SCE with respect to\nthe following features: (1) the family of applicable games, (2) the number of\nfree parameters, (3) the belief updating process, (4) the treatment of public\nhistories, (5) effects in games of complete information, (6) violations of\nsubgame perfection and sequential rationality, (7) re-labeling of actions, and\n(8) effects in one-stage simultaneous-move games.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.05515v1"
    },
    {
        "title": "Comment on Matsushima, Miyazaki, and Yagi (2010) \"Role of Linking\n  Mechanisms in Multitask Agency with Hidden Information\"",
        "authors": [
            "Ian Ball",
            "Deniz Kattwinkel"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We correct a gap in the proof of Theorem 2 in Matsushima et al. (2010).\n",
        "pdf_link": "http://arxiv.org/pdf/2304.05936v1"
    },
    {
        "title": "Recursive Preferences and Ambiguity Attitudes",
        "authors": [
            "Massimo Marinacci",
            "Giulio Principi",
            "Lorenzo Stanca"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the implications of recursivity and state monotonicity in\nintertemporal consumption problems under ambiguity. We show that monotone\nrecursive preferences admit a recursive and ex-ante representation, both with\ntranslation invariant certainty equivalents. Translation invariance restricts\nthe decision maker's absolute ambiguity attitudes to be constant. As a\nbyproduct, this restriction implies that monotone recursive and convex\npreferences collapse to the variational model. Using dynamic consistency, we\nshow that our two representations are connected by a condition that extends the\nstandard rectangularity notion for recursive multiple priors. This \"generalized\nrectangularity\" condition allows us to uniquely retrieve the ex-ante\nrepresentation starting fromthe recursive one and to obtain dynamic consistency\nconditions for preferences exhibiting constant absolute ambiguity aversion.\nInterpreting generalized rectangularity as a law of iterated nonlinear\nexpectations, we discuss its relevance with respect to large sample theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.06830v5"
    },
    {
        "title": "Social Welfare Functions with Voters Qualifications: Impossibility\n  Results",
        "authors": [
            "Yasunori Okumura"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider the social welfare function a la Arrow, where some voters are not\nqualified to evaluate some alternatives. Thus, the inputs of the social welfare\nfunction are the preferences of voters on the alternatives that they are\nqualified to evaluate only. Our model is a generalization of the peer rating\nmodel, where each voter evaluates the other voters (except for\nhimself/herself). We demonstrate the following three impossibility results.\nFirst, if a transitive valued social welfare function satisfies independence of\nirrelevant alternatives and the Pareto principle, then a dictator who is\nqualified to evaluate all alternatives exists. Second, a transitive valued\nfunction satisfying the Pareto principle exists if and only if at least one\nvoter is qualified to evaluate all alternatives. Finally, if no voter is\nqualified to evaluate all alternatives, then under a transitive valued social\nwelfare function satisfying the weak Pareto principle and independence of\nirrelevant alternatives, all alternatives are indifferent for any preference\nprofile of voters.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.06961v2"
    },
    {
        "title": "Test-Optional Admissions",
        "authors": [
            "Wouter Dessein",
            "Alex Frankel",
            "Navin Kartik"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Many U.S. colleges now use test-optional admissions. A frequent claim is that\nby not seeing standardized test scores, a college can admit a student body it\nprefers, say with more diversity. But how can observing less information\nimprove decisions? This paper proposes that test-optional policies are a\nresponse to social pressure on admission decisions. We model a college that\nbears disutility when it makes admission decisions that \"society\" dislikes.\nGoing test optional allows the college to reduce its \"disagreement cost\". We\nanalyze how missing scores are imputed and the consequences for the college,\nstudents, and society.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.07551v3"
    },
    {
        "title": "Data, Competition, and Digital Platforms",
        "authors": [
            "Dirk Bergemann",
            "Alessandro Bonatti"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyze digital markets where a monopolist platform uses data to match\nmultiproduct sellers with heterogeneous consumers who can purchase both on and\noff the platform. The platform sells targeted ads to sellers that recommend\ntheir products to consumers and reveals information to consumers about their\nvalues. The revenue-optimal mechanism is a managed advertising campaign that\nmatches products and preferences efficiently. In equilibrium, sellers offer\nhigher qualities at lower unit prices on than off the platform.\nPrivacy-respecting data-governance rules such as organic search results or\nfederated learning can lead to welfare gains for consumers.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.07653v1"
    },
    {
        "title": "Non-diversified portfolios with subjective expected utility",
        "authors": [
            "Christopher P. Chambers",
            "Georgios Gerasimou"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Diversification is the typical investment strategy of risk-averse agents.\nHowever, non-diversified positions that allocate all resources to a single\nasset, state of the world or revenue stream are common too. We show that\nwhenever finitely many non-diversified demands under uncertainty are compatible\nwith risk-averse subjective expected utility maximization under strictly\npositive beliefs, they are also rationalizable under the same beliefs by many\nqualitatively distinct risk-averse as well as risk-neutral and risk-seeking\npreferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08059v4"
    },
    {
        "title": "Optimism, overconfidence, and moral hazard",
        "authors": [
            "Ludvig Sinander"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I revisit the standard moral-hazard model, in which an agent's preference\nover contracts is rooted in costly effort choice. I characterise the\nbehavioural content of the model in terms of empirically testable axioms, and\nshow that the model's parameters are identified. I propose general behavioural\ndefinitions of relative (over)confidence and optimism, and characterise these\nin terms of the parameters of the moral-hazard model. My formal results are\nrooted in a simple but powerful insight: that the moral-hazard model is closely\nrelated to the well-known 'variational' model of choice under uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08343v4"
    },
    {
        "title": "With a Grain of Salt: Uncertain Veracity of External News and Firm\n  Disclosures",
        "authors": [
            "Jonathan Libgober",
            "Beatrice Michaeli",
            "Elyashiv Wiedman"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We examine how uncertain veracity of external news influences investor\nbeliefs, market prices and corporate disclosures. Despite assuming independence\nbetween the news' veracity and the firm's endowment with private information,\nwe find that favorable news is taken ``with a grain of salt'' in equilibrium --\nmore precisely, perceived as less likely veracious -- which reinforces investor\nbeliefs that nondisclosing managers are hiding disadvantageous information.\nHence more favorable external news could paradoxically lead to lower market\nvaluation. That is, amid management silence, stock prices may be non-monotonic\nin the positivity of external news. In line with mounting empirical evidence,\nour analysis implies asymmetric price reactions to news and price declines\nfollowing firm disclosures. We further predict that external news that is more\nlikely veracious may increase or decrease the probability of disclosure and\nlink these effects to empirically observable characteristics.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09262v3"
    },
    {
        "title": "The Economics of Partisan Gerrymandering",
        "authors": [
            "Anton Kolotilin",
            "Alexander Wolitzky"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the problem of a partisan gerrymanderer who assigns voters to\nequipopulous districts so as to maximize his party's expected seat share. The\ndesigner faces both aggregate uncertainty (how many votes his party will\nreceive) and idiosyncratic, voter-level uncertainty (which voters will vote for\nhis party). We argue that pack-and-pair districting, where weaker districts are\n``packed'' with a single type of voter, while stronger districts contain two\nvoter types, is typically optimal for the gerrymanderer. The optimal form of\npack-and-pair districting depends on the relative amounts of aggregate and\nidiosyncratic uncertainty. When idiosyncratic uncertainty dominates, it is\noptimal to pack opposing voters and pair more favorable voters; this plan\nresembles traditional ``packing-and-cracking.'' When aggregate uncertainty\ndominates, it is optimal to pack moderate voters and pair extreme voters; this\n``matching slices'' plan has received some attention in the literature.\nEstimating the model using precinct-level returns from recent US House\nelections indicates that, in practice, idiosyncratic uncertainty dominates and\npacking opponents is optimal; moreover, traditional pack-and-crack districting\nis approximately optimal. We discuss implications for redistricting reform and\npolitical polarization. Methodologically, we exploit a formal connection\nbetween gerrymandering -- partitioning voters into districts -- and information\ndesign -- partitioning states of the world into signals.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09381v1"
    },
    {
        "title": "Consistent Linear Orders for Supermajority Rules",
        "authors": [
            "Yasunori Okumura"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider linear orders of finite alternatives that are constructed by\naggregating the preferences of individuals. We focus on a linear order that is\nconsistent with the collective preference relation, which is constructed by one\nof the supermajority rules and modified using two procedures if there exist\nsome cycles. One modification procedure uses the transitive closure, and the\nother uses the Suzumura consistent closure. We derive two sets of linear orders\nthat are consistent with the (modified) collective preference relations formed\nby any of the supermajority rules and show that these sets are generally not\nempty. These sets of linear orders are closely related to those obtained\nthrough the ranked pairs method and the Schulze method. Finally, we show that\nany linear order included in either of the sets satisfies two properties: the\nextended Condorcet criterion and the Pareto principle.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09419v4"
    },
    {
        "title": "Utilitarian Theorems and Equivalence of Utility Theories",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we consider an environment in which the utilitarian theorem\nfor the NM utility function derived by Harsanyi and the utilitarian theorem for\nAlt's utility function derived by Harvey hold simultaneously, and prove that\nthe NM utility function coincides with Alt's utility function under this setup.\nThis result is so paradoxical that we must presume that at least one of the\nutilitarian theorems contains a strong assumption. We examine the assumptions\none by one and conclude that one of Harsanyi's axioms is strong.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09973v4"
    },
    {
        "title": "Partition-based Stability of Coalitional Games",
        "authors": [
            "Jian Yang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We are concerned with the stability of a coalitional game, i.e., a\ntransferable-utility (TU) cooperative game. First, the concept of core can be\nweakened so that the blocking of changes is limited to only those with\nmultilateral backings. This principle of consensual blocking, as well as the\ntraditional core-defining principle of unilateral blocking and one straddling\nin between, can all be applied to partition-allocation pairs. Each such pair is\nmade up of a partition of the grand coalition and a corresponding allocation\nvector whose components are individually rational and efficient for the various\nconstituent coalitions of the given partition. For the resulting strong,\nmedium, and weak stability concepts, the first is core-compatible in that the\ntraditional core exactly contains those allocations that are associated through\nthis strong stability concept with the all-consolidated partition consisting of\nonly the grand coalition. Probably more importantly, the latter medium and weak\nstability concepts are universal. By this, we mean that any game, no matter how\n``poor'' it is, has its fair share of stable solutions. There is also a\nsteepest ascent method to guide the convergence process to a mediumly stable\npartition-allocation pair from any starting partition.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.10651v1"
    },
    {
        "title": "A Partial Order for Strictly Positive Coalitional Games and a Link from\n  Risk Aversion to Cooperation",
        "authors": [
            "Jian Yang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We deal with coalitional games possessing strictly positive values.\nIndividually rational allocations of such a game has clear fractional\ninterpretations. Many concepts, including the long-existing core and other\nstability notions more recently proposed by Yang \\cite{Y22}, can all be re-cast\nin this fractional mode. The latter allows a certain ranking between games,\nwhich we deem as in the sense of ``centripetality'', to imply a clearly\ndescribable shift in the games' stable solutions. %These trends would be\npreserved after the imposition of the restriction that fractions be positive as\nwell. When coalitions' values are built on both random outcomes and a common\npositively homogeneous reward function characterizing players' enjoyments from\ntheir shares, the above link could help explain why aversion to risk often\npromotes cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.10652v1"
    },
    {
        "title": "Compatibility between stability and strategy-proofness with\n  single-peaked preferences on trees",
        "authors": [
            "Pinaki Mandal"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies the stability and strategy-proofness aspect of the\ntwo-sided one-to-one matching market. Agents have single-peaked preferences on\ntrees. In this setting, we characterize all rich anonymous tree-single-peaked\ndomains where a stable and (weakly group) strategy-proof matching rule exists.\nWe also show that whenever there exists a stable and strategy-proof matching\nrule on a rich anonymous tree-single-peaked domain, one or both of the deferred\nacceptance rules (Gale and Shapley, 1962) satisfy stability and weak group\nstrategy-proofness on that domain. Finally, we show that for markets with a\nsize of at least five, there is no rich anonymous domain where a stable and\nnon-bossy matching rule exists. As a corollary, we show incompatibility between\nstability and group strategy-proofness on rich anonymous tree-single-peaked\ndomains for markets with a size of at least five.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.11494v1"
    },
    {
        "title": "Partner Choice and Morality: Preference Evolution under Stable Matching",
        "authors": [
            "Ziwei Wang",
            "Jiabin Wu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We present a model that investigates preference evolution with endogenous\nmatching. In the short run, individuals' subjective preferences simultaneously\ndetermine who they choose to match with and how they behave in the social\ninteractions with their matched partners, which result in material payoffs for\nthem. Material payoffs in turn affect how preferences evolve in the long run.\nTo properly model the \"match-to-interact\" process, we combine stable matching\nand equilibrium concepts. Our analysis unveils that endogenous matching gives\nrise to the \"we is greater than me\" moral perspective. This perspective is\nunderpinned by a preference that exhibits both homophily and efficiency, which\nenables individuals to reach a consensus of a collective ``we\" that transcends\nthe boundaries of the individual \"I\" and \"you.\" Such a preference stands out in\nthe evolutionary process because it is able to force positive assortative\nmatching and efficient play among individuals carrying the same preference\ntype. Under incomplete information, a strong form of homophily, which we call\nparochialism, is necessary for a preference to prevail in evolution, because\nstronger incentives are required to engage in self-sorting with information\nfriction.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.11504v2"
    },
    {
        "title": "Choice Structures in Games",
        "authors": [
            "Paolo Galeazzi",
            "Johannes Marti"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Following the decision-theoretic approach to game theory, we extend the\nanalysis of Epstein & Wang and of Di Tillio from hierarchies of preference\nrelations to hierarchies of choice functions. We then construct the universal\nchoice structure containing all these choice hierarchies, and show how the\nuniversal preference structure of Di Tillio is embedded in it.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.11575v1"
    },
    {
        "title": "Homophily and infections: static and dynamic effects",
        "authors": [
            "Matteo Bizzarri",
            "Fabrizio Panebianco",
            "Paolo Pin"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyze the effect of homophily in the diffusion of a harmful state\nbetween two groups of agents that differ in immunization rates. Homophily has a\nvery different impact on the steady state infection level (that is increasing\nin homophily when homophily is small, and decreasing when high), and on the\ncumulative number of infections generated by a deviation from the steady state\n(that, instead, is decreasing in homophily when homophily is small, and\nincreasing when high). If immunization rates are endogenous, homophily has the\nopposite impact on the two groups. However, the sign of the group-level impact\nis the opposite if immunization is motivated by infection risk or by peer\npressure. If motivations are group-specific, homophily can be harmful to both\ngroups.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.11934v2"
    },
    {
        "title": "Monotone comparative statics for submodular functions, with an\n  application to aggregated deferred acceptance",
        "authors": [
            "Alfred Galichon",
            "Yu-Wei Hsieh",
            "Maxime Sylvestre"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We propose monotone comparative statics results for maximizers of submodular\nfunctions, as opposed to maximizers of supermodular functions as in the\nclassical theory put forth by Veinott, Topkis, Milgrom, and Shannon among\nothers. We introduce matrons, a natural structure that is dual to sublattices\nthat generalizes existing structures such as matroids and polymatroids in\ncombinatorial optimization and M-sets in discrete convex analysis. Our monotone\ncomparative statics result is based on a natural order on matrons, which is\ndual in some sense to Veinott's strong set order on sublattices. As an\napplication, we propose a deferred acceptance algorithm that operates in the\ncase of divisible goods, and we study its convergence properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12171v2"
    },
    {
        "title": "Communication in the Infinitely Repeated Prisoner's Dilemma: Theory and\n  Experiments",
        "authors": [
            "Maximilian Andres"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  So far, the theory of equilibrium selection in the infinitely repeated\nprisoner's dilemma is insensitive to communication possibilities. To address\nthis issue, we incorporate the assumption that communication reduces -- but\ndoes not entirely eliminate -- an agent's uncertainty that the other agent\nfollows a cooperative strategy into the theory. Because of this, agents still\nworry about the payoff from cooperating when the other one defects, i.e. the\nsucker's payoff S, and, games with communication are more conducive to\ncooperation than games without communication. This theory is supported by data\nfrom laboratory experiments, and by machine learning based evaluation of the\ncommunication content.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12297v1"
    },
    {
        "title": "The structure of strategy-proof rules",
        "authors": [
            "Jorge Alcalde-Unzu",
            "Marc Vorsatz"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We establish that all strategy-proof social choice rules in strict preference\ndomains follow necessarily a two-step procedure. In the first step, agents are\nasked to reveal some specific information about their preferences. Afterwards,\na subrule that is dictatorial or strategy-proof of range 2 must be applied, and\nthe selected subrule may differ depending on the answers of the first step. As\na consequence, the strategy-proof rules that have been identified in the\nliterature for some domains can be reinterpreted in terms of our procedure and,\nmore importantly, this procedure serves as a guide for determining the\nstructure of the strategy-proof rules in domains that have not been explored\nyet.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12843v1"
    },
    {
        "title": "Optimal tie-breaking rules",
        "authors": [
            "Sumit Goel",
            "Amit Goyal"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider two-player contests with the possibility of ties and study the\neffect of different tie-breaking rules on effort. For ratio-form and\ndifference-form contests that admit pure-strategy Nash equilibrium, we find\nthat the effort of both players is monotone decreasing in the probability that\nties are broken in favor of the stronger player. Thus, the effort-maximizing\ntie-breaking rule commits to breaking ties in favor of the weaker agent. With\nsymmetric agents, we find that the equilibrium is generally symmetric and\nindependent of the tie-breaking rule. We also study the design of random\ntie-breaking rules that are ex-ante fair and identify sufficient conditions\nunder which breaking ties before the contest actually leads to greater expected\neffort than the more commonly observed practice of breaking ties after the\ncontest.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.13866v2"
    },
    {
        "title": "Nontransitive Preferences and Stochastic Rationalizability: A Behavioral\n  Equivalence",
        "authors": [
            "Mogens Fosgerau",
            "John Rehbeck"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Nontransitive choices have long been an area of curiosity within economics.\nHowever, determining whether nontransitive choices represent an individual's\npreference is a difficult task since choice data is inherently stochastic. This\npaper shows that behavior from nontransitive preferences under a monotonicity\nassumption is equivalent to a transitive stochastic choice model. In\nparticular, nontransitive preferences are regularly interpreted as a strength\nof preference, so we assume alternatives are chosen proportionally to the\nnontransitive preference. One implication of this result is that one cannot\ndistinguish ``complementarity in attention\" and ``complementarity in demand.\"\n",
        "pdf_link": "http://arxiv.org/pdf/2304.14631v1"
    },
    {
        "title": "Gain-Loss Hedging and Cumulative Prospect Theory",
        "authors": [
            "Lorenzo Bastianello",
            "Alain Chateauneuf",
            "Bernard Cornet"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Two acts are comonotonic if they yield high payoffs in the same states of\nnature. The main purpose of this paper is to derive a new characterization of\nCumulative Prospect Theory (CPT) through simple properties involving\ncomonotonicity. The main novelty is a concept dubbed gain-loss hedging: mixing\npositive and negative acts creates hedging possibilities even when acts are\ncomonotonic. This allows us to clarify in which sense CPT differs from Choquet\nexpected utility. Our analysis is performed under the simpler case of\n(piece-wise) constant marginal utility which allows us to clearly separate the\nperception of uncertainty from the evaluation of outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.14843v1"
    },
    {
        "title": "Social Preferences and Deliberately Stochastic Behavior",
        "authors": [
            "Yosuke Hashidate",
            "Keisuke Yoshihara"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This study proposes a tractable stochastic choice model to identify\nmotivations for prosocial behavior, and to explore alternative motivations of\ndeliberate randomization beyond ex-ante fairness concerns. To represent social\npreferences, we employ an additively perturbed utility model consisting of the\nsum of expected utility and a nonlinear cost function, where the utility\nfunction is purely selfish while the cost function depends on social\npreferences. Using the cost function, we study stochastic choice patterns to\ndistinguish between stochastic inequity-averse behavior and stochastic\nshame-mitigating behavior. Moreover, we discuss how our model can complement\nrecent experimental evidence of ex-post and ex-ante fairness concerns.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.14977v1"
    },
    {
        "title": "On extensions of partial priorities in school choice",
        "authors": [
            "Minoru Kitahara",
            "Yasunori Okumura"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider a school choice matching model where the priorities for schools\nare represented by binary relations that may not be weak order. We focus on the\n(total order) extensions of the binary relations. We introduce a class of\nalgorithms to derive one of the extensions of a binary relation and\ncharacterize them by using the class. We show that if the binary relations are\nthe partial orders, then for each stable matching for the profile of the binary\nrelations, there is an extension for which it is also stable. Moreover, if\nthere are multiple stable matchings for the profile of the binary relations\nthat are ranked by Pareto dominance, there is an extension for which all of\nthose matchings are stable. We provide several applications of these results.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00641v2"
    },
    {
        "title": "Signaling With Commitment",
        "authors": [
            "Raphael Boleslavsky",
            "Mehdi Shadmehr"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the canonical signaling game, endowing the sender with commitment\npower: before learning the state, sender designs a strategy, which maps the\nstate into a probability distribution over actions. We provide a geometric\ncharacterization of the sender's attainable payoffs, described by the\ntopological join of the graphs of the interim payoff functions associated with\ndifferent sender actions. We extend the sender's commitment power to the design\nof a communication protocol, characterizing whether and how sender benefits\nfrom revealing information about the state, beyond what is inferred from his\naction. We apply our results to the design of adjudication procedures, rating\nor grading systems, and sequencing algorithms for online platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00777v2"
    },
    {
        "title": "An Assignment Problem with Interdependent Valuations and Externalities",
        "authors": [
            "Tatiana Daddario",
            "Richard P. McLean",
            "Andrew Postlewaite"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we take a mechanism design approach to optimal assignment\nproblems with asymmetrically informed buyers. In addition, the surplus\ngenerated by an assignment of a buyer to a seller may be adversely affected by\nexternalities generated by other assignments. The problem is complicated by\nseveral factors. Buyers know their own valuations and externality costs but do\nnot know this same information for other buyers. Buyers also receive private\nsignals correlated with the state and, consequently, the implementation problem\nexhibits interdependent valuations. This precludes a naive application of the\nVCG mechanism and to overcome this interdependency problem, we construct a\ntwo-stage mechanism. In the first stage, we exploit correlation in the firms\nsignals about the state to induce truthful reporting of observed signals. Given\nthat buyers are honest in stage 1, we then use a VCG-like mechanism in stage 2\nthat induces honest reporting of valuation and externality functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.01477v1"
    },
    {
        "title": "A More Informed Sender Benefits the Receiver When the Sender Has\n  Transparent Motives",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A sender with state-independent preferences (i.e., transparent motives)\nprivately observes a signal about the state of the world before sending a\nmessage to a receiver, who subsequently takes an action. Regardless of whether\nthe receiver can mediate--and commit to a garbling of the sender's message--or\ndelegate--commit to a stochastic decision rule as a function of the\nmessage--and understanding the statement ``the receiver is better off as a\nresult of an improvement of the sender's information'' to mean that her maximal\nand minimal equilibrium payoffs (weakly) increase as the sender's signal\nimproves (in a Blackwell sense), we find that if the sender is more informed,\nthe receiver is better off.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.01512v1"
    },
    {
        "title": "The Indoctrination Game",
        "authors": [
            "Lotem Ikan",
            "David Lagziel"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The indoctrination game is a complete-information contest over public\nopinion. The players exert costly effort to manifest their private opinions in\npublic in order to control the discussion, so that the governing opinion is\nsimilar to theirs. Our analysis provides a theoretical foundation for the\nsilent majority and vocal minority phenomena, i.e., we show that all moderate\nopinions remain mute in equilibrium while allowing extremists full control of\nthe discussion. Moreover, we prove that elevated exposure to others' opinions\nincreases the observed polarization among individuals. Using these results, we\nformulate a new social-learning framework, referred to as an indoctrination\nprocess.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.02604v1"
    },
    {
        "title": "Lemonade from Lemons: Information Design and Adverse Selection",
        "authors": [
            "Navin Kartik",
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A seller posts a price for a single object. The seller's and buyer's values\nmay be interdependent. We characterize the set of payoff vectors across all\ninformation structures. Simple feasibility and individual-rationality\nconstraints identify the payoff set. The buyer can obtain the entire surplus;\noften, other mechanisms cannot enlarge the payoff set. We also study payoffs\nwhen the buyer is more informed than the seller, and when the buyer is fully\ninformed. All three payoff sets coincide (only) in notable special cases -- in\nparticular, when there is complete breakdown in a ``lemons market'' with an\nuninformed seller and fully-informed buyer.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.02994v1"
    },
    {
        "title": "Games Under Network Uncertainty",
        "authors": [
            "Promit K. Chaudhuri",
            "Matthew O. Jackson",
            "Sudipta Sarangi",
            "Hector Tzavellas"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We examine settings in which agents choose behaviors and care about their\nneighbors' behaviors, but have incomplete information about the network in\nwhich they are embedded. We develop a model in which agents use local knowledge\nof their direct (and in some cases indirect) connections to make inferences\nabout the complementarity strength of their actions with other agents in the\nsociety. Consequently, an agent's position in the network and identity plays a\ncrucial role in determining their strategic behavior in ways that we can\nquantify. Our main results characterize equilibrium behaviors under various\nbeliefs. In particular, we analyze the role of heterogeneous network\ninformation among agents in detail. For instance, we show how having people\nupdate about the network can lead those with lower degree to systematically\nunderestimate the complementarities in the society, while those with higher\ndegree overestimate the complementarities. We also study the inferences that\nagents make and the resulting behaviors in several prominent families of\nnetwork architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.03124v5"
    },
    {
        "title": "Disclosure and Incentives in Teams",
        "authors": [
            "Paula Onuchic",
            "João Ramos"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider a team-production environment where all participants are\nmotivated by career concerns, and where a team's joint productive outcome may\nhave different reputational implications for different team members. In this\ncontext, we characterize equilibrium disclosure of team-outcomes when\nteam-disclosure choices aggregate individual decisions through some\ndeliberation protocol. In contrast with individual disclosure problems, we show\nthat equilibria often involve partial disclosure. Furthermore, we study the\neffort-incentive properties of equilibrium disclosure strategies implied by\ndifferent deliberation protocols; and show that the partial disclosure of team\noutcomes may improve individuals' incentives to contribute to the team.\nFinally, we study the design of deliberation protocols, and characterize\nproductive environments where effort-incentives are maximized by unilateral\ndecision protocols or more consensual deliberation procedures.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.03633v1"
    },
    {
        "title": "Algorithmic Decision Processes",
        "authors": [
            "Carlo Baldassi",
            "Fabio Maccheroni",
            "Massimo Marinacci",
            "Marco Pirazzini"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We develop a full-fledged analysis of an algorithmic decision process that,\nin a multialternative choice problem, produces computable choice probabilities\nand expected decision times.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.03645v1"
    },
    {
        "title": "Private Experimentation, Data Truncation, and Verifiable Disclosure",
        "authors": [
            "Yichuan Lou"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A sender seeks to persuade a receiver by presenting evidence obtained through\na sequence of private experiments. The sender has complete flexibility in his\nchoice of experiments, contingent on the private experimentation history. The\nsender can disclose each experiment outcome credibly, but cannot prove whether\nhe has disclosed everything. By requiring `continuous disclosure', I first show\nthat the private sequential experimentation problem can be reformulated into a\nstatic one, in which the sender chooses a single signal to learn about the\nstate. Using this observation, I derive necessary conditions for a signal to be\nchosen in equilibrium, and then identify the set of beliefs induced by such\nsignals. Finally, I characterize sender-optimal signals from the\nconcavification of his value function constrained to this set.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.04231v1"
    },
    {
        "title": "Robust Regulation of Firms' Access to Consumer Data",
        "authors": [
            "Jose Higueras"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper I study how to regulate firms' access to consumer data when the\nlatter is used for price discrimination and the regulator faces non-Bayesian\nuncertainty about the correlation structure between data and willingness to\npay, and hence about the way the monopolist will use the consumers' information\nto segment the market. I fully characterize all policies that are worst-case\noptimal when the regulator maximizes consumer surplus: the regulator allows the\nmonopolist to access data if the monopolist cannot use the database to identify\na small group of consumers. Furthermore, from the set of policies that achieve\nthe largest worst-case consumer surplus, I identify the ones that are\nundominated; i.e., there is no alternative policy that never yields lower\nconsumer surplus, and sometimes strictly higher consumer surplus.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.05822v4"
    },
    {
        "title": "Yquilibrium: A Theory for (Non-) Convex Economies",
        "authors": [
            "Jacob K Goeree"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  General equilibrium, the cornerstone of modern economics and finance, rests\non assumptions many markets do not meet. Spectrum auctions, electricity\nmarkets, and cap-and-trade programs for resource rights often feature\nnon-convexities in preferences or production that can cause non-existence of\nWalrasian equilibrium and render general equilibrium vacuous. Yquilibrium\ncomplements general equilibrium with an optimization approach to (non-) convex\neconomies that does not require perfect competition. Yquilibrium coincides with\nWalrasian equilibrium when the latter exists. Yquilibrium exists even if\nWalrasian equilibrium ceases to and produces optimal allocations subject to\nlinear, anonymous, and (approximately) utility-clearing prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.06256v1"
    },
    {
        "title": "Multiple Adjusted Quantiles",
        "authors": [
            "Christopher P. Chambers",
            "Alan D. Miller"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We cardinally and ordinally rank distribution functions (CDFs). We present a\nnew class of statistics, maximal adjusted quantiles, and show that a statistic\nis invariant with respect to cardinal shifts, preserves least upper bounds with\nrespect to the first order stochastic dominance relation, and is lower\nsemicontinuous if and only if it is a maximal adjusted quantile. A dual result\nis provided, as are ordinal results. Preservation of least upper bounds is\ngiven several interpretations, including one that relates to changes in tax\nbrackets, and one that relates to valuing options composed of two assets.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.06354v1"
    },
    {
        "title": "Hail Mary Pass: Contests with Stochastic Progress",
        "authors": [
            "Chang Liu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies the equilibrium behavior in contests with stochastic\nprogress. Participants have access to a safe action that makes progress\ndeterministically, but they can also take risky moves that stochastically\ninfluence their progress towards the goal and thus their relative position. In\nthe unique well-behaved Markov perfect equilibrium of this dynamic contest, the\nfollower drops out if the leader establishes a substantial lead, but resorts to\n\"Hail Marys\" beforehand: no matter how low the return of the risky move is, the\nfollower undertakes in an attempt to catch up. Moreover, if the risky move has\na medium return (between high and low), the leader will also adopt it when the\nfollower is close to dropping out - an interesting preemptive motive. We also\nexamine the impact of such equilibrium behavior on the optimal prize\nallocation.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07218v1"
    },
    {
        "title": "Mechanism Design without Rational Expectations",
        "authors": [
            "Giacomo Rubbini"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Is incentive compatibility still necessary for implementation if we relax the\nrational expectations assumption? This paper proposes a generalized model of\nimplementation that does not assume agents hold rational expectations and\ncharacterizes the class of solution concepts requiring Bayesian Incentive\nCompatibility (BIC) for full implementation. Surprisingly, for a broad class of\nsolution concepts, full implementation of functions still requires BIC even if\nrational expectations do not hold. This finding implies that some classical\nresults, such as the impossibility of efficient bilateral trade (Myerson &\nSatterthwaite, 1983), hold for a broader range of non-equilibrium solution\nconcepts, confirming their relevance even in boundedly rational setups.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07472v2"
    },
    {
        "title": "Group knowledge and individual introspection",
        "authors": [
            "Michele Crescenzi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study distributed knowledge, which is what privately informed agents come\nto know by communicating freely with one another and sharing everything they\nknow. Agents are not necessarily fully rational and differ in the ability to\nform higher-order knowledge. We model the inference making process that leads\nto distributed knowledge, and we do that by introducing revision operators and\nrevision types. Since reasoning abilities can be heterogeneous, inference\nmaking turns out to be order dependent. We show that there are two\nqualitatively different cases of how distributed knowledge is attained. In the\nfirst, distributed knowledge is determined by any group member who can\nreplicate all the inferences that anyone else in the group makes. This result\nis in line with the extant literature. In the second case, no member can\nreplicate all the inferences that are made within the group. As a result,\ndistributed knowledge is determined by any two group members who can jointly\nreplicate what anyone else infers. This case can be interpreted as a form of\nwisdom of crowd effect and shows that, contrary to what is generally believed,\ndistributed knowledge cannot always be reduced to the reasoning abilities of a\nsingle group member.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08729v3"
    },
    {
        "title": "COWPEA (Candidates Optimally Weighted in Proportional Election using\n  Approval voting)",
        "authors": [
            "Toby Pereira"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper describes a new method of proportional representation that uses\napproval voting, known as COWPEA (Candidates Optimally Weighted in Proportional\nElection using Approval voting). COWPEA optimally elects an unlimited number of\ncandidates with potentially different weights to a body, rather than giving a\nfixed number equal weight. A version that elects a fixed a number of candidates\nwith equal weight does exist, but it is non-deterministic, and is known as\nCOWPEA Lottery. This methods passes the \"Holy Grail\" criteria of monotonicity,\nIndependence of Irrelevant Ballots, and Independence of Universally Approved\nCandidates. There are also ways to convert COWPEA and COWPEA Lottery to score\nor graded voting methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08857v4"
    },
    {
        "title": "Complete Conditional Type Structures",
        "authors": [
            "Nicodemo De Vito"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Hierarchies of conditional beliefs (Battigalli and Siniscalchi 1999) play a\ncentral role for the epistemic analysis of solution concepts in sequential\ngames. They are modelled by type structures, which allow the analyst to\nrepresent the players' hierarchies without specifying an infinite sequence of\nconditional beliefs. Here, we study type structures that satisfy a \"richness\"\nproperty, called completeness. This property is defined on the type structure\nalone, without explicit reference to hierarchies of beliefs or other type\nstructures. We provide sufficient conditions under which a complete type\nstructure represents all hierarchies of conditional beliefs. In particular, we\npresent an extension of the main result in Friedenberg (2010) to type\nstructures with conditional beliefs. KEYWORDS: Conditional probability systems,\nhierarchies of beliefs, type structures, completeness, terminality. JEL: C72,\nD80\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08940v2"
    },
    {
        "title": "A Theory of Auditability for Allocation Mechanisms",
        "authors": [
            "Aram Grigoryan",
            "Markus Möller"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In centralized mechanisms and platforms, participants do not fully observe\neach others' type reports. Hence, if there is a deviation from the promised\nmechanism, participants may be unable to detect it. We formalize a notion of\nauditabilty that captures how easy or hard it is to detect deviations from a\nmechanism. We find a stark contrast between the auditabilities of prominent\nmechanisms. We also provide tight characterizations of maximally auditable\nclasses of allocation mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.09314v3"
    },
    {
        "title": "Heterogeneous Noise and Stable Miscoordination",
        "authors": [
            "Srinivas Arigapudi",
            "Yuval Heller",
            "Amnon Schreiber"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Coordination games admit two types of equilibria: pure equilibria, where all\nplayers successfully coordinate their actions, and mixed equilibria, where\nplayers frequently experience miscoordination. The existing literature shows\nthat under many evolutionary dynamics, populations converge to a pure\nequilibrium from almost any initial distribution of actions. By contrast, we\nshow that under plausible learning dynamics, where agents observe the actions\nof a random sample of their opponents and adjust their strategies accordingly,\nstable miscoordination can arise when there is heterogeneity in the sample\nsizes. This occurs when some agents make decisions based on small samples\n(anecdotal evidence) while others rely on large samples. Finally, we\ndemonstrate the empirical relevance of our results in a bargaining application.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10301v1"
    },
    {
        "title": "Interviewing Matching in Random Markets",
        "authors": [
            "Maxwell Allman",
            "Itai Ashlagi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In many centralized labor markets candidates interview with potential\nemployers before matches are formed through a clearinghouse One prominent\nexample is the market for medical residencies and fellowships, which in recent\nyears has had a large increase in the number of interviews. There have been\nnumerous efforts to reduce the cost of interviewing in these markets using a\nvariety of signalling mechanisms, however, the theoretical properties of these\nmechanisms have not been systematically studied in models with rich\npreferences. In this paper we give theoretical guarantees for a variety of\nmechanisms, finding that these mechanisms must properly balance competition.\n  We consider a random market in which agents' latent preferences are based on\nobserved qualities, personal taste and (ex post) interview shocks and assume\nthat following an interview mechanism a final stable match is generated with\nrespect to preferences over interview partners. We study a novel many-to-many\ninterview match mechanism to coordinate interviews and that with relatively few\ninterviews, when suitably designed, the interview match yields desirable\nproperties.\n  We find that under the interview matching mechanism with a limit of $k$\ninterviews per candidate and per position, the fraction of positions that are\nunfilled vanishes quickly with $k$. Moreover the ex post efficiency grows\nrapidly with $k$, and reporting sincere pre-interview preferences to this\nmechanism is an $\\epsilon$-Bayes Nash equilibrium. Finally, we compare the\nperformance of the interview match to other signalling and coordination\nmechanisms from the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11350v2"
    },
    {
        "title": "The Over-and-Above Implementation of Reserve Policy in India",
        "authors": [
            "Orhan Aygün",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The over-and-above choice rule is the prominent selection procedure to\nimplement affirmative action. In India, it is legally mandated to allocate\npublic school seats and government job positions. This paper presents an\naxiomatic characterization of the over-and-above choice rule by rigorously\nstating policy goals as formal axioms. Moreover, we characterize the deferred\nacceptance mechanism coupled with the over-and-above choice rules for\ncentralized marketplaces.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11758v2"
    },
    {
        "title": "Nash implementation in a many-to-one matching market",
        "authors": [
            "Noelia Juarez",
            "Paola B. Manasero",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In a many-to-one matching market, we analyze the matching game induced by a\nstable rule when firms' choice function satisfy substitutability. We show that\nany stable rule implements the individually rational correspondence in Nash\nequilibrium when both sides of the market play strategically. Moreover, when\nonly workers play strategically and firms' choice functions satisfy the law of\naggregate demand, we show that the firm-optimal stable rule implements the\nstable correspondence in Nash equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13956v3"
    },
    {
        "title": "The Complexity of Corporate Culture as a Potential Source of Firm Profit\n  Differentials",
        "authors": [
            "Frederik Banning",
            "Jessica Reale",
            "Michael Roos"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper proposes an addition to the firm-based perspective on\nintra-industry profitability differentials by modelling a business organisation\nas a complex adaptive system. The presented agent-based model introduces an\nendogenous similarity-based social network and employees' reactions to dynamic\nmanagement strategies informed by key company benchmarks. The value-based\ndecision-making of employees shapes the behaviour of others through their\nperception of social norms from which a corporate culture emerges. These\nelements induce intertwined feedback mechanisms which lead to unforeseen\nprofitability outcomes. The simulations reveal that variants of extreme\nadaptation of management style yield higher profitability in the long run than\nthe more moderate alternatives. Furthermore, we observe convergence towards a\ndominant management strategy with low intensity in monitoring efforts as well\nas high monetary incentivisation of cooperative behaviour. The results suggest\nthat measures increasing the connectedness of the workforce across all four\nvalue groups might be advisable to escape potential lock-in situation and thus\nraise profitability. A further positive impact on profitability can be achieved\nthrough knowledge about the distribution of personal values among a firm's\nemployees. Choosing appropriate and enabling management strategies, and\nsticking to them in the long run, can support the realisation of the inherent\nself-organisational capacities of the workforce, ultimately leading to higher\nprofitability through cultural stability.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.14029v2"
    },
    {
        "title": "Revealed preferences for dynamically inconsistent models",
        "authors": [
            "Federico Echenique",
            "Gerelt Tserenjigmid"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the testable implications of models of dynamically inconsistent\nchoices when planned choices are unobservable, and thus only \"on path\" data is\navailable. First, we discuss the approach in Blow, Browning and Crawford\n(2021), who characterize first-order rationalizability of the model of\nquasi-hyperbolic discounting. We show that the first-order approach does not\nguarantee rationalizability by means of the quasi-hyperbolic model. This\nmotivates consideration of an abstract model of intertemporal choice, under\nwhich we provide a characterization of different behavioral models -- including\nthe naive and sophisticated paradigms of dynamically inconsistent choice.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.14125v2"
    },
    {
        "title": "On the Instability of Fractional Reserve Banking",
        "authors": [
            "Heon Lee"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper develops a dynamic monetary model to study the (in)stability of\nthe fractional reserve banking system. The model shows that the fractional\nreserve banking system can endanger stability in that equilibrium is more prone\nto exhibit endogenous cyclic, chaotic, and stochastic dynamics under lower\nreserve requirements, although it can increase consumption in the steady-state.\nIntroducing endogenous unsecured credit to the baseline model does not change\nthe main results. The calibrated exercise suggests that this channel could be\nanother source of economic fluctuations. This paper also provides empirical\nevidence that is consistent with the prediction of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.14503v3"
    },
    {
        "title": "Cautious Belief and Iterated Admissibility",
        "authors": [
            "Emiliano Catonini",
            "Nicodemo De Vito"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We define notions of cautiousness and cautious belief to provide epistemic\nconditions for iterated admissibility in finite games. We show that iterated\nadmissibility characterizes the behavioral implications of \"cautious\nrationality and common cautious belief in cautious rationality\" in a terminal\nlexicographic type structure. For arbitrary type structures, the behavioral\nimplications of these epistemic assumptions are characterized by the solution\nconcept of self-admissible set (Brandenburger, Friedenberg and Keisler 2008).\nWe also show that analogous conclusions hold under alternative epistemic\nassumptions, in particular if cautiousness is \"transparent\" to the players.\n  KEYWORDS: Epistemic game theory, iterated admissibility, weak dominance,\nlexicographic probability systems. JEL: C72.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.15330v1"
    },
    {
        "title": "Firm-quasi-stability and re-equilibration in matching markets with\n  contracts",
        "authors": [
            "Yi-You Yang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study firm-quasi-stability in the framework of many-to-many matching with\ncontracts under substitutable preferences. We establish various links between\nfirm-quasi-stability and stability, and give new insights into the existence\nand lattice property of stable allocations. In addition, we show that\nfirm-quasi-stable allocations appear naturally when the stability of the market\nis disrupted by the entry of new firms or the retirement of some workers, and\nintroduce a generalized deferred acceptance algorithm to show that the market\ncan regain stability from firm-quasi-stable allocations by a decentralized\nprocess of offers and acceptances. Moreover, it is shown that the entry of new\nfirms or the retirement of workers cannot be bad for any of the incumbent\nworkers and cannot be good for any of the original firms, while each new firm\ngets its optimal outcome under stable allocations whenever the law of aggregate\ndemand holds.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.17948v3"
    },
    {
        "title": "Coarse Information Design",
        "authors": [
            "Qianjun Lyu",
            "Wing Suen",
            "Yimeng Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study an information design problem with continuous state and discrete\nsignal space. Under convex value functions, the optimal information structure\nis interval-partitional and exhibits a dual expectations property: each induced\nsignal is the conditional mean (taken under the prior density) of each\ninterval; and each interval cutoff is the conditional mean (taken under the\nvalue function curvature) of the interval formed by neighboring signals. This\nproperty enables an examination into which part of the state space is more\nfinely partitioned. The analysis can be extended to general value functions and\nadapted to study coarse mechanism design.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.18020v4"
    },
    {
        "title": "Behavioral Causal Inference",
        "authors": [
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  When inferring the causal effect of one variable on another from\ncorrelational data, a common practice by professional researchers as well as\nlay decision makers is to control for some set of exogenous confounding\nvariables. Choosing an inappropriate set of control variables can lead to\nerroneous causal inferences. This paper presents a model of lay decision makers\nwho use long-run observational data to learn the causal effect of their actions\non a payoff-relevant outcome. Different types of decision makers use different\nsets of control variables. I obtain upper bounds on the equilibrium welfare\nloss due to wrong causal inferences, for various families of data-generating\nprocesses. The bounds depend on the structure of the type space. When types are\n\"ordered\" in a certain sense, the equilibrium condition greatly reduces the\ncost of wrong causal inference due to poor controls.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.18916v1"
    },
    {
        "title": "Kinship can hinder cooperation in heterogeneous populations",
        "authors": [
            "Boyu Zhang",
            "Yali Dong",
            "Cheng-Zhong Qin",
            "Sergey Gavrilets"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Kin selection and direct reciprocity are two most basic mechanisms for\npromoting cooperation in human society. Generalizing the standard models of the\nmulti-player Prisoner's Dilemma and the Public Goods games for heterogeneous\npopulations, we study the effects of genetic relatedness on cooperation in the\ncontext of repeated interactions. Two sets of interrelated results are\nestablished: a set of analytical results focusing on the subgame perfect\nequilibrium and a set of agent-based simulation results based on an\nevolutionary game model. We show that in both cases increasing genetic\nrelatedness does not always facilitate cooperation. Specifically, kinship can\nhinder the effectiveness of reciprocity in two ways. First, the condition for\nsustaining cooperation through direct reciprocity is harder to satisfy when\nrelatedness increases in an intermediate range. Second, full cooperation is\nimpossible to sustain for a medium-high range of relatedness values. Moreover,\nindividuals with low cost-benefit ratios can end up with lower payoffs than\ntheir groupmates with high cost-benefit ratios. Our results point to the\nimportance of explicitly accounting for within-population heterogeneity when\nstudying the evolution of cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.19026v2"
    },
    {
        "title": "The Centralizing Effects of Private Order Flow on Proposer-Builder\n  Separation",
        "authors": [
            "Tivas Gupta",
            "Mallesh M Pai",
            "Max Resnick"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The current Proposer-Builder Separation (PBS) equilibrium has several\nbuilders with different backgrounds winning blocks consistently. This paper\nconsiders how that equilibrium will shift when transactions are sold privately\nvia order flow auctions (OFAs) rather than forwarded directly to the public\nmempool. We discuss a novel model that highlights the augmented value of\nprivate order flow for integrated builder searchers. We show that private order\nflow is complementary to top-of-block opportunities, and therefore integrated\nbuilder-searchers are more likely to participate in OFAs and outbid non\nintegrated builders. They will then parlay access to these private transactions\ninto an advantage in the PBS auction, winning blocks more often and extracting\nhigher profits than non-integrated builders. To validate our main assumptions,\nwe construct a novel dataset pairing post-merge PBS outcomes with realized\n12-second volatility on a leading CEX (Binance). Our results show that\nintegrated builder-searchers are more likely to win in the PBS auction when\nrealized volatility is high, suggesting that indeed such builders have an\nadvantage in extracting top-of-block opportunities. Our findings suggest that\nmodifying PBS to disentangle the intertwined dynamics between top-of-block\nextraction and private order flow would pave the way for a fairer and more\ndecentralized Ethereum.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.19150v2"
    },
    {
        "title": "Information aggregation with delegation of votes",
        "authors": [
            "Amrita Dhillon",
            "Grammateia Kotsialou",
            "Dilip Ravindran",
            "Dimitrios Xefteris"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Liquid democracy is a system that combines aspects of direct democracy and\nrepresentative democracy by allowing voters to either vote directly themselves,\nor delegate their votes to others. In this paper we study the information\naggregation properties of liquid democracy in a setting with heterogeneously\ninformed truth-seeking voters -- who want the election outcome to match an\nunderlying state of the world -- and partisan voters. We establish that liquid\ndemocracy admits equilibria which improve welfare and information aggregation\nover direct and representative democracy when voters' preferences and\ninformation precisions are publicly or privately known. Liquid democracy also\nadmits equilibria which do worse than the other two systems. We discuss\nfeatures of efficient and inefficient equilibria and provide conditions under\nwhich voters can more easily coordinate on the efficient equilibria in liquid\ndemocracy than the other two systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.03960v1"
    },
    {
        "title": "Trade-off between manipulability and dictatorial power: a proof of the\n  Gibbard-Satterthwaite Theorem",
        "authors": [
            "Agustin G. Bonifacio"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  By endowing the class of tops-only and efficient social choice rules with a\ndual order structure that exploits the trade-off between different degrees of\nmanipulability and dictatorial power rules allow agents to have, we provide a\nproof of the Gibbard-Satterthwaite Theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.04587v2"
    },
    {
        "title": "Robust Predictions in Games with Rational Inattention",
        "authors": [
            "Tommaso Denti",
            "Doron Ravid"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We derive robust predictions in games involving flexible information\nacquisition, also known as rational inattention (Sims 2003). These predictions\nremain accurate regardless of the specific methods players employ to gather\ninformation. Compared to scenarios where information is predetermined, rational\ninattention reduces welfare and introduces additional constraints on behavior.\nWe show these constraints generically do not bind; the two knowledge regimes\nare behaviorally indistinguishable in most environments. Yet, we demonstrate\nthe welfare difference they generate is substantial: optimal policy depends on\nwhether one assumes information is given or acquired. We provide the necessary\ntools for policy analysis in this context.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.09964v1"
    },
    {
        "title": "Disentangling Revealed Preference From Rationalization by a Preference",
        "authors": [
            "Pablo Schenone"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The weak axiom of revealed preference (WARP) ensures that the revealed\npreference (i) is a preference relation (i.e., it is complete and transitive)\nand (ii) rationalizes the choices. However, when WARP fails, either one of\nthese two properties is violated, but it is unclear which one it is. We provide\nan alternative characterization of WARP by showing that WARP is equivalent to\nthe conjunction of two axioms each of which separately guarantees (i) and (ii).\n",
        "pdf_link": "http://arxiv.org/pdf/2306.11923v3"
    },
    {
        "title": "The Skill-Task Matching Model: Mechanism, Model Structure, and Algorithm",
        "authors": [
            "Da Xie",
            "WeiGuo Yang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We distinguished between the expected and actual profit of a firm. We\nproposed that, beyond maximizing profit, a firm's goal also encompasses\nminimizing the gap between expected and actual profit. Firms strive to enhance\ntheir capability to transform projects into reality through a process of trial\nand error, evident as a cyclical iterative optimization process. To\ncharacterize this iterative mechanism, we developed the Skill-Task Matching\nModel, extending the task approach in both multidimensional and iterative\nmanners. We vectorized jobs and employees into task and skill vector spaces,\nrespectively, while treating production techniques as a skill-task matching\nmatrix and business strategy as a task value vector. In our model, the process\nof stabilizing production techniques and optimizing business strategies\ncorresponds to the recalibration of parameters within the skill-task matching\nmatrix and the task value vector. We constructed a feed-forward neural network\nalgorithm to run this model and demonstrated how it can augment operational\nefficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.12176v5"
    },
    {
        "title": "Selling Multiple Complements with Packaging Costs",
        "authors": [
            "Simon Finster"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider a package assignment problem with multiple units of indivisible\nitems. The seller specifies preferences over partitions of their supply between\nbuyers as packaging costs. To express these preferences, we propose incremental\ncosts together with a graph that defines cost interdependence. This facilitates\nusing linear programming to find anonymous and package-linear Walrasian\nequilibrium prices. We provide necessary and sufficient conditions for the\nexistence of Walrasian equilibria, as well as additional sufficient conditions.\nFurthermore, our cost framework ensures fair and transparent dual pricing and\nadmits preferences over the concentration of allocated bundles in the market.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.14247v2"
    },
    {
        "title": "Equal Pay for Similar Work",
        "authors": [
            "Diego Gentile Passaro",
            "Fuhito Kojima",
            "Bobak Pakzad-Hurson"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Equal pay laws increasingly require that workers doing \"similar\" work are\npaid equal wages within firm. We study such \"equal pay for similar work\" (EPSW)\npolicies theoretically and test our model's predictions empirically using\nevidence from a 2009 Chilean EPSW. When EPSW only binds across protected class\n(e.g., no woman can be paid less than any similar man, and vice versa), firms\nsegregate their workforce by gender. When there are more men than women in a\nlabor market, EPSW increases the gender wage gap. By contrast, EPSW that is not\nbased on protected class can decrease the gender wage gap.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17111v2"
    },
    {
        "title": "Recurring Auctions with Costly Entry: Theory and Evidence",
        "authors": [
            "Shanglyu Deng",
            "Qiyao Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Recurring auctions are ubiquitous for selling durable assets like artworks\nand homes, with follow-up auctions held for unsold items. We investigate such\nauctions theoretically and empirically. Theoretical analysis demonstrates that\nrecurring auctions outperform single-round auctions when buyers face entry\ncosts, enhancing efficiency and revenue due to sorted entry of potential\nbuyers. Optimal reserve price sequences are characterized. Empirical findings\nfrom home foreclosure auctions in China reveal significant annual gains in\nefficiency (3.40 billion USD, 16.60%) and revenue (2.97 billion USD, 15.92%)\nusing recurring auctions compared to single-round auctions. Implementing\noptimal reserve prices can further improve efficiency (3.35%) and revenue\n(3.06%).\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17355v2"
    },
    {
        "title": "Two characterizations of the dense rank",
        "authors": [
            "José Luis García-Lapresta",
            "Miguel Martínez-Panero"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we have considered the dense rank for assigning positions to\nalternatives in weak orders. If we arrange the alternatives in tiers (i.e.,\nindifference classes), the dense rank assigns position 1 to all the\nalternatives in the top tier, 2 to all the alternatives in the second tier, and\nso on. We have proposed a formal framework to analyze the dense rank when\ncompared to other well-known position operators such as the standard, modified\nand fractional ranks. As the main results, we have provided two different\naxiomatic characterizations which determine the dense rank by considering\nposition invariance conditions along horizontal extensions (duplication), as\nwell as through vertical reductions and movements (truncation, and upwards or\ndownwards independency).\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17546v1"
    },
    {
        "title": "Obvious Manipulations in Matching without and with Contracts",
        "authors": [
            "R. Pablo Arribillaga",
            "E. Pepa Risma"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper explores many-to-one matching models, both with and without\ncontracts, where doctors' preferences are private and hospitals' preferences\nare public and substitutable. It is known that any stable-dominating mechanism\n--which is either stable or individually rational and Pareto-dominates (from\nthe doctors' perspective) a stable mechanism--, is susceptible to manipulation\nby doctors. Our study focuses on \\textit{obvious manipulations} and identifies\nstable-dominating mechanisms that prevent them. Without contracts, we show that\nmore efficient mechanisms are less likely to be obviously manipulable and that\nany stable-dominating mechanism is not obviously manipulable. However, with\ncontracts, none of these results hold. While we demonstrate that the\nDoctor-Proposing Deferred Acceptance (DA) Mechanism remains not obviously\nmanipulable, we show that the Hospital-Proposing DA Mechanism and any efficient\nmechanism that Pareto-dominates the Doctor-Proposing DA Mechanism become (very)\nobviously manipulable, in the model with contracts.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17773v2"
    },
    {
        "title": "Unbalanced Growth and Land Overvaluation",
        "authors": [
            "Tomohiro Hirano",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Historical trends suggest the decline in importance of land as a production\nfactor but its continued importance as a store of value. Using an overlapping\ngenerations model with land and aggregate uncertainty, we theoretically study\nthe long-run behavior of land prices and identify economic conditions under\nwhich land becomes overvalued on the long-run trend relative to the\nfundamentals defined by the present value of land rents. Unbalanced growth\ntogether with the elasticity of substitution between production factors plays a\ncritical role. Around the trend, land prices exhibit recurrent stochastic\nfluctuations, with expansions and contractions in the size of land\novervaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.00349v4"
    },
    {
        "title": "The Classical Theory of Supply and Demand",
        "authors": [
            "Sabiou Inoua",
            "Vernon Smith"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper introduces and formalizes the classical view on supply and demand,\nwhich, we argue, has an integrity independent and distinct from the\nneoclassical theory. Demand and supply, before the marginal revolution, are\ndefined not by an unobservable criterion such as a utility function, but by an\nobservable monetary variable, the reservation price: the buyer's (maximum)\nwillingness to pay (WTP) value (a potential price) and the seller's (minimum)\nwillingness to accept (WTA) value (a potential price) at the marketplace.\nMarket demand and supply are the cumulative distribution of the buyers' and\nsellers' reservation prices, respectively. This WTP-WTA classical view of\nsupply and demand formed the means whereby market participants were motivated\nin experimental economics although experimentalists (trained in neoclassical\neconomics) were not cognizant of their link to the past. On this foundation was\nerected a vast literature on the rules of trading for a host of institutions,\nmodern and ancient. This paper documents textually this reappraisal of\nclassical economics and then formalizes it mathematically. A follow-up paper\nwill articulate a theory of market price formation rooted in this classical\nview on supply and demand and in experimental findings on market behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.00413v1"
    },
    {
        "title": "Order preservation with dummies in the musseum pass problem",
        "authors": [
            "Ricardo Martínez",
            "Joaquín Sánchez-Soriano"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the problem of sharing the revenue obtained by selling museum passes\nfrom the axiomatic perspective. In this setting, we propose replacing the usual\ndummy axiom with a milder requirement: order preservation with dummies. This\nnew axiom formalizes the philosophical idea that even null agents/museums may\nhave the right to receive a minimum allocation in a sharing situation. By\nreplacing dummy with order preservation with dummies, we characterize several\nfamilies of rules, which are convex combinations of the uniform and Shapley\napproaches. Our findings generalize several existing results in the literature.\nAlso, we consider a domain of problems that is richer than the domain proposed\nby Ginsburgh and Zang (2003) in their seminal paper on the museum pass problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.00622v1"
    },
    {
        "title": "Wishful Thinking is Risky Thinking",
        "authors": [
            "Jarrod Burgh",
            "Emerson Melo"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We develop a model of wishful thinking that incorporates the costs and\nbenefits of biased beliefs. We establish the connection between distorted\nbeliefs and risk, revealing how wishful thinking can be understood in terms of\nrisk measures. Our model accommodates extreme beliefs, allowing\nwishful-thinking decision-makers to assign zero probability to undesirable\nstates and positive probability to otherwise impossible states.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.02422v2"
    },
    {
        "title": "A Belief-Based Characterization of Reduced-Form Auctions",
        "authors": [
            "Xu Lang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study games of chance (e.g., pokers, dices, horse races) in the form of\nagents' first-order posterior beliefs about game outcomes. We ask for any\nprofile of agents' posterior beliefs, is there a game that can generate these\nbeliefs? We completely characterize all feasible joint posterior beliefs from\nthese games. The characterization enables us to find a new variant of Border's\ninequalities (Border, 1991), which we call a belief-based characterization of\nBorder's inequalities. It also leads to a generalization of Aumann's Agreement\nTheorem. We show that the characterization results are powerful in bounding the\ncorrelation of agents' joint posterior beliefs.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.04070v1"
    },
    {
        "title": "Fatal errors and misuse of mathematics in the Hong-Page Theorem and\n  Landemore's epistemic argument",
        "authors": [
            "Álvaro Romaniega"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In the pursuit of understanding collective intelligence, the Hong-Page\nTheorems have been presented as cornerstones of the interplay between diversity\nand ability. However, upon rigorous examination, there seem to be inherent\nproblems and misinterpretations within these theorems. H\\'el\\`ene Landemore's\napplication of these results in her epistemic argument and her political\nproposal showcases a invalid use of mathematical principles. This paper\ncritically dissects the Hong-Page Theorems, revealing significant\ninconsistencies and oversights, and underscores the indispensable role of\n``ability\" in group problem-solving contexts. This paper aims not to undermine\nthe importance of diversity, but rather to highlight the dangers of misusing\nmathematical principles and the necessity for a more careful analysis of\nmathematical results when applying them to social sciences.d the necessity for\na more nuanced comprehension of mathematical results when applying them to\nsocial sciences.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.04709v3"
    },
    {
        "title": "S Equilibrium: A Synthesis of (Behavioral) Game Theory",
        "authors": [
            "Jacob K Goeree",
            "Bernardo Garcia-Pola"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  $S$ equilibrium synthesizes a century of game-theoretic modeling. $S$-beliefs\ndetermine choices as in the refinement literature and level-$k$, without\nanchoring on Nash equilibrium or imposing ad hoc belief formation. $S$-choices\nallow for mistakes as in QRE, without imposing rational expectations. $S$\nequilibrium is explicitly set-valued to avoid the common practice of selecting\nthe best prediction from an implicitly defined set of unknown, and unaccounted\nfor, size. $S$-equilibrium sets vary with a complexity parameter, offering a\ntrade-off between accuracy and precision unlike in $M$ equilibrium. Simple\n\"areametrics\" determine the model's parameter and show that choice sets with a\nrelative size of 5 percent capture 58 percent percent of the data.\nGoodness-of-fit tests applied to data from a broad array of experimental games\nconfirm $S$ equilibrium's ability to predict behavior in and out of sample. In\ncontrast, choice (belief) predictions of level-$k$ and QRE are rejected in most\n(all) games.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06309v1"
    },
    {
        "title": "Contracting with Heterogeneous Researchers",
        "authors": [
            "Han Wang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the design of contracts that incentivize a researcher to conduct a\ncostly experiment, extending the work of Yoder (2022) from binary states to a\ngeneral state space. The cost is private information of the researcher. When\nthe experiment is observable, we find the optimal contract and show that higher\ntypes choose more costly experiments, but not necessarily more Blackwell\ninformative ones. When only the experiment result is observable, the principal\ncan still achieve the same optimal outcome if and only if a certain\nmonotonicity condition with respect to types holds. Our analysis demonstrates\nthat the general case is qualitatively different than the binary one, but that\nthe contracting problem remains tractable.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07629v1"
    },
    {
        "title": "Optimal Queue Design",
        "authors": [
            "Yeon-Koo Che",
            "Olivier Tercieux"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the optimal method for rationing scarce resources through a queue\nsystem. The designer controls agents' entry into a queue and their exit, their\nservice priority -- or queueing discipline -- as well as their information\nabout queue priorities, while providing them with the incentive to join the\nqueue and, importantly, to stay in the queue, when recommended by the designer.\nUnder a mild condition, the optimal mechanism induces agents to enter up to a\ncertain queue length and never removes any agents from the queue; serves them\naccording to a first-come-first-served (FCFS) rule; and provides them with no\ninformation throughout the process beyond the recommendations they receive.\nFCFS is also necessary for optimality in a rich domain. We identify a novel\nrole for queueing disciplines in regulating agents' beliefs and their dynamic\nincentives and uncover a hitherto unrecognized virtue of FCFS in this regard.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07746v1"
    },
    {
        "title": "Quantal Response Equilibrium with a Continuum of Types: Characterization\n  and Nonparametric Identification",
        "authors": [
            "Evan Friedman",
            "Duarte Gonçalves"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Quantal response equilibrium (QRE), a statistical generalization of Nash\nequilibrium, is a standard benchmark in the analysis of experimental data.\nDespite its influence, nonparametric characterizations and tests of QRE are\nunavailable beyond the case of finite games. We address this gap by completely\ncharacterizing the set of QRE in a class of binary-action games with a\ncontinuum of types. Our characterization provides sharp predictions in settings\nsuch as global games, volunteer's dilemma, and the compromise game. Further, we\nleverage our results to develop nonparametric tests of QRE. As an empirical\napplication, we revisit the experimental data from Carrillo and Palfrey (2009)\non the compromise game.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.08011v2"
    },
    {
        "title": "Anticomonotonicity for Preference Axioms: The Natural Counterpart to\n  Comonotonicity",
        "authors": [
            "Giulio Principi",
            "Peter P. Wakker",
            "Ruodu Wang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Comonotonicity (``same variation'') of random variables minimizes hedging\npossibilities and has been widely used, e.g., in Gilboa and Schmeidler's\nambiguity models. This paper investigates anticomonotonicity (``opposite\nvariation''; abbreviated ``AC''), the natural counterpart to comonotonicity. It\nminimizes leveraging rather than hedging possibilities. Surprisingly, AC\nrestrictions of several traditional axioms do not give new models. Instead,\nthey strengthen the foundations of existing classical models: (a) linear\nfunctionals through Cauchy's equation; (b) Anscombe-Aumann expected utility;\n(c) as-if-risk-neutral pricing through no-arbitrage; (d) de Finetti's\nbookmaking foundation of Bayesianism using subjective probabilities; (e) risk\naversion in Savage's subjective expected utility. In each case, our\ngeneralizations show where the critical tests of classical axioms lie: in the\nAC cases (maximal hedges). We next present examples where AC restrictions do\nessentially weaken existing axioms, and do provide new properties and new\nmodels.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.08542v3"
    },
    {
        "title": "Unraveling Coordination Problems",
        "authors": [
            "Roweno J. R. K. Heijmans"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Strategic uncertainty complicates policy design in coordination games. To\nrein in strategic uncertainty, the Planner in this paper connects the problem\nof policy design to that of equilibrium selection. We characterize the subsidy\nscheme that induces coordination on a given outcome of the game as its unique\nequilibrium. Optimal subsidies are unique, symmetric for identical players,\ncontinuous functions of model parameters, and do not make the targeted\nstrategies strictly dominant for any one player; these properties differ\nstarkly from canonical results in the literature. Uncertainty about payoffs\nimpels policy moderation as overly aggressive intervention might itself induce\ncoordination failure.\n  JEL codes: D81, D82, D83, D86, H20.\n  Keywords: mechanism design, global games, contracting with externalities,\nunique implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.08557v6"
    },
    {
        "title": "Horizontal and Vertical Differentiation: Approaching Endogenous\n  Measurement in Intra-industry Trade",
        "authors": [
            "Sourish Dutta"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Studying intra-industry trade involves theoretical explanations and empirical\nmethods to measure the phenomenon. Indicators have been developed to measure\nthe intensity of intra-industry trade, leading to theoretical models explaining\nits determinants. It is essential to distinguish between horizontal and\nvertical differentiation in empirical analyses. The determinants and\nconsequences of intra-industry trade depend on whether the traded products\ndiffer in quality. A method for distinguishing between vertical and horizontal\ndifferentiation involves comparing exports' unit value to imports for each\nindustry's intra-industry trade. This approach has limitations, leading to the\nneed for an alternative method.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.10660v2"
    },
    {
        "title": "Sharing Credit for Joint Research",
        "authors": [
            "Nicholas Wu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  How can one efficiently share payoffs with collaborators when participating\nin risky research? First, I show that efficiency can be achieved by allocating\npayoffs asymmetrically between the researcher who makes a breakthrough\n(\"winner\") and the others, even if agents cannot observe others' effort. When\nthe winner's identity is non-contractible, allocating credit based on effort at\ntime of breakthrough also suffices to achieve efficiency; so the terminal\neffort profile, rather than the full history of effort, is a sufficient\nstatistic. These findings suggest that simple mechanisms using minimal\ninformation are robust and effective in addressing inefficiencies in strategic\nexperimentation.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12104v3"
    },
    {
        "title": "Indicator Choice in Pay-for-Performance",
        "authors": [
            "Majid Mahzoon",
            "Ali Shourideh",
            "Ariel Zetlin-Jones"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the classic principal-agent model when the signal observed by the\nprincipal is chosen by the agent. We fully characterize the optimal information\nstructure from an agent's perspective in a general moral hazard setting with\nlimited liability. Due to endogeneity of the contract chosen by the principal,\nthe agent's choice of information is non-trivial. We show that the agent's\nproblem can be mapped into a geometrical game between the principal and the\nagent in the space of likelihood ratios. We use this representation result to\nshow that coarse contracts are sufficient: The agent can achieve her best with\nbinary signals. Additionally, we can characterize conditions under which the\nagent is able to extract the entire surplus and implement the first-best\nefficient allocation. Finally, we show that when effort and performance are\none-dimensional, under a general class of models, threshold signals are\noptimal. Our theory can thus provide a rationale for coarseness of contracts\nbased on the bargaining power of the agent in negotiations.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12457v1"
    },
    {
        "title": "It's Not Always the Leader's Fault: How Informed Followers Can Undermine\n  Efficient Leadership",
        "authors": [
            "Panagiotis Kyriazis",
            "Edmund Lou"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Coordination facilitation and efficient decision-making are two essential\ncomponents of successful leadership. In this paper, we take an informational\napproach and investigate how followers' information impacts coordination and\nefficient leadership in a model featuring a leader and a team of followers. We\nshow that efficiency is achieved as the unique rationalizable outcome of the\ngame when followers possess sufficiently imprecise information. In contrast, if\nfollowers have accurate information, the leader may fail to coordinate them\ntoward the desired outcome or even take an inefficient action herself. We\ndiscuss the implications of the results for the role of leaders in the context\nof financial fragility and crises.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.13841v3"
    },
    {
        "title": "Power relations in Game Theory",
        "authors": [
            "Daniele De Luca"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The concept of power among players can be expressed as a combination of their\nutilities. A player who obeys another takes into account the utility of the\ndominant one. Technically it is a matter of superimposing some weighted sum or\nproduct function onto the individual utility function, where the weights can be\nrepresented through directed graphs that reflect a situation of power among the\nplayers. It is then possible to define some global indices of the system, such\nas the level of hierarchy, mutualism and freedom, and measure their effects on\ngame equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.14170v1"
    },
    {
        "title": "Control and Spread of Contagion in Networks",
        "authors": [
            "John Higgins",
            "Tarun Sabarwal"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study proliferation of an action in binary action network coordination\ngames that are generalized to include global effects. This captures important\naspects of proliferation of a particular action or narrative in online social\nnetworks, providing a basis to understand their impact on societal outcomes.\nOur model naturally captures complementarities among starting sets, network\nresilience, and global effects, and highlights interdependence in channels\nthrough which contagion spreads. We present new, natural, and computationally\ntractable algorithms to define and compute equilibrium objects that facilitate\nthe general study of contagion in networks and prove their theoretical\nproperties. Our algorithms are easy to implement and help to quantify\nrelationships previously inaccessible due to computational intractability.\nUsing these algorithms, we study the spread of contagion in scale-free networks\nwith 1,000 players using millions of Monte Carlo simulations. Our analysis\nprovides quantitative and qualitative insight into the design of policies to\ncontrol or spread contagion in networks. The scope of application is enlarged\ngiven the many other situations across different fields that may be modeled\nusing this framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.00062v1"
    },
    {
        "title": "Repeated Bidding with Dynamic Value",
        "authors": [
            "Benjamin Heymann",
            "Alexandre Gilotte",
            "Rémi Chan-Renous"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider a repeated auction where the buyer's utility for an item depends\non the time that elapsed since his last purchase. We present an algorithm to\nbuild the optimal bidding policy, and then, because optimal might be\nimpractical, we discuss the cost for the buyer of limiting himself to shading\npolicies.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.01755v1"
    },
    {
        "title": "The Banks Set and the Bipartisan Set May Be Disjoint",
        "authors": [
            "Felix Brandt",
            "Florian Grundbacher"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Tournament solutions play an important role within social choice theory and\nthe mathematical social sciences at large. We construct a tournament of order\n36 for which the Banks set and the bipartisan set are disjoint. This implies\nthat refinements of the Banks set, such as the minimal extending set and the\ntournament equilibrium set, can also be disjoint from the bipartisan set.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.01881v2"
    },
    {
        "title": "The Expected Shapley value on a class of probabilistic games",
        "authors": [
            "Surajit Borkotokey",
            "Sujata Gowala",
            "Rajnish Kumar"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a class of probabilistic cooperative games which can be treated as\nan extension of the classical cooperative games with transferable utilities.\nThe coalitions have an exogenous probability of being realized. This\nprobability distribution is known beforehand and the distribution of the\nexpected worth needs to be done before the realization of the state. We obtain\na value for this class of games and present three characterizations of this\nvalue using natural extensions of the axioms used in the seminal axiomatization\nof the Shapley value. The value, which we call the Expected Shapley value,\nallocates the players their expected worth with respect to a probability\ndistribution.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.03489v1"
    },
    {
        "title": "Weighted position value for Network games",
        "authors": [
            "Niharika Kakoty",
            "Surajit Borkotokey",
            "Rajnish Kumar",
            "Abhijit Bora"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In Network games under cooperative framework, the position value is a link\nbased allocation rule. It is obtained from the Shapley value of an associated\ncooperative game where the links of the network are considered players. The\nShapley value of each of the links is then divided equally among the players\nwho form those links. The inherent assumption is that the value is indifferent\nto the weights of the players in the network. Depending on how much central a\nplayer is in the network, or the ability of making links with other players\netc., for example, players can be considered to have weights. Thus, in such\nsituations, dividing the Shapley value equally among the players can be an\nover-simplistic notion. We propose a generalised version of the position value:\nthe weighted position value that allocates the Shapley shares proportional to\nthe players' weights. These weights of the players are exogenously given. We\nprovide two axiomatic characterizations of our value. Finally, a bidding\nmechanism is formulated to show that any sub-game perfect equilibrium (SPE) of\nthis mechanism coincides with the weighted position value.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.03494v1"
    },
    {
        "title": "How to choose a Compatible Committee?",
        "authors": [
            "Ritu Dutta",
            "Rajnish Kumnar",
            "Surajit Borkotokey"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Electing a committee of size k from m alternatives (k < m) is an interesting\nproblem under the multi-winner voting rules. However, very few committee\nselection rules found in the literature consider the coalitional possibilities\namong the alternatives that the voters believe that certain coalitions are more\neffective and can more efficiently deliver desired outputs. To include such\npossibilities, in this present study, we consider a committee selection problem\n(or multi-winner voting problem) where voters are able to express their opinion\nregarding interdependencies among alternatives. Using a dichotomous preference\nscale termed generalized approval evaluation we construct an $m$-person\ncoalitional game which is more commonly called a cooperative game with\ntransferable utilities. To identify each alternative's score we use the Shapley\nvalue (Shapley, 1953) of the cooperative game we construct for the purpose. Our\napproach to the committee selection problem emphasizes on an important issue\ncalled the compatibility principle. Further, we show that the properties of the\nShapley value are well suited in the committee selection context too. We\nexplore several properties of the proposed committee selection rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.03507v1"
    },
    {
        "title": "Uniqueness of equilibrium and redistributive policies: a geometric\n  approach to efficiency",
        "authors": [
            "Andrea Loi",
            "Stefano Matta",
            "Daria Uccheddu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper examines the relationship between resource reallocation,\nuniqueness of equilibrium and efficiency in economics. We explore the\nimplications of reallocation policies for stability, conflict, and\ndecision-making by analysing the existence of geodesic coordinate functions in\nthe equilibrium manifold. Our main result shows that in an economy with M = 2\nconsumers and L goods, if L coordinate functions, representing policies, are\ngeodesics on the equilibrium manifold (a property that we call the finite\ngeodesic property), then the equilibrium is globally unique. The presence of\ngeodesic variables indicates optimization and efficiency in the economy, while\nnon-geodesic variables add complexity. Finally, we establish a link between the\nexisting results on curvature, minimal entropy, geodesics and uniqueness in\nsmooth exchange economies. This study contributes to the understanding of the\ngeometric and economic properties of equilibria and offers potential\napplications in policy considerations. Keywords: Uniqueness of equilibrium,\nredistributive policies, geodesics, equilibrium manifold, equilibrium\nselection, curvature, geodesics.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.03706v1"
    },
    {
        "title": "Tropical Analysis: With an Application to Indivisible Goods",
        "authors": [
            "Nicholas C. Bedard",
            "Jacob K. Goeree"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We establish the Subgradient Theorem for monotone correspondences -- a\nmonotone correspondence is equal to the subdifferential of a potential if and\nonly if it is conservative, i.e. its integral along a closed path vanishes\nirrespective of the selection from the correspondence along the path. We prove\ntwo attendant results: the Potential Theorem, whereby a conservative monotone\ncorrespondence can be integrated up to a potential, and the Duality Theorem,\nwhereby the potential has a Fenchel dual whose subdifferential is another\nconservative monotone correspondence. We use these results to reinterpret and\nextend Baldwin and Klemperer's (2019) characterization of demand in economies\nwith indivisible goods. We introduce a simple test for existence of Walrasian\nequilibrium in quasi-linear economies. Fenchel's Duality Theorem implies this\ntest is met when the aggregate utility is concave, which is not necessarily the\ncase with indivisible goods even if all consumers have concave utilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.04593v1"
    },
    {
        "title": "School Choice with Multiple Priorities",
        "authors": [
            "Minoru Kitahara",
            "Yasunori Okumura"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This study considers a model where schools may have multiple priority orders\non students, which may be inconsistent with each other. For example, in school\nchoice systems, since the sibling priority and the walk zone priority coexist,\nthe priority orders based on them would be conflicting. We introduce a weaker\nfairness notion called M-fairness to examine such markets. Further, we focus on\na more specific situation where all schools have only two priority orders, and\nfor a certain group of students, a priority order of each school is an\nimprovement of the other priority order of the school. An illustrative example\nis the school choice matching market with a priority-based affirmative action\npolicy. We introduce a mechanism that utilizes the efficiency adjusted deferred\nacceptance algorithm and show that the mechanism satisfies properties called\nresponsiveness to improvements and improved-group optimally M-stability, which\nis stronger than student optimally M-stability.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.04780v4"
    },
    {
        "title": "Dynamic delegation in promotion contests",
        "authors": [
            "Théo Durandard"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I study how organizations assign tasks to identify the best candidate to\npromote among a pool of workers. Task allocation and workers' motivation\ninteract through the organization's promotion decisions. The organization\ndesigns the workers' careers to both screen and develop talent. When only\nnon-routine tasks are informative about a worker's type and non-routine tasks\nare scarce, the organization's preferred promotion system is an index contest.\nEach worker is assigned a number that depends only on his own type. The\nprincipal delegates the non-routine task to the worker whose current index is\nthe highest and promotes the first worker whose type exceeds a threshold. Each\nworker's threshold is independent of the other workers' types. Competition is\nmediated by the allocation of tasks: who gets the opportunity to prove\nthemselves is a determinant factor in promotions. Finally, features of the\noptimal promotion contest rationalize the prevalence of fast-track promotion,\nthe role of seniority, or when a group of workers is systemically advantaged.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.05668v1"
    },
    {
        "title": "On the unimportance of commitment for monetary policy",
        "authors": [
            "Juan Paez-Farrell"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In a New Keynesian model where the trade-off between stabilising the\naggregate inflation rate and the output gap arises from sectoral asymmetries,\nthe gains from commitment are either zero or negligible. Thus, to the extent\nthat economic fluctuations are caused by sectoral shocks, policies designed to\novercome the stabilisation bias are aiming to correct an unimportant problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.08044v2"
    },
    {
        "title": "A Majority Rule Philosophy for Instant Runoff Voting",
        "authors": [
            "Ross Hyman",
            "Deb Otis",
            "Seamus Allen",
            "Greg Dennis"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We present the core support criterion, a voting criterion satisfied by\nInstant Runoff Voting (IRV) that is analogous to the Condorcet criterion but\nreflective of a different majority rule philosophy. Condorcet methods can be\nthought of as conducting elections between each pair of candidates, counting\nall ballots to determine the winner of each pair-election. IRV can also be\nthought of as conducting elections between all pairs of candidates but for each\npair-election only counting ballots from voters who do not prefer another major\ncandidate (as determined self-consistently from the IRV social ranking) to the\ntwo candidates in contention. The appropriateness of including all ballots or a\nsubset of ballots for a pair-election, depends on whether the society deems the\nentire or a selected ballot set in compliance with freedom of association\n(which implies freedom of non-association) for a given pair election. Arguments\nbased on freedom of association rely on more information about an electorate\nthan can be learned from ranked ballots alone. We present a\nfreedom-of-association based argument to explain why IRV may be preferable to\nCondorcet in some circumstances, including the 2022 Alaska special\ncongressional election, based on the political context of that election.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.08430v2"
    },
    {
        "title": "Asymptotic Value of Monitoring Structures in Stochastic Games",
        "authors": [
            "Daehyun Kim",
            "Ichiro Obara"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies how improved monitoring affects the limit equilibrium\npayoff set for stochastic games with imperfect public monitoring. We introduce\na simple generalization of Blackwell garbling called weighted garbling in order\nto compare different monitoring structures for this class of games. Our main\nresult is the monotonicity of the limit perfect public equilibrium (PPE) payoff\nset with respect to this information order. We show that the limit PPE payoff\nset expands when the monitoring structure gets more informative with respect to\nthe weighted garbling order. We also show that a similar monotonicity holds for\nstrongly symmetric equilibrium for symmetric stochastic games. Finally, we show\nthat our weighted garbling order is useful to compare the limit PPE payoff set\nfor different state transition laws and monitoring structures when the limit\nfeasible payoff set is the same.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09211v2"
    },
    {
        "title": "Endowments, patience types, and uniqueness in two-good HARA utility\n  economies",
        "authors": [
            "Andrea Loi",
            "Stefano Matta"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper establishes a link between endowments, patience types, and the\nparameters of the HARA Bernoulli utility function that ensure equilibrium\nuniqueness in an economy with two goods and two impatience types with additive\nseparable preferences. We provide sufficient conditions that guarantee\nuniqueness of equilibrium for any possible value of $\\gamma$ in the HARA\nutility function\n$\\frac{\\gamma}{1-\\gamma}\\left(b+\\frac{a}{\\gamma}x\\right)^{1-\\gamma}$. The\nanalysis contributes to the literature on uniqueness in pure exchange economies\nwith two-goods and two agent types and extends the result in [4].\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09347v1"
    },
    {
        "title": "Central Bank Digital Currency with Collateral-constrained Banks",
        "authors": [
            "Hanfeng Chen",
            "Maria Elena Filippin"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyze the risks to bank intermediation following the introduction of a\ncentral bank digital currency (CBDC). The CBDC competes with commercial bank\ndeposits as the household's source of liquidity. We revisit the result in the\nliterature regarding the equivalence of payment systems by introducing a\ncollateral constraint for banks when borrowing from the central bank. When\ncomparing two equilibria with and without the CBDC, the central bank can ensure\nthe same equilibrium allocation and price system by offering loans to banks.\nHowever, to access loans, banks must hold collateral at the expense of\nextending credit to firms, and the central bank assumes part of the\ncredit-extension role. Thus, in the equivalence analysis, while the CBDC\nintroduction has no real effects on the economy, it does not guarantee full\nneutrality as it affects banks' business models. In a dynamic model extension,\nwe analyze the effects of an increase in the CBDC and show that the CBDC not\nonly does not cause bank disintermediation or crowd out of deposits but may\nfoster an expansion of bank credit to firms.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.10359v6"
    },
    {
        "title": "Nash Equilibrium Existence without Convexity",
        "authors": [
            "Conrad Kosowsky"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, I prove the existence of a pure-strategy Nash equilibrium for\na large class of games with nonconvex strategy spaces. Specifically, if each\nplayer's strategies form a compact, connected Euclidean neighborhood retract\nand if all best-response correspondences are null-homotopic, then the game has\na pure-strategy Nash equilibrium. As an application, I show how this result can\nprove the fundamental theorem of algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.11597v1"
    },
    {
        "title": "Multivariate Majorization in Principal-Agents Models",
        "authors": [
            "Nicholas C Bedard",
            "Jacob K Goeree",
            "Ningyi Sun"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We introduce a definition of multivariate majorization that is new to the\neconomics literature. Our majorization technique allows us to generalize Mussa\nand Rosen's (1978) \"ironing\" to a broad class of multivariate principal-agents\nproblems. Specifically, we consider adverse selection problems in which agents'\ntypes are one dimensional but informational externalities create a\nmultidimensional ironing problem. Our majorization technique applies to\ndiscrete and continuous type spaces alike and we demonstrate its usefulness for\ncontract theory and mechanism design. We further show that multivariate\nmajorization yields a natural extension of second-order stochastic dominance to\nmultiple dimensions and derive its implications for decision making under\nmultivariate risk.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.13804v1"
    },
    {
        "title": "Self-Enforced Job Matching",
        "authors": [
            "Ce Liu",
            "Ziwei Wang",
            "Hanzhe Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The classic two-sided many-to-one job matching model assumes that firms treat\nworkers as substitutes and workers ignore colleagues when choosing where to\nwork. Relaxing these assumptions may lead to nonexistence of stable matchings.\nHowever, matching is often not a static allocation, but an ongoing process with\nlong-lived firms and short-lived workers. We show that stability is always\nguaranteed dynamically when firms are patient, even with complementarities in\nfirm technologies and peer effects in worker preferences. While no-poaching\nagreements are anti-competitive, they can maintain dynamic stability in markets\nthat are otherwise unstable, which may contribute to their prevalence in labor\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.13899v1"
    },
    {
        "title": "Reputation Effects with Endogenous Records",
        "authors": [
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A patient firm interacts with a sequence of consumers. The firm is either an\nhonest type who supplies high quality and never erases its records, or an\nopportunistic type who chooses what quality to supply and may erase its records\nat a low cost. We show that in every equilibrium, the firm has an incentive to\nbuild a reputation for supplying high quality until its continuation value\nexceeds its commitment payoff, but its ex ante payoff must be close to its\nminmax value when it has a sufficiently long lifespan. Therefore, even a small\nfraction of opportunistic types can wipe out the firm's returns from building\nreputations. Even if the honest type can commit to reveal information about its\nhistory according to any disclosure policy, the opportunistic type's payoff\ncannot exceed its equilibrium payoff when the consumers receive no information.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.13956v2"
    },
    {
        "title": "Equity Pay In Networked Teams",
        "authors": [
            "Krishna Dasaratha",
            "Benjamin Golub",
            "Anant Shah"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A group of agents each exert effort to produce a joint output, with the\ncomplementarities between their efforts represented by a (weighted) network.\nUnder equity compensation, a principal motivates the agents to work by giving\nthem shares of the output. We describe the optimal equity allocation. It is\ncharacterized by a neighborhood balance condition: any two agents receiving\nequity have the same (weighted) total equity assigned to their neighbors. We\nalso study the problem of selecting the team of agents who receive positive\nequity, and show this team must form a tight-knit subset of the complementarity\nnetwork, with any pair being complementary to one another or jointly to another\nteam member. Finally, we give conditions under which the amount of equity used\nfor compensation is increasing in the strength of a team's complementarities\nand discuss several other applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.14717v1"
    },
    {
        "title": "Efficiency in Multiple-Type Housing Markets",
        "authors": [
            "Di Feng"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider multiple-type housing markets (Moulin, 1995), which extend\nShapley-Scarf housing markets (Shapley and Scarf, 1974) from one dimension to\nhigher dimensions. In this model, Pareto efficiency is incompatible with\nindividual rationality and strategy-proofness (Konishi et al., 2001).\nTherefore, we consider two weaker efficiency properties: coordinatewise\nefficiency and pairwise efficiency. We show that these two properties both (i)\nare compatible with individual rationality and strategy-proofness, and (ii)\nhelp us to identify two specific mechanisms. To be more precise, on various\ndomains of preference profiles, together with other well-studied properties\n(individual rationality, strategy-proofness, and non-bossiness), coordinatewise\nefficiency and pairwise efficiency respectively characterize two extensions of\nthe top-trading-cycles mechanism (TTC): the coordinatewise top-trading-cycles\nmechanism (cTTC) and the bundle top-trading-cycles mechanism (bTTC). Moreover,\nwe propose several variations of our efficiency properties, and we find that\neach of them is either satisfied by cTTC or bTTC, or leads to an impossibility\nresult (together with individual rationality and strategy-proofness).\nTherefore, our characterizations can be primarily interpreted as a\ncompatibility test: any reasonable efficiency property that is not satisfied by\ncTTC or bTTC could be considered incompatible with individual rationality and\nstrategy-proofness. The external validity of our results in the context of\ngeneral environments is also discussed. For multiple-type housing markets with\nstrict preferences, our characterization of bTTC constitutes the first\ncharacterization of an extension of the prominent TTC mechanism\n",
        "pdf_link": "http://arxiv.org/pdf/2308.14989v2"
    },
    {
        "title": "Regret-Minimizing Project Choice",
        "authors": [
            "Yingni Guo",
            "Eran Shmaya"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  An agent observes the set of available projects and proposes some, but not\nnecessarily all, of them. A principal chooses one or none from the proposed\nset. We solve for a mechanism that minimizes the principal's worst-case regret.\nWe compare the single-project environment in which the agent can propose only\none project with the multiproject environment in which he can propose many. In\nboth environments, if the agent proposes one project, it is chosen for sure if\nthe principal's payoff is sufficiently high; otherwise, the probability that it\nis chosen decreases in the agent's payoff. In the multiproject environment, the\nagent's payoff from proposing multiple projects equals his maximal payoff from\nproposing each project alone. The multiproject environment outperforms the\nsingle-project one by providing better fallback options than rejection and by\ndelivering this payoff to the agent more efficiently.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.00214v1"
    },
    {
        "title": "The Effect of Punishment and Reward on Cooperation in a Prisoners'\n  Dilemma Game",
        "authors": [
            "Alexander Kangas"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This work studies the effect of incentives (in the form of punishment and\nreward) on the equilibrium fraction of cooperators and defectors in an iterated\nn-person prisoners' dilemma game. With a finite population of players employing\na strategy of nice tit-for-tat or universal defect, an equilibrium fraction of\neach player-type can be identified from linearized payoff functions. Incentives\ntake the form of targeted and general punishment, and targeted and general\nreward. The primary contribution of this work is in clearly articulating the\ndesign and marginal effect of these incentives on cooperation. Generalizable\nresults indicate that while targeted incentives have the potential to\nsubstantially reduce but never entirely eliminate defection, they exhibit\ndiminishing marginal effectiveness. General incentives on the other hand have\nthe potential to eliminate all defection from the population of players.\nApplications to policy are briefly considered.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.00556v1"
    },
    {
        "title": "Constructing a type-adjustable mechanism to yield Pareto-optimal\n  outcomes",
        "authors": [
            "Haoyang Wu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In mechanism design theory, agents' types are described as their private\ninformation, and the designer may reveal some public information to affect\nagents' types in order to obtain more payoffs. Traditionally, each agent's\nprivate type and the public information are represented as a random variable\nrespectively. In this paper, we propose a type-adjustable mechanism where each\nagent's private type is represented as a function of two parameters,\n\\emph{i.e.}, his intrinsic factor and an external factor. Each agent's\nintrinsic factor is modeled as a private random variable, and the external\nfactor is modeled as a solution of the designer's optimization problem. If the\ndesigner chooses an optimal value of external factor as public information, the\ntype-adjustable mechanism may yield Pareto-optimal outcomes, which let the\ndesigner and each agent obtain more expected payoffs than what they would\nobtain at most in the traditional optimal mechanisms. As a comparison, in an\nauction with interdependent values, only the seller will benefit from public\ninformation which is represented as a random variable. We propose a revised\nversion of revelation principle for type-adjustable Bayesian equilibrium. In\nthe end, we compare the type-adjustable mechanism with other relevant models.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01096v2"
    },
    {
        "title": "Do Losses Matter? The Effect of Information-Search Technologies on Risky\n  Choices",
        "authors": [
            "Luigi Mittone",
            "Mauro Papi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Despite its importance, relatively little attention has been devoted to\nstudying the effects of exposing individuals to digital choice interfaces. In\ntwo pre-registered lottery-choice experiments, we administer three\ninformation-search technologies that are based on well-known heuristics: in the\nABS (alternative-based search) treatment, subjects explore outcomes and\ncorresponding probabilities within lotteries; in the CBS (characteristic-based\nsearch) treatment, subjects explore outcomes and corresponding probabilities\nacross lotteries; in the Baseline treatment, subjects view outcomes and\ncorresponding probabilities all at once. We find that (i) when lottery outcomes\ncomprise gains and losses (experiment 1), exposing subjects to the CBS\ntechnology systematically makes them choose safer lotteries, compared to the\nsubjects that are exposed to the other technologies, and (ii) when lottery\noutcomes comprise gains only (experiment 2), the above results are reversed:\nexposing subjects to the CBS technology systematically makes them choose\nriskier lotteries. By combining the information-search and choice analysis, we\noffer an interpretation of our results that is based on prospect theory,\nwhereby the information-search technology subjects are exposed to contributes\nto determine the level of attention that the lottery attributes receive, which\nin turn has an effect on the reference point.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01495v1"
    },
    {
        "title": "On the minimal simplex economy",
        "authors": [
            "Antonio Pulgarín"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In our previous paper we proved that every affine economy has a competitive\nequilibrium. We define a simplex economy as an affine economy consisting of a\nstochastic allocation (defining the initial endowments) and a variation with\nrepetition of the number of commodities taking the number of consumers\n(representing the preferences). We show that a competitive equilibrium can be\nintrinsically computed in any minimal simplex economy.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.03784v3"
    },
    {
        "title": "Local Priority Mechanisms",
        "authors": [
            "Joseph Root",
            "David S. Ahn"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We introduce a novel family of mechanisms for constrained allocation problems\nwhich we call local priority mechanisms. These mechanisms are parameterized by\na function which assigns a set of agents, the local compromisers, to every\ninfeasible allocation. The mechanism then greedily attempts to match agents\nwith their top choices. Whenever it reaches an infeasible allocation, the local\ncompromisers move to their next favorite alternative. Local priority mechanisms\nexist for any constraint, so this provides a method of constructing new designs\nfor any constrained allocation problem. We give axioms which characterize local\npriority mechanisms. Since constrained allocation includes many canonical\nproblems as special constraints, we apply this characterization to show that\nseveral well-known mechanisms, including deferred acceptance for school choice,\ntop trading cycles for house allocation, and serial dictatorship can be\nunderstood as instances of local priority mechanisms. Other mechanisms,\nincluding the Boston mechanism, are not local priority mechanisms. We give\nsufficient conditions for a local priority mechanism to be group\nstrategy-proof. We also provide conditions which enable welfare comparisons\nacross local priority mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04020v2"
    },
    {
        "title": "Concave many-to-one matching",
        "authors": [
            "Chao Huang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We propose a notion of concavity in two-sided many-to-one matching, which is\nan analogue to the balancedness condition in cooperative games. A stable\nmatching exists when the market is concave. We provide a class of concave\nmarkets. In the proof of the existence theorem, we use Scarf's algorithm to\nfind a stable schedule matching, which is of independent interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04181v1"
    },
    {
        "title": "Robust equilibria in cheap-talk games with fairly transparent motives",
        "authors": [
            "Jan-Henrik Steg",
            "Elshan Garashli",
            "Michael Greinecker",
            "Christoph Kuzmics"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  For cheap-talk games with a binary state space in which the sender has\nstate-independent preferences, we characterize equilibria that are robust to\nintroducing slight state-dependence on the side of the sender. Not all\nequilibria are robust, but the sender-optimum is always achieved at some robust\nequilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04193v2"
    },
    {
        "title": "A duality between utility transforms and probability distortions",
        "authors": [
            "Christopher P. Chambers",
            "Peng Liu",
            "Ruodu Wang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we establish a mathematical duality between utility transforms\nand probability distortions. These transforms play a central role in decision\nunder risk by forming the foundation for the classic theories of expected\nutility, dual utility, and rank-dependent utility. Our main results establish\nthat probability distortions are characterized by commutation with utility\ntransforms, and utility transforms are characterized by commutation with\nprobability distortions. These results require no additional conditions, and\nhence each class can be axiomatized with only one property. Moreover, under\nmonotonicity, rank-dependent utility transforms can be characterized by set\ncommutation with either utility transforms or probability distortions.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.05816v2"
    },
    {
        "title": "Dynamic Arrangements in Economic Theory: Level-Agnostic Representations",
        "authors": [
            "Fernando Tohmé"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  If Economics is understood as the study of the interactions among intentional\nagents, being rationality the main source of intentional behavior, the\nmathematical tools that it requires must be extended to capture systemic\neffects. Here we choose an alternative toolbox based on Category Theory. We\nexamine potential {\\em level-agnostic} formalisms, presenting three categories,\n$\\mathcal{PR}$, $\\mathcal{G}$ and an encompassing one, $\\mathcal{PR-G}$. The\nlatter allows for representing dynamic rearrangements of the interactions among\ndifferent agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.06383v1"
    },
    {
        "title": "Not obviously manipulable allotment rules",
        "authors": [
            "R. Pablo Arribillaga",
            "Agustin G. Bonifacio"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In the problem of allocating a single non-disposable commodity among agents\nwhose preferences are single-peaked, we study a weakening of strategy-proofness\ncalled not obvious manipulability (NOM). If agents are cognitively limited,\nthen NOM is sufficient to describe their strategic behavior. We characterize a\nlarge family of own-peak-only rules that satisfy efficiency, NOM, and a minimal\nfairness condition. We call these rules \"simple\". In economies with excess\ndemand, simple rules fully satiate agents whose peak amount is less than or\nequal to equal division and assign, to each remaining agent, an amount between\nequal division and his peak. In economies with excess supply, simple rules are\ndefined symmetrically. These rules can be thought of as a two-step procedure\nthat involves solving a claims problem. We also show that the single-plateaued\ndomain is maximal for the characterizing properties of simple rules. Therefore,\neven though replacing strategy-proofness with NOM greatly expands the family of\nadmissible rules, the maximal domain of preferences involved remains basically\nunaltered.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.06546v2"
    },
    {
        "title": "A Reexamination of Proof Approaches for the Impossibility Theorem",
        "authors": [
            "Kazuya Yamamoto"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The decisive-set and pivotal-voter approaches have been used to prove Arrow's\nimpossibility theorem. This study presents a proof using a proof calculus in\nlogic. A valid deductive inference between the premises, the axioms and\nconditions of the theorem, and the conclusion, dictatorship, guarantees that\nevery profile of all possible social welfare functions is examined, thereby\nestablishing the theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.06753v3"
    },
    {
        "title": "Quota Mechanisms: Finite-Sample Optimality and Robustness",
        "authors": [
            "Ian Ball",
            "Deniz Kattwinkel"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A quota mechanism links together multiple decisions by imposing a quota\nacross decisions. We analyze the performance of quota mechanisms when the\nnumber of linked decisions is finite and the designer has imperfect knowledge\nof the type distribution; previously, only asymptotic results were known. Using\na new optimal transport approach, we derive an ex-post decision error guarantee\nfor quota mechanisms. This guarantee cannot be improved by any mechanisms\nwithout transfers. We quantify the sensitivity of quota mechanisms to errors in\nthe designer's estimate of the type distribution. Finally, we show that quotas\nare robust to agents' beliefs about each other.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.07363v3"
    },
    {
        "title": "Learning Source Biases: Multisource Misspecifications and Their Impact\n  on Predictions",
        "authors": [
            "Junnan He",
            "Lin Hu",
            "Matthew Kovach",
            "Anqi Li"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study how a Bayesian decision maker (DM) learns about the biases of novel\ninformation sources to predict a random state. Absent frictions, the DM uses\nfamiliar sources as yardsticks to accurately discern the biases of novel\nsources. We derive the distortion of the DM's long-run prediction when he holds\nmisspecified beliefs about the biases of several familiar sources. The\ndistortion aggregates misspecifications across familiar sources independently\nof the number and nature of the novel sources the DM learns about. This has\nimplications for labor market discrimination, media bias, and project finance\nand oversight.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.08740v3"
    },
    {
        "title": "Substitutability in Favor Exchange",
        "authors": [
            "Oguzhan Celebi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I introduce a favor exchange model where favors are substitutable and study\nbilateral enforcement of cooperation. Without substitutability, the value of a\nrelationship does not depend on the rest of the network, and in equilibrium\nthere is either no cooperation or universal cooperation. When favors are\nsubstitutable, each additional relationship is less valuable than the previous,\nand intermediate levels of cooperation are observed. I extend the model to\nallow for transfers, heterogeneous players, and multilateral enforcement. My\nresults can explain the stratification of social networks in post-Soviet states\nand the adoption of different enforcement mechanisms by different groups of\nmedieval traders.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10749v1"
    },
    {
        "title": "Common Agency with Non-Delegation or Imperfect Commitment",
        "authors": [
            "Seungjin Han",
            "Siyang Xiong"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In classical contract theory, we usually impose two assumptions: delegated\ncontracts and perfect commitment. While the second assumption is demanding, the\nfirst one suffers no loss of generality. Following this tradition, current\ncommon-agency models impose delegated contracts and perfect commitment. We\nfirst show that non-delegated contracts expand the set of equilibrium outcomes\nunder common agency. Furthermore, the powerful menu theorem for common agency\n(Peters (2001) and Martimort and Stole (2002)}) fails for either non-delegated\ncontracts or imperfect commitment. We identify canonical contracts in such\nenvironments, and re-establish generalized menu theorems. Given imperfect\ncommitment, our results for common-agency models are analogous to those in\nBester and Strausz (2001) and Doval and Skreta (2012) for the classical\ncontract theory, which re-establish the revelation principle.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.11595v1"
    },
    {
        "title": "Buyer-Optimal Algorithmic Consumption",
        "authors": [
            "Shota Ichihashi",
            "Alex Smolin"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  An algorithm recommends a product to a buyer based on the product's value to\nthe buyer and its price. We characterize an algorithm that maximizes the\nbuyer's expected payoff and show that it strategically biases recommendations\nto incentivize lower prices. Under optimal algorithmic consumption, informing a\nseller about the buyer's value does not affect the buyer's expected payoff but\nleads to a more equitable distribution of payoffs across different values.\nThese results extend to Pareto-optimal algorithms and multiseller markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.12122v3"
    },
    {
        "title": "Linearity of Aggregate Production Functions",
        "authors": [
            "Christopher P. Chambers",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We prove that when individual firms employ constant-returns-to-scale\nproduction functions, the aggregate production function defined by the maximum\nachievable total output given total inputs is always linear on some part of the\ndomain. Our result provides a microfoundation for the linear production\nfunction.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.15760v1"
    },
    {
        "title": "Adaptive Priority Mechanisms",
        "authors": [
            "Oguzhan Celebi",
            "Joel Flynn"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  How should authorities that care about match quality and diversity allocate\nresources when they are uncertain about the market? We introduce adaptive\npriority mechanisms (APM) that prioritize agents based on both their scores and\ncharacteristics. We derive an APM that is optimal and show that the ubiquitous\npriority and quota mechanisms are optimal if and only if the authority is\nrisk-neutral or extremely risk-averse over diversity, respectively. With many\nauthorities, each authority using the optimal APM is dominant and implements\nthe unique stable matching. Using Chicago Public Schools data, we find that the\ngains from adopting APM may be considerable.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.15997v1"
    },
    {
        "title": "Separately Convex and Separately Continuous Preferences: On Results of\n  Schmeidler, Shafer, and Bergstrom-Parks-Rader",
        "authors": [
            "Metin Uyanik",
            "Aniruddha Ghosh",
            "M. Ali Khan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We provide necessary and sufficient conditions for a correspondence taking\nvalues in a finite-dimensional Euclidean space to be open so as to revisit the\npioneering work of Schmeidler (1969), Shafer (1974), Shafer-Sonnenschein (1975)\nand Bergstrom-Rader-Parks (1976) to answer several questions they and their\nfollowers left open. We introduce the notion of separate convexity for a\ncorrespondence and use it to relate to classical notions of continuity while\ngiving salience to the notion of separateness as in the interplay of separate\ncontinuity and separate convexity of binary relations. As such, we provide a\nconsolidation of the convexity-continuity postulates from a broad\ninter-disciplinary perspective and comment on how the qualified notions\nproposed here have implications of substantive interest for choice theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.00531v1"
    },
    {
        "title": "A new proof for the existence of Nash equilibrium",
        "authors": [
            "Davide Carpentiere",
            "Stephen Watson"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We present a new proof for the existence of a Nash equilibrium, which\ninvolves no fixed point theorem. The self-contained proof consists of two\nparts. The first part introduces the notions of root function and\npre-equilibrium. The second part shows the existence of pre-equilibria and Nash\nequilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.01528v1"
    },
    {
        "title": "Affirmative Action in India: Restricted Strategy Space, Complex\n  Constraints, and Direct Mechanism Design",
        "authors": [
            "Orhan Aygün",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Since 1950, India has instituted an intricate affirmative action program\nthrough a meticulously designed reservation system. This system incorporates\nvertical and horizontal reservations to address historically marginalized\ngroups' socioeconomic imbalances. Vertical reservations designate specific\nquotas of available positions in publicly funded educational institutions and\ngovernment employment for Scheduled Castes, Scheduled Tribes, Other Backward\nClasses, and Economically Weaker Sections. Concurrently, horizontal\nreservations are employed within each vertical category to allocate positions\nfor additional subgroups, such as women and individuals with disabilities. In\neducational admissions, the legal framework recommended that unfilled positions\nreserved for the OBC category revert to unreserved status. Moreover, we\ndocument that individuals from vertically reserved categories have more\ncomplicated preferences over institution-vertical category position pairs, even\nthough authorities only elicit their preferences over institutions. To address\nthese challenges, the present paper proposes a novel class of choice rules,\ntermed the Generalized Lexicographic (GL) choice rules. This class is\ncomprehensive, subsuming the most salient priority structures discussed in the\nextant matching literature. Utilizing the GL choice rules and the deferred\nacceptance mechanism, we present a robust framework that generates equitable\nand effective solutions for resource allocation problems in the Indian context.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.02660v1"
    },
    {
        "title": "A Formal Transaction Cost-Based Analysis of the Economic Feasibility of\n  Ecosystems",
        "authors": [
            "Christoph F. Strnadl"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Ecosystems enjoy increasing attention due to their flexibility and innovative\npower. It is well known, however, that this type of network-based economic\ngovernance structures occupies a potentially unstable position between the two\nstable (governance) endpoints, namely the firm (i.e., hierarchical governance)\nand the (open) market (i.e., coordination through the monetary system).\n  This paper develops a formal (mathematical) theory of the economic value of\n(generic) ecosystem by extending transaction costs economics using certain\nelements from service-dominant logic.\n  Within a first-best setting of rational actors, we derive analytical\nsolutions for the hub-and-spoke and generic ecosystem configurations under some\nuniformity assumptions of ecosystem participants. Additionally, we are able to\ninfer a generic condition for the welfare-maximizing and utility-maximizing\nprice of the hub-and-spoke configuration in the familiar form of Lerner indices\nand elasticities.\n  Relinquishing a first-best rational actors approach, we additionally derive\nseveral general propositions on (i) necessary conditions for the economic\nfeasibility of ecosystem-based transactions, (ii) scaling requirements for\necosystem stability, and (iii) a generic feasibility condition for arbitrary\nprovider-consumer ecosystems.\n  Finally, we present an algebraic definition of business ecosystems and relate\nit to existing informal definition attempts. Thereby we demonstrate that the\nproperty of \"being an ecosystem\" of a network of transacting actors cannot be\ndecided on structural grounds alone.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.03157v3"
    },
    {
        "title": "General Equilibrium Theory for Climate Change",
        "authors": [
            "Robert M. Anderson",
            "Haosui Duanmu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We propose two general equilibrium models, quota equilibrium and emission tax\nequilibrium. The government specifies quotas or taxes on emissions, then\nrefrains from further action. Quota equilibrium exists; the allocation of\nemission property rights strongly impacts the distribution of welfare. If the\nonly externality arises from total net emissions, quota equilibrium is\nconstrained Pareto Optimal. Every quota equilibrium can be realized as an\nemission tax equilibrium and vice versa. However, for certain tax rates,\nemission tax equilibrium may not exist, or may exhibit high multiplicity. Full\nPareto Optimality of quota equilibrium can often be achieved by setting the\nright quota.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.03650v1"
    },
    {
        "title": "Is Arrow's Dictator a Drinker?",
        "authors": [
            "Jeffrey Uhlmann"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We critique the formulation of Arrow's no-dictator condition to show that it\ndoes not correspond to the accepted informal/intuitive interpretation. This has\nimplications for the theorem's scope of applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04917v1"
    },
    {
        "title": "Equivalence between individual and group strategy-proofness under\n  stability",
        "authors": [
            "Pinaki Mandal"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies the (group) strategy-proofness aspect of two-sided\nmatching markets under stability. For a one-to-one matching market, we show an\nequivalence between individual and group strategy-proofness under stability. We\nobtain this equivalence assuming the domain satisfies a richness condition.\nHowever, the result cannot be extended to the many-to-one matching markets. We\nfurther consider a setting with single-peaked preferences and characterize all\ndomains compatible for stability and (group) strategy-proofness.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.05252v1"
    },
    {
        "title": "The spatial evolution of economic activities and the emergence of cities",
        "authors": [
            "Davide Fiaschi",
            "Cristiano Ricci"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies the spatial agglomeration of workers and income in a\ncontinuous space and time framework. Production and consumption are decided in\nlocal markets, characterized by the presence of spatial spillovers and\namenities. Workers move across locations maximizing their instantaneous\nutility, subject to mobility costs. We prove the existence of a short-run\nCournot-Nash equilibrium, and that, in the limit of an infinite number of\nworkers, the sequence of short-run equilibria can be expressed by a partial\ndifferential equation. We characterize the conditions under which the long-run\nequilibrium displays spatial agglomerations. Social welfare is non-decreasing\nover time, and in the long-run equilibrium the expected utility of a\nrepresentative worker is equalized over space and, therefore, the spatial\nallocation is efficient. The model can reproduce several stylized effects, such\nas the emergence of spatial agglomerations (cities) with different sizes and\nshapes; the dependence by history of spatial pattern of economic activities; a\nnon-linear out-of-equilibrium dynamics; and finally, the phenomenon of\nmetastability, where a long period of apparent stability in the spatial\ndistribution is followed by a sharp transition to a new equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.07883v1"
    },
    {
        "title": "Credibility in Credence Goods Markets",
        "authors": [
            "Xiaoxiao Hu",
            "Haoran Lei"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  An expert seller chooses an experiment to influence a client's purchasing\ndecision, but may manipulate the experiment result for personal gain. When\ncredibility surpasses a critical threshold, the expert chooses a\nfully-revealing experiment and, if possible, manipulates the unfavorable\nresult. In this case, a higher credibility strictly benefits the expert,\nwhereas the client never benefits from the expert's services. We also discuss\npolicies regarding monitoring expert's disclosure and price regulation. When\nprices are imposed exogenously, monitoring disclosure does not affect the\nclient's highest equilibrium value. A lower price may harm the client when it\ndiscourages the expert from disclosing information.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09544v1"
    },
    {
        "title": "Coherent Distorted Beliefs",
        "authors": [
            "Christopher P. Chambers",
            "Yusufcan Masatlioglu",
            "Collin Raymond"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Many models of economics assume that individuals distort objective\nprobabilities. We propose a simple consistency condition on distortion\nfunctions, which we term distortion coherence, that ensures that the function\ncommutes with conditioning on an event. We show that distortion coherence\nrestricts belief distortions to have a particular function form: power-weighted\ndistortions, where distorted beliefs are proportional to the original beliefs\nraised to a power and weighted by a state-specific value. We generalize our\nfindings to allow for distortions of the probabilities assigned to both states\nand signals, which nests the functional forms widely used in studying\nprobabilistic biases (e.g., Grether, 1980 and Benjamin, 2019). We show how\ncoherent distorted beliefs are tightly related to several extant models of\nmotivated beliefs: they are the outcome of maximizing anticipated expected\nutility subject to a generalized Kullback-Liebler cost of distortion. Moreover,\nin the domain of lottery choice, we link coherent distortions to explanations\nof non-expected utility like the Allais paradox: individuals who maximize\nsubjective expected utility maximizers conditional on coherent distorted\nbeliefs are equivalent to the weighted utility maximizers studied by Chew\n[1983].\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09879v2"
    },
    {
        "title": "Tractable Aggregation in Endogenous Network Formation Models",
        "authors": [
            "Jose M. Betancourt"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies the long-run properties of a stochastic best-response\nnetwork formation model. Players stochastically meet and make decisions about\nchanging the state of their relationship. I give sufficient conditions under\nwhich this game induces a reversible Markov process in the space of networks,\nand show that in this case the stationary distribution is given by a Gibbs\nmeasure with an associated aggregating function that depends on players'\nutilities. Reversibility also implies the existence of a potential for a\ndeterministic version of the network formation game. Using the properties of\nthe Gibbs measure I show that, in simple settings, the long-run behavior of the\nmodel for increasingly large networks is driven by a trade-off between player\nincentives and the exponentially increasing number of feasible networks. I use\nthis framework to obtain network statistics for simple models of social media\nfollowing and international trade.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.10764v2"
    },
    {
        "title": "Revenue sharing at music streaming platforms",
        "authors": [
            "Gustavo Bergantiños",
            "Juan D. Moreno-Ternero"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the problem of sharing the revenues raised from subscriptions to\nmusic streaming platforms among content providers. We provide direct, axiomatic\nand game-theoretical foundations for two focal (and somewhat polar) methods\nwidely used in practice: pro-rata and user-centric. The former rewards artists\nproportionally to their number of total streams. With the latter, each user's\nsubscription fee is proportionally divided among the artists streamed by that\nuser. We also provide foundations for a family of methods compromising among\nthe previous two, which addresses the rising concern in the music industry to\nexplore new streaming models that better align the interests of artists, fans\nand streaming services.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.11861v1"
    },
    {
        "title": "A note on the logical inconsistency of the Hotelling Rule: A Revisit\n  from the System's Analysis Perspective",
        "authors": [
            "Nikolay Khabarov",
            "Alexey Smirnov",
            "Michael Obersteiner"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The \"Hotelling rule\" (HR) called to be \"the fundamental principle of the\neconomics of exhaustible resources\" has a logical deficiency which was never\npaid a sufficient attention to. This deficiency should be taken into account\nbefore attempting to explain discrepancies between the price prediction\nprovided by the HR and historically observed prices. Our analysis is focused on\nthe HR in its original form, we do not touch upon other aspects such as varying\nextraction costs and other ways of upgrading the original model underlying the\nHotelling rule. We conclude that HR can not be derived from the simple models\nas it was claimed, therefore it should be understood as an assumption on its\nown, and not as a rule derived from other more basic assumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.12807v1"
    },
    {
        "title": "Majority rule as a unique voting method in elections with multiple\n  candidates",
        "authors": [
            "Mateusz Krukowski"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  May's classical theorem states that in a single-winner choose-one voting\nsystem with just two candidates, majority rule is the only social choice\nfunction satisfying anonimity, neutrality and positive responsiveness axiom.\nAnonimity and neutrality are usually regarded as very natural constraints on\nthe social choice function. Positive responsiveness, on the other hand, is\nsometimes deemed too strong of an axiom, which stimulates further search for\nless stringent conditions. One viable substitute is Gerhard J. Woeginger's\n\"reducibility to subsocieties\". We demonstrate that the condition generalizes\nto more than two candidates and, consequently, characterizes majority rule for\nelections with multiple candidates.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.12983v1"
    },
    {
        "title": "Monotonicity Failure in Ranked Choice Voting -- Necessary and Sufficient\n  Conditions for 3-Candidate Elections",
        "authors": [
            "Rylie Weaver"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Ranked choice voting is vulnerable to monotonicity failure - a voting failure\nwhere a candidate is cost an election due to losing voter preference or granted\nan election due to gaining voter preference. Despite increasing use of ranked\nchoice voting at the time of writing of this paper, the frequency of\nmonotonicity failure is still a very open question. This paper builds on\nprevious work to develop conditions which can be used to test if it's possible\nthat monotonicity failure has happened in a 3-candidate ranked choice voting\nelection.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.12988v1"
    },
    {
        "title": "Persuasion in Veto Bargaining",
        "authors": [
            "Jenny S Kim",
            "Kyungmin Kim",
            "Richard Van Weelden"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider the classic veto bargaining model but allow the agenda setter to\nengage in persuasion to convince the veto player to approve her proposal. We\nfully characterize the optimal proposal and experiment when Vetoer has\nquadratic loss, and show that the proposer-optimal can be achieved either by\nproviding no information or with a simple binary experiment. Proposer chooses\nto reveal partial information when there is sufficient expected misalignment\nwith Vetoer. In this case the opportunity to engage in persuasion strictly\nbenefits Proposer and increases the scope to exercise agenda power.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.13148v1"
    },
    {
        "title": "Non-linear approximations of DSGE models with neural-networks and\n  hard-constraints",
        "authors": [
            "Emmet Hall-Hoffarth"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Recently a number of papers have suggested using neural-networks in order to\napproximate policy functions in DSGE models, while avoiding the curse of\ndimensionality, which for example arises when solving many HANK models, and\nwhile preserving non-linearity. One important step of this method is to\nrepresent the constraints of the economic model in question in the outputs of\nthe neural-network. I propose, and demonstrate the advantages of, a novel\napproach to handling these constraints which involves directly constraining the\nneural-network outputs, such that the economic constraints are satisfied by\nconstruction. This is achieved by a combination of re-scaling operations that\nare differentiable and therefore compatible with the standard gradient descent\napproach used when fitting neural-networks. This has a number of attractive\nproperties, and is shown to out-perform the penalty-based approach suggested by\nthe existing literature, which while theoretically sound, can be poorly behaved\npractice for a number of reasons that I identify.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.13436v1"
    },
    {
        "title": "Diversity Preferences, Affirmative Action and Choice Rules",
        "authors": [
            "Oguzhan Celebi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I study the relationship between diversity preferences and the choice rules\nimplemented by institutions, with a particular focus on the affirmative action\npolicies. I characterize the choice rules that can be rationalized by diversity\npreferences and demonstrate that the recently rescinded affirmative action\nmechanism used to allocate government positions in India cannot be\nrationalized. I show that if institutions evaluate diversity without\nconsidering intersectionality of identities, their choices cannot satisfy the\ncrucial substitutes condition. I characterize choice rules that satisfy the\nsubstitutes condition and are rationalizable by preferences that are separable\nin diversity and match quality domains.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.14442v1"
    },
    {
        "title": "Social Learning of General Rules",
        "authors": [
            "Enrique Urbano Arellano",
            "Xinyang Wang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Why do agents adopt a particular general behavioral rule among a collection\nof possible alternatives? To address this question, we introduce a dynamic\nsocial learning framework, where agents rely on general rules of thumb and\nimitate the behavioral rules of successful peers. We find the social learning\noutcome can be characterized independent of the initial rule distribution. When\none dominant general rule consistently yields superior problem-specific\noutcomes, social learning almost surely leads all agents to adopt this dominant\nrule; otherwise, provided the population is sufficiently large, the better rule\nfor the more frequent problem becomes the consensus rule with arbitrarily high\nprobability. As a result, the behavioral rule selected by the social learning\nprocess need not maximize social welfare. We complement our theoretical\nanalysis with an application to the market sentiment selection in a stochastic\nproduction market.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.15861v1"
    },
    {
        "title": "A Note on the Continuity of Expected Utility Functions",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we study the continuity of expected utility functions, and\nderive a necessary and sufficient condition for a weak order on the space of\nsimple probabilities to have a continuous expected utility function. We also\nverify that almost the same condition is necessary and sufficient for a weak\norder on the space of probabilities with compact-support to have a continuous\nexpected utility function.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.16806v2"
    },
    {
        "title": "Safety, in Numbers",
        "authors": [
            "Marilyn Pease",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We introduce a way to compare actions in decision problems. An action is\nsafer than another if the set of beliefs at which the decision-maker prefers\nthe safer action increases in size (in the set inclusion sense) as the\ndecision-maker becomes more risk averse. We provide a full characterization of\nthis relation and show that it is equivalent to a robust concept of\nsingle-crossing. We discuss applications to investment hedging, security\ndesign, and game theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17517v2"
    },
    {
        "title": "Multilateral matching with scale economies",
        "authors": [
            "Chao Huang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies multilateral matching in which any set of agents can\nnegotiate contracts. We assume scale economies in the sense that an agent\nsubstitutes some contracts with some new contracts only if the newly signed\ncontracts involve a weakly larger set of partners. We show that a weakly\nsetwise stable outcome exists in a market with scale economies and a setwise\nstable outcome exists under a stronger scale economies condition. Our\nconditions apply to environments in which more partners bring advantages, and\nallow agents to bargain over contracts signed by them.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.19479v1"
    },
    {
        "title": "From Doubt to Devotion: Trials and Learning-Based Pricing",
        "authors": [
            "Tan Gan",
            "Nicholas Wu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  An informed seller designs a dynamic mechanism to sell an experience good.\nThe seller has partial information about the product match, which affects the\nbuyer's private consumption experience. We characterize equilibrium mechanisms\nof this dynamic informed principal problem. The belief gap between the informed\nseller and the uninformed buyer, coupled with the buyer's learning, gives rise\nto mechanisms that provide the skeptical buyer with limited access to the\nproduct and an option to upgrade if the buyer is swayed by a good experience.\nDepending on the seller's screening technology, this takes the form of\nfree/discounted trials or tiered pricing, which are prevalent in digital\nmarkets. In contrast to static environments, having consumer data can reduce\nsellers' revenue in equilibrium, as they fine-tune the dynamic design with\ntheir data forecasting the buyer's learning process.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.00846v1"
    },
    {
        "title": "Persuasion and Matching: Optimal Productive Transport",
        "authors": [
            "Anton Kolotilin",
            "Roberto Corrao",
            "Alexander Wolitzky"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider general Bayesian persuasion problems where the receiver's utility\nis single-peaked in a one-dimensional action. We show that a signal that pools\nat most two states in each realization is always optimal, and that such\npairwise signals are the only solutions under a non-singularity condition (the\ntwist condition). Our core results provide conditions under which riskier\nprospects induce higher or lower actions, so that the induced action is\nsingle-dipped or single-peaked on each set of nested prospects. We also provide\nconditions for the optimality of either full disclosure or negative assortative\ndisclosure, where all prospects are nested. Methodologically, our results rely\non novel duality and complementary slackness theorems. Our analysis extends to\na general problem of assigning one-dimensional inputs to productive units,\nwhich we call optimal productive transport. This problem covers additional\napplications including club economies (assigning workers to firms, or students\nto schools), robust option pricing (assigning future asset prices to price\ndistributions), and partisan gerrymandering (assigning voters to districts).\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02889v1"
    },
    {
        "title": "Stable partitions for proportional generalized claims problems",
        "authors": [
            "Oihane Gallo",
            "Bettina Klaus"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider a set of agents who have claims on an endowment that is not large\nenough to cover all claims. Agents can form coalitions but a minimal coalition\nsize $\\theta$ is required to have positive coalitional funding that is\nproportional to the sum of the claims of its members. We analyze the structure\nof stable partitions when coalition members use well-behaved rules to allocate\ncoalitional endowments, e.g., the well-known constrained equal awards rule\n(CEA) or the constrained equal losses rule (CEL).For continuous, (strictly)\nresource monotonic, and consistent rules, stable partitions with (mostly)\n$\\theta$-size coalitions emerge. For CEA and CEL we provide algorithms to\nconstruct such a stable partition formed by $\\theta$-size coalitions.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03950v2"
    },
    {
        "title": "Collective Sampling: An Ex Ante Perspective",
        "authors": [
            "Yangfan Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I study collective dynamic information acquisition. Players decide when to\nstop sequential sampling via a collective stopping rule, which specifies\ndecisive coalitions that can terminate information acquisition upon agreement.\nI develop a methodology to characterize equilibria using an ex ante\nperspective. Instead of stopping strategies, players choose distributions over\nposterior beliefs subject to majorization constraints. Equilibrium sampling\nregions are characterized via a fixed-point argument based on concavification.\nCollective sampling generates learning inefficiencies and having more decisive\ncoalitions typically reduces learning. I apply the model to committee search\nand competition in persuasion.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.05758v3"
    },
    {
        "title": "Patience ensures fairness",
        "authors": [
            "Florian Brandl",
            "Andrew Mackenzie"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We revisit the problem of fairly allocating a sequence of time slots when\nagents may have different levels of patience (Mackenzie and Komornik, 2023).\nFor each number of agents, we provide a lower threshold and an upper threshold\non the level of patience such that (i) if each agent is at least as patient as\nthe lower threshold, then there is a proportional allocation, and (ii) if each\nagent is at least as patient as the upper threshold and moreover has weak\npreference for earlier time slots, then there is an envy-free allocation. In\nboth cases, the proof is constructive.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06092v2"
    },
    {
        "title": "A non-invariance result for the spatial AK model",
        "authors": [
            "Cristiano Ricci"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper deals with the positivity condition of an infinite-dimensional\nevolutionary equation, associated with a control problem for the optimal\nconsumption over space. We consider a spatial growth model for capital, with\nproduction generating endogenous growth and technology of the form AK. We show\nthat for certain initial data, even in the case of heterogeneous spatial\ndistribution of technology and population, the solution to an auxiliary control\nproblem that is commonly used as a candidate for the original problem is not\nadmissible. In particular, we show that initial conditions that are\nnon-negative, under the auxiliary optimal consumption strategy, may lead to\nnegative capital allocations over time.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06811v1"
    },
    {
        "title": "From Authority-Respect to Grassroots-Dissent: Degree-Weighted Social\n  Learning and Convergence Speed",
        "authors": [
            "Chen Cheng",
            "Xiao Han",
            "Xin Tong",
            "Yusheng Wu",
            "Yiqing Xing"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Opinions are influenced by neighbors, with varying degrees of emphasis based\non their connections. Some may value more connected neighbors' views due to\nauthority respect, while others might lean towards grassroots perspectives. The\nemergence of ChatGPT could signify a new ``opinion leader'' whose views people\nput a lot of weight on. This study introduces a degree-weighted DeGroot\nlearning model to examine the effects of such belief updates on learning\noutcomes, especially the speed of belief convergence. We find that greater\nrespect for authority doesn't guarantee faster convergence. The influence of\nauthority respect is non-monotonic. The convergence speed, influenced by\nincreased authority-respect or grassroots dissent, hinges on the unity of elite\nand grassroots factions. This research sheds light on the growing skepticism\ntowards public figures and the ensuing dissonance in public debate.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.07010v1"
    },
    {
        "title": "Decision-making under risk: when is utility maximization equivalent to\n  risk minimization?",
        "authors": [
            "Francesco Ruscitti",
            "Ram Sewak Dubey",
            "Giorgio Laguzzi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Motivated by the analysis of a general optimal portfolio selection problem,\nwhich encompasses as special cases an optimal consumption and an optimal\ndebt-arrangement problem, we are concerned with the questions of how a\npersonality trait like risk-perception can be formalized and whether the two\nobjectives of utility-maximization and risk-minimization can be both achieved\nsimultaneously. We address these questions by developing an axiomatic\nfoundation of preferences for which utility-maximization is equivalent to\nminimizing a utility-based shortfall risk measure. Our axiomatization hinges on\na novel axiom in decision theory, namely the risk-perception axiom.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.07269v1"
    },
    {
        "title": "Considering Risk Aversion in Economic Evaluation: A Rank Dependent\n  Approach",
        "authors": [
            "Jacob Smith"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper presents a method for incorporating risk aversion into existing\ndecision tree models used in economic evaluations. The method involves applying\na probability weighting function based on rank dependent utility theory to\nreduced lotteries in the decision tree model. This adaptation embodies the fact\nthat different decision makers can observe the same decision tree model\nstructure but come to different conclusions about the optimal treatment. The\nproposed solution to this problem is to compensate risk-averse decision makers\nto use the efficient technology that they are reluctant to adopt.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.07905v2"
    },
    {
        "title": "Incompleteness, Independence, and Negative Dominance",
        "authors": [
            "Harvey Lederman"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper introduces the axiom of Negative Dominance, stating that if a\nlottery $f$ is strictly preferred to a lottery $g$, then some outcome in the\nsupport of $f$ is strictly preferred to some outcome in the support of $g$. It\nis shown that if preferences are incomplete on a sufficiently rich domain, then\nthis plausible axiom, which holds for complete preferences, is incompatible\nwith an array of otherwise plausible axioms for choice under uncertainty. In\nparticular, in this setting, Negative Dominance conflicts with the standard\nIndependence axiom. A novel theory, which includes Negative Dominance, and\nrejects Independence, is developed and shown to be consistent.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.08471v1"
    },
    {
        "title": "Structural Advantages for Integrated Builders in MEV-Boost",
        "authors": [
            "Mallesh Pai",
            "Max Resnick"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Currently, over 90% of Ethereum blocks are built using MEV-Boost, an auction\nthat allows validators to sell their block-building power to builders who\ncompete in an open English auction in each slot. Shortly after the merge, when\nMEV-Boost was in its infancy, most block builders were neutral, meaning they\ndid not trade themselves but rather aggregated transactions from other traders.\nOver time, integrated builders, operated by trading firms, began to overtake\nmany of the neutral builders. Outside of the integrated builder teams, little\nis known about which advantages integration confers beyond latency and how\nlatency advantages distort on-chain trading.\n  This paper explores these poorly understood advantages. We make two\ncontributions. First, we point out that integrated builders are able to bid\ntruthfully in their own bundle merge and then decide how much profit to take\nlater in the final stages of the PBS auction when more information is\navailable, making the auction for them look closer to a second-price auction\nwhile independent searchers are stuck in a first-price auction. Second, we find\nthat latency disadvantages convey a winner's curse on slow bidders when\nunderlying values depend on a stochastic price process that change as bids are\nsubmitted.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09083v1"
    },
    {
        "title": "Posterior-Mean Separable Costs of Information Acquisition",
        "authors": [
            "Jeffrey Mensch",
            "Komal Malik"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyze a problem of revealed preference given state-dependent stochastic\nchoice data in which the payoff to a decision maker (DM) only depends on their\nbeliefs about posterior means. Often, the DM must also learn about or pay\nattention to the state; in applied work on this subject, a convenient\nassumption is that the costs of such learning are linearly dependent in the\ndistribution over posterior means. We provide testable conditions to identify\nwhether this assumption holds. This allows for the use of information design\ntechniques to solve the DM's problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09496v4"
    },
    {
        "title": "Modeling trading games in a stochastic non-life insurance market",
        "authors": [
            "Leonard Mushunje",
            "David Edmund Allen"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We studied the behavior and variation of utility between the two conflicting\nplayers in a closed Nash-equilibrium loop. Our modeling approach also captured\nthe nexus between optimal premium strategizing and firm performance using the\nLotka-Volterra completion model. Our model robustly modeled the two main cases,\ninsurer-insurer and insurer-policyholder, which we accompanied by numerical\nexamples of premium movements and their relationship to the market equilibrium\npoint. We found that insurers with high claim exposures tend to set high\npremiums. The other competitors either set a competitive premium or adopt the\nfixed premium charge to remain in the game; otherwise, they will operate below\nthe optimal point. We also noted an inverse link between trading premiums and\nclaims in general insurance games due to self-interest and utility\nindifferences. We concluded that while an insurer aims to charge high premiums\nto enjoy more, policyholders are willing to avoid these charges by paying less.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.10917v1"
    },
    {
        "title": "Benefiting from Bias: Delegating to Encourage Information Acquisition",
        "authors": [
            "Ian Ball",
            "Xin Gao"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A principal delegates decisions to a biased agent. Payoffs depend on a state\nthat the principal cannot observe. Initially, the agent does not observe the\nstate, but he can acquire information about it at a cost. We characterize the\nprincipal's optimal delegation set. This set features a cap on high decisions\nand a gap around the agent's ex ante favorite decision. It may even induce\nex-post Pareto-dominated decisions. Under certain conditions on the cost of\ninformation acquisition, we show that the principal prefers delegating to an\nagent with a small bias than to an unbiased agent.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.11526v1"
    },
    {
        "title": "Uniformly Strict Equilibrium for Repeated Games with Private Monitoring\n  and Communication",
        "authors": [
            "Richard McLean",
            "Ichiro Obara",
            "Andrew Postlewaite"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Cooperation through repetition is an important theme in game theory. In this\nregard, various celebrated ``folk theorems'' have been proposed for repeated\ngames in increasingly more complex environments. There has, however, been\ninsufficient attention paid to the robustness of a large set of equilibria that\nis needed for such folk theorems. Starting with perfect public equilibrium as\nour starting point, we study uniformly strict equilibria in repeated games with\nprivate monitoring and direct communication (cheap talk). We characterize the\nlimit equilibrium payoff set and identify the conditions for the folk theorem\nto hold with uniformly strict equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12242v2"
    },
    {
        "title": "Successive Incentives",
        "authors": [
            "Jens Gudmundsson",
            "Jens Leth Hougaard",
            "Juan D. Moreno-Ternero",
            "Lars Peter Østerdal"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the design of optimal incentives in sequential processes. To do so,\nwe consider a basic and fundamental model in which an agent initiates a\nvalue-creating sequential process through costly investment with random\nsuccess. If unsuccessful, the process stops. If successful, a new agent\nthereafter faces a similar investment decision, and so forth. For any outcome\nof the process, the total value is distributed among the agents using a reward\nrule. Reward rules thus induce a game among the agents. By design, the reward\nrule may lead to an asymmetric game, yet we are able to show equilibrium\nexistence with optimal symmetric equilibria. We characterize optimal reward\nrules that yield the highest possible welfare created by the process, and the\nhighest possible expected payoff for the initiator of the process. Our findings\nshow that simple reward rules invoking short-run incentives are sufficient to\nmeet long-run objectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12494v1"
    },
    {
        "title": "Underreaction and dynamic inconsistency in communication games under\n  noise",
        "authors": [
            "Gerrit Bauch"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Communication is rarely perfect, but rather prone to error of transmission\nand reception. Often the origin of these errors cannot be properly quantified\nand is thus imprecisely known. We analyze the impact of an ambiguous noise\nwhich may alter the received message on a communication game of common\ninterest. The noise is ambiguous in the sense that the parameters of the\nerror-generating process and thus the likelihood to receive a message by\nmistake are Knightianly unknown. Ex-ante and interim responses are\ncharacterized under maxmin preferences. While the sender can disregard\nambiguity, the receiver reveals a dynamically inconsistent, but astonishing\nbehavior under a quadratic loss. Their interim actions will be closer to the\npooling action than their ex-ante ones, as if facing a higher likelihood of an\noccurring error.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12496v1"
    },
    {
        "title": "Belief identification by proxy",
        "authors": [
            "Elias Tsakas"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  It is well known that individual beliefs cannot be identified using\ntraditional choice data, unless we exogenously assume state-independent\nutilities. In this paper, I propose a novel methodology that solves this\nlong-standing identification problem in a simple way. This method relies on the\nextending the state space by introducing a proxy, for which the agent has no\nstakes conditional on the original state space. The latter allows us to\nidentify the agent's conditional beliefs about the proxy given each state\nrealization, which in turn suffices for indirectly identifying her beliefs\nabout the original state space. This approach is analogous to the one of\ninstrumental variables in econometrics. Similarly to instrumental variables,\nthe appeal of this method comes from the flexibility in selecting a proxy.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.13394v1"
    },
    {
        "title": "Organizational economic sustainability via process optimization and\n  human capital: a Soft Systems Methodology (SSM) approach",
        "authors": [
            "Wadim Strielkowski",
            "Evgeny Kuzmin",
            "Arina Suvorova",
            "Natalya Nikitina",
            "Olga Gorlova"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This review paper focuses on enhancing organizational economic sustainability\nthrough process optimization and human capital effective management utilizing\nthe soft systems methodology (SSM) approach which offers a holistic approach\nfor understanding complex real-world challenges. By emphasizing systems\nthinking and engaging diverse stakeholders in problem-solving, SSM provides a\ncomprehensive understanding of the problem's context and potential solutions.\nThe approach guides a systematic process of inquiry that leads to feasible and\ndesirable changes in tackling complex problems effectively. Our paper employs\nthe bibliometric analysis based on the sample of 5171 research articles,\nproceedings papers, and book chapters indexed in Web of Science (WoS) database.\nWe carry out the network cluster analysis using the text data and the\nbibliometric data with the help of VOSViewer software. Our results confirm that\nas the real-world situations are becoming more complex and the new challenges\nsuch as the global warming and climate change are threatening many economic and\nsocial processes, SSM approach is currently getting back at the forefront of\nacademic research related to such topics as organizational management and\nsustainable human capital efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17882v2"
    },
    {
        "title": "Baumol's Climate Disease",
        "authors": [
            "Fangzhi Wang",
            "Hua Liao",
            "Richard S. J. Tol"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We investigate optimal carbon abatement in a dynamic general equilibrium\nclimate-economy model with endogenous structural change. By differentiating the\nproduction of investment from consumption, we show that social cost of carbon\ncan be conceived as a reduction in physical capital. In addition, we\ndistinguish two final sectors in terms of productivity growth and climate\nvulnerability. We theoretically show that heterogeneous climate vulnerability\nresults in a climate-induced version of Baumol's cost disease. Further, if\nclimate-vulnerable sectors have high (low) productivity growth, climate impact\ncan either ameliorate (aggravate) the Baumol's cost disease, call for less\n(more) stringent climate policy. We conclude that carbon abatement should not\nonly factor in unpriced climate capital, but also be tailored to Baumol's cost\nand climate diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.00160v1"
    },
    {
        "title": "Homophily and Specialization in Networks",
        "authors": [
            "Patrick Allmis",
            "Luca Paolo Merlino"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, players contribute to two local public goods for which they\nhave different tastes and sponsor costly links to enjoy the provision of\nothers. In equilibrium, either there are several contributors specialized in\npublic good provision or only two contributors who are not entirely\nspecialized. Higher linking costs have a non-monotonic impact on welfare and\npolarization, as they affect who specializes in public good provision. When the\navailable budget is small, subsidies should be given to players who already\nspecialize in public good provision; otherwise, they should target only one\nplayer who specializes in public good provision.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.00457v1"
    },
    {
        "title": "Prior-Free Predictions for Persuasion",
        "authors": [
            "Eric Gao",
            "Daniel Luo"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyze prior-free predictions in the design of persuasion games: settings\nwhere Receiver contracts their action on Sender's choices of experiment and\nrealized signals about some state. To do so, we characterize robust mechanisms\n- those which induce the same allocation rules (mappings from the state to\nactions) regardless of prior beliefs. These mechanisms take a simple form: they\n(1) incentivize fully revealing experiments, (2) depend only on the induced\nposterior, and (3) maximally punish pooling deviations. We then highlight a\ntight connection between ordinal preference uncertainty and prior-dependent\npredictions - all such rules are implementable if and only if the sender has a\nstate-independent least favorite action. This, in turn, implies all (and only)\nordinally monotone allocation rules are robust in binary action problems. We\napply our model to school choice and uncover a novel informational\njustification for deferred acceptance when school preferences depend on\nstudents' unknown ability. Finally, we study good allocation settings with\nexternalities and state-dependent outside options and show all efficient\nallocation rules are robust, even with significant preference heterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.02465v9"
    },
    {
        "title": "Algorithmic collusion under competitive design",
        "authors": [
            "Ivan Conjeaud"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a simple model of algorithmic collusion in which Q-learning\nalgorithms are designed in a strategic fashion. We let players\n(\\textit{designers}) choose their exploration policy simultaneously prior to\nletting their algorithms repeatedly play a prisoner's dilemma. We prove that,\nin equilibrium, collusive behavior is reached with positive probability. Our\nnumerical simulations indicate symmetry of the equilibria and give insight for\nhow they are affected by a parameter of interest. We also investigate general\nprofiles of exploration policies. We characterize the behavior of the system\nfor extreme profiles (fully greedy and fully explorative) and use numerical\nsimulations and clustering methods to measure the likelihood of collusive\nbehavior in general cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.02644v3"
    },
    {
        "title": "Two is enough: a flip on Bertrand through positive network effects",
        "authors": [
            "Renato Soeiro",
            "Alberto Pinto"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We discuss price competition when positive network effects are the only other\nfactor in consumption choices. We show that partitioning consumers into two\ngroups creates a rich enough interaction structure to induce negative marginal\ndemand and produce pure price equilibria where both firms profit. The crucial\ncondition is one group has centripetal influence while the other has\ncentrifugal influence. The result is contrary to when positive network effects\ndepend on a single aggregate variable and challenges the prevalent assumption\nthat demand must be micro-founded on a distribution of consumer characteristics\nwith specific properties, highlighting the importance of interaction structures\nin shaping market outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.02865v1"
    },
    {
        "title": "Revealing Sequential Rationality and Forward Induction",
        "authors": [
            "Pierfrancesco Guarino"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Given a dynamic ordinal game, we deem a strategy sequentially rational if\nthere exist a Bernoulli utility function and a conditional probability system\nwith respect to which the strategy is a maximizer. We establish a complete\nclass theorem by characterizing sequential rationality via the new Conditional\nB-Dominance. Building on this notion, we introduce Iterative Conditional\nB-Dominance, which is an iterative elimination procedure that characterizes the\nimplications of forward induction in the class of games under scrutiny and\nselects the unique backward induction outcome in dynamic ordinal games with\nperfect information satisfying a genericity condition. Additionally, we show\nthat Iterative Conditional B-Dominance, as a `forward induction reasoning'\nsolution concept, captures: $(i)$ the unique backward induction outcome\nobtained via sophisticated voting in binary agendas with sequential majority\nvoting; $(ii)$ farsightedness in dynamic ordinal games derived from social\nenvironments; $(iii)$ a unique outcome in ordinal Money-Burning Games.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.03536v1"
    },
    {
        "title": "Decomposable Stochastic Choice",
        "authors": [
            "Fedor Sandomirskiy",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We investigate inherent stochasticity in individual choice behavior across\ndiverse decisions. Each decision is modeled as a menu of actions with outcomes,\nand a stochastic choice rule assigns probabilities to actions based on the\noutcome profile. Outcomes can be monetary values, lotteries, or elements of an\nabstract outcome space. We characterize decomposable rules: those that predict\nindependent choices across decisions not affecting each other. For monetary\noutcomes, such rules form the one-parametric family of multinomial logit rules.\nFor general outcomes, there exists a universal utility function on the set of\noutcomes, such that choice follows multinomial logit with respect to this\nutility. The conclusions are robust to replacing strict decomposability with an\napproximate version or allowing minor dependencies on the actions' labels.\nApplications include choice over time, under risk, and with ambiguity.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.04827v2"
    },
    {
        "title": "Public policy for management of forest pests within an ownership mosaic",
        "authors": [
            "Andrew R. Tilman",
            "Robert G. Haight"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Urban forests provide ecosystem services that are public goods with local\n(shade) to global (carbon sequestration) benefits and occur on both public and\nprivate lands. Thus, incentives for private tree owners to invest in tree care\nmay fall short of those of a public forest manager aiming to optimize ecosystem\nservice benefits for society. The management of a forest pest provides a\nsalient focus area because pests threaten public goods provision and pest\nmanagement generates feedback that mitigates future risks to forests. We use a\ngame theoretic model to determine optimal pest treatment subsidies for a focal\nprivately owned tree and use an optimization approach to guide targeted public\ntreatment of a representative public tree. We find that optimal public\nsubsidies for private tree treatment depend on assessed tree health and on the\nprevalence of the pest in the community, considerations absent from many\nexisting programs. Next, by applying our pest treatment policies to a\ncommunity-scale model of emerald ash borer forest pest dynamics, we predict ash\nmortality under a range of treatment scenarios over a 50-year time horizon. Our\nresults highlight how designing policies that consider the public goods\nbenefits of private actions can contribute to sustainable land management.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.05403v2"
    },
    {
        "title": "Artificial Intelligence in the Knowledge Economy",
        "authors": [
            "Enrique Ide",
            "Eduard Talamas"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The rise of Artificial Intelligence (AI) has the potential to reshape the\nknowledge economy by enabling problem solving at scale. This paper introduces a\nframework to analyze this transformation, incorporating AI into an economy\nwhere humans form hierarchical firms to use their time efficiently: Less\nknowledgeable individuals become \"workers\" solving routine problems, while more\nknowledgeable individuals become \"solvers\" assisting workers with exceptional\nproblems. We model AI as a technology that transforms computing power into \"AI\nagents,\" which can either operate autonomously (as co-workers or\nsolvers/co-pilots) or non-autonomously (only as co-pilots). We show that basic\nautonomous AI displaces humans towards specialized problem solving, leading to\nsmaller, less productive, and less decentralized firms. In contrast, advanced\nautonomous AI reallocates humans to routine work, resulting in larger, more\nproductive, and more decentralized firms. While autonomous AI primarily\nbenefits the most knowledgeable individuals, non-autonomous AI\ndisproportionately benefits the least knowledgeable. However, autonomous AI\nachieves higher overall output. These findings reconcile seemingly\ncontradictory empirical evidence and reveal key tradeoffs involved in\nregulating AI autonomy.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.05481v9"
    },
    {
        "title": "Social preferences and expected utility",
        "authors": [
            "Mehmet S. Ismail",
            "Ronald Peeters"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  It is well known that ex ante social preferences and expected utility are not\nalways compatible. In this note, we introduce a novel framework that naturally\nseparates social preferences from selfish preferences to answer the following\nquestion: What specific forms of social preferences can be accommodated within\nthe expected utility paradigm? In a departure from existing frameworks, our\nframework reveals that ex ante social preferences are not inherently in\nconflict with expected utility in games, provided a decision-maker's aversion\nto randomization in selfish utility \"counterbalances\" her social preference for\nrandomization. We also show that when a player's preferences in both the game\n(against another player) and the associated decision problem (against Nature)\nconform to expected utility axioms, the permissible range of social preferences\nbecomes notably restricted. Only under this condition do we reaffirm the\nexisting literature's key insight regarding the incompatibility of ex ante\ninequality aversion with expected utility.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.06048v1"
    },
    {
        "title": "Simple Proofs of the Variational and Multiple Priors Representations",
        "authors": [
            "Ian Ball"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This note gives simpler proofs of the variational and multiple priors\nrepresentations in Maccheroni et al. (2006) and Gilboa and Schmeidler (1989).\n",
        "pdf_link": "http://arxiv.org/pdf/2312.06107v3"
    },
    {
        "title": "Optimal Information Acquisition Under Intervention",
        "authors": [
            "Augusto Nieto-Barthaburu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We present a model of a forecaster who must predict the future value of a\nvariable that depends on an exogenous state and on the intervention of a\npolicymaker. Our focus is on the incentives of the forecaster to acquire costly\nprivate information to use in his forecasting exercise. We show that the\npolicy-making environment plays a crucial role in determining the incentives of\nthe forecaster to acquire information. Key parameters are the expected strength\nof policy intervention, the precision of the policymaker's private information,\nand the precision of public information. We identify conditions, which are\nplausible in applications, under which the forecaster optimally acquires little\nor no private information, and instead bases his forecast exclusively on\ninformation publicly known at the time the forecast is made. Furthermore we\nshow that, also under plausible conditions, stronger policy intervention and\nmore precise policymaker's information crowd-out forecaster's information\nacquisition.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.07757v1"
    },
    {
        "title": "The Market for Lemons and the Regulator's Signalling Problem",
        "authors": [
            "Roy Long"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The Market for Lemons is a classic model of asymmetric information first\nstudied by Nobel Prize economist George Akerlof. It shows that information\nasymmetry between the seller and buyer may result in market collapse or some\nsellers leaving the market. \"Lemons\" in the used car market are cars of poor\nquality. The information asymmetry present is that the buyer is uncertain of\nthe cars' true quality. I first offer a simple baseline model that illustrates\nthe market collapse, and then examine what happens when regulation, ie. a DMV\nis introduced to reveal (signal) the true car quality to the buyer. The effect\non the market varies based on the assumptions about the regulator. The central\nfocus is on the DMV's signal structure, which can have interesting effects on\nthe market and the information asymmetry. I show that surprisingly, when the\nDMV actually decreases the quality of their signal in a well constructed way,\nit can substantially increase their profit. On the other hand, this negatively\neffects overall welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.10896v1"
    },
    {
        "title": "Measuring the Concentration of Control in Contemporary Ethereum",
        "authors": [
            "Simon Brown"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Ethereum is undergoing significant changes to its architecture as it evolves.\nThese changes include its switch to PoS consensus and the introduction of\nsignificant infrastructural changes that do not require a change to the core\nprotocol, but that fundamentally affect the way users interact with the\nnetwork. These changes represent an evolution toward a more modular\narchitecture, in which there exists new exogenous vectors for centralization.\nThis paper builds on previous studies of decentralization of Ethereum to\nreflect these recent significant changes, and Ethereum's new modular paradigm.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14562v1"
    },
    {
        "title": "Inconsistency of Score-Elevated Reserve Policy for Indian Affirmative\n  Action",
        "authors": [
            "Orhan Aygn",
            "Bertan Turhan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  India has enacted an intricate affirmative action program through a\nreservation system since the 1950s. Notably, in 2008, a historic judgment by\nthe Supreme Court of India (SCI) in the case of Ashoka Kumar Thakur vs. Union\nof India mandated a 27 percent reservation to the Other Backward Classes (OBC).\nThe SCI's ruling suggested implementing the OBC reservation as a soft reserve\nwithout defining a procedural framework. The SCI recommended a maximum of 10\npoints difference between the cutoff scores of the open-category and OBC\npositions. We show that this directive conflicts with India's fundamental\nSupreme Court mandates on reservation policy. Moreover, we show that the\nscore-elevated reserve policy proposed by S\\\"onmez and Yenmez (2022) is\ninconsistent with this directive.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14648v2"
    },
    {
        "title": "Interdependent Total Factor Productivity in an Input-Output model",
        "authors": [
            "Thomas M. Bombarde",
            "Andrew L. Krause"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Industries learn productivity improvements from their suppliers. The observed\nempirical importance of these interactions, often omitted by input-output\nmodels, mandates larger attention. This article embeds interdependent total\nfactor productivity (TFP) growth into a general non-parametric input-output\nmodel. TFP growth is assumed to be Cobb-Douglas in TFP-stocks of adjacent\nsectors, where elasticities are the input-output coefficients. Studying how the\nsteady state of the system reacts to changes in research effort bears insight\nfor policy and the input-output literature. First, industries higher in the\nsupply chain see a greater multiplication of their productivity gains. Second,\nthe presence of `laggard' industries can bottleneck the the rest of the\neconomy. By deriving these insights formally, we review a canonical method for\naggregating TFP -- Hulten's Theorem -- and show the potential importance of\nbackward linkages.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.15362v1"
    },
    {
        "title": "Theorizing the Socio-Cultural Dynamics of Consumer Decision-Making for\n  Participation in Community-Supported Agriculture",
        "authors": [
            "Sota Takagi",
            "Yusuke Numazawa",
            "Kentaro Katsube",
            "Wataru Omukai",
            "Miki Saijo",
            "Takumi Ohashi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In the context of the urgent need to establish sustainable food systems,\nCommunity Supported Agriculture (CSA), in which consumers share risks with\nproducers, has gained increasing attention. Understanding the factors that\ninfluence consumer participation in CSA is crucial, yet the complete picture\nand interrelations of these factors remain unclear in existing studies. This\nresearch adopts a scoping review and the KJ method to elucidate the factors\ninfluencing consumer participation in CSA and to theorize the consumer\nparticipation. In particular, we focus on the dynamics of individual\ndecision-making for participation, under the premise that individuals are\nembedded in socio-cultural environments. We examine the decision-making process\nbased on the seesaw of expected gains and losses from participation, along with\nthe reflexivity to the individual and the process of updating decision-making\npost-participation. Our study highlights how individual decision-making for\nparticipation is influenced by relationships with others within the embedded\nsocio-cultural environment, as well as by attachment and connection to the\ncommunity. It also shows that discrepancies between expectations and\nexperiences post-participation, and the transformation of the social capital,\npromote the updating of decision-making processes. In addition, among the\nfactors identified in this study for participation in CSA, the decision to\nparticipate was heavily influenced by expectations of variety of ingredients,\nsuggesting that other factors such as food education and learning\nopportunities, contribution to environmental and social issues, and connections\nwith people and nature had little impact. Although there are limitations, the\ninsights gained from this study offer profound implications for stakeholders\nand provide valuable insights for more sustainable and efficient CSA practices.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.17529v2"
    },
    {
        "title": "Equilibrium existence in a discrete-time endogenous growth model with\n  physical and human capital",
        "authors": [
            "Luis Alcala"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies a discrete-time version of the Lucas-Uzawa endogenous\ngrowth model with physical and human capital. Equilibrium existence is proved\napplying tools of dynamic programming with unbounded returns. The proofs rely\non properties of homogeneous functions and also apply well-known inequalities\nin real analysis, seldom used in the literature, which significantly simplifies\nthe task of verifying certain assumptions that are rather technical in nature.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00342v1"
    },
    {
        "title": "Community Enforcement with Endogenous Records",
        "authors": [
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study repeated games with anonymous random matching where players\nendogenously decide whether to disclose signals about their past actions. I\nestablish an-anti folk theorem, that when players are sufficiently long-lived,\nthey will almost always play their dominant actions and will almost never\ncooperate. When players' expected lifespans are intermediate, they can sustain\nsome cooperation if their actions are substitutes but cannot sustain any\ncooperation if their actions are complements. Therefore, the maximal level of\ncooperation a community can sustain is not monotone with respect to its\nmembers' expected lifespans and the complementarity of players' actions can\nundermine their abilities to sustain cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00839v3"
    },
    {
        "title": "Theoretical Steps to Optimize Transportation in the Cubic Networks and\n  the Congestion Paradox",
        "authors": [
            "Joonkyung Yoo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Given a player is guaranteed the same payoff for each delivery path in a\nsingle-cube delivery network, the player's best response is to randomly divide\nall goods and deliver them to all other nodes, and the best response satisfies\nthe Kuhn-Tucker condition. The state of the delivery network is randomly\ncomplete. If congestion costs are introduced to the player's maximization\nproblem in a multi-cubic delivery network, the congestion paradox arises where\nall coordinates become congested as long as the previous assumptions about\npayoffs are maintained.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00940v1"
    },
    {
        "title": "Changing Simplistic Worldviews",
        "authors": [
            "Maxim Senkov",
            "Toygar T. Kerman"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a Bayesian persuasion model with two-dimensional states of the\nworld, in which the sender (she) and receiver (he) have heterogeneous prior\nbeliefs and care about different dimensions. The receiver is a naive agent who\nhas a simplistic worldview: he ignores the dependency between the two\ndimensions of the state. We provide a characterization for the sender's gain\nfrom persuasion both when the receiver is naive and when he is rational. We\nshow that the receiver benefits from having a simplistic worldview if and only\nif it makes him perceive the states in which his interest is aligned with the\nsender as less likely.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.02867v1"
    },
    {
        "title": "Incontestable Assignments",
        "authors": [
            "Benoit Decerf",
            "Guillaume Haeringer",
            "Martin Van der Linden"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In school districts where assignments are exclusively determined by a\nclearinghouse students can only appeal their assignment with a valid reason. An\nassignment is incontestable if it is appeal-proof. We study incontestability\nwhen students do not observe the other students' preferences and assignments.\nIncontestability is shown to be equivalent to individual rationality,\nnon-wastefulness, and respect for top-priority sets (a weakening of justified\nenvy). Stable mechanisms and those Pareto dominating them are incontestable, as\nwell as the Top-Trading Cycle mechanism (but Boston is not). Under a mild\nconsistency property, incontestable mechanisms are i-indinstiguishable (Li,\n2017), and share similar incentive properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03598v2"
    },
    {
        "title": "Learning about a changing state",
        "authors": [
            "Benjamin Davies"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A long-lived Bayesian agent observes costly signals of a time-varying state.\nHe chooses the signals' precisions sequentially, balancing their costs and\nmarginal informativeness. I compare the optimal myopic and forward-looking\nprecisions when the state follows a Brownian motion. I also compare the myopic\nprecisions induced by other Gaussian processes.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03607v1"
    },
    {
        "title": "The Priced Survey Methodology: Theory",
        "authors": [
            "Avner Seror"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, I introduce the Priced Survey Methodology (PSM), a tool\ndesigned to overcome the limitations of traditional survey methods in analyzing\nsocial preferences. The PSM's design draws inspiration from consumption choice\nexperiments, as respondents fill out the same survey multiple times under\ndifferent choice sets. I generalize Afriat's theorem and show that the\nGeneralized Axiom of Revealed Preferences is necessary and sufficient for the\nexistence of a concave, continuous, and single-peaked utility function\nrationalizing answers to the PSM. This result has two major implications.\nFirst, it is possible to measure a respondent's ideal answer to a survey using\nonly ordinal relations between possible answers. Second, the PSM captures\naspects of social preferences often overlooked in standard surveys, such as the\nrelative importance that respondents attribute to different survey questions. I\ndeploy a PSM measuring altruistic preferences in a sample of online\nparticipants, recover respondents' single-peaked preferences, and draw several\nimplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03876v1"
    },
    {
        "title": "Anonymous and Strategy-Proof Voting under Subjective Expected Utility\n  Preferences",
        "authors": [
            "Eric Bahel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study three axioms in the model of constrained social choice under\nuncertainty where (i) agents have subjective expected utility preferences over\nacts and (ii) different states of nature have (possibly) different sets of\navailable outcomes. Anonymity says that agents' names or labels should never\nplay a role in the mechanism used to select the social act. Strategy-proofness\nrequires that reporting one's true preferences be a (weakly) dominant strategy\nfor each agent in the associated direct revelation game. Range unanimity\nessentially says that a feasible act must be selected by society whenever it is\nreported as every voter's favorite act within the range of the mechanism. We\nfirst show that every social choice function satisfying these three axioms can\nbe factored as a product of voting rules that are either constant or binary\n(always yielding one of two pre-specified outcomes in each state). We describe\nfour basic types of binary factors: three of these types are novel to this\nliterature and exploit the voters' subjective beliefs. Our characterization\nresult then states that a social choice function is anonymous, strategy-proof\nand range-unanimous if and only if every binary factor (in its canonical\nfactorization) is of one of these four basic types.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.04060v2"
    },
    {
        "title": "Should Politicians be Informed? Targeted Benefits and Heterogeneous\n  Voters",
        "authors": [
            "Maxim Senkov",
            "Arseniy Samsonov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We compare two scenarios in a model where politicians offer local public\ngoods to heterogeneous voters: one where politicians have access to data on\nvoters and thus can target specific ones, and another where politicians only\ndecide on the level of spending. When the budget is small, or the public good\nhas a high value, access to voter information leads the winner to focus on\npoorer voters, enhancing voter welfare. With a larger budget or less crucial\npublic goods, politicians target a narrow group of swing voters, which harms\nthe voter welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.04273v1"
    },
    {
        "title": "Partition-form Cooperative Games in Two-Echelon Supply Chains",
        "authors": [
            "Gurkirat Wadhwa",
            "Tushar Shankar Walunj",
            "Veeraruna Kavitha"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Competition and cooperation are inherent features of any multi-echelon supply\nchain. The interactions among the agents across the same echelon and that\nacross various echelons influence the percolation of market demand across\nechelons. The agents may want to collaborate with others in pursuit of\nattracting higher demand and thereby improving their own revenue. We consider\none supplier (at a higher echelon) and two manufacturers (at a lower echelon\nand facing the customers) and study the collaborations that are `stable'; the\nmain differentiator from the existing studies in supply chain literature is the\nconsideration of the following crucial aspect -- the revenue of any\ncollaborative unit also depends upon the way the opponents collaborate. Such\ncompetitive scenarios can be modeled using what is known as partition form\ngames.\n  Our study reveals that the grand coalition is not stable when the product is\nessential and the customers buy it from any of the manufacturers without a\npreference. The supplier prefers to collaborate with only one manufacturer, the\none stronger in terms of market power; further, such collaboration is stable\nonly when the stronger manufacturer is significantly stronger. Interestingly,\nno stable collaborative arrangements exist when the two manufacturers are\nnearly equal in market power.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.04939v1"
    },
    {
        "title": "Temporary exclusion in repeated contests",
        "authors": [
            "Yaron Azrieli"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Consider a population of agents who repeatedly compete for awards, as in the\ncase of researchers annually applying for grants. Noise in the selection\nprocess may encourage entry of low quality proposals, forcing the principal to\ncommit large resources to reviewing applications and further increasing award\nmisallocation. A \\emph{temporary exclusion} policy prohibits an agent from\napplying in the current period if they were rejected in the previous. We\ncompare the steady state equilibria of the games with and without exclusion.\nWhenever the benefit from winning is sufficiently large exclusion results in\nmore self-selection, eliminating entry of low quality applications. We extend\nthe analysis to more general exclusion policies. We also show that exclusion\nhas a distributional effect, where better able agents exhibit more\nself-selection.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.06257v3"
    },
    {
        "title": "Utilitarian Beliefs in Social Networks: Explaining the Emergence of\n  Hatred",
        "authors": [
            "Houda Nait El Barj",
            "Theophile Sautory"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the dynamics of opinions in a setting where a leader has a payoff\nthat depends on agents' beliefs and where agents derive psychological utility\nfrom their beliefs. Agents sample a signal that maximises their utility and\nthen communicate with each other through a network formed by disjoint social\ngroups. The leader has a choice to target a finite set of social groups with a\nspecific signal to influence their beliefs and maximise his returns.\nHeterogeneity in agents' preferences allows us to analyse the evolution of\nopinions as a dynamical system with asymmetric forces. We apply our model to\nexplain the emergence of hatred and the spread of racism in a society. We show\nthat when information is restricted, the equilibrium level of hatred is\ndetermined solely by the belief of the most extremist agent in the group\nregardless of the inherent structure of the network. On the contrary, when\ninformation is dense, the space is completely polarised in equilibrium with the\npresence of multiple \"local truths\" which oscillate in periodic cycles. We find\nthat when preferences are uniformly distributed, the equilibrium level of\nhatred depends solely on the value of the practical punishment associated with\nholding a hate belief. Our finding suggests that an optimal policy to reduce\nhatred should focus on increasing the cost associated with holding a racist\nbelief.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07178v1"
    },
    {
        "title": "Unemployment Volatility: When Workers Pay Costs upon Accepting Jobs",
        "authors": [
            "Rich Ryan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  When a firm hires a worker, adding the new hire to payroll is costly. These\ncosts reduce the amount of resources that can go to recruiting workers and\namplify how unemployment responds to changes in productivity. Workers also\nincur up-front costs upon accepting jobs. Examples include moving expenses and\nregulatory fees. I establish that workers' costs lessen the response of\nunemployment to productivity changes and do not subtract from resources\navailable for recruitment. The influence of workers' costs is bounded by\nproperties of a matching function, which describes how job openings and\nunemployment produce hires. Using data on job finding that are adjusted for\nworkers' transitions between employment and unemployment and for how the Job\nOpenings and Labor Turnover Survey records hires, I estimate a bound that\nascribes limited influence to workers' costs. The results demonstrate that\ncosts paid by workers upon accepting jobs affect outcomes in the labor market\n(firms threaten workers with paying the up-front costs again if wage\nnegotiations fail), but their influence on volatility is less important than\nfirms' costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07423v1"
    },
    {
        "title": "A General Approach for Computing a Consensus in Group Decision Making\n  That Integrates Multiple Ethical Principles",
        "authors": [
            "Francisco Salas-Molina",
            "Filippo Bistaffa",
            "Juan A. Rodriguez-Aguilar"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We tackle the problem of computing a consensus according to multiple ethical\nprinciples -- which can include, for example, the principle of maximum freedom\nassociated with the Benthamite doctrine and the principle of maximum fairness\nassociated with the Rawlsian principles -- among the preferences of different\nindividuals in the context of Group-Decision-Making. More formally, we put\nforward a novel formalisation of the above-mentioned problem based on a\nmultinorm approximation problem that aims at minimising multiple p-metric\ndistance functions, where each parameter p represents a given ethical\nprinciple. Our contribution incurs obvious benefits from a social-choice\nperspective. Firstly, our approach significantly generalises state-of-the-art\napproaches that were limited to only two ethical principles (p set to one, for\nmaximum freedom, and p set to infinity, for maximum fairness). Secondly, our\nexperimental results considering an established test case demonstrate that our\napproach is capable, thanks to a novel re-weighting scheme, to compute a\nmulti-norm consensus that takes into account each ethical principle in a\nbalanced way, in contrast with state-of-the-art approaches that were heavily\nbiased towards the p=1 ethical principle\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07818v2"
    },
    {
        "title": "Strategic formation of production networks",
        "authors": [
            "Antoine Mandel",
            "Van-Quy Nguyen",
            "Bach Dong-Xuan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We provide a strategic model of the formation of production networks that\nsubsumes the standard general equilibrium approach. The objective of firms in\nour setting is to choose their supply relationships so as to maximize their\nprofit at the general equilibrium that unfolds. We show that this objective is\nequivalent to the maximization by the firms of their eigenvector centrality in\nthe production network. As is common in network formation games based on\ncentrality, there are multiple Nash equilibria in our setting. We have\ninvestigated the characteristics and the social efficiency of these equilibria\nin a stylized version of our model representing international trade networks.\nWe show that the impact of network structure on social welfare is firstly\ndetermined by a trade-off between costs of increasing process complexity and\npositive spillovers on productivity induced by the diversification of the input\nmix. We further analyze a variant of our model that accounts for the risks of\ndisruption of supply relationships. In this setting, we characterize how social\nwelfare depends on the structure of the production network, the spatial\ndistribution of risks, and the process of shock aggregation in supply chains.\nWe finally show that simple trade policies characterized by sets of links that\nare either prevented or catalyzed can be a powerful equilibrium selection\ndevice.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08929v1"
    },
    {
        "title": "Game Representations and Extensions of the Shapley Value",
        "authors": [
            "Pradeep Dubey"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We show that any cooperative game can be represented by an assignment of\ncostly facilities to players, in which it is intuitively obvious how to\nallocate the total cost in an equitable manner. This equitable solution turns\nout to be the Shapley value of the game, and thus provides as an alternative\njustification of the value. Game representations also open the door for\nextending the Shapley value to situations where not all coalitions can form,\nprovided those that can constitute a \"semi-algebra\"; or, more generally, a\n\"hierarchy\"; or, still more generally, have \"full span\".\n",
        "pdf_link": "http://arxiv.org/pdf/2401.09845v1"
    },
    {
        "title": "Wealth dynamics in a multi-aggregate closed monetary system",
        "authors": [
            "Andrea Monaco",
            "Matteo Ghio",
            "Adamaria Perrotta"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine the statistical properties of a closed monetary economy with\nmulti-aggregates interactions. Building upon Yakovenko's single-agent monetary\nmodel (Dragulescu and Yakovenko, 2000), we investigate the joint equilibrium\ndistribution of aggregate size and wealth. By comparing theoretical and\nsimulated data, we validate our findings and investigate the influence of both\nmicro dynamics and macro characteristics of the system on the distribution.\nAdditionally, we analyze the system's convergence towards equilibrium under\nvarious conditions. Our laboratory model may offer valuable insights into\nmacroeconomic phenomena allowing to reproduce typical wealth distribution\nfeatures observed in real economy.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.09871v1"
    },
    {
        "title": "Coevolution of Resource and Strategies in Common-Pool Resource Dilemmas:\n  A Coupled Human-Environmental System Model",
        "authors": [
            "Chengyi Tu",
            "Renfei Chen",
            "Ying Fan",
            "Yongliang Yang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Common-pool resource governance requires users to cooperate and avoid\noverexploitation, but defection and free-riding often undermine cooperation. We\nmodel a human-environmental system that integrates dynamics of resource and\nusers' strategies. The resource follows a logistic function that depends on\nnatural growth rate, carrying capacity, and extraction rates of cooperators and\ndefectors. The users' strategies evolve according to different processes that\ncapture effects of payoff, resource, and noise. We analyze the feedback between\nresource availability and strategic adaptation, and explores the conditions for\nthe emergence and maintenance of cooperation. We find different processes lead\nto different regimes of equilibrium solutions and resource levels depending on\nthe parameter configuration and initial conditions. We also show that some\nprocesses can enhance the sustainability of the resource by making the users\nmore responsive to the resource scarcity. The paper advances the understanding\nof human-environmental system and offers insights for resource governance\npolicies and interventions.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11269v1"
    },
    {
        "title": "Efficiency in random allocation with ordinal rules",
        "authors": [
            "Samson Alva",
            "Eun Jeong Heo",
            "Vikram Manjunath"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study ordinal rules for allocating indivisible goods via lottery.\nOrdinality requires a rule to consider only how agents rank degenerate\nlotteries and may be necessitated by cognitive, informational, or as we show,\nincentive constraints. The limited responsiveness of ordinal rules to agents'\npreferences means that they can only satisfy welfare properties based on first\norder stochastic dominance, which is incomplete.\n  We define a new efficiency concept for ordinal rules. While ordinality and\nefficiency together are incompatible with the usual notions of fairness and\nsomewhat limit randomization, they do leave room for a rich class of rules. We\ndemonstrate this through a characterization of all ordinal, efficient,\nstrategy-proof, non-bossy, boundedly invariant, and neutral rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11899v2"
    },
    {
        "title": "Beveridgean Phillips Curve",
        "authors": [
            "Pascal Michaillat",
            "Emmanuel Saez"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper proposes a new, Beveridgean model of the Phillips curve. While the\nNew Keynesian Phillips Curve is based on monopolistic pricing under\nprice-adjustment costs, the Beveridgean Phillips curve is based on\ndirected-search pricing under price-adjustment costs. Under directed-search\npricing, prices respond to slack instead of marginal costs. The Beveridgean\nPhillips curve links the inflation gap to the unemployment gap, with the\nfollowing properties. First, it produces the divine coincidence: it guarantees\nthat the rate of inflation is on target whenever the rate of unemployment is\nefficient. Second, whenever the Beveridge curve shifts, the Phillips curve\nshifts if it is formulated with inflation and unemployment, but it remains\nunaffected if it is formulated with inflation and labor-market tightness.\nThird, the Phillips curve displays a kink at the point of divine coincidence if\nwe assume that wage decreases -- which reduce workers' morale -- are more\ncostly to producers than price increases -- which upset customers. These three\nproperties describe recent US data well.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12475v2"
    },
    {
        "title": "Three Variations on Money Pump, Common Prior, and Trade",
        "authors": [
            "Ziv Hellman",
            "Miklos Pinter"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider finite information structures, and quest for the answer of the\nquestion: What is the proper definition of prior?\n  In the single player setting we conclude that a probability distribution is a\nprior if it is disintegrable, because this definition excludes money pump.\n  In the multiplayer setting our analysis does not boil down to one proper\nnotion of common prior (the multiplayer version of prior). The appropriate\nnotion is a choice of the modeller in this setting. We consider three variants\nof money pump, each \"defines\" a notion of common prior.\n  Furthermore, we also consider three variants of trade, each correspond to one\nof the money pump variants, hence to one of the common prior variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.13132v1"
    },
    {
        "title": "Costly Persuasion by a Partially Informed Sender",
        "authors": [
            "Shaofei Jiang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study a model of costly Bayesian persuasion by a privately and partially\ninformed sender who conducts a public experiment. The cost of running an\nexperiment is the expected reduction of a weighted log-likelihood ratio\nfunction of the sender's belief. This is microfounded by a Wald sequential\nsampling problem where good news and bad news cost differently. I focus on\nequilibria satisfying the D1 criterion. The equilibrium outcome depends\ncrucially on the relative costs of drawing good and bad news in the experiment.\nIf good news is not too costly compared to bad news, there exists a unique\nseparating equilibrium, and the receiver learns more information thanks to\nsender private information. If good news is sufficiently costlier than bad\nnews, the single-crossing property fails. There may exist pooling and partial\npooling equilibria, and in some equilibria, the receiver learns less\ninformation compared to a benchmark with an uninformed sender.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14087v4"
    },
    {
        "title": "A mathematical theory of power",
        "authors": [
            "Daniele De Luca"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper proposes a new approach to power in Game Theory. Cooperation and\nconflict are simulated with a mechanism of payoff alteration, called F-game.\nUsing convex combinations of preferences, an F-game can measure players'\nattitude to cooperate. We can then define actual and potential power as special\nrelations between different states of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16406v1"
    },
    {
        "title": "Robust Performance Evaluation of Independent and Identical Agents",
        "authors": [
            "Ashwin Kambhampati"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A principal provides nondiscriminatory incentives for independent and\nidentical agents. The principal cannot observe the agents' actions, nor does\nshe know the entire set of actions available to them. It is shown, very\ngenerally, that any worst-case optimal contract is nonaffine in performances.\nIn addition, each agent's pay must depend on the performance of another. In the\ncase of two agents and binary output, existence of a worst-case optimal\ncontract is established and it is proven that any such contract exhibits joint\nperformance evaluation -- each agent's pay is strictly increasing in the\nperformance of the other. The analysis identifies a fundamentally new channel\nleading to the optimality of nonlinear team-based incentive pay.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16542v1"
    },
    {
        "title": "Coordinating Resource Allocation during Product Transitions Using a\n  Multifollower Bilevel Programming Model",
        "authors": [
            "Rahman Khorramfar",
            "Osman Ozaltin",
            "Reha Uzsoy",
            "Karl Kempf"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the management of product transitions in a semiconductor\nmanufacturing firm that requires the coordination of resource allocation\ndecisions by multiple, autonomous Product Divisions using a multi-follower\nbilevel model to capture the hierarchical and decentralized nature of this\ndecision process. Corporate management, acting as the leader, seeks to maximize\nthe firm's total profit over a finite horizon. The followers consist of\nmultiple Product Divisions that must share manufacturing and engineering\nresources to develop, produce and sell products in the market. Each Product\nDivision needs engineering capacity to develop new products, and factory\ncapacity to produce products for sale while also producing the prototypes and\nsamples needed for the product development process. We model this\ninterdependency between Product Divisions as a generalized Nash equilibrium\nproblem at the lower level and propose a reformulation where Corporate\nManagement acts as the leader to coordinate the resource allocation decisions.\nWe then derive an equivalent single-level reformulation and develop a\ncut-and-column generation algorithm. Extensive computational experiments\nevaluate the performance of the algorithm and provide managerial insights on\nhow key parameters and the distribution of decision authority affect system\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.17402v1"
    },
    {
        "title": "Recent Advances on Uniqueness of Competitive Equilibrium",
        "authors": [
            "Alexis Akira Toda",
            "Kieran James Walsh"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This article reviews the recent advances in the uniqueness and multiplicity\nof competitive equilibria in models arising in mathematical economics, finance,\nmacroeconomics, and trade.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.00998v1"
    },
    {
        "title": "When and Where To Submit A Paper",
        "authors": [
            "Daniel Luo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  What is the optimal order in which a researcher should submit their papers to\njournals of differing quality? I analyze a sequential search model without\nrecall where the researcher's expected value from journal submission depends on\nthe history of past submissions. Acceptances immediately terminate the search\nprocess and deliver some payoff, while rejections carry information about the\npaper's quality, affecting the researcher's belief in acceptance probability\nover future journals. When journal feedback does not change the paper's\nquality, the researcher's optimal strategy is monotone in their acceptance\npayoff. Submission costs distort the researcher's effective acceptance payoff,\nbut maintain monotone optimality. If journals give feedback which can affect\nthe paper's quality, such as through \\textit{referee reports}, the search order\ncan change drastically depending on the agent's prior belief about their\npaper's quality. However, I identify a set of \\textit{assortative matched}\nconditions on feedback such that monotone strategies remain optimal whenever\nthe agent's prior is sufficiently optimistic.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01745v1"
    },
    {
        "title": "Censored Beliefs and Wishful Thinking",
        "authors": [
            "Jarrod Burgh",
            "Emerson Melo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We present a model elucidating wishful thinking, which comprehensively\nincorporates both the costs and benefits associated with biased beliefs. Our\nfindings reveal that wishful thinking behavior can be accurately characterized\nas equivalent to superquantile-utility maximization within the domain of\nthreshold beliefs distortion cost functions. By leveraging this equivalence, we\nestablish conditions that elucidate when an optimistic decision-maker exhibits\na preference for choices characterized by positive skewness and increased risk.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01892v1"
    },
    {
        "title": "Redistribution with Needs",
        "authors": [
            "Ricardo Martinez",
            "Juan D. Moreno-Ternero"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We take an axiomatic approach to study redistribution problems when agents\nreport income and needs. We formalize axioms reflecting ethical and operational\nprinciples such as additivity, impartiality and individual rationality.\nDifferent combinations of those axioms characterize three focal rules (laissez\nfaire, full redistribution, and need-adjusted full redistribution) as well as\ncompromises among them. We also uncover the structure of those compromises\nexploring the Lorenz dominance criterion as well as majority voting. Our\nanalysis provides an axiomatic justification for a linear income tax system. We\nconclude our analysis resorting to Eurostat's Household Budget Survey from\nwhere we illustrate the different redistribution patterns accounting for needs\nacross European countries.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.02802v1"
    },
    {
        "title": "Monopoly agenda control with privately informed voters",
        "authors": [
            "Kirill S. Evdokimov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  An agenda-setter repeatedly proposes a spatial policy to voters until some\nproposal is accepted. Voters have distinct but correlated preferences and\nreceive private signals about the common state. I investigate whether the\nagenda-setter retains the power to screen voters as players become perfectly\npatient and private signals become perfectly precise. I show that the extent of\nthis power depends on the relative precision of private signals and the\nconflict of preferences among voters, confirming the crucial role of committee\nsetting and single-peaked preferences. When the private signals have equal\nprecision, the agenda-setter can achieve the full-information benchmark. When\none voter receives an asymptotically more precise signal, the agenda-setter's\npower to screen depends on preference diversity. These results imply that the\nlack of commitment to a single proposal can benefit the agenda-setter.\nSurprisingly, an increase in the voting threshold can allow the agenda-setter\nto extract more surplus.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.06495v1"
    },
    {
        "title": "Perfect Bayesian Persuasion",
        "authors": [
            "Elliot Lipnowski",
            "Doron Ravid",
            "Denis Shishkin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A sender commits to an experiment to persuade a receiver. Accounting for the\nsender's experiment-choice incentives, and not presupposing a receiver\ntie-breaking rule when indifferent, we characterize when the sender's\nequilibrium payoff is unique and so coincides with her \"Bayesian persuasion\"\nvalue. A sufficient condition in finite models is that every action which is\nreceiver-optimal at some belief is uniquely optimal at some other belief -- a\ngeneric property. We similarly show the equilibrium sender payoff is typically\nunique in ordered models. In an extension, we show uniqueness generates\nrobustness to imperfect sender commitment.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.06765v1"
    },
    {
        "title": "Continuous Representations of Preferences by Means of Two Continuous\n  Functions",
        "authors": [
            "Gianni Bosi",
            "Asier Estevan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Let $\\precsim$ be a reflexive binary relation on a topological space $(X,\n\\tau )$. A pair $(u,v)$ of continuous real-valued functions on $(X, \\tau )$ is\nsaid to be a {\\em continuous representation} of $\\precsim$ if, for all $x,y \\in\nX$, [$(x \\precsim y \\Leftrightarrow u(x) \\leq v(y))$]. In this paper we provide\na characterization of the existence of a continuous representation of this kind\nin the general case when neither the functions $u$ and $v$ nor the topological\nspace $(X,\\tau )$ are required to satisfy any particular assumptions. Such\ncharacterization is based on a suitable continuity assumption of the binary\nrelation $\\precsim$, called {\\em weak continuity}. In this way, we generalize\nall the previous results on the continuous representability of interval orders,\nand also of total preorders, as particular cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07908v1"
    },
    {
        "title": "Domestic Competitive Balance and International Success: The Case of The\n  Football Industry",
        "authors": [
            "Juan D. Moreno-Ternero",
            "Tim Pawlowski",
            "Shlomo Weber"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper examines the interdependence of international success and\ncompetitive balance of domestic sports competitions. More specifically, we\napply the notion of the Herfindahl-Hirschman index to examine the effect of\ninternational rewards on distortion of competitive balance in domestic\ncompetitions and derive conditions under which the level of domestic\ncompetitive balance raises or falls. Our results yield interesting policy\nimplications for the regulation of prize schemes in international competitions.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.08396v1"
    },
    {
        "title": "Equitable screening",
        "authors": [
            "Filip Tokarski"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study the problem of a government providing benefits while considering the\nperceived equity of the resulting allocation. Such concerns are modeled through\nan equity constraint requiring that equally deserving agents receive equal\nallocations. I ask what forms of screening are compatible with equity and show\nthat while the government cannot equitably screen with a single instrument\n(e.g. payments or wait times), combining multiple instruments, which on their\nown favor different groups, allows it to screen while still producing an\nequitable allocation.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.08781v2"
    },
    {
        "title": "Attraction Via Prices and Information",
        "authors": [
            "Pak Hung Au",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the ramifications of increased commitment power for information\nprovision in an oligopolistic market with search frictions. Although prices are\nposted and, therefore, guide search, if firms cannot commit to information\nprovision policies, there is no active search at equilibrium so consumers visit\n(and purchase from) at most one firm. If firms can guide search by both their\nprices and information policies, there exists a unique symmetric equilibrium\nexhibiting price dispersion and active search. Nevertheless, when the market is\nthin, consumers prefer the former case, which features intense price\ncompetition. Firms always prefer the latter.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11754v1"
    },
    {
        "title": "Ironing allocations",
        "authors": [
            "Filip Tokarski"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I propose a new approach to solving standard screening problems when the\nmonotonicity constraint binds. A simple geometric argument shows that when\nvirtual values are quasi-concave, the optimal allocation can be found by\nappropriately truncating the solution to the relaxed problem. I provide a\nsimple algorithm for finding this optimal truncation when virtual values are\nconcave.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11881v1"
    },
    {
        "title": "Optimal Design of Climate Disclosure Policies: Transparency versus\n  Externality",
        "authors": [
            "Shangen Li"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Does a more transparent climate disclosure policy induce lower emissions?\nThis paper examines the welfare implications of transparency in climate\ndisclosure regulation. Increased disclosure transparency could result in a\nlarger equilibrium externality, but never leaves the firm worse off.\nConsequently, mandating full disclosure is no different from maximizing the\nfirm's private benefit while disregarding the ensuing externality. Transparency\nbeyond binary disclosure is necessary only when the firm holds private\ninformation about its incentives for emission reduction. I provide conditions\nunder which focusing on threshold disclosure policies entails no loss of\ngenerality.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11961v2"
    },
    {
        "title": "The matching problem with linear transfers is equivalent to a\n  hide-and-seek game",
        "authors": [
            "Alfred Galichon",
            "Antoine Jacquet"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Matching problems with linearly transferable utility (LTU) generalize the\nwell-studied transferable utility (TU) case by relaxing the assumption that\nutility is transferred one-for-one within matched pairs. We show that LTU\nmatching problems can be reframed as nonzero-sum games between two players,\nthus generalizing a result from von Neumann. The underlying linear programming\nstructure of TU matching problems, however, is lost when moving to LTU. These\nresults draw a new bridge between non-TU matching problems and the theory of\nbimatrix games, with consequences notably regarding the computation of stable\noutcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.12200v2"
    },
    {
        "title": "Sequential unanimity voting rules for binary social choice",
        "authors": [
            "Stergios Athanasoglou",
            "Somouaoga Bonkoungou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a group of voters that needs to decide between two candidates. We\npropose a novel family of neutral and strategy-proof rules, which we call\nsequential unanimity rules. By demonstrating their formal equivalence to the\nM-winning coalition rules of Moulin (1983), we show that sequential unanimity\nrules are characterized by neutrality and strategy-proofness. We establish our\nresults by developing algorithms that transform a given M-winning coalition\nrule into an equivalent sequential unanimity rule and vice versa. The analysis\ncan be extended to accommodate the full preference domain in which voters may\nbe indifferent between candidates.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.13009v3"
    },
    {
        "title": "Mechanism Design with Sequential-Move Games: Revelation Principle",
        "authors": [
            "Siyang Xiong"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Traditionally, mechanism design focuses on simultaneous-move games (e.g.,\nMyerson (1981)). In this paper, we study mechanism design with sequential-move\ngames, and provide two results on revelation principles for general solution\nconcepts (e.g., perfect Bayesian equilibrium, obvious dominance, strong-obvious\ndominance). First, if a solution concept is additive, implementation in\nsequential-move games is equivalent to implementation in simultaneous-move\ngames. Second, for any solution concept \\r{ho} and any social choice function\nf, we identify a canonical operator {\\gamma}^{(\\r{ho},f)}, which is defined on\nprimitives. We prove that, if \\r{ho} is monotonic, f can be implemented by a\nsequential-move game if and only if {\\gamma}^{(\\r{ho},f)} is achievable, which\ntranslates a complicated mechanism design problem into checking some conditions\ndefined on primitives. Most of the existing solution concepts are either\nadditive or monotonic.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.13580v2"
    },
    {
        "title": "Multidimensional Signaling with a Resource Constraint",
        "authors": [
            "Seungjin Han",
            "Alex Sam"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study multidimensional signaling (cognitive/non-cognitive) as a sender's\nportfolio choice with a resource constraint. We establish the existence of a\nunique monotone D1 equilibrium where the cognitive (non-cognitive) signal\nincreases (decreases) in sender type and the sum of the two increases in sender\ntype. The equilibrium is characterized by two threshold sender types. The low\nthreshold is one where a kink occurs in signaling. The constraint is binding\nonly for sender types above it. The high threshold is the other one, above\nwhich all types spend all the resources in cognitive signal with pooling and\ndiscontinuity on the top.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.14003v2"
    },
    {
        "title": "Implementations of Cooperative Games Under Non-Cooperative Solution\n  Concepts",
        "authors": [
            "Justin Chan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Cooperative games can be distinguished as non-cooperative games in which\nplayers can freely sign binding agreements to form coalitions. These coalitions\ninherit a joint strategy set and seek to maximize collective payoffs. When the\npayoffs to each coalition under some non-cooperative solution concept coincide\nwith their value in the cooperative game, the cooperative game is said to be\nimplementable and the non-cooperative game its implementation. This paper\nproves that all strictly superadditive partition function form games are\nimplementable under Nash equilibrium and rationalizability; that all weakly\nsuperadditive characteristic function form games are implementable under Nash\nequilibrium; and that all weakly superadditive partition function form games\nare implementable under trembling hand perfect equilibrium. Discussion then\nproceeds on the appropriate choice of non-cooperative solution concept for the\nimplementation.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.14952v2"
    },
    {
        "title": "Aggregating Incomplete Rankings",
        "authors": [
            "Yasunori Okumura"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This study considers the method to derive a ranking of alternatives by\naggregating the rankings submitted by several individuals who may not evaluate\nall of them. The collection of subsets of alternatives that individuals (can)\nevaluate is referred to as an evaluability profile. For a given evaluability\nprofile, we define an aggregating ranking function whose inputs are the\nrankings of individuals on the alternatives they evaluate. We investigate the\nproperties of aggregating ranking functions, which are modifications of those\nintroduced in previous studies. Whether an aggregating ranking function\nsatisfying a combination of properties exists depends on the evaluability\nprofile. Thus, we identify the necessary and sufficient conditions on\nevaluability profiles to ensure the existence of the functions satisfying four\ndifferent combinations of properties. Furthermore, to examine how frequently\npossible or impossible evaluability profiles occur, we derive the proportion of\neach type in specific cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.16309v4"
    },
    {
        "title": "Distributions of Posterior Quantiles via Matching",
        "authors": [
            "Anton Kolotilin",
            "Alexander Wolitzky"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We offer a simple analysis of the problem of choosing a statistical\nexperiment to optimize the induced distribution of posterior medians, or more\ngenerally $q$-quantiles for any $q \\in (0,1)$. We show that all implementable\ndistributions of the posterior $q$-quantile are implemented by a single\nexperiment, the $q$-quantile matching experiment, which pools pairs of states\nacross the $q$-quantile of the prior in a positively assortative manner, with\nweight $q$ on the lower state in each pair. A dense subset of implementable\ndistributions of posterior $q$-quantiles can be uniquely implemented by\nperturbing the $q$-quantile matching experiment. A linear functional is\noptimized over distributions of posterior $q$-quantiles by taking the optimal\nselection from each set of $q$-quantiles induced by the $q$-quantile matching\nexperiment. The $q$-quantile matching experiment is the only experiment that\nsimultaneously implements all implementable distributions of the posterior\n$q$-quantile.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17142v1"
    },
    {
        "title": "Fuzzy Classification Aggregation",
        "authors": [
            "Federico Fioravanti"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider the problem where a set of individuals has to classify $m$\nobjects into $p$ categories and does so by aggregating the individual\nclassifications. We show that if $m\\geq 3$, $m\\geq p\\geq 2$, and\nclassifications are fuzzy, that is, objects belong to a category to a certain\ndegree, then an optimal and independent aggregator rule that satisfies a weak\nunanimity condition belongs to the family of Weighted Arithmetic Means. We also\nobtain characterization results for $m= p= 2$.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17620v4"
    },
    {
        "title": "Identifying Assumptions and Research Dynamics",
        "authors": [
            "Andrew Ellis",
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A representative researcher has repeated opportunities for empirical\nresearch. To process findings, she must impose an \"identifying assumption.\" She\nconducts research when the assumption is sufficiently plausible (taking into\naccount both current beliefs and the quality of the opportunity), and updates\nbeliefs as if the assumption were perfectly valid. We study the dynamics of\nthis learning process. While the rate of research cannot always increase over\ntime, research slowdown is possible. We characterize environments in which the\nrate is constant. Long-run beliefs can exhibit history-dependence and \"false\ncertitude.\" We apply the model to stylized examples of empirical methodologies:\nexperiments, various causal-inference techniques, and \"calibration.\"\n",
        "pdf_link": "http://arxiv.org/pdf/2402.18713v2"
    },
    {
        "title": "A Continuous-Time Stochastic Model of the Fiscal Theory of the Price\n  Level and Consistency of Its Critique",
        "authors": [
            "Andrey Kofnov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The paper tests the validity of the critique of the fiscal theory of the\nprice level. A stochastic general equilibrium model with continuous time is\nconstructed. An active fiscal policy and a passive monetary policy have been\nset. Monetary policy manages the interest rate through the Taylor rule. The\nstochastic default factor in the special form is introduced. A complete\ndefinite system of equations is obtained for the detection of equilibrium. It\nis asserted that the peculiarities of the approach to modeling are of critical\nimportance for verifying the presence of certain hypotheses and formulating\nconclusions. The results of this work are in support of the fiscal theory of\nthe price level.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.01593v1"
    },
    {
        "title": "Competing Mechanisms in Games Played Through Agents: Theory and\n  Experiment",
        "authors": [
            "Seungjin Han",
            "Andrew Leal"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper proposes Competing Mechanism Games Played Through Agent (CMGPTA),\nan extension of the GPTA (Prat and Rustichini (2003)), where a Principal can\noffer any arbitrary mechanism that specifies a transfer schedule for each agent\nconditional on all Agents' messages. We identify the set of equilibrium\nallocations using deviator-reporting mechanisms (DRMs) on the path and single\ntransfer schedules off the path. We design a lab experiment implementing DRMs.\nWe observe that implemented outcomes are efficient more often than random. A\nmajority of the time, Agents do tell the truth on the identity of a deviating\nPrincipal, despite potential gains from (tacit) collusion on false reports. As\nplay progresses, Agents learn to play with their counterparty Agent with the\naverage predicted probability of collusion on false reports across groups\nincreasing from about 9% at the beginning of the experiment to just under 20%\nby the end. However, group heterogeneity is significant.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03317v3"
    },
    {
        "title": "Two-Person Adversarial Games are Zero-Sum: An Elaboration of a Folk\n  Theorem",
        "authors": [
            "M. Ali Khan",
            "Arthur Paul Pedersen",
            "David Schrittesser"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The observation that every two-person adversarial game is an affine\ntransformation of a zero-sum game is traceable to Luce & Raiffa (1957) and made\nexplicit in Aumann (1987). Recent work of (ADP) Adler et al. (2009), and of\nRaimondo (2023) in increasing generality, proves what has so far remained a\nconjecture. We present two proofs of an even more general formulation: the\nfirst draws on multilinear utility theory developed by Fishburn & Roberts\n(1978); the second is a consequence of the ADP proof itself for a special case\nof a two-player game with a set of three actions.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04029v5"
    },
    {
        "title": "A topological characterization of the existence of w-stable sets",
        "authors": [
            "Athanasios Andrikopoulos",
            "Nikolaos Sampanis"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The theory of optimal choice sets is a solution theory that has a long and\nwell-established tradition in social choice and game theories. Some of\nimportant general solution concepts of choice problems when the set of best\nalternatives does not exist (this problem occurs when the preferences yielded\nby an economic process are cyclic) is the Stable Set (Von Neumann-Morgenstern\nset) and its variants (Generalized Stable set, Extended Stable set, m-Stable\nset and w-Stable set). The theory of w-stable sets solution is more realistic\nbecause: (1) It solves the existence problem of solution; (2) It expands the\nnotions of maximal alternative set and (3) The concept of stability is defined\nin such a way as to prevent a chosen alternative from being dominated by\nanother alternative and sets this stability within the solution. In this paper,\nwe present a topological characterization of the existence of w-Stable sets\nsolution of arbitrary binary relations over non-finite sets of alternatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04512v1"
    },
    {
        "title": "Can One Hear the Shape of a Decision Problem?",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We explore the connection between an agent's decision problem and her ranking\nof information structures. We find that a finite amount of ordinal data on the\nagent's ranking of experiments is enough to identify her (finite) set of\nundominated actions (up to relabeling and duplication) and the beliefs\nrendering each such action optimal. An additional smattering of cardinal data,\ncomparing the relative value to the agent of finitely many pairs of\nexperiments, identifies her utility function up to an action-independent\npayoff.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06344v2"
    },
    {
        "title": "Success functions in large contests",
        "authors": [
            "Yaron Azrieli",
            "Christopher P. Chambers"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider contests with a large set (continuum) of participants and\naxiomatize contest success functions that arise when performance is composed of\nboth effort and a random element, and when winners are those whose performance\nexceeds a cutoff determined by a market clearing condition. A co-monotonicity\nproperty is essentially all that is needed for a representation in the general\ncase, but significantly stronger conditions must hold to obtain an additive\nstructure. We illustrate the usefulness of this framework by revisiting some of\nthe classic questions in the contests literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.07152v2"
    },
    {
        "title": "Collusive Outcomes Without Collusion",
        "authors": [
            "Inkoo Cho",
            "Noah Williams"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We develop a model of algorithmic pricing that shuts down every channel for\nexplicit or implicit collusion while still generating collusive outcomes. We\nanalyze the dynamics of a duopoly market where both firms use pricing\nalgorithms consisting of a parameterized family of model specifications. The\nfirms update both the parameters and the weights on models to adapt\nendogenously to market outcomes. We show that the market experiences recurrent\nepisodes where both firms set prices at collusive levels. We analytically\ncharacterize the dynamics of the model, using large deviation theory to explain\nthe recurrent episodes of collusive outcomes. Our results show that collusive\noutcomes may be a recurrent feature of algorithmic environments with\ncomplementarities and endogenous adaptation, providing a challenge for\ncompetition policy.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.07177v1"
    },
    {
        "title": "Score-based mechanisms",
        "authors": [
            "Eduardo Perez-Richet",
            "Vasiliki Skreta"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We propose a mechanism design framework that incorporates both soft\ninformation, which can be freely manipulated, and semi-hard information, which\nentails a cost for falsification. The framework captures various contexts such\nas school choice, public housing, organ transplant and manipulations of\nclassification algorithms. We first provide a canonical class of mechanisms for\nthese settings. The key idea is to treat the submission of hard information as\nan observable and payoff-relevant action and the contractible part of the\nmechanism as a mapping from submitted scores to a distribution over decisions\n(a score-based decision rule). Each type report triggers a distribution over\nscore submission requests and a distribution over decision rules. We provide\nconditions under which score-based mechanisms are without loss of generality.\nIn other words, situations under which the agent does not make any type reports\nand decides without a mediator what score to submit in a score-based decision\nrule. We proceed to characterize optimal approval mechanisms in the presence of\nmanipulable hard information. In several leading settings optimal mechanisms\nare score-based (and thus do not rely on soft information) and involve costly\nscreening. The solution methodology we employ is suitable both for concave cost\nfunctions and quadratic costs and is applicable to a wide range of contexts in\neconomics and in computer science.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08031v1"
    },
    {
        "title": "Tournament Auctions",
        "authors": [
            "Luca Anderlini",
            "GaOn Kim"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine ``tournament'' second-price auctions in which $N$ bidders compete\nfor the right to participate in a second stage and contend against bidder\n$N+1$. When the first $N$ bidders are committed so that their bids cannot be\nchanged in the second stage, the analysis yields some unexpected results. The\nfirst $N$ bidders consistently bid above their values in equilibrium. When\nbidder $N+1$ is sufficiently stronger than the first $N$, overbidding leads to\nan increase in expected revenue in comparison to the standard second-price\nauction when $N$ is large.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08102v1"
    },
    {
        "title": "The social value of overreaction to information",
        "authors": [
            "Matteo Bizzarri",
            "Daniele d'Arienzo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the welfare effects of overreaction to information in the form of\ndiagnostic expectations in markets with asymmetric information, and the effect\nof a simple intervention in the form of a tax or a subsidy. A large enough\nlevel of overreaction is always welfare-decreasing and can rationalize a tax on\nfinancial transactions. A small degree of overreaction to private information\ncan both increase or decrease welfare. This is because there are two competing\nexternalities: an information externality, due to the informational role of\nprices, and a pecuniary externality, due to the allocative role of prices. When\nthe information externality prevails on the pecuniary externality, the loading\non private information in agents' trades is too small compared to the welfare\noptimum: in this case, a small degree of overreaction is welfare-improving.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08532v1"
    },
    {
        "title": "News Media as Suppliers of Narratives (and Information)",
        "authors": [
            "Kfir Eliaz",
            "Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We present a model of news media that shape consumer beliefs by providing\ninformation (signals about an exogenous state) and narratives (models of what\ndetermines outcomes). To amplify consumers' engagement, media maximize\nconsumers' anticipatory utility. Focusing on a class of separable consumer\npreferences, we show that a monopolistic media platform facing homogenous\nconsumers provides a false \"empowering\" narrative coupled with an\noptimistically biased signal. Consumer heterogeneity gives rise to a novel\nmenu-design problem due to a \"data externality\" among consumers. The optimal\nmenu features multiple narratives and creates polarized beliefs. These effects\nalso arise in a competitive media market model.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.09155v1"
    },
    {
        "title": "Irrational Random Utility Models",
        "authors": [
            "Daniele Caliari",
            "Henrik Petri"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We show that the set of aggregate choices of a population of rational\ndecision-makers - random utility models (RUMs) - can be represented by a\npopulation of irrational ones if, and only if, their preferences are\nsufficiently uncorrelated. We call this representation: Irrational RUM. We then\nshow that almost all RUMs can be represented by a population in which at least\nsome decision-makers are irrational and that under specific conditions their\nirrational behavior is unconstrained.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.10208v1"
    },
    {
        "title": "Speed, Accuracy, and Complexity",
        "authors": [
            "Duarte Gonçalves"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper re-examines the use of response time to infer problem complexity.\nIt revisits a canonical Wald model of optimal stopping, taking signal-to-noise\nratio as a measure of problem complexity. While choice quality is monotone in\nproblem complexity, expected stopping time is inverse U-shaped. Indeed,\ndecisions are fast in both very simple and very complex problems: in simple\nproblems, it is quick to understand which alternative is best, while in complex\nproblems it would be too costly -- an insight which extends to general costly\ninformation acquisition models. This non-monotonicity also underlies an\nambiguous relationship between response time and ability, whereby higher\nability entails slower decisions in very complex problems, but faster decisions\nin simple problems. Finally, this paper proposes a new method to correctly\ninfer problem complexity based on the finding that distorting incentives in\nfavour of an alternative has a greater effect on choices in more complex\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.11240v3"
    },
    {
        "title": "When is Trust Robust?",
        "authors": [
            "Luca Anderlini",
            "Larry Samuelson",
            "Daniele Terlizzese"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine an economy in which interactions are more productive if agents can\ntrust others to refrain from cheating. Some agents are scoundrels, who cheat at\nevery opportunity, while others cheat only if the cost of cheating, a\ndecreasing function of the proportion of cheaters, is sufficiently low. The\neconomy exhibits multiple equilibria. As the proportion of scoundrels in the\neconomy declines, the high-trust equilibrium can be disrupted by arbitrarily\nsmall perturbations or by arbitrarily small infusions of low-trust agents,\nwhile the low-trust equilibrium becomes impervious to perturbations and\ninfusions of high-trust agents. Scoundrels may thus have the effect of making\ntrust more robust.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.12917v2"
    },
    {
        "title": "On Equilibrium Determinacy in Overlapping Generations Models with Money",
        "authors": [
            "Tomohiro Hirano",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper provides a detailed analysis of the local determinacy of monetary\nand non-monetary steady states in Tirole (1985)'s classical two-period\noverlapping generations model with capital and production. We show that the\nsufficient condition for local determinacy in endowment economies provided by\nScheinkman (1980) does not generalize to models with production: there are\nrobust examples with arbitrary utility functions in which the non-monetary\nsteady state is locally determinate or indeterminate. In contrast, the monetary\nsteady state is locally determinate under fairly weak conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13222v1"
    },
    {
        "title": "The Limits of Identification in Discrete Choice",
        "authors": [
            "Christopher P. Chambers",
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper uncovers tight bounds on the number of preferences permissible in\nidentified random utility models. We show that as the number of alternatives in\na discrete choice model becomes large, the fraction of preferences admissible\nin an identified model rapidly tends to zero. We propose a novel sufficient\ncondition ensuring identification, which is strictly weaker than some of those\nexisting in the literature. While this sufficient condition reaches our upper\nbound, an example demonstrates that this condition is not necessary for\nidentification. Using our new condition, we show that the classic ``Latin\nSquare\" example from social choice theory is identified from stochastic choice\ndata.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13773v3"
    },
    {
        "title": "Robust Communication Between Parties with Nearly Independent Preferences",
        "authors": [
            "Alistair Barton"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study finite-state communication games in which the sender's preference is\nperturbed by random private idiosyncrasies. Persuasion is generically\nimpossible within the class of statistically independent sender/receiver\npreferences -- contrary to prior research establishing persuasive equilibria\nwhen the sender's preference is precisely transparent.\n  Nevertheless, robust persuasion may occur when the sender's preference is\nonly slightly state-dependent/idiosyncratic. This requires approximating an\n`acyclic' equilibrium of the transparent preference game, generically implying\nthat this equilibrium is also `connected' -- a generalization of\npartial-pooling equilibria. It is then necessary and sufficient that the\nsender's preference satisfy a monotonicity condition relative to the\napproximated equilibrium.\n  If the sender's preference further satisfies a `semi-local' version of\nincreasing differences, then this analysis extends to sender preferences that\nrank pure actions (but not mixed actions) according to a state-independent\norder.\n  We apply these techniques to study (1) how ethical considerations, such as\nempathy for the receiver, may improve or impede comm\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13983v1"
    },
    {
        "title": "Discounted Subjective Expected Utility in Continuous Time",
        "authors": [
            "Lorenzo Bastianello",
            "Vassili Vergopoulos"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  By embedding uncertainty into time, we obtain a conjoint axiomatic\ncharacterization of both Exponential Discounting and Subjective Expected\nUtility that accommodates arbitrary state and outcome spaces. In doing so, we\nprovide a novel and simple time-interpretation of subjective probability. The\nsubjective probability of an event is calibrated using time discounting.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.15319v1"
    },
    {
        "title": "Risk Propagation in Endogenous Supply Chains",
        "authors": [
            "Andrea Titton"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper investigates the endogenous formation of supply chains and its\nconsequences for disruption propagation. In production networks where upstream\nrisk is highly correlated and supplier relationships are not observable, the\nmarginal risk reduction of adding an additional supplier is low, because this\nadditional supplier's risk is likely to be correlated to that of the firm's\nexisting suppliers. This channel reduces firm incentives to diversify, which\ngives rise to inefficiently fragile production networks.\n  By solving the social planner problem, I show that, if the risk reduction\nexperienced downstream resulting from upstream diversification were to be\ninternalised by upstream firms, endogenous production networks would be\nresilient to most levels of risk. Furthermore, I show that imperfect\ninformation yields inefficient but more robust supply chains. Despite its\nstylised form, the model identifies the trade-off firms face when diversifying\nrisk and isolates the mechanism that aggregates these decisions into a\nproduction network. Furthermore, it maps the conditions of the trade-off, such\nas expected profits of the firm or the sourcing costs, to the properties of the\nproduction network.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16632v2"
    },
    {
        "title": "Share the Sugar",
        "authors": [
            "Christian Tarsney",
            "Harvey Lederman",
            "Dean Spears"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We provide a general argument against value incomparability, based on a new\nstyle of impossibility result. In particular, we show that, against plausible\nbackground assumptions, value incomparability creates an incompatibility\nbetween two very plausible principles for ranking lotteries: a weak ``negative\ndominance'' principle (to the effect that Lottery 1 can be better than Lottery\n2 only if some possible outcome of Lottery 1 is better than some possible\noutcome of Lottery 2) and a weak form of ex ante Pareto (to the effect that, if\nLottery 1 gives an unambiguously better prospect to some individuals than\nLottery 2, and equally good prospects to everyone else, then Lottery 1 is\nbetter than Lottery 2). After spelling out our results, and the arguments based\non them, we consider which principle the proponent of incomparability ought to\nreject.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.17641v1"
    },
    {
        "title": "Learning Optimal Behavior Through Reasoning and Experiences",
        "authors": [
            "Cosmin Ilut",
            "Rosen Valchev"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We develop a novel framework of bounded rationality under cognitive frictions\nthat studies learning over optimal behavior through both deliberative reasoning\nand accumulated experiences. Using both types of information, agents engage in\nBayesian non-parametric estimation of the unknown action value function.\nReasoning signals are produced internally through mental deliberation, subject\nto a cognitive cost. Experience signals are the observed utility outcomes at\nprevious actions. Agents' subjective estimation uncertainty, which evolves\nthrough information accumulation, modulates the two modes of learning in a\nstate- and history-dependent way. We discuss how the model draws on and bridges\nconceptual, methodological and empirical insights from both economics and the\ncognitive sciences literature on reinforcement learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.18185v1"
    },
    {
        "title": "Designing Simple Mechanisms",
        "authors": [
            "Shengwu Li"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Which mechanisms are simple to play? When is it easy for participants to see\nthat a mechanism is incentive-compatible? I will start by explaining how and\nwhy economists came to ask these questions. Then I will discuss three recent\nanswers, that capture different aspects of what makes a mechanism simple.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.18694v3"
    },
    {
        "title": "Optimal Auction Design with Contingent Payments and Costly Verification",
        "authors": [
            "Ian Ball",
            "Teemu Pekkarinen"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the design of an auction for an income-generating asset such as an\nintellectual property license. Each bidder has a signal about his future income\nfrom acquiring the asset. After the asset is allocated, the winner's income is\nrealized privately. The principal can audit the winner, at a cost, and then\ncharge a payment contingent on the winner's realized income. We solve for a\ndynamic mechanism that maximizes revenue, net auditing costs. The winning\nbidder is charged linear royalties up to a cap. A higher bidder pays more in\ncash and faces a lower royalty cap.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.19945v3"
    },
    {
        "title": "Call the Dentist! A (Con-)Cavity in the Value of Information",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A natural way of quantifying the ``amount of information'' in decision\nproblems yields a globally concave value for information. Another (in contrast,\nadversarial) way almost never does.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01190v1"
    },
    {
        "title": "Equilibrium in Style: A Modeling Framework on the Cash Flow and the Life\n  Cycle of a Consumer Store",
        "authors": [
            "Shanyu Han",
            "Jian Lei",
            "Yang Liu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The consumer store is ubiquitous and plays an important role in our everyday\nlives. It is an open question why stores usually have such short life cycles\n(typically around 3 years in China). This paper proposes a theoretical\nframework based on an equilibrium in style supply of stores and style demand of\nconsumers to characterize store cash flow (revenue), leading to a strong\nexplanation of this puzzle. In our model, we derive that the preference\nshifting of consumers is the main reason for the cash flow decreasing to its\nbreak-even line over time, while the visibility broadening leads to initial\ngrowth, resulting in rainbow-shaped cash flow and its life cycle. Moreover, the\nintensified spatial competition will lead to an unexpected decrease in the\nstore's cash flow, or even closure. We calibrate our model with proprietary\ndata of three Chinese stores from three representative industries and study the\nrelationship between customers' preference shifting and cash flow. To our\nknowledge, there have been no prior attempts to quantitatively model the life\ncycle of the store.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02426v2"
    },
    {
        "title": "Farkas' Lemma and Complete Indifference",
        "authors": [
            "Florian Herold",
            "Christoph Kuzmics"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In a finite two player game consider the matrix of one player's payoff\ndifference between any two consecutive pure strategies. Define the half space\ninduced by a column vector of this matrix as the set of vectors that form an\nobtuse angle with this column vector. We use Farkas' lemma to show that this\nplayer can be made indifferent between all pure strategies if and only if the\nunion of all these half spaces covers the whole vector space. This result leads\nto a necessary (and almost sufficient) condition for a game to have a\ncompletely mixed Nash equilibrium. We demonstrate its usefulness by providing\nthe class of all symmetric two player three strategy games that have a unique\nand completely mixed symmetric Nash equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02620v1"
    },
    {
        "title": "Chasing Contests",
        "authors": [
            "Zhuo Chen",
            "Yun Liu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper proposes a dynamic research contest, namely chasing contest, in\nwhich two asymmetric contestants exert costly effort to accomplish two\nbreakthroughs. The contestants are asymmetric in that one of them is\npresent-biased and has already achieved one breakthrough (the leader), whereas\nthe other is time-consistent and needs to achieve two breakthroughs to win (the\nchaser). The principal can choose between two disclosure policies: immediately\nannouncing the chaser's first breakthrough (public chasing contest) or\nannouncing only the final result (hidden chasing contest). We characterize the\nunique x-start and y-stop equilibrium under both disclosure policies, in which\nthe leader starts working from an instant x to the end while the chaser stops\nexerting effort by the instant y. In addition, the chaser will never stop\nearlier in the hidden chasing contest, whereas a late deadline extends the\nleader's effort in the public contest.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02756v2"
    },
    {
        "title": "Productivity and quality-adjusted life years: QALYs, PALYs and beyond",
        "authors": [
            "Kristian S. Hansen",
            "Juan D. Moreno-Ternero",
            "Lars P. Østerdal"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We develop a unified framework for the measurement and valuation of health\nand productivity. Within this framework, we characterize evaluation functions\nallowing for compromises between the classical quality-adjusted life years\n(QALYs) and its polar productivity-adjusted life years (PALYs). Our framework\nand characterization results provide a new normative basis for the economic\nevaluation of health care interventions, as well as occupational health and\nsafety policies, aimed to impact both health and productivity of individuals.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.04121v1"
    },
    {
        "title": "Money Pumps and Bounded Rationality",
        "authors": [
            "Joshua Lanier",
            "Matthew Polisson",
            "John K. -H. Quah"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The standard criterion of rationality in economics is the maximization of a\nutility function that is stable across multiple observations of an agent's\nchoice behavior. In this paper, we discuss two notions of the money pump that\ncharacterize two corresponding notions of utility-maximization. We explain the\nsenses in which the amount of money that can be pumped from a consumer is a\nuseful measure of the consumer's departure from utility-maximization.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.04843v1"
    },
    {
        "title": "Information Sale on Network",
        "authors": [
            "Jihwan Do",
            "Lining Han",
            "Xiaoxi Li"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies a stylized model of a monopoly data seller when\ninformation-sharing network exists among data buyers. We show that, if the\nbuyers' prior information is sufficiently noisy, the optimal selling strategy\nis characterized by a maximum independent set, which is the largest set of\nbuyers who do not have information-sharing link at all. In addition, the\nprecision of the seller's data decreases in the number of information-sharing\nlinks among buyers, but it is higher than the socially efficient level of\nprecision.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.05546v1"
    },
    {
        "title": "Robust Pricing for Quality Disclosure",
        "authors": [
            "Tan Gan",
            "Hongcheng Li"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A platform charges a producer for disclosing hard evidence of product quality\nto a consumer before trading. To tackle strategic uncertainty, the platform\noffers the producer quality-dependent and disclosure probability-dependent\nprices to maximize its revenue guarantee across all equilibria. The platform\noptimally offers off-path disclosure options to incentivize each producer type\nto \"conquer herself\" by deviating continually to full disclosure, yielding\nstrictly convex advertising price functions of disclosure probability.\nMoreover, the platform prioritizes attracting higher types into service and\noffers them higher rents despite the absence of adverse selection. Comparative\nstatics demonstrate that more informative hard evidence increases the\nplatform's revenue guarantee.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.06019v2"
    },
    {
        "title": "Istanbul Flower Auction: The Need for Speed",
        "authors": [
            "Isa Hafalir",
            "Onur Kesten",
            "Donglai Luo",
            "Katerina Sherstyuk",
            "Cong Tao"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine a unique auction format used in the Istanbul flower market, which\ncould transform into either Dutch or English auction depending on bidders'\nbidding behaviors. By introducing a time cost that reduces the value of a\nperishable good as time passes, we explore how this hybrid auction format\naccommodates the desire for speed via an adaptive starting price. We show that\nthe Istanbul Flower Auction outperforms both the Dutch and English auctions in\nterms of the auctioneer's utility. With numerical analysis, we also illustrate\nthe Istanbul Flower Auction's superiority in terms of social welfare and\nauction duration. Our results highlight the critical role of auction design in\nimproving welfare when the duration of the auction process plays a role.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.08288v2"
    },
    {
        "title": "Competition for Budget-Constrained Buyers: Exploring All-Pay Auctions",
        "authors": [
            "Cemil Selcuk"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This note pursues two primary objectives. First, we analyze the outcomes of\nan all-pay auction within a store where buyers with and without financial\nconstraints arrive at varying rates, and where buyer types are private\ninformation. Second, we investigate the selection of an auction format\n(comprising first-price, second-price, and all-pay formats) in a competitive\nsearch setting, where sellers try to attract customers. Our results indicate\nthat if the budget constraint is not too restrictive, the all-pay rule emerges\nas the preferred selling format in the unique symmetric equilibrium. This is\nthanks to its ability to prompt buyers to submit lower bids, thereby generally\navoiding budget constraints, while allowing the seller to collect all bids.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.08762v1"
    },
    {
        "title": "Long run consequence of p-hacking",
        "authors": [
            "Xuanye Wang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the theoretical consequence of p-hacking on the accumulation of\nknowledge under the framework of mis-specified Bayesian learning. A sequence of\nresearchers, in turn, choose projects that generate noisy information in a\nfield. In choosing projects, researchers need to carefully balance as projects\ngenerates big information are less likely to succeed. In doing the project, a\nresearcher p-hacks at intensity $\\varepsilon$ so that the success probability\nof a chosen project increases (unduly) by a constant $\\varepsilon$. In\ninterpreting previous results, researcher behaves as if there is no p-hacking\nbecause the intensity $\\varepsilon$ is unknown and presumably small. We show\nthat over-incentivizing information provision leads to the failure of learning\nas long as $\\varepsilon\\neq 0$. If the incentives of information provision is\nproperly provided, learning is correct almost surely as long as $\\varepsilon$\nis small.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.08984v1"
    },
    {
        "title": "More, better or different? Trade-offs between group size and competence\n  development in jury theorems",
        "authors": [
            "Gustaf Arrhenius",
            "Klas Markström"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In many circumstances there is a trade off between the number of voters and\nthe time they can be given before having to make a decision since both aspects\nare costly. An example is the hiring of a committee with a fixed salary budget:\nmore people but a shorter time for each to develop their competence about the\nissue at hand or less people with a longer time for competence development? In\nthis paper we investigate the interaction between the number of voters, the\ndevelopment of their competence over time and the final probability for an\noptimal majority decision. Among other things we consider how different\nlearning profiles, or rates of relevant competence increase, for the members of\na committee affects the optimal committee size.\n  To the best of our knowledge, our model is the first that includes the\npotentially positive effects of having a heterogeneous group of voters on\nmajority decisions in a satisfactory way. We also discuss how some earlier\nattempts fail to capture the effect of heterogeneity correctly.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09523v1"
    },
    {
        "title": "A note on heterogeneity, trade integration and spatial inequality",
        "authors": [
            "José M. Gaspar"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the impact of economic integration on spatial development in a model\nwhere all consumers are inter-regionally mobile and have heterogeneous\npreferences regarding their residential location choices. This heterogeneity is\nthe unique dispersion force in the model. We show that, under reasonable values\nfor the elasticity of substitution among varieties of consumption goods, a\nhigher trade integration always promotes more symmetric patterns, irrespective\nof the functional form of the dispersion force. We also show that an increase\nin the degree of heterogeneity in preferences for location leads to less\nspatial inequality.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09796v1"
    },
    {
        "title": "Intergenerational Insurance",
        "authors": [
            "Francesco Lancia",
            "Alessia Russo",
            "Tim Worrall"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  How should successive generations insure each other when the young can\ndefault on previously promised transfers to the old? This paper studies\nintergenerational insurance that maximizes the expected discounted utility of\nall generations subject to participation constraints for each generation. If\ncomplete insurance is unattainable, the optimal intergenerational insurance is\nhistory-dependent even when the environment is stationary. The risk from a\ngenerational shock is spread into the future, with periodic resetting.\nInterpreting intergenerational insurance in terms of debt, the fiscal reaction\nfunction is nonlinear and the risk premium on debt is lower than the risk\npremium with complete insurance.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.10090v1"
    },
    {
        "title": "The Relationship between Consumer Theories with and without Utility\n  Maximization",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  To study the assumption that the utility maximization hypothesis implicitly\nadds to consumer theory, we consider a mathematical representation of\npre-marginal revolution consumer theory based on subjective exchange ratios. We\nintroduce two axioms on subjective exchange ratio, and show that both axioms\nhold if and only if consumer behavior is consistent with the utility\nmaximization hypothesis. Moreover, we express the process for a consumer to\nfind the transaction stopping point in terms of differential equations, and\nprove that the conditions for its stability are equal to the two axioms\nintroduced in the above argument. Therefore, the consumer can find his/her\ntransaction stopping point if and only if his/her behavior is consistent with\nthe utility maximization hypothesis. In addition to these results, we discuss\nequivalence conditions for axioms to evaluate their mathematical strength, and\nmethods for expressing the theory of subjective exchange ratios in terms of\nbinary relations.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.10931v1"
    },
    {
        "title": "Optimal Refund Mechanism with Consumer Learning",
        "authors": [
            "Qianjun Lyu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies the optimal refund mechanism when an uninformed buyer can\nprivately acquire information about his valuation of a product over time. We\nconsider a class of refund mechanisms based on stochastic return policies: if\nthe buyer requests a return, the seller will issue a (partial) refund while\nallowing the buyer to keep the product with some probability. Such return\npolicies can affect the buyer's learning process and thereby influence the\nreturn rate. Nevertheless, we show that the optimal refund mechanism is\ndeterministic and takes a simple form: either the seller offers a sufficiently\nlow price and disallows returns to deter buyer learning, or she offers a\nsufficiently high price with free returns to implement maximal buyer learning.\nThe form of the optimal refund mechanism is non-monotone in the buyer's prior\nbelief regarding his valuation.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.14927v1"
    },
    {
        "title": "Maximal Procurement under a Budget",
        "authors": [
            "Nicole Immorlica",
            "Nicholas Wu",
            "Brendan Lucier"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the problem of a principal who wants to influence an agent's\nobservable action, subject to an ex-post budget. The agent has a private type\ndetermining their cost function. This paper endogenizes the value of the\nresource driving incentives, which holds no inherent value but is restricted by\nfinite availability. We characterize the optimal mechanism, showing the\nemergence of a pooling region where the budget constraint binds for low-cost\ntypes. We then introduce a linear value for the transferable resource; as the\nprincipal's value increases, the mechanism demands more from agents with\nbinding budget constraint but less from others.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.15531v1"
    },
    {
        "title": "Disappointment concordance and duet expectiles",
        "authors": [
            "Fabio Bellini",
            "Tiantian Mao",
            "Ruodu Wang",
            "Qinyu Wu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We introduce an axiom of disappointment-concordance (disco) aversion for a\npreference relation over acts in an Anscombe-Aumann setting. This axiom means\nthat the decision maker, facing the sum of two acts, dislikes the situation\nwhere both acts realize simultaneously as disappointments. Our main result is\nthat, under strict monotonicity and continuity, the axiom of disco aversion\ncharacterizes preference relations represented by a new class of functionals\nbelonging to the Gilboa-Schmeidler family, which we call the duet expectiled\nutilities. When the outcome space is the real line, a duet expectiled utility\nbecomes a duet expectile, which involves two endogenous probability measures.\nIt further becomes a usual expectile, ,a statistical quantity popular in\nregression and risk measures, when these two probability measures coincide. We\ndiscuss properties of duet expectiles and connections with fundamental concepts\nincluding probabilistic sophistication, risk aversion, and uncertainty\naversion.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17751v2"
    },
    {
        "title": "Domar aggregation under nonneutral elasticity of substitution",
        "authors": [
            "Satoshi Nakano",
            "Kazuhiko Nishimura"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The characteristics inherent in a Domar aggregation, when all sectoral\nproductions embody a common nonneutral elasticity of substitution, is examined.\nThere, the general equilibrium propagation of productivity changes entails\nstructural transformation that brings nonlinearities in their aggregation into\nprice indices. We show that negative singularity, such that a finite\nproductivity decrease induces an infinitely large price, is possible in an\ninelastic economy, while positive singularity, such that a finite productivity\nincrease induces a zero price, is possible in an elastic economy. Regarding the\naggregate outputs, two independent productivity changes will have synergism in\nan elastic economy, whereas negative synergism will be prevalent in an\ninelastic economy. Neither issue is of concern in a Cobb-Douglas economy where\nthe elasticity of substitution is everywhere neutral.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.18137v1"
    },
    {
        "title": "Reputation in Repeated Global Games of Regime Change with Exit",
        "authors": [
            "Daniel Luo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study a repeated binary-action supermodular game with endogenous exit where\nmany short-lived agents attempt to coordinate a revolt against a regime. The\nregime undertakes costly actions to increase the short-run players'\ncoordination frictions, though acts only after if the revolt is unsuccessful,\ninducing a lack-of-commitment problem. In the complete-information repeated\ngame, a folk theorem holds, with payoff multiplicity arising due to both the\nregime's dynamic incentives and agents' stage-game strategic complementarities.\nNeither the regime's reputational incentives nor belief dispersion among agents\n(via global-games type uncertainty) alone meaningfully refine the equilibrium\npayoff set. Together, though, the interaction between these two forces uniquely\nselect the regime's highest payoff in equilibrium. Furthermore, under a Markov\nrefinement, they select a unique equilibrium where the regime plays their\noptimal commitment action. Methodologically, I develop tools to analyze\nrepeated games with endogenous exit where the regime's commitment action\nflexibly varies with their discount rate.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.18884v1"
    },
    {
        "title": "Persuasion in Networks: Can the Sender Do Better than Using Public\n  Signals?",
        "authors": [
            "Yifan Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Political and advertising campaigns increasingly exploit social networks to\nspread information and persuade people. This paper studies a persuasion model\nto examine whether such a strategy is better than simply sending public\nsignals. Receivers in the model have heterogeneous priors and will pass on a\nsignal if they are persuaded by it to take sender's preferred action. I show\nthat a risk neutral or risk loving sender prefers to use public signals, unless\nmore skeptical receivers are sufficiently more connected in the network. A risk\naverse sender may prefer to exploit the network. These results still hold when\nthe network exhibits homophily.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.18965v2"
    },
    {
        "title": "Level-$k$ Reasoning, Cognitive Hierarchy, and Rationalizability",
        "authors": [
            "Shuige Liu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We employ a unified framework to provide an epistemic-theoretical foundation\nfor Camerer, Ho, and Chong's (2003) cognitive hierarchy (CH) solution and its\ndynamic extension, using the directed rationalizability concept introduced in\nBattigalli and Siniscalchi (2003). We interpret level-$k$ as an information\ntype instead of specification of strategic sophistication, and define\nrestriction $ \\Delta^\\kappa$ on the beliefs of information types; based on it,\nwe show that in the behavioral consequence of rationality, common belief in\nrationality and transparency of $\\Delta^\\kappa$, called\n$\\Delta^\\kappa$-rationalizability, the strategic sophistication of each\ninformation type is endogenously determined. We show that in static games, the\nCH solution generically coincides with $\\Delta^\\kappa$-rationalizability; this\nresult also connects CH with Bayesian equilibrium. By extending $\\Delta^\\kappa$\nto dynamic games, we show that Lin and Palfrey's (2024) dynamic cognitive\nhierarchy (DCH) solution, an extension of CH in dynamic games, generically\ncoincides with the behavioral consequence of rationality, common strong belief\nin rationality, and transparency of (dynamic) $\\Delta^\\kappa$. The same\nframework can also be used to analyze many variations of CH in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.19623v3"
    },
    {
        "title": "A Taste for Variety",
        "authors": [
            "Galit Ashkenazi-Golan",
            "Dominik Karos",
            "Ehud Lehrer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A decision maker repeatedly chooses one of a finite set of actions. In each\nperiod, the decision maker's payoff depends on fixed basic payoff of the chosen\naction and the frequency with which the action has been chosen in the past. We\nanalyze optimal strategies associated with three types of evaluations of\ninfinite payoffs: discounted present value, the limit inferior, and the limit\nsuperior of the partial averages. We show that when the first two are the\nevaluation schemes, a stationary strategy can always achieve the best possible\noutcome. However, for the latter evaluation scheme, a stationary strategy can\nachieve the best outcome only if all actions that are chosen with strictly\npositive frequency by an optimal stationary strategy have the same basic\npayoff.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.00561v1"
    },
    {
        "title": "Dynamic opinion updating with endogenous networks",
        "authors": [
            "Ugo Bolletta",
            "Paolo Pin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Polarization is a well-documented phenomenon across a wide range of social\nissues. However, prevailing theories often compartmentalize the examination of\nherding behavior and opinion convergence within different contexts. In this\nstudy, we delve into the micro-foundations of how individuals strategically\nselect reference groups, offering insight into a dynamic process where both\nindividual opinions and the network evolve simultaneously. We base our model on\ntwo parameters: people's direct benefit from connections and their adaptability\nin adjusting their opinions. Our research highlights which conditions impede\nthe network from achieving complete connectivity, resulting in enduring\npolarization. Notably, our model also reveals that polarization can transiently\nemerge during the transition towards consensus. We explore the connection\nbetween these scenarios and a critical network metric: the initial diameter,\nunder specific conditions related to the initial distribution of opinions.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.01341v1"
    },
    {
        "title": "Manipulation of Belief Aggregation Rules",
        "authors": [
            "Christopher P. Chambers",
            "Federico Echenique",
            "Takashi Hayashi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies manipulation of belief aggregation rules in the setting\nwhere the society first collects individual's probabilistic opinions and then\nsolves a public portfolio choice problem with common utility based on the\naggregate belief.\n  First, we show that belief reporting in Nash equilibrium under the linear\nopinion pool and log utility is identified as the profile of state-contingent\nwealth shares in parimutuel equilibrium with risk-neutral preference.\n  Then we characterize belief aggregation rules which are Nash-implementable.\nWe provide a necessary and essentially sufficient condition for\nimplementability, which is independent of the common risk attitude.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.01655v1"
    },
    {
        "title": "Turning the Ratchet: Dynamic Screening with Multiple Agents",
        "authors": [
            "Mehmet Ekmekci",
            "Lucas Maestri",
            "Dong Wei"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a dynamic contracting problem with multiple agents and a lack of\ncommitment. A principal who can only commit to one-period contracts wants to\nscreen efficient agents over time. Once an agent reveals his type, the\nprincipal becomes tempted to revise contract terms, causing a \"ratchet effect.\"\nAlterations of contracts are observable and, hence, whenever past promises are\nnot honored future information revelation stops. We provide a necessary and\nsufficient condition under which the principal is able to foster information\nrevelation. When players are sufficiently patient, the agents' private\ninformation is either never revealed or fully revealed in a sequential manner.\nOptimal contracts entail high-powered incentives after an agent's type is\ninitially disclosed, and rewards for information revelation disappear in the\nlong run.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04468v1"
    },
    {
        "title": "Predictive Enforcement",
        "authors": [
            "Yeon-Koo Che",
            "Jinwoo Kim",
            "Konrad Mierendorff"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study law enforcement guided by data-informed predictions of \"hot spots\"\nfor likely criminal offenses. Such \"predictive\" enforcement could lead to data\nbeing selectively and disproportionately collected from neighborhoods targeted\nfor enforcement by the prediction. Predictive enforcement that fails to account\nfor this endogenous \"datafication\" may lead to the over-policing of\ntraditionally high-crime neighborhoods and performs poorly, in particular, in\nsome cases as poorly as if no data were used. Endogenizing the incentives for\ncriminal offenses identifies additional deterrence benefits from the\ninformationally efficient use of data.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04764v2"
    },
    {
        "title": "Designing Social Learning",
        "authors": [
            "Aleksei Smirnov",
            "Egor Starkov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies strategic communication in the context of social learning.\nProduct reviews are used by consumers to learn product quality, but in order to\nwrite a review, a consumer must be convinced to purchase the item first. When\nreviewers care about welfare of future consumers, this leads to a conflict: a\nreviewer today wants the future consumers to purchase the item even when this\ncomes at a loss to them, so that more information is revealed for the consumers\nthat come after. We show that due to this conflict, communication via reviews\nis inevitably noisy, regardless of whether reviewers can commit to a\ncommunication strategy or have to resort to cheap talk. The optimal\ncommunication mechanism involves truthful communication of extreme experiences\nand pools the moderate experiences together.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.05744v3"
    },
    {
        "title": "Credit, Land Speculation, and Long-Run Economic Growth",
        "authors": [
            "Tomohiro Hirano",
            "Joseph E. Stiglitz"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper presents a model that studies the impact of credit expansions\narising from increases in collateral values or lower interest rate policies on\nlong-run productivity and economic growth in a two-sector endogenous growth\neconomy, with the driver of growth lying in one sector (manufacturing) but not\nin the other (real estate). We show that it is not so much aggregate credit\nexpansion that matters for long-run productivity and economic growth but\nsectoral credit expansions. Credit expansions associated mainly with relaxation\nof real estate financing (capital investment financing) will be\nproductivity-and growth-retarding (enhancing). Without financial regulations,\nlow interest rates and more expansionary monetary policy may so encourage land\nspeculation using leverage that productive capital investment and economic\ngrowth are decreased. Unlike in standard macroeconomic models, in ours, the\nequilibrium price of land will be finite even if the safe rate of interest is\nless than the rate of output growth.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.05901v1"
    },
    {
        "title": "The geometry of consumer preference aggregation",
        "authors": [
            "Fedor Sandomirskiy",
            "Philip Ushchev"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We revisit a classical question of how individual consumer preferences and\nincomes shape aggregate behavior. We develop a method that applies to\npopulations with homothetic preferences and reduces the hard problem of\naggregation to simply computing a weighted average in the space of logarithmic\nexpenditure functions. We apply the method to identify aggregation-invariant\npreference domains, characterize aggregate preferences from common domains like\nlinear or Leontief, and describe indecomposable preferences that do not\ncorrespond to the aggregate behavior of any non-trivial population.\nApplications include robust welfare analysis, information design, discrete\nchoice models, pseudo-market mechanisms, and preference identification.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.06108v1"
    },
    {
        "title": "The Perils of Overreaction",
        "authors": [
            "Konstantin von Beringe",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In order to study updating rules, we consider the problem of a malevolent\nprincipal screening an imperfectly Bayesian agent. We uncover a fundamental\ndichotomy between underreaction and overreaction to information. If an agent's\nposterior is farther away from the prior than it should be under Bayes' law,\nshe can always be exploited by the principal to an unfettered degree: the\nagent's ex ante expected loss can be made arbitrarily large. In stark contrast,\nan agent who underreacts (whose posterior is closer to the prior than the\nBayesian posterior) cannot be exploited at all.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.08087v1"
    },
    {
        "title": "Revealed preference and revealed preference cycles: a survey",
        "authors": [
            "Paweł Dziewulski",
            "Joshua Lanier",
            "John K. -H. Quah"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Afriat's Theorem (1967) states that a dataset can be thought of as being\ngenerated by a consumer maximizing a continuous and increasing utility function\nif and only if it is free of revealed preference cycles containing a strict\nrelation. The latter property is often known by its acronym, GARP (for\ngeneralized axiom of revealed preference). This paper surveys extensions and\napplications of Afriat's seminal result. We focus on those results where the\nconsistency of a dataset with the maximization of a utility function satisfying\nsome property can be characterized by a suitably modified version of GARP.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.08459v1"
    },
    {
        "title": "Goodness-of-fit and utility estimation: what's possible and what's not",
        "authors": [
            "Joshua Lanier",
            "John K. -H. Quah"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A goodness-of-fit index measures the consistency of consumption data with a\ngiven model of utility-maximization. We show that for the class of well-behaved\n(i.e., continuous and increasing) utility functions there is no goodness-of-fit\nindex that is continuous and accurate, where the latter means that a perfect\nscore is obtained if and only if a dataset can be rationalized by a\nwell-behaved utility function. While many standard goodness-of-fit indices are\ninaccurate we show that these indices are (in a sense we make precise)\nessentially accurate. Goodness-of-fit indices are typically generated by loss\nfunctions and we find that standard loss functions usually do not yield a\nbest-fitting utility function when they are minimized. Nonetheless, welfare\ncomparisons can be made by working out a robust preference relation from the\ndata.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.08464v1"
    },
    {
        "title": "Why Transaction Cost Economics Failed and How to Fix It",
        "authors": [
            "Li Mingqian"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The connotation of transaction costs has never been definitively determined,\nand the independence of the concept has never been rigorously demonstrated.\nThis paper delves into the thought systems of several prominent economists in\nthe development of transaction cost economics, starting from first-hand\nmaterials. By combining multiple works of the authors, it reconstructs the true\nmeanings and identifies endogeneity issues and logical inconsistencies. The\nconclusion of this paper is bold. Previous research has been largely filled\nwith misinterpretations and misunderstandings, as people have focused solely on\nthe wording of transaction cost definitions, neglecting the nature of\ntransaction costs. The intention of transaction cost theory has been\nunwittingly assimilated into the objects it intends to criticize. After\ndelineating the framework of \"transaction costs-property rights-competition\",\nthis paper reconstructs the concept of transaction costs and the history of\ntransaction cost concepts, providing a direct response to this theoretical\npuzzle that has plagued the academic community for nearly a century.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.09087v2"
    },
    {
        "title": "Selling Correlated Information Products",
        "authors": [
            "Klajdi Hoxha"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  How do consultants price expertise? This paper studies a problem of selling\ninformation products (expertise) to a buyer (client) who faces decision-making\nproblem under uncertainty. The client is privately informed about the type of\nexpertise she needs and her willingness to pay (WTP) for additional\ninformation. A monopolist seller (consultant) designs and sells information\nproducts as Blackwell experiments over the underlying states associated with\neach client-specific desired expertise. Because there is correlation across\nstates, a client with high WTP may find it profitable to purchase information\nabout a low type's state, whenever correlation is sufficiently high. I find\nthat the consultant can extract full (socially efficient) surplus whenever such\n(marginal) gains do not exceed the (marginal) costs of buying cheaper, but\nnoisier information. Otherwise, unlike typical results in mechanism design, I\nfind that buyers with low and sufficiently high value for information get no\ninformation rents, and only the \"middle\" types enjoy positive surplus. Common\npricing structures observed in practice, like flat/hourly rates or value-based\nfees, are obtained as optimal contracts if correlation across states is\nsufficiently high or low, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11142v1"
    },
    {
        "title": "A simple proof of the representation theorem for betweenness preferences",
        "authors": [
            "Yutaro Akita"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper presents a simple proof of Dekel (1986)'s representation theorem\nfor betweenness preferences. The proof is based on the separation theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11371v2"
    },
    {
        "title": "Random Attention Span",
        "authors": [
            "Dazhuo Wei"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, I introduce a random attention span model (RAS) which uses\nstopping time to identify decision-makers' behavior under limited attention.\nUnlike many limited attention models, the RAS identifies preferences using time\nvariation without any need for menu variation. In addition, the RAS allows the\nconsideration set to be correlated with the preference. I also use the revealed\npreference theory that provides testable implications for observable choice\nprobabilities. Then, I test the model and estimate the preference distribution\nusing data from M-Turk experiments on choice behaviors that involve lotteries;\nthere is general alignment with the distribution results from logit attention\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11578v1"
    },
    {
        "title": "The Machiavellian frontier of stable mechanisms",
        "authors": [
            "Qiufu Chen",
            "Yuanmei Li",
            "Xiaopeng Yin",
            "Luosai Zhang",
            "Siyi Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The impossibility theorem in Roth (1982) states that no stable mechanism\nsatisfies strategy-proofness. This paper explores the Machiavellian frontier of\nstable mechanisms by weakening strategy-proofness. For a fixed mechanism\n$\\varphi$ and a true preference profile $\\succ$, a $(\\varphi,\\succ)$-boost\nmispresentation of agent i is a preference of i that is obtained by (i) raising\nthe ranking of the truth-telling assignment $\\varphi_i(\\succ)$, and (ii)\nkeeping rankings unchanged above the new position of this truth-telling\nassignment. We require a matching mechanism $\\varphi$ neither punish nor reward\nany such misrepresentation, and define such axiom as\n$\\varphi$-boost-invariance. This is strictly weaker than requiring\nstrategy-proofness. We show that no stable mechanism $\\varphi$ satisfies\n$\\varphi$-boost-invariance. Our negative result strengthens the Roth\nImpossibility Theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.12804v2"
    },
    {
        "title": "Comparisons of Sequential Experiments for Additively Separable Problems",
        "authors": [
            "Mark Whitmeyer",
            "Cole Williams"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  For three natural classes of dynamic decision problems; 1. additively\nseparable problems, 2. discounted problems, and 3. discounted problems for a\nfixed discount factor; we provide necessary and sufficient conditions for one\nsequential experiment to dominate another in the sense that the dominant\nexperiment is preferred to the other for any decision problem in the specified\nclass. We use these results to study the timing of information arrival in\nadditively separable problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.13709v1"
    },
    {
        "title": "The Hamilton-Jacobi-Bellman Equation in Economic Dynamics with a\n  Non-Smooth Fiscal Policy",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a class of economic growth models that includes the classical\nRamsey--Cass--Koopmans capital accumulation model and verify that, under\nseveral assumptions, the value function of the model is the unique viscosity\nsolution to the Hamilton--Jacobi--Bellman equation. Moreover, we discuss a\nsolution method for these models using differential inclusion, where the\nsubdifferential of the value function plays an important role. Next, we present\nan assumption under which the value function is a classical solution to the\nHamilton--Jacobi--Bellman equation, and show that many economic models satisfy\nthis assumption. In particular, our result still holds in an economic growth\nmodel in which the government takes a non-smooth Keynesian policy rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.16643v2"
    },
    {
        "title": "Games under the Tiered Deferred Acceptance Mechanism",
        "authors": [
            "Jiarui Xie"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the tiered deferred acceptance mechanism used in school admissions,\nsuch as in China and Turkey. This mechanism partitions schools into tiers and\napplies the deferred acceptance algorithm within each tier. Once assigned,\nstudents cannot apply to schools in subsequent tiers. We show that this\nmechanism is not strategy-proof. In the induced preference revelation game, we\nfind that merging tiers preserves all equilibrium outcomes, and within-tier\nacyclicity is necessary and sufficient for the mechanism to implement stable\nmatchings. We also find that introducing tiers to the deferred acceptance\nmechanism may not improve student quality at top-tier schools as intended.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.00455v3"
    },
    {
        "title": "Generative AI as Economic Agents",
        "authors": [
            "Nicole Immorlica",
            "Brendan Lucier",
            "Aleksandrs Slivkins"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Traditionally, AI has been modeled within economics as a technology that\nimpacts payoffs by reducing costs or refining information for human agents. Our\nposition is that, in light of recent advances in generative AI, it is\nincreasingly useful to model AI itself as an economic agent. In our framework,\neach user is augmented with an AI agent and can consult the AI prior to taking\nactions in a game. The AI agent and the user have potentially different\ninformation and preferences over the communication, which can result in\nequilibria that are qualitatively different than in settings without AI.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.00477v1"
    },
    {
        "title": "Absolute and Relative Ambiguity Attitudes",
        "authors": [
            "Francesco Fabbri",
            "Giulio Principi",
            "Lorenzo Stanca"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We represent preferences that exhibit absolute or relative attitudes towards\nambiguity without assuming convexity of preferences. Our analysis is motivated\nby the recent experimental evidence by Baillon and Placido (2019) indicating\nthat ambiguity becomes more tolerable as individuals are better off overall.\nDecreasing absolute ambiguity aversion is characterized by constant\nsuperadditive certainty equivalents and admits an act-dependent variational\nrepresentation (Maccheroni et al., 2006). Decreasing relative ambiguity\naversion relates to positive superhomogeneity and admits an act-dependent\nconfidence preference representation (Chateauneuf and Faro, 2009). We apply our\ncharacterizations to retrieve a classic risk sharing result on the efficiency\nof trade and subjective beliefs of the individuals (Rigotti et al., 2008).\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01343v2"
    },
    {
        "title": "Local non-bossiness",
        "authors": [
            "Eduardo Duque",
            "Juan S. Pereyra",
            "Juan Pablo Torres-Martínez"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The student-optimal stable mechanism (DA), the most popular mechanism in\nschool choice, is the only one that is both stable and strategy-proof. However,\nwhen DA is implemented, a student can change the schools of others without\nchanging her own. We show that this drawback is limited: a student cannot\nchange her classmates while remaining in the same school. We refer to this new\nproperty as local non-bossiness and use it to provide a new characterization of\nDA that does not rely on stability. Furthermore, we show that local\nnon-bossiness plays a crucial role in providing incentives to be truthful when\nstudents have preferences over their colleagues. As long as students first\nconsider the school to which they are assigned and then their classmates, DA\ninduces the only stable and strategy-proof mechanism. There is limited room to\nexpand this preference domain without compromising the existence of a stable\nand strategy-proof mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01398v3"
    },
    {
        "title": "Monotone Equilibrium Design for Matching Markets with Signaling",
        "authors": [
            "Seungjin Han",
            "Alex Sam",
            "Youngki Shin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study monotone equilibrium design by a planner who chooses an interval of\nreactions that receivers take before senders and receivers move in matching\nmarkets with signaling. Given the convex efficiency frontier over sender\nsurplus and receiver surplus generated by the interval delegation, the optimal\nreaction interval crucially depends on the ripple effect of its lower bound and\non the trade-off between matching inefficiency and signaling cost savings in\nthe top pooling region generated by its upper bound. Our analysis generates\ncohesive market design results that integrate the literature on minimum wage,\nfirm size distribution, and relative risk aversion.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01886v2"
    },
    {
        "title": "Network Threshold Games",
        "authors": [
            "Alastair Langtry",
            "Sarah Taylor",
            "Yifan Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies the general class of games where agents: (1) are embedded\non a network, (2) have two possible actions, and (3) these actions are\nstrategic complements. We use a measure of network cohesiveness -- the k-core\n-- to provide a novel characterisation of the equilibria. After transforming\nthe network appropriately, the k-core fully describes both the minimal and\nmaximal equilibria, and also provides a partial characterisation of all others.\nThis framework is also the binary action version of the large class of network\ngames with strategic complements and continuous actions.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.04540v1"
    },
    {
        "title": "Learning about informativeness",
        "authors": [
            "Wanying Huang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study whether individuals can learn the informativeness of their\ninformation technology through social learning. As in the classic sequential\nsocial learning model, rational agents arrive in order and make decisions based\non the past actions of others and their private signals. There is uncertainty\nregarding the informativeness of the common signal-generating process. We show\nthat learning in this setting is not guaranteed, and depends crucially on the\nrelative tail distributions of private beliefs induced by uninformative and\ninformative signals. We identify the phenomenon of perpetual disagreement as\nthe cause of learning and characterize learning in the canonical Gaussian\nenvironment.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.05299v1"
    },
    {
        "title": "Third Degree Price Discrimination Under Costly Information Acquisition",
        "authors": [
            "Irfan Tekdir"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper investigates third-degree price discrimination under endogenous\nmarket segmentation. Segmenting a market requires access to information about\nconsumers, and this information comes with a cost. I explore the trade-offs\nbetween the benefits of segmentation and the costs of information acquisition,\nrevealing a non-monotonic relationship between consumer surplus and the cost of\ninformation acquisition for monopolist. I show that in some markets, allowing\nthe monopolist easier access to customer data can also benefit customers. I\nalso analyzed how social welfare reacts to changes in the cost level of\ninformation acquisition and showed that the non-monotonicity result is also\nvalid in social welfare analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.06026v1"
    },
    {
        "title": "Information Aggregation with Costly Information Acquisition",
        "authors": [
            "Spyros Galanis",
            "Sergei Mikhalishchev"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study information aggregation in a dynamic trading model with partially\ninformed traders. Ostrovsky [2012] showed that 'separable' securities aggregate\ninformation in all equilibria, however, separability is not robust to small\nchanges in the traders' private information. To remedy this problem, we enhance\nthe model by allowing traders to acquire signals with cost $\\kappa$, in every\nperiod. We show that '$\\kappa$ separable securities' aggregate information and,\nas the cost decreases, nearly all securities become $\\kappa$ separable,\nirrespective of the traders' initial private information. Moreover, the switch\nto $\\kappa$ separability happens not gradually but discontinuously, hence even\na small decrease in costs can result in a security aggregating information.\nFinally, even with myopic traders, cheaper information may accelerate or\ndecelerate information aggregation for all but Arrow-Debreu securities.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.07186v2"
    },
    {
        "title": "Matching With Pre-Existing Binding Agreements: The Agreeable Core",
        "authors": [
            "Peter Doe"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Matching market models ignore prior commitments. Yet many job seekers, for\nexample, are already employed, and the same holds for many other matching\nmarkets. I analyze two-sided matching markets with pre-existing binding\nagreements between market participants. In this model, a pair of participants\nbound to each other by a pre-existing agreement must agree to any action they\ntake. To analyze their behavior, I propose a new solution concept, the\nagreeable core, consisting of the matches which cannot be renegotiated without\nviolating the binding agreements. My main contribution is an algorithm that\nconstructs such a match by a novel combination of the Deferred Acceptance and\nTop Trading Cycles algorithms. The algorithm is robust to various manipulations\nand has applications to numerous markets including the resident-to-hospital\nmatch, college admissions, school choice, and labor markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.08700v2"
    },
    {
        "title": "Mechanism Design by a Politician",
        "authors": [
            "Giovanni Valvassori Bolgè"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A set of agents has to make a decision about the provision of a public good\nand its financing. Agents have heterogeneous values for the public good and\neach agent's value is private information. An agenda-setter has the right to\nmake a proposal about a public-good level and a vector of contributions. For\nthe proposal to be approved, only the favourable votes of a subset of agents\nare needed. If the proposal is not approved, a type-dependent outside option is\nimplemented. I characterize the optimal public-good provision and the\ncoalition-formation for any outside option in dominant strategies. Optimal\npublic-good provision might be a non-monotonic function of the outside option\npublic-good level. Moreover, the optimal coalition might be a non-convex set of\ntypes.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.08936v1"
    },
    {
        "title": "Equality of Opportunity and Opportunity Pluralism",
        "authors": [
            "Giovanni Valvassori Bolgè"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper seeks to explore the potential trade-off arising between the\ntheories of $\\textit{Equality of Opportunity}$ and $\\textit{Opportunity\nPluralism}$. Whereas the first theory has received much attention in the\nliterature on Welfare Economics, the second one has only recently been\nintroduced with the publication of the book by Joseph Fishkin,\n$\\textit{Bottlenecks: A New Theory of Equal Opportunity}$. After arguing\nextensively that any notion of human flourishing is incompatible with\ntraditional theories of $\\textit{Equality of Opportunity}$, the author proposes\nan alternative theory squarely based on a broad notion of human development.\nThis paper seeks to formalize the argument made in this book through the lens\nof economic theory. My analysis suggests that traditional theories of\n$\\textit{Equality of Opportunity}$ are not incompatible with\n$\\textit{Opportunity Pluralism}$.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.08955v1"
    },
    {
        "title": "Equilibria and Group Welfare in Vote Trading Systems",
        "authors": [
            "Matthew I. Jones"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We introduce a new framework to study the group dynamics and game-theoretic\nconsiderations when voters in a committee are allowed to trade votes. This\nmodel represents a significant step forward by considering vote-for-vote trades\nin a low-information environment where voters do not know the preferences of\ntheir trading partners. All voters draw their preference intensities on two\nissues from a common probability distribution and then consider offering to\ntrade with an anonymous partner. The result is a strategic game between two\nvoters that can be studied analytically. We compute the Nash equilibria for\nthis game and derive several interesting results involving symmetry, group\nheterogeneity, and more. This framework allows us to determine that trades are\ntypically detrimental to the welfare of the group as a whole, but there are\nexceptions. We also expand our model to allow all voters to trade votes and\nderive approximate results for this more general scenario. Finally, we emulate\nvote trading in real groups by forming simulated committees using real voter\npreference intensity data and computing the resulting equilibria and associated\nwelfare gains or losses.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.09536v1"
    },
    {
        "title": "Existence and structure of Nash equilibria for supermodular games",
        "authors": [
            "Lu Yu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Two theorems announced by Topkis about the topological description of\nsublattices are proved. They are applied to extend some classical results\nconcerning the existence and the order structure of Nash equilibria of certain\nsupermodular games, with some problems in Zhou's proof corrected.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.09582v1"
    },
    {
        "title": "Embracing the Enemy",
        "authors": [
            "Álvaro Delgado-Vega",
            "Johannes Schneider"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the repeated interactions between two power-hungry agents, the\n\"friend\", and the \"enemy,\" and one power broker, the principal. All three care\nabout the leading agent's policy choice. The principal, who aligns more with\nthe friend, can influence but not fully control leadership allocation. After an\ninitial cordon sanitaire breaks, the principal embraces the enemy, sometimes\npromising persistent support: she grants the enemy power in exchange for\nmoderation, which benefits the friend who reciprocates. The closer the\nprincipal is to the friend, the more she desires to embrace the enemy, but the\nharder it is to uphold such promises.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.09734v5"
    },
    {
        "title": "Endogenous Identity in a Social Network",
        "authors": [
            "Christian Ghiglino",
            "Nicole Tabasso"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Interaction with individuals from other socioeconomic classes has been shown\nto be a main driver for social mobility. We employ tools of social identity\ntheory and network analysis to show how exposure to individuals of different\nsocial identities can lead to interactions with them, and an adoption of their\nidentity, creating social mobility. We find that even if all individuals have\nthe same ability, they may endogenously choose different identities, leading to\ndifferent classes and actions. In particular, we derive a sufficient condition\nfor such an equilibrium to exist, which equates to a novel measure of cohesion.\nFurthermore, we show that the most socially mobile individuals (changing their\nidentity) are those who either have few connections or a more heterogeneous mix\nof identities in their connections. Finally, we show that upward social\nmobility increases action levels in society, but not necessarily welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.10972v1"
    },
    {
        "title": "Endogenous Attention and the Spread of False News",
        "authors": [
            "Tuval Danenberg",
            "Drew Fudenberg"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the impact of endogenous attention in a dynamic model of social\nmedia sharing. Each period, a distinct user randomly draws a story from the\npool of stories on the platform and decides whether or not to share it. Users\nwant to share stories that are true and interesting, but differentiating true\nstories from false ones requires attention. Before deciding whether to share a\nstory, users choose their level of attention based on how interesting the story\nis and the platform's current proportions of true and false stories. We\ncharacterize the limit behavior of the share of true stories using stochastic\napproximation techniques. For some parameter specifications, the system has a\nunique limit. For others, the limit is random -- starting from the same initial\nconditions, the platform may end up with very different proportions of true and\nfalse stories and different user sharing behavior. We present various\ncomparative statics for the limit. Endogenous attention leads to a\ncounterbalancing force to changes in the credibility of false stories but can\nintensify the effects of changes in false stories' production rate.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11024v1"
    },
    {
        "title": "Hoping for the best while preparing for the worst in the face of\n  uncertainty: a new type of incomplete preferences",
        "authors": [
            "Pierre Bardier",
            "Bach Dong-Xuan",
            "Van-Quy Nguyen"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We propose and axiomatize a new model of incomplete preferences under\nuncertainty, which we call hope-and-prepare preferences. Act f is considered\nmore desirable than act g when, and only when, both an optimistic evaluation,\ncomputed as the welfare level attained in a best-case scenario, and a\npessimistic one, computed as the welfare level attained in a worst-case\nscenario, rank f above g. Our comparison criterion involves multiple priors, as\nbest and worst cases are determined among sets of probability distributions,\nand is, generically, less conservative than Bewley preferences and twofold\nmulti-prior preferences, the two ambiguity models that are closest to ours.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11166v2"
    },
    {
        "title": "Moral Hazard with Network Effects",
        "authors": [
            "Marc Claveria-Mayol"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study a moral hazard problem between a principal and multiple agents who\nexperience positive peer effects represented by a (weighted) network. Under the\noptimal linear contract, the principal provides high-powered incentives to\ncentral agents in the network in order to exploit the larger incentive\nspillovers such agents create. The analysis reveals a novel measure of network\ncentrality that captures rich channels of direct and indirect incentive\nspillovers and characterizes the optimal contract and its induced equilibrium\nefforts. The notion of centrality relevant for incentive spillovers in the\nmodel emphasizes the role of pairs of agents who link to common neighbors in\nthe network. This characterization leads to a measure of marginal network\neffects and identifies the agents whom the principal targets with stronger\nincentives in response to the addition (or strengthening) of a link. When the\nprincipal can position agents with heterogeneous costs of effort in the\nnetwork, the principal prefers to place low-cost agents in central positions.\nThe results shed light on how firms can increase productivity through corporate\nculture, office layout, and social interactions.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11660v1"
    },
    {
        "title": "Incentive Contracts and Peer Effects in the Workplace",
        "authors": [
            "Marc Claveria-Mayol",
            "Pau Milán",
            "Nicolás Oviedo-Dávila"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the problem of a principal designing wage contracts that\nsimultaneously incentivize and insure workers. Workers' incentives are\nconnected through chains of productivity spillovers, represented by a network\nof peer-effects. We solve for the optimal linear contract for any network and\nshow that optimal incentives are steeper for more central workers. We link firm\nprofits to organizations' structure via the spectral properties of the coworker\nnetwork. When production is modular, the incentive allocation rule is sensitive\nto the link structure across and within modules. When firms can't write\npersonalize contracts, better connected workers extract rents. In this case,\nunemployment emerges endogenously because large within-group differences in\ncentrality can decrease firm's profits.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11712v3"
    },
    {
        "title": "Dynamic Evidence Disclosure: Delay the Good to Accelerate the Bad",
        "authors": [
            "Jan Knoepfle",
            "Julia Salmi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze the dynamic tradeoff between generating and disclosing evidence.\nAgents are tempted to delay investing in a new technology in order to learn\nfrom information generated by the experiences of others. This informational\nfree-riding is collectively harmful as it slows down learning and innovation\nadoption. A welfare-maximizing designer can delay the disclosure of previously\ngenerated information in order to speed up adoption. The optimal policy\ntransparently discloses bad news and delays good news. This finding resonates\nwith regulation demanding that fatal breakdowns be reported promptly. The\ndesigner's intervention makes all agents better off.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11728v2"
    },
    {
        "title": "Persuasion and Optimal Stopping",
        "authors": [
            "Andrew Koh",
            "Sivakorn Sanguanmoo",
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We provide a unified analysis of how dynamic information should be designed\nin optimal stopping problems: a principal controls the flow of information\nabout a payoff relevant state to persuade an agent to stop at the right time,\nin the right state, and choose the right action. We further show that for\narbitrary preferences, intertemporal commitment is unnecessary: optimal dynamic\ninformation designs can always be made dynamically consistent.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.12278v2"
    },
    {
        "title": "Data Trade and Consumer Privacy",
        "authors": [
            "Jiadong Gu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies optimal mechanisms for collecting and trading data.\nConsumers benefit from revealing information about their tastes to a service\nprovider because this improves the service. However, the information is also\nvaluable to a third party as it may extract more revenue from the consumer in\nanother market called the product market. The paper characterizes the\nconstrained optimal mechanism for the service provider subject to incentive\nfeasibility. It is shown that the service provider sometimes sells no\ninformation or only partial information in order to preserve profits in the\nservice market. In a general setup, the service provision distortion and\nno-price discrimination in the product market are exclusive. Moreover, a ban on\ndata trade may reduce social welfare because it makes it harder to price\ndiscriminate in the product market.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.12457v2"
    },
    {
        "title": "Combining Combined Forecasts: a Network Approach",
        "authors": [
            "Marcos R. Fernandes"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This study investigates the practice of experts aggregating forecasts before\ninforming a decision-maker. The significance of this subject extends to various\ncontexts where experts inform their assessments to a decision-maker following\ndiscussions with peers. My findings show that, irrespective of the information\nstructure, aggregation rules introduce no bias to decision-making in expected\nterms. Nevertheless, the concern revolves around variance. In situations where\nexperts are equally precise, and pair-wise correlation of forecasts is the same\nacross all pairs of experts, the network structure plays a pivotal role in\ndecision-making variance. For classical structures, I show that star networks\nexhibit the highest variance, contrasting with $d$-regular networks that\nachieve zero variance, emphasizing their efficiency. Additionally, by employing\nthe Poisson random graph model under the assumptions of a large network size\nand a small connection probability, the results indicate that both the expected\nNetwork Bias and its variance converge to zero as the network size becomes\nsufficiently large. These insights enhance the understanding of decision-making\nunder different information, network structures and aggregation rules. They\nenrich the literature on combining forecasts by exploring the effects of prior\nnetwork communication on decision-making.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.13749v1"
    },
    {
        "title": "Nonparametric Analysis of Random Utility Models Robust to Nontransitive\n  Preferences",
        "authors": [
            "Wilfried Youmbi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The Random Utility Model (RUM) is the gold standard in describing the\nbehavior of a population of consumers. The RUM operates under the assumption of\ntransitivity in consumers' preference relationships, but the empirical\nliterature has regularly documented its violation. In this paper, I introduce\nthe Random Preference Model (RPM), a novel framework for understanding the\nchoice behavior in a population akin to RUMs, which preserves monotonicity and\naccommodates nontransitive behaviors. The primary objective is to test the null\nhypothesis that a population of rational consumers generates cross-sectional\ndemand distributions without imposing constraints on the unobserved\nheterogeneity or the number of goods. I analyze data from the UK Family\nExpenditure Survey and find evidence that contradicts RUMs and supports RPMs.\nThese findings underscore RPMs' flexibility and capacity to explain a wider\nspectrum of consumer behaviors compared to RUMs. This paper generalizes the\nstochastic revealed preference methodology of McFadden & Richter (1990) for\nfinite choice sets to settings with nontransitive and possibly nonconvex\npreference relations.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.13969v1"
    },
    {
        "title": "Redistribution Through Market Segmentation",
        "authors": [
            "Victor Augias",
            "Alexis Ghersengorin",
            "Daniel M. A. Barreto"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study how to optimally segment a monopolistic market given a\nredistributive objective. Optimal redistributive segmentations (i) induce the\nseller to price progressively, i.e., richer consumers pay higher prices than\npoorer ones, and (ii) may require giving a higher profit than uniform pricing\nif the redistributive motive is strong. We further show that optimal\nredistributive segmentations are implementable via price-based regulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14174v2"
    },
    {
        "title": "Information Revelation and Pandering in Elections",
        "authors": [
            "Navin Kartik",
            "Francesco Squintani",
            "Katrin Tinn"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Do elections efficiently aggregate politicians' policy-relevant private\ninformation? This paper argues that politicians' office motivation is an\nobstacle. In a two-candidate Hotelling-Downs model in which each candidate has\nsocially-valuable policy information, we establish that equilibrium welfare is\nat best what can be obtained by disregarding one politician's information. We\nalso find that for canonical information structures, politicians have an\nincentive to ``anti-pander'', i.e., to overreact to their information. Some\ndegree of pandering -- underreacting to information -- would be socially\nbeneficial.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.17084v1"
    },
    {
        "title": "Complexity Aversion",
        "authors": [
            "Yuan Gu",
            "Chao Hung Chan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper proposes a model of decision-making under uncertainty in which an\nagent is constrained in her cognitive ability to consider complex acts. We\nidentify the complexity of an act according to the corresponding partition of\nstate space. The agent ranks acts according to the expected utility net of\ncomplexity cost. A key feature of this model is that the agent is able to\nupdate her complexity cost function after the arrival of new information. The\nmain result characterizes axiomatically an updating rule for complexity cost\nfunction, the Minimal Complexity Aversion representation. According to this\nrule, the agent measures the complexity cost of an act conditional on the new\ninformation by using the cost of another act that gives exactly the same\npartition of the event but with the lowest ex-ante cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18463v1"
    },
    {
        "title": "Pareto-Nash Reversion Strategies: Three Period Dynamic Co-operative\n  Signalling with Sticky Efficiency Wages",
        "authors": [
            "Alfred Anate Mayaki"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper the Nash equilibrium reversion is used as an optimal tool for\nclearing dynamic prices and wages. The balanced growth path of the efficiency\nwage and the outcome of repeated household and firm wage bargaining decisions\nare determined by various exogenous competitive rigidities. A location model is\npursued to explore the extent to which a downstream spatial cooperation\nagreement might affect the price equilibrium. There is also an endogenous\nhiring function and a knowledge base which is increasing in output, as is the\nreal wage. As the article demonstrates, after accounting for real rigidities in\nthe baseline model the effect of wage growth on household utility through\nstaggered bargaining can be best catered for by adopting a policy of point\nscoring on the mobility of skilled labour against the models key rigidities.\nFinally labour mobility is explored. Mobility point scores, which serve to\nencourage mobility from skilled labour within the model not only increase the\nknowledge base but also place upward pressure on nominal wage growth.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18471v1"
    },
    {
        "title": "Convex Choice",
        "authors": [
            "Navin Kartik",
            "Andreas Kleiner"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  For multidimensional Euclidean type spaces, we study convex choice: from any\nchoice set, the set of types that make the same choice is convex. We establish\nthat, in a suitable sense, this property characterizes the sufficiency of local\nincentive constraints. Convex choice is also of interest more broadly. We tie\nconvex choice to a notion of directional single-crossing differences (DSCD).\nFor an expected-utility agent choosing among lotteries, DSCD implies that\npreferences are either one-dimensional or must take the affine form that has\nbeen tractable in multidimensional mechanism design.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.19063v1"
    },
    {
        "title": "Common Identification and Common Learning",
        "authors": [
            "Martin W. Cripps"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Cripps, Ely, Mailath and Samuelson (2008) showed that if there are finitely\nmany states, and the signals are i.i.d and finite, then individual learning is\nsufficient for common learning. In this note we describe what is commonly\nlearned when this sufficient condition does not hold.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.20029v1"
    },
    {
        "title": "Information About Other Players in Mechanism Design",
        "authors": [
            "Eric Yan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We show the existence of mechanism design settings where the social planner\nhas an interest in players receiving noisy signals about the types of other\nagents. When the social planner is interested only in partial implementation,\nany social choice rule that is incentive compatible after players receive\nadditional information about other agents was originally incentive compatible\nprior to the change in information structure. However, information about other\nagents can eliminate undesired equilibria in an implementing mechanism. Thus,\nthere are social choice rules which are not fully implementable in a given\ninformation environment that become fully implementable after players have\nadditional information about the types of other agents. We provide some general\nconditions under which an undesired equilibrium can be eliminated by additional\ninformation about other players.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.00037v1"
    },
    {
        "title": "Counterexamples to \"Transitive Regret\"",
        "authors": [
            "Yuan Chang",
            "Shuo Li Liu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Theorem 1 in Bikhchandani & Segal (2011; Theoretical Economics) suggests that\na complete, transitive, monotonic, and continuous preference is regret based if\nand only if it is expected utility. Their Proposition 1 suggests that\ntransitivity and continuity of a regret-based preference implies an equivalence\ncondition: if random variables $X$ and $Y$ have the same distribution, then\n$X\\sim Y$. We give counterexamples to Proposition 1.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.00055v1"
    },
    {
        "title": "Nash equilibria of games with generalized complementarities",
        "authors": [
            "Lu Yu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  To generalize complementarities for games, we introduce some conditions\nweaker than quasisupermodularity and the single crossing property. We prove\nthat the Nash equilibria of a game satisfying these conditions form a nonempty\ncomplete lattice. This is a purely order-theoretic generalization of Zhou's\ntheorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.00636v1"
    },
    {
        "title": "Random Attention and Unobserved Reference Alternatives",
        "authors": [
            "Varun Bansal"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, I develop and characterize a random attention model with\nunobserved reference alternatives. The decision-maker pays attention to\ndifferent subsets of the available set of alternatives randomly. The reference\nalternatives are exactly those alternatives that are always paid attention to,\ni.e. they are attention-privileged. These alternatives are unknown to the\noutside observer. The characterization allows for a complete identification of\nthe reference alternatives and a coarse identification of the underlying\npreferences. I then restrict the model by considering the independent random\nattention function and provide a complete identification of the underlying\npreferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01528v3"
    },
    {
        "title": "Beyond the Mean: Testing Consumer Rationality through Higher Moments of\n  Demand",
        "authors": [
            "Sebastiaan Maes",
            "Raghav Malhotra"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a setting where an analyst has access to purely aggregate\ninformation about the consumption choices of a heterogenous population of\nindividuals. We show that observing the statistical moments of market demand\nallows the analyst to test aggregate data for rationality. Interestingly, just\nthe mean and variance of demand carry observable restrictions. This is in stark\ncontrast to impossibility result of the Sonnenschein-Mantel-Debreu theorem,\nwhich shows that aggregate demand carries no observable restrictions at all. We\nleverage our approach to deliver a characterization of rationality in terms of\nmoments for the common two-good case. We illustrate the usefulness of\nmoment-based restrictions through two applications: (i) improving the precision\nof demand and welfare estimates; and (ii) testing for the existence of a\nwelfare-relevant representative consumer.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01538v1"
    },
    {
        "title": "Comparative Patience",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We begin by formulating and characterizing a dominance criterion for prize\nsequences: $x$ dominates $y$ if any impatient agent prefers $x$ to $y$. With\nthis in hand, we define a notion of comparative patience. Alice is more patient\nthan Bob if Alice's normalized discounted utility gain by going from any $y$ to\nany dominating $x$ is less than Bob's discounted utility gain from such an\nimprovement. We provide a full characterization of this relation in terms of\nthe agents' discount rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.02323v1"
    },
    {
        "title": "Information Greenhouse: Optimal Persuasion for Medical Test-Avoiders",
        "authors": [
            "Zhuo Chen"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Patients often delay or reject medical tests due to information avoidance,\nwhich hinders timely reception of necessary treatments. This paper studies the\noptimal information policy to persuade an information-avoidant patient to\nundergo the test and make the best choice that maximizes his health. The\npatient sequentially decides whether to take the test and the optimal treatment\nplan. The information provided is about the background knowledge of the\ndisease, and disclosure can take place both before and after the test decision.\nThe optimal information policy depends on whether the patient is willing to be\ntested when he is completely pessimistic. If so, the optimal policy features\nwarning-in-advance: the disclosure only takes place before the test, and the\nbad news guarantees the patient to be tested and be treated even without\nfurther information. If not, the optimal policy constructs an information\ngreenhouse: an information structure that provides high anticipatory utility is\ncommitted when the patient is tested and the test result is bad. Extensions to\nex ante participation constraint and general information preference are also\nconsidered.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.02948v2"
    },
    {
        "title": "Pattern formation by advection-diffusion in new economic geography",
        "authors": [
            "Kensuke Ohtake"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A new economic geography model is proposed in which the migration of mobile\nworkers is proximate and perturbed by non-economic factors. The model consists\nof a tractable core-periphery model assuming a quasi-linear log utility\nfunction of consumers and an advection-diffusion equation governing the time\nevolution of a population distribution. The stability of a spatially\nhomogeneous stationary solution and the large time behavior of solutions to the\nmodel on a one-dimensional periodic space are investigated. When the spatially\nhomogeneous stationary solution is unstable, solutions starting around it are\nfound to eventually form spatial patterns with several urban areas in which\nmobile workers agglomerate.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.05804v1"
    },
    {
        "title": "Optimal Decision Mechanisms for Committees: Acquitting the Guilty",
        "authors": [
            "Deniz Kattwinkel",
            "Alexander Winter"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A group of privately informed agents chooses between two alternatives. How\nshould the decision rule be designed if agents are known to be biased in favor\nof one of the options? We address this question by considering the Condorcet\nJury Setting as a mechanism design problem. Applications include the optimal\ndecision mechanisms for boards of directors, political committees, and trial\njuries.\n  While we allow for any kind of mechanism, the optimal mechanism is a voting\nmechanism. In the terminology of the trial jury example: When jurors (agents)\nare more eager to convict than the lawmaker (principal), then the defendant\nshould be convicted if and only if neither too many nor too few jurors vote to\nconvict.\n  This kind of mechanism accords with a judicial procedure from ancient Jewish\nlaw.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.07293v1"
    },
    {
        "title": "Carbon Pricing and Resale in Emission Trading Systems",
        "authors": [
            "Peyman Khezr"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Secondary markets and resale are integral components of all emission trading\nsystems. Despite the justification for these secondary trades, such as\nunpredictable demand, they may encourage speculation and result in the\nmisallocation of permits. In this paper, our aim is to underscore the\nimportance of efficiency in the initial allocation mechanism and to explore how\nconcerns leading to the establishment of secondary markets, such as uncertain\ndemand, can be addressed through alternative means, such as frequent auctions.\nWe demonstrate that the existence of a secondary market could lead to higher\nuntruthful bids in the auction, further encouraging speculation and the\naccumulation of rent. Our results suggest that an inefficient initial\nallocation could enable speculators with no use value for the permits to bid in\nthe auction and subsequently earn rents in secondary markets by trading these\npermits. Even if the secondary market operates efficiently, the resulting rent,\nwhich represents a potential loss of auction revenue, cannot be overlooked.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.07386v1"
    },
    {
        "title": "Incentivizing Agents through Ratings",
        "authors": [
            "Peiran Xiao"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study the optimal design of ratings to motivate agent investment in quality\nwhen transfers are unavailable. The principal designs a rating scheme that maps\nthe agent's quality to a (possibly stochastic) score. The agent has private\ninformation about his ability, which determines his cost of investment, and\nchooses the quality level. The market observes the score and offers a wage\nequal to the agent's expected quality. For example, a school incentivizes\nlearning through a grading policy that discloses the student's quality to the\njob market.\n  I reduce the principal's problem to the design of an interim wage function of\nquality. When restricted to deterministic ratings, I provide necessary and\nsufficient conditions for the optimality of simple pass/fail tests and lower\ncensorship. In particular, when the principal's objective is expected quality,\npass/fail tests are optimal if agents' abilities are concentrated towards the\ntop of the distribution, while pass/lower censorship is optimal if abilities\nare concentrated towards the mode. The results generalize existing results in\noptimal delegation with voluntary participation, as pass/fail tests (lower\ncensorship) correspond to take-it-or-leave-it offers (threshold delegation).\nAdditionally, I provide sufficient conditions for deterministic ratings to\nremain optimal when stochastic ratings are allowed. For quality maximization,\npass/fail tests remain optimal if the ability distribution becomes increasingly\nmore concentrated towards the top.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.10525v4"
    },
    {
        "title": "Informational Size in School Choice",
        "authors": [
            "Di Feng",
            "Yun Liu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper introduces a novel measurement of informational size to school\nchoice problems, which inherits its ideas from Mount and Reiter (1974). This\nconcept measures a matching mechanism's information size by counting the\nmaximal relevant preference and priority rankings to secure a certain pairwise\nassignment of a student to a school across all possible matching problems. Our\nanalysis uncovers two key insights. First, the three prominent strategy-proof\nmatching mechanisms, the deferred acceptance (DA) mechanism, the top trading\ncycles (TTC) mechanism, and the serial dictatorship (SD) mechanism, is\n(strictly) less informative than the non-strategy-proof immediate acceptance\n(IA) mechanism. This result highlights a previously omitted advantage of IA in\nterm of its information demand, which partially explain the its popularity in\nreal-world matching problems especially when acquiring information is both\npecuniarily and cognitively costly. Second, when the matching problem contains\nat least four students, the TTC demands less information compared to the DA to\nimplement a desired allocation. The issue of comparison between TTC and DA has\npuzzled researchers both in theory (Gonczarowski and Thomas, 2023) and in\nexperiment (Hakimov and Kubler, 2021). Our result responds to this issue from\nan informational perspective: in experiments with relatively fewer students,\nagents tend to prefer DA over TTC as DA requires fewer information to secure\none's allocation in all problems (Guillen and Veszteg, 2021), while the\nopposite is true when the market size increases (Pais et al., 2011). Among\nothers, our informational size concept offers a new perspective to understand\nthe differences in auditability (Grigoryan and Moller, 2024), manipulation\nvulnerability (Pathak and Sonmez, 2013), and privacy protection (Haupt and\nHitzig, 2022), among some commonly used matching mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.11273v1"
    },
    {
        "title": "Multi-Tier Tournaments: Matching and Scoring Players",
        "authors": [
            "Steven J. Brams",
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We introduce a novel system of matching and scoring players in tournaments,\ncalled Multi-Tier Tournaments, illustrated by chess and based on the following\nrules:\n  1. Players are divided into skill-based tiers, based on their Elo ratings.\n  2. Starting with one or more mini-tournaments of the least skilled players\n(Tier 1), the winner or winners -- after playing multiple opponents -- move to\nthe next-higher tier.\n  3. The winners progress to a final tier of the best-performing players from\nlower tiers as well as players with the highest Elo ratings.\n  4. Performance in each tier is given by a player's Tournament Score (TS),\nwhich depends on his/her wins, losses, and draws (not on his/her Elo rating).\n  Whereas a player's Elo rating determines in which mini-tournament he/she\nstarts play, TS and its associated tie-breaking rules determine whether a\nplayer moves up to higher tiers and, in the final mini-tournament, wins the\ntournament. This combination of players' past Elo ratings and current TS's\nprovides a fair and accurate measure of a player's standing among the players\nin the tournament. We apply a variation of Multi-Tier Tournaments to the top 20\nactive chess players in the world (as of February 2024). Using a dataset of\n1209 head-to-head games, we illustrate the viability of giving lower-rated\nplayers the opportunity to progress and challenge higher-rated players. We also\nbriefly discuss the application of Multi-Tier Tournaments to baseball, soccer,\nand other sports that emphasize physical rather than mental skills.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.13845v1"
    },
    {
        "title": "Cohesion, Ideology, and Tolerance",
        "authors": [
            "Patrick Allmis"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Agents with different ideologies often form alliances to achieve their goals.\nParadoxically, ideologically similar agents are often opponents. In this paper,\nideologically heterogeneous agents choose the ideological composition of their\nneighborhood, their tolerance, and invest into connections. The resulting\nweighted network describes allies, opponents, and strengths. Disputes with\nopponents determine benefits, which increase in an agent's strength and\ncohesion. Cohesive agents have fewer mutual allies with opponents. In\nequilibrium, the network is segregated when cohesion is effective enough and\nsome agents tolerate ideologically distant types to oppose closer ones.\nSubsidizing connections dampens polarization in societies on the verge of\nsegregation.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14045v1"
    },
    {
        "title": "Justified Fairness in House Allocation Problems: two Characterizations\n  of Strategy-proof Mechanisms",
        "authors": [
            "Di Feng",
            "Jacob Coreno"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider the house allocation problems with strict preferences, where\nmonetary transfers are not allowed. We propose two properties in the spirit of\njustified fairness. Interestingly, together with other well-studied properties\n(strategy-proofness and non-bossiness), our two new properties identify serial\ndictatorships and sequential dictatorships, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14101v1"
    },
    {
        "title": "Fair allocation of riparian water rights",
        "authors": [
            "Ricardo Martinez",
            "Juan D. Moreno-Ternero"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We take an axiomatic approach to the allocation of riparian water rights. We\nformalize ethical or structural properties as axioms of allocation rules. We\nshow that several combinations of these axioms characterize focal rules\nimplementing the principle of Territorial Integration of all Basin States in\nvarious forms. One of them connects to the Shapley value, the long-standing\ncenterpiece of cooperative game theory. The others offer natural compromises\nbetween the polar principles of Absolute Territorial Sovereignty and Unlimited\nTerritorial Integrity. We complete our study with an empirical application to\nthe allocation of riparian water rights in the Nile River.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14623v1"
    },
    {
        "title": "(Non-)Commutative Aggregation",
        "authors": [
            "Yuzhao Yang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Commutativity is a normative criterion of aggregation and updating stating\nthat the aggregation of expert posteriors should be identical to the update of\nthe aggregated priors. I propose a thought experiment that raises questions\nabout the normative appeal of Commutativity. I propose a weakened version of\nCommutativity and show how that assumption plays central roles in the\ncharacterization of linear belief aggregation, multiple-weight aggregation, and\nan aggregation rule which can be viewed as the outcome of a game played by\n\"dual-selves,\" Pessimism and Optimism. Under suitable conditions, I establish\nequivalences between various relaxations of Commutativity and classic axioms\nfor decision-making under uncertainty, including Independence, C-Independence,\nand Ambiguity Aversion.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14959v1"
    },
    {
        "title": "Dynamic Signals",
        "authors": [
            "Mark Whitmeyer",
            "Cole Williams"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, we reveal that the signal representation of information\nintroduced by Gentzkow and Kamenica (2017) can be applied profitably to dynamic\ndecision problems. We use this to characterize when one dynamic information\nstructure is more valuable to an agent than another, irrespective of what other\ndynamic sources of information the agent may possess. Notably, this robust\ndominance is equivalent to an intuitive dynamic version of Brooks, Frankel, and\nKamenica (2022)'s reveal-or-refine condition.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16648v1"
    },
    {
        "title": "Colonel Blotto Game: An Analysis and Extension to Networks",
        "authors": [
            "Sidarth Erat"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The Colonel Blotto game, introduced by Borel in the 1920s, is often used for\nmodeling various real-life settings, such as elections, lobbying, etc. The game\nis based on the allocation of limited resources by players to a set of fields.\nEach field is ``won'' and a corresponding field-specific value is obtained by\nthe player who sends the most resources. In this paper, we formulate a discrete\nBlotto game played on a general \\textit{accessibility network} (i.e., the\nbipartite graph made of players and the fields they can allocate resources to).\nThe primary goal is to find how the topology of the accessibility network\ncontrols the existence and uniqueness of equilibrium allocations, and how it\naffects the fraction of fields that are entered and the average payoff of\nplayers at equilibrium. We establish that, in a 2-regular topology, when the\nvalues of fields are close enough and the number of players is not a multiple\nof 4, then there is a unique equilbrium. We also prove that players are better\noff and fields are more likely to be entered in a regular topology than a\nrandom topology. We find numerically that dispersion of field weights\nnegatively affects average player payoff. The main contribution is a framework\nfor analyzing contests where players are permitted access to some (but not\nnecessarily all) venues of competition.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16707v1"
    },
    {
        "title": "Quantity Limits on Addictive Goods",
        "authors": [
            "Eric Gao"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Addiction is a major societal issue leading to billions in healthcare losses\nper year. Policy makers often introduce ad hoc quantity limits-limits on the\nconsumption or possession of a substance-something which current economic\nmodels of addiction have failed to address. This paper enriches Bernheim and\nRangel (2004)'s model of addiction driven by cue-triggered decisions by\nincorporating endogenous choice of how much of the addictive good to consume,\ninstead of just whether or not consumption happens. Stricter quality limits\nimprove welfare as long as they do not preclude the myopically optimal level of\nconsumption.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16987v1"
    },
    {
        "title": "Robust Comparative Statics with Misspecified Bayesian Learning",
        "authors": [
            "Aniruddha Ghosh"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We present novel monotone comparative statics results for steady state\nbehavior in a dynamic optimization environment with misspecified Bayesian\nlearning. We consider a generalized framework, based on Esponda and Pouzo\n(2021), wherein a Bayesian learner facing a dynamic optimization problem has a\nprior on a set of parameterized transition probability functions (models) but\nis misspecified in the sense that the true process is not within this set. In\nthe steady state, the learner infers the model that best-fits the data\ngenerated by their actions, and in turn, their actions are optimally chosen\ngiven their inferred model. We characterize conditions on the primitives of the\nenvironment, and in particular, over the set of models under which the steady\nstate distribution over states and actions and inferred models exhibit\nmonotonic behavior. Further, we offer a new theorem on the existence of a\nsteady state on the basis of a monotonicity argument. Lastly, we provide an\nupper bound on the cost of misspecification, again in terms of the primitives\nof the environment. We demonstrate the utility of our results for several\nenvironments of general interest, including forecasting models, dynamic\neffort-task, and optimal consumption-savings problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.17037v1"
    },
    {
        "title": "Diversity in Choice as Majorization",
        "authors": [
            "Federico Echenique",
            "Teddy Mekonnen",
            "M. Bumin Yenmez"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We use majorization to model comparative diversity in school choice. A\npopulation of agents is more diverse than another population of agents if its\ndistribution over groups is less concentrated: being less concentrated takes a\nspecific mathematical meaning borrowed from the theory of majorization. We\nadapt the standard notion of majorization in order to favor arbitrary\ndistributional objectives, such as population-level distributions over\nrace/ethnicity or socioeconomic status. With school admissions in mind, we\naxiomatically characterize choice rules that are consistent with modified\nmajorization, and constitute a principled method for admitting a diverse\npopulation of students into a school. Two important advantages of our approach\nis that majorization provides a natural notion of diversity, and that our\naxioms are independent of any exogenous priority ordering. We compare our\nchoice rule to the leading proposal in the literature, ``reserves and quotas,''\nand find ours to be more flexible.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.17589v1"
    },
    {
        "title": "Generalization of Zhou fixed point theorem",
        "authors": [
            "Lu Yu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We give two generalizations of the Zhou fixed point theorem. They weaken the\nsubcompleteness condition of values, and relax the ascending condition of the\ncorrespondence. As an application, we derive a generalization of Topkis's\ntheorem on the existence and order structure of the set of Nash equilibria of\nsupermodular games.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.17884v1"
    },
    {
        "title": "Order-theoretical fixed point theorems for correspondences and\n  application in game theory",
        "authors": [
            "Lu Yu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  For an ascending correspondence $F:X\\to 2^X$ with chain-complete values on a\ncomplete lattice $X$, we prove that the set of fixed points is a complete\nlattice. This strengthens Zhou's fixed point theorem. For chain-complete posets\nthat are not necessarily lattices, we generalize the Abian-Brown and the\nMarkowsky fixed point theorems from single-valued maps to multivalued\ncorrespondences. We provide an application in game theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.18582v1"
    },
    {
        "title": "Getting the Agent to Wait",
        "authors": [
            "Maryam Saeedi",
            "Yikang Shen",
            "Ali Shourideh"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine the strategic interaction between an expert (principal) maximizing\nengagement and an agent seeking swift information. Our analysis reveals: When\npriors align, relative patience determines optimal disclosure -- impatient\nagents induce gradual revelation, while impatient principals cause delayed,\nabrupt revelation. When priors disagree, catering to the bias often emerges,\nwith the principal initially providing signals aligned with the agent's bias.\nWith private agent beliefs, we observe two phases: one engaging both agents,\nfollowed by catering to one type. Comparing personalized and non-personalized\nstrategies, we find faster information revelation in the non-personalized case,\nbut higher quality information in the personalized case.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19127v1"
    },
    {
        "title": "Certifying Lemons",
        "authors": [
            "Hershdeep Chopra"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper examines an adverse selection environment where a sender with\nprivate information (high or low ability) tries to convince a receiver of\nhaving higher ability. Without commitment or costly signaling, market failure\ncan occur. Certification intermediaries reduce these frictions by enabling\nsignaling through hard information. This paper focuses on a monopolistic\ncertifier and its impact on equilibrium welfare and certificate design. Key\nfindings show that the certifier provides minimal information, pooling senders\nof varying abilities and leaving low rents for high type senders, which\ntypically disadvantages the receiver. However, when precise information is\ndemanded, the certifier screens the sender perfectly, benefiting the receiver.\nThus, the monopolistic intermediary has an ambiguous effect on market\nefficiency. The results emphasize the importance of high certification\nstandards, which drive low ability senders out of the market. Conditions for\nsuch equilibria are characterized, showing how simple threshold strategies by\nthe receiver induce first-best outcomes. Additionally, the relationship between\nthe characteristics of offered certificates and welfare is identified.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19814v2"
    },
    {
        "title": "Unimprovable Students and Inequality in School Choice",
        "authors": [
            "Josue Ortega",
            "Gabriel Ziegler",
            "R. Pablo Arribillaga"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The Efficiency-Adjusted Deferred Acceptance (EADA) mechanism corrects the\nPareto-inefficiency of the celebrated Deferred Acceptance (DA) algorithm by\nassigning every student to a weakly more preferred school. However, it remains\nuncertain which and how many students do not see an improvement in their DA\nplacement under EADA. We show that, despite its advantages, EADA does not\nbenefit students assigned to their worst-ranked schools or those who remain\nunmatched under DA. Additionally, it limits the placement improvement of\nmarginalized students, thereby maintaining school segregation. The placement of\nworst-off students under EADA can be exceptionally poor, even though\nsignificantly more egalitarian allocations are possible. Lastly, we provide a\nbound on the expected number of unimproved students using a random market\napproach valid for small markets. Our findings shed light on why EADA fails to\nmitigate the inequality produced by DA in empirical evaluations.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19831v3"
    },
    {
        "title": "Persuading an inattentive and privately informed receiver",
        "authors": [
            "Pietro Dall'Ara"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies the persuasion of a receiver who accesses information only\nif she exerts costly attention effort. A sender designs an experiment to\npersuade the receiver to take a specific action. The experiment affects the\nreceiver's attention effort, that is, the probability that she updates her\nbeliefs. As a result, persuasion has two margins: extensive (effort) and\nintensive (action). The receiver's utility exhibits a supermodularity property\nin information and effort. By leveraging this property, we prove a general\nequivalence between experiments and persuasion mechanisms \\`a la Kolotilin et\nal.\\ (2017). In applications, the sender's optimal strategy involves censoring\nfavorable states.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01250v2"
    },
    {
        "title": "Harmful choices",
        "authors": [
            "Angelo Petralia"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We investigate the choice behavior of a decision maker (DM) who harms\nherself, by maximizing in each menu some distortion of her true preference, in\nwhich the first i alternatives are moved to the bottom, in a reversed order.\nThe deterministic declination of our pattern has no empirical power, but it\nallows to define a degree of self-punishment, which measures the extent of the\ndenial of pleasure adopted by the DM in her decision. We analyze irrational\nchoices that display the lowest degree of self-punishment, and a\ncharacterization of them is provided. Moreover, we characterize the choice\nbehavior that exhibits the highest degree of self-punishment, and we show that\nit comprises almost all choices. We also characterize stochastic\nself-punishment, which collects all the Random Utility Models (RUMs) whose\nsupport is restricted to the harmful distortions of some preference. Necessary\nand sufficient conditions for a full identification of the DM's preference and\nrandomization over its harmful distortions are singled out. Finally, the degree\nof self-punishment of harmful stochastic choices is characterized.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01317v9"
    },
    {
        "title": "Strategic Analysis of Fair Rank-Minimizing Mechanisms with Agent Refusal\n  Option",
        "authors": [
            "Yasunori Okumura"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This study examines strategic issues in fair rank-minimizing mechanisms,\nwhich choose an assignment that minimizes the average rank of object types to\nwhich agents are assigned and satisfy a fairness property called equal\ntreatment of equals. As one of these fair mechanisms, the uniform\nrank-minimizing mechanism is considered. We focus on the case where agents can\nrefuse their assignment and obtain the outside option instead. Without the\nrefusal option, truth-telling is not strategically dominated by any strategies\nif a fair rank-minimizing mechanism is used. However, if agents have the option\nand the uniform rank-minimizing mechanism is used, then a strategy called an\noutside option demotion strategy strategically dominates truth-telling.\nMoreover, we show that adopting this strategy may lead to inefficient\nassignments. To counter this, we propose a modification of the uniform\nrank-minimizing mechanism, though it may lead agents to strategically reduce\nthe number of acceptable types.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01673v4"
    },
    {
        "title": "The Logic of Political Survival Revisited: Consequences of Elite\n  Uncertainty Under Authoritarian Rule",
        "authors": [
            "Tamar Zeilberger"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Existing research has established that autocrats offer concessions to prevent\nouster by their inner circle. This paper examines how those concessions are\ninfluenced by the relative uncertainty of an autocrat's inner circle about\nremaining in that favored body. I take as my starting point the formal model of\npolitical survival presented in Bueno de Mesquita et al.'s The Logic of\nPolitical Survival. I extend the model to account for variation in the relative\nuncertainty of an autocrat's inner circle. To make the math tractable, I\ndispense with convention and introduce comparative statics across two models\nwith different formulations of uncertainty. This exercise reveals a set of\nconditions under which to expect an increase in the concessions offered by an\nautocrat, with implications for development and democracy. Those findings yield\na corresponding set of logical corollaries with potential to further our\nunderstanding of authoritarian politics, including an unexamined facet of the\n\"dictator's dilemma\" (Wintrobe 1990, 1998) and related incentives for members\nof an inner circle to permit purges or act to destabilize their ranks. The\nmodels also identify a source of policy volatility not found outside of\nautocracies. Taken together, the findings suggest a need for more research on\nelite uncertainty in autocracies.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01887v1"
    },
    {
        "title": "Bargaining via Weber's law",
        "authors": [
            "V. G. Bardakhchyan",
            "A. E. Allahverdyan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We solve the two-player bargaining problem employing Weber's law in\npsychophysics, which is applied to the perception of utility changes. Using\nthis law, the players define the jointly acceptable range of utilities on the\nPareto line, which narrows down the range of possible solutions. Choosing a\nunique solution can be achieved by applying the Weber approach iteratively. The\nsolution is covariant to independent affine transformations of utilities. We\nprovide a behavioral interpretation of this solution, where the players\nnegotiate via Weber's law. For susceptible players, iterations are unnecessary,\nso they converge in one stage toward the (axiomatic) asymmetric Nash solution\nof the bargaining problem, where the weights of each player are expressed via\ntheir Weber constants. Thus the Nash solution is reached without external\narbiters and without requiring the independence of irrelevant alternatives. We\nalso show that our solution applies to the ultimatum game (which is not\nbargaining but still involves offer formation) and leads to an affine-covariant\nsolution of this game that can reproduce its empirical features. Unlike\nprevious solutions (e.g. the one based on fairness), ours does not involve\ncomparing inter-personal utilities and is based on a partial symmetry between\nthe proposer and respondent.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.02492v3"
    },
    {
        "title": "The Design and Price of Influence",
        "authors": [
            "Raphael Boleslavsky",
            "Aaron Kolb"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A sender has a privately known preference over the action chosen by a\nreceiver. The sender would like to influence the receiver's decision by\nproviding information, in the form of a statistical experiment or test. The\ntechnology for information production is controlled by a monopolist\nintermediary, who offers a menu of tests and prices to screen the sender's\ntype, possibly including a \"threat\" test to punish nonparticipation. We\ncharacterize the intermediary's optimal screening menu and the associated\ndistortions, which we show may benefit the receiver. We compare the sale of\npersuasive information with other forms of influence -- overt bribery and\ncontrolling access.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.03689v1"
    },
    {
        "title": "Robust Market Design with Opaque Announcements",
        "authors": [
            "Aram Grigoryan",
            "Markus Möller"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We introduce a framework where the announcements of a clearinghouse about the\nallocation process are opaque in the sense that there can be more than one\noutcome compatible with a realization of type reports. We ask whether desirable\nproperties can be ensured under opacity in a robust sense. A property can be\nguaranteed under an opaque announcement if every mechanism compatible with it\nsatisfies the property. We find an impossibility result: strategy-proofness\ncannot be guaranteed under any level of opacity. In contrast, in some\nenvironments, weak Maskin monotonicity and non-bossiness can be guaranteed\nunder opacity.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04509v1"
    },
    {
        "title": "Revealed Invariant Preference",
        "authors": [
            "Peter Caradonna",
            "Christopher P. Chambers"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider the problem of rationalizing choice data by a preference\nsatisfying an arbitrary collection of invariance axioms. Examples of such\naxioms include quasilinearity, homotheticity, independence-type axioms for\nmixture spaces, constant relative/absolute risk and ambiguity aversion axioms,\nstationarity for dated rewards or consumption streams, separability, and many\nothers. We provide necessary and sufficient conditions for invariant\nrationalizability via a novel approach which relies on tools from the\ntheoretical computer science literature on automated theorem proving. We also\nestablish a generalization of the Dushnik-Miller theorem, which we use to give\na complete description of the out-of-sample predictions generated by the data\nunder any such collection of axioms.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04573v1"
    },
    {
        "title": "Protected Income and Inequality Aversion",
        "authors": [
            "Marc Fleurbaey",
            "Eduardo Zambrano"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Imagine that a large increment can be given to an individual in a society. We\nask: what is the maximal sacrifice that can be imposed on another individual\naccording to an evaluator for the sake of this increment? We show that the\nanswer can reveal how inequality averse an evaluator is. In particular, all\nKolm-Pollak evaluators would sacrifice the full income of the sacrificed\nindividual if their income was low enough and a declining fraction of their\nincome otherwise. Kolm-Atkinson evaluators would sacrifice the full income of\nthe sacrificed individual, for all income levels, if their inequality aversion\nwas no greater than one, and sacrifice a constant fraction of their income\notherwise. Motivated by these findings, we propose a class of social\npreferences that, starting from a baseline level of protection, protect a\nhigher fraction of the sacrificed individual's income the lower their income.\nIn addition to relating levels of protected income to coefficients of\ninequality, we also characterize the classes of additively separable social\nwelfare functions that guarantee specific (absolute or relative) levels of\nprotection.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04814v2"
    },
    {
        "title": "Recurrent Stochastic Fluctuations with Financial Speculation",
        "authors": [
            "Tomohiro Hirano"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Throughout history, many countries have repeatedly experienced large swings\nin asset prices, which are usually accompanied by large fluctuations in\nmacroeconomic activity. One of the characteristics of the period before major\neconomic fluctuations is the emergence of new financial products; the situation\nprior to the 2008 financial crisis is a prominent example of this. During that\nperiod, a variety of structured bonds, including securitized products,\nappeared. Because of the high returns on such financial products, many economic\nagents were involved in them for speculative purposes, even if they were\nriskier, producing macro-scale effects.\n  With this motivation, we present a simple macroeconomic model with financial\nspeculation. Our model illustrates two points. First, stochastic fluctuations\nin asset prices and macroeconomic activity are driven by the repeated\nappearance and disappearance of risky financial assets, rather than expansions\nand contractions in credit availability. Second, in an economy with sufficient\nborrowing and lending, the appearance of risky financial assets leads to\ndecreased productive capital, while in an economy with severely limited\nborrowing and lending, it leads to increased productive capital.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.05047v1"
    },
    {
        "title": "Dynamic choices, temporal invariance and variational discounting",
        "authors": [
            "Bach Dong-Xuan",
            "Philippe Bich"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  People often face trade-offs between costs and benefits occurring at various\npoints in time. The predominant discounting approach is to use the exponential\nform. Central to this approach is the discount rate, a unique parameter that\nconverts a future value into its present equivalent. However, a universally\naccepted discount rate remains a matter of ongoing debate and lacks consensus.\nThis paper provides a robust solution for resolving conflicts in discount\nrates, which recommends considering all discount rates but aims to assign\nvarying degrees of importance to these rates. Moreover, a considerable number\nof economists support a theory that suggests equal consideration of future and\npresent utilities. In response to this debate, we introduce a general criterion\ncapable of accommodating situations where it is feasible not to discount future\nutilities. This criterion encompasses and extends various existing criteria in\nthe literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.05632v1"
    },
    {
        "title": "Identifying Restrictions on the Random Utility Model",
        "authors": [
            "Peter P. Caradonna",
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We characterize those ex-ante restrictions on the random utility model which\nlead to identification. We first identify a simple class of perturbations which\ntransfer mass from a suitable pair of preferences to the pair formed by\nswapping certain compatible lower contour sets. We show that two distributions\nover preferences are behaviorally equivalent if and only if they can be\nobtained from each other by a finite sequence of such transformations. Using\nthis, we obtain specialized characterizations of which restrictions on the\nsupport of a random utility model yield identification, as well as of the\nextreme points of the set of distributions rationalizing a given data set.\nFinally, when a model depends smoothly on some set of parameters, we show that\nunder mild topological assumptions, identification is characterized by a\nstraightforward, local test.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.06547v1"
    },
    {
        "title": "Managing cascading disruptions through optimal liability assignment",
        "authors": [
            "Jens Gudmundsson",
            "Jens Leth Hougaard",
            "Jay Sethuraman"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Interconnected agents such as firms in a supply chain make simultaneous\npreparatory investments to increase chances of honouring their respective\nbilateral agreements. Failures cascade: if one fails their agreement, then so\ndo all who follow in the chain. Thus, later agents' investments turn out to be\npointless when there is an earlier failure. How losses are shared affects how\nagents invest to avoid the losses in the first place. In this way, a solution\nsets agent liabilities depending on the point of disruption and induces a\nsupermodular investment game. We characterize all efficient solutions. These\nhave the form that later agents -- who are not directly liable for the\ndisruption -- still shoulder some of the losses, justified on the premise that\nthey might have failed anyway. Importantly, we find that such indirect\nliabilities are necessary to avoid unbounded inefficiencies. Finally, we\npinpoint one efficient solution with several desirable properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07361v1"
    },
    {
        "title": "The Dial-a-Ride Problem with Limited Pickups per Trip",
        "authors": [
            "Boshuai Zhao",
            "Kai Wang",
            "Wenchao Wei",
            "Roel Leus"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The Dial-a-Ride Problem (DARP) is an optimization problem that involves\ndetermining optimal routes and schedules for several vehicles to pick up and\ndeliver items at minimum cost. Motivated by real-world carpooling and\ncrowdshipping scenarios, we introduce an additional constraint imposing a\nmaximum number on the number of pickups per trip. This results in the\nDial-a-Ride Problem with Limited Pickups per Trip (DARP-LPT). We apply a\nfragment-based method for DARP-LPT, where a fragment is a partial path.\nSpecifically, we extend two formulations from Rist & Forbes (2021): the\nFragment Flow Formulation (FFF) and the Fragment Assignment Formulation (FAF).\nWe establish FFF's superiority over FAF, both from a theoretical as well as\nfrom a computational perspective. Furthermore, our results show that FFF and\nFAF significantly outperform traditional arc-based formulations in terms of\nsolution quality and time. Additionally, compared to the two existing fragment\nsets, one with longer partial paths and another with shorter ones, our newly\ngenerated fragment sets perform better in terms of solution quality and time\nwhen fed into FFF.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07602v2"
    },
    {
        "title": "How to Make an Action Better",
        "authors": [
            "Marilyn Pease",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  For two actions in a decision problem, a and b, each of which that produces a\nstate-dependent monetary reward, we study how to robustly make action a more\nattractive. Action a' improves upon a in this manner if the set of beliefs at\nwhich a is preferred to b is a subset of the set of beliefs at which a' is\npreferred to b, irrespective of the risk-averse agent's utility function (in\nmoney). We provide a full characterization of this relation and discuss\napplications in politics, bilateral trade, insurance, and information\nacquisition.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09294v3"
    },
    {
        "title": "Undominated monopoly regulation",
        "authors": [
            "Debasis Mishra",
            "Sanket Patil"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study undominated mechanisms with transfers for regulating a monopolist\nwho privately observes the marginal cost of production. We show that in any\nundominated mechanism, there is a quantity floor, which depends only on the\nprimitives, and the regulator's operation decision is stochastic only if the\nmonopolist produces at the quantity floor. We provide a near-complete\ncharacterization of the set of undominated mechanisms and use it to (a) provide\na foundation for deterministic mechanisms, (b) show that the efficient\nmechanism is dominated, and (c) derive a max-min optimal regulatory mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09473v2"
    },
    {
        "title": "Monetizing digital content with network effects: A mechanism-design\n  approach",
        "authors": [
            "Vincent Meisner",
            "Pascal Pillath"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We design profit-maximizing mechanisms to sell an excludable and non-rival\ngood with network effects. Buyers have heterogeneous private values that depend\non how many others also consume the good. In optimum, an endogenous number of\nthe highest types consume the good, and we provide an algorithm that implements\nthis allocation in dominant strategies. We apply our insights to digital\ncontent creation, and we are able to rationalize features seen in monetization\nschemes in this industry such as voluntary contributions, community subsidies,\nand exclusivity bids.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.15196v3"
    },
    {
        "title": "Robust Robustness",
        "authors": [
            "Ian Ball",
            "Deniz Kattwinkel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The maxmin approach to distributional robustness evaluates each mechanism\naccording to its payoff guarantee over all priors in an ambiguity set. We\npropose a refinement: the guarantee must be approximately satisfied at priors\nnear the ambiguity set (in the weak topology). We call such a guarantee robust.\nThe payoff guarantees from some maxmin-optimal mechanisms in the literature are\nnot robust. We show, however, that over certain standard ambiguity sets (such\nas continuous moment sets), every mechanism's payoff guarantee is robust. We\ngive a behavioral characterization of our refined robustness notion by imposing\na new continuity axiom on maxmin preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.16898v2"
    },
    {
        "title": "Why do elites extend property rights: unlocking investment and the\n  switch to public goods",
        "authors": [
            "Alastair Langtry"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper presents a new rationale for a self-interested economic elite\nvoluntarily extending property rights. When agents make endogenous investment\ndecisions, there is a commitment problem. Ex-post, the elite face strong\nincentives to expropriate investments from the non-elite (who don't have\nproperty rights), which dissuades investment. Extending property rights to new\ngroups can resolve this problem, even for those not given property rights, by\nmaking public good provision more attractive to the elite. Unlike other models\nof franchise extensions, extending property rights in this paper does not\ninvolve the elite ceding control to others. Rather, it changes the incentives\nthey face. Additionally, adding identity groups to the model shows that an\nelite faces weaker incentives to resolve the commitment problem when it is part\nof a minority identity -- identity fragmentation makes it harder for a society\nto extend property rights.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.17335v1"
    },
    {
        "title": "Robust Technology Regulation",
        "authors": [
            "Andrew Koh",
            "Sivakorn Sanguanmoo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze how uncertain technologies should be robustly regulated. An agent\ndevelops a new technology and, while privately learning about its harms and\nbenefits, continually chooses whether to continue development. A principal,\nuncertain about what the agent might learn, chooses among dynamic mechanisms\n(e.g., paths of taxes or subsidies) to influence the agent's choices in\ndifferent states. We show that learning robust mechanisms -- those which\ndeliver the highest payoff guarantee across all learning processes -- are\nsimple and resemble `regulatory sandboxes' consisting of zero marginal tax on\nR&D which keeps the agent maximally sensitive to new information up to a hard\nquota, upon which the agent turns maximally insensitive. Robustness is\nimportant: we characterize the worst-case learning process under non-robust\nmechanisms and show that they induce growing but weak optimism which can\ndeliver unboundedly poor principal payoffs; hard quotas safeguard against this.\nIf the regulator also learns, adaptive hard quotas are robustly optimal which\nhighlights the importance of expertise in regulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.17398v1"
    },
    {
        "title": "Optimal allocations with capacity constrained verification",
        "authors": [
            "Albin Erlanson",
            "Andreas Kleiner"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A principal has $m$ identical objects to allocate among a group of $n$\nagents. Objects are desirable and the principal's value of assigning an object\nto an agent is the agent's private information. The principal can verify up to\n$k$ agents, where $k<m$, thereby perfectly learning the types of those\nverified. We find the mechanism that maximizes the principal's expected utility\nwhen no monetary transfers are available. In this mechanism, an agent receives\nan object if (i) his type is above a cutoff and among the $m$ highest types,\n(ii) his type is above some lower cutoff but among the $k$ highest types, or\n(iii) he receives an object in a lottery that allocates the remaining objects\nrandomly.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.02031v1"
    },
    {
        "title": "Uniform price auction with quantity constraints",
        "authors": [
            "Kiho Yoon"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the equilibria of uniform price auctions where bidders have flat\ndemands up to their respective quantity constraints. We present an iterative\nprocedure that systematically finds a Nash equilibrium outcome under\nsemi-complete information as well as a novel ascending auction under incomplete\ninformation that has this outcome as a dominant strategy equilibrium. Demand\nreduction and low price equilibrium may occur since it is sometimes\nadvantageous for a bidder to give up some of his/her demand and get the\nremaining demand at a low price rather than to get his/her entire demand at a\nhigher price.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.04047v1"
    },
    {
        "title": "Obvious Strategy-proofness with Respect to a Partition",
        "authors": [
            "R. Pablo Arribillaga",
            "Jordi Massó",
            "Alejandro Neme"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We define and study obvious strategy-proofness with respect to a partition of\nthe set of agents. It encompasses strategy-proofness as a special case when the\npartition is the coarsest one and obvious strategy-proofness when the partition\nis the finest. For any partition, it falls between these two extremes. We\nestablish two general properties of this new notion and apply it to the simple\nanonymous voting problem with two alternatives and strict preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05315v1"
    },
    {
        "title": "Strictly Proper Scoring Mechanisms Without Expected Arbitrage",
        "authors": [
            "Jack Edwards"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  When eliciting forecasts from a group of experts, it is important to reward\npredictions so that market participants are incentivized to tell the truth.\nExisting mechanisms partially accomplish this but remain susceptible to groups\nof experts colluding to increase their expected reward, meaning that no\naggregation of predictions can be fully trusted to represent the true beliefs\nof forecasters. This paper presents two novel scoring mechanisms which elicit\ntruthful forecasts from any group of experts, even if they can collude or\naccess each other's predictions. The key insight of this approach is a\nrandomization component which maintains strict properness but prevents experts\nfrom coordinating dishonest reports in advance. These mechanisms are strictly\nproper and do not admit expected arbitrage, resolving an open question in the\nfield.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.07046v2"
    },
    {
        "title": "Balancing Selection Efficiency and Societal Costs in Selective Contests",
        "authors": [
            "Penghuan Yan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Selective contests can impair participants' overall welfare in\novercompetitive environments, such as school admissions. This paper models the\nsituation as an optimal contest design problem with binary actions, treating\neffort costs as societal costs incurred to achieve a desired level of\nselectivity. We provide a characterization for the feasible set of selection\nefficiency and societal cost in selective contests by establishing their\nrelationship with feasible equilibrium strategies. We find that selection\nefficiency and contestants' welfare are complementary, i.e. it is almost\nimpossible to improve one without sacrificing the other. We derive the optimal\nequilibrium outcome given the feasible set and characterize the corresponding\noptimal contest design. Our analysis demonstrates that it is always optimal for\na contest designer who is sufficiently concerned with societal cost to\nintentionally introduce randomness into the contest. Furthermore, we show that\nthe designer can optimize any linear payoff function by adjusting a single\nparameter related to the intensity of randomness, without altering the specific\nstructure of the contest.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09768v4"
    },
    {
        "title": "Beyond Rationality: Unveiling the Role of Animal Spirits and Inflation\n  Extrapolation in Central Bank Communication of the US",
        "authors": [
            "Arpan Chakraborty"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Modern macroeconomic models, particularly those grounded in Rational\nExpectation Dynamic Stochastic General Equilibrium (DSGE), operate under the\nassumption of fully rational decision-making. This paper examines the impact of\nbehavioral factors, particularly 'animal spirits' (emotional and psychological\ninfluences on economic decisions) and 'inflation extrapolators', on the\ncommunication index/sentiment index of the US Federal Reserve. Utilizing\nsimulations from a behavioral New Keynesian model alongside real-world data\nderived from Federal Reserve speeches, the study employs an Auto-Regressive\nDistributed Lag (ARDL) technique to analyze the interplay between these\nfactors. The findings indicate that while the fraction of inflation\nextrapolators do not significantly affect the Fed's sentiment index, various\naspects of animal spirits exert a notable impact. This suggests that not only\nis the US output gap influenced by animal spirits, but the Federal Reserve's\ncommunication is also substantially shaped by these behavioral factors. This\nhighlights the limitations of rational expectation DSGE models and underscores\nthe importance of incorporating behavioral insights to achieve a more nuanced\nunderstanding of economic dynamics and central bank communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.10938v1"
    },
    {
        "title": "Expert Classification Aggregation",
        "authors": [
            "Federico Fioravanti"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider the problem where a set of individuals has to classify $m$\nobjects into $p$ categories by aggregating the individual classifications, and\nno category can be left empty. An aggregator satisfies \\emph{Expertise} if\nindividuals are decisive either over the classification of a given object, or\nthe classification into a given category. We show that requiring an aggregator\nto satisfy \\emph{Expertise} and be either unanimous or independent leads to\nnumerous impossibility results.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.11033v1"
    },
    {
        "title": "Approximately Optimal Auctions With a Strong Bidder",
        "authors": [
            "Luca Anderlini",
            "GaOn Kim"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider auctions with N+1 bidders. Of these, N are symmetric and N+1 is\n\"sufficiently strong\" relative to the others. The auction is a \"tournament\" in\nwhich the first N players bid to win the right to compete with N+1. The bids of\nthe first N players are binding and the highest bidder proceeds to a\nsecond-price competition with N+1.\n  When N+1's values converge in distribution to an atom above the upper end of\nthe distribution of the N bidders and the rest of the distribution is drained\naway from low values sufficiently slowly, the auction's expected revenue is\narbitrarily close to the one obtained in a Myerson (1981) optimal auction.\n  The tournament design is \"detail free\" in the sense that no specific\nknowledge of the distributions is needed in addition to the fact that bidder\nN+1 is stronger than the others as required. In particular, no additional\ninformation about the value of the atom is needed. This is important since\nmis-calibrating by a small amount an attempt to implement the optimal auction\ncan lead to large losses in revenue.\n  We provide an interpretation of these results as possibly providing\nguidelines to a seller on how to strategically \"populate\" auctions with a\nsingle bidder even when only weaker bidders are available.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.11048v1"
    },
    {
        "title": "A knapsack for collective decision-making",
        "authors": [
            "Yurun Ge",
            "Lucas Böttcher",
            "Tom Chou",
            "Maria R. D'Orsogna"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Collective decision-making is the process through which diverse stakeholders\nreach a joint decision. Within societal settings, one example is participatory\nbudgeting, where constituents decide on the funding of public projects. How to\nmost efficiently aggregate diverse stakeholder inputs on a portfolio of\nprojects with uncertain long-term benefits remains an open question. We address\nthis problem by studying collective decision-making through the integration of\npreference aggregation and knapsack allocation methods. Since different\nstakeholder groups may evaluate projects differently,we examine several\naggregation methods that combine their diverse inputs. The aggregated\nevaluations are then used to fill a ``collective'' knapsack. Among the methods\nwe consider are the arithmetic mean, Borda-type rankings, and delegation to\nexperts. We find that the factors improving an aggregation method's ability to\nidentify projects with the greatest expected long-term value include having\nmany stakeholder groups, moderate variation in their expertise levels, and some\ndegree of delegation or bias favoring groups better positioned to objectively\nassess the projects. We also discuss how evaluation errors and heterogeneous\ncosts impact project selection. Our proposed aggregation methods are relevant\nnot only in the context of funding public projects but also, more generally,\nfor organizational decision-making under uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.13236v1"
    },
    {
        "title": "Sequential Network Design",
        "authors": [
            "Yang Sun",
            "Wei Zhao",
            "Junjie Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study dynamic network formation from a centralized perspective. In each\nperiod, the social planner builds a single link to connect previously unlinked\npairs. The social planner is forward-looking, with instantaneous utility\nmonotonic in the aggregate number of walks of various lengths. We show that,\nforming a nested split graph at each period is optimal, regardless of the\ndiscount function. When the social planner is sufficiently myopic, it is\noptimal to form a quasi-complete graph at each period, which is unique up to\npermutation. This finding provides a micro-foundation for the quasi-complete\ngraph, as it is formed under a greedy policy. We also investigate the\nrobustness of these findings under non-linear best response functions and\nweighted networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.14136v1"
    },
    {
        "title": "Competitive Markets with Imperfectly Discerning Consumers",
        "authors": [
            "Yair Antler ad Ran Spiegler"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We develop a market model in which products generate state-dependent\npotential hidden charges. Firms differ in their ability to realize this\npotential. Unlike firms, consumers do not observe the state. They try to infer\nhidden charges from market prices, using idiosyncratic subjective models. We\nshow that an interior competitive equilibrium is uniquely given by what is\nformally a Bellman equation. We leverage this representation to characterize\nequilibrium headline prices, add-on charges and welfare. Market responses to\nshocks display patterns that are impossible under rational expectations. For\nexample, equilibrium prices can be fully revealing and yet vary with consumers'\nprivate information.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.14885v1"
    },
    {
        "title": "Deep Learning to Play Games",
        "authors": [
            "Daniele Condorelli",
            "Massimiliano Furlan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We train two neural networks adversarially to play normal-form games. At each\niteration, a row and column network take a new randomly generated game and\noutput individual mixed strategies. The parameters of each network are\nindependently updated via stochastic gradient descent to minimize expected\nregret given the opponent's strategy. Our simulations demonstrate that the\njoint behavior of the networks converges to strategies close to Nash equilibria\nin almost all games. For all $2 \\times 2$ and in 80% of $3 \\times 3$ games with\nmultiple equilibria, the networks select the risk-dominant equilibrium. Our\nresults show how Nash equilibrium emerges from learning across heterogeneous\ngames.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.15197v1"
    },
    {
        "title": "The Political Economy of Zero-Sum Thinking",
        "authors": [
            "S. Nageeb Ali",
            "Maximilian Mihm",
            "Lucas Siga"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper offers a strategic rationale for zero-sum thinking in elections.\nWe show that asymmetric information and distributional considerations together\nmake voters wary of policies supported by others. This force impels a majority\nof voters to support policies contrary to their preferences and information.\nOur analysis identifies and interprets a form of \"adverse correlation\" that is\nnecessary and sufficient for zero-sum thinking to prevail in equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.15946v1"
    },
    {
        "title": "Continuity and Monotonicity of Preferences and Probabilistic Equivalence",
        "authors": [
            "Sushil Bikhchandani",
            "Uzi Segal"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We show that probabilistic equivalence of a regret-based preference\nrelationship over random variables is implied by a weak form of continuity and\nmonotonicity.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.17529v1"
    },
    {
        "title": "Dynamic Competition for Attention",
        "authors": [
            "Jan Knoepfle"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies information transmission from multiple senders who compete\nfor the attention of a decision maker. Each sender is partially informed about\nthe state of the world and decides how to reveal her information over time to\nmaximise attention. A decision maker wants to learn about the state but faces\nan attention cost. We derive a condition on the informational environment and\nthe decision problem that guarantees that all information from the senders can\nbe transmitted to the decision maker in equilibrium. A simple class of\ninformation processes implements full transmission across general environments.\nThe attention each sender receives is proportional to the residual value of her\ninformation. In the case of conditionally iid-informed senders, in the limit as\nthe number of senders grows large, the receiver learns the state exactly and\nimmediately (at no attention cost).\n",
        "pdf_link": "http://arxiv.org/pdf/2409.18595v2"
    },
    {
        "title": "Mechanism Design with Endogenous Perception",
        "authors": [
            "Benjamin Balzer",
            "Benjamin Young"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We model endogenous perception of private information in single-agent\nscreening problems, with potential evaluation errors. The agent's evaluation of\ntheir type depends on their cognitive state: either attentive (i.e., they\ncorrectly perceive their type) or inattentive (i.e., they might misperceive\ntheir type). The mechanism's incentives structure determines the agent's\ncognitive state via costly investment in cognition. We derive a general\nrepresentation of attention incentives, show how they vary with the mechanism's\nallocation rule, and define a notion of accuracy of perception. In applications\nwe showcase how perception both shapes and is shaped by the design of\nmechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.19853v2"
    },
    {
        "title": "Anonymity and strategy-proofness on a domain of single-peaked and\n  single-dipped preferences",
        "authors": [
            "Oihane Gallo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze the problem of locating a public facility on a line in a society\nwhere agents have either single-peaked or single-dipped preferences. We\nconsider the domain analyzed in Alcalde-Unzu et al. (2024), where the type of\npreference of each agent is public information, but the location of her\npeak/dip as well as the rest of the preference are unknown. We characterize all\nstrategy-proof and type-anonymous rules on this domain. Building on existing\nresults, we provide a two-step characterization\": first, the median between the\npeaks and a collection of fixed values is computed (Moulin, 1980), resulting in\neither a single alternative or a pair of contiguous alternatives. If the\noutcome of the median is a pair, we apply a double-quota majority method\" in\nthe second step to choose between the two alternatives in the pair (Moulin,\n1983). We also show the additional conditions that type-anonymity imposes on\nthe strategy-proof rules characterized by Alcalde-Unzu et al. (2024). Finally,\nwe show the equivalence between the two characterizations.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.03387v1"
    },
    {
        "title": "Persuasion with Ambiguous Communication",
        "authors": [
            "Xiaoyu Cheng",
            "Peter Klibanoff",
            "Sujoy Mukerji",
            "Ludovic Renou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper explores whether and to what extent ambiguous communication can be\nbeneficial to the sender in a persuasion problem, when the receiver (and\npossibly the sender) is ambiguity averse. We provide a concavification-like\ncharacterization of the sender's optimal ambiguous communication. The\ncharacterization highlights the necessity of using a collection of experiments\nthat form a splitting of an obedient (i.e., incentive compatible) experiment.\nSome experiments in the collection must be Pareto-ranked in the sense that both\nplayers agree on their payoff ranking. The existence of a binary such\nPareto-ranked splitting is necessary for ambiguous communication to benefit the\nsender, and, if an optimal Bayesian persuasion experiment can be split in this\nway, this is sufficient for an ambiguity-neutral sender as well as the receiver\nto benefit. Such gains are impossible when the receiver has only two actions.\nThe possibility of gains is substantially robust to (non-extreme) sender\nambiguity aversion.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.05504v2"
    },
    {
        "title": "Optimal Information Acquisition Strategies: The Case of Online Lending",
        "authors": [
            "Mendelson Haim",
            "Zhu Mingxi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Online lending has garnered significant attention in IS literature,\nparticularly platform lending, but direct (balance sheet) lending is\nincreasingly critical. This paper explores optimal information acquisition\nstrategies for direct online lenders, addressing the broader question: Should a\ndecision-maker rely on multiple lean experiments or opt for a single grand\nexperiment? We first examine a model where an online lender issuing unsecured\nloans maximizes its expected NPV at an exogenous interest rate, finding that a\nlean experimentation strategy is optimal. However, when the interest rate is\nendogenous, the choice between lean and grand experimentation depends on the\ndemand elasticity. If elasticity is increasing or constant, the lender prefers\na grand experiment, offering the same loan terms in each period. We also\nanalyze consumer segmentation and demonstrate how higher income variability\nbenefits the lender through more effective experimentation. In addition, we\ninvestigate hybrid information architectures that combine dynamic\nexperimentation with traditional static models. Our results show that the\nhybrid architecture enhances lender profitability, offering a flexible approach\nthat integrates sequential learning with static information. The study\ncontributes to understanding how different information architectures affect\nlending strategies, experimentation, and profitability in online lending.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.05539v1"
    },
    {
        "title": "Scoring Auctions with Coarse Beliefs",
        "authors": [
            "Joseph Feffer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies a simplicity notion in a mechanism design setting in which\nagents do not necessarily share a common prior. I develop a model in which\nagents participate in a prior-free game of (coarse) information acquisition\nfollowed by an auction. After acquiring information, the agents have\nuncertainty about the environment in which they play and about their opponents'\nhigher-order beliefs. A mechanism admits a coarse beliefs equilibrium if agents\ncan play best responses even with this uncertainty. Focusing on\nmultidimensional scoring auctions, I fully characterize a property that allows\nan auction format to admit coarse beliefs equilibria. The main result\nclassifies auctions into two sets: those in which agents learn relatively\nlittle about their setting versus those in which they must fully learn a type\ndistribution to form equilibrium strategies. I then find a simple, primitive\ncondition on the auction's rules to distinguish between these two classes. I\nthen use the condition to categorize real-world scoring auctions by their\nstrategic simplicity.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.06150v1"
    },
    {
        "title": "Impact of Artificial Intelligence on Environmental Quality through\n  Technical Change: A Free Dynamic Equilibrium Approach",
        "authors": [
            "Van Khanh Pham",
            "Duc Minh Le"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In the times we live in today, humanity faces unprecedented environmental\nchallenges. The emergence of artificial intelligence (AI) has opened new doors\nin our collective efforts to address our planet's pressing problems; however,\nmany have doubts on the actual extent of impact that AI have on the\nenvironment. In particular, AI also assisting dirty production is a drawback\nthat is largely absent from the literature. To investigate the impact of AI on\nthe environment, we establish mathematical models to model the economy and the\nproduction process of goods based on outdated and advanced technologies. The\nsecondary results are stated in the form of lemmas, the main results are stated\nin the form of theorems. From the theorems we conclude that AI may not on its\nown prevent an environmental disaster, a reason of which is its concurrent\ncontribution to dirty production. With temporary government intervention,\nhowever, AI is able to avert an environmental disaster.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.06501v1"
    },
    {
        "title": "Search Prominence with Costly Product Returns",
        "authors": [
            "Sanxi Li",
            "Jun Yu",
            "Mingsheng Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Search prominence may have a detrimental impact on a firm's profits in the\npresence of costly product returns. We analyze the impact of search prominence\non firm profitability in a duopoly search model, considering the presence of\ncostly product returns. Consumer match values are assumed to be independently\nand identically distributed across the two products. Our results show that the\nnon-prominent firm benefits from facing consumers with relatively low match\nvalues for the prominent firm's products, thus avoiding costly returns. When\nreturn costs are sufficiently high, the prominent firm may earn lower profits\nthan its non-prominent competitor. This outcome holds under both price\nexogeneity and price competition. Furthermore, the profitability advantage of\nprominence diminishes as return costs increase. Platforms that maximize ad\nrevenue should consider retaining positive return cost for consumers rather\nthan fully passing it on to firms. For e-commerce platforms, it is crucial to\nalign product return policies with broader management objectives to optimize\nfirm profitability.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.06791v1"
    },
    {
        "title": "Optimal Allocation with Peer Information",
        "authors": [
            "Axel Niemeyer",
            "Justus Preusser"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study allocation problems without monetary transfers where agents hold\nprivate information about one another, modeled as a general form of correlated\ninformation. Such peer information is relevant in a number of settings,\nincluding science funding, allocation of targeted aid, or intra-firm\nallocation. We characterize optimal dominant-strategy incentive-compatible\n(DIC) mechanisms using techniques from the theory of perfect graphs. Optimal\nDIC mechanisms tend to be complex and involve allocation lotteries that cannot\nbe purified without upsetting incentives. In rich type spaces, nearly all\nextreme points of the set of DIC mechanisms are stochastic. Finding an optimal\ndeterministic DIC mechanism is NP-hard. We propose the simple class of\nranking-based mechanisms and show that they are approximately optimal when\nagents are informationally small. These mechanisms allocate to agents ranked\nhighly by their peers but strategically deny the allocation to agents suspected\nof having evaluated their peers dishonestly.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.08954v1"
    },
    {
        "title": "The Pond Dilemma with Heterogeneous Relative Concerns",
        "authors": [
            "Paweł Gola"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper explores team formation when workers differ in skills and their\ndesire to out-earn co-workers. I cast this question as a two-dimensional\nassignment problem with imperfectly transferable utility and show that\nequilibrium sorting optimally trades off output maximisation with the need to\nmatch high-skill workers to co-workers with weak relative concerns. This can\nlead to positive (negative) assortative matching in skill even with submodular\n(supermodular) production functions. Under supermodular production, this\nheterogeneity in preferences benefits all workers and reduces wage inequality.\nWith submodular production, the distributional consequences are ambiguous, and\nsome workers become worse off. The model reveals that skill-biased\ntechnological change (SBTC) incentivises domestic outsourcing, as firms seek to\navoid detrimental social comparisons between high- and low-skill workers, thus\nproviding a compelling explanation for the long-term increase in outsourcing.\nFinally, the benefits of SBTC can trickle down to low-skill workers-but only\nthose whose relative concerns are weak.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12566v1"
    },
    {
        "title": "Peace in the Face of Uncertainty: Resource Allocation with Stochastic\n  Armaments",
        "authors": [
            "Sarah Taylor"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper examines a government's strategic resource allocation choices when\nfacing an opposing group whose military power is uncertain. We investigate how\nthis uncertainty affects the government's decision to divide resources in a way\nthat either guarantees peace, despite unresolved uncertainty, or risks\nconflict. We find that under low uncertainty, the government prefers\ndistributions which ensure peace, while under high uncertainty, they are\nwilling to risk war. When uncertainty is low, the government's allocation is\ndecreasing in uncertainty. When uncertainty is high it is increasing. The\nlatter leads to an increased probability of fighting and falling total welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.14362v1"
    },
    {
        "title": "Analysis of short-run and long-run marginal costs of generation in the\n  power market",
        "authors": [
            "Shamim Homaei",
            "Simon Roussanaly",
            "Asgeir Tomasgard"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In power markets, understanding the cost dynamics of electricity generation\nis crucial. The complexity of price formation in the power system arises from\nits diverse attributes, such as various generator types, each characterized by\nits specific fixed and variable costs as well as different lifetimes. In this\npaper, we adopt an approach that investigates both long-run marginal cost\n(LRMC) and short-run marginal cost (SRMC) in a perfect competition market.\nAccording to economic theory, marginal pricing serves as an effective method\nfor determining the generation cost of electricity. This paper presents a\ncapacity expansion model designed to evaluate the marginal cost of electricity\ngeneration, encompassing both long-term and short-term perspectives. Following\na parametric analysis and the calculation of LRMCs, this study investigates the\nallocation of investment costs across various time periods and how these costs\nfactor into the LRMC to ensure cost recovery. Additionally, an exploration of\nSRMCs reveals the conditions under which LRMCs and SRMCs converge or diverge.\nWe observe that when there is a disparity between LRMC and SRMC, setting\nelectricity generation prices equal to SRMCs does not ensure the complete\nrecovery of investment and operational costs. This phenomenon holds\nimplications for market reliability and challenges the pricing strategies that\nrely solely on SRMCs. Furthermore, our investigation highlighted the\nsignificance of addressing degeneracy in the power market modeling. Primal\ndegeneracy in the SRMC model can result in multiple values for the dual\nvariable representing SRMC. This multiplicity of values creates ambiguity\nregarding the precise SRMC value, making it challenging to ascertain the\ncorrect estimation. As a result, resolving degeneracy will ensure the\nreliability of the SRMC value, consequently enhancing the robustness and\ncredibility of our analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.15861v1"
    },
    {
        "title": "Commitment and Randomization in Communication",
        "authors": [
            "Emir Kamenica",
            "Xiao Lin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  When does a Sender, in a Sender-Receiver game, strictly value commitment? In\na setting with finite actions and finite states, we establish that,\ngenerically, Sender values commitment if and only if he values randomization.\nIn other words, commitment has no value if and only if a partitional experiment\nis optimal under commitment. Moreover, if Sender's preferred cheap-talk\nequilibrium necessarily involves randomization, then Sender values commitment.\nWe also ask: how often (i.e., for what share of preference profiles) does\ncommitment have no value? For any prior, any independent, atomless distribution\nof preferences, and any state space: if there are $\\left|A\\right|$ actions, the\nlikelihood that commitment has no value is at least\n$\\frac{1}{\\left|A\\right|^{\\left|A\\right|}}$. As the number of states grows\nlarge, this likelihood converges precisely to\n$\\frac{1}{\\left|A\\right|^{\\left|A\\right|}}$.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.17503v1"
    },
    {
        "title": "On Regularity and Normalization in Sequential Screening",
        "authors": [
            "Ian Ball",
            "Teemu Pekkarinen"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We comment on the regularity assumptions in the multi-agent sequential\nscreening model of Eso and Szentes (2007). First, we observe that the\nregularity assumptions are not invariant to relabeling each agent's signal\nrealizations. Second, we show that the regularity assumptions rule out\nvaluation distributions with common bounded support. Third, we show that if\neach signal realization is labeled to equal the expected valuation, then the\nregularity assumptions imply that each agent's valuation is equal to his signal\nrealization plus independent mean-zero noise.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.17962v1"
    },
    {
        "title": "Stochastic cooperative games of risk averse players and application to\n  multiple newsvendors problem",
        "authors": [
            "David Ryzák",
            "Martin Černý"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies the stochastic setting in cooperative games and suggests a\nsolution concept based on second order stochastic dominance (SSD), which is\noften applied to robustly model risk averse behaviour of players in different\neconomic and game theoretic models as it enables to model not specified levels\nof risk aversion among players. The main result of the paper connects this\nsolution concept, \\emph{SSD-core}, in case of uniform distribution of the game\nto cores of two deterministic cooperative games. Interestingly, balancedness of\nboth of these games and convexity of one of these implies non-emptiness of the\nSSD-core. The opposite implication does not, in general, hold and leads to\nquestions about intersections of cores of two games and their relations.\nFinally, we present an application of the SSD-core to the multiple newsvendors\nproblem, where we provide a characterization of risk averse behaviour of\nplayers with an interpretation in terms of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19002v1"
    },
    {
        "title": "Performance Rating Equilibrium",
        "authors": [
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this note, I introduce a novel performance rating system called\nPerformance Rating Equilibrium (PRE). A PRE is a vector of hypothetical ratings\nfor each player, such that if these ratings were each player's initial rating\nat the start of a tournament, scoring the same points against the same\nopponents would leave each player's initial rating unchanged. In other words,\nall players' initial ratings perfectly predict their actual scores in the\ntournament. This property, however, does not hold for the well-known Tournament\nPerformance Rating. PRE is defined as a fixed point of a multidimensional\nrating function. I show that such a fixed point, and hence a PRE, exists under\nmild conditions. I provide an implementation of PRE along with several\nempirical applications. PREs have broad applicability, from sports competitions\nto the evaluation of large language models.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19006v2"
    },
    {
        "title": "Information Sharing with Social Image Concerns and the Spread of Fake\n  News",
        "authors": [
            "Dana Sisak",
            "Philipp Denter"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study how social image concerns affect information sharing patterns\nbetween peers. An individual receives a signal (\"news\") about the state of the\nworld and can either share it with a peer or not. This signal has two\nattributes: a headline -- e.g., arguing for or against human-induced climate\nchange -- and a veracity status, indicating if the signal is based on facts or\nmade-up. The headline is observable at no cost by everyone, while observing the\nveracity status is costly and the cost depends on an individual's type. We\nstudy the sharing patterns induced by two different types of social image\nconcern: wanting to be perceived as talented, which implies being able to\ndistinguish proper from fake news, and wanting to signal one's worldview. Our\nmodel can rationalize the empirical finding that fake news may be shared with a\nhigher propensity than proper news (e.g., Vosoughi et al., 2018). We show that\nboth a veracity and a worldview concern may rationalize this finding, though\nsharing patterns are empirically distinguishable and welfare implications\ndiffer.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19557v2"
    },
    {
        "title": "The green transition of firms: The role of evolutionary competition,\n  adjustment costs, transition risk, and green technology progress",
        "authors": [
            "Davide Radi",
            "Frank Westerhoff"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We propose an evolutionary competition model to investigate the green\ntransition of firms, highlighting the role of adjustment costs, dynamically\nadjusted transition risk, and green technology progress in this process. Firms\nbase their decisions to adopt either green or brown technologies on relative\nperformance. To incorporate the costs of switching to another technology into\ntheir decision-making process, we generalize the classical exponential\nreplicator dynamics. Our global analysis reveals that increasing transition\nrisk, e.g., by threatening to impose stricter environmental regulations,\neffectively incentivizes the green transition. Economic policy recommendations\nderived from our model further suggest maintaining high transition risk\nregardless of the industry's level of greenness. Subsidizing the costs of\nadopting green technologies can reduce the risk of a failed green transition.\nWhile advances in green technologies can amplify the effects of green policies,\nthey do not completely eliminate the possibility of a failed green transition.\nFinally, evolutionary pressures favor the green transition when green\ntechnologies are profitable.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.20379v1"
    },
    {
        "title": "Voting with Random Proposers: Two Rounds Suffice",
        "authors": [
            "Hans Gersbach",
            "Kremena Valkanova"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper introduces Voting with Random Proposers (VRP) procedure to address\nthe challenges of agenda manipulation in voting. In each round of VRP, a\nrandomly selected proposer suggests an alternative that is voted on against the\nprevious round's winner. In a framework with single-peaked preferences, we show\nthat the VRP procedure guarantees that the Condorcet winner is implemented in a\nfew rounds with truthful voting, and in just two rounds under sufficiently\nsymmetric preference distributions or if status quo positions are not extreme.\nThe results have applications for committee decisions, legislative\ndecision-making, and the organization of citizens' assemblies and decentralized\nautonomous organizations.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.20476v1"
    },
    {
        "title": "Motivated Reasoning and the Political Economy of Climate Change Inaction",
        "authors": [
            "Philipp Denter"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Two office-driven politicians compete in an election by proposing policies.\nThere are two possible states of the world: climate change is either mild, with\nno lasting effect on welfare if addressed properly, or severe, leading to\nreduced welfare even with appropriate measures. Voters receive signals about\nthe state but may interpret them in a non-Bayesian way, holding motivated\nbeliefs. An equilibrium always exists where voters ignore signals suggesting\nsevere consequences, causing politicians to propose policies for mild climate\nchange -- even when they know otherwise. If severe climate change leads to only\nmoderate welfare losses, another efficient equilibrium exists. In this\nequilibrium, voters trust politicians to choose the optimal policies, implying\nvoters choose to trust their signals, which in turn encourages optimal policy\nchoices by politicians. The model highlights the role of political rhetoric and\ntrust in government, and a first glance at the data reveals patterns consistent\nwith the models predictions.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.20982v1"
    },
    {
        "title": "Weighted Garbling",
        "authors": [
            "Daehyun Kim",
            "Ichiro Obara"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We introduce and develop an information order for experiments based on a\ngeneralized notion of garbling called weighted garbling. An experiment is more\ninformative than another in this order if the latter experiment is obtained by\na weighted garbling of the former. This notion can be shown to be equivalent to\na regular garbling conditional on some event for the former experiment. We also\ncharacterize this order in terms of posterior beliefs and show that it only\ndepends on the support of posterior beliefs, not their distribution. Our main\nresults are two characterizations of the weighted-garbling order based on some\ndecision problems. For static Bayesian decision problems, one experiment is\nmore informative than another in the weighted-garbling order if and only if a\ndecision maker's value of information (i.e., the difference in the optimal\nexpected payoffs with and without an experiment) from the former is guaranteed\nto be some fraction of the value of information from the latter for any\ndecision problem. When the weighted garbling is a regular garbling, this lower\nbound reduces to the value of information itself as the fraction becomes one,\nthus generalizing the result in Blackwell (1951, 1953). We also consider a\nclass of stopping time problems where the state of nature changes over time\naccording to a hidden Markov process, and a patient decision maker can conduct\nthe same experiment as many times as she wants without any cost before making a\none-time decision. We show that an experiment is more informative than another\nin the weighted-garbling order if and only if the decision maker achieves a\nweakly higher expected payoff for any problem with a regular prior belief in\nthis class.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21694v1"
    },
    {
        "title": "Strategic communication of narratives",
        "authors": [
            "Gerrit Bauch",
            "Manuel Foerster"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We conceptualize the communication of narratives as a cheap-talk game under\nmodel uncertainty. The sender has private information about the true data\ngenerating process of publicly observable data. The receiver is uncertain about\nhow to interpret the data, but aware of the sender's incentives to\nstrategically provide interpretations (\"narratives\") in her favor. We consider\na general class of decision rules under ambiguity resolving the receiver's\nignorance of the true data generating process, including maximum likelihood\nexpected utility. The set of equilibria is characterized by a positive integer\n$N$: there is an equilibrium that induces $n$ different actions for each $1\\leq\nn \\leq N$. The diverting power of the sender is weaker than with a na\\\"ive\nreceiver being unaware of the sender's incentives. Surprisingly, the receiver\nsometimes prefers to be na\\\"ive.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.23259v1"
    },
    {
        "title": "The psychology of prizes: Loss aversion and optimal tournament rewards",
        "authors": [
            "Dmitry Ryvkin",
            "Qin Wu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the optimal allocation of prizes in rank-order tournaments with loss\naverse agents. Prize sharing becomes increasingly optimal with loss aversion\nbecause more equitable prizes reduce the marginal psychological cost of\nanticipated losses. Furthermore, loss aversion can boost effort if prizes are\nsufficiently equitable, but otherwise effort declines with loss aversion.\nOverall, these results give credence to more equitable allocations of\ncompetitive rewards. A win-win scenario is where optimal prizes are equitable\neven under loss neutrality, in which case the principal benefits from agents'\nloss aversion.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.01068v1"
    },
    {
        "title": "Utilitarian Social Choice and Distributional Welfare Analysis",
        "authors": [
            "Federico Echenique",
            "Quitzé Valenzuela-Stookey"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Harsanyi (1955) showed that the only way to aggregate individual preferences\ninto a social preference which satisfies certain desirable properties is\n``utilitarianism'', whereby the social utility function is a weighted average\nof individual utilities. This representation forms the basis for welfare\nanalysis in most applied work. We argue, however, that welfare analysis based\non Harsanyi's version of utilitarianism may overlook important distributional\nconsiderations. We therefore introduce a notion of utilitarianism for\ndiscrete-choice settings which applies to \\textit{social choice functions},\nwhich describe the actions of society, rather than social welfare functions\nwhich describe society's preferences (as in Harsanyi). We characterize a\nrepresentation of utilitarian social choice, and show that it provides a\nfoundation for a family of \\textit{distributional welfare measures} based on\nquantiles of the distribution of individual welfare effects, rather than\naverages.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.01315v1"
    },
    {
        "title": "An algorithm for two-player repeated games with imperfect public\n  monitoring",
        "authors": [
            "Jasmina Karabegovic"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper introduces an explicit algorithm for computing perfect public\nequilibrium (PPE) payoffs in repeated games with imperfect public monitoring,\npublic randomization, and discounting. The method adapts the established\nframework by Abreu, Pearce, and Stacchetti (1990) into a practical tool that\nbalances theoretical accuracy with computational efficiency. The algorithm\nsimplifies the complex task of identifying PPE payoff sets for any given\ndiscount factor {\\delta}. A stand-alone implementation of the algorithm can be\naccessed at: https://github.com/jasmina-karabegovic/IRGames.git.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.01566v1"
    },
    {
        "title": "Troll Farms",
        "authors": [
            "Philipp Denter",
            "Boris Ginzburg"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Political agents often aim to influence elections through troll farms --\norganisations that disseminate messages emulating genuine information. We study\nthe behaviour of a troll farm that faces a heterogeneous electorate of\npartially informed voters, and aims to achieve a desired political outcome by\ntargeting each type of voter with a specific distribution of messages. We show\nthat such tactics are more effective when voters are otherwise well-informed,\nfor example, when the media is of high quality. At the same time, increased\npolarisation, as well as deviations from Bayesian rationality, can reduce the\nnegative effect of troll farms and restore efficiency of electoral outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03241v1"
    },
    {
        "title": "From Design to Disclosure",
        "authors": [
            "S. Nageeb Ali",
            "Andreas Kleiner",
            "Kun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies games of voluntary disclosure in which a sender discloses\nevidence to a receiver who then offers an allocation and transfers. We\ncharacterize the set of equilibrium payoffs in this setting. Our main result\nestablishes that any payoff profile that can be achieved through information\ndesign can also be supported by an equilibrium of the disclosure game. Hence,\nour analysis suggests an equivalence between disclosure and design in these\nsettings. We apply our results to monopoly pricing, bargaining over policies,\nand insurance markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03608v1"
    },
    {
        "title": "Robust Regulation of Labour Contracts",
        "authors": [
            "Théo Durandard",
            "Alexis Ghersengorin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the robust regulation of labour contracts in moral hazard problems.\nA firm offers a contract to incentivise production by an agent protected by\nlimited liability. A regulator chooses the set of permissible contracts to (i)\nimprove efficiency and (ii) protect the worker. The regulator ignores the\nagent's productive actions and the firm's costs and evaluates regulation by its\nworst-case regret. The regret-minimising regulation imposes a linear minimum\nwage, allowing all contracts above this linear threshold. The slope of the\nminimum contract balances the worker's protection - by ensuring they receive a\nminimal share of the production - and the necessary flexibility for incentive\nprovision.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.04841v1"
    },
    {
        "title": "Higher education funding: The value of choice",
        "authors": [
            "Limor Hatsor",
            "Ronen Bar-El"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  An alternative to the dependence on traditional student loans may offer a\nviable relief from the tremendous burden that those loans usually incur. This\narticle establishes that it is desirable for governmental intervention to grant\nstudents 'more choice' in their funding decisions by allowing them to have\nportfolios, mixtures of different types of loans. To emphasize this point, a\nmodel is presented of a situation where students invest in higher education\nwhile facing uncertainty about their individual earning potential. The model\nreveals that when students are allowed to have portfolios of loans, some of\nthem indeed take the opportunity and diversify their loans, benefiting\nthemselves, but also improving the loan terms of other students. Therefore,\nwhen governments organize student loans, they should consider providing\nstudents with more choice in their funding decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05506v1"
    },
    {
        "title": "Green antitrust conundrum: Collusion with social goals",
        "authors": [
            "Nigar Hashimzade",
            "Limor Hatsor",
            "Artyom Jelnov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Recent antitrust regulations in several countries have granted exemptions for\ncollusion aimed at achieving environmental goals. Firms can apply for\nexemptions if collusion helps to develop or to implement costly clean\ntechnology, particularly in sectors like renewable energy, where capital costs\nare high and economies of scale are significant. However, if the cost of the\ngreen transition is unknown to the competition regulator, firms might exploit\nthe exemption by fixing prices higher than necessary. The regulator faces the\ndecision of whether to permit collusion and whether to commission an\ninvestigation of potential price fixing, which incurs costs. We fully\ncharacterise the equilibria in this scenario that depend on the regulator's\nbelief about the high cost of green transition. If the belief is high enough,\ncollusion will be allowed. We also identify conditions under which a\nregulator's commitment to always investigate price fixing is preferable to\nmaking discretionary decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06095v1"
    },
    {
        "title": "Allocating Positional Goods: A Mechanism Design Approach",
        "authors": [
            "Peiran Xiao"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study the optimal allocation of positional goods with externalities and\none-sided transfers. Because consumers care about their relative positions in\nconsumption, allocating an item to one buyer has externalities on others. Using\na mechanism design approach, I characterize the externalities by a feasibility\ncondition. I find the revenue-maximizing mechanism excludes some low types and\nfully separates the rest if and only if the buyer's type distribution satisfies\nMyerson's regularity. The seller can guarantee at least half the maximal\nrevenue by offering one level of positional goods, and the approximation can be\narbitrarily close if the distribution is sufficiently concave. Moreover, if the\ndistribution has an increasing (decreasing) failure rate, total pooling (full\nseparation) without exclusion maximizes the consumer surplus, and the consumer\nsurplus is decreasing (increasing) in the number of positional good levels.\nApplications include education, priority services, luxury goods, and\norganizational design.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06285v1"
    },
    {
        "title": "Voting behind the Veil of Ignorance",
        "authors": [
            "Boris Ginzburg"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A committee consisting of two factions is considering a project whose\ndistributive consequences are unknown. This uncertainty can be resolved at some\nunknown future time. By delaying approval, the committee can gradually learn\nwhich faction benefits from the project. Because support of both factions is\nrequired for approval, it can only happen when there is sufficient amount of\nuncertainty about the identities of winners and losers. I show that in many\nsituations, a project is more likely to be approved if it gives a lower payoff\nto everyone. The probability of approval and expected payoffs of both factions\nare higher if the project is ex ante less likely to benefit the faction that\ntends to receive good news faster. Equilibrium amount of learning is excessive,\nand a deadline on adopting the project is often optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06998v1"
    },
    {
        "title": "Mechanisms for a dynamic many-to-many school choice problem",
        "authors": [
            "Adriana Amieva",
            "Agustín Bonifacio",
            "Pablo Neme"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine the problem of assigning teachers to public schools over time when\nteachers have tenured positions and can work simultaneously in multiple\nschools. To do this, we investigate a dynamic many-to-many school choice\nproblem where public schools have priorities over teachers and teachers hold\nsubstitutable preferences over subsets of schools. We introduce a new concept\nof dynamic stability that recognizes the tenured positions of teachers and we\nprove that a dynamically stable matching always exists. We propose the\nTenured-Respecting Deferred Acceptance $(TRDA)$ mechanism, which produces a\ndynamically stable matching that is constrained-efficient within the class of\ndynamically stable matchings and minimizes unjustified claims. To improve\nefficiency beyond this class, we also propose the Tenured-Respecting\nEfficiency-Adjusted Deferred Acceptance $(TREADA)$ mechanism, an adaptation of\nthe Efficiency-Adjusted Deferred Acceptance mechanism to our dynamic context.\nWe demonstrate that the outcome of the $TREADA$ mechanism Pareto-dominates any\ndynamically stable matching and achieves efficiency when all teachers consent.\nAdditionally, we examine the issue of manipulability, showing that although the\n$TRDA$ and $TREADA$ mechanisms can be manipulated, they remain non-obviously\ndynamically manipulable under specific conditions on schools' priorities.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.07851v1"
    },
    {
        "title": "On the Welfare (Ir)Relevance of Two-Stage Models",
        "authors": [
            "Mikhail Freer",
            "Hassan Nosratabadi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In a two-stage model of choice a decision maker first shortlists a given menu\nand then applies her preferences. We show that a sizeable class of these models\nrun into significant issues in terms of identification of preferences\n(welfare-relevance) and thus cannot be used for welfare analysis. We classify\nthese models by their revealed preference principles and expose the principle\nthat we deem to be the root of their identification issue. Taking our analysis\nto an experimental data, we observe that half of the alternatives that are\nrevealed preferred to another under rational choice are left revealed preferred\nto nothing for any member of this class of models. Furthermore, the\nwelfare-relevance of the specific models established in the literature are much\nworse. The model with the highest welfare-relevance produces a revealed\npreference relation with the average density of 2% (1 out of 45 possible\ncomparisons revealed), while rational choice does 63% (28 out of 45 possible\ncomparisons). We argue that the issue is not an inherent feature of two-stage\nmodels, and rather lies in the approach with which the first stage is modelled\nin the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08263v1"
    },
    {
        "title": "Orchestrating Organizational Politics: Baron and Ferejohn Meet Tullock",
        "authors": [
            "Qiang Fu",
            "Zenan Wu",
            "Yuxuan Zhu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper examines the optimal organizational rules that govern the process\nof dividing a fixed surplus. The process is modeled as a sequential\nmultilateral bargaining game with costly recognition. The designer sets the\nvoting rule -- i.e., the minimum number of votes required to approve a proposal\n-- and the mechanism for proposer recognition, which is modeled as a biased\ngeneralized lottery contest. We show that for diverse design objectives, the\noptimum can be achieved by a dictatorial voting rule, which simplifies the game\ninto a standard biased contest model.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08419v1"
    },
    {
        "title": "Equilibrium Cycle: A \"Dynamic\" Equilibrium",
        "authors": [
            "Tushar Shankar Walunj",
            "Shiksha Singhal",
            "Veeraruna Kavitha",
            "Jayakrishnan Nair"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, we introduce a novel equilibrium concept, called the\nequilibrium cycle, which seeks to capture the outcome of oscillatory game\ndynamics. Unlike the (pure) Nash equilibrium, which defines a fixed point of\nmutual best responses, an equilibrium cycle is a set-valued solution concept\nthat can be demonstrated even in games where best responses do not exist (for\nexample, in discontinuous games). The equilibrium cycle identifies a Cartesian\nproduct set of action profiles that satisfies three important properties:\nstability against external deviations, instability against internal deviations,\nand minimality. This set-valued equilibrium concept generalizes the classical\nnotion of the minimal curb set to discontinuous games. In finite games, the\nequilibrium cycle is related to strongly connected sink components of the best\nresponse graph.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08471v2"
    },
    {
        "title": "Industrial symbiosis: How to apply successfully",
        "authors": [
            "Limor Hatsor",
            "Artyom Jelnov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The premise of industrial symbiosis IS is that advancing a circular economy\nthat reuses byproducts as inputs in production is valuable for the environment.\nWe challenge this premise in a simple model. Ceteris paribus, IS is an\nenvironmentally friendly approach; however, implementing IS may introduce\nincreased pollution into the market equilibrium. The reason for this is that\nproducers' incentives for recycling can be triggered by the income gained from\nselling recycled waste in the secondary market, and thereby may not align with\nenvironmental protection. That is, producers may boost production and\nsubsequent pollution to sell byproducts without internalizing the pollution\nemitted in the primary industry or the recycling process. We compare the market\nsolution to the social optimum and identify a key technology parameter - the\nshare of reused byproducts that may have mutual benefits for firms, consumers,\nand the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08483v1"
    },
    {
        "title": "Competition, Persuasion, and Search",
        "authors": [
            "Teddy Mekonnen",
            "Bobak Pakzad-Hurson"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  An agent engages in sequential search. He does not directly observe the\nquality of the goods he samples, but he can purchase signals designed by profit\nmaximizing principal(s). We formulate the principal-agent relationship as a\nrepeated contracting problem within a stopping game and characterize the set of\nequilibrium payoffs. We show that when the agent's search cost falls below a\ngiven threshold, competition does not impact how much surplus is generated in\nequilibrium nor how the surplus is divided. In contrast, competition benefits\nthe agent at the expense of total surplus when the search cost exceeds that\nthreshold. Our results challenge the view that monopoly decreases market\nefficiency, and moreover, suggest that it generates the highest value of\ninformation for the agent.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11183v3"
    },
    {
        "title": "Modeling the Modeler: A Normative Theory of Experimental Design",
        "authors": [
            "Fernando Payró",
            "Evan Piermont"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider an analyst whose goal is to identify a subject's utility function\nthrough revealed preference analysis. We argue the analyst's preference about\nwhich experiments to run should adhere to three normative principles: The\nfirst, Structural Invariance, requires that the value of a choice experiment\nonly depends on what the experiment may potentially reveal. The second,\nIdentification Separability, demands that the value of identification is\nindependent of what would have been counterfactually identified had the subject\nhad a different utility. Finally, Information Monotonicity asks that more\ninformative experiments are preferred. We provide a representation theorem,\nshowing that these three principles characterize Expected Identification Value\nmaximization, a functional form that unifies several theories of experimental\ndesign. We also study several special cases and discuss potential applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11625v1"
    },
    {
        "title": "Reinterpreting Delay and Procrastination",
        "authors": [
            "Conrad Kosowsky"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I model a rational agent who spends resources between the current time and\nsome fixed future deadline. Opportunities to spend resources arise randomly\naccording to a Poisson process, and the quality of each opportunity follows a\nuniform distribution. The agent values their current resource stock at exactly\nthe sum of expected utility from all future spending opportunities. Unlike in\ntraditional discounted expected utility models, the agent exhibits correlation\naversion, static (but not dynamic) preference reversals, and monotonicity with\nrespect to payment timing. Connecting the agent's risk and time preference is\nintuitive, and doing so leads to a new model of procrastination where the agent\nmisperceives their general attitude toward spending resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11828v1"
    },
    {
        "title": "Quasi-stability notions in two-sided matching models",
        "authors": [
            "Nadia Guiñazú",
            "Noelia Juarez",
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper presents weakened notions of corewise stability and setwise\nstability for matching markets where agents have substitutable choice\nfunctions. We introduce the concepts of worker-quasi-core, firm-quasi-core, and\nworker-quasisetwise stability. We also examine their relationship to\nestablished notions in the literature, such as worker-quasi and firm-quasi\nstability in both many-to-one and many-to-many markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.12533v1"
    },
    {
        "title": "Scoring and Favoritism in Optimal Procurement Design",
        "authors": [
            "Pasha Andreyanov",
            "Ilia Krasikov",
            "Alex Suzdaltsev"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study buyer-optimal procurement mechanisms when quality is contractible.\nWhen some costs are borne by every participant of a procurement auction\nregardless of winning, the classic analysis should be amended. We show that an\noptimal symmetric mechanism is a scoring auction with a score function that may\nbe either flatter or steeper than classically. This depends on the relative\ndegrees of information asymmetry over the all-pay and winner-pay costs.\n  However, the symmetry of the optimal mechanism is not granted due to the\npresence of all-pay costs. When ex-post efficiency is less important than the\nduplication of costs, favoritism becomes optimal. We show that, depending on\nthe degree of convexity of costs, the solution takes one of two novel formats\nwith a partially asymmetric treatment of firms, which we call a score floor and\na score ceiling auction. Interestingly, these auctions feature side payments\nfrom or to the buyer, which has nothing to do with corruption.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.12714v1"
    },
    {
        "title": "Matching Design with Sufficiency and Applications to Child Welfare",
        "authors": [
            "Terence Highsmith Ii"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In many local foster care systems across the United States, child welfare\npractitioners struggle to effectively match children in need of a home to\nfoster families. We tackle this problem while navigating a key sensitivity in\nthis domain: in foster care systems, individual caseworkers must assent to any\nproposed matching. We codify this constraint in one-sided matching markets as\nthe problem of matching design with sufficiency. We design a mechanism that\nguarantees outcome sufficiency, a form of welfare-maximizing Pareto efficiency\nensuring that no caseworker can ex-post gain from any child-family placement\nreassignment and that the foster care authority's objective preferences for\nchild-family placements are maximally satisfied. Our work subsequently\nevaluates this mechanism's strategic properties. Finally, we plan to conduct a\nlab-in-the-field experiment to elicit real-world caseworkers' preferences and\nestimate the child welfare gains our algorithm produces. Current\nsimulation-based results show dramatic improvements to welfare. Designing\nsufficient matching systems is an example of mechanism-reform because replacing\nexisting systems without regard for existing agents' preferences and wishes has\npreviously resulted in failure.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.12860v3"
    },
    {
        "title": "Flow methods for cooperative games with generalized coalition\n  configuration",
        "authors": [
            "Encarnacion Algaba",
            "Eric Remila",
            "Philippe Solal"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper introduces the class of cooperative games with generalized\ncoalition configuration. This new class of games corresponds to cooperative\ngames with coalition configuration and restricted cooperation. A coalition\nconfiguration is a collection of coalitions covering the agent set. The\nrestriction of cooperation between agents is represented by a set system on\neach element of the coalition configuration. A coalition profile is a list of\nfeasible coalitions, one for each element of the coalition configuration. A\ncoalition profile function associates a worth with each coalition profile.\nBased on this framework, we define and axiomatically characterize marginal\nvalues whose coefficients induce a unitary flow on the product digraph obtained\nfrom these set systems. Next, we propose a two-step procedure, inspired by\nOwen's procedure, to construct flow methods as above. Then, we show that the\nassociated flow is decomposable into two flows. Finally, we use two axioms to\ncharacterize the flows that can be decomposed in this way, and hence the flow\nmethods constructed using our procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13684v1"
    },
    {
        "title": "Non-Allais Paradox and Context-Dependent Risk Attitudes",
        "authors": [
            "Edward Honda",
            "Keh-Kuan Sun"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We provide and axiomatize a representation of preferences over lotteries that\ngeneralizes the expected utility model. Our representation is consistent with\nthe violations of the independence axiom that we observe in the laboratory\nexperiment that we conduct. The violations differ from the Allais Paradox in\nthat they are incompatible with some of the most prominent non-expected utility\nmodels. Our representation can be interpreted as a decision-maker with\ncontext-dependent attitudes to risks and allows us to generate various types of\nrealistic behavior. We analyze some properties of our model, including\nspecifications that ensure preferences for first-order stochastic dominance. We\ntest whether subjects in our experiment exhibit the type of context-dependent\nrisk attitudes that arise in our model.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13823v1"
    },
    {
        "title": "Marginal Reputation",
        "authors": [
            "Daniel Luo",
            "Alexander Wolitzky"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study reputation formation where a long-run player repeatedly observes\nprivate signals and takes actions. Short-run players observe the long-run\nplayer's past actions but not her past signals. The long-run player can thus\ndevelop a reputation for playing a distribution over actions, but not\nnecessarily for playing a particular mapping from signals to actions.\nNonetheless, we show that the long-run player can secure her Stackelberg payoff\nif distinct commitment types are statistically distinguishable and the\nStackelberg strategy is confound-defeating. This property holds if and only if\nthe Stackelberg strategy is the unique solution to an optimal transport\nproblem. If the long-run player's payoff is supermodular in one-dimensional\nsignals and actions, she secures the Stackelberg payoff if and only if the\nStackelberg strategy is monotone. An application of our results provides a\nreputational foundation for a class of Bayesian persuasion solutions when the\nsender has a small lying cost. Our results extend to the case where distinct\ncommitment types may be indistinguishable but the Stackelberg type is salient\nunder the prior.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.15317v2"
    },
    {
        "title": "The Role of the Assumptions for the Existence of a General Equilibrium",
        "authors": [
            "Pablo Ahumada"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  General Equilibrium Theory is the benchmark of economics, especially its\nresults concerning the efficient allocation of resources, known as the First\nand Second Welfare Theorems. Yet, General Equilibrium Theory is beyond the\nscope of most economists. This paper is pitched as the first entry point into\nthe theory. General Equilibrium Theory proves that at least one state of\nequilibrium always exists. In its most general approach, it uses fixed-point\ntheorems to this end. This paper discusses the assumptions on individuals'\nbehaviour and the structure of the system of exchange that guarantee that the\nconditions of the fixed-point theorems are satisfied. The purpose is to lay\nbare the role each plays in proving the existence of equilibrium and provide a\nclear picture of the relationship between the assumptions and the result. The\ndiscussion is presented in the simplest possible setting that captures the\nfundamental features of commodity exchange.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17072v2"
    },
    {
        "title": "Independence and indifferent points imply continuity",
        "authors": [
            "Gerrit Bauch"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The expected utility theorem of von Neumann and Morgenstern (1947) has been a\nmilestone in economics, describing rational behavior by two axioms on a weak\npreference on lotteries on a finite set of outcomes: the Independence Axiom and\nthe Continuity Axiom. For a weak preference fulfilling the Independence Axiom,\nI prove that continuity is equivalent to the existence of a set indifferent\nlotteries spanning a hyperplane.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17883v1"
    },
    {
        "title": "Remote Surgery with 5G or 6G: Knowledge Production and Diffusion\n  Globally and in the German Case",
        "authors": [
            "Marina Martinelli",
            "André Tosi Furtado"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper is a comprehensive exploring of technology capability in 5G/6G\nTIS, explicitly focusing on the potential of remote surgery globally and in\nGermany. The paper's main contribution is its ability to anticipate new debates\non the interplay between TIS and contexts, with particular emphasis on the\nnational and international levels. Our findings, derived from a Bibliometrics\nstudy of industry-academic relationships, highlight crucial collaborations in\nGermany, positioning the country as a strategic actor in international TIS and,\nby extension, in applying 5G/6G technological systems to remote surgery due to\nits knowledge production capability. We propose policies that can stimulate\ninteraction between smaller suppliers and larger companies, which can act as\nintermediaries and provide access to international markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17899v1"
    },
    {
        "title": "Household Resource Allocation Dynamics and Policies: Integrating Future\n  Earnings of Children, Fertility, Pension, Health, and Education",
        "authors": [
            "Sushmita Kumari",
            "Siddharth Gavhale"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This study presents a model that examines how families make decisions about\nhaving children, managing resources, and planning for their financial security\nin light of social and economic factors. It explores the balance between the\nnumber of children and the quality of life parents wish to provide, including\neducation and future income prospects. By considering parents' expectations\nabout their children's future earnings, the model gives new insights into how\nfamilies allocate their resources. It also looks at how decisions about savings\nand pensions are connected to daily spending and family planning, showing the\ncomplex links between these factors. The findings offer valuable guidance for\npolicies that address these interrelated challenges and better support families\nin managing their resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.18144v1"
    },
    {
        "title": "Dynamic matching games: stationary equilibria under varying commitments",
        "authors": [
            "Nadia Guiñazú",
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper examines equilibria in dynamic two-sided matching games, extending\nGale and Shapley's foundational model to a non-cooperative, decentralized, and\ndynamic framework. We focus on markets where agents have utility functions and\ncommitments vary. Specifically, we analyze a dynamic matching game in which\nfirms make offers to workers in each period, considering three types of\ncommitment: (i) no commitment from either side, (ii) firms' commitment, and\n(iii) workers' commitment. Our results demonstrate that stable matchings can be\nsupported as stationary equilibria under different commitment scenarios,\ndepending on the strategies adopted by firms and workers. Furthermore, we\nidentify key conditions, such as discount factors, that influence agents'\ndecisions to switch partners, thereby shaping equilibrium outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.19372v1"
    },
    {
        "title": "Money Burning Improves Mediated Communication",
        "authors": [
            "Yi Liu",
            "Yang Yu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper explores the problem of mediated communication enhanced by\nmoney-burning tactics for commitment power. In our model, the sender has\nstate-independent preferences and can design a communication mechanism that\nboth transmits messages and burns money. We characterize the sender's maximum\nequilibrium payoff, which has clear geometric interpretations and is linked to\ntwo types of robust Bayesian persuasion. We demonstrate that, generically, the\nmoney-burning tactic \\emph{strictly} improves the sender's payoff for almost\nall prior beliefs where commitment is valuable for the sender. Furthermore, our\ncommunication model directly applies to Web 3.0 communities, clarifying the\ncommitment value within these contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.19431v1"
    },
    {
        "title": "Tournaments with a Standard",
        "authors": [
            "Mikhail Drugov",
            "Dmitry Ryvkin",
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study tournaments where winning a rank-dependent prize requires passing a\nminimum performance standard. We show that, for any prize allocation, the\noptimal standard is always at a mode of performance that is weakly higher than\nthe global mode and identify a necessary and sufficient condition for it to be\nat the global mode. When the prize scheme can be designed as well, the\nwinner-take-all prize scheme is optimal for noise distributions with an\nincreasing failure rate; and awarding equal prizes to all qualifying agents is\noptimal for noise distributions with a decreasing failure rate. For\ndistributions with monotone likelihood ratios -- log-concave and log-convex,\nrespectively -- these pay schemes are also optimal in a larger class of\nanonymous, monotone contracts that may depend on cardinal performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.01139v1"
    },
    {
        "title": "Capacity Constraints in Principal-Agent Problems",
        "authors": [
            "Aubrey Clark"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Adding a capacity constraint to a hidden-action principal-agent problem\nresults in the same set of Pareto optimal contracts as the unconstrained\nproblem where output is scaled down by a constant factor. This scaling factor\nis increasing in the agent's capacity to exert effort.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.01760v1"
    },
    {
        "title": "Categorize and randomize: a model of sequential stochastic choice",
        "authors": [
            "Ester Sudano"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We model stochastic choices with categorization, resulting from the\npreliminary step of grouping alternatives in homogenous disjoint classes. The\nagent randomly chooses one class among those available, then randomly picks an\nitem within the selected class. We give a formal definition of a choice\ngenerated by this procedure, and provide a characterization. The characterizing\nproperties allow an external observer to elicit that categorization is applied.\nIn a more general interpretation, the model allows to describe the observed\nchoice as the composition of independent subchoices. This composition preserves\nrationalizability by random utility maximization. A generalization of the model\nsubsumes Luce model and Nested Logit.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.03554v1"
    },
    {
        "title": "Consumption Dependent Random Utility",
        "authors": [
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a dynamic random utility model that allows for consumption\ndependence. We axiomatically analyze this model and find insights that allow us\nto distinguish between behavior that arises due to consumption dependence and\nbehavior that arises due to state dependence. Building on our axiomatic\nanalysis, we develop a hypothesis test for consumption dependent random\nutility. We show that our hypothesis test offers computational improvements\nover the natural extension of Kitamura and Stoye (2018) to our environment.\nFinally, we consider a parametric application of our model and show how an\nanalyst can predict the long run perturbation to market shares due to habit\nformation using choice data from only two periods.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.05344v1"
    },
    {
        "title": "Network and timing effects in social learning",
        "authors": [
            "Wade Hann-Caruthers",
            "Minghao Pan",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a group of agents who can each take an irreversible costly action\nwhose payoff depends on an unknown state. Agents learn about the state from\nprivate signals, as well as from past actions of their social network\nneighbors, which creates an incentive to postpone taking the action. We show\nthat outcomes depend on network structure: on networks with a linear structure\npatient agents do not converge to the first-best action, while on regular\ndirected tree networks they do.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.07061v1"
    },
    {
        "title": "The Economics of Equilibrium with Indivisible Goods",
        "authors": [
            "Ravi Jagadeesan",
            "Alexander Teytelboym"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper develops a theory of competitive equilibrium with indivisible\ngoods based entirely on economic conditions on demand. The key idea is to\nanalyze complementarity and substitutability between bundles of goods, rather\nthan merely between goods themselves. This approach allows us to formulate\nsufficient, and essentially necessary, conditions for equilibrium existence,\nwhich unify settings with complements and settings with substitutes. Our\nanalysis has implications for auction design.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.07946v1"
    },
    {
        "title": "Strategic Attribute Learning",
        "authors": [
            "Jean-Michel Benkert",
            "Ludmila Matyskova",
            "Egor Starkov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A researcher allocates a budget of informative tests across multiple unknown\nattributes to influence a decision-maker. We derive the researcher's\nequilibrium learning strategy by solving an auxiliary single-player problem.\nThe attribute weights in this problem depend on how much the researcher and the\ndecision-maker disagree. If the researcher expects an excessive response to new\ninformation, she forgoes learning altogether. In an organizational context, we\nshow that a manager favors more diverse analysts as the hierarchical distance\ngrows. In another application, we show how an appropriately opposed advisor can\nconstrain a discriminatory politician, and identify the welfare-inequality\nPareto frontier of researchers.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10024v1"
    },
    {
        "title": "Quantifying Educational Competition: A Game-Theoretic Model with Policy\n  Implications",
        "authors": [
            "Siyuan He"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The competitive pressures in China's primary and secondary education system\nhave persisted despite decades of policy interventions aimed at reducing\nacademic burdens and alleviating parental anxiety. This paper develops a\ngame-theoretic model to analyze the strategic interactions among families in\nthis system, revealing how competition escalates into a socially irrational\n\"education arms race.\" Through equilibrium analysis and simulations, the study\ndemonstrates the inherent trade-offs between education equity and social\nwelfare, alongside the policy failures arising from biased social cognition.\nThe model is further extended using Spence's signaling framework to explore the\ninefficiencies of the current system and propose policy solutions that address\nthese issues.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10974v2"
    },
    {
        "title": "Obvious manipulations, consistency, and the uniform rule",
        "authors": [
            "R. Pablo Arribillaga",
            "Agustin G. Bonifacio"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In the problem of fully allocating an infinitely divisible commodity among\nagents whose preferences are single-peaked, we show that the uniform rule is\nthe only allocation rule that satisfies efficiency, the equal division\nguarantee, consistency, and non-obvious manipulability.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12495v1"
    },
    {
        "title": "On Monotone Persuasion",
        "authors": [
            "Anton Kolotilin",
            "Hongyi Li",
            "Andriy Zapechelnyuk"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study monotone persuasion in the linear case, where posterior\ndistributions over states are summarized by their mean. We solve the two\nleading cases where optimal unrestricted signals can be nonmonotone. First, if\nthe objective is s-shaped and the state is discrete, then optimal monotone\nsignals are upper censorship, whereas optimal unrestricted signals may require\nrandomization. Second, if the objective is m-shaped and the state is\ncontinuous, then optimal monotone signals are interval disclosure, whereas\noptimal unrestricted signals may require nonmonotone pooling. We illustrate our\nresults with an application to media censorship.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.14400v2"
    },
    {
        "title": "Prudence and higher-order risk attitudes in the rank-dependent utility\n  model",
        "authors": [
            "Ruodu Wang",
            "Qinyu Wu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We obtain a full characterization of consistency with respect to higher-order\nstochastic dominance within the rank-dependent utility model. Different from\nthe results in the literature, we do not assume any conditions on the utility\nfunctions and the probability weighting function, such as differentiability or\ncontinuity. It turns out that the level of generality that we offer leads to\nmodels that do not have a continuous probability weighting function and yet\nthey satisfy prudence. In particular, the corresponding probability weighting\nfunction can only have a jump at 1, and must be linear on [0,1).\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15350v1"
    },
    {
        "title": "Profit Allocation in the We Media Value Chain: A Shapley Value-Based\n  Approach",
        "authors": [
            "Jianfei Xu",
            "Rui Zhang",
            "Junhui Fan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The study takes the social media industry as its research subject and\nexamines the impact of scientific innovation capabilities on profit\ndistribution within the value chain of the social media industry. It proposes a\nspecific solution to the profit distribution problem using an improved Shapley\nvalue method. Additionally, the AHP (Analytic Hierarchy Process) is employed to\nevaluate the profit distribution model, allowing the improved Shapley value\nmethod to better address the issue of profit allocation within the value chain\nof the social media industry. This approach ensures that each member receives a\nfair share of the profits, fostering strong cooperative relationships among\nmembers. Moreover, it compensates for the shortcomings of the traditional\nShapley value method in addressing such problems to a certain extent.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18130v1"
    },
    {
        "title": "Calibrating the Subjective",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I conduct a version of Rabin's (2000) calibration exercise in the subjective\nexpected utility realm. I show that the rejection of some risky bet by a\nrisk-averse agent only implies the rejection of more extreme and less desirable\nbets and nothing more.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18486v1"
    },
    {
        "title": "Market allocations under conflation of goods",
        "authors": [
            "Niccolò Urbinat",
            "Marco LiCalzi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study competitive equilibria in exchange economies when a continuum of\ngoods is conflated into a finite set of commodities. The design of conflation\nchoices affects the allocation of scarce resources among agents, by\nconstraining trading opportunities and shifting competitive pressures. We\ndemonstrate the consequences on relative prices, trading positions, and\nwelfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18875v1"
    },
    {
        "title": "A Certain Notion of Strategy Freedom under Retail Competition in Claims\n  Problems",
        "authors": [
            "Kentarô Yamamoto"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A new axiom for rules for claims problems is introduced. It strengthens a\ncondition studied in supply chain literature, which forces rules to\ndisincentivize order inflation under capacity allocation and retail\ncompetition. The relevance of the axiom is further demonstrated by one of the\nmain results of the present article: it characterizes the weighted constrained\nequal awards rule together with known natural axioms.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.19506v1"
    },
    {
        "title": "Robust Intervention in Networks",
        "authors": [
            "Daeyoung Jeong",
            "Tongseok Lim",
            "Euncheol Shin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In various contexts, such as learning, social distancing behavior, and\nfinancial contagion, economic agents' decisions are interdependent and can be\nrepresented as a network. This paper investigates how a decision maker (DM) can\ndesign an optimal intervention while addressing uncertainty in the network\nstructure. The DM's problem is modeled as a zero-sum game against an\nadversarial player, referred to as \"Nature,\" whose objective is to disrupt the\nDM's goals by reconfiguring the network into its most disadvantageous state.\nUsing the principle of duality, we derive the DM's unique robust intervention\nstrategy and identify the corresponding unique worst-case network structure\ndetermined by Nature. This framework provides insights into robust\ndecision-making under network uncertainty, balancing the DM's objectives with\nNature's adversarial actions. Moreover, we explore the costs of robustness and\nhighlight the significance of higher-order uncertainties.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00235v1"
    },
    {
        "title": "Paired Course and Dorm Allocation",
        "authors": [
            "Eric Gao"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  Serial dictatorship is efficient for any given one-sided matching problem,\nbut may not be if there are multiple markets under consideration. One\nenvironment where this phenomenon is welfare-relevant is in course and dorm\nallocation at universities, where serial dictatorship is often used\ninterdependently in each market. This paper introduces and considers paired\nserial dictatorship, an adaptation of serial dictatorship for problems where\ntwo goods are allocated simultaneously. Paired serial dictatorship allows\nstudents to first report relative preferences between courses and dorms, which\nthen influence their priority in either market. I find that paired serial\ndictatorship induces screening along relative preferences and is generally\nwelfare-improving compared to running random serial dictatorship independently\nfor courses and dorms.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02686v1"
    },
    {
        "title": "Bundled School Choice",
        "authors": [
            "Lingbo Huang",
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  This paper introduces a novel school choice system by incorporating school\nbundles into the standard framework. Schools are grouped into hierarchical\nbundles and offered to students as options for preference reports. By listing a\nbundle, a student seeks admission to any school within the bundle without\nranking them. This approach addresses students' difficulty in forming precise\npreference rankings and expands the number of schools students can report on\nconstrained preference lists, potentially enhancing their match likelihood and\nwelfare. We develop a modified deferred acceptance mechanism that maintains\nstability while accommodating bundle reports. Laboratory experiments validate\nour theoretical findings, showing that well-designed bundles aligned with\nstudent preferences improve welfare and matching rates without compromising\nfairness. Practical applications are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04241v1"
    },
    {
        "title": "Making school choice lotteries transparent",
        "authors": [
            "Lingbo Huang",
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  Lotteries are commonly employed in school choice to fairly resolve priority\nties; however, current practices leave students uninformed about their lottery\noutcomes when submitting preferences. This paper advocates for revealing\nlottery results prior to preference submission. When preference lists are\nconstrained in length, revealing lotteries can reduce uncertainties and enable\ninformed decision-making regarding the selection of schools to rank. Through\nthree stylized models, we demonstrate the benefits of lottery revelation in\nresolving conflicting preferences, equalizing opportunities among students with\nvarying outside options, and alleviating the neighborhood school bias. Our\nfindings are further supported by a laboratory experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04243v1"
    },
    {
        "title": "Knowledge Phenomenology Research of Future Industrial Iconic Product\n  Innovation",
        "authors": [
            "Jiang Xu",
            "Haoxiang Qu"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  Iconic products, as innovative carriers supporting the development of future\nindustries, are key breakthrough points for driving the transformation of new\nquality productive forces. This article is grounded in the philosophy of\ntechnology and examines the evolution of human civilization to accurately\nidentify the patterns of product innovation. By integrating theories from\nsystems science, it analyzes the intrinsic logical differences between\ntraditional products and iconic products. The study finds that iconic products\nare based on a comprehensive knowledge system that integrates explicit and\ntacit knowledge, enabling them to adapt to complex dynamic environments.\nTherefore, based on the method of phenomenological essence reduction and the\nprocess of specialized knowledge acquisition, this study establishes the first\nprinciple of knowledge phenomenology: \"knowledge generation-moving from the\ntacit to the explicit-moving from the explicit to the tacit-fusion of the\nexplicit and tacit.\" Grounded in knowledge phenomenology, it reconstructs the\nproduct design evolution process and establishes a forward innovative design\nframework for iconic products, consisting of \"design problem space-explicit\nknowledge space-tacit knowledge space-innovative solution space.\" Furthermore,\nbased on FBS design theory, it develops a disruptive technology innovation\nforecasting framework of \"technology problem space-knowledge base\nprediction-application scenario prediction-coupled technology prediction,\"\nwhich collectively advances the innovation systems engineering of iconic\nproducts. In light of the analysis of the global future industrial competitive\nlandscape, it proposes a strategy for enhancing embodied intelligence in iconic\nproducts.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.07141v1"
    },
    {
        "title": "Entry deterrence by exploiting economies of scope in data aggregation",
        "authors": [
            "Luis Guijarro",
            "José-Ramón Vidal",
            "Vicent Pla"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  We model a market for data where an incumbent and a challenger compete for\ndata from a producer. The incumbent has access to an exclusive data producer,\nand it uses this exclusive access, together with economies of scope in the\naggregation of the data, as a strategy against the potential entry by the\nchallenger. We assess the incumbent incentives to either deter or accommodate\nthe entry of the challenger. We show that the incumbent will accommodate when\nthe exclusive access is costly and when the economies of scope are low, and it\nwill blockade or deter otherwise. The results would justify an access\nregulation that incentivizes the entry of the challenger, e.g., by increasing\nproduction costs for the exclusive data.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.07235v1"
    },
    {
        "title": "Making Tennis Fairer: The Grand Tiebreaker",
        "authors": [
            "Steven J. Brams",
            "Mehmet S. Ismail",
            "D. Marc Kilgour"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  Tennis, like other games and sports, is governed by rules, including the\nrules that determine the winner of points, games, sets, and matches. If the two\nplayers are equally skilled -- each has the same probability of winning a point\nwhen serving or when receiving -- we show that each has an equal chance of\nwinning games, sets, and matches, whether or not sets go to a tiebreak.\nHowever, in a women's match that is decided by 2 out of 3 sets, and a men's\nmatch that is decided by 3 out of 5 sets, it is possible that the player who\nwins the most games may not be the player who wins the match. We calculate the\nprobability that this happens and show that it has actually occurred -- most\nnotably, in the 2019 men's Wimbledon final between Novak Djokovic and Roger\nFederer, which took almost five hours to complete and is considered one of the\ngreatest tennis matches ever (Djokovic won). We argue that the discrepancy\nbetween the game winner and the match winner, when it occurs, should be\nresolved by a Grand Tiebreak (GT) -- played according to the rules of tiebreaks\nin sets -- because each player has a valid claim to being called the rightful\nwinner. A GT would have the salutary effect of -- even every point -- lest\nhe/she win in sets but lose more games. This would make competition keener\nthroughout a match and probably decrease the need for a GT, because the game\nand set winner would more likely coincide when the players fight hard for every\npoint.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.07309v1"
    },
    {
        "title": "Bursting Bubbles in a Macroeconomic Model",
        "authors": [
            "Tomohiro Hirano",
            "Keiichi Kishi",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  This paper identifies the conditions and mechanisms that give rise to\nstochastic bubbles that are expected to collapse. To illustrate the essence of\nthe emergence of stochastic bubbles, we first present a toy model, and then we\npresent a full-fledged macro-finance model of intangible capital and show that\nstochastic stock bubbles attached to intangible capital emerge in the process\nof spillover of technological innovation. We show that the dynamics with\nstochastic bubbles, which is characterized by unbalanced growth, is a temporary\ndeviation from a balanced growth path in which asset prices equal the\nfundamentals.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08215v1"
    },
    {
        "title": "On the Dominance of Truth-Telling in Gradual Mechanisms",
        "authors": [
            "Wenqian Wang",
            "Zhiwen Zheng"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  Recent literature highlights the advantages of implementing social rules via\ndynamic game forms. We characterize when truth-telling remains a dominant\nstrategy in gradual mechanisms implementing strategy-proof social rules, where\nagents gradually reveal their private information while acquiring information\nabout others in the process. Our first characterization hinges on the\nincentive-preservation of a basic transformation on gradual mechanisms called\nilluminating that partitions information sets. The second relies on a single\nreaction-proofness condition. We demonstrate the usefulness of both\ncharacterizations through applications to second-price auctions and the\ntop-trading cycles algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08802v1"
    },
    {
        "title": "A robust measure of complexity",
        "authors": [
            "Egor Bronnikov",
            "Elias Tsakas"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  We introduce a robust belief-based measure of complexity. The idea is that\ntask A is deemed more complex than task B if the probability of solving A\ncorrectly is smaller than the probability of solving B correctly regardless of\nthe reward. We fully characterize the corresponding order over the set of\ntasks. The main characteristic of this relation is that it depends, not only on\ndifficulty (like most complexity definitions in the literature) but also on ex\nante uncertainty. Finally, we show that for every task for which information is\noptimally acquired, there exists a more complex task which always induces less\neffort regardless of the reward.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.09139v1"
    },
    {
        "title": "Topological Connectedness and Behavioral Assumptions on Preferences: A\n  Two-Way Relationship",
        "authors": [
            "M. Ali Khan",
            "Metin Uyanık"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper offers a comprehensive treatment of the question as to whether a\nbinary relation can be consistent (transitive) without being decisive\n(complete), or decisive without being consistent, or simultaneously\ninconsistent or indecisive, in the presence of a continuity hypothesis that is,\nin principle, non-testable. It identifies topological connectedness of the\n(choice) set over which the continuous binary relation is defined as being\ncrucial to this question. Referring to the two-way relationship as the\nEilenberg-Sonnenschein (ES) research program, it presents four synthetic, and\ncomplete, characterizations of connectedness, and its natural extensions; and\ntwo consequences that only stem from it. The six theorems are novel to both the\neconomic and the mathematical literature: they generalize pioneering results of\nEilenberg (1941), Sonnenschein (1965), Schmeidler (1971) and Sen (1969), and\nare relevant to several applied contexts, as well as to ongoing theoretical\nwork.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02004v2"
    },
    {
        "title": "Learning and Selfconfirming Equilibria in Network Games",
        "authors": [
            "Pierpaolo Battigalli",
            "Fabrizio Panebianco",
            "Paolo Pin"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Consider a set of agents who play a network game repeatedly. Agents may not\nknow the network. They may even be unaware that they are interacting with other\nagents in a network. Possibly, they just understand that their payoffs depend\non an unknown state that is, actually, an aggregate of the actions of their\nneighbors. Each time, every agent chooses an action that maximizes her\ninstantaneous subjective expected payoff and then updates her beliefs according\nto what she observes. In particular, we assume that each agent only observes\nher realized payoff. A steady state of the resulting dynamic is a\nselfconfirming equilibrium given the assumed feedback. We characterize the\nstructure of the set of selfconfirming equilibria in the given class of network\ngames, we relate selfconfirming and Nash equilibria, and we analyze simple\nconjectural best-reply paths whose limit points are selfconfirming equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11775v3"
    },
    {
        "title": "Schrödinger type equation for subjective identification of supply\n  and demand",
        "authors": [
            "Marcin Makowski",
            "Edward W. Piotrowski",
            "Jan Sładkowski"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  The present authors have put forward a quantum game theory based model of\nmarket prices movements. By using Fisher information, we present a construction\nof an equation of Schr\\\"{o}dinger type for probability distributions for\nrelationship between demand and supply. Various analogies between quantum\nphysics and market phenomena can be found.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11824v1"
    },
    {
        "title": "Making Decisions under Model Misspecification",
        "authors": [
            "Simone Cerreia-Vioglio",
            "Lars Peter Hansen",
            "Fabio Maccheroni",
            "Massimo Marinacci"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We use decision theory to confront uncertainty that is sufficiently broad to\nincorporate \"models as approximations.\" We presume the existence of a featured\ncollection of what we call \"structured models\" that have explicit substantive\nmotivations. The decision maker confronts uncertainty through the lens of these\nmodels, but also views these models as simplifications, and hence, as\nmisspecified. We extend the max-min analysis under model ambiguity to\nincorporate the uncertainty induced by acknowledging that the models used in\ndecision-making are simplified approximations. Formally, we provide an\naxiomatic rationale for a decision criterion that incorporates model\nmisspecification concerns.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01071v4"
    },
    {
        "title": "Distributionally Robust Pricing in Independent Private Value Auctions",
        "authors": [
            "Alex Suzdaltsev"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A seller chooses a reserve price in a second-price auction to maximize\nworst-case expected revenue when she knows only the mean of value distribution\nand an upper bound on either values themselves or variance. Values are private\nand iid. Using an indirect technique, we prove that it is always optimal to set\nthe reserve price to the seller's own valuation. However, the maxmin reserve\nprice may not be unique. If the number of bidders is sufficiently high, all\nprices below the seller's valuation, including zero, are also optimal. A\nsecond-price auction with the reserve equal to seller's value (or zero) is an\nasymptotically optimal mechanism (among all ex post individually rational\nmechanisms) as the number of bidders grows without bound.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01618v2"
    },
    {
        "title": "Geometry of anonymous binary social choices that are strategy-proof",
        "authors": [
            "Achille Basile",
            "Surekha Rao",
            "K. P. S. Bhaskara Rao"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Let $V$ be society whose members express preferences about two alternatives,\nindifference included. Identifying anonymous binary social choice functions\nwith binary functions $f=f(k,m)$ defined over the integer triangular grid\n$G=\\{(k,m)\\in \\mathbb{N}_0\\times\\mathbb{N}_0 : k+m\\le |V|\\} $, we show that\nevery strategy-proof, anonymous social choice function can be described\ngeometrically by listing, in a sequential manner, groups of segments of G, of\nequal (maximum possible) length, alternately horizontal and vertical,\nrepresentative of preference profiles that determine the collective choice of\none of the two alternatives. Indeed, we show that every function which is\nanonymous and strategy-proof can be described in terms of a sequence of\nnonnegative integers $(q_1, q_2, \\cdots, q_s)$ corresponding to the\ncardinalities of the mentioned groups of segments. We also analyze the\nconnections between our present representation with another of our earlier\nrepresentations involving sequences of majority quotas.\n  A Python code is available with the authors for the implementation of any\nsuch social choice function.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.02041v1"
    },
    {
        "title": "Pricing group membership",
        "authors": [
            "Siddhartha Bandyopadhyay",
            "Antonio Cabrales"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a model where agents differ in their `types' which determines\ntheir voluntary contribution towards a public good. We analyze what the\nequilibrium composition of groups are under centralized and centralized choice.\nWe show that there exists a top-down sorting equilibrium i.e. an equilibrium\nwhere there exists a set of prices which leads to groups that can be ordered by\nlevel of types, with the first k types in the group with the highest price and\nso on. This exists both under decentralized and centralized choosing. We also\nanalyze the model with endogenous group size and examine under what conditions\nis top-down sorting socially efficient. We illustrate when integration (i.e.\nmixing types so that each group's average type if the same) is socially better\nthan top-down sorting. Finally, we show that top down sorting is efficient even\nwhen groups compete among themselves.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.03102v1"
    },
    {
        "title": "Decision Conflict, Logit, and the Outside Option",
        "authors": [
            "Georgios Gerasimou"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Decision makers often opt for the deferral outside option when they find it\ndifficult to make an active choice. Contrary to existing logit models with an\noutside option where the latter is assigned a fixed value exogenously, this\npaper introduces and analyzes a class of logit models where that option's value\nis menu-dependent, may be determined endogenously, and could be interpreted as\nproxying the varying degree of decision difficulty at different menus. We focus\non the *power logit* special class of these models. We show that these predict\nsome observed choice-deferral effects that are caused by hard decisions,\nincluding non-monotonic \"roller-coaster\" choice-overload phenomena that are\nregulated by the presence or absence of a clearly dominant feasible\nalternative. We illustrate the usability, novel insights and explanatory gains\nof the proposed framework for empirical discrete choice analysis and\ntheoretical modelling of imperfectly competitive markets in the presence of\npotentially indecisive consumers.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.04229v9"
    },
    {
        "title": "Purely Bayesian counterfactuals versus Newcomb's paradox",
        "authors": [
            "Lê Nguyên Hoang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper proposes a careful separation between an entity's epistemic system\nand their decision system. Crucially, Bayesian counterfactuals are estimated by\nthe epistemic system; not by the decision system. Based on this remark, I prove\nthe existence of Newcomb-like problems for which an epistemic system\nnecessarily expects the entity to make a counterfactually bad decision. I then\naddress (a slight generalization of) Newcomb's paradox. I solve the specific\ncase where the player believes that the predictor applies Bayes rule with a\nsupset of all the data available to the player. I prove that the counterfactual\noptimality of the 1-Box strategy depends on the player's prior on the\npredictor's additional data. If these additional data are not expected to\nreduce sufficiently the predictor's uncertainty on the player's decision, then\nthe player's epistemic system will counterfactually prefer to 2-Box. But if the\npredictor's data is believed to make them quasi-omniscient, then 1-Box will be\ncounterfactually preferred. Implications of the analysis are then discussed.\nMore generally, I argue that, to better understand or design an entity, it is\nuseful to clearly separate the entity's epistemic, decision, but also data\ncollection, reward and maintenance systems, whether the entity is human,\nalgorithmic or institutional.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.04256v1"
    },
    {
        "title": "On social welfare orders satisfying anonymity and asymptotic density-one\n  Pareto",
        "authors": [
            "Ram Sewak Dubey",
            "Giorgio Laguzzi",
            "Francesco Ruscitti"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the nature (i.e., constructive as opposed to non-constructive) of\nsocial welfare orders on infinite utility streams, and their representability\nby means of real-valued functions. We assume finite anonymity and introduce a\nnew efficiency concept we refer to as asymptotic density-one Pareto. We\ncharacterize the existence of representable and constructive social welfare\norders (satisfying the above properties) in terms of easily verifiable\nconditions on the feasible set of one-period utilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.05879v2"
    },
    {
        "title": "Verification Results for Age-Structured Models of Economic-Epidemics\n  Dynamics",
        "authors": [
            "Giorgio Fabbri",
            "Fausto Gozzi",
            "Giovanni Zanco"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In this paper we propose a macro-dynamic age-structured set-up for the\nanalysis of epidemics/economic dynamics in continuous time. The resulting\noptimal control problem is reformulated in an infinite dimensional Hilbert\nspace framework where we perform the basic steps of dynamic programming\napproach. Our main result is a verification theorem which allows to guess the\nfeedback form of optimal strategies. This will be a departure point to discuss\nthe behavior of the models of the family we introduce and their policy\nimplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.07335v1"
    },
    {
        "title": "The Vigilant Eating Rule: A General Approach for Probabilistic Economic\n  Design with Constraints",
        "authors": [
            "Haris Aziz",
            "Florian Brandl"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider the problem of probabilistic allocation of objects under ordinal\npreferences. We devise an allocation mechanism, called the vigilant eating rule\n(VER), that applies to nearly arbitrary feasibility constraints. It is\nconstrained ordinally efficient, can be computed efficiently for a large class\nof constraints, and treats agents equally if they have the same preferences and\nare subject to the same constraints. When the set of feasible allocations is\nconvex, we also present a characterization of our rule based on ordinal\negalitarianism. Our results about VER do not just apply to allocation problems\nbut to all collective choice problems in which agents have ordinal preferences\nover discrete outcomes. As a case study, we assume objects have priorities for\nagents and apply VER to sets of probabilistic allocations that are constrained\nby stability. VER coincides with the (extended) probabilistic serial rule when\npriorities are flat and the agent proposing deterministic deferred acceptance\nalgorithm when preferences and priorities are strict. While VER always returns\na stable and constrained efficient allocation, it fails to be strategyproof,\nunconstrained efficient, and envy-free. We show, however, that each of these\nthree properties is incompatible with stability and constrained efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.08991v3"
    },
    {
        "title": "Constrained Trading Networks",
        "authors": [
            "Can Kizilkale",
            "Rakesh Vohra"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Trades based on bilateral (indivisible) contracts can be represented by a\nnetwork. Vertices correspond to agents while arcs represent the non-price\nelements of a bilateral contract. Given prices for each arc, agents choose the\nincident arcs that maximize their utility. We enlarge the model to allow for\npolymatroidal constraints on the set of contracts that may be traded which can\nbe interpreted as modeling limited one for-one substitution. We show that for\ntwo-sided markets there exists a competitive equilibrium however for\nmulti-sided markets this may not be possible.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.09757v1"
    },
    {
        "title": "Insights on the Theory of Robust Games",
        "authors": [
            "Giovanni Paolo Crespi",
            "Davide Radi",
            "Matteo Rocca"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A robust game is a distribution-free model to handle ambiguity generated by a\nbounded set of possible realizations of the values of players' payoff\nfunctions. The players are worst-case optimizers and a solution, called\nrobust-optimization equilibrium, is guaranteed by standard regularity\nconditions. The paper investigates the sensitivity to the level of uncertainty\nof this equilibrium. Specifically, we prove that it is an epsilon-Nash\nequilibrium of the nominal counterpart game, where the epsilon-approximation\nmeasures the extra profit that a player would obtain by reducing his level of\nuncertainty. Moreover, given an epsilon-Nash equilibrium of a nominal game, we\nprove that it is always possible to introduce uncertainty such that the\nepsilon-Nash equilibrium is a robust-optimization equilibrium. An example shows\nthat a robust Cournot duopoly model can admit multiple and asymmetric\nrobust-optimization equilibria despite only a symmetric Nash equilibrium exists\nfor the nominal counterpart game.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.00225v1"
    },
    {
        "title": "An optimal mechanism charging for priority in a queue",
        "authors": [
            "Moshe Haviv",
            "Eyal Winter"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We derive a revenue-maximizing scheme that charges customers who are\nhomogeneous with respect to their waiting cost parameter for a random fee in\norder to become premium customers. This scheme incentivizes all customers to\npurchase priority, each at his/her drawn price. We also design a\nrevenue-maximizing scheme for the case where customers are heterogeneous with\nrespect to their waiting cost parameter. Now lower cost parameter customers are\nencouraged to join the premium class at a low price: Given that, those with\nhigh cost parameter would be willing to pay even more for this privilege.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06533v1"
    },
    {
        "title": "The Theory of Weak Revealed Preference",
        "authors": [
            "Victor H. Aguiar",
            "Per Hjertstrand",
            "Roberto Serrano"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We offer a rationalization of the weak generalized axiom of revealed\npreference (WGARP) for both finite and infinite data sets of consumer choice.\nWe call it maximin rationalization, in which each pairwise choice is associated\nwith a \"local\" utility function. We develop its associated weak\nrevealed-preference theory. We show that preference recoverability and welfare\nanalysis \\`a la Varian (1982) may not be informative enough, when the weak\naxiom holds, but when consumers are not utility maximizers. We clarify the\nreasons for this failure and provide new informative bounds for the consumer's\ntrue preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.00296v1"
    },
    {
        "title": "The Hamiltonian approach to the problem of derivation of production\n  functions in economic growth theory",
        "authors": [
            "Roman G. Smirnov",
            "Kunpeng Wang"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We introduce a general Hamiltonian framework that appears to be a natural\nsetting for the derivation of various production functions in economic growth\ntheory, starting with the celebrated Cobb-Douglas function. Employing our\nmethod, we investigate some existing models and propose a new one as special\ncases of the general $n$-dimensional Lotka-Volterra system of eco-dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.11224v1"
    },
    {
        "title": "An Analysis of Random Elections with Large Numbers of Voters",
        "authors": [
            "Matthew Harrison-Trainor"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In an election in which each voter ranks all of the candidates, we consider\nthe head-to-head results between each pair of candidates and form a labeled\ndirected graph, called the margin graph, which contains the margin of victory\nof each candidate over each of the other candidates. A central issue in\ndeveloping voting methods is that there can be cycles in this graph, where\ncandidate $\\mathsf{A}$ defeats candidate $\\mathsf{B}$, $\\mathsf{B}$ defeats\n$\\mathsf{C}$, and $\\mathsf{C}$ defeats $\\mathsf{A}$. In this paper we apply the\ncentral limit theorem, graph homology, and linear algebra to analyze how likely\nsuch situations are to occur for large numbers of voters. There is a large\nliterature on analyzing the probability of having a majority winner; our\nanalysis is more fine-grained. The result of our analysis is that in elections\nwith the number of voters going to infinity, margin graphs that are more cyclic\nin a certain precise sense are less likely to occur.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.02979v1"
    },
    {
        "title": "Sales Policies for a Virtual Assistant",
        "authors": [
            "Wenjia Ba",
            "Haim Mendelson",
            "Mingxi Zhu"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the implications of selling through a voice-based virtual assistant\n(VA). The seller has a set of products available and the VA decides which\nproduct to offer and at what price, seeking to maximize its revenue, consumer-\nor total-surplus. The consumer is impatient and rational, seeking to maximize\nher expected utility given the information available to her. The VA selects\nproducts based on the consumer's request and other information available to it\nand then presents them sequentially. Once a product is presented and priced,\nthe consumer evaluates it and decides whether to make a purchase. The\nconsumer's valuation of each product comprises a pre-evaluation value, which is\ncommon knowledge, and a post-evaluation component which is private to the\nconsumer. We solve for the equilibria and develop efficient algorithms for\nimplementing the solution. We examine the effects of information asymmetry on\nthe outcomes and study how incentive misalignment depends on the distribution\nof private valuations. We find that monotone rankings are optimal in the cases\nof a highly patient or impatient consumer and provide a good approximation for\nother levels of patience. The relationship between products' expected\nvaluations and prices depends on the consumer's patience level and is monotone\nincreasing (decreasing) when the consumer is highly impatient (patient). Also,\nthe seller's share of total surplus decreases in the amount of private\ninformation. We compare the VA to a traditional web-based interface, where\nmultiple products are presented simultaneously on each page. We find that\nwithin a page, the higher-value products are priced lower than the lower-value\nproducts when the private valuations are exponentially distributed. Finally,\nthe web-based interface generally achieves higher profits for the seller than a\nVA due to the greater commitment power inherent in its presentation.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.03719v1"
    },
    {
        "title": "Mechanisms for a No-Regret Agent: Beyond the Common Prior",
        "authors": [
            "Modibo Camara",
            "Jason Hartline",
            "Aleck Johnsen"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A rich class of mechanism design problems can be understood as\nincomplete-information games between a principal who commits to a policy and an\nagent who responds, with payoffs determined by an unknown state of the world.\nTraditionally, these models require strong and often-impractical assumptions\nabout beliefs (a common prior over the state). In this paper, we dispense with\nthe common prior. Instead, we consider a repeated interaction where both the\nprincipal and the agent may learn over time from the state history. We\nreformulate mechanism design as a reinforcement learning problem and develop\nmechanisms that attain natural benchmarks without any assumptions on the\nstate-generating process. Our results make use of novel behavioral assumptions\nfor the agent -- centered around counterfactual internal regret -- that capture\nthe spirit of rationality without relying on beliefs.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.05518v1"
    },
    {
        "title": "Selling Two Identical Objects",
        "authors": [
            "Sushil Bikhchandani",
            "Debasis Mishra"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  It is well-known that optimal (i.e., revenue-maximizing) selling mechanisms\nin multidimensional type spaces may involve randomization. We obtain conditions\nunder which deterministic mechanisms are optimal for selling two identical,\nindivisible objects to a single buyer. We analyze two settings: (i) decreasing\nmarginal values (DMV) and (ii) increasing marginal values (IMV). Thus, the\nvalues of the buyer for the two units are not independent.\n  We show that under a well-known condition on distributions~(due to McAfee and\nMcMillan (1988)), (a) it is optimal to sell the first unit deterministically in\nthe DMV model and (b) it is optimal to bundle (which is a deterministic\nmechanism) in the IMV model. Under a stronger sufficient condition on\ndistributions, a deterministic mechanism is optimal in the DMV model.\n  Our results apply to heterogeneous objects when there is a specified sequence\nin which the two objects must be sold.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.11545v5"
    },
    {
        "title": "Social Learning in Nonatomic Routing Games",
        "authors": [
            "Emilien Macault",
            "Marco Scarsini",
            "Tristan Tomala"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a discrete-time nonatomic routing game with variable demand and\nuncertain costs. Given a routing network with single origin and destination,\nthe cost function of each edge depends on some uncertain persistent state\nparameter. At every period, a random traffic demand is routed through the\nnetwork according to a Wardrop equilibrium. The realized costs are publicly\nobserved and the public Bayesian belief about the state parameter is updated.\nWe say that there is strong learning when beliefs converge to the truth and\nweak learning when the equilibrium flow converges to the complete-information\nflow. We characterize the networks for which learning occurs. We prove that\nthese networks have a series-parallel structure and provide a counterexample to\nshow that learning may fail in non-series-parallel networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.11580v3"
    },
    {
        "title": "A characterization of absorbing sets in coalition formation games",
        "authors": [
            "Agustin G. Bonifacio",
            "Elena Inarra",
            "Pablo Neme"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Given a standard myopic dynamic process among coalition structures, an\nabsorbing set is a minimal collection of such structures that is never left\nonce entered through that process. Absorbing sets are an important solution\nconcept in coalition formation games, but they have drawbacks: they can be\nlarge and hard to obtain. In this paper, we characterize an absorbing set in\nterms of a collection consisting of a small number of sets of coalitions that\nwe refer to as a \"reduced form\" of a game. We apply our characterization to\nstudy convergence to stability in several economic environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.11689v3"
    },
    {
        "title": "Pareto efficient combinatorial auctions: dichotomous preferences without\n  quasilinearity",
        "authors": [
            "Komal Malik",
            "Debasis Mishra"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a combinatorial auction model where preferences of agents over\nbundles of objects and payments need not be quasilinear. However, we restrict\nthe preferences of agents to be dichotomous. An agent with dichotomous\npreference partitions the set of bundles of objects as acceptable} and\nunacceptable, and at the same payment level, she is indifferent between bundles\nin each class but strictly prefers acceptable to unacceptable bundles. We show\nthat there is no Pareto efficient, dominant strategy incentive compatible\n(DSIC), individually rational (IR) mechanism satisfying no subsidy if the\ndomain of preferences includes all dichotomous preferences. However, a\ngeneralization of the VCG mechanism is Pareto efficient, DSIC, IR and satisfies\nno subsidy if the domain of preferences contains only positive income effect\ndichotomous preferences. We show the tightness of this result: adding any\nnon-dichotomous preference (satisfying some natural properties) to the domain\nof quasilinear dichotomous preferences brings back the impossibility result.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12114v1"
    },
    {
        "title": "Ordinal Bayesian incentive compatibility in random assignment model",
        "authors": [
            "Sulagna Dasgupta",
            "Debasis Mishra"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We explore the consequences of weakening the notion of incentive\ncompatibility from strategy-proofness to ordinal Bayesian incentive\ncompatibility (OBIC) in the random assignment model. If the common prior of the\nagents is a uniform prior, then a large class of random mechanisms are OBIC\nwith respect to this prior -- this includes the probabilistic serial mechanism.\nWe then introduce a robust version of OBIC: a mechanism is locally robust OBIC\nif it is OBIC with respect all independent priors in some neighborhood of a\ngiven independent prior. We show that every locally robust OBIC mechanism\nsatisfying a mild property called elementary monotonicity is strategy-proof.\nThis leads to a strengthening of the impossibility result in Bogomolnaia and\nMoulin (2001): if there are at least four agents, there is no locally robust\nOBIC and ordinally efficient mechanism satisfying equal treatment of equals.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.13104v2"
    },
    {
        "title": "Expectations, Networks, and Conventions",
        "authors": [
            "Benjamin Golub",
            "Stephen Morris"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In coordination games and speculative over-the-counter financial markets,\nsolutions depend on higher-order average expectations: agents' expectations\nabout what counterparties, on average, expect their counterparties to think,\netc. We offer a unified analysis of these objects and their limits, for general\ninformation structures, priors, and networks of counterparty relationships. Our\nkey device is an interaction structure combining the network and agents'\nbeliefs, which we analyze using Markov methods. This device allows us to nest\nclassical beauty contests and network games within one model and unify their\nresults. Two applications illustrate the techniques: The first characterizes\nwhen slight optimism about counterparties' average expectations leads to\ncontagion of optimism and extreme asset prices. The second describes the\ntyranny of the least-informed: agents coordinating on the prior expectations of\nthe one with the worst private information, despite all having nearly common\ncertainty, based on precise private signals, of the ex post optimal action.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.13802v1"
    },
    {
        "title": "The Implications of Pricing on Social Learning",
        "authors": [
            "Itai Arieli",
            "Moran Koren",
            "Rann Smorodinsky"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the implications of endogenous pricing for learning and welfare in\nthe classic herding model . When prices are determined exogenously, it is known\nthat learning occurs if and only if signals are unbounded. By contrast, we show\nthat learning can occur when signals are bounded as long as non-conformism\namong consumers is scarce. More formally, learning happens if and only if\nsignals exhibit the vanishing likelihood property introduced bellow. We discuss\nthe implications of our results for potential market failure in the context of\nSchumpeterian growth with uncertainty over the value of innovations.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03452v1"
    },
    {
        "title": "On the Kolkata index as a measure of income inequality",
        "authors": [
            "Suchismita Banerjee",
            "Bikas K. Chakrabarti",
            "Manipushpak Mitra",
            "Suresh Mutuswami"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the mathematical and economic structure of the Kolkata (k) index of\nincome inequality. We show that the k-index always exists and is a unique fixed\npoint of the complementary Lorenz function, where the Lorenz function itself\ngives the fraction of cumulative income possessed by the cumulative fraction of\npopulation (when arranged from poorer to richer). We show that the k-index\ngeneralizes Pareto's 80/20 rule. Although the k and Pietra indices both split\nthe society into two groups, we show that k-index is a more intensive measure\nfor the poor-rich split. We compare the normalized k-index with the Gini\ncoefficient and the Pietra index and discuss when they coincide. We establish\nthat for any income distribution the value of Gini coefficient is no less than\nthat of the Pietra index and the value of the Pietra index is no less than that\nof the normalized k-index. While the Gini coefficient and the Pietra index are\naffected by transfers exclusively among the rich or among the poor, the k-index\nis only affected by transfers across the two groups.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03615v2"
    },
    {
        "title": "Identifying Present-Bias from the Timing of Choices",
        "authors": [
            "Paul Heidhues",
            "Philipp Strack"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Timing decisions are common: when to file your taxes, finish a referee\nreport, or complete a task at work. We ask whether time preferences can be\ninferred when \\textsl{only} task completion is observed. To answer this\nquestion, we analyze the following model: each period a decision maker faces\nthe choice whether to complete the task today or to postpone it to later. Cost\nand benefits of task completion cannot be directly observed by the analyst, but\nthe analyst knows that net benefits are drawn independently between periods\nfrom a time-invariant distribution and that the agent has time-separable\nutility. Furthermore, we suppose the analyst can observe the agent's exact\nstopping probability. We establish that for any agent with quasi-hyperbolic\n$\\beta,\\delta$-preferences and given level of partial naivete $\\hat{\\beta}$,\nthe probability of completing the task conditional on not having done it\nearlier increases towards the deadline. And conversely, for any given\npreference parameters $\\beta,\\delta$ and (weakly increasing) profile of task\ncompletion probability, there exists a stationary payoff distribution that\nrationalizes her behavior as long as the agent is either sophisticated or fully\nnaive. An immediate corollary being that, without parametric assumptions, it is\nimpossible to rule out time-consistency even when imposing an a priori\nassumption on the permissible long-run discount factor. We also provide an\nexact partial identification result when the analyst can, in addition to the\nstopping probability, observe the agent's continuation value.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03959v1"
    },
    {
        "title": "Mixtures of Mean-Preserving Contractions",
        "authors": [
            "Joseph Whitmeyer",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Given a purely atomic probability measure with support on n points, P, any\nmean-preserving contraction (mpc) of P, Q, with support on m > n points is a\nmixture of mpcs of P, each with support on most n points. We illustrate an\napplication of this result in economics.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.05157v3"
    },
    {
        "title": "Cheating in Ranking Systems",
        "authors": [
            "Lihi Dery",
            "Dror Hermel",
            "Artyom Jelnov"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Consider an application sold on an on-line platform, with the app paying a\ncommission fee and, henceforth, offered for sale on the platform. The ability\nto sell the application depends on its customer ranking. Therefore, developers\nmay have an incentive to promote their applications ranking in a dishonest\nmanner. One way to do this is by faking positive customer reviews. However, the\nplatform is able to detect dishonest behavior (cheating) with some probability\nand then proceeds to decide whether to ban the application. We provide an\nanalysis and find the equilibrium behaviors of both the applications developers\n(cheat or not) and the platform (setting of the commission fee). We provide\ninitial insights into how the platforms detection accuracy affects the\nincentives of the app developers.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.09116v1"
    },
    {
        "title": "The Income Fluctuation Problem and the Evolution of Wealth",
        "authors": [
            "Qingyin Ma",
            "John Stachurski",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We analyze the household savings problem in a general setting where returns\non assets, non-financial income and impatience are all state dependent and\nfluctuate over time. All three processes can be serially correlated and\nmutually dependent. Rewards can be bounded or unbounded and wealth can be\narbitrarily large. Extending classic results from an earlier literature, we\ndetermine conditions under which (a) solutions exist, are unique and are\nglobally computable, (b) the resulting wealth dynamics are stationary, ergodic\nand geometrically mixing, and (c) the wealth distribution has a Pareto tail. We\nshow how these results can be used to extend recent studies of the wealth\ndistribution. Our conditions have natural economic interpretations in terms of\nasymptotic growth rates for discounting and return on savings.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.13045v3"
    },
    {
        "title": "Quality Selection in Two-Sided Markets: A Constrained Price\n  Discrimination Approach",
        "authors": [
            "Bar Light",
            "Ramesh Johari",
            "Gabriel Weintraub"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Online platforms collect rich information about participants and then share\nsome of this information back with them to improve market outcomes. In this\npaper we study the following information disclosure problem in two-sided\nmarkets: If a platform wants to maximize revenue, which sellers should the\nplatform allow to participate, and how much of its available information about\nparticipating sellers' quality should the platform share with buyers? We study\nthis information disclosure problem in the context of two distinct two-sided\nmarket models: one in which the platform chooses prices and the sellers choose\nquantities (similar to ride-sharing), and one in which the sellers choose\nprices (similar to e-commerce). Our main results provide conditions under which\nsimple information structures commonly observed in practice, such as banning\ncertain sellers from the platform while not distinguishing between\nparticipating sellers, maximize the platform's revenue. The platform's\ninformation disclosure problem naturally transforms into a constrained price\ndiscrimination problem where the constraints are determined by the equilibrium\noutcomes of the specific two-sided market model being studied. We analyze this\nconstrained price discrimination problem to obtain our structural results.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.02251v7"
    },
    {
        "title": "On an Extension of a Theorem of Eilenberg and a Characterization of\n  Topological Connectedness",
        "authors": [
            "M. Ali Khan",
            "Metin Uyanik"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  On taking a non-trivial and semi-transitive bi-relation constituted by two\n(hard and soft) binary relations, we report a (i) p-continuity assumption that\nguarantees the completeness and transitivity of its soft part, and a (ii)\ncharacterization of a connected topological space in terms of its attendant\nproperties on the space. Our work generalizes antecedent results in applied\nmathematics, all following Eilenberg (1941), and now framed in the context of a\nparametrized-topological space. This re-framing is directly inspired by the\ncontinuity assumption in Wold (1943-44) and the mixture-space structure\nproposed in Herstein and Milnor (1953), and the unifying synthesis of these\npioneering but neglected papers that it affords may have independent interest.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.12787v1"
    },
    {
        "title": "Robust perfect equilibrium in large games",
        "authors": [
            "Enxian Chen",
            "Lei Qiao",
            "Xiang Sun",
            "Yeneng Sun"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper proposes a new equilibrium concept \"robust perfect equilibrium\"\nfor non-cooperative games with a continuum of players, incorporating three\ntypes of perturbations. Such an equilibrium is shown to exist (in symmetric\nmixed strategies and in pure strategies) and satisfy the important properties\nof admissibility, aggregate robustness, and ex post robust perfection. These\nproperties strengthen relevant equilibrium results in an extensive literature\non strategic interactions among a large number of agents. Illustrative\napplications to congestion games and potential games are presented. In the\nparticular case of a congestion game with strictly increasing cost functions,\nwe show that there is a unique symmetric robust perfect equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.12908v3"
    },
    {
        "title": "A game of hide and seek in networks",
        "authors": [
            "Francis Bloch",
            "Bhaskar Dutta",
            "Marcin Dziubinski"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose and study a strategic model of hiding in a network, where the\nnetwork designer chooses the links and his position in the network facing the\nseeker who inspects and disrupts the network. We characterize optimal networks\nfor the hider, as well as equilibrium hiding and seeking strategies on these\nnetworks. We show that optimal networks are either equivalent to cycles or\nvariants of a core-periphery networks where every node in the periphery is\nconnected to a single node in the core.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03132v1"
    },
    {
        "title": "Optimal epidemic suppression under an ICU constraint",
        "authors": [
            "Laurent Miclo",
            "Daniel Spiro",
            "Jörgen Weibull"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  How much and when should we limit economic and social activity to ensure that\nthe health-care system is not overwhelmed during an epidemic? We study a\nsetting where ICU resources are constrained while suppression is costly (e.g.,\nlimiting economic interaction). Providing a fully analytical solution we show\nthat the common wisdom of \"flattening the curve\", where suppression measures\nare continuously taken to hold down the spread throughout the epidemic, is\nsuboptimal. Instead, the optimal suppression is discontinuous. The epidemic\nshould be left unregulated in a first phase and when the ICU constraint is\napproaching society should quickly lock down (a discontinuity). After the\nlockdown regulation should gradually be lifted, holding the rate of infected\nconstant thus respecting the ICU resources while not unnecessarily limiting\neconomic activity. In a final phase, regulation is lifted. We call this\nstrategy \"filling the box\".\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01327v1"
    },
    {
        "title": "Equilibria of nonatomic anonymous games",
        "authors": [
            "Simone Cerreia-Vioglio",
            "Fabio Maccheroni",
            "David Schmeidler"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We add here another layer to the literature on nonatomic anonymous games\nstarted with the 1973 paper by Schmeidler. More specifically, we define a new\nnotion of equilibrium which we call $\\varepsilon$-estimated equilibrium and\nprove its existence for any positive $\\varepsilon$. This notion encompasses and\nbrings to nonatomic games recent concepts of equilibrium such as\nself-confirming, peer-confirming, and Berk--Nash. This augmented scope is our\nmain motivation. At the same time, our approach also resolves some conceptual\nproblems present in Schmeidler (1973), pointed out by Shapley. In that paper\\\nthe existence of pure-strategy Nash equilibria has been proved for any\nnonatomic game with a continuum of players, endowed with an atomless countably\nadditive probability. But, requiring Borel measurability of strategy profiles\nmay impose some limitation on players' choices and introduce an exogenous\ndependence among\\ players' actions, which clashes with the nature of\nnoncooperative game theory. Our suggested solution is to consider every subset\nof players as measurable. This leads to a nontrivial purely finitely additive\ncomponent which might prevent the existence of equilibria and requires a novel\nmathematical approach to prove the existence of $\\varepsilon$-equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01839v1"
    },
    {
        "title": "Belief-Averaged Relative Utilitarianism",
        "authors": [
            "Florian Brandl"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider social welfare functions when the preferences of individual\nagents and society maximize subjective expected utility in the tradition of\nSavage. A system of axioms is introduced whose unique solution is the social\nwelfare function that averages the agents' beliefs and sums up their utility\nfunctions, normalized to have the same range. The first distinguishing axiom\nrequires positive association of society's preferences with the agents'\npreferences for acts about which beliefs agree. The second is a weakening of\nArrow's independence of irrelevant alternatives that only applies to\nnon-redundant acts.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.03693v3"
    },
    {
        "title": "Functional Decision Theory in an Evolutionary Environment",
        "authors": [
            "Noah Topper"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Functional decision theory (FDT) is a fairly new mode of decision theory and\na normative viewpoint on how an agent should maximize expected utility. The\ncurrent standard in decision theory and computer science is causal decision\ntheory (CDT), largely seen as superior to the main alternative evidential\ndecision theory (EDT). These theories prescribe three distinct methods for\nmaximizing utility. We explore how FDT differs from CDT and EDT, and what\nimplications it has on the behavior of FDT agents and humans. It has been shown\nin previous research how FDT can outperform CDT and EDT. We additionally show\nFDT performing well on more classical game theory problems and argue for its\nextension to human problems to show that its potential for superiority is\nrobust. We also make FDT more concrete by displaying it in an evolutionary\nenvironment, competing directly against other theories.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05154v2"
    },
    {
        "title": "Evolution, Heritable Risk, and Skewness Loving",
        "authors": [
            "Yuval Heller",
            "Arthur Robson"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Our understanding of risk preferences can be sharpened by considering their\nevolutionary basis. The existing literature has focused on two sources of risk:\nidiosyncratic risk and aggregate risk. We introduce a new source of risk,\nheritable risk, in which there is a positive correlation between the fitness of\na newborn agent and the fitness of her parent. Heritable risk was plausibly\ncommon in our evolutionary past and it leads to a strictly higher growth rate\nthan the other sources of risk. We show that the presence of heritable risk in\nthe evolutionary past may explain the tendency of people to exhibit skewness\nloving today.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05772v3"
    },
    {
        "title": "Fault Tolerant Equilibria in Anonymous Games: best response\n  correspondences and fixed points",
        "authors": [
            "Deepanshu Vasal",
            "Randall Berry"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The notion of fault tolerant Nash equilibria has been introduced as a way of\nstudying the robustness of Nash equilibria. Under this notion, a fixed number\nof players are allowed to exhibit faulty behavior in which they may deviate\narbitrarily from an equilibrium strategy. A Nash equilibrium in a game with $N$\nplayers is said to be $\\alpha$-tolerant if no non-faulty user wants to deviate\nfrom an equilibrium strategy as long as $N-\\alpha-1$ other players are playing\nthe equilibrium strategies, i.e., it is robust to deviations from rationality\nby $\\alpha$ faulty players. In prior work, $\\alpha$-tolerance has been largely\nviewed as a property of a given Nash equilibria. Here, instead we consider\nfollowing Nash's approach for showing the existence of equilibria, namely,\nthrough the use of best response correspondences and fixed-point arguments. In\nthis manner, we provide sufficient conditions for the existence an\n$\\alpha$-tolerant equilibrium. This involves first defining an\n$\\alpha$-tolerant best response correspondence. Given a strategy profile of\nnon-faulty agents, this correspondence contains strategies for a non-faulty\nplayer that are a best response given any strategy profile of the faulty\nplayers. We prove that if this correspondence is non-empty, then it is\nupper-hemi-continuous. This enables us to apply Kakutani's fixed-point theorem\nand argue that if this correspondence is non-empty for every strategy profile\nof the non-faulty players then there exists an $\\alpha$-tolerant equilibrium.\nHowever, we also illustrate by examples, that in many games this best response\ncorrespondence will be empty for some strategy profiles even though\n$\\alpha$-tolerant equilibira still exist.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06812v2"
    },
    {
        "title": "Existence and Uniqueness of Recursive Utility Models in $L_p$",
        "authors": [
            "Flint O'Neil"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Recursive preferences, of the sort developed by Epstein and Zin (1989), play\nan integral role in modern macroeconomics and asset pricing theory.\nUnfortunately, it is non-trivial to establish the unique existence of a\nsolution to recursive utility models. We show that the tightest known existence\nand uniqueness conditions can be extended to (i) Schorfheide, Song and Yaron\n(2018) recursive utilities and (ii) recursive utilities with `narrow framing'.\nFurther, we sharpen the solution space of Borovicka and Stachurski (2019) from\n$L_1$ to $L_p$ so that the results apply to a broader class of modern asset\npricing models. For example, using $L_2$ Hilbert space theory, we find the\nclass of parameters which generate a unique $L_2$ solution to the Bansal and\nYaron (2004) and Schorfheide, Song and Yaron (2018) models.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07067v1"
    },
    {
        "title": "Cores in discrete exchange economies with complex endowments",
        "authors": [
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The core is a traditional and useful solution concept in economic theory. But\nin discrete exchange economies without transfers, when endowments are complex,\nthe core may be empty. This motivates Balbuzanov and Kotowski (2019) to\ninterpret endowments as exclusion rights and propose a new concept called\nexclusion core. Our contribution is twofold. First, we propose a rectification\nof the core to solve its problem under complex endowments. Second, we propose a\nrefinement of Balbuzanov and Kotowski's exclusion core to improve its\nperformance. Our two core concepts share a common idea of correcting the\nmisused altruism of unaffected agents in blocking coalitions. We propose a\nmechanism to find allocations in the two cores.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.09351v2"
    },
    {
        "title": "Second-order Inductive Inference: an axiomatic approach",
        "authors": [
            "Patrick H. O'Callaghan"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Consider a predictor who ranks eventualities on the basis of past cases: for\ninstance a search engine ranking webpages given past searches. Resampling past\ncases leads to different rankings and the extraction of deeper information. Yet\na rich database, with sufficiently diverse rankings, is often beyond reach.\nInexperience demands either \"on the fly\" learning-by-doing or prudence: the\narrival of a novel case does not force (i) a revision of current rankings, (ii)\ndogmatism towards new rankings, or (iii) intransitivity. For this higher-order\nframework of inductive inference, we derive a suitably unique numerical\nrepresentation of these rankings via a matrix on eventualities x cases and\ndescribe a robust test of prudence. Applications include: the success/failure\nof startups; the veracity of fake news; and novel conditions for the existence\nof a yield curve that is robustly arbitrage-free.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.02934v5"
    },
    {
        "title": "Equilibria in a large production economy with an infinite dimensional\n  commodity space and price dependent preferences",
        "authors": [
            "Hyo Seok Jang",
            "Sangjik Lee"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We prove the existence of a competitive equilibrium in a production economy\nwith infinitely many commodities and a measure space of agents whose\npreferences are price dependent. We employ a saturated measure space for the\nset of agents and apply recent results for an infinite dimensional separable\nBanach space such as Lyapunov's convexity theorem and an exact Fatou's lemma to\nobtain the result.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.07444v2"
    },
    {
        "title": "Efficiency in Truthful Auctions via a Social Network",
        "authors": [
            "Seiji Takanashi",
            "Takehiro Kawasaki",
            "Taiki Todo",
            "Makoto Yokoo"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this paper, we study efficiency in truthful auctions via a social network,\nwhere a seller can only spread the information of an auction to the buyers\nthrough the buyers' network. In single-item auctions, we show that no mechanism\nis strategy-proof, individually rational, efficient, and weakly budget\nbalanced. In addition, we propose $\\alpha$-APG mechanisms, a class of\nmechanisms which operate a trade-off between efficiency and weakly budget\nbalancedness. In multi-item auctions, there already exists a strategy-proof\nmechanism when all buyers need only one item. However, we indicate a\ncounter-example to strategy-proofness in this mechanism, and to the best of our\nknowledge, the question of finding a strategy-proof mechanism remains open. We\nassume that all buyers have decreasing marginal utility and propose a\ngeneralized APG mechanism that is strategy-proof and individually rational but\nnot efficient. Importantly, we show that this mechanism achieves the largest\nefficiency measure among all strategy-proof mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12422v1"
    },
    {
        "title": "Derivation of non-classical stochastic price dynamics equations",
        "authors": [
            "Carey Caginalp",
            "Gunduz Caginalp"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We analyze the relative price change of assets starting from basic\nsupply/demand considerations subject to arbitrary motivations. The resulting\nstochastic differential equation has coefficients that are functions of supply\nand demand. We derive these rigorously. The variance in the relative price\nchange is then also dependent on the supply and demand, and is closely\nconnected to the expected return. An important consequence for risk assessment\nand options pricing is the implication that variance is highest when the\nmagnitude of price change is greatest, and lowest near market extrema. This\noccurs even if supply and demand are not dependent on price trend. The\nstochastic equation differs from the standard equation in mathematical finance\nin which the expected return and variance are decoupled. The methodology has\nimplications for the basic framework for risk assessment, suggesting that\nvolatility should be measured in the context of regimes of price change. The\nmodel we propose shows how investors are often misled by the apparent calm of\nmarkets near a market peak. Risk assessment methods utilizing volatility can be\nimproved using this formulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.01103v2"
    },
    {
        "title": "Fairness and efficiency for probabilistic allocations with participation\n  constraints",
        "authors": [
            "Federico Echenique",
            "Antonio Miralles",
            "Jun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We propose a notion of fairness for allocation problems in which different\nagents may have different reservation utilities, stemming from different\noutside options, or property rights. Fairness is usually understood as the\nabsence of envy, but this can be incompatible with reservation utilities. It is\npossible that Alice's envy of Bob's assignment cannot be remedied without\nviolating Bob's participation constraint. Instead, we seek to rule out {\\em\njustified envy}, defined as envy for which a remedy would not violate any\nagent's participation constraint. We show that fairness, meaning the absence of\njustified envy, can be achieved together with efficiency and individual\nrationality. We introduce a competitive equilibrium approach with\nprice-dependent incomes obtaining the desired properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.04336v3"
    },
    {
        "title": "Probabilistic Verification in Mechanism Design",
        "authors": [
            "Ian Ball",
            "Deniz Kattwinkel"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We introduce a model of probabilistic verification in mechanism design. The\nprincipal elicits a message from the agent and then selects a test to give the\nagent. The agent's true type determines the probability with which he can pass\neach test. We characterize whether each type has an associated test that best\nscreens out all other types. If this condition holds, then the testing\ntechnology can be represented in a tractable reduced form. We use this reduced\nform to solve for profit-maximizing mechanisms with verification. As the\nverification technology varies, the solution continuously interpolates between\nthe no-verification solution and full surplus extraction.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.05556v5"
    },
    {
        "title": "Outgroup Homogeneity Bias Causes Ingroup Favoritism",
        "authors": [
            "Marcel Montrey",
            "Thomas R. Shultz"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Ingroup favoritism, the tendency to favor ingroup over outgroup, is often\nexplained as a product of intergroup conflict, or correlations between group\ntags and behavior. Such accounts assume that group membership is meaningful,\nwhereas human data show that ingroup favoritism occurs even when it confers no\nadvantage and groups are transparently arbitrary. Another possibility is that\ningroup favoritism arises due to perceptual biases like outgroup homogeneity,\nthe tendency for humans to have greater difficulty distinguishing outgroup\nmembers than ingroup ones. We present a prisoner's dilemma model, where\nindividuals use Bayesian inference to learn how likely others are to cooperate,\nand then act rationally to maximize expected utility. We show that, when such\nindividuals exhibit outgroup homogeneity bias, ingroup favoritism between\narbitrary groups arises through direct reciprocity. However, this outcome may\nbe mitigated by: (1) raising the benefits of cooperation, (2) increasing\npopulation diversity, and (3) imposing a more restrictive social structure.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.08203v1"
    },
    {
        "title": "Recovering Preferences from Finite Data",
        "authors": [
            "Christopher P. Chambers",
            "Federico Echenique",
            "Nicolas Lambert"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study preferences estimated from finite choice experiments and provide\nsufficient conditions for convergence to a unique underlying \"true\" preference.\nOur conditions are weak, and therefore valid in a wide range of economic\nenvironments. We develop applications to expected utility theory, choice over\nconsumption bundles, menu choice and intertemporal consumption. Our framework\nunifies the revealed preference tradition with models that allow for errors.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.05457v4"
    },
    {
        "title": "Arrow, Hausdorff, and Ambiguities in the Choice of Preferred States in\n  Complex Systems",
        "authors": [
            "T. Erber",
            "M. J. Frank"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Arrow's `impossibility' theorem asserts that there are no satisfactory\nmethods of aggregating individual preferences into collective preferences in\nmany complex situations. This result has ramifications in economics, politics,\ni.e., the theory of voting, and the structure of tournaments. By identifying\nthe objects of choice with mathematical sets, and preferences with Hausdorff\nmeasures of the distances between sets, it is possible to extend Arrow's\narguments from a sociological to a mathematical setting. One consequence is\nthat notions of reversibility can be expressed in terms of the relative\nconfigurations of patterns of sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.07771v1"
    },
    {
        "title": "A New Approach to Fair Distribution of Welfare",
        "authors": [
            "Moshe Babaioff",
            "Uriel Feige"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We consider transferable-utility profit-sharing games that arise from\nsettings in which agents need to jointly choose one of several alternatives,\nand may use transfers to redistribute the welfare generated by the chosen\nalternative. One such setting is the Shared-Rental problem, in which students\njointly rent an apartment and need to decide which bedroom to allocate to each\nstudent, depending on the student's preferences. Many solution concepts have\nbeen proposed for such settings, ranging from mechanisms without transfers,\nsuch as Random Priority and the Eating mechanism, to mechanisms with transfers,\nsuch as envy free solutions, the Shapley value, and the Kalai-Smorodinsky\nbargaining solution. We seek a solution concept that satisfies three natural\nproperties, concerning efficiency, fairness and decomposition. We observe that\nevery solution concept known (to us) fails to satisfy at least one of the three\nproperties. We present a new solution concept, designed so as to satisfy the\nthree properties. A certain submodularity condition (which holds in interesting\nspecial cases such as the Shared-Rental setting) implies both existence and\nuniqueness of our solution concept.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11346v1"
    },
    {
        "title": "Macroscopic approximation methods for the analysis of adaptive networked\n  agent-based models: The example of a two-sector investment model",
        "authors": [
            "Jakob J. Kolb",
            "Finn Müller-Hansen",
            "Jürgen Kurths",
            "Jobst Heitzig"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  In this paper, we propose a statistical aggregation method for agent-based\nmodels with heterogeneous agents that interact both locally on a complex\nadaptive network and globally on a market. The method combines three approaches\nfrom statistical physics: (a) moment closure, (b) pair approximation of\nadaptive network processes, and (c) thermodynamic limit of the resulting\nstochastic process. As an example of use, we develop a stochastic agent-based\nmodel with heterogeneous households that invest in either a fossil-fuel or\nrenewables-based sector while allocating labor on a competitive market. Using\nthe adaptive voter model, the model describes agents as social learners that\ninteract on a dynamic network. We apply the approximation methods to derive a\nset of ordinary differential equations that approximate the macro-dynamics of\nthe model. A comparison of the reduced analytical model with numerical\nsimulations shows that the approximation fits well for a wide range of\nparameters. The proposed method makes it possible to use analytical tools to\nbetter understand the dynamical properties of models with heterogeneous agents\non adaptive networks. We showcase this with a bifurcation analysis that\nidentifies parameter ranges with multi-stabilities. The method can thus help to\nexplain emergent phenomena from network interactions and make them\nmathematically traceable.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.13758v2"
    },
    {
        "title": "Cheating with (Recursive) Models",
        "authors": [
            "Kfir Eliaz",
            "Ran Spiegler",
            "Yair Weiss"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  To what extent can agents with misspecified subjective models predict false\ncorrelations? We study an \"analyst\" who utilizes models that take the form of a\nrecursive system of linear regression equations. The analyst fits each equation\nto minimize the sum of squared errors against an arbitrarily large sample. We\ncharacterize the maximal pairwise correlation that the analyst can predict\ngiven a generic objective covariance matrix, subject to the constraint that the\nestimated model does not distort the mean and variance of individual variables.\nWe show that as the number of variables in the model grows, the false pairwise\ncorrelation can become arbitrarily close to one, regardless of the true\ncorrelation.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01251v1"
    },
    {
        "title": "Weak Monotone Comparative Statics",
        "authors": [
            "Yeon-Koo Che",
            "Jinwoo Kim",
            "Fuhito Kojima"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We develop a theory of monotone comparative statics based on weak set order\n-- in short, weak monotone comparative statics -- and identify the enabling\nconditions in the context of individual choices, Pareto optimal choices% for a\ncoalition of agents, Nash equilibria of games, and matching theory. Compared\nwith the existing theory based on strong set order, the conditions for weak\nmonotone comparative statics are weaker, sometimes considerably, in terms of\nthe structure of the choice environments and underlying preferences of agents.\nWe apply the theory to establish existence and monotone comparative statics of\nNash equilibria in games with strategic complementarities and of stable\nmany-to-one matchings in two-sided matching problems, allowing for general\npreferences that accommodate indifferences and incompleteness.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.06442v4"
    },
    {
        "title": "Innovation and Strategic Network Formation",
        "authors": [
            "Krishna Dasaratha"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a model of innovation with a large number of firms that create new\ntechnologies by combining several discrete ideas. These ideas are created via\nprivate investment and spread between firms. Firms face a choice between\nsecrecy, which protects existing intellectual property, and openness, which\nfacilitates learning from others. Their decisions determine interaction rates\nbetween firms, and these interaction rates enter our model as link\nprobabilities in a learning network. Higher interaction rates impose both\npositive and negative externalities, as there is more learning but also more\ncompetition. We show that the equilibrium learning network is at a critical\nthreshold between sparse and dense networks. At equilibrium, the positive\nexternality from interaction dominates: the innovation rate and welfare would\nbe dramatically higher if the network were denser. So there are large returns\nto increasing interaction rates above the critical threshold. Nevertheless,\nseveral natural types of interventions fail to move the equilibrium away from\ncriticality. One effective policy solution is to introduce informational\nintermediaries, such as public innovators who do not have incentives to be\nsecretive. These intermediaries can facilitate a high-innovation equilibrium by\ntransmitting ideas from one private firm to another.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.06872v4"
    },
    {
        "title": "Manipulable outcomes within the class of scoring voting rules",
        "authors": [
            "Mostapha Diss",
            "Boris Tsvelikhovskiy"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Coalitional manipulation in voting is considered to be any scenario in which\na group of voters decide to misrepresent their vote in order to secure an\noutcome they all prefer to the first outcome of the election when they vote\nhonestly. The present paper is devoted to study coalitional manipulability\nwithin the class of scoring voting rules. For any such rule and any number of\nalternatives, we introduce a new approach allowing to characterize all the\noutcomes that can be manipulable by a coalition of voters. This gives us the\npossibility to find the probability of manipulable outcomes for some\nwell-studied scoring voting rules in case of small number of alternatives and\nlarge electorates under a well-known assumption on individual preference\nprofiles.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.09173v3"
    },
    {
        "title": "Dynamic Optimal Choice When Rewards are Unbounded Below",
        "authors": [
            "Qingyin Ma",
            "John Stachurski"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We propose a new approach to solving dynamic decision problems with rewards\nthat are unbounded below. The approach involves transforming the Bellman\nequation in order to convert an unbounded problem into a bounded one. The major\nadvantage is that, when the conditions stated below are satisfied, the\ntransformed problem can be solved by iterating with a contraction mapping.\nWhile the method is not universal, we show by example that many common decision\nproblems do satisfy our conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.13025v1"
    },
    {
        "title": "One Step at a Time: Does Gradualism Build Coordination?",
        "authors": [
            "Maoliang Ye",
            "Jie Zheng",
            "Plamen Nikolov",
            "Sam Asher"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This study investigates a potential mechanism to promote coordination. With\ntheoretical guidance using a belief-based learning model, we conduct a\nmulti-period, binary-choice, and weakest-link laboratory coordination\nexperiment to study the effect of gradualism - increasing the required levels\n(stakes) of contributions slowly over time rather than requiring a high level\nof contribution immediately - on group coordination performance. We randomly\nassign subjects to three treatments: starting and continuing at a high stake,\nstarting at a low stake but jumping to a high stake after a few periods, and\nstarting at a low stake while gradually increasing the stakes over time (the\nGradualism treatment). We find that relative to the other two treatments,\ngroups coordinate most successfully at high stakes in the Gradualism treatment.\nWe also find evidence that supports the belief-based learning model. These\nfindings point to a simple mechanism for promoting successful voluntary\ncoordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.01386v1"
    },
    {
        "title": "Subjective Complexity Under Uncertainty",
        "authors": [
            "Quitzé Valenzuela-Stookey"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Complexity of the problem of choosing among uncertain acts is a salient\nfeature of many of the environments in which departures from expected utility\ntheory are observed. I propose and axiomatize a model of choice under\nuncertainty in which the size of the partition with respect to which an act is\nmeasurable arises endogenously as a measure of subjective complexity. I derive\na representation of incomplete Simple Bounds preferences in which acts that are\ncomplex from the perspective of the decision maker are bracketed by simple acts\nto which they are related by statewise dominance. The key axioms are motivated\nby a model of learning from limited data. I then consider choice behavior\ncharacterized by a \"cautious completion\" of Simple Bounds preferences, and\ndiscuss the relationship between this model and models of ambiguity aversion. I\ndevelop general comparative statics results, and explore applications to\nportfolio choice, contracting, and insurance choice.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.01852v3"
    },
    {
        "title": "An Optimal Distributionally Robust Auction",
        "authors": [
            "Alex Suzdaltsev"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  An indivisible object may be sold to one of $n$ agents who know their\nvaluations of the object. The seller would like to use a revenue-maximizing\nmechanism but her knowledge of the valuations' distribution is scarce: she\nknows only the means (which may be different) and an upper bound for\nvaluations. Valuations may be correlated.\n  Using a constructive approach based on duality, we prove that a mechanism\nthat maximizes the worst-case expected revenue among all deterministic\ndominant-strategy incentive compatible, ex post individually rational\nmechanisms is such that the object should be awarded to the agent with the\nhighest linear score provided it is nonnegative. Linear scores are\nbidder-specific linear functions of bids. The set of optimal mechanisms\nincludes other mechanisms but all those have to be close to the optimal linear\nscore auction in a certain sense. When means are high, all optimal mechanisms\nshare the linearity property. Second-price auction without a reserve is an\noptimal mechanism when the number of symmetric bidders is sufficiently high.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.05192v2"
    },
    {
        "title": "Data and Incentives",
        "authors": [
            "Annie Liang",
            "Erik Madsen"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  \"Big data\" gives markets access to previously unmeasured characteristics of\nindividual agents. Policymakers must decide whether and how to regulate the use\nof this data. We study how new data affects incentives for agents to exert\neffort in settings such as the labor market, where an agent's quality is\ninitially unknown but is forecast from an observable outcome. We show that\nmeasurement of a new covariate has a systematic effect on the average effort\nexerted by agents, with the direction of the effect determined by whether the\ncovariate is informative about long-run quality or about a shock to short-run\noutcomes. For a class of covariates satisfying a statistical property we call\nstrong homoskedasticity, this effect is uniform across agents. More generally,\nnew measurements can impact agents unequally, and we show that these\ndistributional effects have a first-order impact on social welfare.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06543v2"
    },
    {
        "title": "Corona Games: Masks, Social Distancing and Mechanism Design",
        "authors": [
            "Balazs Pejo",
            "Gergely Biczok"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Pandemic response is a complex affair. Most governments employ a set of\nquasi-standard measures to fight COVID-19 including wearing masks, social\ndistancing, virus testing and contact tracing. We argue that some non-trivial\nfactors behind the varying effectiveness of these measures are selfish\ndecision-making and the differing national implementations of the response\nmechanism. In this paper, through simple games, we show the effect of\nindividual incentives on the decisions made with respect to wearing masks and\nsocial distancing, and how these may result in a sub-optimal outcome. We also\ndemonstrate the responsibility of national authorities in designing these games\nproperly regarding the chosen policies and their influence on the preferred\noutcome. We promote a mechanism design approach: it is in the best interest of\nevery government to carefully balance social good and response costs when\nimplementing their respective pandemic response mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06674v4"
    },
    {
        "title": "The Equilibrium Existence Duality: Equilibrium with Indivisibilities &\n  Income Effects",
        "authors": [
            "Elizabeth Baldwin",
            "Omer Edhan",
            "Ravi Jagadeesan",
            "Paul Klemperer",
            "Alexander Teytelboym"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We show that, with indivisible goods, the existence of competitive\nequilibrium fundamentally depends on agents' substitution effects, not their\nincome effects. Our Equilibrium Existence Duality allows us to transport\nresults on the existence of competitive equilibrium from settings with\ntransferable utility to settings with income effects. One consequence is that\nnet substitutability---which is a strictly weaker condition than gross\nsubstitutability---is sufficient for the existence of competitive equilibrium.\nWe also extend the ``demand types'' classification of valuations to settings\nwith income effects and give necessary and sufficient conditions for a pattern\nof substitution effects to guarantee the existence of competitive equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.16939v1"
    },
    {
        "title": "Some game theoretic marketing attribution models",
        "authors": [
            "Elisenda Molina",
            "Juan Tejada",
            "Tom Weiss"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In this paper, we propose and analyse two game theoretical models useful to\ndesign marketing channels attribution mechanisms based on cooperative TU games\nand bankruptcy problems, respectively. First, we analyse the Sum Game, a\ncoalitional game introduced by Morales (2016). We extend the ideas introduced\nin Zhao et al. (2018) and Cano-Berlanga et al. (2017) to the case in which the\norder and the repetition of channels on the paths to conversion are taken into\naccount. In all studied cases, the Shapley value is proposed as the attribution\nmechanism. Second, a bankruptcy problem approach is proposed, and a similar\nanalysis is developed relying on the Constrained Equal Loss (CEL) and\nProportional (PROP) rules as attribution mechanisms. In particular, it is\nrelevant to note that the class of attribution bankruptcy problems is a proper\nsubclass of bankruptcy problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.00812v1"
    },
    {
        "title": "Mathematical Game Theory: A New Approach",
        "authors": [
            "Ulrich Faigle"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  These lecture notes attempt a mathematical treatment of game theory akin to\nmathematical physics. A game instance is defined as a sequence of states of an\nunderlying system. This viewpoint unifies classical mathematical models for\n2-person and, in particular, combinatorial and zero-sum games as well as models\nfor investing and betting. n-person games are studied with emphasis on notions\nof utilities, potentials and equilibria, which allows to subsume cooperative\ngames as special cases. The represenation of a game theoretic system in a\nHilbert space furthermore establishes a link to the mathematical model of\nquantum mechancis and general interaction systems.\n  The notes sketch an outline of the theory. Details are available as a\ntextbook elsewhere.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.01850v3"
    },
    {
        "title": "Human Social Cycling Spectrum",
        "authors": [
            "Wang Zhijian",
            "Yao Qingmei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper investigates the reality and accuracy of evolutionary game\ndynamics theory in human game behavior experiments. In classical game theory,\nthe central concept is Nash equilibrium, which reality and accuracy has been\nwell known since the firstly illustration by the O'Neill game experiment in\n1987. In game dynamics theory, the central approach is dynamics equations,\nhowever, its reality and accuracy is rare known, especially in high dimensional\ngames. By develop a new approach, namely the eigencycle approach, with the\neigenvectors from the game dynamics equations, we discover the fine structure\nof the cycles in the same experiments. We show that, the eigencycle approach\ncan increase the accuracy by an order of magnitude in the human dynamic\nhehavior data. As the eigenvector is fundamental in dynamical systems theory\nwhich has applications in natural, social, and virtual worlds, the power of the\neigencycles is expectedly. Inspired by the high dimensional eigencycles, we\nsuggest that, the mathematical concept, namely 'invariant manifolds', could be\na candidate as the central concept for the game dynamics theory, like the fixed\npoint concept for classical game theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.03315v2"
    },
    {
        "title": "Occupational segregation in a Roy model with composition preferences",
        "authors": [
            "Haoning Chen",
            "Miaomiao Dong",
            "Marc Henry",
            "Ivan Sidorov"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose a model of labor market sector self-selection that combines\ncomparative advantage, as in the Roy model, and sector composition preference.\nTwo groups choose between two sectors based on heterogeneous potential incomes\nand group compositions in each sector. Potential incomes incorporate group\nspecific human capital accumulation and wage discrimination. Composition\npreferences are interpreted as reflecting group specific amenity preferences as\nwell as homophily and aversion to minority status. We show that occupational\nsegregation is amplified by the composition preferences and we highlight a\nresulting tension between redistribution and diversity. The model also exhibits\ntipping from extreme compositions to more balanced ones. Tipping occurs when a\nsmall nudge, associated with affirmative action, pushes the system to a very\ndifferent equilibrium, and when the set of equilibria changes abruptly when a\nparameter governing the relative importance of pecuniary and composition\npreferences crosses a threshold.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.04485v3"
    },
    {
        "title": "Equitable preference relations on infinite utility streams",
        "authors": [
            "Ram S. Dubey",
            "Giorgio Laguzzi"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose generalized versions of strong equity and Pigou-Dalton transfer\nprinciple. We study the existence and the real valued representation of social\nwelfare relations satisfying these two generalized equity principles. Our\nresults characterize the restrictions on one period utility domains for the\nequitable social welfare relation (i) to exist; and (ii) to admit real-valued\nrepresentations.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.06481v2"
    },
    {
        "title": "Decision Making under Uncertainty: A Game of Two Selves",
        "authors": [
            "Jianming Xia"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In this paper we characterize the niveloidal preferences that satisfy the\nWeak Order, Monotonicity, Archimedean, and Weak C-Independence Axioms from the\npoint of view of an intra-personal, leader-follower game. We also show that the\nleader's strategy space can serve as an ambiguity aversion index.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.07509v1"
    },
    {
        "title": "The economics of stop-and-go epidemic control",
        "authors": [
            "Claudius Gros",
            "Daniel Gros"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We analyse 'stop-and-go' containment policies that produce infection cycles\nas periods of tight lockdowns are followed by periods of falling infection\nrates. The subsequent relaxation of containment measures allows cases to\nincrease again until another lockdown is imposed and the cycle repeats. The\npolicies followed by several European countries during the Covid-19 pandemic\nseem to fit this pattern. We show that 'stop-and-go' should lead to lower\nmedical costs than keeping infections at the midpoint between the highs and\nlows produced by 'stop-and-go'. Increasing the upper and reducing the lower\nlimits of a stop-and-go policy by the same amount would lower the average\nmedical load. But increasing the upper and lowering the lower limit while\nkeeping the geometric average constant would have the opposite effect. We also\nshow that with economic costs proportional to containment, any path that brings\ninfections back to the original level (technically a closed cycle) has the same\noverall economic cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.07739v2"
    },
    {
        "title": "Self-Fulfilling Prophecies, Quasi Non-Ergodicity and Wealth Inequality",
        "authors": [
            "Jean-Philippe Bouchaud",
            "Roger Farmer"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We construct a model of an exchange economy in which agents trade assets\ncontingent on an observable signal, the probability of which depends on public\nopinion. The agents in our model are replaced occasionally and each person\nupdates beliefs in response to observed outcomes. We show that the distribution\nof the observed signal is described by a quasi-non-ergodic process and that\npeople continue to disagree with each other forever. These disagreements\ngenerate large wealth inequalities that arise from the multiplicative nature of\nwealth dynamics which make successful bold bets highly profitable.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.09445v3"
    },
    {
        "title": "The Probabilistic Serial and Random Priority Mechanisms with Minimum\n  Quotas",
        "authors": [
            "Marek Bojko"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Consider the problem of assigning indivisible objects to agents with strict\nordinal preferences over objects, where each agent is interested in consuming\nat most one object, and objects have integer minimum and maximum quotas. We\ndefine an assignment to be feasible if it satisfies all quotas and assume such\nan assignment always exists. The Probabilistic Serial (PS) and Random Priority\n(RP) mechanisms are generalised based on the same intuitive idea: Allow agents\nto consume their most preferred available object until the total mass of agents\nyet to be allocated is exactly equal to the remaining amount of unfilled lower\nquotas; in this case, we restrict agents' menus to objects which are yet to\nfill their minimum quotas. We show the mechanisms satisfy the same criteria as\ntheir classical counterparts: PS is ordinally efficient, envy-free and weakly\nstrategy-proof; RP is strategy-proof, weakly envy-free but not ordinally\nefficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.11028v1"
    },
    {
        "title": "Shapley-Scarf Housing Markets: Respecting Improvement, Integer\n  Programming, and Kidney Exchange",
        "authors": [
            "Péter Biró",
            "Flip Klijn",
            "Xenia Klimentova",
            "Ana Viana"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In a housing market of Shapley and Scarf, each agent is endowed with one\nindivisible object and has preferences over all objects. An allocation of the\nobjects is in the (strong) core if there exists no (weakly) blocking coalition.\nIn this paper we show that in the case of strict preferences the unique strong\ncore allocation (or competitive allocation) respects improvement: if an agent's\nobject becomes more attractive for some other agents, then the agent's\nallotment in the unique strong core allocation weakly improves. We obtain a\ngeneral result in case of ties in the preferences and provide new integer\nprogramming formulations for computing (strong) core and competitive\nallocations. Finally, we conduct computer simulations to compare the\ngame-theoretical solutions with maximum size and maximum weight exchanges for\nmarkets that resemble the pools of kidney exchange programmes.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00167v1"
    },
    {
        "title": "The Wisdom of the Crowd and Higher-Order Beliefs",
        "authors": [
            "Yi-Chun Chen",
            "Manuel Mueller-Frank",
            "Mallesh M Pai"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The classic wisdom-of-the-crowd problem asks how a principal can \"aggregate\"\ninformation about the unknown state of the world from agents without\nunderstanding the information structure among them. We propose a new simple\nprocedure called Population-Mean-Based Aggregation to achieve this goal. The\nprocedure only requires eliciting agents' beliefs about the state, and also\neliciting some agents' expectations of the average belief in the population. We\nshow that this procedure fully aggregates information: in an infinite\npopulation, it always infers the true state of the world. The procedure can\naccommodate correlations in agents' information, misspecified beliefs, any\nfinite number of possible states of the world, and only requires very weak\nassumptions on the information structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02666v2"
    },
    {
        "title": "Bounds and Heuristics for Multi-Product Personalized Pricing",
        "authors": [
            "Guillermo Gallego",
            "Gerardo Berbeglia"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present tight bounds and heuristics for personalized, multi-product\npricing problems. Under mild conditions we show that the best price in the\ndirection of a positive vector results in profits that are guaranteed to be at\nleast as large as a fraction of the profits from optimal personalized pricing.\nFor unconstrained problems, the fraction depends on the factor and on optimal\nprice vectors for the different customer types. For constrained problems the\nfactor depends on the factor and a ratio of the constraints. Using a factor\nvector with equal components results in uniform pricing and has exceedingly\nmild sufficient conditions for the bound to hold. A robust factor is presented\nthat achieves the best possible performance guarantee. As an application, our\nmodel yields a tight lower-bound on the performance of linear pricing relative\nto optimal personalized non-linear pricing, and suggests effective non-linear\nprice heuristics relative to personalized solutions. Additionally, our model\nprovides guarantees for simple strategies such as bundle-size pricing and\ncomponent-pricing with respect to optimal personalized mixed bundle pricing.\nHeuristics to cluster customer types are also developed with the goal of\nimproving performance by allowing each cluster to price along its own factor.\nNumerical results are presented for a variety of demand models that illustrate\nthe tradeoffs between using the economic factor and the robust factor for each\ncluster, as well as the tradeoffs between using a clustering heuristic with a\nworst case performance of two and a machine learning clustering algorithm. In\nour experiments economically motivated factors coupled with machine learning\nclustering heuristics performed best.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03038v2"
    },
    {
        "title": "Interview Hoarding",
        "authors": [
            "Vikram Manjunath",
            "Thayer Morrill"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Many centralized matching markets are preceded by interviews between\nparticipants. We study the impact on the final match of an increase in the\nnumber of interviews for one side of the market. Our motivation is the match\nbetween residents and hospitals where, due to the COVID-19 pandemic, interviews\nfor the 2020-21 season of the National Residency Matching Program were switched\nto a virtual format. This drastically reduced the cost to applicants of\naccepting interview invitations. However, the reduction in cost was not\nsymmetric since applicants, not programs, previously bore most of the costs of\nin-person interviews. We show that if doctors can accept more interviews, but\nthe hospitals do not increase the number of interviews they offer, then no\npreviously matched doctor is better off and many are potentially harmed. This\nadverse consequence is the result of what we call interview hoarding. We prove\nthis analytically and characterize optimal mitigation strategies for special\ncases. We use simulations to extend these insights to more general settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06440v4"
    },
    {
        "title": "Expected utility theory on mixture spaces without the completeness axiom",
        "authors": [
            "David McCarthy",
            "Kalle Mikkola",
            "Teruji Thomas"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A mixture preorder is a preorder on a mixture space (such as a convex set)\nthat is compatible with the mixing operation. In decision theoretic terms, it\nsatisfies the central expected utility axiom of strong independence. We\nconsider when a mixture preorder has a multi-representation that consists of\nreal-valued, mixture-preserving functions. If it does, it must satisfy the\nmixture continuity axiom of Herstein and Milnor (1953). Mixture continuity is\nsufficient for a mixture-preserving multi-representation when the dimension of\nthe mixture space is countable, but not when it is uncountable. Our strongest\npositive result is that mixture continuity is sufficient in conjunction with a\nnovel axiom we call countable domination, which constrains the order complexity\nof the mixture preorder in terms of its Archimedean structure. We also consider\nwhat happens when the mixture space is given its natural weak topology.\nContinuity (having closed upper and lower sets) and closedness (having a closed\ngraph) are stronger than mixture continuity. We show that continuity is\nnecessary but not sufficient for a mixture preorder to have a\nmixture-preserving multi-representation. Closedness is also necessary; we leave\nit as an open question whether it is sufficient. We end with results concerning\nthe existence of mixture-preserving multi-representations that consist entirely\nof strictly increasing functions, and a uniqueness result.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06898v1"
    },
    {
        "title": "Price Discrimination in the Presence of Customer Loyalty and Differing\n  Firm Costs",
        "authors": [
            "Theja Tulabandhula",
            "Aris Ouksel",
            "Son Nguyen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study how loyalty behavior of customers and differing costs to produce\nundifferentiated products by firms can influence market outcomes. In prior\nworks that study such markets, firm costs have generally been assumed\nnegligible or equal, and loyalty is modeled as an additive bias in customer\nvaluations. We extend these previous treatments by explicitly considering cost\nasymmetry and richer customer loyalty behavior in a game-theoretic model. Thus,\nin the setting where firms incur different non-negligible product costs, and\ncustomers have firm-specific loyalty levels, we comprehensively characterize\nthe effects of loyalty and product cost difference on market outcomes such as\nprices, market shares, and profits. Our analysis and numerical simulations\nprovide new insights into how firms can price, how they can survive competition\neven with higher product costs, and how they can control these costs and/or\nincrease customer loyalty to change their market position.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.09620v2"
    },
    {
        "title": "Incentives for accelerating the production of Covid-19 vaccines in the\n  presence of adjustment costs",
        "authors": [
            "Claudius Gros",
            "Daniel Gros"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Delays in the availability of vaccines are costly as the pandemic continues.\nHowever, in the presence of adjustment costs firms have an incentive to\nincrease production capacity only gradually. The existing contracts specify\nonly a fixed quantity to be supplied over a certain period and thus provide no\nincentive for an accelerated buildup in capacity. A high price does not change\nthis. The optimal contract would specify a decreasing price schedule over time\nwhich can replicate the social optimum.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.09807v1"
    },
    {
        "title": "Pricing decisions under manufacturer's component open-supply strategy",
        "authors": [
            "Peiya Zhu",
            "Xiaofei Qian",
            "Xinbao Liu",
            "Shaojun Lu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Faced with huge market potential and increasing competition in emerging\nindustries, product manufacturers with key technologies tend to consider\nwhether to implement a component open supply strategy. This study focuses on a\npricing game induced by the component open supply strategy between a vertically\nintegrated manufacturer (who produces key components and end products) and an\nexterior product manufacturer (who produces end products using purchased key\ncomponents) with different customer perceived value and different cost\nstructure. This study first establishes a three stage pricing game model and\nproposes demand functions by incorporating relative customer perceived value.\nBased on the demand functions, we obtain feasible regions of the exterior\nmanufacturer's sourcing decision and the optimal price decision in each region.\nThen the effects of relative customer perceived value, cost structure, and\nmarket structure on price decisions and optimal profits of the vertically\nintegrated manufacturer are demonstrated. Finally, as for the optimal component\nsupply strategy, we present a generalized closed supply Pareto zone and\nestablish supply strategy Pareto zones under several specific configurations.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.10280v2"
    },
    {
        "title": "Selling Data to an Agent with Endogenous Information",
        "authors": [
            "Yingkai Li"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider a model of a data broker selling information to a single agent to\nmaximize his revenue. The agent has a private valuation of the additional\ninformation, and upon receiving the signal from the data broker, the agent can\nconduct her own experiment to refine her posterior belief on the states with\nadditional costs. To maximize expected revenue, only offering full information\nin general is suboptimal, and the optimal mechanism may contain a continuum of\nmenu options with partial information to prevent the agent from having\nincentives to acquire additional information from other sources. However, our\nmain result shows that the additional benefit from price discrimination is\nlimited, i.e., posting a deterministic price for revealing full information\nobtains at least half of the optimal revenue for arbitrary prior and cost\nfunctions.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.05788v4"
    },
    {
        "title": "A Natural Adaptive Process for Collective Decision-Making",
        "authors": [
            "Florian Brandl",
            "Felix Brandt"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Consider an urn filled with balls, each labeled with one of several possible\ncollective decisions. Now, let a random voter draw two balls from the urn and\npick her more preferred as the collective decision. Relabel the losing ball\nwith the collective decision, put both balls back into the urn, and repeat.\nOnce in a while, relabel a randomly drawn ball with a random collective\ndecision. We prove that the empirical distribution of collective decisions\nproduced by this process approximates a maximal lottery, a celebrated\nprobabilistic voting rule proposed by Peter C. Fishburn (Rev. Econ. Stud.,\n51(4), 1984). In fact, the probability that the collective decision in round\n$n$ is made according to a maximal lottery increases exponentially in $n$. The\nproposed procedure is more flexible than traditional voting rules and bears\nstrong similarities to natural processes studied in biology, physics, and\nchemistry as well as algorithms proposed in machine learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.14351v6"
    },
    {
        "title": "Complex dynamics of knowledgeable monopoly models with gradient\n  mechanisms",
        "authors": [
            "Xiaoliang Li",
            "Jiacheng Fu",
            "Wei Niu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we explore the dynamics of two monopoly models with\nknowledgeable players. The first model was initially introduced by Naimzada and\nRicchiuti, while the second one is simplified from a famous monopoly introduced\nby Puu. We employ several tools based on symbolic computations to analyze the\nlocal stability and bifurcations of the two models. To the best of our\nknowledge, the complete stability conditions of the second model are obtained\nfor the first time. We also investigate periodic solutions as well as their\nstability. Most importantly, we discover that the topological structure of the\nparameter space of the second model is much more complex than that of the first\none. Specifically, in the first model, the parameter region for the stability\nof any periodic orbit with a fixed order constitutes a connected set. In the\nsecond model, however, the stability regions for the 3-cycle, 4-cycle, and\n5-cycle orbits are disconnected sets formed by many disjoint portions.\nFurthermore, we find that the basins of the two stable equilibria in the second\nmodel are disconnected and also have complicated topological structures. In\naddition, the existence of chaos in the sense of Li-Yorke is rigorously proved\nby finding snapback repellers and 3-cycle orbits in the two models,\nrespectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01497v1"
    },
    {
        "title": "Extending the Characterization of Maximum Nash Welfare",
        "authors": [
            "Sheung Man Yuen",
            "Warut Suksompong"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In the allocation of indivisible goods, the maximum Nash welfare rule has\nrecently been characterized as the only rule within the class of additive\nwelfarist rules that satisfies envy-freeness up to one good. We extend this\ncharacterization to the class of all welfarist rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.03798v2"
    },
    {
        "title": "Binary Mechanisms under Privacy-Preserving Noise",
        "authors": [
            "Farzad Pourbabaee",
            "Federico Echenique"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study mechanism design for public-good provision under a noisy\nprivacy-preserving transformation of individual agents' reported preferences.\nThe setting is a standard binary model with transfers and quasi-linear utility.\nAgents report their preferences for the public good, which are randomly\n``flipped,'' so that any individual report may be explained away as the outcome\nof noise. We study the tradeoffs between preserving the public decisions made\nin the presence of noise (noise sensitivity), pursuing efficiency, and\nmitigating the effect of noise on revenue.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.06967v3"
    },
    {
        "title": "Auctions without commitment in the auto-bidding world",
        "authors": [
            "Aranyak Mehta",
            "Andres Perlroth"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Advertisers in online ad auctions are increasingly using auto-bidding\nmechanisms to bid into auctions instead of directly bidding their value\nmanually. One prominent auto-bidding format is the target cost-per-acquisition\n(tCPA) which maximizes the volume of conversions subject to a\nreturn-of-investment constraint. From an auction theoretic perspective however,\nthis trend seems to go against foundational results that postulate that for\nprofit-maximizing bidders, it is optimal to use a classic bidding system like\nmarginal CPA (mCPA) bidding rather than using strategies like tCPA.\n  In this paper we rationalize the adoption of such seemingly sub-optimal\nbidding within the canonical quasi-linear framework. The crux of the argument\nlies in the notion of commitment. We consider a multi-stage game where first\nthe auctioneer declares the auction rules; then bidders select either the tCPA\nor mCPA bidding format and then, if the auctioneer lacks commitment, it can\nrevisit the rules of the auction (e.g., may readjust reserve prices depending\non the observed bids). Our main result is that so long as a bidder believes\nthat the auctioneer lacks commitment to follow the rule of the declared auction\nthen the bidder will make a higher profit by choosing the tCPA format over the\nmCPA format.\n  We then explore the commitment consequences for the auctioneer. In a\nsimplified version of the model where there is only one bidder, we show that\nthe tCPA subgame admits a credible equilibrium while the mCPA format does not.\nThat is, when the bidder chooses the tCPA format the auctioneer can credibly\nimplement the auction rules announced at the beginning of the game. We also\nshow that, under some mild conditions, the auctioneer's revenue is larger when\nthe bidder uses the tCPA format rather than mCPA. We further quantify the value\nfor the auctioneer to be able to commit to the declared auction rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.07312v2"
    },
    {
        "title": "The Hazards and Benefits of Condescension in Social Learning",
        "authors": [
            "Itai Arieli",
            "Yakov Babichenko",
            "Stephan Müller",
            "Farzad Pourbabaee",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In a misspecified social learning setting, agents are condescending if they\nperceive their peers as having private information that is of lower quality\nthan it is in reality. Applying this to a standard sequential model, we show\nthat outcomes improve when agents are mildly condescending. In contrast, too\nmuch condescension leads to worse outcomes, as does anti-condescension.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.11237v3"
    },
    {
        "title": "Equilibria and their stability in an asymmetric duopoly model of Kopel",
        "authors": [
            "Xiaoliang Li",
            "Kongyan Chen"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, we investigate the equilibria and their stability in an\nasymmetric duopoly model of Kopel by using several tools based on symbolic\ncomputations. We explore the possible positions of the equilibria in Kopel's\nmodel. We discuss the possibility of the existence of multiple positive\nequilibria and establish a necessary and sufficient condition for a given\nnumber of equilibria to exist. Furthermore, if the two duopolists adopt the\nbest response reactions or homogeneous adaptive expectations, we establish\nrigorous conditions for the existence of distinct numbers of positive\nequilibria for the first time.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.12628v1"
    },
    {
        "title": "Censorship Resistance in On-Chain Auctions",
        "authors": [
            "Elijah Fox",
            "Mallesh Pai",
            "Max Resnick"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Modern blockchains guarantee that submitted transactions will be included\neventually; a property formally known as liveness. But financial activity\nrequires transactions to be included in a timely manner. Unfortunately,\nclassical liveness is not strong enough to guarantee this, particularly in the\npresence of a motivated adversary who benefits from censoring transactions. We\ndefine censorship resistance as the amount it would cost the adversary to\ncensor a transaction for a fixed interval of time as a function of the\nassociated tip. This definition has two advantages, first it captures the fact\nthat transactions with a higher miner tip can be more costly to censor, and\ntherefore are more likely to swiftly make their way onto the chain. Second, it\napplies to a finite time window, so it can be used to assess whether a\nblockchain is capable of hosting financial activity that relies on timely\ninclusion.\n  We apply this definition in the context of auctions. Auctions are a building\nblock for many financial applications, and censoring competing bids offers an\neasy-to-model motivation for our adversary. Traditional proof-of-stake\nblockchains have poor enough censorship resistance that it is difficult to\nretain the integrity of an auction when bids can only be submitted in a single\nblock. As the number of bidders $n$ in a single block auction increases, the\nprobability that the winner is not the adversary, and the economic efficiency\nof the auction, both decrease faster than $1/n$. Running the auction over\nmultiple blocks, each with a different proposer, alleviates the problem only if\nthe number of blocks grows faster than the number of bidders. We argue that\nblockchains with more than one concurrent proposer have can have strong\ncensorship resistance. We achieve this by setting up a prisoner's dilemma among\nthe proposers using conditional tips.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13321v2"
    },
    {
        "title": "Incentive Compatibility in the Auto-bidding World",
        "authors": [
            "Yeganeh Alimohammadi",
            "Aranyak Mehta",
            "Andres Perlroth"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Auto-bidding has recently become a popular feature in ad auctions. This\nfeature enables advertisers to simply provide high-level constraints and goals\nto an automated agent, which optimizes their auction bids on their behalf. In\nthis paper, we examine the effect of different auctions on the incentives of\nadvertisers to report their constraints to the auto-bidder intermediaries. More\nprecisely, we study whether canonical auctions such as first price auction\n(FPA) and second price auction (SPA) are auto-bidding incentive compatible\n(AIC): whether an advertiser can gain by misreporting their constraints to the\nautobidder.\n  We consider value-maximizing advertisers in two important settings: when they\nhave a budget constraint and when they have a target cost-per-acquisition\nconstraint. The main result of our work is that for both settings, FPA and SPA\nare not AIC. This contrasts with FPA being AIC when auto-bidders are\nconstrained to bid using a (sub-optimal) uniform bidding policy. We further\nextend our main result and show that any (possibly randomized) auction that is\ntruthful (in the classic profit-maximizing sense), scalar invariant and\nsymmetric is not AIC. Finally, to complement our findings, we provide\nsufficient market conditions for FPA and SPA to become AIC for two advertisers.\nThese conditions require advertisers' valuations to be well-aligned. This\nsuggests that when the competition is intense for all queries, advertisers have\nless incentive to misreport their constraints.\n  From a methodological standpoint, we develop a novel continuous model of\nqueries. This model provides tractability to study equilibrium with\nauto-bidders, which contrasts with the standard discrete query model, which is\nknown to be hard. Through the analysis of this model, we uncover a surprising\nresult: in auto-bidding with two advertisers, FPA and SPA are auction\nequivalent.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13414v2"
    },
    {
        "title": "Commitment Against Front Running Attacks",
        "authors": [
            "Andrea Canidio",
            "Vincent Danos"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We provide a game-theoretic analysis of the problem of front-running attacks.\nWe use it to distinguish attacks from legitimate competition among honest users\nfor having their transactions included earlier in the block. We also use it to\nintroduce an intuitive notion of the severity of front-running attacks. We then\nstudy a simple commit-reveal protocol and discuss its properties. This protocol\nhas costs because it requires two messages and imposes a delay. However, we\nshow that it prevents the most severe front-running attacks while preserving\nlegitimate competition between users, guaranteeing that the earliest\ntransaction in a block belongs to the honest user who values it the most. When\nthe protocol does not fully eliminate attacks, it nonetheless benefits honest\nusers because it reduces competition among attackers (and overall expenditure\nby attackers).\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13785v3"
    },
    {
        "title": "Auctions with Tokens: Monetary Policy as a Mechanism Design Choice",
        "authors": [
            "Andrea Canidio"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I study mechanism design with blockchain-based tokens, that is, tokens that\ncan be used within a mechanism but can also be saved and traded outside of the\nmechanism. I do so by considering a repeated, private-value auction, in which\nthe auctioneer accepts payments in a blockchain-based token he creates and\ninitially owns. I show that the present-discounted value of the expected\nrevenues is the same as in a standard auction with dollars, but these revenues\naccrue earlier and are less variable. The optimal monetary policy involves the\nburning of tokens used in the auction, a common feature of many\nblockchain-based auctions. I then introduce non-contractible effort and the\npossibility of misappropriating revenues. I compare the auction with tokens to\nan auction with dollars in which the auctioneer can also issue financial\nsecurities. An auction with tokens is preferred when there are sufficiently\nsevere contracting frictions, while the opposite is true when contracting\nfrictions are low.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13794v2"
    },
    {
        "title": "Shapley-like values without symmetry",
        "authors": [
            "Jacob North Clark",
            "Stephen Montgomery-Smith"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Following the work of Lloyd Shapley on the Shapley value, and tangentially\nthe work of Guillermo Owen, we offer an alternative non-probabilistic\nformulation of part of the work of Robert J. Weber in his 1978 paper\n\"Probabilistic values for games.\" Specifically, we focus upon efficient but not\nsymmetric allocations of value for cooperative games. We retain standard\nefficiency and linearity, and offer an alternative condition, \"reasonableness,\"\nto replace the other usual axioms. In the pursuit of the result, we discover\nproperties of the linear maps that describe the allocations. This culminates in\na special class of games for which any other map that is \"reasonable,\nefficient\" can be written as a convex combination of members of this special\nclass of allocations, via an application of the Krein-Milman theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07747v2"
    },
    {
        "title": "Equitable voting rules",
        "authors": [
            "Laurent Bartholdi",
            "Wade Hann-Caruthers",
            "Maya Josyula",
            "Omer Tamuz",
            "Leeat Yariv"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  May's Theorem (1952), a celebrated result in social choice, provides the\nfoundation for majority rule. May's crucial assumption of symmetry, often\nthought of as a procedural equity requirement, is violated by many choice\nprocedures that grant voters identical roles. We show that a weakening of May's\nsymmetry assumption allows for a far richer set of rules that still treat\nvoters equally. We show that such rules can have minimal winning coalitions\ncomprising a vanishing fraction of the population, but not less than the square\nroot of the population size. Methodologically, we introduce techniques from\ngroup theory and illustrate their usefulness for the analysis of social choice\nquestions.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01227v4"
    },
    {
        "title": "Incentivising Participation in Liquid Democracy with Breadth-First\n  Delegation",
        "authors": [
            "Grammateia Kotsialou",
            "Luke Riley"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Liquid democracy allows members of an electorate to either directly vote over\nalternatives, or delegate their voting rights to someone they trust. Most of\nthe liquid democracy literature and implementations allow each voter to\nnominate only one delegate per election. However, if that delegate abstains,\nthe voting rights assigned to her are left unused. To minimise the number of\nunused delegations, it has been suggested that each voter should declare a\npersonal ranking over voters she trusts. In this paper, we show that even if\npersonal rankings over voters are declared, the standard delegation method of\nliquid democracy remains problematic. More specifically, we show that when\npersonal rankings over voters are declared, it could be undesirable to receive\ndelegated voting rights, which is contrary to what liquid democracy\nfundamentally relies on. To solve this issue, we propose a new method to\ndelegate voting rights in an election, called breadth-first delegation.\nAdditionally, the proposed method prioritises assigning voting rights to\nindividuals closely connected to the voters who delegate.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.03710v2"
    },
    {
        "title": "M Equilibrium: A theory of beliefs and choices in games",
        "authors": [
            "Jacob K. Goeree",
            "Philippos Louis"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We introduce a set-valued solution concept, M equilibrium, to capture\nempirical regularities from over half a century of game-theory experiments. We\nshow M equilibrium serves as a meta theory for various models that hitherto\nwere considered unrelated. M equilibrium is empirically robust and, despite\nbeing set-valued, falsifiable. We report results from a series of experiments\ncomparing M equilibrium to leading behavioral-game-theory models and\ndemonstrate its virtues in predicting observed choices and stated beliefs. Data\nfrom experimental games with a unique pure-strategy Nash equilibrium and\nmultiple M equilibria exhibit coordination problems that could not be\nanticipated through the lens of existing models.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05138v2"
    },
    {
        "title": "An Inattention Model for Traveler Behavior with e-Coupons",
        "authors": [
            "Han Qiu"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  In this study, we consider traveler coupon redemption behavior from the\nperspective of an urban mobility service. Assuming traveler behavior is in\naccordance with the principle of utility maximization, we first formulate a\nbaseline dynamical model for traveler's expected future trip sequence under the\nframework of Markov decision processes and from which we derive approximations\nof the optimal coupon redemption policy. However, we find that this baseline\nmodel cannot explain perfectly observed coupon redemption behavior of traveler\nfor a car-sharing service. To resolve this deviation from utility-maximizing\nbehavior, we suggest a hypothesis that travelers may not be aware of all\ncoupons available to them. Based on this hypothesis, we formulate an\ninattention model on unawareness, which is complementary to the existing models\nof inattention, and incorporate it into the baseline model. Estimation results\nshow that the proposed model better explains the coupon redemption dataset than\nthe baseline model. We also conduct a simulation experiment to quantify the\nnegative impact of unawareness on coupons' promotional effects. These results\ncan be used by mobility service operators to design effective coupon\ndistribution schemes in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.05070v1"
    },
    {
        "title": "Katugampola Generalized Conformal Derivative Approach to Inada\n  Conditions and Solow-Swan Economic Growth Model",
        "authors": [
            "G. Fernández-Anaya",
            "L. A. Quezada-Téllez",
            "B. Nuñez-Zavala",
            "D. Brun-Battistini"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This article shows a new focus of mathematic analysis for the Solow-Swan\neconomic growth model, using the generalized conformal derivative Katugampola\n(KGCD). For this, under the same Solow-Swan model assumptions, the Inada\nconditions are extended, which, for the new model shown here, depending on the\norder of the KGCD. This order plays an important role in the speed of\nconvergence of the closed solutions obtained with this derivative for capital\n(k) and for per-capita production (y) in the cases without migration and with\nnegative migration. Our approach to the model with the KGCD adds a new\nparameter to the Solow-Swan model, the order of the KGCD and not a new state\nvariable. In addition, we propose several possible economic interpretations for\nthat parameter.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.00130v1"
    },
    {
        "title": "Unforeseen Evidence",
        "authors": [
            "Evan Piermont"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  I propose a normative updating rule, extended Bayesianism, for the\nincorporation of probabilistic information arising from the process of becoming\nmore aware. Extended Bayesianism generalizes standard Bayesian updating to\nallow the posterior to reside on richer probability space than the prior. I\nthen provide an observable criterion on prior and posterior beliefs such that\nthey were consistent with extended Bayesianism.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.07019v3"
    },
    {
        "title": "Arrow's Theorem Through a Fixpoint Argument",
        "authors": [
            "Frank M. V. Feys",
            "Helle Hvid Hansen"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We present a proof of Arrow's theorem from social choice theory that uses a\nfixpoint argument. Specifically, we use Banach's result on the existence of a\nfixpoint of a contractive map defined on a complete metric space. Conceptually,\nour approach shows that dictatorships can be seen as fixpoints of a certain\nprocess.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10381v1"
    },
    {
        "title": "Empirical strategy-proofness",
        "authors": [
            "Rodrigo A. Velez",
            "Alexander L. Brown"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the plausibility of sub-optimal Nash equilibria of the direct\nrevelation mechanism associated with a strategy-proof social choice function.\nBy using the recently introduced empirical equilibrium analysis (Velez and\nBrown, 2019, arXiv:1804.07986) we determine that this behavior is plausible\nonly when the social choice function violates a non-bossiness condition and\ninformation is not interior. Analysis of the accumulated experimental and\nempirical evidence on these games supports our findings.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12408v5"
    },
    {
        "title": "Robust Monopoly Regulation",
        "authors": [
            "Yingni Guo",
            "Eran Shmaya"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the regulation of a monopolistic firm using a robust-design\napproach. We solve for the policy that minimizes the regulator's worst-case\nregret, where the regret is the difference between his complete-information\npayoff minus his realized payoff. When the regulator's payoff is consumers'\nsurplus, it is optimal to impose a price cap. The optimal cap balances the\nbenefit from more surplus for consumers and the loss from underproduction. When\nhis payoff is consumers' surplus plus the firm's profit, he offers a piece-rate\nsubsidy in order to mitigate underproduction, but caps the total subsidy so as\nnot to incentivize severe overproduction.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.04260v1"
    },
    {
        "title": "Dynamically Aggregating Diverse Information",
        "authors": [
            "Annie Liang",
            "Xiaosheng Mu",
            "Vasilis Syrgkanis"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  An agent has access to multiple information sources, each of which provides\ninformation about a different attribute of an unknown state. Information is\nacquired continuously -- where the agent chooses both which sources to sample\nfrom, and also how to allocate attention across them -- until an endogenously\nchosen time, at which point a decision is taken. We provide an exact\ncharacterization of the optimal information acquisition strategy under weak\nconditions on the agent's prior belief about the different attributes. We then\napply this characterization to derive new results regarding: (1) endogenous\ninformation acquisition for binary choice, (2) strategic information provision\nby biased news sources, and (3) the dynamic consequences of attention\nmanipulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.07015v3"
    },
    {
        "title": "Games of Incomplete Information Played By Statisticians",
        "authors": [
            "Annie Liang"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Players are statistical learners who learn about payoffs from data. They may\ninterpret the same data differently, but have common knowledge of a class of\nlearning procedures. I propose a metric for the analyst's \"confidence\" in a\nstrategic prediction, based on the probability that the prediction is\nconsistent with the realized data. The main results characterize the analyst's\nconfidence in a given prediction as the quantity of data grows large, and\nprovide bounds for small datasets. The approach generates new predictions, e.g.\nthat speculative trade is more likely given high-dimensional data, and that\ncoordination is less likely given noisy data.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.07018v2"
    },
    {
        "title": "Overcoming Free-Riding in Bandit Games",
        "authors": [
            "Johannes Hörner",
            "Nicolas Klein",
            "Sven Rady"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper considers a class of experimentation games with L\\'{e}vy bandits\nencompassing those of Bolton and Harris (1999) and Keller, Rady and Cripps\n(2005). Its main result is that efficient (perfect Bayesian) equilibria exist\nwhenever players' payoffs have a diffusion component. Hence, the trade-offs\nemphasized in the literature do not rely on the intrinsic nature of bandit\nmodels but on the commonly adopted solution concept (MPE). This is not an\nartifact of continuous time: we prove that efficient equilibria arise as limits\nof equilibria in the discrete-time game. Furthermore, it suffices to relax the\nsolution concept to strongly symmetric equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.08953v5"
    },
    {
        "title": "Almost Quasi-linear Utilities in Disguise: Positive-representation An\n  Extension of Roberts' Theorem",
        "authors": [
            "Ilan Nehama"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This work deals with the implementation of social choice rules using dominant\nstrategies for unrestricted preferences. The seminal Gibbard-Satterthwaite\ntheorem shows that only few unappealing social choice rules can be implemented\nunless we assume some restrictions on the preferences or allow monetary\ntransfers. When monetary transfers are allowed and quasi-linear utilities\nw.r.t. money are assumed, Vickrey-Clarke-Groves (VCG) mechanisms were shown to\nimplement any affine-maximizer, and by the work of Roberts, only\naffine-maximizers can be implemented whenever the type sets of the agents are\nrich enough.\n  In this work, we generalize these results and define a new class of\npreferences: Preferences which are positive-represented by a quasi-linear\nutility. That is, agents whose preference on a subspace of the outcomes can be\nmodeled using a quasi-linear utility. We show that the characterization of VCG\nmechanisms as the incentive-compatible mechanisms extends naturally to this\ndomain. Our result follows from a simple reduction to the characterization of\nVCG mechanisms. Hence, we see our result more as a fuller more correct version\nof the VCG characterization.\n  This work also highlights a common misconception in the community attributing\nthe VCG result to the usage of transferable utility. Our result shows that the\nincentive-compatibility of the VCG mechanisms does not rely on money being a\ncommon denominator, but rather on the ability of the designer to fine the\nagents on a continuous (maybe agent-specific) scale.\n  We think these two insights, considering the utility as a representation and\nnot as the preference itself (which is common in the economic community) and\nconsidering utilities which represent the preference only for the relevant\ndomain, would turn out to fruitful in other domains as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.12131v1"
    },
    {
        "title": "A Note on Solving Discretely-Constrained Nash-Cournot Games via\n  Complementarity",
        "authors": [
            "Dimitri J. Papageorgiou",
            "Francisco Trespalacios",
            "Stuart Harwood"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Discretely-constrained Nash-Cournot games have attracted attention as they\narise in various competitive energy production settings in which players must\nmake one or more discrete decisions. Gabriel et al. [\"Solving\ndiscretely-constrained Nash-Cournot games with an application to power\nmarkets.\" Networks and Spatial Economics 13(3), 2013] claim that the set of\nequilibria to a discretely-constrained Nash-Cournot game coincides with the set\nof solutions to a corresponding discretely-constrained mixed complementarity\nproblem. We show that this claim is false.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.01536v1"
    },
    {
        "title": "Is the Juice Worth the Squeeze? Machine Learning (ML) In and For\n  Agent-Based Modelling (ABM)",
        "authors": [
            "Johannes Dahlke",
            "Kristina Bogner",
            "Matthias Mueller",
            "Thomas Berger",
            "Andreas Pyka",
            "Bernd Ebersberger"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In recent years, many scholars praised the seemingly endless possibilities of\nusing machine learning (ML) techniques in and for agent-based simulation models\n(ABM). To get a more comprehensive understanding of these possibilities, we\nconduct a systematic literature review (SLR) and classify the literature on the\napplication of ML in and for ABM according to a theoretically derived\nclassification scheme. We do so to investigate how exactly machine learning has\nbeen utilized in and for agent-based models so far and to critically discuss\nthe combination of these two promising methods. We find that, indeed, there is\na broad range of possible applications of ML to support and complement ABMs in\nmany different ways, already applied in many different disciplines. We see\nthat, so far, ML is mainly used in ABM for two broad cases: First, the\nmodelling of adaptive agents equipped with experience learning and, second, the\nanalysis of outcomes produced by a given ABM. While these are the most\nfrequent, there also exist a variety of many more interesting applications.\nThis being the case, researchers should dive deeper into the analysis of when\nand how which kinds of ML techniques can support ABM, e.g. by conducting a more\nin-depth analysis and comparison of different use cases. Nonetheless, as the\napplication of ML in and for ABM comes at certain costs, researchers should not\nuse ML for ABMs just for the sake of doing it.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.11985v1"
    },
    {
        "title": "Greater search cost reduces prices",
        "authors": [
            "Sander Heinsalu"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The optimal price of each firm falls in the search cost of consumers, in the\nlimit to the monopoly price, despite the exit of lower-value consumers in\nresponse to costlier search. Exit means that fewer inframarginal consumers\nremain. The decrease in marginal buyers is smaller, because part of demand is\ncomposed of customers coming from rival firms. These buyers can be held up and\nare not marginal. Higher search cost reduces the fraction of incoming switchers\namong buyers, which decreases the hold-up motive, thus the price.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01238v1"
    },
    {
        "title": "On Vickrey's Income Averaging",
        "authors": [
            "Stefan Steinerberger",
            "Aleh Tsyvinski"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a small set of axioms for income averaging -- recursivity,\ncontinuity, and the boundary condition for the present. These properties yield\na unique averaging function that is the density of the reflected Brownian\nmotion with a drift started at the current income and moving over the past\nincomes. When averaging is done over the short past, the weighting function is\nasymptotically converging to a Gaussian. When averaging is done over the long\nhorizon, the weighing function converges to the exponential distribution. For\nall intermediate averaging scales, we derive an explicit solution that\ninterpolates between the two.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.06289v1"
    },
    {
        "title": "The Moral Burden of Ambiguity Aversion",
        "authors": [
            "Brian Jabarian"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In their article, \"Egalitarianism under Severe Uncertainty\", Philosophy and\nPublic Affairs, 46:3, 2018, Thomas Rowe and Alex Voorhoeve develop an original\nmoral decision theory for cases under uncertainty, called \"pluralist\negalitarianism under uncertainty\". In this paper, I firstly sketch their views\nand arguments. I then elaborate on their moral decision theory by discussing\nhow it applies to choice scenarios in health ethics. Finally, I suggest a new\ntwo-stage Ellsberg thought experiment challenging the core of the principle of\ntheir theory. In such an experiment pluralist egalitarianism seems to suggest\nthe wrong, morally and rationally speaking, course of action -- no matter\nwhether I consider my thought experiment in a simultaneous or a sequential\nsetting.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.08892v2"
    },
    {
        "title": "On the integration of Shapley-Scarf housing markets",
        "authors": [
            "Rajnish Kunar",
            "Kriti Manocha",
            "Josue Ortega"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the welfare consequences of merging Shapley--Scarf markets. Market\nintegration can lead to large welfare losses and make the vast majority of\nagents worse-off, but is on average welfare-enhancing and makes all agents\nbetter off ex-ante. The number of agents harmed by integration is a minority\nwhen all markets are small or agents' preferences are highly correlated.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09075v3"
    },
    {
        "title": "A Social Network Analysis of Occupational Segregation",
        "authors": [
            "I. Sebastian Buhai",
            "Marco J. van der Leij"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose an equilibrium interaction model of occupational segregation and\nlabor market inequality between two social groups, generated exclusively\nthrough the documented tendency to refer informal job seekers of identical\n\"social color\". The expected social color homophily in job referrals\nstrategically induces distinct career choices for individuals from different\nsocial groups, which further translates into stable partial occupational\nsegregation equilibria with sustained wage and employment inequality -- in line\nwith observed patterns of racial or gender labor market disparities. Supporting\nthe qualitative analysis with a calibration and simulation exercise, we\nfurthermore show that both first and second best utilitarian social optima\nentail segregation, any integration policy requiring explicit distributional\nconcerns. Our framework highlights that the mere social interaction through\nhomophilous contact networks can be a pivotal channel for the propagation and\npersistence of gender and racial labor market gaps, complementary to long\nstudied mechanisms such as taste or statistical discrimination.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09293v4"
    },
    {
        "title": "Black-Box Strategies and Equilibrium for Games with Cumulative Prospect\n  Theoretic Players",
        "authors": [
            "Soham R. Phade",
            "Venkat Anantharam"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The betweenness property of preference relations states that a probability\nmixture of two lotteries should lie between them in preference. It is a\nweakened form of the independence property and hence satisfied in expected\nutility theory (EUT). Experimental violations of betweenness are\nwell-documented and several preference theories, notably cumulative prospect\ntheory (CPT), do not satisfy betweenness. We prove that CPT preferences satisfy\nbetweenness if and only if they conform with EUT preferences. In game theory,\nlack of betweenness in the players' preference relations makes it essential to\ndistinguish between the two interpretations of a mixed action by a player -\nconscious randomizations by the player and the uncertainty in the beliefs of\nthe opponents. We elaborate on this distinction and study its implication for\nthe definition of Nash equilibrium. This results in four different notions of\nequilibrium, with pure and mixed action Nash equilibrium being two of them. We\ndub the other two pure and mixed black-box strategy Nash equilibrium\nrespectively. We resolve the issue of existence of such equilibria and examine\nhow these different notions of equilibrium compare with each other.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09592v1"
    },
    {
        "title": "Multinomial logit processes and preference discovery: inside and outside\n  the black box",
        "authors": [
            "Simone Cerreia-Vioglio",
            "Fabio Maccheroni",
            "Massimo Marinacci",
            "Aldo Rustichini"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We provide two characterizations, one axiomatic and the other\nneuro-computational, of the dependence of choice probabilities on deadlines,\nwithin the widely used softmax representation \\[ p_{t}\\left( a,A\\right)\n=\\dfrac{e^{\\frac{u\\left( a\\right) }{\\lambda \\left( t\\right) }+\\alpha \\left(\na\\right) }}{\\sum_{b\\in A}e^{\\frac{u\\left( b\\right) }{\\lambda \\left( t\\right)\n}+\\alpha \\left( b\\right) }}% \\] where $p_{t}\\left( a,A\\right) $ is the\nprobability that alternative $a$ is selected from the set $A$ of feasible\nalternatives if $t$ is the time available to decide, $\\lambda$ is a time\ndependent noise parameter measuring the unit cost of information, $u$ is a time\nindependent utility function, and $\\alpha$ is an alternative-specific bias that\ndetermines the initial choice probabilities reflecting prior information and\nmemory anchoring.\n  Our axiomatic analysis provides a behavioral foundation of softmax (also\nknown as Multinomial Logit Model when $\\alpha$ is constant). Our\nneuro-computational derivation provides a biologically inspired algorithm that\nmay explain the emergence of softmax in choice behavior. Jointly, the two\napproaches provide a thorough understanding of soft-maximization in terms of\ninternal causes (neurophysiological mechanisms) and external effects (testable\nimplications).\n",
        "pdf_link": "http://arxiv.org/pdf/2004.13376v3"
    },
    {
        "title": "Spruce budworm and oil price: a biophysical analogy",
        "authors": [
            "Luciano Celi",
            "Claudio Della Volpe",
            "Luca Pardi",
            "Stefano Siboni"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The behavior of complex systems is one of the most intriguing phenomena\ninvestigated by recent science; natural and artificial systems offer a wide\nopportunity for this kind of analysis. The energy conversion is both a process\nbased on important physical laws and one of the most important economic\nsectors; the interaction between these two aspects of energy production\nsuggests the possibility to apply some of the approaches of the dynamic\nsystems' analysis. In particular, a phase plot, which is one of the methods to\ndetect a correlation between quantities in a complex system, provides a good\nway to establish qualitative analogies between the ecological systems and the\neconomic ones and may shed light on the processes governing the evolution of\nthe system. The aim of this paper is to highlight the analogies between some\npeculiar characteristics of the oil production vs. price and show in which way\nsuch characteristics are similar to some behavioral mechanisms found in Nature.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.14898v1"
    },
    {
        "title": "Robust communication on networks",
        "authors": [
            "Marie Laclau",
            "Ludovic Renou",
            "Xavier Venel"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider sender-receiver games, where the sender and the receiver are two\ndistinct nodes in a communication network. Communication between the sender and\nthe receiver is thus indirect. We ask when it is possible to robustly implement\nthe equilibrium outcomes of the direct communication game as equilibrium\noutcomes of indirect communication games on the network. Robust implementation\nrequires that: (i) the implementation is independent of the preferences of the\nintermediaries and (ii) the implementation is guaranteed at all histories\nconsistent with unilateral deviations by the intermediaries. Robust\nimplementation of direct communication is possible if and only if either the\nsender and receiver are directly connected or there exist two disjoint paths\nbetween the sender and the receiver.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.00457v2"
    },
    {
        "title": "Binary Relations in Mathematical Economics: On the Continuity,\n  Additivity and Monotonicity Postulates in Eilenberg, Villegas and DeGroot",
        "authors": [
            "M. Ali Khan",
            "Metin Uyanik"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This chapter examines how positivity and order play out in two important\nquestions in mathematical economics, and in so doing, subjects the postulates\nof continuity, additivity and monotonicity to closer scrutiny. Two sets of\nresults are offered: the first departs from Eilenberg's (1941) necessary and\nsufficient conditions on the topology under which an anti-symmetric, complete,\ntransitive and continuous binary relation exists on a topologically connected\nspace; and the second, from DeGroot's (1970) result concerning an additivity\npostulate that ensures a complete binary relation on a {\\sigma}-algebra to be\ntransitive. These results are framed in the registers of order, topology,\nalgebra and measure-theory; and also beyond mathematics in economics: the\nexploitation of Villegas' notion of monotonic continuity by Arrow-Chichilnisky\nin the context of Savage's theorem in decision theory, and the extension of\nDiamond's impossibility result in social choice theory by Basu-Mitra. As such,\nthis chapter has a synthetic and expository motivation, and can be read as a\nplea for inter-disciplinary conversations, connections and collaboration.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.01952v1"
    },
    {
        "title": "Stability in Repeated Matching Markets",
        "authors": [
            "Ce Liu"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper develops a framework for repeated matching markets. The model\ndeparts from the Gale-Shapley matching model by having a fixed set of\nlong-lived hospitals match with a new generation of short-lived residents in\nevery period. I show that there are two kinds of hospitals in this repeated\nenvironment: some hospitals can be motivated dynamically to voluntarily reduce\ntheir hiring capacity, potentially making more residents available to rural\nhospitals; the others, however, are untouchable even with repeated interaction\nand must obtain the same match as they do in a static matching. In large\nmatching markets with correlated preferences, at most a vanishingly small\nfraction of the hospitals are untouchable. The vast majority of hospitals can\nbe motivated using dynamic incentives.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.03794v2"
    },
    {
        "title": "Polarization in Networks: Identification-alienation Framework",
        "authors": [
            "Kenan Huremovic",
            "Ali Ozkes"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We introduce a model of polarization in networks as a unifying framework for\nthe measurement of polarization that covers a wide range of applications. We\nconsider a sufficiently general setup for this purpose: node- and\nedge-weighted, undirected, and connected networks. We generalize the axiomatic\ncharacterization of Esteban and Ray (1994) and show that only a particular\ninstance within this class can be used justifiably to measure polarization in\nnetworks.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.07061v5"
    },
    {
        "title": "Degrees of individual and groupwise backward and forward responsibility\n  in extensive-form games with ambiguity, and their application to social\n  choice problems",
        "authors": [
            "Jobst Heitzig",
            "Sarah Hiller"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Many real-world situations of ethical relevance, in particular those of\nlarge-scale social choice such as mitigating climate change, involve not only\nmany agents whose decisions interact in complicated ways, but also various\nforms of uncertainty, including quantifiable risk and unquantifiable ambiguity.\nIn such problems, an assessment of individual and groupwise moral\nresponsibility for ethically undesired outcomes or their responsibility to\navoid such is challenging and prone to the risk of under- or overdetermination\nof responsibility. In contrast to existing approaches based on strict causation\nor certain deontic logics that focus on a binary classification of\n`responsible' vs `not responsible', we here present several different\nquantitative responsibility metrics that assess responsibility degrees in units\nof probability. For this, we use a framework based on an adapted version of\nextensive-form game trees and an axiomatic approach that specifies a number of\npotentially desirable properties of such metrics, and then test the developed\ncandidate metrics by their application to a number of paradigmatic social\nchoice situations. We find that while most properties one might desire of such\nresponsibility metrics can be fulfilled by some variant, an optimal metric that\nclearly outperforms others has yet to be found.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.07352v1"
    },
    {
        "title": "Prophylaxis of Epidemic Spreading with Transient Dynamics",
        "authors": [
            "Geraldine Bouveret",
            "Antoine Mandel"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We investigate the containment of epidemic spreading in networks from a\nnormative point of view. We consider a susceptible/infected model in which\nagents can invest in order to reduce the contagiousness of network links. In\nthis setting, we study the relationships between social efficiency, individual\nbehaviours and network structure. First, we exhibit an upper bound on the Price\nof Anarchy and prove that the level of inefficiency can scale up to linearly\nwith the number of agents. Second, we prove that policies of uniform reduction\nof interactions satisfy some optimality conditions in a vast range of networks.\nIn setting where no central authority can enforce such stringent policies, we\nconsider as a type of second-best policy the shift from a local to a global\ngame by allowing agents to subsidise investments in contagiousness reduction in\nthe global rather than in the local network. We then characterise the scope for\nPareto improvement opened by such policies through a notion of Price of\nAutarky, measuring the ratio between social welfare at a global and a local\nequilibrium. Overall, our results show that individual behaviours can be\nextremely inefficient in the face of epidemic propagation but that policy can\ntake advantage of the network structure to design efficient containment\npolicies.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.07580v1"
    },
    {
        "title": "A Maximum Theorem for Incomplete Preferences",
        "authors": [
            "Leandro Gorno",
            "Alessandro Rivello"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We extend Berge's Maximum Theorem to allow for incomplete preferences. We\nfirst provide a simple version of the Maximum Theorem for convex feasible sets\nand a fixed preference. Then, we show that if, in addition to the traditional\ncontinuity assumptions, a new continuity property for the domains of\ncomparability holds, the limits of maximal elements along a sequence of\ndecision problems are maximal elements in the limit problem. While this new\ncontinuity property for the domains of comparability is not generally necessary\nfor optimality to be preserved by limits, we provide conditions under which it\nis necessary and sufficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09781v6"
    },
    {
        "title": "Dominant Resource Fairness with Meta-Types",
        "authors": [
            "Steven Yin",
            "Shatian Wang",
            "Lingyi Zhang",
            "Christian Kroer"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Inspired by the recent COVID-19 pandemic, we study a generalization of the\nmulti-resource allocation problem with heterogeneous demands and Leontief\nutilities. Unlike existing settings, we allow each agent to specify\nrequirements to only accept allocations from a subset of the total supply for\neach resource. These requirements can take form in location constraints (e.g. A\nhospital can only accept volunteers who live nearby due to commute\nlimitations). This can also model a type of substitution effect where some\nagents need 1 unit of resource A \\emph{or} B, both belonging to the same\nmeta-type. But some agents specifically want A, and others specifically want B.\nWe propose a new mechanism called Dominant Resource Fairness with Meta Types\nwhich determines the allocations by solving a small number of linear programs.\nThe proposed method satisfies Pareto optimality, envy-freeness,\nstrategy-proofness, and a notion of sharing incentive for our setting. To the\nbest of our knowledge, we are the first to study this problem formulation,\nwhich improved upon existing work by capturing more constraints that often\narise in real life situations. Finally, we show numerically that our method\nscales better to large problems than alternative approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11961v3"
    },
    {
        "title": "Myopic equilibria, the spanning property, and subgame bundles",
        "authors": [
            "Robert Simon",
            "Stanislaw Spiez",
            "Henryk Torunczyk"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  For a set-valued function $F$ on a compact subset $W$ of a manifold, spanning\nis a topological property that implies that $F(x) \\ne 0$ for interior points\n$x$ of $W$. A myopic equilibrium applies when for each action there is a payoff\nwhose functional value is not necessarily affine in the strategy space. We show\nthat if the payoffs satisfy the spanning property, then there exist a myopic\nequilibrium (though not necessarily a Nash equilibrium). Furthermore, given a\nparametrized collection of games and the spanning property to the structure of\npayoffs in that collection, the resulting myopic equilibria and their payoffs\nhave the spanning property with respect to that parametrization. This is a far\nreaching extension of the Kohberg-Mertens Structure Theorem. There are at least\nfour useful applications, when payoffs are exogenous to a finite game tree (for\nexample a finitely repeated game followed by an infinitely repeated game), when\none wants to understand a game strategically entirely with behaviour\nstrategies, when one wants to extends the subgame concept to subsets of a game\ntree that are known in common, and for evolutionary game theory. The proofs\ninvolve new topological results asserting that spanning is preserved by\nrelevant operations on set-valued functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.12876v1"
    },
    {
        "title": "Learning what they think vs. learning what they do: The\n  micro-foundations of vicarious learning",
        "authors": [
            "Sanghyun Park",
            "Phanish Puranam"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Vicarious learning is a vital component of organizational learning. We\ntheorize and model two fundamental processes underlying vicarious learning:\nobservation of actions (learning what they do) vs. belief sharing (learning\nwhat they think). The analysis of our model points to three key insights.\nFirst, vicarious learning through either process is beneficial even when no\nagent in a system of vicarious learners begins with a knowledge advantage.\nSecond, vicarious learning through belief sharing is not universally better\nthan mutual observation of actions and outcomes. Specifically, enabling mutual\nobservability of actions and outcomes is superior to sharing of beliefs when\nthe task environment features few alternatives with large differences in their\nvalue and there are no time pressures. Third, symmetry in vicarious learning in\nfact adversely affects belief sharing but improves observational learning. All\nthree results are shown to be the consequence of how vicarious learning affects\nself-confirming biased beliefs.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.15264v2"
    },
    {
        "title": "Lookahead and Hybrid Sample Allocation Procedures for Multiple Attribute\n  Selection Decisions",
        "authors": [
            "Jeffrey W. Herrmann",
            "Kunal Mehta"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Attributes provide critical information about the alternatives that a\ndecision-maker is considering. When their magnitudes are uncertain, the\ndecision-maker may be unsure about which alternative is truly the best, so\nmeasuring the attributes may help the decision-maker make a better decision.\nThis paper considers settings in which each measurement yields one sample of\none attribute for one alternative. When given a fixed number of samples to\ncollect, the decision-maker must determine which samples to obtain, make the\nmeasurements, update prior beliefs about the attribute magnitudes, and then\nselect an alternative. This paper presents the sample allocation problem for\nmultiple attribute selection decisions and proposes two sequential, lookahead\nprocedures for the case in which discrete distributions are used to model the\nuncertain attribute magnitudes. The two procedures are similar but reflect\ndifferent quality measures (and loss functions), which motivate different\ndecision rules: (1) select the alternative with the greatest expected utility\nand (2) select the alternative that is most likely to be the truly best\nalternative. We conducted a simulation study to evaluate the performance of the\nsequential procedures and hybrid procedures that first allocate some samples\nusing a uniform allocation procedure and then use the sequential, lookahead\nprocedure. The results indicate that the hybrid procedures are effective;\nallocating many (but not all) of the initial samples with the uniform\nallocation procedure not only reduces overall computational effort but also\nselects alternatives that have lower average opportunity cost and are more\noften truly best.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.16119v1"
    },
    {
        "title": "Debunking Rumors in Networks",
        "authors": [
            "Luca P. Merlino",
            "Paolo Pin",
            "Nicole Tabasso"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the diffusion of a true and a false message (the rumor) in a social\nnetwork. Upon hearing a message, individuals may believe it, disbelieve it, or\ndebunk it through costly verification. Whenever the truth survives in steady\nstate, so does the rumor. Communication intensity in itself is irrelevant for\nrelative rumor prevalence, and the effect of homophily depends on the exact\nverification process and equilibrium verification rates. Our model highlights\nthat successful policies in the fight against rumors increase individuals'\nincentives to verify.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.01018v3"
    },
    {
        "title": "How to Sell Hard Information",
        "authors": [
            "S. Nageeb Ali",
            "Nima Haghpanah",
            "Xiao Lin",
            "Ron Siegel"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The seller of an asset has the option to buy hard information about the value\nof the asset from an intermediary. The seller can then disclose the acquired\ninformation before selling the asset in a competitive market. We study how the\nintermediary designs and sells hard information to robustly maximize her\nrevenue across all equilibria. Even though the intermediary could use an\naccurate test that reveals the asset's value, we show that robust revenue\nmaximization leads to a noisy test with a continuum of possible scores that are\ndistributed exponentially. In addition, the intermediary always charges the\nseller for disclosing the test score to the market, but not necessarily for\nrunning the test. This enables the intermediary to robustly appropriate a\nsignificant share of the surplus resulting from the asset sale even though the\ninformation generated by the test provides no social value.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08037v1"
    },
    {
        "title": "Are randomness of behavior and information flow important to opinion\n  forming in organization?",
        "authors": [
            "Agnieszka Kowalska-Styczeń",
            "Krzysztof Malarz"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We examine how the randomness of behavior and the flow of information between\nagents affect the formation of opinions. Our main research involves the process\nof opinion evolution, opinion clusters formation and studying the probability\nof sustaining opinion. The results show that opinion formation (clustering of\nopinion) is influenced by both flow of information between agents (interactions\noutside the closest neighbors) and randomness in adopting opinions.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.15736v1"
    },
    {
        "title": "When \"Better\" is better than \"Best\"",
        "authors": [
            "Ben Amiet",
            "Andrea Collevecchio",
            "Kais Hamza"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider two-player normal form games where each player has the same\nfinite strategy set.\n  The payoffs of each player are assumed to be i.i.d. random variables with a\ncontinuous distribution.\n  We show that, with high probability, the better-response dynamics converge to\npure Nash equilibrium whenever there is one, whereas best-response dynamics\nfails to converge, as it is trapped.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.00239v1"
    },
    {
        "title": "On social networks that support learning",
        "authors": [
            "Itai Arieli",
            "Fedor Sandomirskiy",
            "Rann Smorodinsky"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  It is well understood that the structure of a social network is critical to\nwhether or not agents can aggregate information correctly. In this paper, we\nstudy social networks that support information aggregation when rational agents\nact sequentially and irrevocably. Whether or not information is aggregated\ndepends, inter alia, on the order in which agents decide. Thus, to decouple the\norder and the topology, our model studies a random arrival order.\n  Unlike the case of a fixed arrival order, in our model, the decision of an\nagent is unlikely to be affected by those who are far from him in the network.\nThis observation allows us to identify a local learning requirement, a natural\ncondition on the agent's neighborhood that guarantees that this agent makes the\ncorrect decision (with high probability) no matter how well other agents\nperform. Roughly speaking, the agent should belong to a multitude of mutually\nexclusive social circles.\n  We illustrate the power of the local learning requirement by constructing a\nfamily of social networks that guarantee information aggregation despite that\nno agent is a social hub (in other words, there are no opinion leaders).\nAlthough the common wisdom of the social learning literature suggests that\ninformation aggregation is very fragile, another application of the local\nlearning requirement demonstrates the existence of networks where learning\nprevails even if a substantial fraction of the agents are not involved in the\nlearning process. On a technical level, the networks we construct rely on the\ntheory of expander graphs, i.e., highly connected sparse graphs with a wide\nrange of applications from pure mathematics to error-correcting codes.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.05255v1"
    },
    {
        "title": "COVID-Town: An Integrated Economic-Epidemiological Agent-Based Model",
        "authors": [
            "Patrick Mellacher"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  I develop a novel macroeconomic epidemiological agent-based model to study\nthe impact of the COVID-19 pandemic under varying policy scenarios. Agents\ndiffer with regard to their profession, family status and age and interact with\nother agents at home, work or during leisure activities. The model allows to\nimplement and test actually used or counterfactual policies such as closing\nschools or the leisure industry explicitly in the model in order to explore\ntheir impact on the spread of the virus, and their economic consequences. The\nmodel is calibrated with German statistical data on time use, demography,\nhouseholds, firm demography, employment, company profits and wages. I set up a\nbaseline scenario based on the German containment policies and fit the\nepidemiological parameters of the simulation to the observed German death curve\nand an estimated infection curve of the first COVID-19 wave. My model suggests\nthat by acting one week later, the death toll of the first wave in Germany\nwould have been 180% higher, whereas it would have been 60% lower, if the\npolicies had been enacted a week earlier. I finally discuss two stylized fiscal\npolicy scenarios: procyclical (zero-deficit) and anticyclical fiscal policy. In\nthe zero-deficit scenario a vicious circle emerges, in which the economic\nrecession spreads from the high-interaction leisure industry to the rest of the\neconomy. Even after eliminating the virus and lifting the restrictions, the\neconomic recovery is incomplete. Anticyclical fiscal policy on the other hand\nlimits the economic losses and allows for a V-shaped recovery, but does not\nincrease the number of deaths. These results suggest that an optimal response\nto the pandemic aiming at containment or holding out for a vaccine combines\nearly introduction of containment measures to keep the number of infected low\nwith expansionary fiscal policy to keep output in lower risk sectors high.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.06289v1"
    },
    {
        "title": "Getting to a feasible income equality",
        "authors": [
            "Ji-Won Park",
            "Chae Un Kim"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Income inequality is known to have negative impacts on an economic system,\nthus has been debated for a hundred years past or more. Numerous ideas have\nbeen proposed to quantify income inequality, and the Gini coefficient is a\nprevalent index. However, the concept of perfect equality in the Gini\ncoefficient is rather idealistic and cannot provide realistic guidance on\nwhether government interventions are needed to adjust income inequality. In\nthis paper, we first propose the concept of a more realistic and feasible\nincome equality that maximizes total social welfare. Then we show that an\noptimal income distribution representing the feasible equality could be modeled\nusing the sigmoid welfare function and the Boltzmann income distribution.\nFinally, we carry out an empirical analysis of four countries and demonstrate\nhow optimal income distributions could be evaluated. Our results show that the\nfeasible income equality could be used as a practical guideline for government\npolicies and interventions.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.09119v2"
    },
    {
        "title": "Classification of Priorities Such That Deferred Acceptance is Obviously\n  Strategyproof",
        "authors": [
            "Clayton Thomas"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the strategic simplicity of stable matching mechanisms where one\nside has fixed preferences, termed priorities. Specifically, we ask which\npriorities are such that the strategyproofness of deferred acceptance (DA) can\nbe recognized by agents unable to perform contingency reasoning, that is,\n\\emph{when is DA obviously strategyproof} (Li, 2017)?\n  We answer this question by completely characterizing those priorities which\nmake DA obviously strategyproof (OSP). This solves an open problem of Ashlagi\nand Gonczarowski, 2018. We find that when DA is OSP, priorities are either\nacyclic (Ergin, 2002), a restrictive condition which allows priorities to only\ndiffer on only two agents at a time, or contain an extremely limited cyclic\npattern where all priority lists are identical except for exactly two. We\nconclude that, for stable matching mechanisms, the tension between\nunderstandability (in the sense of OSP) and expressiveness of priorities is\nvery high.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.12367v2"
    },
    {
        "title": "On the Computational Properties of Obviously Strategy-Proof Mechanisms",
        "authors": [
            "Louis Golowich",
            "Shengwu Li"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present a polynomial-time algorithm that determines, given some choice\nrule, whether there exists an obviously strategy-proof mechanism for that\nchoice rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05149v3"
    },
    {
        "title": "No-harm principle, rationality, and Pareto optimality in games",
        "authors": [
            "Shaun Hargreaves Heap",
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Mill's classic argument for liberty requires that people's exercise of\nfreedom should be governed by a no-harm principle (NHP). In this paper, we\ndevelop the concept of a no-harm equilibrium in $n$-person games where players\nmaximize utility subject to the constraint of the NHP. Our main result is in\nthe spirit of the fundamental theorems of welfare economics. We show that for\nevery initial `reference point' in a game the associated no-harm equilibrium is\nPareto efficient and, conversely, every Pareto efficient point can be supported\nas a no-harm equilibrium for some initial reference point.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.10723v4"
    },
    {
        "title": "New Formulations of Ambiguous Volatility with an Application to Optimal\n  Dynamic Contracting",
        "authors": [
            "Peter G. Hansen"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I introduce novel preference formulations which capture aversion to ambiguity\nabout unknown and potentially time-varying volatility. I compare these\npreferences with Gilboa and Schmeidler's maxmin expected utility as well as\nvariational formulations of ambiguity aversion. The impact of ambiguity\naversion is illustrated in a simple static model of portfolio choice, as well\nas a dynamic model of optimal contracting under repeated moral hazard.\nImplications for investor beliefs, optimal design of corporate securities, and\nasset pricing are explored.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.12306v1"
    },
    {
        "title": "Optimal Epidemic Control in Equilibrium with Imperfect Testing and\n  Enforcement",
        "authors": [
            "Thomas Phelan",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We analyze equilibrium behavior and optimal policy within a\nSusceptible-Infected-Recovered epidemic model augmented with potentially\nundiagnosed agents who infer their health status and a social planner with\nimperfect enforcement of social distancing. We define and prove the existence\nof a perfect Bayesian Markov competitive equilibrium and contrast it with the\nefficient allocation subject to the same informational constraints. We identify\ntwo externalities, static (individual actions affect current risk of infection)\nand dynamic (individual actions affect future disease prevalence), and study\nhow they are affected by limitations on testing and enforcement. We prove that\na planner with imperfect enforcement will always wish to curtail activity, but\nthat its incentives to do so vanish as testing becomes perfect. When a vaccine\narrives far into the future, the planner with perfect enforcement may encourage\nactivity before herd immunity. We find that lockdown policies have modest\nwelfare gains, whereas quarantine policies are effective even with imperfect\ntesting.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.04455v2"
    },
    {
        "title": "High Dimensional Decision Making, Upper and Lower Bounds",
        "authors": [
            "Farzad Pourbabaee"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A decision maker's utility depends on her action $a\\in A \\subset\n\\mathbb{R}^d$ and the payoff relevant state of the world $\\theta\\in \\Theta$.\nOne can define the value of acquiring new information as the difference between\nthe maximum expected utility pre- and post information acquisition. In this\npaper, I find asymptotic results on the expected value of information as $d \\to\n\\infty$, by using tools from the theory of (sub)-Guassian processes and generic\nchaining.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00545v1"
    },
    {
        "title": "A Recursive Measure of Voting Power that Satisfies Reasonable Postulates",
        "authors": [
            "Arash Abizadeh",
            "Adrian Vetta"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We design a recursive measure of voting power based on partial as well as\nfull voting efficacy. Classical measures, by contrast, incorporate solely full\nefficacy. We motivate our design by representing voting games using a division\nlattice and via the notion of random walks in stochastic processes, and show\nthe viability of our recursive measure by proving it satisfies a plethora of\npostulates that any reasonable voting measure should satisfy. These include the\niso-invariance, dummy, dominance, donation, minimum-power bloc, and quarrel\npostulates.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03006v2"
    },
    {
        "title": "Wealth rheology",
        "authors": [
            "Zdzislaw Burda",
            "Malgorzata J. Krawczyk",
            "Krzysztof Malarz",
            "Malgorzata Snarska"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study wealth rank correlations in a simple model of macro-economy. To\nquantify rank correlations between wealth rankings at different times, we use\nKendall's $\\tau$ and Spearman's $\\rho$, Goodman--Kruskal's $\\gamma$, and the\nlists' overlap ratio. We show that the dynamics of wealth flow and the speed of\nreshuffling in the ranking list depend on parameters of the model controlling\nthe wealth exchange rate and the wealth growth volatility. As an example of the\nrheology of wealth in real data, we analyze the lists of the richest people in\nPoland, Germany, the USA and the world.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08048v2"
    },
    {
        "title": "Calibrated Click-Through Auctions: An Information Design Approach",
        "authors": [
            "Dirk Bergemann",
            "Paul Duetting",
            "Renato Paes Leme",
            "Song Zuo"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We analyze the optimal information design in a click-through auction with\nfixed valuations per click, but stochastic click-through rates. While the\nauctioneer takes as given the auction rule of the click-through auction, namely\nthe generalized second-price auction, the auctioneer can design the information\nflow regarding the click-through rates among the bidders. A natural requirement\nin this context is to ask for the information structure to be calibrated in the\nlearning sense. With this constraint, the auction needs to rank the ads by a\nproduct of the bid and an unbiased estimator of the click-through rates, and\nthe task of designing an optimal information structure is thus reduced to the\ntask of designing an optimal unbiased estimator.\n  We show that in a symmetric setting with uncertainty about the click-through\nrates, the optimal information structure attains both social efficiency and\nsurplus extraction. The optimal information structure requires private (rather\nthan public) signals to the bidders. It also requires correlated (rather than\nindependent) signals, even when the underlying uncertainty regarding the\nclick-through rates is independent. Beyond symmetric settings, we show that the\noptimal information structure requires partial information disclosure.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.09375v1"
    },
    {
        "title": "Dominance Solvability in Random Games",
        "authors": [
            "Noga Alon",
            "Kirill Rudov",
            "Leeat Yariv"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the effectiveness of iterated elimination of strictly-dominated\nactions in random games. We show that dominance solvability of games is\nvanishingly small as the number of at least one player's actions grows.\nFurthermore, conditional on dominance solvability, the number of iterations\nrequired to converge to Nash equilibrium grows rapidly as action sets grow.\nNonetheless, when games are highly imbalanced, iterated elimination simplifies\nthe game substantially by ruling out a sizable fraction of actions.\nTechnically, we illustrate the usefulness of recent combinatorial methods for\nthe analysis of general games.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10743v1"
    },
    {
        "title": "Games in the Time of COVID-19: Promoting Mechanism Design for Pandemic\n  Response",
        "authors": [
            "Balázs Pejó",
            "Gergely Biczók"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Most governments employ a set of quasi-standard measures to fight COVID-19\nincluding wearing masks, social distancing, virus testing, contact tracing, and\nvaccination. However, combining these measures into an efficient holistic\npandemic response instrument is even more involved than anticipated. We argue\nthat some non-trivial factors behind the varying effectiveness of these\nmeasures are selfish decision making and the differing national implementations\nof the response mechanism. In this paper, through simple games, we show the\neffect of individual incentives on the decisions made with respect to mask\nwearing, social distancing and vaccination, and how these may result in\nsub-optimal outcomes. We also demonstrate the responsibility of national\nauthorities in designing these games properly regarding data transparency, the\nchosen policies and their influence on the preferred outcome. We promote a\nmechanism design approach: it is in the best interest of every government to\ncarefully balance social good and response costs when implementing their\nrespective pandemic response mechanism; moreover, there is no one-size-fits-all\nsolution when designing an effective solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.12329v2"
    },
    {
        "title": "Graphical Economies with Resale",
        "authors": [
            "Gabriel P. Andrade",
            "Rafael Frongillo",
            "Elliot Gorokhovsky",
            "Sharadha Srinivasan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Kakade, Kearns, and Ortiz (KKO) introduce a graph-theoretic generalization of\nthe classic Arrow--Debreu (AD) exchange economy. Despite its appeal as a\nnetworked version of AD, we argue that the KKO model is too local, in the sense\nthat goods cannot travel more than one hop through the network. We introduce an\nalternative model in which agents may purchase goods on credit in order to\nresell them. In contrast to KKO, our model allows for long-range trade, and\nyields equilibria in more settings than KKO, including sparse endowments. Our\nmodel smoothly interpolates between the KKO and AD equilibrium concepts: we\nrecover KKO when the resale capacity is zero, and recover AD when it is\nsufficiently large. We give general equilibrium existence results, and an\nauction-based algorithm to compute approximate equilibria when agent utilities\nsatisfy the weak gross-substitutes property.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.14397v1"
    },
    {
        "title": "Hypothetical Expected Utility",
        "authors": [
            "Evan Piermont"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper provides a model to analyze and identify a decision maker's (DM's)\nhypothetical reasoning. Using this model, I show that a DM's propensity to\nengage in hypothetical thinking is captured exactly by her ability to recognize\nimplications (i.e., to identify that one hypothesis implies another) and that\nthis later relation is encoded by a DM's observable behavior. Thus, this\ncharacterization both provides a concrete definition of (flawed) hypothetical\nreasoning and, importantly, yields a methodology to identify these judgments\nfrom standard economic data.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.15979v2"
    },
    {
        "title": "A Study of UK Household Wealth through Empirical Analysis and a\n  Non-linear Kesten Process",
        "authors": [
            "Samuel Forbes",
            "Stefan Grosskinsky"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the wealth distribution of UK households through a detailed analysis\nof data from wealth surveys and rich lists, and propose a non-linear Kesten\nprocess to model the dynamics of household wealth. The main features of our\nmodel are that we focus on wealth growth and disregard exchange, and that the\nrate of return on wealth is increasing with wealth. The linear case with\nwealth-independent return rate has been well studied, leading to a log-normal\nwealth distribution in the long time limit which is essentially independent of\ninitial conditions. We find through theoretical analysis and simulations that\nthe non-linearity in our model leads to more realistic power-law tails, and can\nexplain an apparent two-tailed structure in the empirical wealth distribution\nof the UK and other countries. Other realistic features of our model include an\nincrease in inequality over time, and a stronger dependence on initial\nconditions compared to linear models.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.02169v1"
    },
    {
        "title": "Representing choice functions by a total hyper-order",
        "authors": [
            "Daniel Lehmann"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Choice functions over a set $X$ that satisfy the Outcast, a.k.a. Aizerman,\nproperty are exactly those that attach to any set its maximal subset relative\nto some total order of ${2}^{X}$.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.02798v1"
    },
    {
        "title": "A Network Approach to Public Goods: A Short Summary",
        "authors": [
            "Matthew Elliott",
            "Benjamin Golub"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Suppose agents can exert costly effort that creates nonrival, heterogeneous\nbenefits for each other. At each possible outcome, a weighted, directed network\ndescribing marginal externalities is defined. We show that Pareto efficient\noutcomes are those at which the largest eigenvalue of the network is 1. An\nimportant set of efficient solutions, Lindahl outcomes, are characterized by\ncontributions being proportional to agents' eigenvector centralities in the\nnetwork. The outcomes we focus on are motivated by negotiations. We apply the\nresults to identify who is essential for Pareto improvements, how to\nefficiently subdivide negotiations, and whom to optimally add to a team.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04185v1"
    },
    {
        "title": "Making Auctions Robust to Aftermarkets",
        "authors": [
            "Moshe Babaioff",
            "Nicole Immorlica",
            "Yingkai Li",
            "Brendan Lucier"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A prevalent assumption in auction theory is that the auctioneer has full\ncontrol over the market and that the allocation she dictates is final. In\npractice, however, agents might be able to resell acquired items in an\naftermarket. A prominent example is the market for carbon emission allowances.\nThese allowances are commonly allocated by the government using uniform-price\nauctions, and firms can typically trade these allowances among themselves in an\naftermarket that may not be fully under the auctioneer's control. While the\nuniform-price auction is approximately efficient in isolation, we show that\nspeculation and resale in aftermarkets might result in a significant welfare\nloss. Motivated by this issue, we consider three approaches, each ensuring high\nequilibrium welfare in the combined market. The first approach is to adopt\nsmooth auctions such as discriminatory auctions. This approach is robust to\ncorrelated valuations and to participants acquiring information about others'\ntypes. However, discriminatory auctions have several downsides, notably that of\ncharging bidders different prices for identical items, resulting in fairness\nconcerns that make the format unpopular. Two other approaches we suggest are\neither using posted-pricing mechanisms, or using uniform-price auctions with\nanonymous reserves. We show that when using balanced prices, both these\napproaches ensure high equilibrium welfare in the combined market. The latter\nalso inherits many of the benefits from uniform-price auctions such as price\ndiscovery, and can be introduced with a minor modification to auctions\ncurrently in use to sell carbon emission allowances.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.05853v2"
    },
    {
        "title": "Economic Hysteresis and Its Mathematical Modeling",
        "authors": [
            "Isaak D. Mayergoyz",
            "Can E. Korman"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Hysteresis is treated as a history dependent branching, and the use of the\nclassical Preisach model for the analysis of macroeconomic hysteresis is first\ndiscussed. Then, a new Preisach-type model is introduced as a macroeconomic\naggregation of more realistic microeconomic hysteresis than in the case of the\nclassical Preisach model. It is demonstrated that this model is endowed with a\nmore general mechanism of branching and may account for the continuous\nevolution of the economy and its effect on hysteresis. Furthermore, it is shown\nthat the sluggishness of economic recovery is an intrinsic manifestation of\nhysteresis branching.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.10639v2"
    },
    {
        "title": "Beyond Pigouvian Taxes: A Worst Case Analysis",
        "authors": [
            "Moshe Babaioff",
            "Ruty Mundel",
            "Noam Nisan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In the early $20^{th}$ century, Pigou observed that imposing a marginal cost\ntax on the usage of a public good induces a socially efficient level of use as\nan equilibrium. Unfortunately, such a \"Pigouvian\" tax may also induce other,\nsocially inefficient, equilibria. We observe that this social inefficiency may\nbe unbounded, and study whether alternative tax structures may lead to milder\nlosses in the worst case, i.e. to a lower price of anarchy. We show that no tax\nstructure leads to bounded losses in the worst case. However, we do find a tax\nscheme that has a lower price of anarchy than the Pigouvian tax, obtaining\ntight lower and upper bounds in terms of a crucial parameter that we identify.\nWe generalize our results to various scenarios that each offers an alternative\nto the use of a public road by private cars, such as ride sharing, or using a\nbus or a train.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.12023v2"
    },
    {
        "title": "Escaping Arrow's Theorem: The Advantage-Standard Model",
        "authors": [
            "Wesley H. Holliday",
            "Mikayla Kelley"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  There is an extensive literature in social choice theory studying the\nconsequences of weakening the assumptions of Arrow's Impossibility Theorem.\nMuch of this literature suggests that there is no escape from Arrow-style\nimpossibility theorems, while remaining in an ordinal preference setting,\nunless one drastically violates the Independence of Irrelevant Alternatives\n(IIA). In this paper, we present a more positive outlook. We propose a model of\ncomparing candidates in elections, which we call the Advantage-Standard (AS)\nmodel. The requirement that a collective choice rule (CCR) be representable by\nthe AS model captures a key insight of IIA but is weaker than IIA; yet it is\nstronger than what is known in the literature as weak IIA (two profiles alike\non $x,y$ cannot have opposite strict social preferences on $x$ and $y$). In\naddition to motivating violations of IIA, the AS model makes intelligible\nviolations of another Arrovian assumption: the negative transitivity of the\nstrict social preference relation $P$. While previous literature shows that\nonly weakening IIA to weak IIA or only weakening negative transitivity of $P$\nto acyclicity still leads to impossibility theorems, we show that jointly\nweakening IIA to AS representability and weakening negative transitivity of $P$\nleads to no such impossibility theorems. Indeed, we show that several appealing\nCCRs are AS representable, including even transitive CCRs.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.01134v4"
    },
    {
        "title": "Characterizing the Top Cycle via Strategyproofness",
        "authors": [
            "Felix Brandt",
            "Patrick Lederer"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Gibbard and Satterthwaite have shown that the only single-valued social\nchoice functions (SCFs) that satisfy non-imposition (i.e., the function's range\ncoincides with its codomain) and strategyproofness (i.e., voters are never\nbetter off by misrepresenting their preferences) are dictatorships. In this\npaper, we consider set-valued social choice correspondences (SCCs) that are\nstrategyproof according to Fishburn's preference extension and, in particular,\nthe top cycle, an attractive SCC that returns the maximal elements of the\ntransitive closure of the weak majority relation. Our main theorem implies\nthat, under mild conditions, the top cycle is the only non-imposing\nstrategyproof SCC whose outcome only depends on the quantified pairwise\ncomparisons between alternatives. This result effectively turns the\nGibbard-Satterthwaite impossibility into a complete characterization of the top\ncycle by moving from SCFs to SCCs. It is obtained as a corollary of a more\ngeneral characterization of strategyproof SCCs.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04622v2"
    },
    {
        "title": "Level-strategyproof Belief Aggregation Mechanisms",
        "authors": [
            "Rida Laraki",
            "Estelle Varloot"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In the problem of aggregating experts' probabilistic predictions over an\nordered set of outcomes, we introduce the axiom of level-strategy\\-proofness\n(level-SP) and prove that it is a natural notion with several applications.\nMoreover, it is a robust concept as it implies incentive compatibility in a\nrich domain of single-peakedness over the space of cumulative distribution\nfunctions (CDFs). This contrasts with the literature which assumes\nsingle-peaked preferences over the space of probability distributions. Our main\nresults are: (1) a reduction of our problem to the aggregation of CDFs; (2) the\naxiomatic characterization of level-SP probability aggregation functions with\nand without the addition of other axioms; (3) impossibility results which\nprovide bounds for our characterization; (4) the axiomatic characterization of\ntwo new and practical level-SP methods: the proportional-cumulative method and\nthe middlemost-cumulative method; and (5) the application of\nproportional-cumulative to extend approval voting, majority rule, and majority\njudgment methods to situations where voters/experts are uncertain about how to\ngrade the candidates/alternatives to be ranked.\\footnote{We are grateful to\nThomas Boyer-Kassem, Roger Cooke, Aris Filos-Ratsikas, Herv\\'e Moulin, Clemens\nPuppe and some anonymous EC2021 referees for their helpful comments and\nsuggestions.}\n  \\keywords{Probability Aggregation Functions \\and ordered Set of Alternatives\n\\and Level Strategy-Proofness \\and Proportional-Cumulative \\and\nMiddlemost-Cumulative}\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04705v4"
    },
    {
        "title": "A continuous space model of new economic geography with a quasi-linear\n  log utility function",
        "authors": [
            "Kensuke Ohtake"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider the extension of a tractable NEG model with a quasi-linear log\nutility to continuous space, and investigate the behavior of its solution\nmathematically. The model is a system of nonlinear integral and differential\nequations describing the market equilibrium and the time evolution of the\nspatial distribution of population density. A unique global solution is\nconstructed and a homogeneous stationary solution with evenly distributed\npopulation is shown to be unstable. Furthermore, it is shown numerically that\nthe destabilized homogeneous stationary solution eventually forms spiky spatial\ndistributions. The number of the spikes decreases as the preference for variety\nincreases or the transport cost decreases.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12217v8"
    },
    {
        "title": "Balanced House Allocation",
        "authors": [
            "Xinghua Long",
            "Rodrigo A. Velez"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We introduce balancedness a fairness axiom in house allocation problems. It\nrequires a mechanism to assign the top choice, the second top choice, and so\non, on the same number of profiles for each agent. This axiom guarantees equal\ntreatment of all agents at the stage in which the mechanism is announced when\nall preference profiles are equally likely. We show that, with an interesting\nexception for the three-agent case, Top Trading Cycles from individual\nendowments is the only mechanism that is balanced, efficient, and group\nstrategy-proof.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.01992v1"
    },
    {
        "title": "Matching markets with middlemen under transferable utility",
        "authors": [
            "Ata Atay",
            "Eric Bahel",
            "Tamás Solymosi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies matching markets in the presence of middlemen. In our\nframework, a buyer-seller pair may either trade directly or use the services of\na middleman; and a middleman may serve multiple buyer-seller pairs. Direct\ntrade between a buyer and a seller is costlier than a trade mediated by a\nmiddleman. For each such market, we examine an associated cooperative game with\ntransferable utility. First, we show that an optimal matching for a matching\nmarket with middlemen can be obtained by considering the two-sided assignment\nmarket where each buyer-seller pair is allowed to use the mediation service of\nthe middlemen free of charge and attain the maximum surplus. Second, we prove\nthat the core of a matching market with middlemen is always non-empty. Third,\nwe show the existence of a buyer-optimal core allocation and a seller-optimal\ncore allocation. In general, the core does not exhibit a middleman-optimal\nmatching. Finally, we establish the coincidence between the core and the set of\ncompetitive equilibrium payoff vectors.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.05456v2"
    },
    {
        "title": "UTXO in Digital Currencies: Account-based or Token-based? Or Both?",
        "authors": [
            "Aldar C-F. Chan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  There are different interpretations of the terms \"tokens\" and \"token-based\nsystems\" in the literature around blockchain and digital currencies although\nthe distinction between token-based and account-based systems is well\nentrenched in economics. Despite the wide use of the terminologies of tokens\nand tokenisation in the cryptocurrency community, the underlying concept\nsometimes does not square well with the economic notions, or is even contrary\nto them. The UTXO design of Bitcoin exhibits partially characteristics of a\ntoken-based system and partially characteristics of an account-based system. A\ndiscussion on the difficulty to implement the economic notion of tokens in the\ndigital domain, along with an exposition of the design of UTXO, is given in\norder to discuss why UTXO-based systems should be viewed as account-based\naccording to the classical economic notion. Besides, a detailed comparison\nbetween UTXO-based systems and account-based systems is presented. Using the\ndata structure of the system state representation as the defining feature to\ndistinguish digital token-based and account-based systems is therefore\nsuggested. This extended definition of token-based systems covers both physical\nand digital tokens while neatly distinguishing token-based and account-based\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.09294v1"
    },
    {
        "title": "Non-equilibrium time-dependent solution to discrete choice with social\n  interactions",
        "authors": [
            "James Holehouse",
            "Hector Pollitt"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We solve the binary decision model of Brock and Durlauf in time using a\nmethod reliant on the resolvent of the master operator of the stochastic\nprocess. Our solution is valid when not at equilibrium and can be used to\nexemplify path-dependent behaviours of the binary decision model. The solution\nis computationally fast and is indistinguishable from Monte Carlo simulation.\nWell-known metastable effects are observed in regions of the model's parameter\nspace where agent rationality is above a critical value, and we calculate the\ntime scale at which equilibrium is reached from first passage time theory to a\nmuch greater approximation than has been previously conducted. In addition to\nconsidering selfish agents, who only care to maximise their own utility, we\nconsider altruistic agents who make decisions on the basis of maximising global\nutility. Curiously, we find that although altruistic agents coalesce more\nstrongly on a particular decision, thereby increasing their utility in the\nshort-term, they are also more prone to being subject to non-optimal metastable\nregimes as compared to selfish agents. The method used for this solution can be\neasily extended to other binary decision models, including Kirman's ant model,\nand under reinterpretation also provides a time-dependent solution to the\nmean-field Ising model. Finally, we use our time-dependent solution to\nconstruct a likelihood function that can be used on non-equilibrium data for\nmodel calibration. This is a rare finding, since often calibration in economic\nagent based models must be done without an explicit likelihood function. From\nsimulated data, we show that even with a well-defined likelihood function,\nmodel calibration is difficult unless one has access to data representative of\nthe underlying model.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.09633v3"
    },
    {
        "title": "Unstable diffusion in social networks",
        "authors": [
            "Teruyoshi Kobayashi",
            "Yoshitaka Ogisu",
            "Tomokatsu Onaga"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  How and to what extent will new activities spread through social ties? Here,\nwe develop a more sophisticated framework than the standard mean-field approach\nto describe the diffusion dynamics of multiple activities on complex networks.\nWe show that the diffusion of multiple activities follows a saddle path and can\nbe highly unstable. In particular, when the two activities are sufficiently\nsubstitutable, either of them would dominate the other by chance even if they\nare equally attractive ex ante. When such symmetry-breaking occurs, any\naverage-based approach cannot correctly calculate the Nash equilibrium - the\nsteady state of an actual diffusion process.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14560v1"
    },
    {
        "title": "Can an AI agent hit a moving target?",
        "authors": [
            " Rui",
            " Shi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I model the belief formation and decision making processes of economic agents\nduring a monetary policy regime change (an acceleration in the money supply)\nwith a deep reinforcement learning algorithm in the AI literature. I show that\nwhen the money supply accelerates, the learning agents only adjust their\nactions, which include consumption and demand for real balance, after gathering\nlearning experience for many periods. This delayed adjustments leads to low\nreturns during transition periods. Once they start adjusting to the new\nenvironment, their welfare improves. Their changes in beliefs and actions lead\nto temporary inflation volatility. I also show that, 1. the AI agents who\nexplores their environment more adapt to the policy regime change quicker,\nwhich leads to welfare improvements and less inflation volatility, and 2. the\nAI agents who have experienced a structural change adjust their beliefs and\nbehaviours quicker than an inexperienced learning agent.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.02474v3"
    },
    {
        "title": "Gambits: Theory and Evidence",
        "authors": [
            "Shiva Maharaj",
            "Nicholas Polson",
            "Christian Turk"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Gambits are central to human decision-making. Our goal is to provide a theory\nof Gambits. A Gambit is a combination of psychological and technical factors\ndesigned to disrupt predictable play. Chess provides an environment to study\ngambits and behavioral game theory. Our theory is based on the Bellman\noptimality path for sequential decision-making. This allows us to calculate the\n$Q$-values of a Gambit where material (usually a pawn) is sacrificed for\ndynamic play. On the empirical side, we study the effectiveness of a number of\npopular chess Gambits. This is a natural setting as chess Gambits require a\nsequential assessment of a set of moves (a.k.a. policy) after the Gambit has\nbeen accepted. Our analysis uses Stockfish 14.1 to calculate the optimal\nBellman $Q$ values, which fundamentally measures if a position is winning or\nlosing. To test whether Bellman's equation holds in play, we estimate the\ntransition probabilities to the next board state via a database of expert human\nplay. This then allows us to test whether the \\emph{Gambiteer} is following the\noptimal path in his decision-making. Our methodology is applied to the popular\nStafford and reverse Stafford (a.k.a. Boden-Kieretsky-Morphy) Gambit and other\ncommon ones including the Smith-Morra, Goring, Danish and Halloween Gambits. We\nbuild on research in human decision-making by proving an irrational skewness\npreference within agents in chess. We conclude with directions for future\nresearch.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.02755v5"
    },
    {
        "title": "A Mechanism Design Approach to Allocating Travel Funds",
        "authors": [
            "Michael A. Jones"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  I explain how faculty members could exploit a method to allocate travel funds\nand how to use game theory to design a method that cannot be manipulated.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.04161v1"
    },
    {
        "title": "Stability and Efficiency of Random Serial Dictatorship",
        "authors": [
            "Suhas Vijaykumar"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper establishes non-asymptotic convergence of the cutoffs in Random\nserial dictatorship in an environment with many students, many schools, and\narbitrary student preferences. Convergence is shown to hold when the number of\nschools, $m$, and the number of students, $n$, satisfy the relation $m \\ln m\n\\ll n$, and we provide an example showing that this result is sharp.\n  We differ significantly from prior work in the mechanism design literature in\nour use of analytic tools from randomized algorithms and discrete probability,\nwhich allow us to show concentration of the RSD lottery probabilities and\ncutoffs even against adversarial student preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.07024v1"
    },
    {
        "title": "Bayesian Persuasion in Sequential Trials",
        "authors": [
            "Shih-Tang Su",
            "Vijay G. Subramanian",
            "Grant Schoenebeck"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We consider a Bayesian persuasion or information design problem where the\nsender tries to persuade the receiver to take a particular action via a\nsequence of signals. This we model by considering multi-phase trials with\ndifferent experiments conducted based on the outcomes of prior experiments. In\ncontrast to most of the literature, we consider the problem with constraints on\nsignals imposed on the sender. This we achieve by fixing some of the\nexperiments in an exogenous manner; these are called determined experiments.\nThis modeling helps us understand real-world situations where this occurs:\ne.g., multi-phase drug trials where the FDA determines some of the experiments,\nfunding of a startup by a venture capital firm, start-up acquisition by big\nfirms where late-stage assessments are determined by the potential acquirer,\nmulti-round job interviews where the candidates signal initially by presenting\ntheir qualifications but the rest of the screening procedures are determined by\nthe interviewer. The non-determined experiments (signals) in the multi-phase\ntrial are to be chosen by the sender in order to persuade the receiver best.\nWith a binary state of the world, we start by deriving the optimal signaling\npolicy in the only non-trivial configuration of a two-phase trial with\nbinary-outcome experiments. We then generalize to multi-phase trials with\nbinary-outcome experiments where the determined experiments can be placed at\nany chosen node in the trial tree. Here we present a dynamic programming\nalgorithm to derive the optimal signaling policy that uses the two-phase trial\nsolution's structural insights. We also contrast the optimal signaling policy\nstructure with classical Bayesian persuasion strategies to highlight the impact\nof the signaling constraints on the sender.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.09594v3"
    },
    {
        "title": "Attention Overload",
        "authors": [
            "Matias D. Cattaneo",
            "Paul Cheung",
            "Xinwei Ma",
            "Yusufcan Masatlioglu"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We introduce an Attention Overload Model that captures the idea that\nalternatives compete for the decision maker's attention, and hence the\nattention that each alternative receives decreases as the choice problem\nbecomes larger. Using this nonparametric restriction on the random attention\nformation, we show that a fruitful revealed preference theory can be developed\nand provide testable implications on the observed choice behavior that can be\nused to (point or partially) identify the decision maker's preference and\nattention frequency. We then enhance our attention overload model to\naccommodate heterogeneous preferences. Due to the nonparametric nature of our\nidentifying assumption, we must discipline the amount of heterogeneity in the\nchoice model: we propose the idea of List-based Attention Overload, where\nalternatives are presented to the decision makers as a list that correlates\nwith both heterogeneous preferences and random attention. We show that\npreference and attention frequencies are (point or partially) identifiable\nunder nonparametric assumptions on the list and attention formation mechanisms,\neven when the true underlying list is unknown to the researcher. Building on\nour identification results, for both preference and attention frequencies, we\ndevelop econometric methods for estimation and inference that are valid in\nsettings with a large number of alternatives and choice problems, a distinctive\nfeature of the economic environment we consider. We provide a software package\nin R implementing our empirical methods, and illustrate them in a simulation\nstudy.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.10650v4"
    },
    {
        "title": "Evolutionary Foundation for Heterogeneity in Risk Aversion",
        "authors": [
            "Yuval Heller",
            "Ilan Nehama"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We examine the evolutionary basis for risk aversion with respect to aggregate\nrisk. We study populations in which agents face choices between alternatives\nwith different levels of aggregate risk. We show that the choices that maximize\nthe long-run growth rate are induced by a heterogeneous population in which the\nleast and most risk-averse agents are indifferent between facing an aggregate\nrisk and obtaining its linear and harmonic mean for sure, respectively.\nMoreover, approximately optimal behavior can be induced by a simple\ndistribution according to which all agents have constant relative risk\naversion, and the coefficient of relative risk aversion is uniformly\ndistributed between zero and two.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.11245v3"
    },
    {
        "title": "A Robust Efficient Dynamic Mechanism",
        "authors": [
            "Endre Csóka"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Athey and Segal introduced an efficient budget-balanced mechanism for a\ndynamic stochastic model with quasilinear payoffs and private values, using the\nsolution concept of perfect Bayesian equilibrium. We show that this\nimplementation is not robust in multiple senses, especially for at least 3\nagents. For example, we will show a generic setup where all efficient strategy\nprofiles can be eliminated by iterative elimination of weakly dominated\nstrategies. Furthermore, this model used strong assumptions about the\ninformation of the agents, and the mechanism was not robust to the relaxation\nof these assumptions. In this paper, we will show a different mechanism that\nimplements efficiency under weaker assumptions and uses the stronger solution\nconcept of ``efficient Nash equilibrium with guaranteed expected payoffs''.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.15219v2"
    },
    {
        "title": "Market Areas in General Equilibrium",
        "authors": [
            "Gianandrea Lanzara",
            "Matteo Santacesaria"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper proposes a spatial model with a realistic geography where a\ncontinuous distribution of agents (e.g., farmers) engages in economic\ninteractions with one location from a finite set (e.g., cities). The spatial\nstructure of the equilibrium consists of a tessellation, i.e., a partition of\nspace into a collection of mutually exclusive market areas. After proving the\nexistence of a unique equilibrium, we characterize how the location of borders\nand, in the case with mobile labor, the set of inhabited cities change in\nresponse to economic shocks. To deal with a two-dimensional space, we draw on\ntools from computational geometry and from the theory of shape optimization.\nFinally, we provide an empirical application to illustrate the usefulness of\nthe framework for applied work.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.15849v2"
    },
    {
        "title": "Information Spillover in Multiple Zero-sum Games",
        "authors": [
            "Lucas Pahl"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper considers an infinitely repeated three-player Bayesian game with\nlack of information on two sides, in which an informed player plays two\nzero-sum games simultaneously at each stage against two uninformed players.\nThis is a generalization of the Aumann et al. [1] two-player zero-sum one-sided\nincomplete information model. Under a correlated prior, the informed player\nfaces the problem of how to optimally disclose information among two uninformed\nplayers in order to maximize his long-term average payoffs. Our objective is to\nunderstand the adverse effects of \\information spillover\" from one game to the\nother in the equilibrium payoff set of the informed player. We provide\nconditions under which the informed player can fully overcome such adverse\neffects and characterize equilibrium payoffs. In a second result, we show how\nthe effects of information spillover on the equilibrium payoff set of the\ninformed player might be severe.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.01647v3"
    },
    {
        "title": "Rational AI: A comparison of human and AI responses to triggers of\n  economic irrationality in poker",
        "authors": [
            "C. Grace Haaf",
            "Devansh Singh",
            "Cinny Lin",
            "Scofield Zou"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Humans exhibit irrational decision-making patterns in response to\nenvironmental triggers, such as experiencing an economic loss or gain. In this\npaper we investigate whether algorithms exhibit the same behavior by examining\nthe observed decisions and latent risk and rationality parameters estimated by\na random utility model with constant relative risk-aversion utility function.\nWe use a dataset consisting of 10,000 hands of poker played by Pluribus, the\nfirst algorithm in the world to beat professional human players and find (1)\nPluribus does shift its playing style in response to economic losses and gains,\nceteris paribus; (2) Pluribus becomes more risk-averse and rational following a\ntrigger but the humans become more risk-seeking and irrational; (3) the\ndifference in playing styles between Pluribus and the humans on the dimensions\nof risk-aversion and rationality are particularly differentiable when both have\nexperienced a trigger. This provides support that decision-making patterns\ncould be used as \"behavioral signatures\" to identify human versus algorithmic\ndecision-makers in unlabeled contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.07295v1"
    },
    {
        "title": "A Game Theoretic Analysis of Liquidity Events in Convertible Instruments",
        "authors": [
            "Ron van der Meyden"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Convertible instruments are contracts, used in venture financing, which give\ninvestors the right to receive shares in the venture in certain circumstances.\nIn liquidity events, investors may have the option to either receive back their\nprincipal investment, or to receive a proportional payment after conversion of\nthe contract to a shareholding. In each case, the value of the payment may\ndepend on the choices made by other investors who hold such convertible\ncontracts. A liquidity event therefore sets up a game theoretic optimization\nproblem. The paper defines a general model for such games, which is shown to\ncover all instances of the Y Combinator Simple Agreement for Future Equity\n(SAFE) contracts, a type of convertible instrument that is commonly used to\nfinance startup ventures. The paper shows that, in general, pure strategy Nash\nequilibria do not necessarily exist in this model, and there may not exist an\noptimum pure strategy Nash equilibrium in cases where pure strategy Nash\nequilibria do exist. However, it is shown when all contracts are uniformly one\nof the SAFE contract types, an optimum pure strategy Nash equilibrium exists.\nPolynomial time algorithms for computing (optimum) pure strategy Nash\nequilibria in these cases are developed.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.12237v1"
    },
    {
        "title": "Agglomeration triggered by the effect of the number of regions: A model\n  in NEG with a quadratic subutility",
        "authors": [
            "Kensuke Ohtake"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We extend the mathematical model proposed by Ottaviano-Tabuchi-Thisse (2002)\nto a multi-regional case and investigate the stability of the homogeneous\nstationary solution of the model in a one-dimensional periodic space. When the\nnumber of regions is two and three, the homogeneous stationary solution is\nstable under sufficiently high transport cost. On the other hand, when the\nnumber of regions is a multiple of four, the homogeneous stationary solution is\nunstable under any values of the transport cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.02920v3"
    },
    {
        "title": "Theoretical Economics and the Second-Order Economic Theory. What is it?",
        "authors": [
            "Victor Olkhov"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The economic and financial variables of economic agents determine\nmacroeconomic variables. Current models consider agents' variables that are\ndetermined by the sums of values and volumes of agents' trades during some time\ninterval {\\Delta}. We call them first-order economic variables. We describe how\nthe volatilities and correlations of market trade values and volumes determine\nprice volatility. We argue that such a link requests consideration of agents'\neconomic variables of the second order that are composed of sums of squares of\nagents' transactions during {\\Delta}. Almost any variable of the first order\nshould be complemented by its second-order pair. Respectively, the sums of\nagents' second-order variables introduce macroeconomic variables of the second\norder. The description of the first- and second-order macroeconomic variables\nestablishes the subject of second-order economic theory. We highlight that the\ncomplexity of second-order economic theory essentially restricts any hopes for\nprecise predictions of price probability and, at best, could provide estimates\nof price volatility. That limits the predictions of price probability to\nGauss's approximations only.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.04566v2"
    },
    {
        "title": "Behavioral Foundations of Nested Stochastic Choice and Nested Logit",
        "authors": [
            "Matthew Kovach",
            "Gerelt Tserenjigmid"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We provide the first behavioral characterization of nested logit, a\nfoundational and widely applied discrete choice model, through the introduction\nof a non-parametric version of nested logit that we call Nested Stochastic\nChoice (NSC). NSC is characterized by a single axiom that weakens Independence\nof Irrelevant Alternatives based on revealed similarity to allow for the\nsimilarity effect. Nested logit is characterized by an additional\nmenu-independence axiom. Our axiomatic characterization leads to a practical,\ndata-driven algorithm that identifies the true nest structure from choice data.\nWe also discuss limitations of generalizing nested logit by studying the\ntestable implications of cross-nested logit.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.07155v2"
    },
    {
        "title": "A dynamic theory of spatial externalities",
        "authors": [
            "Raouf Boucekkine",
            "Giorgio Fabbri",
            "Salvatore Federico",
            "Fausto Gozzi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We characterize the shape of spatial externalities in a continuous time and\nspace differential game with transboundary pollution. We posit a realistic\nspatiotemporal law of motion for pollution (diffusion and advection), and\ntackle spatiotemporal non-cooperative (and cooperative) differential games.\nPrecisely, we consider a circle partitioned into several states where a local\nauthority decides autonomously about its investment, production and depollution\nstrategies over time knowing that investment/production generates pollution,\nand pollution is transboundary. The time horizon is infinite. We allow for a\nrich set of geographic heterogeneities across states. We solve analytically the\ninduced non-cooperative differential game and characterize its long-term\nspatial distributions. In particular, we prove that there exist a Perfect\nMarkov Equilibrium, unique among the class of the affine feedbacks. We further\nprovide with a full exploration of the free riding problem and the associated\nborder effect.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10584v1"
    },
    {
        "title": "Learning in Random Utility Models Via Online Decision Problems",
        "authors": [
            "Emerson Melo"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the Random Utility Model (RUM) in a repeated stochastic\nchoice situation, in which the decision maker is imperfectly informed about the\npayoffs of each available alternative. We develop a gradient-based learning\nalgorithm by embedding the RUM into an online decision problem. We show that a\nlarge class of RUMs are Hannan consistent (\\citet{Hahn1957}); that is, the\naverage difference between the expected payoffs generated by a RUM and that of\nthe best-fixed policy in hindsight goes to zero as the number of periods\nincrease. In addition, we show that our gradient-based algorithm is equivalent\nto the Follow the Regularized Leader (FTRL) algorithm, which is widely used in\nthe machine learning literature to model learning in repeated stochastic choice\nproblems. Thus, we provide an economically grounded optimization framework to\nthe FTRL algorithm. Finally, we apply our framework to study recency bias,\nno-regret learning in normal form games, and prediction markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10993v3"
    },
    {
        "title": "Random Rank-Dependent Expected Utility",
        "authors": [
            "Nail Kashaev",
            "Victor Aguiar"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We present a novel characterization of random rank-dependent expected utility\nfor finite datasets and finite prizes. The test lends itself to statistical\ntesting using the tools in Kitamura and Stoye (2018).\n",
        "pdf_link": "http://arxiv.org/pdf/2112.13649v1"
    },
    {
        "title": "Mechanism Design with Informational Punishment",
        "authors": [
            "Benjamin Balzer",
            "Johannes Schneider"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We introduce \\emph{informational punishment} to the design of mechanisms that\ncompete with an exogenous status quo mechanism: Players can send garbled public\nmessages with some delay, and others cannot commit to ignoring them. Optimal\ninformational punishment ensures that full participation is without loss, even\nif any single player can publicly enforce the status quo mechanism.\nInformational punishment permits using a standard revelation principle, is\nindependent of the mechanism designer's objective, and operates exclusively off\nthe equilibrium path. It is robust to refinements and applies in\ninformed-principal settings. We provide conditions that make it robust to\nopportunistic signal designers.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01149v2"
    },
    {
        "title": "Simultaneous Optimal Transport",
        "authors": [
            "Ruodu Wang",
            "Zhenyuan Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We propose a general framework of mass transport between vector-valued\nmeasures, which will be called simultaneous optimal transport (SOT). The new\nframework is motivated by the need to transport resources of different types\nsimultaneously, i.e., in single trips, from specified origins to destinations;\nsimilarly, in economic matching, one needs to couple two groups, e.g., buyers\nand sellers, by equating supplies and demands of different goods at the same\ntime. The mathematical structure of simultaneous transport is very different\nfrom the classic setting of optimal transport, leading to many new challenges.\nThe Monge and Kantorovich formulations are contrasted and connected. Existence\nconditions and duality formulas are established. More interestingly, by\nconnecting SOT to a natural relaxation of martingale optimal transport (MOT),\nwe introduce the MOT-SOT parity, which allows for explicit solutions of SOT in\nmany interesting cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.03483v3"
    },
    {
        "title": "The Transfer Performance of Economic Models",
        "authors": [
            "Isaiah Andrews",
            "Drew Fudenberg",
            "Lihua Lei",
            "Annie Liang",
            "Chaofeng Wu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Economists often estimate models using data from a particular domain, e.g.\nestimating risk preferences in a particular subject pool or for a specific\nclass of lotteries. Whether a model's predictions extrapolate well across\ndomains depends on whether the estimated model has captured generalizable\nstructure. We provide a tractable formulation for this \"out-of-domain\"\nprediction problem and define the transfer error of a model based on how well\nit performs on data from a new domain. We derive finite-sample forecast\nintervals that are guaranteed to cover realized transfer errors with a\nuser-selected probability when domains are iid, and use these intervals to\ncompare the transferability of economic models and black box algorithms for\npredicting certainty equivalents. We find that in this application, the black\nbox algorithms we consider outperform standard economic models when estimated\nand tested on data from the same domain, but the economic models generalize\nacross domains better than the black-box algorithms do.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04796v4"
    },
    {
        "title": "Matching with Transfers under Distributional Constraints",
        "authors": [
            "Devansh Jalota",
            "Michael Ostrovsky",
            "Marco Pavone"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study two-sided many-to-one matching markets with transferable utilities,\ne.g., labor and rental housing markets, in which money can exchange hands\nbetween agents, subject to distributional constraints on the set of feasible\nallocations. In such markets, we establish the efficiency of equilibrium\narrangements, specified by an assignment and transfers between agents on the\ntwo sides of the market, and study the conditions on the distributional\nconstraints and agent preferences under which equilibria exist and can be\ncomputed efficiently. To this end, we first consider the setting when the\nnumber of institutions (e.g., firms in a labor market) is one and show that\nequilibrium arrangements exist irrespective of the nature of the constraint\nstructure or the agents' preferences. However, equilibrium arrangements may not\nexist in markets with multiple institutions even when agents on each side have\nlinear (or additively separable) preferences over agents on the other side.\nThus, for markets with linear preferences, we study sufficient conditions on\nthe constraint structure that guarantee the existence of equilibria using\nlinear programming duality. Our linear programming approach not only\ngeneralizes that of Shapley and Shubik (1971) in the one-to-one matching\nsetting to the many-to-one matching setting under distributional constraints\nbut also provides a method to compute market equilibria efficiently.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05232v2"
    },
    {
        "title": "Closure operators: Complexity and applications to classification and\n  decision-making",
        "authors": [
            "Hamed Hamze Bajgiran",
            "Federico Echenique"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the complexity of closure operators, with applications to machine\nlearning and decision theory. In machine learning, closure operators emerge\nnaturally in data classification and clustering. In decision theory, they can\nmodel equivalence of choice menus, and therefore situations with a preference\nfor flexibility. Our contribution is to formulate a notion of complexity of\nclosure operators, which translate into the complexity of a classifier in ML,\nor of a utility function in decision theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05339v2"
    },
    {
        "title": "Information Design for Differential Privacy",
        "authors": [
            "Ian M. Schmutte",
            "Nathan Yoder"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Firms and statistical agencies must protect the privacy of the individuals\nwhose data they collect, analyze, and publish. Increasingly, these\norganizations do so by using publication mechanisms that satisfy differential\nprivacy. We consider the problem of choosing such a mechanism so as to maximize\nthe value of its output to end users. We show that mechanisms which add noise\nto the statistic of interest--like most of those used in practice--are\ngenerally not optimal when the statistic is a sum or average of magnitude data\n(e.g., income). However, we also show that adding noise is always optimal when\nthe statistic is a count of data entries with a certain characteristic, and the\nunderlying database is drawn from a symmetric distribution (e.g., if\nindividuals' data are i.i.d.). When, in addition, data users have supermodular\npayoffs, we show that the simple geometric mechanism is always optimal by using\na novel comparative static that ranks information structures according to their\nusefulness in supermodular decision problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05452v6"
    },
    {
        "title": "A constraint on the dynamics of wealth concentration",
        "authors": [
            "Valerio Astuti"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In the context of a large class of stochastic processes used to describe the\ndynamics of wealth growth, we prove a set of inequalities establishing\nnecessary and sufficient conditions in order to avoid infinite wealth\nconcentration. These inequalities generalize results previously found only in\nthe context of particular models, or with more restrictive sets of hypotheses.\nIn particular, we emphasize the role of the additive component of growth -\nusually representing labor incomes - in limiting the growth of inequality. Our\nmain result is a proof that in an economy with random wealth growth, with\nreturns non-negatively correlated with wealth, an average labor income growing\nat least proportionally to the average wealth is necessary to avoid a runaway\nconcentration. One of the main advantages of this result with respect to the\nstandard economics literature is the independence from the concept of an\nequilibrium wealth distribution, which does not always exist in random growth\nmodels. We analyze in this light three toy models, widely studied in the\neconomics and econophysics literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05789v5"
    },
    {
        "title": "Reduced-Form Allocations with Complementarity: A 2-Person Case",
        "authors": [
            "Xu Lang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We investigate the implementation of reduced-form allocation probabilities in\na two-person bargaining problem without side payments, where the agents have to\nselect one alternative from a finite set of social alternatives. We provide a\nnecessary and sufficient condition for the implementability. We find that the\nimplementability condition in bargaining has some new feature compared to\nBorder's theorem. Our results have applications in compromise problems and\npackage exchange problems where the agents barter indivisible objects and the\nagents value the objects as complements.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06245v3"
    },
    {
        "title": "An Equilibrium Model of the First-Price Auction with Strategic\n  Uncertainty: Theory and Empirics",
        "authors": [
            "Bernhard Kasberger"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In many first-price auctions, bidders face considerable strategic\nuncertainty: They cannot perfectly anticipate the other bidders' bidding\nbehavior. We propose a model in which bidders do not know the entire\ndistribution of opponent bids but only the expected (winning) bid and lower and\nupper bounds on the opponent bids. We characterize the optimal bidding\nstrategies and prove the existence of equilibrium beliefs. Finally, we apply\nthe model to estimate the cost distribution in highway procurement auctions and\nfind good performance out-of-sample.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07517v2"
    },
    {
        "title": "Selling to a principal and a budget-constrained agent",
        "authors": [
            "Debasis Mishra",
            "Kolagani Paramahamsa"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We analyze a model of selling a single object to a principal-agent pair who\nwant to acquire the object for a firm. The principal and the agent have\ndifferent assessments of the object's value to the firm. The agent is\nbudget-constrained while the principal is not. The agent participates in the\nmechanism, but she can (strategically) delegate decision-making to the\nprincipal. We derive the revenue-maximizing mechanism in a two-dimensional type\nspace (values of the agent and the principal). We show that below a threshold\nbudget, a mechanism involving two posted prices and three outcomes (one of\nwhich involves randomization) is the optimal mechanism for the seller.\nOtherwise, a single posted price mechanism is optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10378v3"
    },
    {
        "title": "Decisions over Sequences",
        "authors": [
            "Bhavook Bhardwaj",
            "Siddharth Chatterjee"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper introduces a class of objects called decision rules that map\ninfinite sequences of alternatives to a decision space. These objects can be\nused to model situations where a decision maker encounters alternatives in a\nsequence such as receiving recommendations. Within the class of decision rules,\nwe study natural subclasses: stopping and uniform stopping rules. Our main\nresult establishes the equivalence of these two subclasses of decision rules.\nNext, we introduce the notion of computability of decision rules using Turing\nmachines and show that computable rules can be implemented using a simpler\ncomputational device: a finite automaton. We further show that computability of\nchoice rules -- an important subclass of decision rules -- is implied by their\ncontinuity with respect to a natural topology. Finally, we introduce some\nnatural heuristics in this framework and provide their behavioral\ncharacterization.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.00070v2"
    },
    {
        "title": "Bayesian Persuasion with Mediators",
        "authors": [
            "Itai Arieli",
            "Yakov Babichenko",
            "Fedor Sandomirskiy"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  An informed sender communicates with an uninformed receiver through a\nsequence of uninformed mediators; agents' utilities depend on receiver's action\nand the state. For any number of mediators, the sender's optimal value is\ncharacterized. For one mediator, the characterization has a geometric meaning\nof constrained concavification of sender's utility, optimal persuasion requires\nthe same number of signals as without mediators, and the presence of the\nmediator is never profitable for the sender. Surprisingly, the second mediator\nmay improve the value but optimal persuasion may require more signals.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04285v2"
    },
    {
        "title": "Game Dynamics Structure Control by Design: an Example from Experimental\n  Economics",
        "authors": [
            "Wang Zhijian"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Game dynamics structure (e.g., endogenous cycle motion) in human subjects\ngame experiments can be predicted by game dynamics theory. However, whether the\nstructure can be controlled by mechanism design to a desired goal is not known.\nHere, using the pole assignment approach in modern control theory, we\ndemonstrate how to control the structure in two steps: (1) Illustrate an\ntheoretical workflow on how to design a state-depended feedback controller for\ndesired structure; (2) Evaluate the controller by laboratory human subject game\nexperiments and by agent-based evolutionary dynamics simulation. To our\nknowledge, this is the first realisation of the control of the human social\ngame dynamics structure in theory and experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06088v1"
    },
    {
        "title": "Efficiency in Random Resource Allocation and Social Choice",
        "authors": [
            "Federico Echenique",
            "Joseph Root",
            "Fedor Sandomirskiy"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study efficiency in general collective choice problems where agents have\nordinal preferences and randomization is allowed. We explore the structure of\npreference profiles where ex-ante and ex-post efficiency coincide, offer a\nunifying perspective on the known results, and give several new\ncharacterizations. The results have implications for well-studied mechanisms\nincluding random serial dictatorship and a number of specific environments,\nincluding the dichotomous, single-peaked, and social choice domains.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06353v3"
    },
    {
        "title": "Cournot duopoly games with isoelastic demands and diseconomies of scale",
        "authors": [
            "Xiaoliang Li"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this discussion draft, we investigate five different models of duopoly\ngames, where the market is assumed to have an isoelastic demand function.\nMoreover, quadratic cost functions reflecting decreasing returns to scale are\nconsidered. The games in this draft are formulated with systems of two\nnonlinear difference equations. Existing equilibria and their local stability\nare analyzed by symbolic computations. In the model where a gradiently\nadjusting player and a rational (or a boundedly rational) player compete with\neach other, diseconomies of scale are proved to have an effect of stability\nenhancement, which is consistent with the similar results found by Fisher for\nhomogeneous oligopolies with linear demand functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.09972v1"
    },
    {
        "title": "Incentive Compatibility in Two-Stage Repeated Stochastic Games",
        "authors": [
            "Bharadwaj Satchidanandan",
            "Munther A. Dahleh"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We address the problem of mechanism design for two-stage repeated stochastic\ngames -- a novel setting using which many emerging problems in next-generation\nelectricity markets can be readily modeled. Repeated playing affords the\nplayers a large class of strategies that adapt a player's actions to all past\nobservations and inferences obtained therefrom. In other settings such as\niterative auctions or dynamic games where a large strategy space of this sort\nmanifests, it typically has an important implication for mechanism design: It\nmay be impossible to obtain truth-telling as a dominant strategy equilibrium.\nConsequently, in such scenarios, it is common to settle for mechanisms that\nrender truth-telling only a Nash equilibrium, or variants thereof, even though\nNash equilibria are known to be poor models of real-world behavior. This is\nowing to each player having to make overly specific assumptions about the\nbehaviors of the other players to employ their Nash equilibrium strategy, which\nthey may not make. In general, the lesser the burden of speculation in an\nequilibrium, the more plausible it is that it models real-world behavior.\nGuided by this maxim, we introduce a new notion of equilibrium called Dominant\nStrategy Non-Bankrupting Equilibrium (DNBE) which requires the players to make\nvery little assumptions about the behavior of the other players to employ their\nequilibrium strategy. Consequently, a mechanism that renders truth-telling a\nDNBE as opposed to only a Nash equilibrium could be quite effective in molding\nreal-world behavior along truthful lines. We present a mechanism for two-stage\nrepeated stochastic games that renders truth-telling a Dominant Strategy\nNon-Bankrupting Equilibrium. The mechanism also guarantees individual\nrationality and maximizes social welfare. Finally, we describe an application\nof the mechanism to design demand response markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.10206v2"
    },
    {
        "title": "On the Fragility of the Basis on the Hamilton-Jacobi-Bellman Equation in\n  Economic Dynamics",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this paper, we provide an example of the optimal growth model in which\nthere exist infinitely many solutions to the Hamilton-Jacobi-Bellman equation\nbut the value function does not satisfy this equation. We consider the cause of\nthis phenomenon, and find that the lack of a solution to the original problem\nis crucial. We show that under several conditions, there exists a solution to\nthe original problem if and only if the value function solves the\nHamilton-Jacobi-Bellman equation. Moreover, in this case, the value function is\nthe unique nondecreasing concave solution to the Hamilton-Jacobi-Bellman\nequation. We also show that without our conditions, this uniqueness result does\nnot hold.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.10595v4"
    },
    {
        "title": "The Combinatorial Multi-Round Ascending Auction",
        "authors": [
            "Bernhard Kasberger",
            "Alexander Teytelboym"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The Combinatorial Multi-Round Ascending Auction (CMRA) is a new auction\nformat that has already been used in several recent European spectrum auctions.\nWe characterize ex-post equilibria that feature auction-specific forms of\ntruthful bidding, demand expansion, and demand reduction for settings where\nbidders have either decreasing or non-decreasing marginal values. In\nparticular, we show that the truthtelling equilibrium is fragile to small\nasymmetries in the bidders' caps. On the other hand, if bidders are\nsufficiently symmetric, the CMRA is vulnerable to risk-free collusion. We\npropose an alternative activity rule that prevents such collusive strategies\nbut keeps the other equilibria intact. We discuss to what extent our theory is\nconsistent with outcomes in Danish spectrum auctions and how our predictions\ncan be tested using bidding data.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.11783v2"
    },
    {
        "title": "On the probability of a Condorcet winner among a large number of\n  alternatives",
        "authors": [
            "Lisa Sauermann"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Consider $2k-1$ voters, each of which has a preference ranking between $n$\ngiven alternatives. An alternative $A$ is called a Condorcet winner, if it wins\nagainst every other alternative $B$ in majority voting (meaning that for every\nother alternative $B$ there are at least $k$ voters who prefer $A$ over $B$).\nThe notion of Condorcet winners has been studied intensively for many decades,\nyet some basic questions remain open. In this paper, we consider a model where\neach voter chooses their ranking randomly according to some probability\ndistribution among all rankings. One may then ask about the probability to have\na Condorcet winner with these randomly chosen rankings (which, of course,\ndepends on $n$ and $k$, and the underlying probability distribution on the set\nof rankings). In the case of the uniform probability distribution over all\nrankings, which has received a lot of attention and is often referred to as the\nsetting of an \"impartial culture\", we asymptotically determine the probability\nof having a Condorcet winner for a fixed number $2k-1$ of voters and $n$\nalternatives with $n\\to \\infty$. This question has been open for around fifty\nyears. While some authors suggested that the impartial culture should exhibit\nthe lowest possible probability of having a Condorcet winner, in fact the\nprobability can be much smaller for other distributions. We determine, for all\nvalues of $n$ and $k$, the smallest possible probability of having a Condorcet\nwinner (and give an example of a probability distribution over all rankings\nwhich achieves this minimum possible probability).\n",
        "pdf_link": "http://arxiv.org/pdf/2203.13713v1"
    },
    {
        "title": "Dynamic Structure in Four-strategy Game: Theory and Experiment",
        "authors": [
            "Zhijian Wang",
            "Shujie Zhou",
            "Qinmei Yao",
            "Yijia Wang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Game dynamics theory, as a field of science, the consistency of theory and\nexperiment is essential. In the past 10 years, important progress has been made\nin the merging of the theory and experiment in this field, in which dynamics\ncycle is the presentation. However, the merging works have not got rid of the\nconstraints of Euclidean two-dimensional cycle so far. This paper uses a\nclassic four-strategy game to study the dynamic structure (non-Euclidean\nsuperplane cycle). The consistency is in significant between the three ways:\n(1) the analytical results from evolutionary dynamics equations, (2)\nagent-based simulation results from learning models and (3) laboratory results\nfrom human subjects game experiments. The consistency suggests that, game\ndynamic structure could be quantitatively predictable, observable and\ncontrollable in general.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.14669v1"
    },
    {
        "title": "On Maximum Weighted Nash Welfare for Binary Valuations",
        "authors": [
            "Warut Suksompong",
            "Nicholas Teh"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider the problem of fairly allocating indivisible goods to agents with\nweights representing their entitlements. A natural rule in this setting is the\nmaximum weighted Nash welfare (MWNW) rule, which selects an allocation\nmaximizing the weighted product of the agents' utilities. We show that when\nagents have binary valuations, a specific version of MWNW is resource- and\npopulation-monotone, satisfies group-strategyproofness, and can be implemented\nin polynomial time.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.03803v2"
    },
    {
        "title": "Hierarchical Bayesian Persuasion: Importance of Vice Presidents",
        "authors": [
            "Majid Mahzoon"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study strategic information transmission in a hierarchical setting where\ninformation gets transmitted through a chain of agents up to a decision maker\nwhose action is of importance to every agent. This situation could arise\nwhenever an agent can communicate to the decision maker only through a chain of\nintermediaries, for example, an entry-level worker and the CEO in a firm, or an\nofficial in the bottom of the chain of command and the president in a\ngovernment. Each agent can decide to conceal part or all the information she\nreceives. Proving we can focus on simple equilibria, where the only player who\nconceals information is the first one, we provide a tractable recursive\ncharacterization of the equilibrium outcome, and show that it could be\ninefficient. Interestingly, in the binary-action case, regardless of the number\nof intermediaries, there are a few pivotal ones who determine the amount of\ninformation communicated to the decision maker. In this case, our results\nunderscore the importance of choosing a pivotal vice president for maximizing\nthe payoff of the CEO or president.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.05304v2"
    },
    {
        "title": "Approximating Choice Data by Discrete Choice Models",
        "authors": [
            "Haoge Chang",
            "Yusuke Narita",
            "Kota Saito"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We obtain a necessary and sufficient condition under which random-coefficient\ndiscrete choice models, such as mixed-logit models, are rich enough to\napproximate any nonparametric random utility models arbitrarily well across\nchoice sets. The condition turns out to be the affine-independence of the set\nof characteristic vectors. When the condition fails, resulting in some random\nutility models that cannot be closely approximated, we identify preferences and\nsubstitution patterns that are challenging to approximate accurately. We also\npropose algorithms to quantify the magnitude of approximation errors.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.01882v4"
    },
    {
        "title": "Robust Data-Driven Decisions Under Model Uncertainty",
        "authors": [
            "Xiaoyu Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  When sample data are governed by an unknown sequence of independent but\npossibly non-identical distributions, the data-generating process (DGP) in\ngeneral cannot be perfectly identified from the data. For making decisions\nfacing such uncertainty, this paper presents a novel approach by studying how\nthe data can best be used to robustly improve decisions. That is, no matter\nwhich DGP governs the uncertainty, one can make a better decision than without\nusing the data. I show that common inference methods, e.g., maximum likelihood\nand Bayesian updating cannot achieve this goal. To address, I develop new\nupdating rules that lead to robustly better decisions either asymptotically\nalmost surely or in finite sample with a pre-specified probability. Especially,\nthey are easy to implement as are given by simple extensions of the standard\nstatistical procedures in the case where the possible DGPs are all independent\nand identically distributed. Finally, I show that the new updating rules also\nlead to more intuitive conclusions in existing economic models such as asset\npricing under ambiguity.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04573v1"
    },
    {
        "title": "Fair Shares: Feasibility, Domination and Incentives",
        "authors": [
            "Moshe Babaioff",
            "Uriel Feige"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider fair allocation of a set $M$ of indivisible goods to $n$\nequally-entitled agents, with no monetary transfers. Every agent $i$ has a\nvaluation $v_i$ from some given class of valuation functions. A share $s$ is a\nfunction that maps a pair $(v_i,n)$ to a value, with the interpretation that if\nan allocation of $M$ to $n$ agents fails to give agent $i$ a bundle of value at\nleast equal to $s(v_i,n)$, this serves as evidence that the allocation is not\nfair towards $i$. For such an interpretation to make sense, we would like the\nshare to be feasible, meaning that for any valuations in the class, there is an\nallocation that gives every agent at least her share. The maximin share was a\nnatural candidate for a feasible share for additive valuations. However,\nKurokawa, Procaccia and Wang [2018] show that it is not feasible.\n  We initiate a systematic study of the family of feasible shares. We say that\na share is \\emph{self maximizing} if truth-telling maximizes the implied\nguarantee. We show that every feasible share is dominated by some\nself-maximizing and feasible share. We seek to identify those self-maximizing\nfeasible shares that are polynomial time computable, and offer the highest\nshare values. We show that a SM-dominating feasible share -- one that dominates\nevery self-maximizing (SM) feasible share -- does not exist for additive\nvaluations (and beyond). Consequently, we relax the domination property to that\nof domination up to a multiplicative factor of $\\rho$ (called\n$\\rho$-dominating). For additive valuations we present shares that are\nfeasible, self-maximizing and polynomial-time computable. For $n$ agents we\npresent such a share that is $\\frac{2n}{3n-1}$-dominating. For two agents we\npresent such a share that is $(1 - \\epsilon)$-dominating. Moreover, for these\nshares we present poly-time algorithms that compute allocations that give every\nagent at least her share.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.07519v1"
    },
    {
        "title": "A General Framework for a Class of Quarrels: The Quarrelling Paradox\n  Revisited",
        "authors": [
            "Arash Abizadeh",
            "Adrian Vetta"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  If a measure of voting power assigns greater voting power to a player because\nit no longer effectively cooperates with another, then the measure displays the\nquarrelling paradox and violates the quarrel postulate. We provide formal\ncriteria by which to judge whether a given conception of quarrelling is (a)\nreasonable and (b) fit to serve as the basis for a reasonable quarrel\npostulate. To achieve this, we formalize a general framework distinguishing\nbetween three degrees of quarrelling (weak, strong, cataclysmic), symmetric vs.\nasymmetrical quarrels, and reciprocal vs. non-reciprocal quarrels, and which\nthereby yields twelve conceptions of quarrelling, which encompasses the two\nconceptions proposed by Felsenthal and Machover and by Laruelle and Valenciano,\nrespectively. We argue that the two existing formulations of the quarrel\npostulate based on these conceptions are unreasonable. In contrast, we prove\nthat the symmetric, weak conception of quarrelling identified by our framework\n-- whether reciprocal or not -- is fit to serve as the basis for a reasonable\nquarrel postulate. Furthermore, the classic Shapley-Shubik index and\nPenrose-Banzhaf measure both satisfy the quarrel postulate based on a symmetric\nweak quarrel.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08353v1"
    },
    {
        "title": "A Continuum Model of Stable Matching With Finite Capacities",
        "authors": [
            "Nick Arnosti"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper introduces a unified framework for stable matching, which nests\nthe traditional definition of stable matching in finite markets and the\ncontinuum definition of stable matching from Azevedo and Leshno (2016) as\nspecial cases. Within this framework, I identify a novel continuum model, which\nmakes individual-level probabilistic predictions.\n  This new model always has a unique stable outcome, which can be found using\nan analog of the Deferred Acceptance algorithm. The crucial difference between\nthis model and that of Azevedo and Leshno (2016) is that they assume that the\namount of student interest at each school is deterministic, whereas my proposed\nalternative assumes that it follows a Poisson distribution. As a result, this\nnew model accurately predicts the simulated distribution of cutoffs, even for\nmarkets with only ten schools and twenty students.\n  This model generates new insights about the number and quality of matches.\nWhen schools are homogeneous, it provides upper and lower bounds on students'\naverage rank, which match results from Ashlagi, Kanoria and Leshno (2017) but\napply to more general settings. This model also provides clean analytical\nexpressions for the number of matches in a platform pricing setting considered\nby Marx and Schummer (2021).\n",
        "pdf_link": "http://arxiv.org/pdf/2205.12881v1"
    },
    {
        "title": "Communicating with Anecdotes",
        "authors": [
            "Nika Haghtalab",
            "Nicole Immorlica",
            "Brendan Lucier",
            "Markus Mobius",
            "Divyarthi Mohan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a communication game between a sender and a receiver. The sender\nchooses one of her signals about the state of the world (i.e., anecdotes) and\ncommunicates to the receiver who takes an action affecting both players. The\nsender and the receiver both care about the state of the world but are also\ninfluenced by personal preferences, so their ideal actions can differ. We\ncharacterize perfect Bayesian equilibria. The sender faces a temptation to\npersuade: she wants to select a biased anecdote to influence the receiver's\naction. Anecdotes are still informative to the receiver (who will debias at\nequilibrium) but the attempt to persuade comes at a cost to precision. This\ngives rise to informational homophily where the receiver prefers to listen to\nlike-minded senders because they provide higher-precision signals.\nCommunication becomes polarized when the sender is an expert with access to\nmany signals, with the sender choosing extreme outlier anecdotes at equilibrium\n(unless preferences are perfectly aligned). This polarization dissipates all\ngains from communication with an increasingly well-informed sender when the\nanecdote distribution is heavy-tailed. Experts can therefore face a curse of\ninformedness: receivers will prefer to listen to less-informed senders who\ncannot pick biased signals as easily.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.13461v2"
    },
    {
        "title": "Asymptotic welfare performance of Boston assignment algorithms",
        "authors": [
            "Geoffrey Pritchard",
            "Mark C. Wilson"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We make a detailed analysis of three key algorithms (Serial Dictatorship and\nthe naive and adaptive variants of the Boston algorithm) for the housing\nallocation problem, under the assumption that agent preferences are chosen iid\nuniformly from linear orders on the items. We compute limiting distributions\n(with respect to some common utility functions) as $n\\to \\infty$ of both the\nutilitarian welfare and the order bias. To do this, we compute limiting\ndistributions of the outcomes for an arbitrary agent whose initial relative\nposition in the tiebreak order is $\\theta\\in[0,1]$, as a function of $\\theta$.\nThe results for the Boston algorithms are all new, and we expect that these\nfundamental results on the stochastic processes underlying these algorithms\nwill have wider applicability in future. Overall our results show that the\ndifferences in utilitarian welfare performance of the three algorithms are\nfairly small but still important. However, the differences in order bias are\nmuch greater. Also, Naive Boston beats Adaptive Boston, which beats Serial\nDictatorship, on both utilitarian welfare and order bias.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.15418v1"
    },
    {
        "title": "Continuous space core-periphery model with transport costs in\n  differentiated agriculture",
        "authors": [
            "Kensuke Ohtake"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The core-periphery model with transport costs in differentiated agriculture\nis extended to continuous space. A homogeneous stationary solution is unstable\nbut exhibits redispersion that it is stabilized by sufficiently low\nmanufacturing transport costs or sufficiently strong preference for\nmanufacturing variety. It is numerically observed that a solution starting from\naround the unstable homogeneous solution eventually forms a spike-like\nagglomeration. Moreover, the redispersion also appears in the sense that the\nnumber of the spikes goes from decreasing to increasing as the manufacturing\ntransport costs decrease. It is also observed that lower agricultural transport\ncosts and stronger preference for agricultural variety promote agglomeration.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.01040v6"
    },
    {
        "title": "Optimal Stopping Theory for a Distributionally Robust Seller",
        "authors": [
            "Pieter Kleer",
            "Johan van Leeuwaarden"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Sellers in online markets face the challenge of determining the right time to\nsell in view of uncertain future offers. Classical stopping theory assumes that\nsellers have full knowledge of the value distributions, and leverage this\nknowledge to determine stopping rules that maximize expected welfare. In\npractice, however, stopping rules must often be determined under partial\ninformation, based on scarce data or expert predictions. Consider a seller that\nhas one item for sale and receives successive offers drawn from some value\ndistributions. The decision on whether or not to accept an offer is\nirrevocable, and the value distributions are only partially known. We therefore\nlet the seller adopt a robust maximin strategy, assuming that value\ndistributions are chosen adversarially by nature to minimize the value of the\naccepted offer. We provide a general maximin solution to this stopping problem\nthat identifies the optimal (threshold-based) stopping rule for the seller for\nall possible statistical information structures. We then perform a detailed\nanalysis for various ambiguity sets relying on knowledge about the common mean,\ndispersion (variance or mean absolute deviation) and support of the\ndistributions. We show for these information structures that the seller's\nstopping rule consists of decreasing thresholds converging to the common mean,\nand that nature's adversarial response, in the long run, is to always create an\nall-or-nothing scenario. The maximin solutions also reveal what happens as\ndispersion or the number of offers grows large.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.02477v2"
    },
    {
        "title": "A Two-Ball Ellsberg Paradox: An Experiment",
        "authors": [
            "Brian Jabarian",
            "Simon Lazarus"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We conduct an incentivized experiment on a nationally representative US\nsample \\\\ (N=708) to test whether people prefer to avoid ambiguity even when it\nmeans choosing dominated options. In contrast to the literature, we find that\n55\\% of subjects prefer a risky act to an ambiguous act that always provides a\nlarger probability of winning. Our experimental design shows that such a\npreference is not mainly due to a lack of understanding. We conclude that\nsubjects avoid ambiguity \\textit{per se} rather than avoiding ambiguity because\nit may yield a worse outcome. Such behavior cannot be reconciled with existing\nmodels of ambiguity aversion in a straightforward manner.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.04605v6"
    },
    {
        "title": "Credible equilibrium",
        "authors": [
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Credible equilibrium is a solution concept that imposes a stronger\ncredibility notion than subgame perfect equilibrium. A credible equilibrium is\na refinement of subgame perfect equilibrium such that if a threat in a subgame\ng is \"credible,\" then it must also be credible in every subgame g' that is\n\"equivalent\" to g. I show that (i) a credible equilibrium exists in multi-stage\ngames, and (ii) if every stage game has a unique Nash equilibrium, then the\ncredible equilibrium is unique even in infinite horizon multi-stage games.\nMoreover, in perfect information games, credible equilibrium is equivalent to\nsubgame perfect equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.05241v1"
    },
    {
        "title": "Social Media and Democracy",
        "authors": [
            "Ronen Gradwohl",
            "Yuval Heller",
            "Arye Hillman"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the ability of a social media platform with a political agenda to\ninfluence voting outcomes. Our benchmark is Condorcet's jury theorem, which\nstates that the likelihood of a correct decision under majority voting\nincreases with the number of voters. We show how information manipulation by a\nsocial media platform can overturn the jury theorem, thereby undermining\ndemocracy. We also show that sometimes the platform can do so only by providing\ninformation that is biased in the opposite direction of its preferred outcome.\nFinally, we compare manipulation of voting outcomes through social media to\nmanipulation through traditional media.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.14430v1"
    },
    {
        "title": "Optimal Multi-Dimensional Auctions: Conjectures and Simulations",
        "authors": [
            "Alexey Kushnir",
            "James Michelson"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We explore the properties of optimal multi-dimensional auctions in a model\nwhere a single object of multiple qualities is sold to several buyers. Using\nsimulations, we test some hypotheses conjectured by Belloni et al. [3] and\nKushnir and Shourideh [7]. As part of this work, we provide the first\nopen-source library for multi-dimensional auction simulations written in\nPython.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01664v1"
    },
    {
        "title": "With a little help from my friends: essentiality vs opportunity in group\n  criticality",
        "authors": [
            "Michele Aleandri",
            "Marco Dall'Aglio"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We define a notion of the criticality of a player for simple monotone games\nbased on cooperation with other players, either to form a winning coalition or\nto break a winning one, with an essential role for all the players involved. We\ncompare it with the notion of differential criticality given by Beisbart that\nmeasures power as the opportunity left by other players. We prove that our\nproposal satisfies an extension of the strong monotonicity introduced by Young,\nassigns no power to null players and does not reward free riders, and can\neasily be computed from the minimal winning and blocking coalitions. An\napplication to the Italian elections is presented. Our analysis shows that the\nmeasures of group criticality defined so far cannot weigh essential players\nwhile only remaining an opportunity measure. We propose a group opportunity\ntest to reconcile the two views.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.03565v5"
    },
    {
        "title": "Queueing games with an endogenous number of machines",
        "authors": [
            "Ata Atay",
            "Christian Trudeau"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies queueing problems with an endogenous number of machines\nwith and without an initial queue, the novelty being that coalitions not only\nchoose how to queue, but also on how many machines. For a given problem, agents\ncan (de)activate as many machines as they want, at a cost. After minimizing the\ntotal cost (processing costs and machine costs), we use a game theoretical\napproach to share to proceeds of this cooperation, and study the existence of\nstable allocations. First, we study queueing problems with an endogenous number\nof machines, and examine how to share the total cost. We provide an upper bound\nand a lower bound on the cost of a machine to guarantee the non-emptiness of\nthe core (the set of stable allocations). Next, we study requeueing problems\nwith an endogenous number of machines, where there is an existing queue. We\nexamine how to share the cost savings compared to the initial situation, when\noptimally requeueing/changing the number of machines. Although, in general,\nstable allocation may not exist, we guarantee the existence of stable\nallocations when all machines are considered public goods, and we start with an\ninitial schedule that might not have the optimal number of machines, but in\nwhich agents with large waiting costs are processed first.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07190v3"
    },
    {
        "title": "Stable Matching with Mistaken Agents",
        "authors": [
            "Georgy Artemov",
            "Yeon-Koo Che",
            "YingHua He"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Motivated by growing evidence of agents' mistakes in strategically simple\nenvironments, we propose a solution concept -- robust equilibrium -- that\nrequires only an asymptotically optimal behavior. We use it to study large\nrandom matching markets operated by the applicant-proposing Deferred Acceptance\n(DA). Although truth-telling is a dominant strategy, almost all applicants may\nbe non-truthful in robust equilibrium; however, the outcome must be arbitrarily\nclose to the stable matching. Our results imply that one can assume truthful\nagents to study DA outcomes, theoretically or counterfactually. However, to\nestimate the preferences of mistaken agents, one should assume stable matching\nbut not truth-telling.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.13939v4"
    },
    {
        "title": "Finite Tests from Functional Characterizations",
        "authors": [
            "Charles Gauthier",
            "Raghav Malhotra",
            "Agustin Troccoli Moretti"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Classically, testing whether decision makers belong to specific preference\nclasses involves two main approaches. The first, known as the functional\napproach, assumes access to an entire demand function. The second, the revealed\npreference approach, constructs inequalities to test finite demand data. This\npaper bridges these methods by using the functional approach to test finite\ndata through preference learnability results. We develop a computationally\nefficient algorithm that generates tests for choice data based on functional\ncharacterizations of preference families. We provide these restrictions for\nvarious applications, including homothetic and weakly separable preferences,\nwhere the latter's revealed preference characterization is provably NP-Hard. We\nalso address choice under uncertainty, offering tests for betweenness\npreferences. Lastly, we perform a simulation exercise demonstrating that our\ntests are effective in finite samples and accurately reject demands not\nbelonging to a specified class.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03737v5"
    },
    {
        "title": "Persuading Risk-Conscious Agents: A Geometric Approach",
        "authors": [
            "Jerry Anunrojwong",
            "Krishnamurthy Iyer",
            "David Lingenbrink"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider a persuasion problem between a sender and a receiver whose\nutility may be nonlinear in her belief; we call such receivers risk-conscious.\nSuch utility models arise when the receiver exhibits systematic biases away\nfrom expected-utility-maximization, such as uncertainty aversion (e.g., from\nsensitivity to the variance of the waiting time for a service). Due to this\nnonlinearity, the standard approach to finding the optimal persuasion mechanism\nusing revelation principle fails. To overcome this difficulty, we use the\nunderlying geometry of the problem to develop a convex optimization framework\nto find the optimal persuasion mechanism. We define the notion of full\npersuasion and use our framework to characterize conditions under which full\npersuasion can be achieved. We use our approach to study binary persuasion,\nwhere the receiver has two actions and the sender strictly prefers one of them\nat every state. Under a convexity assumption, we show that the binary\npersuasion problem reduces to a linear program, and establish a canonical set\nof signals where each signal either reveals the state or induces in the\nreceiver uncertainty between two states. Finally, we discuss the broader\napplicability of our methods to more general contexts, and illustrate our\nmethodology by studying information sharing of waiting times in service\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03758v3"
    },
    {
        "title": "Costly Evidence and Discretionary Disclosure",
        "authors": [
            "Mark Whitmeyer",
            "Kun Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A sender flexibly acquires evidence--which she may pay a third party to\ncertify--to disclose to a receiver. When evidence acquisition is overt, the\nreceiver observes the evidence gathering process irrespective of whether its\noutcome is certified. When acquisition is covert, the receiver does not. In\ncontrast to the case with exogenous evidence, the receiver prefers a strictly\npositive certification cost. As acquisition costs vanish, equilibria converge\nto the Pareto-worst free-learning equilibrium. The receiver always prefers\ncovert to overt evidence acquisition.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.04922v1"
    },
    {
        "title": "Impossibility theorems involving weakenings of expansion consistency and\n  resoluteness in voting",
        "authors": [
            "Wesley H. Holliday",
            "Chase Norman",
            "Eric Pacuit",
            "Saam Zahedian"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A fundamental principle of individual rational choice is Sen's $\\gamma$\naxiom, also known as expansion consistency, stating that any alternative chosen\nfrom each of two menus must be chosen from the union of the menus. Expansion\nconsistency can also be formulated in the setting of social choice. In voting\ntheory, it states that any candidate chosen from two fields of candidates must\nbe chosen from the combined field of candidates. An important special case of\nthe axiom is binary expansion consistency, which states that any candidate\nchosen from an initial field of candidates and chosen in a head-to-head match\nwith a new candidate must also be chosen when the new candidate is added to the\nfield, thereby ruling out spoiler effects. In this paper, we study the tension\nbetween this weakening of expansion consistency and weakenings of resoluteness,\nan axiom demanding the choice of a single candidate in any election. As is well\nknown, resoluteness is inconsistent with basic fairness conditions on social\nchoice, namely anonymity and neutrality. Here we prove that even significant\nweakenings of resoluteness, which are consistent with anonymity and neutrality,\nare inconsistent with binary expansion consistency. The proofs make use of SAT\nsolving, with the correctness of a SAT encoding formally verified in the Lean\nTheorem Prover, as well as a strategy for generalizing impossibility theorems\nobtained for special types of voting methods (namely majoritarian and pairwise\nvoting methods) to impossibility theorems for arbitrary voting methods. This\nproof strategy may be of independent interest for its potential applicability\nto other impossibility theorems in social choice.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.06907v3"
    },
    {
        "title": "An axiomatic theory for anonymized risk sharing",
        "authors": [
            "Zhanyi Jiao",
            "Steven Kou",
            "Yang Liu",
            "Ruodu Wang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study an axiomatic framework for anonymized risk sharing. In contrast to\ntraditional risk sharing settings, our framework requires no information on\npreferences, identities, private operations and realized losses from the\nindividual agents, and thereby it is useful for modeling risk sharing in\ndecentralized systems. Four axioms natural in such a framework -- actuarial\nfairness, risk fairness, risk anonymity, and operational anonymity -- are put\nforward and discussed. We establish the remarkable fact that the four axioms\ncharacterizes the conditional mean risk sharing rule, revealing the unique and\nprominent role of this popular risk sharing rule among all others in relevant\napplications of anonymized risk sharing. Several other properties and their\nrelations to the four axioms are studied, as well as their implications in\nrationalizing the design of some sharing mechanisms in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07533v4"
    },
    {
        "title": "Algorithmic Fairness and Statistical Discrimination",
        "authors": [
            "John W. Patty",
            "Elizabeth Maggie Penn"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Algorithmic fairness is a new interdisciplinary field of study focused on how\nto measure whether a process, or algorithm, may unintentionally produce unfair\noutcomes, as well as whether or how the potential unfairness of such processes\ncan be mitigated. Statistical discrimination describes a set of informational\nissues that can induce rational (i.e., Bayesian) decision-making to lead to\nunfair outcomes even in the absence of discriminatory intent. In this article,\nwe provide overviews of these two related literatures and draw connections\nbetween them. The comparison illustrates both the conflict between rationality\nand fairness and the importance of endogeneity (e.g., \"rational expectations\"\nand \"self-fulfilling prophecies\") in defining and pursuing fairness. Taken in\nconcert, we argue that the two traditions suggest a value for considering new\nfairness notions that explicitly account for how the individual characteristics\nan algorithm intends to measure may change in response to the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.08341v1"
    },
    {
        "title": "Ban The Box? Information, Incentives, and Statistical Discrimination",
        "authors": [
            "John W. Patty",
            "Elizabeth Maggie Penn"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  \"Banning the Box\" refers to a policy campaign aimed at prohibiting employers\nfrom soliciting applicant information that could be used to statistically\ndiscriminate against categories of applicants (in particular, those with\ncriminal records). In this article, we examine how the concealing or revealing\nof informative features about an applicant's identity affects hiring both\ndirectly and, in equilibrium, by possibly changing applicants' incentives to\ninvest in human capital. We show that there exist situations in which an\nemployer and an applicant are in agreement about whether to ban the box.\nSpecifically, depending on the structure of the labor market, banning the box\ncan be (1) Pareto dominant, (2) Pareto dominated, (3) benefit the applicant\nwhile harming the employer, or (4) benefit the employer while harming the\napplicant. Our results have policy implications spanning beyond employment\ndecisions, including the use of credit checks by landlords and standardized\ntests in college admissions.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.08348v1"
    },
    {
        "title": "Probabilistic risk aversion for generalized rank-dependent functions",
        "authors": [
            "Ruodu Wang",
            "Qinyu Wu"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Probabilistic risk aversion, defined through quasi-convexity in probabilistic\nmixtures, is a common useful property in decision analysis. We study a general\nclass of non-monotone mappings, called the generalized rank-dependent\nfunctions, which includes the preference models of expected utilities, dual\nutilities, and rank-dependent utilities as special cases, as well as signed\nChoquet functions used in risk management. Our results fully characterize\nprobabilistic risk aversion for generalized rank-dependent functions: This\nproperty is determined by the distortion function, which is precisely one of\nthe two cases: those that are convex and those that correspond to scaled\nquantile-spread mixtures. Our result also leads to seven equivalent conditions\nfor quasi-convexity in probabilistic mixtures of dual utilities and signed\nChoquet functions. As a consequence, although probabilistic risk aversion is\nquite different from the classic notion of strong risk aversion for generalized\nrank-dependent functions, these two notions coincide for dual utilities under\nan additional continuity assumption.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.03425v2"
    },
    {
        "title": "A Structural Model for Detecting Communities in Networks",
        "authors": [
            "Alex Centeno"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The objective of this paper is to identify and analyze the response actions\nof a set of players embedded in sub-networks in the context of interaction and\nlearning. We characterize strategic network formation as a static game of\ninteractions where players maximize their utility depending on the connections\nthey establish and multiple interdependent actions that permit group-specific\nparameters of players. It is challenging to apply this type of model to\nreal-life scenarios for two reasons: The computation of the Bayesian Nash\nEquilibrium is highly demanding and the identification of social influence\nrequires the use of excluded variables that are oftentimes unavailable. Based\non the theoretical proposal, we propose a set of simulant equations and discuss\nthe identification of the social interaction effect employing multi-modal\nnetwork autoregressive.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.08380v2"
    },
    {
        "title": "Rationality and correctness in n-player games",
        "authors": [
            "Lorenzo Bastianello",
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  There are two well-known sufficient conditions for Nash equilibrium in\ntwo-player games: mutual knowledge of rationality (MKR) and mutual knowledge of\nconjectures. MKR assumes that the concept of rationality is mutually known. In\ncontrast, mutual knowledge of conjectures assumes that a given profile of\nconjectures is mutually known, which has long been recognized as a strong\nassumption. In this note, we introduce a notion of \"mutual assumption of\nrationality and correctness\" (MARC), which conceptually aligns more closely\nwith the MKR assumption. We present two main results. Our first result\nestablishes that MARC holds in every two-person zero-sum game. In our second\ntheorem, we show that MARC does not in general hold in n-player games.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.09847v2"
    },
    {
        "title": "Rank-preserving Multidimensional Mechanisms: an equivalence between\n  identical-object and heterogeneous-object models",
        "authors": [
            "Sushil Bikhchandani",
            "Debasis Mishra"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We show that the mechanism-design problem for a monopolist selling multiple,\nheterogeneous objects to a buyer with ex ante symmetric and additive values is\nequivalent to the mechanism-design problem for a monopolist selling identical\nobjects to a buyer with decreasing marginal values. We derive three new results\nfor the identical-objects model: (i) a new condition for revenue monotonicity\nof stochastic mechanisms, (ii) a sufficient condition on priors, such that\nprices in optimal deterministic mechanism are not increasing, and (iii) a\nsimplification of incentive constraints for deterministic mechanisms. We use\nthe equivalence to establish corresponding results in the heterogeneous-objects\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.10137v6"
    },
    {
        "title": "Exploring the Constraints on Artificial General Intelligence: A\n  Game-Theoretic No-Go Theorem",
        "authors": [
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The emergence of increasingly sophisticated artificial intelligence (AI)\nsystems have sparked intense debate among researchers, policymakers, and the\npublic due to their potential to surpass human intelligence and capabilities in\nall domains. In this paper, I propose a game-theoretic framework that captures\nthe strategic interactions between a human agent and a potential superhuman\nmachine agent. I identify four key assumptions: Strategic Unpredictability,\nAccess to Machine's Strategy, Rationality, and Superhuman Machine. The main\nresult of this paper is an impossibility theorem: these four assumptions are\ninconsistent when taken together, but relaxing any one of them results in a\nconsistent set of assumptions. Two straightforward policy recommendations\nfollow: first, policymakers should control access to specific human data to\nmaintain Strategic Unpredictability; and second, they should grant select AI\nresearchers access to superhuman machine research to ensure Access to Machine's\nStrategy holds. My analysis contributes to a better understanding of the\ncontext that can shape the theoretical development of superhuman AI.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12346v2"
    },
    {
        "title": "Learning from Viral Content",
        "authors": [
            "Krishna Dasaratha",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study learning on social media with an equilibrium model of users\ninteracting with shared news stories. Rational users arrive sequentially,\nobserve an original story (i.e., a private signal) and a sample of\npredecessors' stories in a news feed, and then decide which stories to share.\nThe observed sample of stories depends on what predecessors share as well as\nthe sampling algorithm generating news feeds. We focus on how often this\nalgorithm selects more viral (i.e., widely shared) stories. Showing users viral\nstories can increase information aggregation, but it can also generate steady\nstates where most shared stories are wrong. These misleading steady states\nself-perpetuate, as users who observe wrong stories develop wrong beliefs, and\nthus rationally continue to share them. Finally, we describe several\nconsequences for platform design and robustness.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.01267v2"
    },
    {
        "title": "Approximate optimality and the risk/reward tradeoff in a class of bandit\n  problems",
        "authors": [
            "Zengjing Chen",
            "Larry G. Epstein",
            "Guodong Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper studies a sequential decision problem where payoff distributions\nare known and where the riskiness of payoffs matters. Equivalently, it studies\nsequential choice from a repeated set of independent lotteries. The\ndecision-maker is assumed to pursue strategies that are approximately optimal\nfor large horizons. By exploiting the tractability afforded by asymptotics,\nconditions are derived characterizing when specialization in one action or\nlottery throughout is asymptotically optimal and when optimality requires\nintertemporal diversification. The key is the constancy or variability of risk\nattitude. The main technical tool is a new central limit theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.08077v2"
    },
    {
        "title": "AI-powered mechanisms as judges: Breaking ties in chess",
        "authors": [
            "Nejat Anbarci",
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Recently, Artificial Intelligence (AI) technology use has been rising in\nsports to reach decisions of various complexity. At a relatively low complexity\nlevel, for example, major tennis tournaments replaced human line judges with\nHawk-Eye Live technology to reduce staff during the COVID-19 pandemic. AI is\nnow ready to move beyond such mundane tasks, however. A case in point and a\nperfect application ground is chess. To reduce the growing incidence of ties,\nmany elite tournaments have resorted to fast chess tiebreakers. However, these\ntiebreakers significantly reduce the quality of games. To address this issue,\nwe propose a novel AI-driven method for an objective tiebreaking mechanism.\nThis method evaluates the quality of players' moves by comparing them to the\noptimal moves suggested by powerful chess engines. If there is a tie, the\nplayer with the higher quality measure wins the tiebreak. This approach not\nonly enhances the fairness and integrity of the competition but also maintains\nthe game's high standards. To show the effectiveness of our method, we apply it\nto a dataset comprising approximately 25,000 grandmaster moves from World Chess\nChampionship matches spanning from 1910 to 2018, using Stockfish 16, a leading\nchess AI, for analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.08289v3"
    },
    {
        "title": "Leverage, Endogenous Unbalanced Growth, and Asset Price Bubbles",
        "authors": [
            "Tomohiro Hirano",
            "Ryo Jinnai",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We present a general equilibrium macro-finance model with a positive feedback\nloop between capital investment and land price. As leverage is relaxed beyond a\ncritical value, through the financial accelerator, a phase transition occurs\nfrom balanced growth where land prices reflect fundamentals (present value of\nrents) to unbalanced growth where land prices grow faster than rents,\ngenerating land price bubbles. Unbalanced growth dynamics and bubbles are\nassociated with financial loosening and technological progress. In an\nanalytically tractable two-sector large open economy model with unique\nequilibria, financial loosening simultaneously leads to low interest rates,\nasset overvaluation, and top-end wealth concentration.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.13100v7"
    },
    {
        "title": "A Rigorous Proof of the Index Theorem for Economists",
        "authors": [
            "Yuhki Hosoya"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper provides a rigorous and gap-free proof of the index theorem used\nin the theory of regular economy. In the index theorem that is the subject of\nthis paper, the assumptions for the excess demand function are only several\nusual assumptions and continuous differentiability around any equilibrium\nprice, and thus it has a form that is applicable to many economies. However,\nthe textbooks on this theme contain only abbreviated proofs and there is no\nknown monograph that contains a rigorous proof of this theorem. Hence, the\npurpose of this paper is to make this theorem available to more economists by\nconstructing a readable proof.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.14272v3"
    },
    {
        "title": "Average Profits of Prejudiced Algorithms",
        "authors": [
            "David J. Jin"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We investigate the level of success a firm achieves depending on which of two\ncommon scoring algorithms is used to screen qualified applicants belonging to a\ndisadvantaged group. Both algorithms are trained on data generated by a\nprejudiced decision-maker independently of the firm. One algorithm favors\ndisadvantaged individuals, while the other algorithm exemplifies prejudice in\nthe training data. We deliver sharp guarantees for when the firm finds more\nsuccess with one algorithm over the other, depending on the prejudice level of\nthe decision-maker.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00578v2"
    },
    {
        "title": "A Characterization of Maximum Nash Welfare for Indivisible Goods",
        "authors": [
            "Warut Suksompong"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In the allocation of indivisible goods, the maximum Nash welfare (MNW) rule,\nwhich chooses an allocation maximizing the product of the agents' utilities,\nhas received substantial attention for its fairness. We characterize MNW as the\nonly additive welfarist rule that satisfies envy-freeness up to one good. Our\ncharacterization holds even in the simplest setting of two agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.04203v2"
    },
    {
        "title": "School Choice with Farsighted Students",
        "authors": [
            "Ata Atay",
            "Ana Mauleon",
            "Vincent Vannetelbosch"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider priority-based school choice problems with farsighted students.\nWe show that a singleton set consisting of the matching obtained from the Top\nTrading Cycles (TTC) mechanism is a farsighted stable set. However, the\nmatching obtained from the Deferred Acceptance (DA) mechanism may not belong to\nany farsighted stable set. Hence, the TTC mechanism provides an assignment that\nis not only Pareto efficient but also farsightedly stable. Moreover, looking\nforward three steps ahead is already sufficient for stabilizing the matching\nobtained from the TTC.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07108v1"
    },
    {
        "title": "Limited Farsightedness in Priority-Based Matching",
        "authors": [
            "Ata Atay",
            "Ana Mauleon",
            "Vincent Vannetelbosch"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider priority-based matching problems with limited farsightedness. We\nshow that, once agents are sufficiently farsighted, the matching obtained from\nthe Top Trading Cycles (TTC) algorithm becomes stable: a singleton set\nconsisting of the TTC matching is a horizon-$k$ vNM stable set if the degree of\nfarsightedness is greater than three times the number of agents in the largest\ncycle of the TTC. On the contrary, the matching obtained from the Deferred\nAcceptance (DA) algorithm may not belong to any horizon-$k$ vNM stable set for\n$k$ large enough.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07427v1"
    },
    {
        "title": "Dynamic spending and portfolio decisions with a soft social norm",
        "authors": [
            "Knut Anton Mork",
            "Fabian Andsem Harang",
            "Haakon Andreas Trønnes",
            "Vegard Skonseng Bjerketvedt"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We explore the implications of a preference ordering for an investor-consumer\nwith a strong preference for keeping consumption above an exogenous social\nnorm, but who is willing to tolerate occasional dips below it. We do this by\nsplicing two CRRA preference orderings, one with high curvature below the norm\nand the other with low curvature at or above it. We find this formulation\nappealing for many endowment funds and sovereign wealth funds, including the\nNorwegian Government Pension Fund Global, which inspired our research. We solve\nthis model analytically as well as numerically and find that annual spending\nshould not only be significantly lower than the expected financial return, but\nmostly also procyclical. In particular, financial losses should, as a rule, be\nfollowed by larger than proportional spending cuts, except when some smoothing\nis needed to keep spending from falling too far below the social norm. Yet, at\nvery low wealth levels, spending should be kept particularly low in order to\nbuild sufficient wealth to raise consumption above the social norm. Financial\nrisk taking should also be modest and procyclical, so that the investor\nsometimes may want to \"buy at the top\" and \"sell at the bottom\". Many of these\nfeatures are shared by habitformation models and other models with some lower\nbound for consumption. However, our specification is more flexible and thus\nmore easily adaptable to actual fund management. The nonlinearity of the policy\nfunctions may present challenges regarding delegation to professional managers.\nHowever, simpler rules of thumb with constant or slowly moving equity share and\nconsumption-wealth ratio can reach almost the same expected discounted utility.\nHowever, the constant levels will then look very different from the\nimplications of expected CRRA utility or Epstein-Zin preferences in that\nconsumption is much lower.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.10053v1"
    },
    {
        "title": "Self-progressive choice models",
        "authors": [
            "Kemal Yildiz"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Consider a population of heterogenous agents whose choice behaviors are\npartially \\textit{comparable} according to a given \\textit{primitive\nordering}.The set of choice functions admissible in the population specifies a\n\\textit{choice model}. As a criterion to guide the model selection process, we\npropose \\textit{self-progressiveness}, ensuring that each aggregate choice\nbehavior explained by the model has a unique orderly representation within the\nmodel itself. We establish an equivalence between self-progressive choice\nmodels and well-known algebraic structures called \\textit{lattices}.\n  This equivalence provides for a precise recipe to restrict or extend any\nchoice model for unique orderly representation. Following this recipe, we\nidentify the set of choice functions that are essential for the unique orderly\nrepresentation of random utility functions. This extended model offers an\nintuitive explanation for the \\textit{choice overload} phenomena. We provide\nthe necessary and sufficient conditions for identifying the underlying\nprimitive ordering.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.13449v11"
    },
    {
        "title": "Informationally Robust Cheap-Talk",
        "authors": [
            "Itai Arieli",
            "Ronen Gradwohl",
            "Rann Smorodinsky"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the robustness of cheap-talk equilibria to infinitesimal private\ninformation of the receiver in a model with a binary state-space and\nstate-independent sender-preferences. We show that the sender-optimal\nequilibrium is robust if and only if this equilibrium either reveals no\ninformation to the receiver or fully reveals one of the states with positive\nprobability. We then characterize the actions that can be played with positive\nprobability in any robust equilibrium. Finally, we fully characterize the\noptimal sender-utility under binary receiver's private information, and provide\nbounds for the optimal sender-utility under general private information.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00281v1"
    },
    {
        "title": "Signaling Games with Costly Monitoring",
        "authors": [
            "Reuben Bearman"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  If in a signaling game the receiver expects to gain no information by\nmonitoring the signal of the sender, then when a cost to monitor is implemented\nhe will never pay that cost regardless of his off-path beliefs. This is the\nargument of a recent paper by T. Denti (2021). However, which pooling\nequilibrium does a receiver anticipate to gain no information through\nmonitoring? This paper seeks to prove that given a sufficiently small cost to\nmonitor any pooling equilibrium with a non-zero index will survive close to the\noriginal equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.01116v1"
    },
    {
        "title": "On the Difficulty of Characterizing Network Formation with Endogenous\n  Behavior",
        "authors": [
            "Benjamin Golub",
            "Yu-Chi Hsieh",
            "Evan Sadler"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Bolletta (2021, Math. Soc. Sci. 114:1-10) studies a model in which a network\nis strategically formed and then agents play a linear best-response investment\ngame in it. The model is motivated by an application in which people choose\nboth their study partners and their levels of educational effort. Agents have\ndifferent one-dimensional types $\\unicode{x2013}$ private returns to effort. A\nmain result claims that pairwise Nash stable networks have a locally complete\nstructure consisting of possibly overlapping cliques: if two agents are linked,\nthey are part of a clique composed of all agents with types between theirs. We\noffer a counterexample showing that the claimed characterization is incorrect,\nhighlight where the analysis errs, and discuss implications for network\nformation models.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05831v2"
    },
    {
        "title": "Welfare Distribution in Two-sided Random Matching Markets",
        "authors": [
            "Itai Ashlagi",
            "Mark Braverman",
            "Geng Zhao"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the welfare structure in two-sided large random matching markets. In\nthe model, each agent has a latent personal score for every agent on the other\nside of the market and her preferences follow a logit model based on these\nscores. Under a contiguity condition, we provide a tight description of stable\noutcomes. First, we identify an intrinsic fitness for each agent that\nrepresents her relative competitiveness in the market, independent of the\nrealized stable outcome. The intrinsic fitness values correspond to scaling\ncoefficients needed to make a latent mutual matrix bi-stochastic, where the\nlatent scores can be interpreted as a-priori probabilities of a pair being\nmatched. Second, in every stable (or even approximately stable) matching, the\nwelfare or the ranks of the agents on each side of the market, when scaled by\ntheir intrinsic fitness, have an approximately exponential empirical\ndistribution. Moreover, the average welfare of agents on one side of the market\nis sufficient to determine the average on the other side. Overall, each agent's\nwelfare is determined by a global parameter, her intrinsic fitness, and an\nextrinsic factor with exponential distribution across the population.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.08599v1"
    },
    {
        "title": "Nash equilibrium selection by eigenvalue control",
        "authors": [
            "Wang Zhijian"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  People choose their strategies through a trial-and-error learning process in\nwhich they gradually discover that some strategies work better than others. The\nprocess can be modelled as an evolutionary game dynamics system, which may be\ncontrollable. In modern control theory, eigenvalue (pole) assignment is a basic\napproach to designing a full-state feedback controller, which can influence the\noutcome of a game. This study shows that, in a game with two Nash equilibria,\nthe long-running strategy distribution can be controlled by pole assignment. We\nillustrate a theoretical workflow to design and evaluate the controller. To our\nknowledge, this is the first realisation of the control of equilibrium\nselection by design in the game dynamics theory paradigm. We hope the\ncontroller can be verified in a laboratory human subject game experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09131v1"
    },
    {
        "title": "Screening Signal-Manipulating Agents via Contests",
        "authors": [
            "Yingkai Li",
            "Xiaoyun Qiu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the design of screening mechanisms subject to competition and\nmanipulation. A social planner has limited resources to allocate to multiple\nagents using only signals manipulable through unproductive effort. We show that\nthe welfare-maximizing mechanism takes the form of a contest and characterize\nthe optimal contest. We apply our results to two settings: either the planner\nhas one item or a number of items proportional to the number of agents. We show\nthat in both settings, with sufficiently many agents, a winner-takes-all\ncontest is never optimal. In particular, the planner always benefits from\nrandomizing the allocation to some agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09168v2"
    },
    {
        "title": "Pulse in collapse: a game dynamics experiment",
        "authors": [
            "Wang Yijia",
            "Wang Zhijian"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The collapse process is a constitutional sub-process in the full finding Nash\nequilibrium process. We conducted laboratory game experiments with human\nsubjects to study this process. We observed significant pulse signals in the\ncollapse process. The observations from the data support the completeness and\nthe consistency of the game dynamics paradigm.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09336v1"
    },
    {
        "title": "Does Machine Learning Amplify Pricing Errors in the Housing Market? --\n  The Economics of Machine Learning Feedback Loops",
        "authors": [
            "Nikhil Malik",
            "Emaad Manzoor"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Machine learning algorithms are increasingly employed to price or value homes\nfor sale, properties for rent, rides for hire, and various other goods and\nservices. Machine learning-based prices are typically generated by complex\nalgorithms trained on historical sales data. However, displaying these prices\nto consumers anchors the realized sales prices, which will in turn become\ntraining samples for future iterations of the algorithms. The economic\nimplications of this machine learning \"feedback loop\" - an indirect\nhuman-algorithm interaction - remain relatively unexplored. In this work, we\ndevelop an analytical model of machine learning feedback loops in the context\nof the housing market. We show that feedback loops lead machine learning\nalgorithms to become overconfident in their own accuracy (by underestimating\nits error), and leads home sellers to over-rely on possibly erroneous\nalgorithmic prices. As a consequence at the feedback loop equilibrium, sale\nprices can become entirely erratic (relative to true consumer preferences in\nabsence of ML price interference). We then identify conditions (choice of ML\nmodels, seller characteristics and market characteristics) where the economic\npayoffs for home sellers at the feedback loop equilibrium is worse off than no\nmachine learning. We also empirically validate primitive building blocks of our\nanalytical model using housing market data from Zillow. We conclude by\nprescribing algorithmic corrective strategies to mitigate the effects of\nmachine learning feedback loops, discuss the incentives for platforms to adopt\nthese strategies, and discuss the role of policymakers in regulating the same.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09438v1"
    },
    {
        "title": "Effort Discrimination and Curvature of Contest Technology in Conflict\n  Networks",
        "authors": [
            "Xiang Sun",
            "Jin Xu",
            "Junjie Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In a model of interconnected conflicts on a network, we compare the\nequilibrium effort profiles and payoffs under two scenarios: uniform effort\n(UE) in which each contestant is restricted to exert the same effort across all\nthe battles she participates, and discriminatory effort (DE) in which such a\nrestriction is lifted. When the contest technology in each battle is of Tullock\nform, a surprising neutrality result holds within the class of semi-symmetric\nconflict network structures: both the aggregate actions and equilibrium payoffs\nunder two regimes are the same. We also show that, in some sense, the Tullock\nform is necessary for such a neutrality result. Moving beyond the Tullock\nfamily, we further demonstrate how the curvature of contest technology shapes\nthe welfare and effort effects.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09861v2"
    },
    {
        "title": "Human and Machine Intelligence in n-Person Games with Partial Knowledge:\n  Theory and Computation",
        "authors": [
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, I formalize intelligence measurement in games by introducing\nmechanisms that assign a real number -- interpreted as an intelligence score --\nto each player in a game. This score quantifies the ex-post strategic ability\nof the players based on empirically observable information, such as the actions\nof the players, the game's outcome, strength of the players, and a reference\noracle machine such as a chess-playing artificial intelligence system.\nSpecifically, I introduce two main concepts: first, the Game Intelligence (GI)\nmechanism, which quantifies a player's intelligence in a game by considering\nnot only the game's outcome but also the \"mistakes\" made during the game\naccording to the reference machine's intelligence. Second, I define\ngamingproofness, a practical and computational concept of strategyproofness. To\nillustrate the GI mechanism, I apply it to an extensive dataset comprising over\na billion chess moves, including over a million moves made by top 20\ngrandmasters in history. Notably, Magnus Carlsen emerges with the highest GI\nscore among all world championship games included in the dataset. In\nmachine-vs-machine games, the well-known chess engine Stockfish comes out on\ntop.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.13937v4"
    },
    {
        "title": "Robust Hicksian Welfare Analysis under Individual Heterogeneity",
        "authors": [
            "Sebastiaan Maes",
            "Raghav Malhotra"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Welfare effects of price changes are often estimated with cross-sections;\nthese do not identify demand with heterogeneous consumers. We develop a\ntheoretical method addressing this, utilizing uncompensated demand moments to\nconstruct local approximations for compensated demand moments, robust to\nunobserved preference heterogeneity. Our methodological contribution offers\nrobust approximations for average and distributional welfare estimates,\nextending to price indices, taxable income elasticities, and general\nequilibrium welfare. Our methods apply to any cross-section; we demonstrate\nthem via UK household budget survey data. We uncover an insight: simple\nnon-parametric representative agent models might be less biased than complex\nparametric models accounting for heterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.01231v3"
    },
    {
        "title": "Fairer Shootouts in Soccer: The $m-n$ Rule",
        "authors": [
            "Steven J. Brams",
            "Mehmet S. Ismail",
            "D. Marc Kilgour"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Winning the coin toss at the end of a tied soccer game gives a team the right\nto choose whether to kick either first or second on all five rounds of penalty\nkicks, when each team is allowed one kick per round. There is considerable\nevidence that the right to make this choice, which is usually to kick first,\ngives a team a significant advantage. To make the outcome of a tied game\nfairer, we suggest a rule that handicaps the team that kicks first (A),\nrequiring it to succeed on one more penalty kick than the team that kicks\nsecond (B). We call this the $m - n$ rule and, more specifically, propose $(m,\nn)$ = (5, 4): For A to win, it must successfully kick 5 goals before the end of\nthe round in which B kicks its 4th; for B to win, it must succeed on 4 penalty\nkicks before A succeeds on 5. If both teams reach (5, 4) on the same round --\nwhen they both kick successfully at (4, 3) -- then the game is decided by\nround-by-round \"sudden death,\" whereby the winner is the first team to score in\na subsequent round when the other team does not. We show that this rule is fair\nin tending to equalize the ability of each team to win a tied game in a penalty\nshootout. We also discuss a related rule that precludes the teams from reaching\n(5, 4) at the same time, obviating the need for sudden death and extra rounds.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.04807v1"
    },
    {
        "title": "A Distributionally Robust Random Utility Model",
        "authors": [
            "David Müller",
            "Emerson Melo",
            "Ruben Schlotter"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper introduces the distributionally robust random utility model\n(DRO-RUM), which allows the preference shock (unobserved heterogeneity)\ndistribution to be misspecified or unknown. We make three contributions using\ntools from the literature on robust optimization. First, by exploiting the\nnotion of distributionally robust social surplus function, we show that the\nDRO-RUM endogenously generates a shock distributionthat incorporates a\ncorrelation between the utilities of the different alternatives. Second, we\nshow that the gradient of the distributionally robust social surplus yields the\nchoice probability vector. This result generalizes the celebrated\nWilliam-Daly-Zachary theorem to environments where the shock distribution is\nunknown. Third, we show how the DRO-RUM allows us to nonparametrically identify\nthe mean utility vector associated with choice market data. This result extends\nthe demand inversion approach to environments where the shock distribution is\nunknown or misspecified. We carry out several numerical experiments comparing\nthe performance of the DRO-RUM with the traditional multinomial logit and\nprobit models.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.05888v1"
    },
    {
        "title": "Distributionally Robust Principal-Agent Problems and Optimality of\n  Contracts",
        "authors": [
            "Peter Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We propose a distributionally robust principal agent formulation, which\ngeneralizes some common variants of worst-case and Bayesian principal agent\nproblems. We construct a theoretical framework to certify whether any\nsurjective contract family is optimal, and bound its sub-optimality. We then\napply the framework to study the optimality of affine contracts. We show with\ngeometric intuition that these simple contract families are optimal when the\nsurplus function is convex and there exists a technology type that is\nsimultaneously least productive and least efficient. We also provide succinct\nexpressions to quantify the optimality gap of any surplus function, based on\nits concave biconjugate. This new framework complements the current literature\nin two ways: invention of a new toolset; understanding affine contracts'\nperformance in a larger landscape. Our results also shed light on the technical\nroots of this question: why are there more positive results in the recent\nliterature that show simple contracts' optimality in robust settings rather\nthan stochastic settings? This phenomenon is related to two technical facts:\nthe sum of quasi-concave functions is not quasi-concave, and the maximization\nand expectation operators do not commute.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07468v2"
    },
    {
        "title": "Expected Utility from a Constructive Viewpoint",
        "authors": [
            "Kislaya Prasad"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper introduces a space of variable lotteries and proves a constructive\nversion of the expected utility theorem. The word ``constructive'' is used here\nin two senses. First, as in constructive mathematics, the logic underlying\nproofs is intuitionistic. In a second sense of the word, ``constructive'' is\ntaken to mean ``built up from smaller components.'' Lotteries as well as\npreferences vary continuously over some topological space. The topology encodes\nobservability or verifiability restrictions -- the open sets of the topology\nserve as the possible truth values of assertions about preference and reflect\nconstraints on the ability to measure, deduce, or observe. Replacing an open\nset by a covering of smaller open sets serves as a notion of refinement of\ninformation. Within this framework, inability to compare arises as a phenomenon\ndistinct from indifference and this gives rise to the constructive failure of\nthe classical expected utility theorem. A constructive version of the theorem\nis then proved, and accomplishes several things. First, the representation\ntheorem uses continuous real-valued functions as indicators of preference for\nvariable lotteries and these functions reflect the inability to compare\nphenomenon. Second, conditions are provided whereby local representations of\npreference over open sets can be collated to provide a global representation.\nThird, the proofs are constructive and do not use the law of the excluded\nmiddle, which may not hold for variable lotteries. Fourth, a version of the\nclassical theorem is obtained by imposing a condition on the collection of open\nsets of the topology which has the effect of making the logic classical.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08633v2"
    },
    {
        "title": "Physics Breakthrough Disproves Fundamental Assumptions of the Chicago\n  School",
        "authors": [
            "Cortelyou C. Kenney"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Classical law and economics is foundational to the American legal system.\nCentered at the University of Chicago, its assumptions, most especially that\nhumans act both rationally and selfishly, informs the thinking of legislatures,\njudges, and government lawyers, and has shaped nearly every aspect of the way\ncommercial transactions are conducted. But what if the Chicago School, as I\nrefer to this line of thinking, is wrong? Alternative approaches such as\nbehavioral law and economics or law and political economy contend that human\ndecisionmaking is based on emotions or should not be regulated as a social\ngeometry of bargains. This Article proposes a different and wholly novel reason\nthat the Chicago School is wrong: a fundamental assumption central to many of\nits game theory models has been disproven. This Article shows that a 2012\nbreakthrough from world famous physicist Freeman Dyson shocked the world of\ngame theory. This Article shows that Chicago School game theorists are wrong on\ntheir own terms because these 2 x 2 games such as the Prisoner's Dilemma,\nChicken, and Snowdrift, ostensibly based on mutual defection and corrective\njustice, in fact yield to an insight of pure cooperation. These new game theory\nsolutions can be scaled to design whole institutions and systems that honor the\npure cooperation insight, holding out the possibility of cracking large scale\nsocial dilemmas like the tragedy of the commons. It demonstrates that, in such\nsystems, pure cooperation is the best answer in the right environment and in\nthe long run. It ends by calling for a new legal field to redesign the\nstructures based on the outdated assumptions of the Chicago School game\ntheorists.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.09321v1"
    },
    {
        "title": "Dynamic Combinatorial Assignment",
        "authors": [
            "Thành Nguyen",
            "Alexander Teytelboym",
            "Shai Vardi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a model of dynamic combinatorial assignment of indivisible objects\nwithout money. We introduce a new solution concept called ``dynamic approximate\ncompetitive equilibrium from equal incomes'' (DACEEI), which stipulates that\nmarkets must approximately clear in almost all time periods. A naive repeated\napplication of approximate competitive equilibrium from equal incomes (Budish,\n2011) does not yield a desirable outcome because the approximation error in\nmarket-clearing compounds quickly over time. We therefore develop a new version\nof the static approximate competitive equilibrium from carefully constructed\nrandom budgets which ensures that, in expectation, markets clear exactly. We\nthen use it to design the ``online combinatorial assignment mechanism'' (OCAM)\nwhich implements a DACEEI with high probability. The OCAM is (i)\ngroup-strategyproof up to one object (ii) envy-free up to one object for almost\nall agents (iii) approximately market-clearing in almost all periods with high\nprobability when the market is large and arrivals are random. Applications\ninclude refugee resettlement, daycare assignment, and airport slot allocation.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.13967v1"
    },
    {
        "title": "An Alternative Approach for Nonparametric Analysis of Random Utility\n  Models",
        "authors": [
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We readdress the problem of nonparametric statistical testing of random\nutility models proposed in Kitamura and Stoye (2018). Although their test is\nelegant, it is subject to computational constraints which leaves execution of\nthe test infeasible in many applications. We note that much of the\ncomputational burden in Kitamura and Stoye's test is due to their test defining\na polyhedral cone through its vertices rather than its faces. We propose an\nalternative but equivalent hypothesis test for random utility models. This test\nrelies on a series of equality and inequality constraints which defines the\nfaces of the corresponding polyhedral cone. Building on our testing procedure,\nwe develop a novel axiomatization of the random utility model. Our new axiom\ncan be interpreted as a condition on surplus allocation in cooperative games.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.14249v4"
    },
    {
        "title": "Weighted Fair Division with Matroid-Rank Valuations: Monotonicity and\n  Strategyproofness",
        "authors": [
            "Warut Suksompong",
            "Nicholas Teh"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the problem of fairly allocating indivisible goods to agents with\nweights corresponding to their entitlements. Previous work has shown that, when\nagents have binary additive valuations, the maximum weighted Nash welfare rule\nis resource-, population-, and weight-monotone, satisfies\ngroup-strategyproofness, and can be implemented in polynomial time. We\ngeneralize these results to the class of weighted additive welfarist rules with\nconcave functions and agents with matroid-rank (also known as binary\nsubmodular) valuations.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.14454v2"
    },
    {
        "title": "The Value of Information and Circular Settings",
        "authors": [
            "Stefan Behringer",
            "Roman V. Belavkin"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We present a universal concept for the Value of Information (VoI), based on\nthe works of Claude Shannon's and Ruslan Stratonovich that can take into\naccount very general preferences of the agents and results in a single number.\nAs such it is convenient for applications and also has desirable properties for\ndecision theory and demand analysis. The Shannon/Stratonovich VoI concept is\ncompared to alternatives and applied in examples. In particular we apply the\nconcept to a circular spatial structure well known from many economic models\nand allow for various economic transport costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16126v2"
    },
    {
        "title": "Decentralized Attack Search and the Design of Bug Bounty Schemes",
        "authors": [
            "Hans Gersbach",
            "Akaki Mamageishvili",
            "Fikri Pitsuwan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Systems and blockchains often have security vulnerabilities and can be\nattacked by adversaries, with potentially significant negative consequences.\nTherefore, infrastructure providers increasingly rely on bug bounty programs,\nwhere external individuals probe the system and report any vulnerabilities\n(bugs) in exchange for rewards (bounty). We develop a simple contest model of\nbug bounty. A group of individuals of arbitrary size is invited to undertake a\ncostly search for bugs. The individuals differ with regard to their abilities,\nwhich we capture by different costs to achieve a certain probability to find\nbugs if any exist. Costs are private information. We study equilibria of the\ncontest and characterize the optimal design of bug bounty schemes. In\nparticular, the designer can vary the size of the group of individuals invited\nto search, add a paid expert, insert an artificial bug with some probability,\nand pay multiple prizes.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.00077v2"
    },
    {
        "title": "Should the Timing of Inspections be Predictable?",
        "authors": [
            "Ian Ball",
            "Jan Knoepfle"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A principal hires an agent to work on a long-term project that culminates in\na breakthrough or a breakdown. At each time, the agent privately chooses to\nwork or shirk. Working increases the arrival rate of breakthroughs and\ndecreases the arrival rate of breakdowns. To motivate the agent to work, the\nprincipal conducts costly inspections. She fires the agent if shirking is\ndetected. We characterize the principal's optimal inspection policy.\nPredictable inspections are optimal if work primarily generates breakthroughs.\nRandom inspections are optimal if work primarily prevents breakdowns.\nCrucially, the agent's actions determine his risk attitude over the timing of\npunishments.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01385v4"
    },
    {
        "title": "Wardrop Equilibrium Can Be Boundedly Rational: A New Behavioral Theory\n  of Route Choice",
        "authors": [
            "Jiayang Li",
            "Zhaoran Wang",
            "Yu Marco Nie"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  As one of the most fundamental concepts in transportation science, Wardrop\nequilibrium (WE) has always had a relatively weak behavioral underpinning. To\nstrengthen this foundation, one must reckon with bounded rationality in human\ndecision-making processes, such as the lack of accurate information, limited\ncomputing power, and sub-optimal choices. This retreat from behavioral\nperfectionism in the literature, however, was typically accompanied by a\nconceptual modification of WE. Here, we show that giving up perfect rationality\nneed not force a departure from WE. On the contrary, WE can be reached with\nglobal stability in a routing game played by boundedly rational travelers. We\nachieve this result by developing a day-to-day (DTD) dynamical model that\nmimics how travelers gradually adjust their route valuations, hence choice\nprobabilities, based on past experiences. Our model, called cumulative logit\n(CumLog), resembles the classical DTD models but makes a crucial change:\nwhereas the classical models assume routes are valued based on the cost\naveraged over historical data, ours values the routes based on the cost\naccumulated. To describe route choice behaviors, the CumLog model only uses two\nparameters, one accounting for the rate at which the future route cost is\ndiscounted in the valuation relative to the past ones and the other describing\nthe sensitivity of route choice probabilities to valuation differences. We\nprove tha CumLog always converges to WE, regardless of the initial point, as\nlong as the behavioral parameters satisfy certain mild conditions. Our theory\nthus upholds WE's role as a benchmark in transportation systems analysis. It\nalso resolves the theoretical challenge posed by Harsanyi's instability problem\nby explaining why equally good routes at WE are selected with different\nprobabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02500v2"
    },
    {
        "title": "Contingent Fees in Order Flow Auctions",
        "authors": [
            "Max Resnick"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Many early order flow auction designs handle the payment for orders when they\nexecute on the chain rather than when they are won in the auction. Payments in\nthese auctions only take place when the orders are executed, creating a free\noption for whoever wins the order. Bids in these auctions set the strike price\nof this option rather than the option premium. This paper develops a simple\nmodel of an order flow auction and compares contingent fees with upfront\npayments as well as mixtures of the two. Results suggest that auctions with a\ngreater share of the payment contingent on execution have lower execution\nprobability, lower revenue, and increased effective spreads in equilibrium. A\nReputation system can act as a negative contingent fee, partially mitigating\nthe downsides; however, unless the system is calibrated perfectly, some of the\nundesirable qualities of the contingent fees remain. Results suggest that\ndesigners of order flow auctions should avoid contingent fees whenever\npossible.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.04981v1"
    },
    {
        "title": "How Do Digital Advertising Auctions Impact Product Prices?",
        "authors": [
            "Dirk Bergemann",
            "Alessandro Bonatti",
            "Nicholas Wu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We present a model of digital advertising with three key features: (i)\nadvertisers can reach consumers on and off a platform, (ii) additional data\nenhances the value of advertiser-consumer matches, and (iii) bidding follows\nauction-like mechanisms. We contrast data-augmented auctions, which leverage\nthe platform's data advantage to improve match quality, and managed campaign\nmechanisms that automate match formation and price-setting. The\nplatform-optimal mechanism is a managed campaign that conditions on-platform\nprices for sponsored products on the off-platform prices set by all\nadvertisers. This mechanism yields the efficient on-platform allocation but\ninefficient off-platform allocations due to high product prices; it attains the\nvertical integration profit for the platform and advertisers; and it increases\noff-platform product prices and decreases consumer surplus, relative to\ndata-augmented auctions.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08432v3"
    },
    {
        "title": "Matching markets with farsighted couples",
        "authors": [
            "Ata Atay",
            "Sylvain Funck",
            "Ana Mauleon",
            "Vincent Vannetelbosch"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We adopt the notion of the farsighted stable set to determine which matchings\nare stable when agents are farsighted in matching markets with couples. We show\nthat a singleton matching is a farsighted stable set if and only if the\nmatching is stable. Thus, matchings that are stable with myopic agents remain\nstable when agents become farsighted. Examples of farsighted stable sets\ncontaining multiple non-stable matchings are provided for markets with and\nwithout stable matchings. For couples markets where the farsighted stable set\ndoes not exist, we propose the DEM farsighted stable set to predict the\nmatchings that are stable when agents are farsighted.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12276v2"
    },
    {
        "title": "Bauer's Maximum Principle for Quasiconvex Functions",
        "authors": [
            "Ian Ball"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This note shows that in Bauer's maximum principle, the assumed convexity of\nthe objective function can be relaxed to quasiconvexity.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.04893v1"
    },
    {
        "title": "Bubble Necessity Theorem",
        "authors": [
            "Tomohiro Hirano",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Asset price bubbles are situations where asset prices exceed the fundamental\nvalues defined by the present value of dividends. This paper presents a\nconceptually new perspective: the necessity of bubbles. We establish the Bubble\nNecessity Theorem in a plausible general class of economic models: with faster\nlong-run economic growth ($G$) than dividend growth ($G_d$) and counterfactual\nlong-run autarky interest rate ($R$) below dividend growth, all equilibria are\nbubbly with non-negligible bubble sizes relative to the economy. This bubble\nnecessity condition naturally arises in economies with sufficiently strong\nsavings motives and multiple factors or sectors with uneven productivity\ngrowth.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08268v5"
    },
    {
        "title": "Coordinating Charitable Donations",
        "authors": [
            "Felix Brandt",
            "Matthias Greger",
            "Erel Segal-Halevi",
            "Warut Suksompong"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Charity is typically carried out by individual donors, who donate money to\ncharities they support, or by centralized organizations such as governments or\nmunicipalities, which collect individual contributions and distribute them\namong a set of charities. Individual charity respects the will of the donors,\nbut may be inefficient due to a lack of coordination; centralized charity is\npotentially more efficient, but may ignore the will of individual donors. We\npresent a mechanism that combines the advantages of both methods for donors\nwith Leontief preferences (i.e., each donor seeks to maximize an individually\nweighted minimum of all contributions across the charities). The mechanism\ndistributes the contribution of each donor efficiently such that no subset of\ndonors has an incentive to redistribute their donations. Moreover, it is\ngroup-strategyproof, satisfies desirable monotonicity properties, maximizes\nNash welfare, returns a unique Lindahl equilibrium, can be computed\nefficiently, and implemented via natural best-response spending dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10286v2"
    },
    {
        "title": "A Robust Characterization of Nash Equilibrium",
        "authors": [
            "Florian Brandl",
            "Felix Brandt"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We characterize Nash equilibrium by postulating coherent behavior across\nvarying games. Nash equilibrium is the only solution concept that satisfies the\nfollowing axioms: (i) strictly dominant actions are played with positive\nprobability, (ii) if a strategy profile is played in two games, it is also\nplayed in every convex combination of these games, and (iii) players can shift\nprobability arbitrarily between two indistinguishable actions, and deleting one\nof these actions has no effect. Our theorem implies that every equilibrium\nrefinement violates at least one of these axioms. Moreover, every solution\nconcept that approximately satisfies these axioms returns approximate Nash\nequilibria, even in natural subclasses of games, such as two-player zero-sum\ngames, potential games, and graphical games.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.03079v2"
    },
    {
        "title": "Feasible Conditional Belief Distributions",
        "authors": [
            "Itai Arieli",
            "Yakov Babichenko",
            "Fedor Sandomirskiy"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Agents receive private signals about an unknown state. The resulting joint\nbelief distributions are complex and lack a simple characterization. Our key\ninsight is that, when conditioned on the state, the structure of belief\ndistributions simplifies: feasibility constrains only the marginal\ndistributions of individual agents across states, with no joint constraints\nwithin a state. We apply this insight to multi-receiver persuasion, identifying\nnew tractable cases and introducing optimal transportation and duality tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07672v2"
    },
    {
        "title": "The Core of Bayesian Persuasion",
        "authors": [
            "Laura Doval",
            "Ran Eilat"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  An analyst observes the frequency with which an agent takes actions, but not\nthe frequency with which she takes actions conditional on a payoff relevant\nstate. In this setting, we ask when the analyst can rationalize the agent's\nchoices as the outcome of the agent learning something about the state before\ntaking action. Our characterization marries the obedience approach in\ninformation design (Bergemann and Morris, 2016) and the belief approach in\nBayesian persuasion (Kamenica and Gentzkow, 2011) relying on a theorem by\nStrassen (1965) and Hall's marriage theorem. We apply our results to\nring-network games and to identify conditions under which a data set is\nconsistent with a public information structure in first-order Bayesian\npersuasion games.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.13849v1"
    },
    {
        "title": "Complementarities in childcare allocation under priorities",
        "authors": [
            "Ata Atay",
            "Antonio Romero-Medina"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We investigate the allocation of children to childcare facilities and propose\nsolutions to overcome limitations in the current allocation mechanism. We\nintroduce a natural preference domain and a priority structure that address\nthese setbacks, aiming to enhance the allocation process. To achieve this, we\npresent an adaptation of the Deferred Acceptance mechanism to our problem,\nwhich ensures strategy-proofness within our preference domain and yields the\nstudent-optimal stable matching. Finally, we provide a maximal domain for the\nexistence of stable matchings using the properties that define our natural\npreference domain. Our results have practical implications for allocating\nindivisible bundles with complementarities.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.14689v1"
    },
    {
        "title": "Forecasting with Feedback",
        "authors": [
            "Robert P. Lieli",
            "Augusto Nieto-Barthaburu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Systematically biased forecasts are typically interpreted as evidence of\nforecasters' irrationality and/or asymmetric loss. In this paper we propose an\nalternative explanation: when forecasts inform economic policy decisions, and\nthe resulting actions affect the realization of the forecast target itself,\nforecasts may be optimally biased even under quadratic loss. The result arises\nin environments in which the forecaster is uncertain about the decision maker's\nreaction to the forecast, which is presumably the case in most applications. We\nillustrate the empirical relevance of our theory by reviewing some stylized\nproperties of Green Book inflation forecasts and relating them to the\npredictions from our model. Our results point out that the presence of policy\nfeedback poses a challenge to traditional tests of forecast rationality.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.15062v3"
    },
    {
        "title": "A Topological Proof of The Gibbard-Satterthwaite Theorem",
        "authors": [
            "Yuliy Baryshnikov",
            "Joseph Root"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We give a new proof of the Gibbard-Satterthwaite Theorem. We construct two\ntopological spaces: one for the space of preference profiles and another for\nthe space of outcomes. We show that social choice functions induce continuous\nmappings between the two spaces. By studying the properties of this mapping, we\nprove the theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.03123v1"
    },
    {
        "title": "Maintaining human wellbeing as socio-environmental systems undergo\n  regime shifts",
        "authors": [
            "Andrew R. Tilman",
            "Elisabeth H. Krueger",
            "Lisa C. McManus",
            "James R. Watson"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Global environmental change is pushing many socio-environmental systems\ntowards critical thresholds, where ecological systems' states are on the\nprecipice of tipping points and interventions are needed to navigate or avert\nimpending transitions. Flickering, where a system vacillates between\nalternative stable states, is touted as a useful early warning signal of\nirreversible transitions to undesirable ecological regimes. However, while\nflickering may presage an ecological tipping point, these dynamics also pose\nunique challenges for human adaptation. In this work, we link an ecological\nmodel that can exhibit flickering to a model of human adaptation to a changing\nenvironment. This allows us to explore the impact of flickering on the utility\nof adaptive agents in a coupled socio-environmental system. We highlight the\nconditions under which flickering causes wellbeing to decline\ndisproportionately, and explore how these dynamics impact the optimal timing of\na transformational change that partially decouples wellbeing from environmental\nvariability. The implications of flickering on nomadic communities in Mongolia,\nartisanal fisheries, and wildfire systems are explored as possible case\nstudies. Flickering, driven in part by climate change and changes to governance\nsystems, may already be impacting communities. We argue that governance\ninterventions investing in adaptive capacity could blunt the negative impact of\nflickering that can occur as socio-environmental systems pass through tipping\npoints, and therefore contribute to the sustainability of these systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04578v1"
    },
    {
        "title": "Reserve Matching with Thresholds",
        "authors": [
            "Suat Evren"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Reserve systems are used to accommodate multiple essential or\nunderrepresented groups in allocating indivisible scarce resources by creating\ncategories that prioritize their respective beneficiaries. Some applications\ninclude the optimal allocation of vaccines, or assignment of minority students\nto elite colleges in India. An allocation is called smart if it optimizes the\nnumber of units distributed. Previous literature mostly assumed baseline\npriorities, which impose significant interdependencies between the priority\nordering of different categories. It also assumes either everybody is eligible\nfor receiving a unit from any category, or only the beneficiaries are eligible.\nThe comprehensive Threshold Model we propose allows independent priority\norderings among categories and arbitrary beneficiary and eligibility\nthresholds, enabling policymakers to avoid comparing incomparables in\naffirmative action systems. We present a new smart reserve system that\noptimizes two objectives simultaneously to allocate scarce resources. Our Smart\nPipeline Matching Mechanism achieves all desirable properties in the most\ngeneral domain possible. Our results apply to any resource allocation market,\nbut we focus our attention on the vaccine allocation problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.13766v2"
    },
    {
        "title": "Competitive and Revenue-Optimal Pricing with Budgets",
        "authors": [
            "Simon Finster",
            "Paul Goldberg",
            "Edwin Lock"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In markets with budget-constrained buyers, competitive equilibria need not be\nefficient in the utilitarian sense, or maximise the seller's revenue. We\nconsider a setting with multiple divisible goods. Firstly, we show that\ncompetitive equilibrium outcomes, and only those, are constrained utilitarian\nefficient, a notion of utilitarian efficiency that respects buyers' demands and\nbudgets. Secondly, we establish that, when buyers have linear valuations,\ncompetitive equilibrium prices are unique and revenue-optimal for a zero-cost\nseller.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.03692v2"
    },
    {
        "title": "Interventions Against Machine-Assisted Statistical Discrimination",
        "authors": [
            "John Y. Zhu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  I study statistical discrimination driven by verifiable beliefs, such as\nthose generated by machine learning, rather than by humans. When beliefs are\nverifiable, interventions against statistical discrimination can move beyond\nsimple, belief-free designs like affirmative action, to more sophisticated\nones, that constrain decision makers based on what they are thinking. Such mind\nreading interventions can perform well where affirmative action does not, even\nwhen the minds being read are biased. My theory of belief-contingent\nintervention design sheds light on influential methods of regulating machine\nlearning, and yields novel interventions robust to covariate shift and\nincorrect, biased beliefs.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04585v3"
    },
    {
        "title": "An Information Theory Approach to the Stock and Cryptocurrency Market: A\n  Statistical Equilibrium Perspective",
        "authors": [
            "Emanuele Citera",
            "Francesco De Pretis"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the stochastic structure of cryptocurrency rates of returns as\ncompared to stock returns by focusing on the associated cross-sectional\ndistributions. We build two datasets. The first comprises forty-six major\ncryptocurrencies, and the second includes all the companies listed in the S&P\n500. We collect individual data from January 2017 until December 2022. We then\napply the Quantal Response Statistical Equilibrium (QRSE) model to recover the\ncross-sectional frequency distribution of the daily returns of cryptocurrencies\nand S&P 500 companies. We study the stochastic structure of these two markets\nand the properties of investors' behavior over bear and bull trends. Finally,\nwe compare the degree of informational efficiency of these two markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04907v1"
    },
    {
        "title": "Cheap Talking Algorithms",
        "authors": [
            "Daniele Condorelli",
            "Massimiliano Furlan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We simulate behaviour of two independent reinforcement learning algorithms\nplaying the Crawford and Sobel (1982) game of strategic information\ntransmission. We adopt memoryless algorithms to capture learning in a static\ngame where a large population interacts anonymously. We show that sender and\nreceiver converge to Nash equilibrium play. The level of informativeness of the\nsender's cheap talk decreases as the bias increases and, at intermediate level\nof the bias, it matches the level predicted by the Pareto optimal equilibrium\nor by the second best one. Conclusions are robust to alternative specifications\nof the learning hyperparameters and of the game.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.07867v6"
    },
    {
        "title": "Risk Aversion and Insurance Propensity",
        "authors": [
            "Fabio Maccheroni",
            "Massimo Marinacci",
            "Ruodu Wang",
            "Qinyu Wu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We provide a new foundation of risk aversion by showing that the propension\nto exploit insurance opportunities fully describes this attitude. Our\nfoundation, which applies to any probabilistically sophisticated preference,\nwell accords with the commonly held prudential interpretation of risk aversion\nthat dates back to the seminal works of Arrow (1963) and Pratt (1964).\n  In our main results, we first characterize the Arrow-Pratt risk aversion in\nterms of propension to full insurance and the stronger notion of risk aversion\nof Rothschild and Stiglitz (1970) in terms of propension to partial insurance.\nWe then extend the analysis to comparative risk aversion by showing that the\nnotion of Yaari (1969) corresponds to comparative propension to full insurance,\nwhile the stronger notion of Ross (1981) corresponds to comparative propension\nto partial insurance.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09173v2"
    },
    {
        "title": "Managing Persuasion Robustly: The Optimality of Quota Rules",
        "authors": [
            "Dirk Bergemann",
            "Tan Gan",
            "Yingkai Li"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a sender-receiver model where the receiver can commit to a decision\nrule before the sender determines the information policy. The decision rule can\ndepend on the signal structure and the signal realization that the sender\nadopts. This framework captures applications where a decision-maker (the\nreceiver) solicit advice from an interested party (sender). In these\napplications, the receiver faces uncertainty regarding the sender's preferences\nand the set of feasible signal structures. Consequently, we adopt a unified\nrobust analysis framework that includes max-min utility, min-max regret, and\nmin-max approximation ratio as special cases. We show that it is optimal for\nthe receiver to sacrifice ex-post optimality to perfectly align the sender's\nincentive. The optimal decision rule is a quota rule, i.e., the decision rule\nmaximizes the receiver's ex-ante payoff subject to the constraint that the\nmarginal distribution over actions adheres to a consistent quota, regardless of\nthe sender's chosen signal structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.10024v1"
    },
    {
        "title": "Improving Robust Decisions with Data",
        "authors": [
            "Xiaoyu Cheng"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A decision-maker faces uncertainty governed by a data-generating process\n(DGP), which is only known to belong to a set of sequences of independent but\npossibly non-identical distributions. A robust decision maximizes the expected\npayoff against the worst possible DGP in this set. This paper characterizes\nwhen and how such robust decisions can be improved with data, measured by the\nexpected payoff under the true DGP, no matter which possible DGP is the truth.\nIt further develops novel and simple inference methods to achieve it, as common\nmethods (e.g., maximum likelihood) may fail to deliver such an improvement.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.16281v4"
    },
    {
        "title": "The Power of Simple Menus in Robust Selling Mechanisms",
        "authors": [
            "Shixin Wang"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a robust selling problem where a seller attempts to sell one item to\na buyer but is uncertain about the buyer's valuation distribution. Existing\nliterature shows that robust screening provides a stronger theoretical\nguarantee than robust deterministic pricing, but at the expense of\nimplementation complexity, as it requires a menu of infinite options. Our\nresearch aims to find simple mechanisms to hedge against market ambiguity\neffectively. We develop a general framework for robust selling mechanisms with\na finite menu (or randomization across finite prices). We propose a tractable\nreformulation that addresses various ambiguity sets of the buyer's valuation\ndistribution, including support, mean, and quantile ambiguity sets. We derive\noptimal selling mechanisms and corresponding performance ratios for different\nmenu sizes, showing that even a modest menu size can deliver benefits similar\nto those achieved by the optimal robust mechanism with infinite options,\nestablishing a favorable trade-off between theoretical performance and\nimplementation simplicity. Remarkably, a menu size of merely two can\nsignificantly enhance the performance ratio compared to deterministic pricing.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17392v3"
    },
    {
        "title": "Implementing Evidence Acquisition: Time Dependence in Contracts for\n  Advice",
        "authors": [
            "Yingkai Li",
            "Jonathan Libgober"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  An expert with no inherent interest in an unknown binary state can exert\neffort to acquire a piece of falsifiable evidence informative of it. A designer\ncan incentivize learning using a mechanism that provides state-dependent\nrewards within fixed bounds. We show that eliciting a single report maximizes\ninformation acquisition if the evidence is revealing or its content\npredictable. This conclusion fails when the evidence is sufficiently imprecise,\nthe failure to find it is informative, and its contents could support either\nstate. Our findings shed light on incentive design for consultation and\nforecasting by showing how learning dynamics qualitatively shape\neffort-maximizing contracts.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.19147v2"
    },
    {
        "title": "Some coordination problems are harder than others",
        "authors": [
            "Argyrios Deligkas",
            "Eduard Eiben",
            "Gregory Gutin",
            "Philip R. Neary",
            "Anders Yeo"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In order to coordinate players in a game must first identify a target pattern\nof behaviour. In this paper we investigate the difficulty of identifying\nprominent outcomes in two kinds of binary action coordination problems in\nsocial networks: pure coordination games and anti-coordination games. For both\nenvironments, we determine the computational complexity of finding a strategy\nprofile that (i) maximises welfare, (ii) maximises welfare subject to being an\nequilibrium, and (iii) maximises potential. We show that the complexity of\nthese objectives can vary with the type of coordination problem. Objectives (i)\nand (iii) are tractable problems in pure coordination games, but for\nanti-coordination games are NP-hard. Objective (ii), finding the best Nash\nequilibrium, is NP-hard for both. Our results support the idea that\nenvironments in which actions are strategic complements (e.g., technology\nadoption) facilitate successful coordination more readily than those in which\nactions are strategic substitutes (e.g., public good provision).\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03195v2"
    },
    {
        "title": "City formation by dual migration of firms and workers",
        "authors": [
            "Kensuke Ohtake"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper studies a mathematical model of city formation by migration of\nfirms and workers. The Core-Periphery model in the new economic geography,\nwhich considers migration of workers driven by real wage inequality among\nregions, is extended to incorporate migration of firms driven by real profit\ninequality among regions. Spatially homogeneous distributions of firms and\nworkers become destabilized and eventually forms several cities in which both\nthe firms and workers agglomerate, and the number of the cities decreases as\ntransport costs become lower.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.05292v3"
    },
    {
        "title": "The Multi-BMBY Mechanism: Proportionality-Preserving and Strategyproof\n  Ownership Restructuring in Private Companies",
        "authors": [
            "Gal Danino",
            "Moran Koren",
            "Omer Madmon"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In privately held startups, restructuring ownership is challenging due to\ndiverse and uncertain valuations among owners. Traditional approaches,\nincluding the BMBY mechanism for equal partnerships, fail to address the\ncomplexities of multi-owner settings and don't elicit true valuations. We\npropose a novel mechanism that extends the BMBY rationale to accommodate these\ncomplex scenarios. Our mechanism ensures truthful valuation elicitation while\noffering several advantages: it is easy to implement, budget balanced,\nresistant to collusion, individually rational, and allocates shares to those\nwho value them most. Crucially, it preserves proportionality among remaining\nowners, maintaining existing power dynamics. The mechanism allows for adaptive\ncontrol of the eventual number of owners, addressing unique startup needs such\nas incentivizing employee ownership. This paper contributes to the field of\nownership restructuring by providing a practical, theoretically-grounded\nsolution for the complex dynamics of startup recapitalization, potentially\nimproving decision-making processes and stakeholder relationships in these\npivotal business transitions.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06780v3"
    },
    {
        "title": "Crowdsearch",
        "authors": [
            "Hans Gersbach",
            "Akaki Mamageishvili",
            "Fikri Pitsuwan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A common economic process is crowdsearch, wherein a group of agents is\ninvited to search for a valuable physical or virtual object, e.g. creating and\npatenting an invention, solving an open scientific problem, or identifying\nvulnerabilities in software. We study a binary model of crowdsearch in which\nagents have different abilities to find the object. We characterize the types\nof equilibria and identify which type of crowd maximizes the likelihood of\nfinding the object. Sometimes, however, an unlimited crowd is not sufficient to\nguarantee that the object is found. It even can happen that inviting more\nagents lowers the probability of finding the object. We characterize the\noptimal prize and show that offering only one prize (winner-takes-all)\nmaximizes the probability of finding the object but is not necessarily optimal\nfor the crowdsearch designer.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.08532v1"
    },
    {
        "title": "Artificial intelligence and the skill premium",
        "authors": [
            "David E. Bloom",
            "Klaus Prettner",
            "Jamel Saadaoui",
            "Mario Veruete"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  What will likely be the effect of the emergence of ChatGPT and other forms of\nartificial intelligence (AI) on the skill premium? To address this question, we\ndevelop a nested constant elasticity of substitution production function that\ndistinguishes between industrial robots and AI. Industrial robots predominantly\nsubstitute for low-skill workers, whereas AI mainly helps to perform the tasks\nof high-skill workers. We show that AI reduces the skill premium as long as it\nis more substitutable for high-skill workers than low-skill workers are for\nhigh-skill workers.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09255v1"
    },
    {
        "title": "Ambiguity aversion as a route to randomness in a duopoly game",
        "authors": [
            "Davide Radi",
            "Laura Gardini"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The global dynamics is investigated for a duopoly game where the perfect\nforesight hypothesis is relaxed and firms are worst-case maximizers.\nOverlooking the degree of product substitutability as well as the sensitivity\nof price to quantity, the unique and globally stable Cournot-Nash equilibrium\nof the complete-information duopoly game, loses stability when firms are not\naware if they are playing a duopoly game, as it is, or an oligopoly game with\nmore than two competitors. This finding resembles Theocharis' condition for the\nstability of the Cournot-Nash equilibrium in oligopolies without uncertainty.\nAs opposed to complete-information oligopoly games, coexisting attractors,\ndisconnected basins of attractions and chaotic dynamics emerge when the\nCournot-Nash equilibrium loses stability. This difference in the global\ndynamics is due to the nonlinearities introduced by the worst-case approach to\nuncertainty, which mirror in bimodal best-reply functions. Conducted with\ntechniques that require a symmetric setting of the game, the investigation of\nthe dynamics reveals that a chaotic regime prevents firms from being ambiguity\naverse, that is, firms are worst-case maximizers only in the\nquantity-expectation space. Therefore, chaotic dynamics are the result and at\nthe same time the source of profit uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.11366v1"
    },
    {
        "title": "Performance rating in chess, tennis, and other contexts",
        "authors": [
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this note, I introduce Estimated Performance Rating (PR$^e$), a novel\nsystem for evaluating player performance in sports and games. PR$^e$ addresses\na key limitation of the Tournament Performance Rating (TPR) system, which is\nundefined for zero or perfect scores in a series of games. PR$^e$ is defined as\nthe rating that solves an optimization problem related to scoring probability,\nmaking it applicable for any performance level. The main theorem establishes\nthat the PR$^e$ of a player is equivalent to the TPR whenever the latter is\ndefined. I then apply this system to historically significant win-streaks in\nassociation football, tennis, and chess. Beyond sports, PR$^e$ has broad\napplicability in domains where Elo ratings are used, from college rankings to\nthe evaluation of large language models.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.12700v1"
    },
    {
        "title": "Monitoring with Rich Data",
        "authors": [
            "Mira Frick",
            "Ryota Iijima",
            "Yuhta Ishii"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider moral hazard problems where a principal has access to rich\nmonitoring data about an agent's action. Rather than focusing on optimal\ncontracts (which are known to in general be complicated), we characterize the\noptimal rate at which the principal's payoffs can converge to the first-best\npayoff as the amount of data grows large. Our main result suggests a novel\nrationale for the widely observed binary wage schemes, by showing that such\nsimple contracts achieve the optimal convergence rate. Notably, in order to\nattain the optimal convergence rate, the principal must set a lenient cutoff\nfor when the agent receives a high vs. low wage. In contrast, we find that\nother common contracts where wages vary more finely with observed data (e.g.,\nlinear contracts) approximate the first-best at a highly suboptimal rate.\nFinally, we show that the optimal convergence rate depends only on a simple\nsummary statistic of the monitoring technology. This yields a detail-free\nranking over monitoring technologies that quantifies their value for incentive\nprovision in data-rich settings and applies regardless of the agent's specific\nutility or cost functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.16789v2"
    },
    {
        "title": "The Gatekeeper Effect: The Implications of Pre-Screening,\n  Self-selection, and Bias for Hiring Processes",
        "authors": [
            "Moran Koren"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the problem of screening in decision-making processes under\nuncertainty, focusing on the impact of adding an additional screening stage,\ncommonly known as a 'gatekeeper.' While our primary analysis is rooted in the\ncontext of job market hiring, the principles and findings are broadly\napplicable to areas such as educational admissions, healthcare patient\nselection, and financial loan approvals. The gatekeeper's role is to assess\napplicants' suitability before significant investments are made. Our study\nreveals that while gatekeepers are designed to streamline the selection process\nby filtering out less likely candidates, they can sometimes inadvertently\naffect the candidates' own decision-making process. We explore the conditions\nunder which the introduction of a gatekeeper can enhance or impede the\nefficiency of these processes. Additionally, we consider how adjusting\ngatekeeping strategies might impact the accuracy of selection decisions. Our\nresearch also extends to scenarios where gatekeeping is influenced by\nhistorical biases, particularly in competitive settings like hiring. We\ndiscover that candidates confronted with a statistically biased gatekeeping\nprocess are more likely to withdraw from applying, thereby perpetuating the\npreviously mentioned historical biases. The study suggests that measures such\nas affirmative action can be effective in addressing these biases. While\ncentered on hiring, the insights and methodologies from our study have\nsignificant implications for a wide range of fields where screening and\ngatekeeping are integral.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.17167v1"
    },
    {
        "title": "Optimal sharing, equilibria, and welfare without risk aversion",
        "authors": [
            "Jean-Gabriel Lauzier",
            "Liyuan Lin",
            "Ruodu Wang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze Pareto optimality and competitive equilibria in a risk-exchange\neconomy, where either all agents are risk seeking in an expected utility model,\nor they exhibit local risk-seeking behaviour in a rank-dependent utility model.\nA novel mathematical tool, the counter-monotonic improvement theorem, states\nthat for any nonnegative allocation of the aggregate random payoff, there\nexists a counter-monotonic random vector, called a jackpot allocation, that is\ncomponentwise riskier than the original allocation, and thus preferred by\nrisk-seeking agents. This result allows us to characterize Pareto optimality,\nthe utility possibility frontier, and competitive equilibria with risk-seeking\nexpected utility agents, and prove the first and second fundamental theorems of\nwelfare economics in this setting. For rank-dependent utility agents that are\nneither risk averse or risk seeking, we show that jackpot allocations can be\nPareto optimal for small-scale payoffs, but for large-scale payoffs they are\ndominated by proportional allocations, thus explaining the often-observed\nsmall-stake gambling behaviour in a risk sharing context. Such jackpot\nallocations are also equilibrium allocations for small-scale payoffs when there\nis no aggregate uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03328v2"
    },
    {
        "title": "A Dynamic Agent Based Model of the Real Economy with Monopolistic\n  Competition, Perfect Product Differentiation, Heterogeneous Agents,\n  Increasing Returns to Scale and Trade in Disequilibrium",
        "authors": [
            "Subhamon Supantha",
            "Naresh Kumar Sharma"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We have used agent-based modeling as our numerical method to artificially\nsimulate a dynamic real economy where agents are rational maximizers of an\nobjective function of Cobb-Douglas type. The economy is characterised by\nheterogeneous agents, acting out of local or imperfect information,\nmonopolistic competition, perfect product differentiation, allowance for\nincreasing returns to scale technology and trade in disequilibrium. An\nalgorithm for economic activity in each period is devised and a general purpose\nopen source agent-based model is developed which allows for counterfactual\ninquiries, testing out treatments, analysing causality of various economic\nprocesses, outcomes and studying emergent properties. 10,000 simulations, with\n10 firms and 80 consumers are run with varying parameters and the results show\nthat from only a few initial conditions the economy reaches equilibrium while\nin most of the other cases it remains in perpetual disequilibrium. It also\nshows that from a few initial conditions the economy reaches a disaster where\nall the consumer wealth falls to zero or only a single producer remains.\nFurthermore, from some initial conditions, an ideal economy with high wage\nrate, high consumer utility and no unemployment is also reached. It was also\nobserved that starting from an equal endowment of wealth in consumers and in\nproducers, inequality emerged in the economy. In majority of the cases most of\nthe firms(6-7) shut down because they were not profitable enough and only a few\nfirms remained. Our results highlight that all these varying outcomes are\npossible for a decentralized market economy with rational optimizing agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07070v1"
    },
    {
        "title": "Individual and Collective Welfare in Risk Sharing with Many States",
        "authors": [
            "Federico Echenique",
            "Farzad Pourbabaee"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We investigate the effects of a large (but finite) state space on models of\nefficient risk sharing. A group of risk-averse agents agree on a risk-sharing\nagreement in an economy without aggregate risk. The economy is subject to a\nperturbation, or shock, that prompts a renegotiation of the agreement. If\nagents insist on an $\\ep$-utility improvement to accept a new agreement, then\nthe probability of a post-shock acceptable agreement vanishes exponentially to\nzero as the number of states grows. We use similar arguments to consider a\nmodel where agents have multiple prior preferences, and show that the existence\nof an $\\ep$-Pareto improving trade requires that some sets of priors have\nvanishingly small measure. Our results hinge on the \"shape does not matter\"\nmessage of high dimensional isoperimetric inequalities.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07337v3"
    },
    {
        "title": "Local Diversity of Condorcet Domains",
        "authors": [
            "Alexander Karpov",
            "Klas Markström",
            "Søren Riis",
            "Bei Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Several of the classical results in social choice theory demonstrate that in\norder for many voting systems to be well-behaved the set domain of individual\npreferences must satisfy some kind of restriction, such as being single-peaked\non a political axis. As a consequence it becomes interesting to measure how\ndiverse the preferences in a well-behaved domain can be.\n  In this paper we introduce an egalitarian approach to measuring preference\ndiversity, focusing on the abundance of distinct suborders one subsets of the\nalternative. We provide a common generalisation of the frequently used concepts\nof ampleness and copiousness.\n  We give a detailed investigation of the abundance for Condorcet domains. Our\ntheorems imply a ceiling for the local diversity in domains on large sets of\nalternatives, which show that in this measure Black's single-peaked domain is\nin fact optimal. We also demonstrate that for some numbers of alternatives,\nthere are Condorcet domains which have largest local diversity without having\nmaximum order.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11912v1"
    },
    {
        "title": "Consumer-Optimal Segmentation in Multi-Product Markets",
        "authors": [
            "Dirk Bergemann",
            "Tibor Heumann",
            "Michael C. Wang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze how market segmentation affects consumer welfare when a monopolist\ncan engage in both second-degree price discrimination (through product\ndifferentiation) and third-degree price discrimination (through market\nsegmentation). We characterize the consumer-optimal market segmentation and\nshow that it has several striking properties: (1) the market segmentation\ndisplays monotonicity$\\unicode{x2014}$higher-value customers always receive\nhigher quality product than lower-value regardless of their segment and across\nany segment; and (2) when aggregate demand elasticity exceeds a threshold\ndetermined by marginal costs, no segmentation maximizes consumer surplus. Our\nresults demonstrate that strategic market segmentation can benefit consumers\neven when it enables price discrimination, but these benefits depend critically\non demand elasticities and cost structures. The findings have implications for\nregulatory policy regarding price discrimination and market segmentation\npractices.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12366v2"
    },
    {
        "title": "Arrow's single peaked domains, richness, and domains for plurality and\n  the Borda count",
        "authors": [
            "Klas Markström",
            "Søren Riis",
            "Bei Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper we extend the study of Arrow's generalisation of Black's\nsingle-peaked domain and connect this to domains where voting rules satisfy\ndifferent versions of independence of irrelevant alternatives.\n  First we report on a computational generation of all non-isomorphic Arrow's\nsingle-peaked domains on $n\\leq 9$ alternatives. Next, we introduce a\nquantitative measure of richness for domains, as the largest number $r$ such\nthat every alternative is given every rank between 1 and $r$ by the orders in\nthe domain. We investigate the richness of Arrow's single-peaked domains and\nprove that Black's single-peaked domain has the highest possible richness, but\nit is not the only domain which attains the maximum.\n  After this we connect Arrow's single-peaked domains to the discussion by\nDasgupta, Maskin and others of domains on which plurality and the Borda count\nsatisfy different versions of Independence of Irrelevant alternatives (IIA).\nFor Nash's version of IIA and plurality, it turns out the domains are exactly\nthe duals of Arrow's single-peaked domains. As a consequence there can be at\nmost two alternatives which are ranked first in any such domain.\n  For the Borda count both Arrow's and Nash's versions of IIA lead to a maximum\ndomain size which is exponentially smaller than $2^{n-1}$, the size of Black's\nsingle-peaked domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12547v1"
    },
    {
        "title": "ISP pricing and Platform pricing interaction under net neutrality",
        "authors": [
            "Luis Guijarro",
            "Vicent Pla",
            "Jose Ramon Vidal"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze the effects of enforcing vs. exempting access ISP from net\nneutrality regulations when platforms are present and operate two-sided pricing\nin their business models. This study is conducted in a scenario where users and\nContent Providers (CPs) have access to the internet by means of their serving\nISPs and to a platform that intermediates and matches users and CPs, among\nother service offerings. Our hypothesis is that platform two-sided pricing\ninteracts in a relevant manner with the access ISP, which may be allowed (an\nhypothetical non-neutrality scenario) or not (the current neutrality regulation\nstatus) to apply two-sided pricing on its service business model. We\npreliminarily conclude that the platforms are extracting surplus from the CPs\nunder the current net neutrality regime for the ISP, and that the platforms\nwould not be able to do so under the counter-factual situation where the ISPs\ncould apply two-sided prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14791v1"
    },
    {
        "title": "Could AI change the scientific publishing market once and for all?",
        "authors": [
            "Wadim Strielkowski"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Artificial-intelligence tools in research like ChatGPT are playing an\nincreasingly transformative role in revolutionizing scientific publishing and\nre-shaping its economic background. They can help academics to tackle such\nissues as limited space in academic journals, accessibility of knowledge,\ndelayed dissemination, or the exponential growth of academic output. Moreover,\nAI tools could potentially change scientific communication and academic\npublishing market as we know them. They can help to promote Open Access (OA) in\nthe form of preprints, dethrone the entrenched journals and publishers, as well\nas introduce novel approaches to the assessment of research output. It is also\nimperative that they should do just that, once and for all.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14952v1"
    },
    {
        "title": "Robust Price Discrimination",
        "authors": [
            "Itai Arieli",
            "Yakov Babichenko",
            "Omer Madmon",
            "Moshe Tennenholtz"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a model of third-degree price discrimination where the seller's\nproduct valuation is unknown to the market designer, who aims to maximize buyer\nsurplus by revealing buyer valuation information. Our main result shows that\nthe regret is bounded by a $\\frac{1}{e}$-fraction of the optimal buyer surplus\nwhen the seller has zero valuation for the product. This bound is attained by\nrandomly drawing a seller valuation and applying the segmentation of Bergemann\net al. (2015) with respect to the drawn valuation. We show that this bound is\ntight in the case of binary buyer valuation.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16942v3"
    },
    {
        "title": "Intergenerational Preferences and Continuity: Reconciling Order and\n  Topology",
        "authors": [
            "Asier Estevan",
            "Roberto Maura",
            "Oscar Valero"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper we focus our efforts on studying how a preorder and topology\ncan be made compatible. Thus we provide a characterization of those that are\ncontinuous-compatible. Such a characterization states that such topologies must\nbe finer than the so-called upper topology induced by the preorder and, thus,\nit clarifies which topology is the smallest one among those that make the\npreorder continuous. Moreover, we provide sufficient conditions that allows us\nto discard in an easy way the continuity of a preference. In the light of the\nobtained results, we provide possibility counterparts of the a few celebrate\nimpossibility theorems for continuous social social intergenerational\npreferences due to P. Diamond, L.G. Svensson and T. Sakai. Furthermore, we\nsuggest quasi-pseudo-metrics as appropriate quantitative tool for reconciling\ntopology and social intergenerational preferences. Thus, we develop a metric\ntype method which is able to guarantee possibility counterparts of the\naforesaid impossibility theorems and, in addition, it is able to give numerical\nquantifications of the improvement of welfare. We also show that our method\nmakes always the intergenerational preferences semi-continuous multi-utility\nrepresentables in the sense of \\\"{O}zg\\\"{u} Evern and Efe O. Ok. Finally, in\norder to keep close to the classical way of measuring in the literature, a\nrefinement of the previous method is presented in such a way that metrics are\ninvolved.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01699v1"
    },
    {
        "title": "Present Value of the Future Consumer Goods Multiplier",
        "authors": [
            "Ihor Kendiukhov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, we derive a formula for the present value of future consumer\ngoods multiplier based on the assumption that a constant share of investment in\nthe production of consumer goods is expected. The present value appears to be\nan infinite geometric sequence. Moreover, we investigate how the notion of the\nmultiplier can help us in macroeconomic analysis of capital and investment\ndynamics and in understanding some general principles of capital market\nequilibrium. Using the concept of this multiplier, we build a macroeconomic\nmodel of capital market dynamics which is consistent with the implications of\nclassical models and with the market equilibrium condition but gives additional\nquantitative and qualitative predictions regarding the dynamics of shares of\ninvestment into the production of consumer goods and the production of means of\nproduction. The investment volume is modeled as a function of the multiplier:\ninvestments adjust when the value of the multiplier fluctuates around its\nequilibrium value of one. In addition, we suggest possible connections between\nthe investment volume and the multiplier value in the form of differential\nequations. We also present the formula for the rate of growth of the\nmultiplier. Independently of the implications of capital market dynamics\nmodels, the formula for the multiplier itself can be applied for the evaluation\nof the present value of capital or the estimation of the macroeconomic impact\nof changes in investment volumes. Our findings show that both the exponential\nand hyperbolic discounting in combination with empirical evidence available\nlead to the value of the multiplier that is close to one.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01938v1"
    },
    {
        "title": "Spreading Information via Social Networks: An Irrelevance Result",
        "authors": [
            "Yu Awaya",
            "Vijay Krishna"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  An informed planner wishes to spread information among a group of agents in\norder to induce efficient coordination -- say the adoption of a new technology\nwith positive externalities. The agents are connected via a social network. The\nplanner informs a seed and then the information spreads via the network. While\nthe structure of the network affects the rate of diffusion, we show that the\nrate of adoption is the same for all acyclic networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.05276v1"
    },
    {
        "title": "A Generalization of Arrow's Impossibility Theorem Through Combinatorial\n  Topology",
        "authors": [
            "Isaac Lara",
            "Sergio Rajsbaum",
            "Armajac Raventós-Pujol"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  To the best of our knowledge, a complete characterization of the domains that\nescape the famous Arrow's impossibility theorem remains an open question. We\nbelieve that different ways of proving Arrovian theorems illuminate this\nproblem. This paper presents a new combinatorial topology proof of Arrow's\ntheorem. In PODC 2022, Rajsbaum and Ravent\\'os-Pujol proved this theorem using\na combinatorial topology approach. This approach uses simplicial complexes to\nrepresent the sets of profiles of preferences and that of single preferences.\nThese complexes grow in dimension with the number of alternatives. This makes\nit difficult to think about the geometry of Arrow's theorem when there are\n(any) finite number of voters and alternatives. Rajsbaum and Ravent\\'os-Pujol\n(2022) use their combinatorial topology approach only for the base case of two\nvoters and three alternatives and then proceed by induction to prove the\ngeneral version. The problem with this strategy is that it is unclear how to\nstudy domain restrictions in the general case by focusing on the base case and\nthen using induction. Instead, the present article uses the two-dimensional\nstructure of the high-dimensional simplicial complexes (formally, the\n$2$$\\unicode{x2013}$skeleton), yielding a new combinatorial topology proof of\nthis theorem. Moreover, we do not assume the unrestricted domain, but a domain\nrestriction that we call the class of polarization and diversity over triples,\nwhich includes the unrestricted domain. By doing so, we obtain a new\ngeneralization of Arrow's theorem. This shows that the combinatorial topology\napproach can be used to study domain restrictions in high dimensions through\nthe $2$$\\unicode{x2013}$skeleton.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.06024v2"
    },
    {
        "title": "The Limits of Price Discrimination Under Privacy Constraints",
        "authors": [
            "Alireza Fallah",
            "Michael I. Jordan",
            "Ali Makhdoumi",
            "Azarakhsh Malekian"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a producer's problem of selling a product to a continuum of\nprivacy-conscious consumers, where the producer can implement third-degree\nprice discrimination, offering different prices to different market segments.\nWe consider a privacy mechanism that provides a degree of protection by\nprobabilistically masking each market segment. We establish that the resultant\nset of all consumer-producer utilities forms a convex polygon, characterized\nexplicitly as a linear mapping of a certain high-dimensional convex polytope\ninto $\\mathbb{R}^2$. This characterization enables us to investigate the impact\nof the privacy mechanism on both producer and consumer utilities. In\nparticular, we establish that the privacy constraint always hurts the producer\nby reducing both the maximum and minimum utility achievable. From the\nconsumer's perspective, although the privacy mechanism ensures an increase in\nthe minimum utility compared to the non-private scenario, interestingly, it may\nreduce the maximum utility. Finally, we demonstrate that increasing the privacy\nlevel does not necessarily intensify these effects. For instance, the maximum\nutility for the producer or the minimum utility for the consumer may exhibit\nnonmonotonic behavior in response to an increase of the privacy level.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.08223v4"
    },
    {
        "title": "On Three-Layer Data Markets",
        "authors": [
            "Alireza Fallah",
            "Michael I. Jordan",
            "Ali Makhdoumi",
            "Azarakhsh Malekian"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a three-layer data market comprising users (data owners), platforms,\nand a data buyer. Each user benefits from platform services in exchange for\ndata, incurring privacy loss when their data, albeit noisily, is shared with\nthe buyer. The user chooses platforms to share data with, while platforms\ndecide on data noise levels and pricing before selling to the buyer. The buyer\nselects platforms to purchase data from. We model these interactions via a\nmulti-stage game, focusing on the subgame Nash equilibrium. We find that when\nthe buyer places a high value on user data (and platforms can command high\nprices), all platforms offer services to the user who joins and shares data\nwith every platform. Conversely, when the buyer's valuation of user data is\nlow, only large platforms with low service costs can afford to serve users. In\nthis scenario, users exclusively join and share data with these low-cost\nplatforms. Interestingly, increased competition benefits the buyer, not the\nuser: as the number of platforms increases, the user utility does not\nnecessarily improve while the buyer utility improves. However, increasing the\ncompetition improves the overall utilitarian welfare. Building on our analysis,\nwe then study regulations to improve the user utility. We discover that banning\ndata sharing maximizes user utility only when all platforms are low-cost. In\nmixed markets of high- and low-cost platforms, users prefer a minimum noise\nmandate over a sharing ban. Imposing this mandate on high-cost platforms and\nbanning data sharing for low-cost ones further enhances user utility.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09697v2"
    },
    {
        "title": "The Value of Context: Human versus Black Box Evaluators",
        "authors": [
            "Andrei Iakovlev",
            "Annie Liang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Machine learning algorithms are now capable of performing evaluations\npreviously conducted by human experts (e.g., medical diagnoses). How should we\nconceptualize the difference between evaluation by humans and by algorithms,\nand when should an individual prefer one over the other? We propose a framework\nto examine one key distinction between the two forms of evaluation: Machine\nlearning algorithms are standardized, fixing a common set of covariates by\nwhich to assess all individuals, while human evaluators customize which\ncovariates are acquired to each individual. Our framework defines and analyzes\nthe advantage of this customization -- the value of context -- in environments\nwith high-dimensional data. We show that unless the agent has precise knowledge\nabout the joint distribution of covariates, the benefit of additional\ncovariates generally outweighs the value of context.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11157v2"
    },
    {
        "title": "Weighted Myerson value for Network games",
        "authors": [
            "Niharika Kakoty",
            "Surajit Borkotokey",
            "Rajnish Kumar",
            "Abhijit Bora"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the weighted Myerson value for Network games extending a similar\nconcept for communication situations. Network games, unlike communication\nsituations, treat direct and indirect links among players differently and\ndistinguish their effects in both worth generation and allocation processes.\nThe weighted Myerson value is an allocation rule for Network games that\ngeneralizes the Myerson value of Network games. Here, the players are assumed\nto have some weights measuring their capacity to form links with other players.\nTwo characterization of the weighted Myerson value are provided. Finally, we\npropose a bidding mechanism to show that the weighted Myerson value is a\nsubgame-perfect Nash equilibrium under a non-cooperative framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11464v1"
    },
    {
        "title": "Stable matching as transportation",
        "authors": [
            "Federico Echenique",
            "Joseph Root",
            "Fedor Sandomirskiy"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study matching markets with aligned preferences and establish a connection\nbetween common design objectives -- stability, efficiency, and fairness -- and\nthe theory of optimal transport. Optimal transport gives new insights into the\nstructural properties of matchings obtained from pursuing these objectives, and\ninto the trade-offs between different objectives. Matching markets with aligned\npreferences provide a tractable stylized model capturing supply-demand\nimbalances in a range of settings such as partnership formation, school choice,\norgan donor exchange, and markets with transferable utility where bargaining\nover transfers happens after a match is formed.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.13378v1"
    },
    {
        "title": "Luce contracts",
        "authors": [
            "Sumit Goel",
            "Wade Hann-Caruthers"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a multi-agent contract design problem with moral hazard. In our\nmodel, each agent exerts costly effort towards an individual task at which it\nmay either succeed or fail, and the principal, who wishes to encourage effort,\nhas an exclusive-use budget that it can use to reward the agents. We first show\nthat any optimal contract must distribute the entire budget among the\nsuccessful agents. Moreover, every such contract is optimal for some objective\nfunction. Our main contribution is then to introduce a novel class of\ncontracts, which we call Luce contracts, and show that there is always a Luce\ncontract that is optimal. A (generic) Luce contract assigns weights to the\nagents and distributes the entire budget among the successful agents in\nproportion to their weights. Lastly, we characterize effort profiles that can\nbe implemented by Luce contracts, and note that Luce contracts offer a\ndesirable alternative for implementation over commonly studied contracts, like\npiece-rate and bonus-pool contracts, on account of their reward\nvariance-minimizing property.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15890v2"
    },
    {
        "title": "Optimal Budget Aggregation with Star-Shaped Preferences",
        "authors": [
            "Felix Brandt",
            "Matthias Greger",
            "Erel Segal-Halevi",
            "Warut Suksompong"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the problem of aggregating distributions, such as budget proposals,\ninto a collective distribution. An ideal aggregation mechanism would be Pareto\nefficient, strategyproof, and fair. Most previous work assumes that agents\nevaluate budgets according to the $\\ell_1$ distance to their ideal budget. We\ninvestigate and compare different models from the larger class of star-shaped\nutility functions - a multi-dimensional generalization of single-peaked\npreferences. For the case of two alternatives, we extend existing results by\nproving that under very general assumptions, the uniform phantom mechanism is\nthe only strategyproof mechanism that satisfies proportionality - a minimal\nnotion of fairness introduced by Freeman et al. (2021). Moving to the case of\nmore than two alternatives, we establish sweeping impossibilities for $\\ell_1$\nand $\\ell_\\infty$ disutilities: no mechanism satisfies efficiency,\nstrategyproofness, and proportionality. We then propose a new kind of\nstar-shaped utilities based on evaluating budgets by the ratios of shares\nbetween a given budget and an ideal budget. For these utilities, efficiency,\nstrategyproofness, and fairness become compatible. In particular, we prove that\nthe mechanism that maximizes the Nash product of individual utilities is\ncharacterized by group-strategyproofness and a core-based fairness condition.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15904v2"
    },
    {
        "title": "Generative AI and Copyright: A Dynamic Perspective",
        "authors": [
            "S. Alex Yang",
            "Angela Huyue Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The rapid advancement of generative AI is poised to disrupt the creative\nindustry. Amidst the immense excitement for this new technology, its future\ndevelopment and applications in the creative industry hinge crucially upon two\ncopyright issues: 1) the compensation to creators whose content has been used\nto train generative AI models (the fair use standard); and 2) the eligibility\nof AI-generated content for copyright protection (AI-copyrightability). While\nboth issues have ignited heated debates among academics and practitioners, most\nanalysis has focused on their challenges posed to existing copyright doctrines.\nIn this paper, we aim to better understand the economic implications of these\ntwo regulatory issues and their interactions. By constructing a dynamic model\nwith endogenous content creation and AI model development, we unravel the\nimpacts of the fair use standard and AI-copyrightability on AI development, AI\ncompany profit, creators income, and consumer welfare, and how these impacts\nare influenced by various economic and operational factors. For example, while\ngenerous fair use (use data for AI training without compensating the creator)\nbenefits all parties when abundant training data exists, it can hurt creators\nand consumers when such data is scarce. Similarly, stronger AI-copyrightability\n(AI content enjoys more copyright protection) could hinder AI development and\nreduce social welfare. Our analysis also highlights the complex interplay\nbetween these two copyright issues. For instance, when existing training data\nis scarce, generous fair use may be preferred only when AI-copyrightability is\nweak. Our findings underscore the need for policymakers to embrace a dynamic,\ncontext-specific approach in making regulatory decisions and provide insights\nfor business leaders navigating the complexities of the global regulatory\nenvironment.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17801v1"
    },
    {
        "title": "New characterizations of completely useful topologies in mathematical\n  utility theory",
        "authors": [
            "Gianni Bosi",
            "Roberto Daris",
            "Gabriele Sbaiz"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Let $X$ be an arbitrary set. Then a topology $t$ on $X$ is said to be\ncompletely useful if every upper semicontinuous linear (total) preorder\n$\\precsim$ on $X$ can be represented by an upper semicontinuous real-valued\norder preserving function. In this paper, appealing, simple and new\ncharacterizations of completely useful topologies will be proved, therefore\nclarifying the structure of such topologies.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.18324v2"
    },
    {
        "title": "Predicting the Unpredictable under Subjective Expected Utility",
        "authors": [
            "Burkhard C. Schipper"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a decision maker who is unaware of objects to be sampled and thus\ncannot form beliefs about the occurrence of particular objects. Ex ante she can\nform beliefs about the occurrence of novelty and the frequencies of yet to be\nknown objects. Conditional on any sampled objects, she can also form beliefs\nabout the next object being novel or being one of the previously sampled\nobjects. We characterize behaviorally such beliefs under subjective expected\nutility. In doing so, we relate \"reverse\" Bayesianism, a central property in\nthe literature on decision making under growing awareness, with exchangeable\nrandom partitions, the central property in the literature on the discovery of\nspecies problem and mutations in statistics, combinatorial probability theory,\nand population genetics. Partition exchangeable beliefs do not necessarily\nsatisfy \"reverse\" Bayesianism. Yet, the most prominent models of exchangeable\nrandom partitions, the model by De Morgan (1838), the one parameter model of\nEwens (1972), and the two parameter model of Pitman (1995) and Zabell (1997),\ndo satisfy \"reverse\" Bayesianism.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.01421v1"
    },
    {
        "title": "Optimistic and pessimistic approaches for cooperative games",
        "authors": [
            "Ata Atay",
            "Christian Trudeau"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Cooperative game theory studies how to allocate the joint value generated by\na set of players. These games are typically analyzed using the characteristic\nfunction form with transferable utility, which represents the value attainable\nby each coalition. In the presence of externalities, coalition values can be\ndefined through various approaches, notably by trying to determine the best and\nworst-case scenarios. Typically, the optimistic and pessimistic perspectives\noffer valuable insights into strategic interactions. In many applications,\nthese approaches correspond to the coalition either choosing first or choosing\nafter the complement coalition. In a general framework in which the actions of\na group affects the set of feasible actions for others, we explore this\nrelationship and show that it always holds in the presence of negative\nexternalities, but only partly with positive externalities. We then show that\nif choosing first/last corresponds to these extreme values, we also obtain a\nuseful inclusion result: allocations that do not allocate more than the\noptimistic upper bounds also do not allocate less than the pessimistic lower\nbounds. Moreover, we show that when externalities are negative, it is always\npossible to guarantee the non-emptiness of these sets of allocations. Finally,\nwe explore applications to illustrate how our findings provide new results and\noffer a means to derive results from the existing literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.01442v2"
    },
    {
        "title": "A dual approach to nonparametric characterization for random utility\n  models",
        "authors": [
            "Nobuo Koida",
            "Koji Shirai"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper develops a novel characterization for random utility models (RUM),\nwhich turns out to be a dual representation of the characterization by Kitamura\nand Stoye (2018, ECMA). For a given family of budgets and its \"patch\"\nrepresentation \\'a la Kitamura and Stoye, we construct a matrix $\\Xi$ of which\neach row vector indicates the structure of possible revealed preference\nrelations in each subfamily of budgets. Then, it is shown that a stochastic\ndemand system on the patches of budget lines, say $\\pi$, is consistent with a\nRUM, if and only if $\\Xi\\pi \\geq \\mathbb{1}$, where the RHS is the vector of\n$1$'s. In addition to providing a concise quantifier-free characterization,\nespecially when $\\pi$ is inconsistent with RUMs, the vector $\\Xi\\pi$ also\ncontains information concerning (1) sub-families of budgets in which cyclical\nchoices must occur with positive probabilities, and (2) the maximal possible\nweights on rational choice patterns in a population. The notion of Chv\\'atal\nrank of polytopes and the duality theorem in linear programming play key roles\nto obtain these results.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04328v3"
    },
    {
        "title": "Equitable Auctions",
        "authors": [
            "Simon Finster",
            "Patrick Loiseau",
            "Simon Mauras",
            "Mathieu Molina",
            "Bary Pradelski"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We initiate the study of how auction design affects the division of surplus\namong buyers. We propose a parsimonious measure for equity and apply it to the\nfamily of standard auctions for homogeneous goods. Our surplus-equitable\nmechanism is efficient, Bayesian-Nash incentive compatible, and achieves\nsurplus parity among winners ex-post. The uniform-price auction is\nequity-optimal if and only if buyers have a pure common value. Against\nintuition, the pay-as-bid auction is not always preferred in terms of equity if\nbuyers have pure private values. In auctions with price mixing between\npay-as-bid and uniform prices, we provide prior-free bounds on the\nequity-preferred pricing rule under a common regularity condition on signals.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.07799v3"
    },
    {
        "title": "Measures of relevance to the success of streaming platforms",
        "authors": [
            "Juan Carlos Gonçalves-Dosantos",
            "Ricardo Martínez",
            "Joaquín Sánchez-Soriano"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Digital streaming platforms, including Twitch, Spotify, Netflix, Disney, and\nKindle, have emerged as one of the main sources of entertainment with\nsignificant growth potential. Many of these platforms distribute royalties\namong streamers, artists, producers, or writers based on their impact. In this\npaper, we measure the relevance of each of these contributors to the overall\nsuccess of the platform, which is information that can play a key role in\nrevenue allocation. We perform an axiomatic analysis to provide normative\nfoundations for three relevance metrics: the uniform, the proportional, and the\nsubscriber-proportional indicators. The last two indicators implement the\nso-called pro-rata and user-centric models, which are extensively applied to\ndistribute revenues in the music streaming market. The axioms we propose\nformalize different principles of fairness, stability, and non-manipulability,\nand are tailor-made for the streaming context. We complete our analysis with a\ncase study that measures the influence of the 19 most-followed streamers\nworldwide on the Twitch platform.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08421v1"
    },
    {
        "title": "Artificial Bugs for Crowdsearch",
        "authors": [
            "Hans Gersbach",
            "Fikri Pitsuwan",
            "Pio Blieske"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Bug bounty programs, where external agents are invited to search and report\nvulnerabilities (bugs) in exchange for rewards (bounty), have become a major\ntool for companies to improve their systems. We suggest augmenting such\nprograms by inserting artificial bugs to increase the incentives to search for\nreal (organic) bugs. Using a model of crowdsearch, we identify the efficiency\ngains by artificial bugs, and we show that for this, it is sufficient to insert\nonly one artificial bug. Artificial bugs are particularly beneficial, for\ninstance, if the designer places high valuations on finding organic bugs or if\nthe budget for bounty is not sufficiently high. We discuss how to implement\nartificial bugs and outline their further benefits.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.09484v1"
    },
    {
        "title": "Auctions with Dynamic Scoring",
        "authors": [
            "Martino Banchio",
            "Aranyak Mehta",
            "Andres Perlroth"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the design of auctions with dynamic scoring, which allocate a single\nitem according to a given scoring rule. We are motivated by online advertising\nauctions when users interact with a platform over the course of a session. The\nplatform ranks ads based on a combination of bids and quality scores, and\nupdates the quality scores throughout the session based on the user's online\nactivity. The platform must decide when to show an ad during the session. By\ndelaying the auction, the auctioneer acquires information about an ad's\nquality, improving her chances of selecting a high quality ad. However\ninformation is costly, because delay reduces market thickness and in turn\nrevenue. When should the auctioneer allocate the impression to balance these\nforces?\n  We develop a theoretical model to study the effect of market design on the\ntrade-off between market thickness and information. In particular, we focus on\nfirst- and second-price auctions. The auctioneer can commit to the auction\nformat, but not to its timing: her decision can thus be cast as a real options\nproblem. We show that under optimal stopping the first-price auction allocates\nefficiently but with delay. Instead, the second-price auction generates more\nrevenue by avoiding delay. The auctioneer benefits from introducing reserve\nprices, more so in a first-price auction.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.11022v1"
    },
    {
        "title": "Identification of Information Structures in Bayesian Games",
        "authors": [
            "Masaki Miyashita"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  To what extent can an external observer observing an equilibrium action\ndistribution in an incomplete information game infer the underlying information\nstructure? We investigate this issue in a general linear-quadratic-Gaussian\nframework. A simple class of canonical information structures is offered and\nproves rich enough to rationalize any possible equilibrium action distribution\nthat can arise under an arbitrary information structure. We show that the class\nis parsimonious in the sense that the relevant parameters can be uniquely\npinned down by an observed equilibrium outcome, up to some qualifications. Our\nresult implies, for example, that the accuracy of each agent's signal about the\nstate is identified, as measured by how much observing the signal reduces the\nstate variance. Moreover, we show that a canonical information structure\ncharacterizes the lower bound on the amount by which each agent's signal can\nreduce the state variance, across all observationally equivalent information\nstructures. The lower bound is tight, for example, when the actual information\nstructure is uni-dimensional, or when there are no strategic interactions among\nagents, but in general, there is a gap since agents' strategic motives confound\ntheir private information about fundamental and strategic uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.11333v1"
    },
    {
        "title": "Learning Macroeconomic Policies based on Microfoundations: A Stackelberg\n  Mean Field Game Approach",
        "authors": [
            "Qirui Mi",
            "Zhiyu Zhao",
            "Siyu Xia",
            "Yan Song",
            "Jun Wang",
            "Haifeng Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The Lucas critique emphasizes the importance of considering microfoundations,\nhow micro-agents (i.e., households) respond to policy changes, in macroeconomic\npolicymaking. However, due to the vast scale and complex dynamics among\nmicro-agents, predicting microfoundations is challenging. Consequently, this\npaper introduces a Stackelberg Mean Field Game (SMFG) approach that models\nmacroeconomic policymaking based on microfoundations, with the government as\nthe leader and micro-agents as dynamic followers. This approach treats\nlarge-scale micro-agents as a population, to optimize macroeconomic policies by\nlearning the dynamic response of this micro-population. Our experimental\nresults indicate that the SMFG approach outperforms real-world macroeconomic\npolicies, existing AI-based and economic methods, enabling the learned\nmacroeconomic policy to achieve the highest performance while guiding\nlarge-scale micro-agents toward maximal social welfare. Additionally, when\nextended to real-world scenarios, households that do not adopt the SMFG policy\nexperience lower utility and wealth than adopters, thereby increasing the\nattractiveness of our policy. In summary, this paper contributes to the field\nof AI for economics by offering an effective tool for modeling and solving\nmacroeconomic policymaking issues.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.12093v3"
    },
    {
        "title": "Fragile Stable Matchings",
        "authors": [
            "Kirill Rudov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We show how fragile stable matchings are in a decentralized one-to-one\nmatching setting. The classical work of Roth and Vande Vate (1990) suggests\nsimple decentralized dynamics in which randomly-chosen blocking pairs match\nsuccessively. Such decentralized interactions guarantee convergence to a stable\nmatching. Our first theorem shows that, under mild conditions, any unstable\nmatching -- including a small perturbation of a stable matching -- can\nculminate in any stable matching through these dynamics. Our second theorem\nhighlights another aspect of fragility: stabilization may take a long time.\nEven in markets with a unique stable matching, where the dynamics always\nconverge to the same matching, decentralized interactions can require an\nexponentially long duration to converge. A small perturbation of a stable\nmatching may lead the market away from stability and involve a sizable\nproportion of mismatched participants for extended periods. Our results hold\nfor a broad class of dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.12183v1"
    },
    {
        "title": "A new social welfare function with a number of desirable properties",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  By relaxing the dominating set in three ways (e.g., from \"each member beats\nevery non-member\" to \"each member beats or ties every non-member, with an\nadditional requirement that at least one member beat every non-member\"), we\npropose a new social welfare function, which satisfies a number of desirable\nproperties including Condorcet winner principle, Condorcet loser principle,\nstrong Gehrlein-stability (hence Smith set principle), anonymity, neutrality,\nweak Pareto, strong Pareto, non-dictatorship, and [independence of irrelevant\nalternatives (IIA) when the pairwise majority relation is an ordering on the\nalternative set]. If the pairwise majority relation is complete and transitive,\nthe proposed method yields a collective preference relation that coincides with\nthe input majority relation. It thus shares the same collective preference\nfunction on the dichotomous domain with the approval voting and the majority\nvoting. It runs in polynomial time and thus possesses a competitive advantage\nover a number of computationally intractable voting rules such as the Dodgson's\nrule, the Kemeny's rule, the Slater's rule, the Banks rule, and the Schwartz's\ntournament equilibrium set (TEQ) rule. When it is used in tournaments, its\nwinner belongs to the uncovered set, the top cycle set, the Smith set, and the\nSchwartz set. In addition, in a tournament where the number of alternatives is\nnot more than 4, its winner set is a subset, sometimes proper, of the Copeland\nwinner set. Whether this attractive argument is still valid in\nfour-more-alternative tournaments remains an open question.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16373v1"
    },
    {
        "title": "On the Pettis Integral Approach to Large Population Games",
        "authors": [
            "Masaki Miyashita",
            "Takashi Ui"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The analysis of large population economies with incomplete information often\nentails the integration of a continuum of random variables. We showcase the\nusefulness of the integral notion \\`a la Pettis (1938) to study such models. We\npresent several results on Pettis integrals, including convenient sufficient\nconditions for Pettis integrability and Fubini-like exchangeability formulae,\nillustrated through a running example. Building on these foundations, we\nconduct a unified analysis of Bayesian games with arbitrarily many\nheterogeneous agents. We provide a sufficient condition on payoff structures,\nunder which the equilibrium uniqueness is guaranteed across all signal\nstructures. Our condition is parsimonious, as it turns out necessary when\nstrategic interactions are undirected. We further identify the moment\nrestrictions, imposed on the equilibrium action-state joint distribution, which\nhave crucial implications for information designer's problem of persuading a\npopulation of strategically interacting agents. To attain these results, we\nintroduce and develop novel mathematical tools, built on the theory of integral\nkernels and reproducing kernel Hilbert spaces in functional analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.17605v1"
    },
    {
        "title": "Strategic complementarities as stochastic control under sticky price",
        "authors": [
            "Lambert Dong"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine how monetary shocks spread throughout an economic model\ncharacterized by sticky prices and general equilibrium, where the pricing\nstrategies of firms are interlinked, fostering a mutually beneficial\nrelationship. In this dynamic equilibrium, pricing choices of firms are\ninfluenced by overall economic factors, which are themselves affected by these\ndecisions. We approach this situation using a path integral control method,\nyielding several important insights. We confirm the presence and uniqueness of\nthe equilibrium and scrutinize the impulse response function (IRF) of output\nsubsequent to a shock affecting the entire economy.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.19847v1"
    },
    {
        "title": "Shill-Proof Auctions",
        "authors": [
            "Andrew Komo",
            "Scott Duke Kominers",
            "Tim Roughgarden"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In an auction, a seller may masquerade as one or more bidders in order to\nmanipulate the clearing price. We characterize single-item auction formats that\nare shill-proof in the sense that a profit-maximizing seller has no incentive\nto submit shill bids. We distinguish between strong shill-proofness, in which a\nseller with full knowledge of bidders' valuations can never profit from\nshilling, and weak shill-proofness, which requires only that the expected\nequilibrium profit from shilling is nonpositive. The Dutch auction (with a\nsuitable reserve) is the unique (revenue-)optimal and strongly shill-proof\nauction. Moreover, the Dutch auction (with no reserve) is the unique\nprior-independent auction that is both efficient and weakly shill-proof. While\nthere are multiple ex-post incentive compatible, weakly shill-proof, and\noptimal auctions; any optimal auction can satisfy only two properties in the\nset {static, ex-post incentive compatible, weakly shill-proof}.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.00475v2"
    },
    {
        "title": "Priority-Neutral Matching Lattices Are Not Distributive",
        "authors": [
            "Clayton Thomas"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Stable matchings are a cornerstone of market design, with numerous practical\ndeployments backed by a rich, theoretically-tractable structure. However, in\nschool-choice problems, stable matchings are not Pareto optimal for the\nstudents. Priority-neutral matchings, introduced by Reny (AER, 2022),\ngeneralizes the set of stable matchings by allowing for certain priority\nviolations, and there is always a Pareto optimal priority-neutral matching.\nMoreover, like stable matchings, the set of priority-neutral matchings forms a\nlattice.\n  We study the structure of the priority-neutral lattice. Unfortunately, we\nshow that much of the simplicity of the stable matching lattice does not hold\nfor the priority-neutral lattice. In particular, we show that the\npriority-neutral lattice need not be distributive. Moreover, we show that the\ngreatest lower bound of two matchings in the priority-neutral lattice need not\nbe their student-by-student minimum, answering an open question. This show that\nmany widely-used properties of stable matchings fail for priority-neutral\nmatchings; in particular, the set of priority-neutral matchings cannot be\nrepresented by via a partial ordering on a set of rotations. However, by\nproving a novel structural property of the set of priority-neutral matchings,\nwe also show that not every lattice arises as a priority-neutral lattice, which\nsuggests that the exact nature of the family of priority-neutral lattices may\nbe subtle.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02142v1"
    },
    {
        "title": "Algorithmic Fairness and Social Welfare",
        "authors": [
            "Annie Liang",
            "Jay Lu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Algorithms are increasingly used to guide high-stakes decisions about\nindividuals. Consequently, substantial interest has developed around defining\nand measuring the ``fairness'' of these algorithms. These definitions of fair\nalgorithms share two features: First, they prioritize the role of a pre-defined\ngroup identity (e.g., race or gender) by focusing on how the algorithm's impact\ndiffers systematically across groups. Second, they are statistical in nature;\nfor example, comparing false positive rates, or assessing whether group\nidentity is independent of the decision (where both are viewed as random\nvariables). These notions are facially distinct from a social welfare approach\nto fairness, in particular one based on ``veil of ignorance'' thought\nexperiments in which individuals choose how to structure society prior to the\nrealization of their social identity. In this paper, we seek to understand and\norganize the relationship between these different approaches to fairness. Can\nthe optimization criteria proposed in the algorithmic fairness literature also\nbe motivated as the choices of someone from behind the veil of ignorance? If\nnot, what properties distinguish either approach to fairness?\n",
        "pdf_link": "http://arxiv.org/pdf/2404.04424v1"
    },
    {
        "title": "Some Characterizations of TTC in Multiple-Object Reallocation Problems",
        "authors": [
            "Jacob Coreno",
            "Di Feng"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper considers reallocation of indivisible objects when agents are\nendowed with and can consume any bundles. We obtain characterizations of\ngeneralized versions of the Top Trading Cycles (TTC) rule on several preference\ndomains. On the lexicographic domain, the TTC rule is uniquely determined by\nbalancedness, Pareto efficiency, the worst endowment lower bound, and either\ntruncation-proofness or drop strategy-proofness. On the more general responsive\ndomain, the TTC rule is the unique individual-good-based rule that satisfies\nbalancedness, individual-good efficiency, truncation-proofness, and either\nindividual rationality or the worst endowment lower bound. On the conditionally\nlexicographic domain, the augmented TTC rule is characterized by balancedness,\nPareto efficiency, the worst endowment lower bound, and drop\nstrategy-proofness. The conditionally lexicographic domain is a maximal domain\non which Pareto efficiency coincides with individual-good efficiency. For the\nhousing market introduced by Shapley and Scarf (1974), the TTC rule is\ncharacterized by Pareto efficiency, individual rationality, and\ntruncation-proofness.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.04822v4"
    },
    {
        "title": "A many-to-one job market: more about the core and the competitive\n  salaries",
        "authors": [
            "Ata Atay",
            "Marina Núñez",
            "Tamás Solymosi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies many-to-one assignment markets, or matching markets with\nwages. Although it is well-known that the core of this model is non-empty, the\nstructure of the core has not been fully investigated. To the known\ndissimilarities with the one-to-one assignment game, we add that the bargaining\nset does not coincide with the core and the kernel may not be included in the\ncore. Besides, not all extreme core allocations can be obtained by means of a\nlexicographic maximization or a lexicographic minimization procedure, as it is\nthe case in the one-to-one assignment game.\n  The maximum and minimum competitive salaries are characterized in two ways:\naxiomatically and by means of easily verifiable properties of an associated\ndirected graph. Regarding the remaining extreme core allocations of the\nmany-to-one assignment game, we propose a lexicographic procedure that, for\neach order on the set of workers, sequentially maximizes or minimizes each\nworker's competitive salary. This procedure provides all extreme vectors of\ncompetitive salaries, that is all extreme core allocations.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.04847v1"
    },
    {
        "title": "The dynamics of diversity on corporate boards",
        "authors": [
            "Matthias Raddant",
            "Fariba Karimi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Diversity in leadership positions, including corporate boards, is an\nimportant aspect of equality. It is important because it is the key to better\ndecision-making and innovation, and above all, it paves the way for future\ngenerations to participate and shape our society. Many studies emphasize the\nimportance of the visibility of role models and the effect that connectivity\nhas on the success of minorities in leadership. However, the connectivity of\nfirms, the dynamics of the adoption of minorities into leadership positions,\nand the long-term effects in terms of group dynamics and visibility are not\nwell understood. Here, we present a model that shows how these effects work\ntogether in a dynamic model that is calibrated with empirical data of firm and\nboard networks. We show that homophily -- the appointment of minorities is\ninfluenced by the presence of minorities in a board and its neighboring\nentities -- is an important effect shaping the trajectory towards equality. We\nfurther show how perception biases and feedback related to the visibility of\nminority members influence the dynamic. We find that reaching equality can be\nsped up or slowed down depending on the distribution of minorities in central\nfirms. These insights bear significant implications for policy-making geared\ntowards fostering equality and diversity within corporate boards.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.11334v2"
    },
    {
        "title": "Testing the simplicity of strategy-proof mechanisms",
        "authors": [
            "Alexander L. Brown",
            "Daniel G. Stephenson",
            "Rodrigo A. Velez"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper experimentally evaluates four mechanisms intended to achieve the\nUniform outcome in rationing problems (Sprumont, 1991). Our benchmark is the\ndominant-strategy, direct-revelation mechanism of the Uniform rule. A\nstrategically equivalent mechanism that provides non-binding feedback during\nthe reporting period greatly improves performance. A sequential revelation\nmechanism produces modest improvements despite not possessing dominant\nstrategies. A novel, obviously strategy-proof mechanism, devised by Arribillaga\net al. (2023), does not improve performance. We characterize each alternative\nto the direct mechanism, finding general lessons about the advantages of\nreal-time feedback and sequentiality of play as well as the potential\nshortcomings of an obviously strategy-proof mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.11883v1"
    },
    {
        "title": "Bertrand oligopoly in insurance markets with Value at Risk Constraints",
        "authors": [
            "Kolos Csaba Ágoston",
            "Veronika Varga"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Since 2016 the operation of insurance companies in the European Union is\nregulated by the Solvency II directive. According to the EU directive the\ncapital requirement should be calculated as a 99.5\\% of Value at Risk. In this\nstudy, we examine the impact of this capital requirement constraint on\nequilibrium premiums and capitals. We discuss the case of the oligopoly\ninsurance market using Bertrand's model, assuming profit maximizing insurance\ncompanies facing Value at Risk constraints. First we analyze companies'\ndecision on premium level. The companies strategic behavior can result positive\nas well as negative expected profit for companies. The desired situation where\ncompetition eliminate positive profit and lead the market to zero-profit state\nis rare. Later we examine ex post and ax ante capital adjustments. Capital\nadjustment does not rule out market anomalies, although somehow changes them.\nPossibility of capital adjustment can lead the market to a situation where all\nof the companies suffer loss. Allowing capital adjustment results monopolistic\npremium level or market failure with positive probabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17915v1"
    },
    {
        "title": "Disentangling Exploration from Exploitation",
        "authors": [
            "Alessandro Lizzeri",
            "Eran Shmaya",
            "Leeat Yariv"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Starting from Robbins (1952), the literature on experimentation via\nmulti-armed bandits has wed exploration and exploitation. Nonetheless, in many\napplications, agents' exploration and exploitation need not be intertwined: a\npolicymaker may assess new policies different than the status quo; an investor\nmay evaluate projects outside her portfolio. We characterize the optimal\nexperimentation policy when exploration and exploitation are disentangled in\nthe case of Poisson bandits, allowing for general news structures. The optimal\npolicy features complete learning asymptotically, exhibits lots of persistence,\nbut cannot be identified by an index a la Gittins. Disentanglement is\nparticularly valuable for intermediate parameter values.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.19116v1"
    },
    {
        "title": "The role of the Allee effect in common-pool resource and its\n  sustainability",
        "authors": [
            "Chengyi Tu",
            "Fabio Menegazzo",
            "Paolo D'Odorico",
            "Samir Suweis"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The management of common-pool resources is a complex challenge due to the\nrisk of overexploitation and the tragedy of the commons. A novel framework has\nbeen introduced to address this issue, focusing on the coevolutionary\nrelationship between human behavior and common-pool resources within a\nhuman-environment system. However, the impact of the Allee effect on the\ncoevolution and its resource sustainability is still unexplored. The Allee\neffect, a biological phenomenon characterized by a correlation between resource\navailability and growth rate, is a fundamental attribute of numerous natural\nresources. In this paper, we introduce two coevolutionary models of resource\nand strategy under replicator dynamics and knowledge feedback by applying the\nAllee effect to the common-pool resources within human-environment system.\nThese models encapsulate various facets of resource dynamics and the players'\nbehavior, such as resource growth function, the extraction rates, and the\nstrategy update rules. We find that the Allee effect can induce bi-stability\nand critical transition, leading to either sustainable or unsustainable\noutcomes depending on the initial condition and parameter configuration. We\ndemonstrate that knowledge feedback enhances the resilience and sustainability\nof the coevolving system, and these results advances the understanding of\nhuman-environment system and management of common-pool resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.01271v1"
    },
    {
        "title": "Counting steps for re-stabilization in a labor matching market",
        "authors": [
            "Agustin G. Bonifacio",
            "Nadia Guiñazu",
            "Noelia Juarez",
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study a one-to-one labor matching market. If a worker considers resigning\nfrom her current job to obtain a better one, how long does it take for this\nworker to actually get it? We present an algorithm that models this situation\nas a re-stabilization process involving a vacancy chain. Each step of the\nalgorithm is a link of such a chain. We show that the length of this vacancy\nchain, which can be interpreted as the time the worker has to wait for her new\njob, is intimately connected with the lattice structure of the set of stable\nmatchings of the market. Namely, this length can be computed by considering the\ncardinalities of cycles in preferences derived from the initial and final\nstable matchings involved.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.07084v1"
    },
    {
        "title": "Substitutability, equilibrium transport, and matching models",
        "authors": [
            "Alfred Galichon",
            "Antoine Jacquet"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This chapter explores the role of substitutability in economic models,\nparticularly in the context of optimal transport and matching models. In\nequilibrium models with substitutability, market-clearing prices can often be\nrecovered using coordinate update methods such as Jacobi's algorithm. We\nprovide a detailed mathematical analysis of models with substitutability\nthrough the lens of Z- and M-functions, in particular regarding their role in\nensuring the convergence of Jacobi's algorithm. The chapter proceeds by\nstudying matching models using substitutability, first focusing on models with\n(imperfectly) transferable utility, and then on models with non-transferable\nutility. In both cases, the text reviews theoretical implications as well as\ncomputational approaches (Sinkhorn, Gale--Shapley), and highlights a practical\neconomic application.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.07628v1"
    },
    {
        "title": "Variational Bayes and non-Bayesian Updating",
        "authors": [
            "Tomasz Strzalecki"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I show how variational Bayes can be used as a microfoundation for a popular\nmodel of non-Bayesian updating.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.08796v2"
    },
    {
        "title": "Statistical Mechanism Design: Robust Pricing, Estimation, and Inference",
        "authors": [
            "Duarte Gonçalves",
            "Bruno A. Furtado"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper tackles challenges in pricing and revenue projections due to\nconsumer uncertainty. We propose a novel data-based approach for firms facing\nunknown consumer type distributions. Unlike existing methods, we assume firms\nonly observe a finite sample of consumers' types. We introduce\n\\emph{empirically optimal mechanisms}, a simple and intuitive class of\nsample-based mechanisms with strong finite-sample revenue guarantees.\nFurthermore, we leverage our results to develop a toolkit for statistical\ninference on profits. Our approach allows to reliably estimate the profits\nassociated for any particular mechanism, to construct confidence intervals, and\nto, more generally, conduct valid hypothesis testing.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.17178v1"
    },
    {
        "title": "New Approaches to Old Problems? Thinking About a New Design of the\n  AML/CFT Strategy",
        "authors": [
            "Chiara Ferri"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The entry of new technological infrastructures into the financial markets\nposes serious concerns about the misuse of the economic system for illicit\npurposes, such as money laundering and financing of terrorism. Although there\nare cases in which this connection has already been discovered by malicious\nactors, distributed ledger technologies can nevertheless represent a powerful\ntool at the disposal of competent authorities to trace illicit flows and to\nbetter monitor risks in financial markets. However, this possibility may go\nthrough an interdisciplinary analysis of the phenomena. The search for\nalternative systems to move funds, rather than the traditional financial\nintermediaries, such as banks, is not a new circumstance and not necessarily\nfor criminal purposes. Nevertheless, some of the already-known value transfer\nsystems may benefit from the use of distributed ledger technology and make\ntheir detection more difficult. The European institutions are discussing the\nneeded legislative packages to enforce the current regulations and to extend\ntheir application to the crypto space, as well as the establishment of a new\ncompetent authority.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.18517v1"
    },
    {
        "title": "Falsifiable Test Design in Coordination Games",
        "authors": [
            "Yingkai Li",
            "Boli Xu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A principal can propose a project to an agent, who then decides whether to\naccept. Their payoffs from launching the project depend on an unknown binary\nstate. The principal can obtain more precise information about the state\nthrough a test at no cost, but crucially, it is common knowledge that she can\nfalsify the test result. In the most interesting case where players have\nconflicted interests, the optimal test is a binary lemon-detecting test. We\nalso find that coordination is possible when the principal is pessimistic but\nnot when the agent is pessimistic. Moreover, when the agent has private\ninformation about the state, a single binary lemon-detecting test remains\noptimal even though the principal has the option to screen the agent by\nproviding a menu of tests. Our finding is consistent with observed tests in\nreal practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.18521v1"
    },
    {
        "title": "Optimizing Exit Queues for Proof-of-Stake Blockchains: A Mechanism\n  Design Approach",
        "authors": [
            "Michael Neuder",
            "Mallesh Pai",
            "Max Resnick"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Byzantine fault-tolerant consensus protocols have provable safety and\nliveness properties for static validator sets. In practice, however, the\nvalidator set changes over time, potentially eroding the protocol's security\nguarantees. For example, systems with accountable safety may lose some of that\naccountability over time as adversarial validators exit. As a result, protocols\nmust rate limit entry and exit so that the set changes slowly enough to ensure\nsecurity. Here, the system designer faces a fundamental trade-off. Slower exits\nincrease friction, making it less attractive to stake in the first place.\nFaster exits provide more utility to stakers but weaken the protocol's\nsecurity.\n  This paper provides the first systematic study of exit queues for\nProof-of-Stake blockchains. Given a collection of validator-set consistency\nconstraints imposed by the protocol, the social planner's goal is to provide a\nconstrained-optimal mechanism that minimizes disutility for the participants.\nWe introduce the MINSLACK mechanism, a dynamic capacity first-come-first-served\nqueue in which the amount of stake that can exit in a period depends on the\nnumber of previous exits and the consistency constraints. We show that MINSLACK\nis optimal when stakers equally value the processing of their withdrawal. When\nstakers values are heterogeneous, the optimal mechanism resembles a priority\nqueue with dynamic capacity. However, this mechanism must reserve exit capacity\nfor the future in case a staker with a much higher need for liquidity arrives.\nWe conclude with a survey of known consistency constraints and highlight the\ndiversity of existing exit mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.05124v2"
    },
    {
        "title": "Optimal Robust Contract Design",
        "authors": [
            "Bo Peng",
            "Zhihao Gavin Tang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider the robust contract design problem when the principal only has\nlimited information about the actions the agent can take. The principal\nevaluates a contract according to its worst-case performance caused by the\nuncertain action space. Carroll (AER 2015) showed that a linear contract is\noptimal among deterministic contracts. Recently, Kambhampati (JET 2023) showed\nthat the principal's payoff can be strictly increased via randomization over\nlinear contracts. In this paper, we characterize the optimal randomized\ncontract, which remains linear and admits a closed form of its cumulative\ndensity function. The advantage of randomized contracts over deterministic\ncontracts can be arbitrarily large even when the principal knows only one\nnon-trivial action of the agent. Furthermore, our result generalizes to the\nmodel of contracting with teams, by Dai and Toikka (Econometrica 2022).\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11528v1"
    },
    {
        "title": "Optimal Bailouts in Diversified Financial Networks",
        "authors": [
            "Krishna Dasaratha",
            "Santosh Venkatesh",
            "Rakesh Vohra"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Widespread default involves substantial deadweight costs which could be\ncountered by injecting capital into failing firms. Injections have positive\nspillovers that can trigger a repayment cascade. But which firms should a\nregulator bailout so as to minimize the total injection of capital while\nensuring solvency of all firms? While the problem is, in general, NP-hard, for\na wide range of networks that arise from a stochastic block model, we show that\nthe optimal bailout can be implemented by a simple policy that targets firms\nbased on their characteristics and position in the network. Specific examples\nof the setting include core-periphery networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.12818v1"
    },
    {
        "title": "Nash equilibria of quasisupermodular games",
        "authors": [
            "Lu Yu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We prove three results on the existence and structure of Nash equilibria for\nquasisupermodular games. A theorem is purely order-theoretic, and the other two\ninvolve topological hypotheses. Our topological results genralize Zhou's\ntheorem (for supermodular games) and Calciano's theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.13783v1"
    },
    {
        "title": "Guaranteed shares of benefits and costs",
        "authors": [
            "Anna Bogomolnaia",
            "Hervé Moulin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We revisit the self-ownership viewpoint to regulate the utilisation of common\nproperty resources. Allocating to each agent \"the fruit of their own labor\" is\ntypically ill-depned, so we look for tight approximations of this decentralised\nideal. For each agent i two guarantees limit, from above and below, the impact\nof other agents on i's allocation. They limit the range of unscripted\nnegotiations, or the choice of a full sharing rule. Our context-free model of\nthe commons is a mapping W from profiles of \"types\" to a freely transferable\namount of benefit or cost. If W is super (resp. sub) modular there is a single\ntight upper (resp. lower) guarantee, and an infinite menu of tight lower (resp.\nupper) guarantees, each one conveying a precise normative viewpoint. We\ndescribe the menu for essentially all modular two person problems, and familiar\nexamples like the allocation of an indivisible item, cooperative production,\nand facility location.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14198v2"
    },
    {
        "title": "Network-Based Optimal Control of Pollution Growth",
        "authors": [
            "Fausto Gozzi",
            "Marta Leocata",
            "Giulia Pucci"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies a model for the optimal control (by a centralized economic\nagent which we call the planner) of pollution diffusion over time and space.\nThe controls are the investments in production and depollution and the goal is\nto maximize an intertemporal utility function. The main novelty is the fact\nthat the spatial component has a network structure. Moreover, in such a\ntime-space setting we also analyze the trade-off between the use of green or\nnon-green technologies: this also seems to be a novelty in such a setting.\nExtending methods of previous papers, we can solve explicitly the problem in\nthe case of linear costs of pollution.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.15338v1"
    },
    {
        "title": "An Efficient and Sybil Attack Resistant Voting Mechanism",
        "authors": [
            "Jeremias Lenzi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Voting mechanisms are widely accepted and used methods for decentralized\ndecision-making. Ensuring the acceptance of the voting mechanism's outcome is a\ncrucial characteristic of robust voting systems. Consider this scenario: A\ngroup of individuals wants to choose an option from a set of alternatives\nwithout requiring an identification or proof-of-personhood system. Moreover,\nthey want to implement utilitarianism as their selection criteria. In such a\ncase, players could submit votes multiple times using dummy accounts, commonly\nknown as a Sybil attack (SA), which presents a challenge for decentralized\norganizations. Is there a voting mechanism that always prevents players from\nbenefiting by casting votes multiple times (SA-proof) while also selecting the\nalternative that maximizes the added valuations of all players (efficient)?\nOne-person-one-vote is neither SA-proof nor efficient. Coin voting is SA-proof\nbut not efficient. Quadratic voting is efficient but not SA-proof. This study\nuses Bayesian mechanism design to propose a solution. The mechanism's structure\nis as follows: Players make wealth deposits to indicate the strength of their\npreference for each alternative. Each player then receives an amount based on\ntheir deposit and the voting outcome. The proposed mechanism relies on two main\nconcepts: 1) Transfers are influenced by the outcome in a way that each\nplayer's optimal action depends only on individual preferences and the number\nof alternatives; 2) A player who votes through multiple accounts slightly\nreduces the expected utility of all players more than the individual benefit\ngained. This study demonstrates that if players are risk-neutral and each\nplayer has private information about their preferences and beliefs, then the\nmechanism is SA-proof and efficient. This research provides new insights into\nthe design of more robust decentralized decision-making mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01844v1"
    },
    {
        "title": "Consistent Conjectures in Dynamic Matching Markets",
        "authors": [
            "Laura Doval",
            "Pablo Schenone"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We provide a framework to study stability notions for two-sided dynamic\nmatching markets in which matching is one-to-one and irreversible. The\nframework gives center stage to the set of matchings an agent anticipates would\nensue should they remain unmatched, which we refer to as the agent's\nconjectures. A collection of conjectures, together with a pairwise stability\nand individual rationality requirement given the conjectures, defines a\nsolution concept for the economy. We identify a sufficient\ncondition--consistency--for a family of conjectures to lead to a nonempty\nsolution (cf. Hafalir, 2008). As an application, we introduce two families of\nconsistent conjectures and their corresponding solution concepts:\ncontinuation-value-respecting dynamic stability, and the extension to dynamic\nmarkets of the solution concept in Hafalir (2008), sophisticated dynamic\nstability.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.04857v3"
    },
    {
        "title": "Collective Upkeep",
        "authors": [
            "Erik Madsen",
            "Eran Shmaya"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We design mechanisms for maintaining public goods which require periodic\nnon-monetary contributions. Utilitarian welfare is maximized by concentrating\ncontributions among low-cost group members, but such policies generally induce\nsome members to leave the group or misreport their preferences. To forestall\nexit, contributions must be shifted from members with intermediate costs to\nsome high-cost members. To deter misreporting, members must be screened using\nup to two membership tiers, which reward larger contributions with increased\naccess to the good. We apply our results to the design of platforms such as\nNetflix and TikTok hosting crowd-sourced recommendation engines, which function\nas public goods supported by user feedback about new content.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.05196v1"
    },
    {
        "title": "Continuous Social Networks",
        "authors": [
            "Julián Chitiva",
            "Xavier Venel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We develop an extension of the classical model of DeGroot (1974) to a\ncontinuum of agents when they interact among them according to a DiKernel $W$.\nWe show that, under some regularity assumptions, the continuous model is the\nlimit case of the discrete one. We provide some applications of this result.\nFirst, we establish a canonical way to reduce the dimensionality of matrices by\ncomparing matrices of different dimensions in the space of DiKernels. Then, we\ndevelop a model of Lobby Competition where two lobbies compete to bias the\nopinion of a continuum of agents. We give sufficient conditions for the\nexistence of a Nash Equilibrium. Furthermore, we establish the conditions under\nwhich a Nash Equilibrium of the game induce an $\\varepsilon$-Nash Equilibrium\nof the discretization of the game. Finally, we put forward some elements for\nthe characterization of equilibrium strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.11710v1"
    },
    {
        "title": "What does a dynamic oligopoly maximize? The continuous time Markov case",
        "authors": [
            "Juan Pablo Rincón-Zapatero"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze the question of whether the outcome of an oligopoly exploiting a\nnonrenewable resource can be replicated by a related monopoly, within the\nframework of continuous time and Markov Perfect Nash Equilibrium. We establish\nnecessary and sufficient conditions and find explicit solutions in some cases.\nAlso, very simple models with externalities are shown which Nash equilibrium\ncannot be replicated in a monopoly.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.20810v1"
    },
    {
        "title": "Lattice operations for the stable set in substitutable matching markets\n  via re-equilibration dynamics",
        "authors": [
            "Agustin G. Bonifacio",
            "Noelia Juarez",
            "Paola B. Manasero"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We compute the lattice operations for the (pairwise) stable set in two-sided\nmatching markets where only substitutability on agents' choice functions is\nimposed. To do this, we use Tarski operators defined on the lattices of\nworker-quasi-stable and firm-quasi-stable matchings. These operators resemble\nlay-off and vacancy chain dynamics, respectively. First, we compute the lattice\noperations in the many-to-one model. Then, we extend these operations to a\nmany-to-many model with substitutable choice functions on one side and\nresponsive preferences on the other, via a morphism that relates many-to-one\nwith many-to-many matchings in a natural way. Finally, we present the lattice\noperations in the many-to-many model with substitutable choice functions on\nboth sides.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.21198v1"
    },
    {
        "title": "Centralization in Attester-Proposer Separation",
        "authors": [
            "Mallesh Pai",
            "Max Resnick"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We show that Execution Tickets and Execution Auctions dramatically increase\ncentralization in the market for block proposals, even without multi-block MEV\nconcerns. Previous analyses have insufficiently or incorrectly modeled the\ninteraction between ahead-of-time auctions and just-in-time (JIT) auctions. We\nstudy a model where bidders compete in an execution auction ahead of time, and\nthen the winner holds a JIT auction to resell the proposal rights when the slot\narrives. During the execution auction, bidders only know the distribution of\ntheir valuations. Bidders then draw values from their distributions and compete\nin the JIT auction. We show that a bidder who wins the execution auction is\nsubstantially advantaged in the JIT auction since they can set a reserve price\nhigher than their own realized value for the slot to increase their revenue. As\na result, there is a strong centralizing force in the execution auction, which\nallows the ex-ante strongest bidder to win the execution auction every time,\nand similarly gives them the strongest incentive to buy up all the tickets.\nSimilar results trivially apply if the resale market is imperfect, since that\nonly reinforces the advantages of the ex-ante strong buyer. To reiterate, these\nresults do not require the bidders to employ multi-block MEV strategies,\nalthough if they did, it would likely amplify the centralizing effects.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.03116v1"
    },
    {
        "title": "Institutions of public judgment established by social contract and\n  taxation",
        "authors": [
            "Taylor A. Kessinger",
            "Joshua B. Plotkin"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Indirect reciprocity is a plausible mechanism for sustaining cooperation:\npeople cooperate with those who have a good reputation, which can be acquired\nby helping others. However, this mechanism requires the population to agree on\nwho has good or bad moral standing. Consensus can be provided by a central\ninstitution that monitors and broadcasts reputations. But how might such an\ninstitution be maintained, and how can a population ensure that it is effective\nand incorruptible? Here we explore a simple mechanism to sustain an institution\nof reputational judgment: a compulsory contribution from each member of the\npopulation, i.e., a tax. We analyze the maximum possible tax rate that\nindividuals will rationally pay to sustain an institution of judgment, which\nprovides a public good in the form of information, and we derive necessary\nconditions for individuals to resist the temptation to evade their tax payment.\nWe also consider the possibility that institution members may be corrupt and\nsubject to bribery, and we analyze how often an institution must be audited to\nprevent bribery. Our analysis has implications for the establishment of robust\npublic institutions that provide social information to support cooperation in\nlarge populations--and the potential negative consequences associated with\nwealth or income inequality.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.11199v2"
    },
    {
        "title": "Rank-Guaranteed Auctions",
        "authors": [
            "Wei He",
            "Jiangtao Li",
            "Weijie Zhong"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We propose a combinatorial ascending auction that is \"approximately\" optimal,\nrequiring minimal rationality to achieve this level of optimality, and is\nrobust to strategic and distributional uncertainties. Specifically, the auction\nis rank-guaranteed, meaning that for any menu M and any valuation profile, the\nex-post revenue is guaranteed to be at least as high as the highest revenue\nachievable from feasible allocations, taking the (|M|+ 1)th-highest valuation\nfor each bundle as the price. Our analysis highlights a crucial aspect of\ncombinatorial auction design, namely, the design of menus. We provide simple\nand approximately optimal menus in various settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.12001v1"
    },
    {
        "title": "The nonlinear economy (I): How resource constrains lead to business\n  cycles",
        "authors": [
            "Frank Schweitzer",
            "Giona Casiraghi"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We explore the nonlinear dynamics of a macroeconomic model with resource\nconstraints. The dynamics is derived from a production function that considers\ncapital and a generalized form of energy as inputs. Energy, the new variable,\nis depleted during the production process and has to be renewed, whereas\ncapital grows with production and decreases from depreciation. Dependent on\ntime scales and energy related control parameters, we obtain steady states of\nhigh or low production, but also sustained oscillations that show properties of\nbusiness cycles. We also find conditions for the coexistence of stable fixed\npoints and limit cycles. Our model allows to specify investment and saving\nfunctions for Kaldor's model of business cycles. We provide evidence for an\nendogenous origin of business cycles if depleting resources are taken into\naccount.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.16015v1"
    },
    {
        "title": "Satisficing Equilibrium",
        "authors": [
            "Bary S. R. Pradelski",
            "Bassel Tarbush"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In a $\\textit{satisficing equilibrium}$ each agent plays one of their $k$\nbest pure actions, but not necessarily their best action. We show that\nsatisficing equilibria in which agents play only their best or second-best\naction exist in almost all games. In fact, in almost all games, there exist\nsatisficing equilibria in which all but one agent best-respond and the\nremaining agent plays at least a second-best action. By contrast, more than one\nthird of games possess no pure Nash equilibrium. In addition to providing\nstatic foundations for satisficing equilibria, we show that a parsimonious\ndynamic converges to satisficing equilibria in almost all games. We apply our\nresults to market design and show that a mediator who can control a single\nagent can enforce stability in most games. Finally, we use our results to study\nthe existence of $\\epsilon$-equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00832v1"
    },
    {
        "title": "Coarse Descriptions and Cautious Preferences",
        "authors": [
            "Evan Piermont",
            "Marcus Pivato"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a model where an agent is must choose between alternatives that\neach provide only an imprecise description of the world (e.g. linguistic\nexpressions). The set of alternatives is closed under logical conjunction and\ndisjunction, but not necessarily negation. (Formally: it is a distributive\nlattice, but not necessarily a Boolean algebra). In our main result, each\nalternative is identified with a subset of an (endogenously defined) state\nspace, and two axioms characterize maximin decision making. This means: from\nthe agent's preferences over alternatives, we derive a preference order on the\nendogenous state space, such that alternatives are ranked in terms of their\nworst outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06054v1"
    },
    {
        "title": "Speeding up deferred acceptance",
        "authors": [
            "Gregory Z. Gutin",
            "Daniel Karapetyan",
            "Philip R. Neary",
            "Alexander Vickery",
            "Anders Yeo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A run of the deferred acceptance (DA) algorithm may contain proposals that\nare sure to be rejected. We introduce the accelerated deferred acceptance\nalgorithm that proceeds in a similar manner to DA but with sure-to-be rejected\nproposals ruled out. Accelerated deferred acceptance outputs the same stable\nmatching as DA but does so more efficiently: it terminates in weakly fewer\nrounds, requires weakly fewer proposals, and final pairs match no later.\nComputational experiments show that these efficiency savings can be strict.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06865v1"
    },
    {
        "title": "Inertial Coordination Games",
        "authors": [
            "Andrew Koh",
            "Ricky Li",
            "Kei Uzui"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze inertial coordination games: dynamic coordination games with an\nendogenously changing state that depends on (i) a persistent fundamental that\nplayers privately learn about; and (ii) past play. We give a tight\ncharacterization of how the speed of learning shapes equilibrium dynamics: the\nrisk-dominant action is selected in the limit if and only if learning is slow\nsuch that posterior precisions grow sub-quadratically. This generalizes results\nfrom static global games and endows them with an alternate learning foundation.\nConversely, when learning is fast, equilibrium dynamics exhibit persistence and\nlimit play is shaped by initial play. Whenever the risk dominant equilibrium is\nselected, the path of play undergoes a sudden transition when signals are\nprecise, and a gradual transition when signals are noisy.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.08145v1"
    },
    {
        "title": "A General Equilibrium Study of Venture Capitalists' Effort on\n  Entrepreneurship",
        "authors": [
            "Liukun Wu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, I propose a new general equilibrium model that explains\nstylized facts about venture capitalists' impact on their portfolio firms.\nVenture capitalists can help increase firms' productivity, yet they face\nincreasing entry costs to enter. I characterize steady state effort choice,\nentry threshold, and mass of venture capitalists, and show how they are\naffected by change in upfront investment, interest rate, and entry costs. The\nkey contribution is that public policy to stimulate startups by subsidizing\nupfront investments or reducing interest cost have limited success if not\naccompanied by an increasing supply of experts who can improve business ideas.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09960v1"
    },
    {
        "title": "A Statistical Equilibrium Approach to Adam Smith's Labor Theory of Value",
        "authors": [
            "Ellis Scharfenaker",
            "Bruno Theodosio",
            "Duncan K. Foley"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Adam Smith's inquiry into the emergence and stability of the\nself-organization of the division of labor in commodity production and exchange\nis considered using statistical equilibrium methods from statistical physics.\nWe develop a statistical equilibrium model of the distribution of independent\ndirect producers in a hub-and-spoke framework that predicts both the center of\ngravity of producers across lines of production as well as the endogenous\nfluctuations between lines of production that arise from Smith's concept of\n\"perfect liberty\". The ergodic distribution of producers implies a long-run\nbalancing of \"advantages to disadvantages\" across lines of employment and\ngravitation of market prices around Smith's natural prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.10402v1"
    },
    {
        "title": "The Extreme Points of Fusions",
        "authors": [
            "Andreas Kleiner",
            "Benny Moldovanu",
            "Philipp Strack",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Our work explores fusions, the multidimensional counterparts of\nmean-preserving contractions and their extreme and exposed points. We reveal an\nelegant geometric/combinatorial structure for these objects. Of particular note\nis the connection between Lipschitz-exposed points (measures that are unique\noptimizers of Lipschitz-continuous objectives) and power diagrams, which are\ndivisions of a space into convex polyhedral ``cells'' according to a weighted\nproximity criterion. These objects are frequently seen in nature--in cell\nstructures in biological systems, crystal and plant growth patterns, and\nterritorial division in animal habitats--and, as we show, provide the essential\nstructure of Lipschitz-exposed fusions. We apply our results to several\nquestions concerning categorization.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.10779v1"
    },
    {
        "title": "Contest design with a finite type-space: A unifying approach",
        "authors": [
            "Andrzej Baranski",
            "Sumit Goel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the classical contest design problem of allocating a budget across\ndifferent prizes to maximize effort in a finite type-space environment. For any\ncontest, we characterize the unique symmetric equilibrium. In this equilibrium,\ndifferent agent types mix over contiguous intervals so that more efficient\nagents always exert greater effort than less efficient agents. We then solve\nfor the expected equilibrium effort, investigate the effect of increasing\ncompetition under linear costs, and identify conditions under which this effect\npersists under general costs. As a result, we find that the winner-takes-all\ncontest is optimal under linear and concave costs. Lastly, we obtain an\nequilibrium convergence result for the continuum type-space, and since the\nfinite type-space encompasses the complete information environment as a special\ncase, our analysis offers a unified approach to studying contests in these\nclassical environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.04970v2"
    },
    {
        "title": "On the Oscillations in Cournot Games with Best Response Strategies",
        "authors": [
            "Zhengyang Liu",
            "Haolin Lu",
            "Liang Shan",
            "Zihe Wang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, we consider the dynamic oscillation in the Cournot oligopoly\nmodel, which involves multiple firms producing homogeneous products. To explore\nthe oscillation under the updates of best response strategies, we focus on the\nlinear price functions. In this setting, we establish the existence of\noscillations. In particular, we show that for the scenario of different costs\namong firms, the best response converges to either a unique equilibrium or a\ntwo-period oscillation. We further characterize the oscillations and propose\nlinear-time algorithms for finding all types of two-period oscillations. To the\nbest of our knowledge, our work is the first step toward fully analyzing the\nperiodic oscillation in the Cournot oligopoly model.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.09435v1"
    },
    {
        "title": "The Simplicity of Optimal Dynamic Mechanisms",
        "authors": [
            "Jose Correa",
            "Andres Cristi",
            "Laura Vargas Koch"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A fundamental economic question is that of designing revenue-maximizing\nmechanisms in dynamic environments. This paper considers a simple yet\ncompelling market model to tackle this question, where forward-looking buyers\narrive at the market over discrete time periods, and a monopolistic seller is\nendowed with a limited supply of a single good. In the case of i.i.d. and\nregular valuations for the buyers, Board and Skrzypacz (2016) characterized the\noptimal mechanism and proved the optimality of posted prices in the\ncontinuous-time limit. Our main result considers the limit case of a continuum\nof buyers, establishing that for arbitrary independent buyers' valuations,\nposted prices and capacity rationing can implement the optimal anonymous\nmechanism. Our result departs from the literature in three ways: It does not\nmake any regularity assumptions, it considers the case of general, not\nnecessarily i.i.d., arrivals, and finally, not only posted prices but also\ncapacity rationing takes part in the optimal mechanism. Additionally, if supply\nis unlimited, we show that the rationing effect vanishes, and the optimal\nmechanism can be implemented using posted prices only, \\`a la Board (2008).\n",
        "pdf_link": "http://arxiv.org/pdf/2410.11738v1"
    },
    {
        "title": "Incentivizing Information Acquisition",
        "authors": [
            "Fan Wu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I study a principal-agent model in which a principal hires an agent to\ncollect information about an unknown continuous state. The agent acquires a\nsignal whose distribution is centered around the state, controlling the\nsignal's precision at a cost. The principal observes neither the precision nor\nthe signal, but rather, using transfers that can depend on the state,\nincentivizes the agent to choose high precision and report the signal\ntruthfully. I identify a sufficient and necessary condition on the agent's\ninformation structure which ensures that there exists an optimal transfer with\na simple cutoff structure: the agent receives a fixed prize when his prediction\nis close enough to the state and receives nothing otherwise. This condition is\nmild and applies to all signal distributions commonly used in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.13978v2"
    },
    {
        "title": "Feedback strategies in the market with uncertainties",
        "authors": [
            "Mustapha Nyenye Issah"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We explore how dynamic entry deterrence operates through feedback strategies\nin markets experiencing stochastic demand fluctuations. The incumbent firm,\naware of its own cost structure, can deter a potential competitor by\nstrategically adjusting prices. The potential entrant faces a one-time,\nirreversible decision to enter the market, incurring a fixed cost, with profits\ndetermined by market conditions and the incumbent's hidden type. Market demand\nfollows a Chan-Karolyi-Longstaff-Sanders Brownian motion. If the demand is low,\nthe threat of entry diminishes, making deterrence less advantageous. In\nequilibrium, a weak incumbent may be incentivized to reveal its type by raising\nprices. We derive an optimal equilibrium using path integral control, where the\nentrant enters once demand reaches a high enough level, and the weak incumbent\nmixes strategies between revealing itself when demand is sufficiently low.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.16203v1"
    },
    {
        "title": "Characterizing the top trading cycles rule for housing markets with\n  lexicographic preferences",
        "authors": [
            "Bettina Klaus"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a housing market model with limited externalities where agents\ncare both about their own consumption via demand preferences and about the\nagent who receives their endowment via supply preferences (we extend the\nassociated lexicographic preference domains introduced in Klaus and Meo, 2023).\nIf preferences are demand lexicographic, then our model extends the classical\nShapley-Scarf housing market (Shapley and Scarf, 1974) with strict preferences\nmodel. Our main result is a characterization of the corresponding top trading\ncycles (TTC) rule by individual rationality, pair efficiency, and\nstrategy-proofness (Theorem 1), which extends that of Ekici (2024) from\nclassical Shapley-Scarf housing markets with strict preferences to our model.\nTwo further characterizations are immediately obtained by strengthening pair\nefficiency to either Pareto efficiency or pairwise stability (Corollaries 1 and\n2). Finally, we show that as soon as we extend the preference domain to include\ndemand lexicographic as well as supply lexicographic preferences (e.g., when\npreferences are separable), no rule satisfying individual rationality, pair\nefficiency, and strategy-proofness exists (Theorem 2).\n",
        "pdf_link": "http://arxiv.org/pdf/2410.16745v1"
    },
    {
        "title": "Note on Bubbles Attached to Real Assets",
        "authors": [
            "Tomohiro Hirano",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A rational bubble is a situation in which the asset price exceeds its\nfundamental value defined by the present value of dividends in a rational\nequilibrium model. We discuss the recent development of the theory of rational\nbubbles attached to real assets, emphasizing the following three points. (i)\nThere exist plausible economic models in which bubbles inevitably emerge in the\nsense that all equilibria are bubbly. (ii) Such models are necessarily\nnonstationary but their long-run behavior can be analyzed using the local\nstable manifold theorem. (iii) Bubbles attached to real assets can naturally\nand necessarily arise with economic development. Finally, we present a model\nwith stocks and land, and show that bubbles in aggregate stock and land prices\nnecessarily emerge.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.17425v1"
    },
    {
        "title": "Dynamic Investment-Driven Insurance Pricing: Equilibrium Analysis and\n  Welfare Implication",
        "authors": [
            "Bingzheng Chen",
            "Zongxia Liang",
            "Shunzhi Pang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper develops a dynamic model to analyze the general equilibrium of the\ninsurance market, focusing on the interaction between insurers' underwriting\nand investment strategies. Three possible equilibrium outcomes are identified:\na positive insurance market, a zero insurance market, and market failure. Our\nfindings reveal why insurers may rationally accept underwriting losses by\nsetting a negative safety loading while relying on investment profits,\nparticularly when there is a negative correlation between insurance gains and\nfinancial returns. Additionally, we explore the impact of regulatory frictions,\nshowing that while imposing a cost on investment can enhance social welfare\nunder certain conditions, it may not always be necessary. Therefore, we\nemphasize the importance of tailoring regulatory interventions to specific\nmarket conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.18432v1"
    },
    {
        "title": "On the limits of informationally efficient stock markets: New insights\n  from a chartist-fundamentalist model",
        "authors": [
            "Laura Gardini",
            "Davide Radi",
            "Noemi Schmitt",
            "Iryna Sushko",
            "Frank Westerhoff"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We utilize a chartist-fundamentalist model to examine the limits of\ninformationally efficient stock markets. In our model, chartists are\npermanently active in the stock market, while fundamentalists trade only when\ntheir mispricing-dependent trading signals are strong. Our findings indicate\nthe possible coexistence of two distinct regimes. Depending on the initial\nconditions, the stock market may exhibit either constant or oscillatory\nmispricing. Constant mispricing occurs when chartists remain the sole active\nspeculators, causing the stock price to converge toward a nonfundamental value.\nConversely, the stock price oscillates around its fundamental value when\nfundamentalists repeatedly enter and exit the market. Exogenous shocks result\nin intricate regime-switching dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21198v1"
    },
    {
        "title": "Markov Stochastic Choice",
        "authors": [
            "Kremena Valkanova"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine the effect of item arrangement on choices using a novel\ndecision-making model based on the Markovian exploration of choice sets. This\nmodel is inspired by experimental evidence suggesting that the decision-making\nprocess involves sequential search through rapid stochastic pairwise\ncomparisons. Our findings show that decision-makers following a reversible\nprocess are unaffected by item rearrangements, and further demonstrate that\nthis property can be inferred from their choice behavior. Additionally, we\nprovide a characterization of the class of Markovian models in which the agent\nmakes all possible pairwise comparisons with positive probability. The\nintersection of reversible models and those allowing all pairwise comparisons\nis observationally equivalent to the well-known Luce model. Finally, we\ncharacterize the class of Markovian models for which the initial fixation does\nnot impact the final choice and show that choice data reveals the existence and\ncomposition of consideration sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.22001v1"
    },
    {
        "title": "The equilibrium properties of obvious strategy profiles in games with\n  many players",
        "authors": [
            "Enxian Chen Bin Wu Hanping Xu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies the equilibrium properties of the ``obvious strategy\nprofile'' in large finite-player games. Each player in such a strategy profile\nsimply adopts a randomized strategy as she would have used in a symmetric\nequilibrium of an idealized large game. We show that, under a continuity\nassumption, (i) obvious strategy profiles constitute a convergent sequence of\napproximate symmetric equilibria as the number of players tends to infinity,\nand (ii) realizations of such strategy profiles also form a convergent sequence\nof (pure strategy) approximate equilibria with probability approaching one. Our\nfindings offer a solution that is easily implemented without coordination\nissues and is asymptotically optimal for players in large finite games.\nAdditionally, we present a convergence result for approximate symmetric\nequilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.22144v1"
    },
    {
        "title": "Flexible Demand Manipulation",
        "authors": [
            "Yifan Dai",
            "Andrew Koh"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We develop a simple framework to analyze how targeted advertising interacts\nwith market power. A designer chooses an advertising plan which allows it to\nflexibly manipulate the demand curve at some cost. A monopolist prices against\nthis manipulated demand curve. We fully characterize the form and value of\nproducer-optimal and consumer-optimal advertising plans under both ex-ante and\nex-post measures of welfare. Flexibility is double-edged: producer-optimal\nplans substantially reduce consumer surplus vis-a-vis uniform advertising, but\nconsumer-optimal plans can substantially improve consumer surplus. We discuss\nimplications for the regulation of targeted advertising.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.24191v1"
    },
    {
        "title": "A decomposition from a substitutable many-to-one matching market to a\n  one-to-one matching market",
        "authors": [
            "Pablo Neme",
            "Jorge Oviedo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  For a many-to-one market with substitutable preferences on the firm's side,\nbased on the Aizerman-Malishevski decomposition, we define an associated\none-to-one market. Given that the usual notion of stability for a one-to-one\nmarket does not fit well for this associated one-to-one market, we introduce a\nnew notion of stability. This notion allows us to establish an isomorphism\nbetween the set of stable matchings in the many-to-one market and the matchings\nin the associated one-to-one market that meet this new stability criterion.\nFurthermore, we present an adaptation of the well-known deferred acceptance\nalgorithm to compute a matching that satisfies this new notion of stability for\nthe associated one-to-one market.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00564v1"
    },
    {
        "title": "On the Equivalence of Synchronous Coordination Game and Asynchronous\n  Coordination Design",
        "authors": [
            "Xinnian Kazusa Pan"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper establishes the equivalence between synchronous and asynchronous\ncoordination mechanisms in dynamic games with strategic complementarities and\ncommon interests. Synchronous coordination, characterized by simultaneous\ncommitments, and asynchronous coordination, defined by sequential action\ntiming, are both prevalent in economic contexts such as crowdfunding and fund\nmanagement. We introduce Monotone Subgame Perfect Nash Equilibrium, MSPNE, to\nanalyze least favorable equilibrium outcomes. We provide a recursive\ncharacterization for synchronous coordination and a graph-theoretic\nrepresentation for asynchronous coordination, demonstrating their equivalence\nin terms of the greatest implementable outcome. Our results show that the\nstructure of commitment, whether simultaneous or sequential, does not affect\nthe achievable welfare outcome under certain conditions. Additionally, we\ndiscuss computational aspects, highlighting the general NP-Hardness of the\nproblem but identifying a significant class of games that are computationally\ntractable. These findings offer valuable insights for the optimal design of\ncoordination mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.01879v1"
    },
    {
        "title": "Multidimensional Screening with Rich Consumer Data",
        "authors": [
            "Mira Frick",
            "Ryota Iijima",
            "Yuhta Ishii"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A multi-product monopolist faces a buyer who is privately informed about his\nvaluations for the goods. As is well-known, optimal mechanisms are in general\ncomplicated, while simple mechanisms -- such as pure bundling or separate sales\n-- can be far from optimal and do not admit clear-cut comparisons. We show that\nthis changes if the monopolist observes sufficiently rich data about the\nbuyer's valuations: Now, pure bundling always outperforms separate sales;\nmoreover, there is a sense in which pure bundling performs essentially as well\nas the optimal mechanism. To formalize this, we characterize how fast the\ncorresponding revenues converge to the first-best revenue as the monopolist's\ndata grows rich: Pure bundling achieves the same convergence rate to the\nfirst-best as optimal mechanisms; in contrast, the convergence rate under\nseparate sales is suboptimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06312v1"
    },
    {
        "title": "A dynamic auction for multilateral collaboration",
        "authors": [
            "Chao Huang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the problem of multilateral collaboration among agents with\ntransferable utilities. Any group of agents can sign a contract consisting of a\nprimitive contract and monetary transfers among the signatories. We propose a\ndynamic auction that finds a stable outcome when primitive contracts are gross\ncomplements for all participants.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06545v1"
    },
    {
        "title": "Incentive Design with Spillovers",
        "authors": [
            "Krishna Dasaratha",
            "Benjamin Golub",
            "Anant Shah"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A principal uses payments conditioned on stochastic outcomes of a team\nproject to elicit costly effort from the team members. We develop a multi-agent\ngeneralization of a classic first-order approach to contract optimization by\nleveraging methods from network games. The main results characterize the\noptimal allocation of incentive pay across agents and outcomes. Incentive\noptimality requires equalizing, across agents, a product of (i) individual\nproductivity (ii) organizational centrality and (iii) responsiveness to\nmonetary incentives.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08026v1"
    },
    {
        "title": "A Strategic Topology on Information Structures",
        "authors": [
            "Dirk Bergemann",
            "Stephen Morris",
            "Rafael Veiel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Two information structures are said to be close if, with high probability,\nthere is approximate common knowledge that interim beliefs are close under the\ntwo information structures. We define an \"almost common knowledge topology\"\nreflecting this notion of closeness. We show that it is the coarsest topology\ngenerating continuity of equilibrium outcomes. An information structure is said\nto be simple if each player has a finite set of types and each type has a\ndistinct first-order belief about payoff states. We show that simple\ninformation structures are dense in the almost common knowledge topology and\nthus it is without loss to restrict attention to simple information structures\nin information design problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.09149v1"
    },
    {
        "title": "Informational Puts",
        "authors": [
            "Andrew Koh",
            "Sivakorn Sanguanmoo",
            "Kei Uzui"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We analyze how dynamic information should be provided to uniquely implement\nthe largest equilibrium in binary-action coordination games. The designer\noffers an informational put: she stays silent if players choose her preferred\naction, but injects asymmetric and inconclusive public information if they lose\nfaith. There is (i) no multiplicity gap: the largest (partially) implementable\nequilibrium can be implemented uniquely; and (ii) no commitment gap: the policy\nis sequentially optimal. Our results have sharp implications for the design of\npolicy in coordination environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.09191v2"
    },
    {
        "title": "Dynamic Envy-Free Permanency in Child Welfare Systems",
        "authors": [
            "Terence Highsmith"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Caseworkers in foster care systems seek to place waiting children in the most\nsuitable homes. Furthermore, social work guidelines prioritize heterogeneous\nattributes of children and homes when deliberating placements. We use insights\nfrom market design and dynamic matching to characterize a class of dynamically\nenvy-free mechanisms that incentivize expedient placements when children and\nhomes arrive to the market over time and homes may accept or decline\nplacements. The mechanisms have robustness against justified envy and costly\npatience. We analyze strategic incentives and efficiency properties of dynamic\nenvy-freeness. Finally, we conduct empirical simulations that affirm that our\nmechanisms drastically increase placements and reduce waiting costs while\nmaintaining robustness to prediction error versus a naive mechanism that always\nsequentially runs Deferred Acceptance. Practitioners can implement our\nmechanisms through assigning priority to child-home matches.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.09817v2"
    },
    {
        "title": "Condorcet-Consistent Choice Among Three Candidates",
        "authors": [
            "Felix Brandt",
            "Chris Dong",
            "Dominik Peters"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A voting rule is a Condorcet extension if it returns a candidate that beats\nevery other candidate in pairwise majority comparisons whenever one exists.\nCondorcet extensions have faced criticism due to their susceptibility to\nvariable-electorate paradoxes, especially the reinforcement paradox (Young and\nLevenglick, 1978) and the no-show paradox (Moulin, 1988). In this paper, we\ninvestigate the susceptibility of Condorcet extensions to these paradoxes for\nthe case of exactly three candidates. For the reinforcement paradox, we\nestablish that it must occur for every Condorcet extension when there are at\nleast eight voters and demonstrate that certain refinements of maximin, a\nvoting rule originally proposed by Condorcet (1785), are immune to this paradox\nwhen there are at most seven voters. For the no-show paradox, we prove that the\nonly homogeneous Condorcet extensions immune to it are refinements of maximin.\nWe also provide axiomatic characterizations of maximin and two of its\nrefinements, Nanson's rule and leximin, highlighting their suitability for\nthree-candidate elections.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.19857v1"
    },
    {
        "title": "Extreme Points in Multi-Dimensional Screening",
        "authors": [
            "Patrick Lahr",
            "Axel Niemeyer"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper characterizes extreme points of the set of incentive-compatible\nmechanisms for screening problems with linear utility. Extreme points are\nexhaustive mechanisms, meaning their menus cannot be scaled and translated to\nmake additional feasibility constraints binding. In problems with\none-dimensional types, extreme points admit a tractable description with a\ntight upper bound on their menu size. In problems with multi-dimensional types,\nevery exhaustive mechanism can be transformed into an extreme point by applying\nan arbitrarily small perturbation. For mechanisms with a finite menu, this\nperturbation displaces the menu items into general position. Generic exhaustive\nmechanisms are extreme points with an uncountable menu. Similar results hold in\napplications to delegation, veto bargaining, and monopoly problems, where we\nconsider mechanisms that are unique maximizers for specific classes of\nobjective functionals. The proofs involve a novel connection between menus of\nextreme points and indecomposable convex bodies, first studied by Gale (1954).\n",
        "pdf_link": "http://arxiv.org/pdf/2412.00649v1"
    },
    {
        "title": "A partial-state space model of unawareness",
        "authors": [
            "Wesley H. Holliday"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We propose a model of unawareness that remains close to the paradigm of\nAumann's model for knowledge [R. J. Aumann, International Journal of Game\nTheory 28 (1999) 263-300]: just as Aumann uses a correspondence on a state\nspace to define an agent's knowledge operator on events, we use a\ncorrespondence on a state space to define an agent's awareness operator on\nevents. This is made possible by three ideas. First, like the model of [A.\nHeifetz, M. Meier, and B. Schipper, Journal of Economic Theory 130 (2006)\n78-94], ours is based on a space of partial specifications of the world,\npartially ordered by a relation of further specification or refinement, and the\nidea that agents may be aware of some coarser-grained specifications while\nunaware of some finer-grained specifications; however, our model is based on a\ndifferent implementation of this idea, related to forcing in set theory.\nSecond, we depart from a tradition in the literature, initiated by [S. Modica\nand A. Rustichini, Theory and Decision 37 (1994) 107-124] and adopted by\nHeifetz et al. and [J. Li, Journal of Economic Theory 144 (2009) 977-993], of\ntaking awareness to be definable in terms of knowledge. Third, we show that the\nnegative conclusion of a well-known impossibility theorem concerning\nunawareness in [Dekel, Lipman, and Rustichini, Econometrica 66 (1998) 159-173]\ncan be escaped by a slight weakening of a key axiom. Together these points\ndemonstrate that a correspondence on a partial-state space is sufficient to\nmodel unawareness of events. Indeed, we prove a representation theorem showing\nthat any abstract Boolean algebra equipped with awareness, knowledge, and\nbelief operators satisfying some plausible axioms is representable as the\nalgebra of events arising from a partial-state space with awareness, knowledge,\nand belief correspondences.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.00897v2"
    },
    {
        "title": "Undergraduate Course Allocation through Competitive Markets",
        "authors": [
            "Daniel Kornbluth",
            "Alexey Kushnir"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Prevailing methods of course allocation at undergraduate institutions involve\nreserving seats to give priority to designated groups of students. We introduce\na competitive equilibrium-based mechanism that assigns course seats using\nstudent preferences and course priorities. This mechanism satisfies approximate\nnotions of stability, efficiency, envy-freeness, and strategy-proofness. We\nevaluate its performance relative to a mechanism widely used in practice using\npreferences estimated from university data. Our empirical findings demonstrate\nan improvement in student satisfaction and allocation fairness. The number of\nstudents who envy another student of weakly lower priority declines by 8\npercent, or roughly 500 students.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.05691v1"
    },
    {
        "title": "Learning to be Indifferent in Complex Decisions: A Coarse\n  Payoff-Assessment Model",
        "authors": [
            "Philippe Jehiel",
            "Aviman Satpathy"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We introduce the Coarse Payoff-Assessment Learning (CPAL) model, which\ncaptures reinforcement learning by boundedly rational decision-makers who focus\non the aggregate outcomes of choosing among exogenously defined clusters of\nalternatives (similarity classes), rather than evaluating each alternative\nindividually. Analyzing a smooth approximation of the model, we show that the\nlearning dynamics exhibit steady-states corresponding to smooth Valuation\nEquilibria (Jehiel and Samet, 2007). We demonstrate the existence of multiple\nequilibria in decision trees with generic payoffs and establish the local\nasymptotic stability of pure equilibria when they occur. Conversely, when\ntrivial choices featuring alternatives within the same similarity class yield\nsufficiently high payoffs, a unique mixed equilibrium emerges, characterized by\nindifferences between similarity classes, even under acute sensitivity to\npayoff differences. Finally, we prove that this unique mixed equilibrium is\nglobally asymptotically stable under the CPAL dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.09321v2"
    },
    {
        "title": "Navigating through Economic Complexity: Phase Diagrams & Parameter\n  Sloppiness",
        "authors": [
            "Jean-Philippe Bouchaud"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We argue that establishing the phase diagram of Agent Based Models (ABM) is a\ncrucial first step, together with a qualitative understanding of how collective\nphenomena come about, before any calibration or more quantitative predictions\nare attempted. Computer-aided *gedanken* experiments are by themselves of\ngenuine value: if we are not able to make sense of emergent phenomena in a\nworld in which we set all the rules, how can we expect to be successful in the\nreal world? ABMs indeed often reveal the existence of Black Swans/Dark Corners\ni.e. discontinuity lines beyond which runaway instabilities appear, whereas\nmost classical economic/finance models are blind to such scenarii. Testing for\nthe overall robustness of the phase diagram against changes in heuristic rules\nis a way to ascertain the plausibility of such scenarii. Furthermore, exploring\nthe phase diagrams of ABM in high dimensions should benefit enormously from the\nidentification of ``stiff'' and ``sloppy'' directions in parameter space.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.11259v1"
    },
    {
        "title": "Quantifying Inefficiency",
        "authors": [
            "Yannai A. Gonczarowski",
            "Ella Segev"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We axiomatically define a cardinal social inefficiency function, which, given\na set of alternatives and individuals' vNM preferences over the alternatives,\nassigns a unique number -- the social inefficiency -- to each alternative.\nThese numbers -- and not only their order -- are uniquely defined by our axioms\ndespite no exogenously given interpersonal comparison, outside option, or\ndisagreement point. We interpret these numbers as per capita losses in\nendogenously normalized utility. We apply our social inefficiency function to a\nsetting in which interpersonal comparison is notoriously hard to justify --\nobject allocation without money -- leveraging techniques from computer science\nto prove an approximate-efficiency result for the Random Serial Dictatorship\nmechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.11984v1"
    },
    {
        "title": "Raising Bidders' Awareness in Second-Price Auctions",
        "authors": [
            "Ying Xue Li",
            "Burkhard C. Schipper"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  When bidders bid on complex objects, they might be unaware of characteristics\neffecting their valuations. We assume that each buyer's valuation is a sum of\nindependent random variables, one for each characteristic. When a bidder is\nunaware of a characteristic, he omits the random variable from the sum. We\nstudy the seller's decision to raise bidders' awareness of characteristics\nbefore a second-price auction with entry fees. Optimal entry fees capture an\nadditional unawareness rent due to unaware bidders misperceiving their\nprobability of winning and the price to be paid upon winning. When raising a\nbidder's individual awareness of a characteristic with positive expected value,\nthe seller faces a trade-off between positive effects on the expected first\norder statistic and unawareness rents of remaining unaware bidders on one hand\nand the loss of the unawareness rent from the newly aware bidder on the other.\nWe present characterization results on raising public awareness together with\nno versus full information. We discuss the winner's curse due to unawareness of\ncharacteristics.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12676v1"
    },
    {
        "title": "Data-Driven Mechanism Design: Jointly Eliciting Preferences and\n  Information",
        "authors": [
            "Dirk Bergemann",
            "Marek Bojko",
            "Paul Dütting",
            "Renato Paes Leme",
            "Haifeng Xu",
            "Song Zuo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study mechanism design when agents hold private information about both\ntheir preferences and a common payoff-relevant state. We show that standard\nmessage-driven mechanisms cannot implement socially efficient allocations when\nagents have multidimensional types, even under favorable conditions. To\novercome this limitation, we propose data-driven mechanisms that leverage\nadditional post-allocation information, modeled as an estimator of the\npayoff-relevant state. Our data-driven mechanisms extend the classic\nVickrey-Clarke-Groves class. We show that they achieve exact implementation in\nposterior equilibrium when the state is either fully revealed or the utility is\nlinear in an unbiased estimator. We also show that they achieve approximate\nimplementation with a consistent estimator, converging to exact implementation\nas the estimator converges, and present bounds on the convergence rate. We\ndemonstrate applications to digital advertising auctions and large language\nmodel (LLM)-based mechanisms, where user engagement naturally reveals relevant\ninformation.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.16132v1"
    },
    {
        "title": "Robust Equilibria in Generic Extensive form Games",
        "authors": [
            "Lucas Pahl",
            "Carlos Pimienta"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We prove the 2-player, generic extensive-form case of the conjecture of\nGovindan and Wilson (1997a,b) and Hauk and Hurkens (2002) stating that an\nequilibrium component is essential in every equivalent game if and only if the\nindex of the component is nonzero. This provides an index-theoretic\ncharacterization of the concept of hyperstable components of equilibria in\ngeneric extensive-form games, first formulated by Kohlberg and Mertens (1986).\nWe also illustrate how to compute hyperstable equilibria in multiple\neconomically relevant examples and show how the predictions of hyperstability\ncompare with other solution concepts.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18449v1"
    },
    {
        "title": "Streaming problems as (multi-issue) claims problems",
        "authors": [
            "Gustavo Bergantiños",
            "Juan D. Moreno-Ternero"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study the problem of allocating the revenues raised via paid subscriptions\nto music streaming platforms among participating artists. We show that the main\nmethods to solve streaming problems (pro-rata, user-centric and families\ngeneralizing them) can be seen as specific (well-known) rules to solve\n(multi-issue) claims problems. Our results permit to provide strong links\nbetween the well-established literature on claims problems and the emerging\nliterature on streaming problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18628v1"
    },
    {
        "title": "Using Ordinal Voting to Compare the Utilitarian Welfare of a Status Quo\n  and A Proposed Policy: A Simple Nonparametric Analysis",
        "authors": [
            "Charles F. Manski"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The relationship of policy choice by majority voting and by maximization of\nutilitarian welfare has long been discussed. I consider choice between a status\nquo and a proposed policy when persons have interpersonally comparable cardinal\nutilities taking values in a bounded interval, voting is compulsory, and each\nperson votes for a policy that maximizes utility. I show that knowledge of the\nattained status quo welfare and the voting outcome yields an informative bound\non welfare with the proposed policy. The bound contains the value of status quo\nwelfare, so the better utilitarian policy is not known. The minimax-regret\ndecision and certain Bayes decisions choose the proposed policy if its vote\nshare exceeds the known value of status quo welfare. This procedure differs\nfrom majority rule, which chooses the proposed policy if its vote share exceeds\n1/2.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18714v1"
    },
    {
        "title": "The Limits of Tolerance",
        "authors": [
            "Alan D. Miller"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  I propose a model of aggregation of intervals relevant to the study of legal\nstandards of tolerance. Seven axioms: responsiveness, anonymity, continuity,\nstrategyproofness, and three variants of neutrality are then used to prove\nseveral important results about a new class of aggregation methods called\nendpoint rules. The class of endpoint rules includes extreme tolerance\n(allowing anything permitted by anyone) and a form of majoritarianism (the\nmedian rule).\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00578v1"
    },
    {
        "title": "An integral transformation approach to differential games: a climate\n  model application",
        "authors": [
            "Raouf Boucekkine",
            "Giorgio Fabbri",
            "Salvatore Federico",
            "Fausto Gozzi",
            "Ted Loch-Temzelides",
            "Cristiano Ricci"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  We develop an Integral Transformation Method (ITM) for the study of suitable\noptimal control and differential game models. This allows for a solution to\nsuch dynamic problems to be found through solving a family of optimization\nproblems parametrized by time. The method is quite flexible, and it can be used\nin several economic applications where the state equation and the objective\nfunctional are linear in a state variable. We illustrate the ITM in the context\nof a two-country integrated assessment climate model. We characterize\nemissions, consumption, transfers, and welfare by computing the Nash equilibria\nof the associated dynamic game. We then compare them to efficiency benchmarks.\nFurther, we apply the ITM in a robust control setup, where we investigate how\n(deep) uncertainty affects climate outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.01749v1"
    },
    {
        "title": "Revealed Social Networks",
        "authors": [
            "Christopher P. Chambers",
            "Yusufcan Masatlioglu",
            "Christopher Turansick"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  People are influenced by their peers when making decisions. In this paper, we\nstudy the linear-in-means model which is the standard empirical model of peer\neffects. As data on the underlying social network is often difficult to come\nby, we focus on data that only captures an agent's choices. Under exogenous\nagent participation variation, we study two questions. We first develop a\nrevealed preference style test for the linear-in-means model. We then study the\nidentification properties of the linear-in-means model. With sufficient\nparticipation variation, we show how an analyst is able to recover the\nunderlying network structure and social influence parameters from choice data.\nOur identification result holds when we allow the social network to vary across\ncontexts. To recover predictive power, we consider a refinement which allows us\nto extrapolate the underlying network structure across groups and provide a\ntest of this version of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02609v1"
    },
    {
        "title": "Blackwell Equilibrium in Repeated Games",
        "authors": [
            "Costas Cavounidis",
            "Sambuddha Ghosh",
            "Johannes Hörner",
            "Eilon Solan",
            "Satoru Takahashi"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  We apply Blackwell optimality to repeated games. An equilibrium whose\nstrategy profile is sequentially rational for all high enough discount factors\nsimultaneously is a Blackwell (subgame-perfect, perfect public, etc.)\nequilibrium. The bite of this requirement depends on the monitoring structure.\nUnder perfect monitoring, a ``folk'' theorem holds relative to an appropriate\nnotion of minmax. Under imperfect public monitoring, absent a public\nrandomization device, any perfect public equilibrium generically involves pure\naction profiles or stage-game Nash equilibria only. Under private conditionally\nindependent monitoring, in a class of games that includes the prisoner's\ndilemma, the stage-game Nash equilibrium is played in every round.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.05481v1"
    },
    {
        "title": "Learning from Neighbors about a Changing State",
        "authors": [
            "Krishna Dasaratha",
            "Benjamin Golub",
            "Nir Hak"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Agents learn about a changing state using private signals and their\nneighbors' past estimates of the state. We present a model in which Bayesian\nagents in equilibrium use neighbors' estimates simply by taking weighted sums\nwith time-invariant weights. The dynamics thus parallel those of the tractable\nDeGroot model of learning in networks, but arise as an equilibrium outcome\nrather than a behavioral assumption. We examine whether information aggregation\nis nearly optimal as neighborhoods grow large. A key condition for this is\nsignal diversity: each individual's neighbors have private signals that not\nonly contain independent information, but also have sufficiently different\ndistributions. Without signal diversity $\\unicode{x2013}$ e.g., if private\nsignals are i.i.d. $\\unicode{x2013}$ learning is suboptimal in all networks and\nhighly inefficient in some. Turning to social influence, we find it is much\nmore sensitive to one's signal quality than to one's number of neighbors, in\ncontrast to standard models with exogenous updating rules.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.02042v8"
    },
    {
        "title": "Optimal Incentive Contract with Endogenous Monitoring Technology",
        "authors": [
            "Anqi Li",
            "Ming Yang"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Recent technology advances have enabled firms to flexibly process and analyze\nsophisticated employee performance data at a reduced and yet significant cost.\nWe develop a theory of optimal incentive contracting where the monitoring\ntechnology that governs the above procedure is part of the designer's strategic\nplanning. In otherwise standard principal-agent models with moral hazard, we\nallow the principal to partition agents' performance data into any finite\ncategories and to pay for the amount of information the output signal carries.\nThrough analysis of the trade-off between giving incentives to agents and\nsaving the monitoring cost, we obtain characterizations of optimal monitoring\ntechnologies such as information aggregation, strict MLRP, likelihood\nratio-convex performance classification, group evaluation in response to rising\nmonitoring costs, and assessing multiple task performances according to agents'\nendogenous tendencies to shirk. We examine the implications of these results\nfor workforce management and firms' internal organizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.11471v6"
    },
    {
        "title": "Intermediated Implementation",
        "authors": [
            "Anqi Li",
            "Yiqing Xing"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We examine problems of ``intermediated implementation,'' in which a single\nprincipal can only regulate limited aspects of the consumption bundles traded\nbetween intermediaries and agents with hidden characteristics. An example is\nsales, in which retailers offer menus of consumption bundles to customers with\nhidden tastes, whereas a manufacturer with a potentially different goal from\nretailers' is limited to regulating sold consumption goods but not retail\nprices by legal barriers. We study how the principal can implement through\nintermediaries any social choice rule that is incentive compatible and\nindividually rational for agents. We demonstrate the effectiveness of per-unit\nfee schedules and distribution regulations, which hinges on whether\nintermediaries have private or interdependent values. We give further\napplications to healthcare regulation and income redistribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.11475v7"
    },
    {
        "title": "Approximately Optimal Mechanism Design",
        "authors": [
            "Tim Roughgarden",
            "Inbal Talgam-Cohen"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Optimal mechanism design enjoys a beautiful and well-developed theory, and\nalso a number of killer applications. Rules of thumb produced by the field\ninfluence everything from how governments sell wireless spectrum licenses to\nhow the major search engines auction off online advertising. There are,\nhowever, some basic problems for which the traditional optimal mechanism design\napproach is ill-suited---either because it makes overly strong assumptions, or\nbecause it advocates overly complex designs. This survey reviews several common\nissues with optimal mechanisms, including exorbitant communication,\ncomputation, and informational requirements; and it presents several examples\ndemonstrating that passing to the relaxed goal of an approximately optimal\nmechanism allows us to reason about fundamental questions that seem out of\nreach of the traditional theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11896v2"
    },
    {
        "title": "Mean Field Equilibrium: Uniqueness, Existence, and Comparative Statics",
        "authors": [
            "Bar Light",
            "Gabriel Weintraub"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  The standard solution concept for stochastic games is Markov perfect\nequilibrium (MPE); however, its computation becomes intractable as the number\nof players increases. Instead, we consider mean field equilibrium (MFE) that\nhas been popularized in the recent literature. MFE takes advantage of averaging\neffects in models with a large number of players. We make three main\ncontributions. First, our main result provides conditions that ensure the\nuniqueness of an MFE. We believe this uniqueness result is the first of its\nnature in the class of models we study. Second, we generalize previous MFE\nexistence results. Third, we provide general comparative statics results. We\napply our results to dynamic oligopoly models and to heterogeneous agent\nmacroeconomic models commonly used in previous work in economics and\noperations.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.02273v3"
    },
    {
        "title": "Axioms for Defeat in Democratic Elections",
        "authors": [
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose six axioms concerning when one candidate should defeat another in\na democratic election involving two or more candidates. Five of the axioms are\nwidely satisfied by known voting procedures. The sixth axiom is a weakening of\nKenneth Arrow's famous condition of the Independence of Irrelevant Alternatives\n(IIA). We call this weakening Coherent IIA. We prove that the five axioms plus\nCoherent IIA single out a method of determining defeats studied in our recent\nwork: Split Cycle. In particular, Split Cycle provides the most resolute\ndefinition of defeat among any satisfying the six axioms for democratic defeat.\nIn addition, we analyze how Split Cycle escapes Arrow's Impossibility Theorem\nand related impossibility results.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.08451v4"
    },
    {
        "title": "Bifurcations in economic growth model with distributed time delay\n  transformed to ODE",
        "authors": [
            "Luca Guerrini",
            "Adam Krawiec",
            "Marek Szydlowski"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider the model of economic growth with time delayed investment\nfunction. Assuming the investment is time distributed we can use the linear\nchain trick technique to transform delay differential equation system to\nequivalent system of ordinary differential system (ODE). The time delay\nparameter is a mean time delay of gamma distribution. We reduce the system with\ndistribution delay to both three and four-dimensional ODEs. We study the Hopf\nbifurcation in these systems with respect to two parameters: the time delay\nparameter and the rate of growth parameter. We derive the results from the\nanalytical as well as numerical investigations. From the former we obtain the\nsufficient criteria on the existence and stability of a limit cycle solution\nthrough the Hopf bifurcation. In numerical studies with the Dana and Malgrange\ninvestment function we found two Hopf bifurcations with respect to the rate\ngrowth parameter and detect the existence of stable long-period cycles in the\neconomy. We find that depending on the time delay and adjustment speed\nparameters the range of admissible values of the rate of growth parameter\nbreaks down into three intervals. First we have stable focus, then the limit\ncycle and again the stable solution with two Hopf bifurcations. Such behaviour\nappears for some middle interval of admissible range of values of the rate of\ngrowth parameter.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.05016v1"
    },
    {
        "title": "Optimization of a Dynamic Profit Function using Euclidean Path Integral",
        "authors": [
            "P. Pramanik",
            "A. M. Polansky"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A Euclidean path integral is used to find an optimal strategy for a firm\nunder a Walrasian system, Pareto optimality and a non-cooperative feedback Nash\nEquilibrium. We define dynamic optimal strategies and develop a Feynman type\npath integration method to capture all non-additive convex strategies. We also\nshow that the method can solve the non-linear case, for example\nMerton-Garman-Hamiltonian system, which the traditional Pontryagin maximum\nprinciple cannot solve in closed form. Furthermore, under Walrasian system we\nare able to solve for the optimal strategy under a linear constraint with a\nlinear objective function with respect to strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.09394v1"
    },
    {
        "title": "Feasible Joint Posterior Beliefs",
        "authors": [
            "Itai Arieli",
            "Yakov Babichenko",
            "Fedor Sandomirskiy",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study the set of possible joint posterior belief distributions of a group\nof agents who share a common prior regarding a binary state, and who observe\nsome information structure. For two agents we introduce a quantitative version\nof Aumann's Agreement Theorem, and show that it is equivalent to a\ncharacterization of feasible distributions due to Dawid et al. (1995). For any\nnumber of agents, we characterize feasible distributions in terms of a\n\"no-trade\" condition. We use these characterizations to study information\nstructures with independent posteriors. We also study persuasion problems with\nmultiple receivers, exploring the extreme feasible distributions.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.11362v4"
    },
    {
        "title": "Suboptimal Provision of Privacy and Statistical Accuracy When They are\n  Public Goods",
        "authors": [
            "John M. Abowd",
            "Ian M. Schmutte",
            "William Sexton",
            "Lars Vilhuber"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  With vast databases at their disposal, private tech companies can compete\nwith public statistical agencies to provide population statistics. However,\nprivate companies face different incentives to provide high-quality statistics\nand to protect the privacy of the people whose data are used. When both privacy\nprotection and statistical accuracy are public goods, private providers tend to\nproduce at least one suboptimally, but it is not clear which. We model a firm\nthat publishes statistics under a guarantee of differential privacy. We prove\nthat provision by the private firm results in inefficiently low data quality in\nthis framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.09353v1"
    },
    {
        "title": "A Survey on Data Pricing: from Economics to Data Science",
        "authors": [
            "Jian Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Data are invaluable. How can we assess the value of data objectively,\nsystematically and quantitatively? Pricing data, or information goods in\ngeneral, has been studied and practiced in dispersed areas and principles, such\nas economics, marketing, electronic commerce, data management, data mining and\nmachine learning. In this article, we present a unified, interdisciplinary and\ncomprehensive overview of this important direction. We examine various\nmotivations behind data pricing, understand the economics of data pricing and\nreview the development and evolution of pricing models according to a series of\nfundamental principles. We discuss both digital products and data products. We\nalso consider a series of challenges and directions for future work.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.04462v2"
    },
    {
        "title": "Learning in a Small/Big World",
        "authors": [
            "Benson Tsz Kin Leung"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Complexity and limited ability have profound effect on how we learn and make\ndecisions under uncertainty. Using the theory of finite automaton to model\nbelief formation, this paper studies the characteristics of optimal learning\nbehavior in small and big worlds, where the complexity of the environment is\nlow and high, respectively, relative to the cognitive ability of the decision\nmaker. Optimal behavior is well approximated by the Bayesian benchmark in very\nsmall world but is more different as the world gets bigger. In addition, in big\nworlds, the optimal learning behavior could exhibit a wide range of\nwell-documented non-Bayesian learning behavior, including the use of\nheuristics, correlation neglect, persistent over-confidence, inattentive\nlearning, and other behaviors of model simplification or misspecification.\nThese results establish a clear and testable relationship among the prominence\nof non-Bayesian learning behavior, complexity, and cognitive ability.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.11917v8"
    },
    {
        "title": "Expressive mechanisms for equitable rent division on a budget",
        "authors": [
            "Rodrigo A. Velez"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study the incentive properties of envy-free mechanisms for the allocation\nof rooms and payments of rent among financially constrained roommates. Each\nagent reports her values for rooms, her housing earmark (soft budget), and an\nindex that reflects the difficulty the agent experiences from having to pay\nover this amount. Then an envy-free allocation for these reports is\nrecommended. The complete information non-cooperative outcomes of each of these\nmechanisms are exactly the envy-free allocations with respect to true\npreferences if and only if the admissible budget violation indices have a\nbound.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.02935v3"
    },
    {
        "title": "Parallel Search for Information",
        "authors": [
            "T. Tony Ke",
            "Wenpin Tang",
            "J. Miguel Villas-Boas",
            "Yuming Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We consider the problem of a decision-maker searching for information on\nmultiple alternatives when information is learned on all alternatives\nsimultaneously. The decision-maker has a running cost of searching for\ninformation, and has to decide when to stop searching for information and\nchoose one alternative. The expected payoff of each alternative evolves as a\ndiffusion process when information is being learned. We present necessary and\nsufficient conditions for the solution, establishing existence and uniqueness.\nWe show that the optimal boundary where search is stopped (free boundary) is\nstar-shaped, and present an asymptotic characterization of the value function\nand the free boundary. We show properties of how the distance between the free\nboundary and the diagonal varies with the number of alternatives, and how the\nfree boundary under parallel search relates to the one under sequential search,\nwith and without economies of scale on the search costs.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.06485v2"
    },
    {
        "title": "Contest Architecture with Public Disclosures",
        "authors": [
            "Toomas Hinnosaar"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  I study optimal disclosure policies in sequential contests. A contest\ndesigner chooses at which periods to publicly disclose the efforts of previous\ncontestants. I provide results for a wide range of possible objectives for the\ncontest designer. While different objectives involve different trade-offs, I\nshow that under many circumstances the optimal contest is one of the three\nbasic contest structures widely studied in the literature: simultaneous,\nfirst-mover, or sequential contest.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11004v2"
    },
    {
        "title": "Resolving New Keynesian Anomalies with Wealth in the Utility Function",
        "authors": [
            "Pascal Michaillat",
            "Emmanuel Saez"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  At the zero lower bound, the New Keynesian model predicts that output and\ninflation collapse to implausibly low levels, and that government spending and\nforward guidance have implausibly large effects. To resolve these anomalies, we\nintroduce wealth into the utility function; the justification is that wealth is\na marker of social status, and people value status. Since people partly save to\naccrue social status, the Euler equation is modified. As a result, when the\nmarginal utility of wealth is sufficiently large, the dynamical system\nrepresenting the zero-lower-bound equilibrium transforms from a saddle to a\nsource---which resolves all the anomalies.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.13645v3"
    },
    {
        "title": "The Crawler: Three Equivalence Results for Object (Re)allocation\n  Problems when Preferences Are Single-peaked",
        "authors": [
            "Yuki Tamura",
            "Hadi Hosseini"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  For object reallocation problems, if preferences are strict but otherwise\nunrestricted, the Top Trading Cycles rule (TTC) is the leading rule: It is the\nonly rule satisfying efficiency, individual rationality, and\nstrategy-proofness. However, on the subdomain of single-peaked preferences,\nBade (2019) defines a new rule, the \"crawler\", which also satisfies these three\nproperties. (i) The crawler selects an allocation by \"visiting\" agents in a\nspecific order. A natural \"dual\" rule can be defined by proceeding in the\nreverse order. Our first theorem states that the crawler and its dual are\nactually the same. (ii) Single-peakedness of a preference profile may in fact\nhold for more than one order and its reverse. Our second theorem states that\nthe crawler is invariant to the choice of the order. (iii) For object\nallocation problems (as opposed to reallocation problems), we define a\nprobabilistic version of the crawler by choosing an endowment profile at random\naccording to a uniform distribution, and applying the original definition. Our\nthird theorem states that this rule is the same as the \"random priority rule\".\n",
        "pdf_link": "http://arxiv.org/pdf/1912.06909v2"
    },
    {
        "title": "An Economical Business-Cycle Model",
        "authors": [
            "Pascal Michaillat",
            "Emmanuel Saez"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper develops a new model of business cycles. The model is economical\nin that it is solved with an aggregate demand-aggregate supply diagram, and the\neffects of shocks and policies are obtained by comparative statics. The model\nbuilds on two unconventional assumptions. First, producers and consumers meet\nthrough a matching function. Thus, the model features unemployment, which\nfluctuates in response to aggregate demand and supply shocks. Second, wealth\nenters the utility function, so the model allows for permanent zero-lower-bound\nepisodes. In the model, the optimal monetary policy is to set the interest rate\nat the level that eliminates the unemployment gap. This optimal interest rate\nis computed from the prevailing unemployment gap and monetary multiplier (the\neffect of the nominal interest rate on the unemployment rate). If the\nunemployment gap is exceedingly large, monetary policy cannot eliminate it\nbefore reaching the zero lower bound, but a wealth tax can.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.07163v2"
    },
    {
        "title": "How to Cut a Cake Fairly: A Generalization to Groups",
        "authors": [
            "Erel Segal-Halevi",
            "Warut Suksompong"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A fundamental result in cake cutting states that for any number of players\nwith arbitrary preferences over a cake, there exists a division of the cake\nsuch that every player receives a single contiguous piece and no player is left\nenvious. We generalize this result by showing that it is possible to partition\nthe players into groups of any desired sizes and divide the cake among the\ngroups, so that each group receives a single contiguous piece and no player\nfinds the piece of another group better than that of the player's own group.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03327v3"
    },
    {
        "title": "Supply Network Formation and Fragility",
        "authors": [
            "Matthew Elliott",
            "Benjamin Golub",
            "Matthew V. Leduc"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We model the production of complex goods in a large supply network. Each firm\nsources several essential inputs through relationships with other firms.\nIndividual supply relationships are at risk of idiosyncratic failure, which\nthreatens to disrupt production. To protect against this, firms multisource\ninputs and strategically invest to make relationships stronger, trading off the\ncost of investment against the benefits of increased robustness. A supply\nnetwork is called fragile if aggregate output is very sensitive to small\naggregate shocks. We show that supply networks of intermediate productivity are\nfragile in equilibrium, even though this is always inefficient. The endogenous\nconfiguration of supply networks provides a new channel for the powerful\namplification of shocks.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03853v7"
    },
    {
        "title": "Comparing School Choice and College Admission Mechanisms By Their\n  Immunity to Strategic Admissions",
        "authors": [
            "Somouaoga Bonkoungou",
            "Alexander S. Nesterov"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Recently dozens of school districts and college admissions systems around the\nworld have reformed their admission rules. As a main motivation for these\nreforms the policymakers cited strategic flaws of the rules: students had\nstrong incentives to game the system, which caused dramatic consequences for\nnon-strategic students. However, almost none of the new rules were\nstrategy-proof. We explain this puzzle. We show that after the reforms the\nrules became more immune to strategic admissions: each student received a\nsmaller set of schools that he can get in using a strategy, weakening\nincentives to manipulate. Simultaneously, the admission to each school became\nstrategy-proof to a larger set of students, making the schools more available\nfor non-strategic students. We also show that the existing explanation of the\npuzzle due to Pathak and S\\\"onmez (2013) is incomplete.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.06166v2"
    },
    {
        "title": "Infinite-Duration All-Pay Bidding Games",
        "authors": [
            "Guy Avni",
            "Ismaël Jecker",
            "Đorđe Žikelić"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In a two-player zero-sum graph game the players move a token throughout a\ngraph to produce an infinite path, which determines the winner or payoff of the\ngame. Traditionally, the players alternate turns in moving the token. In {\\em\nbidding games}, however, the players have budgets, and in each turn, we hold an\n\"auction\" (bidding) to determine which player moves the token: both players\nsimultaneously submit bids and the higher bidder moves the token. The bidding\nmechanisms differ in their payment schemes. Bidding games were largely studied\nwith variants of {\\em first-price} bidding in which only the higher bidder pays\nhis bid. We focus on {\\em all-pay} bidding, where both players pay their bids.\nFinite-duration all-pay bidding games were studied and shown to be technically\nmore challenging than their first-price counterparts. We study for the first\ntime, infinite-duration all-pay bidding games. Our most interesting results are\nfor {\\em mean-payoff} objectives: we portray a complete picture for games\nplayed on strongly-connected graphs. We study both pure (deterministic) and\nmixed (probabilistic) strategies and completely characterize the optimal sure\nand almost-sure (with probability $1$) payoffs that the players can\nrespectively guarantee. We show that mean-payoff games under all-pay bidding\nexhibit the intriguing mathematical properties of their first-price\ncounterparts; namely, an equivalence with {\\em random-turn games} in which in\neach turn, the player who moves is selected according to a (biased) coin toss.\nThe equivalences for all-pay bidding are more intricate and unexpected than for\nfirst-price bidding.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06636v2"
    },
    {
        "title": "Dynamic information design",
        "authors": [
            "Deepanshu Vasal"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider the problem of dynamic information design with one sender and one\nreceiver where the sender observers a private state of the system and takes an\naction to send a signal based on its observation to a receiver. Based on this\nsignal, the receiver takes an action that determines rewards for both the\nsender and the receiver and controls the state of the system. In this technical\nnote, we show that this problem can be considered as a problem of dynamic game\nof asymmetric information and its perfect Bayesian equilibrium (PBE) and\nStackelberg equilibrium (SE) can be analyzed using the algorithms presented in\n[1], [2] by the same author (among others). We then extend this model when\nthere is one sender and multiple receivers and provide algorithms to compute a\nclass of equilibria of this game.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07267v1"
    },
    {
        "title": "Cooperation in Small Groups -- an Optimal Transport Approach",
        "authors": [
            "Xinyang Wang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  If agents cooperate only within small groups of some bounded sizes, is there\na way to partition the population into small groups such that no collection of\nagents can do better by forming a new group? This paper revisited f-core in a\ntransferable utility setting. By providing a new formulation to the problem, we\nbuilt up a link between f-core and the transportation theory. Such a link helps\nus to establish an exact existence result, and a characterization result of\nf-core for a general class of agents, as well as some improvements in computing\nthe f-core in the finite type case.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.11244v1"
    },
    {
        "title": "Pricing under Fairness Concerns",
        "authors": [
            "Erik Eyster",
            "Kristof Madarasz",
            "Pascal Michaillat"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper proposes a theory of pricing premised upon the assumptions that\ncustomers dislike unfair prices---those marked up steeply over cost---and that\nfirms take these concerns into account when setting prices. Since they do not\nobserve firms' costs, customers must extract costs from prices. The theory\nassumes that customers infer less than rationally: when a price rises due to a\ncost increase, customers partially misattribute the higher price to a higher\nmarkup---which they find unfair. Firms anticipate this response and trim their\nprice increases, which drives the passthrough of costs into prices below one:\nprices are somewhat rigid. Embedded in a New Keynesian model as a replacement\nfor the usual pricing frictions, our theory produces monetary nonneutrality:\nwhen monetary policy loosens and inflation rises, customers misperceive markups\nas higher and feel unfairly treated; firms mitigate this perceived unfairness\nby reducing their markups; in general equilibrium, employment rises. The theory\nalso features a hybrid short-run Phillips curve, realistic impulse responses of\noutput and employment to monetary and technology shocks, and an upward-sloping\nlong-run Phillips curve.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.05656v4"
    },
    {
        "title": "Consumer Privacy and Serial Monopoly",
        "authors": [
            "V. Bhaskar",
            "Nikita Roketskiy"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We examine the implications of consumer privacy when preferences today depend\nupon past consumption choices, and consumers shop from different sellers in\neach period. Although consumers are ex ante identical, their initial\nconsumption choices cannot be deterministic. Thus ex post heterogeneity in\npreferences arises endogenously. Consumer privacy improves social welfare,\nconsumer surplus and the profits of the second-period seller, while reducing\nthe profits of the first period seller, relative to the situation where\nconsumption choices are observed by the later seller.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.07644v1"
    },
    {
        "title": "Asymptotic Behavior of Bayesian Learners with Misspecified Models",
        "authors": [
            "Ignacio Esponda",
            "Demian Pouzo",
            "Yuichi Yamamoto"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We consider an agent who represents uncertainty about the environment via a\npossibly misspecified model. Each period, the agent takes an action, observes a\nconsequence, and uses Bayes' rule to update her belief about the environment.\nThis framework has become increasingly popular in economics to study behavior\ndriven by incorrect or biased beliefs. Current literature has characterized\nasymptotic behavior under fairly specific assumptions. By first showing that\nthe key element to predict the agent's behavior is the frequency of her past\nactions, we are able to characterize asymptotic behavior in general settings in\nterms of the solutions of a generalization of a differential equation that\ndescribes the evolution of the frequency of actions. We then present a series\nof implications that can be readily applied to economic applications, thus\nproviding off-the-shelf tools that can be used to characterize behavior under\nmisspecified learning.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.08551v2"
    },
    {
        "title": "The Category of Node-and-Choice Forms, with Subcategories for\n  Choice-Sequence Forms and Choice-Set Forms",
        "authors": [
            "Peter A. Streufert"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  The literature specifies extensive-form games in many styles, and eventually\nI hope to formally translate games across those styles. Toward that end, this\npaper defines $\\mathbf{NCF}$, the category of node-and-choice forms. The\ncategory's objects are extensive forms in essentially any style, and the\ncategory's isomorphisms are made to accord with the literature's small handful\nof ad hoc style equivalences.\n  Further, this paper develops two full subcategories: $\\mathbf{CsqF}$ for\nforms whose nodes are choice-sequences, and $\\mathbf{CsetF}$ for forms whose\nnodes are choice-sets. I show that $\\mathbf{NCF}$ is \"isomorphically enclosed\"\nin $\\mathbf{CsqF}$ in the sense that each $\\mathbf{NCF}$ form is isomorphic to\na $\\mathbf{CsqF}$ form. Similarly, I show that $\\mathbf{CsqF_{\\tilde a}}$ is\nisomorphically enclosed in $\\mathbf{CsetF}$ in the sense that each\n$\\mathbf{CsqF}$ form with no-absentmindedness is isomorphic to a\n$\\mathbf{CsetF}$ form. The converses are found to be almost immediate, and the\nresulting equivalences unify and simplify two ad hoc style equivalences in\nKline and Luckraz 2016 and Streufert 2019.\n  Aside from the larger agenda, this paper already makes three practical\ncontributions. Style equivalences are made easier to derive by [1] a natural\nconcept of isomorphic invariance and [2] the composability of isomorphic\nenclosures. In addition, [3] some new consequences of equivalence are\nsystematically deduced.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12085v1"
    },
    {
        "title": "Interactive coin offerings",
        "authors": [
            "Jason Teutsch",
            "Vitalik Buterin",
            "Christopher Brown"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Ethereum has emerged as a dynamic platform for exchanging cryptocurrency\ntokens. While token crowdsales cannot simultaneously guarantee buyers both\ncertainty of valuation and certainty of participation, we show that if each\ntoken buyer specifies a desired purchase quantity at each valuation then\neveryone can successfully participate. Our implementation introduces smart\ncontract techniques which recruit outside participants in order to circumvent\ncomputational complexity barriers.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.04295v1"
    },
    {
        "title": "New developments in revealed preference theory: decisions under risk,\n  uncertainty, and intertemporal choice",
        "authors": [
            "Federico Echenique"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This survey reviews recent developments in revealed preference theory. It\ndiscusses the testable implications of theories of choice that are germane to\nspecific economic environments. The focus is on expected utility in risky\nenvironments; subjected expected utility and maxmin expected utility in the\npresence of uncertainty; and exponentially discounted utility for intertemporal\nchoice. The testable implications of these theories for data on choice from\nclassical linear budget sets are described, and shown to follow a common\nthread. The theories all imply an inverse relation between prices and\nquantities, with different qualifications depending on the functional forms in\nthe theory under consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.07561v2"
    },
    {
        "title": "An Experiment on Network Density and Sequential Learning",
        "authors": [
            "Krishna Dasaratha",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We conduct a sequential social-learning experiment where subjects each guess\na hidden state based on private signals and the guesses of a subset of their\npredecessors. A network determines the observable predecessors, and we compare\nsubjects' accuracy on sparse and dense networks. Accuracy gains from social\nlearning are twice as large on sparse networks compared to dense networks.\nModels of naive inference where agents ignore correlation between observations\npredict this comparative static in network density, while the finding is\ndifficult to reconcile with rational-learning models.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.02220v3"
    },
    {
        "title": "Analytical solution of $k$th price auction",
        "authors": [
            "Martin Mihelich",
            "Yan Shu"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We provide an exact analytical solution of the Nash equilibrium for the $k$th\nprice auction by using inverse of distribution functions. As applications, we\nidentify the unique symmetric equilibrium where the valuations have polynomial\ndistribution, fat tail distribution and exponential distributions.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.04865v2"
    },
    {
        "title": "A Generalized Markov Chain Model to Capture Dynamic Preferences and\n  Choice Overload",
        "authors": [
            "Kumar Goutam",
            "Vineet Goyal",
            "Agathe Soret"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Assortment optimization is an important problem that arises in many\nindustries such as retailing and online advertising where the goal is to find a\nsubset of products from a universe of substitutable products which maximize\nseller's expected revenue. One of the key challenges in this problem is to\nmodel the customer substitution behavior. Many parametric random utility\nmaximization (RUM) based choice models have been considered in the literature.\nHowever, in all these models, probability of purchase increases as we include\nmore products to an assortment. This is not true in general and in many\nsettings more choices hurt sales. This is commonly referred to as the choice\noverload. In this paper we attempt to address this limitation in RUM through a\ngeneralization of the Markov chain based choice model considered in Blanchet et\nal. (2016). As a special case, we show that our model reduces to a\ngeneralization of MNL with no-purchase attractions dependent on the assortment\nS and strictly increasing with the size of assortment S. While we show that the\nassortment optimization under this model is NP-hard, we present fully\npolynomial-time approximation scheme (FPTAS) under reasonable assumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.06716v4"
    },
    {
        "title": "Optimal Search and Discovery",
        "authors": [
            "Rafael P. Greminger"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper studies a search problem where a consumer is initially aware of\nonly a few products. At every point in time, the consumer then decides between\nsearching among alternatives he is already aware of and discovering more\nproducts. I show that the optimal policy for this search and discovery problem\nis fully characterized by tractable reservation values. Moreover, I prove that\na predetermined index fully specifies the purchase decision of a consumer\nfollowing the optimal search policy. Finally, a comparison highlights\ndifferences to classical random and directed search.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07773v5"
    },
    {
        "title": "A Multicriteria Macroeconomic Model with Intertemporal Equity and\n  Spatial Spillovers",
        "authors": [
            "Herb Kunze",
            "Davide La Torre",
            "Simone Marsiglio"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We analyze a macroeconomic model with intergenerational equity considerations\nand spatial spillovers, which gives rise to a multicriteria optimization\nproblem. Intergenerational equity requires to add in the definition of social\nwelfare a long run sustainability criterion to the traditional discounted\nutilitarian criterion. The spatial structure allows for the possibility of\nheterogeneiity and spatial diffusion implies that all locations within the\nspatial domain are interconnected via spatial spillovers. We rely on different\ntechniques (scalarization, $\\epsilon$-constraint method and goal programming)\nto analyze such a spatial multicriteria problem, relying on numerical\napproaches to illustrate the nature of the trade-off between the discounted\nutilitarian and the sustainability criteria.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.08247v1"
    },
    {
        "title": "Aggregative Efficiency of Bayesian Learning in Networks",
        "authors": [
            "Krishna Dasaratha",
            "Kevin He"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  When individuals in a social network learn about an unknown state from\nprivate signals and neighbors' actions, the network structure often causes\ninformation loss. We consider rational agents and Gaussian signals in the\ncanonical sequential social-learning problem and ask how the network changes\nthe efficiency of signal aggregation. Rational actions in our model are\nlog-linear functions of observations and admit a signal-counting interpretation\nof accuracy. Networks where agents observe multiple neighbors but not their\ncommon predecessors confound information, and even a small amount of\nconfounding can lead to much lower accuracy. In a class of networks where\nagents move in generations and observe the previous generation, we quantify the\ninformation loss with an aggregative efficiency index. Aggregative efficiency\nis a simple function of network parameters: increasing in observations and\ndecreasing in confounding. Later generations contribute little additional\ninformation, even with arbitrarily large generations.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.10116v9"
    },
    {
        "title": "Envy-free Relaxations for Goods, Chores, and Mixed Items",
        "authors": [
            "Kristóf Bérczi",
            "Erika R. Bérczi-Kovács",
            "Endre Boros",
            "Fekadu Tolessa Gedefa",
            "Naoyuki Kamiyama",
            "Telikepalli Kavitha",
            "Yusuke Kobayashi",
            "Kazuhisa Makino"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In fair division problems, we are given a set $S$ of $m$ items and a set $N$\nof $n$ agents with individual preferences, and the goal is to find an\nallocation of items among agents so that each agent finds the allocation fair.\nThere are several established fairness concepts and envy-freeness is one of the\nmost extensively studied ones. However envy-free allocations do not always\nexist when items are indivisible and this has motivated relaxations of\nenvy-freeness: envy-freeness up to one item (EF1) and envy-freeness up to any\nitem (EFX) are two well-studied relaxations. We consider the problem of finding\nEF1 and EFX allocations for utility functions that are not necessarily\nmonotone, and propose four possible extensions of different strength to this\nsetting.\n  In particular, we present a polynomial-time algorithm for finding an EF1\nallocation for two agents with arbitrary utility functions. An example is given\nshowing that EFX allocations need not exist for two agents with non-monotone,\nnon-additive, identical utility functions. However, when all agents have\nmonotone (not necessarily additive) identical utility functions, we prove that\nan EFX allocation of chores always exists. As a step toward understanding the\ngeneral case, we discuss two subclasses of utility functions: Boolean utilities\nthat are $\\{0,+1\\}$-valued functions, and negative Boolean utilities that are\n$\\{0,-1\\}$-valued functions. For the latter, we give a polynomial time\nalgorithm that finds an EFX allocation when the utility functions are\nidentical.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.04428v1"
    },
    {
        "title": "Optimizing Voting Order on Sequential Juries: A Median Voter Theorem and\n  Beyond",
        "authors": [
            "Steve Alpern",
            "Bo Chen"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider an odd-sized \"jury\", which votes sequentially between two states\nof Nature (say A and B, or Innocent and Guilty) with the majority opinion\ndetermining the verdict. Jurors have private information in the form of a\nsignal in [-1,+1], with higher signals indicating A more likely. Each juror has\nan ability in [0,1], which is proportional to the probability of A given a\npositive signal, an analog of Condorcet's p for binary signals. We assume that\njurors vote honestly for the alternative they view more likely, given their\nsignal and prior voting, because they are experts who want to enhance their\nreputation (after their vote and actual state of Nature is revealed). For a\nfixed set of jury abilities, the reliability of the verdict depends on the\nvoting order. For a jury of size three, the optimal ordering is always as\nfollows: middle ability first, then highest ability, then lowest. For\nsufficiently heterogeneous juries, sequential voting is more reliable than\nsimultaneous voting and is in fact optimal (allowing for non-honest voting).\nWhen average ability is fixed, verdict reliability is increasing in\nheterogeneity.\n  For medium-sized juries, we find through simulation that the median ability\njuror should still vote first and the remaining ones should have increasing and\nthen decreasing abilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14045v2"
    },
    {
        "title": "The Yannelis-Prabhakar Theorem on Upper Semi-Continuous Selections in\n  Paracompact Spaces: Extensions and Applications",
        "authors": [
            "M. Ali Khan",
            "Metin Uyanik"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In a 1983 paper, Yannelis-Prabhakar rely on Michael's selection theorem to\nguarantee a continuous selection in the context of the existence of maximal\nelements and equilibria in abstract economies. In this tribute to Nicholas\nYannelis, we root this paper in Chapter II of Yannelis' 1983 Rochester Ph.D.\ndissertation, and identify its pioneering application of the paracompactness\ncondition to current and ongoing work of Yannelis and his co-authors, and to\nmathematical economics more generally. We move beyond the literature to provide\na necessary and sufficient condition for upper semi-continuous local and global\nselections of correspondences, and to provide application to five domains of\nYannelis' interests: Berge's maximum theorem, the Gale-Nikaido-Debreu lemma,\nthe Gale-McKenzie survival assumption, Shafer's non-transitive setting, and the\nAnderson-Khan-Rashid approximate existence theorem. The last resonates with\nChapter VI of the Yannelis' dissertation.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.16681v1"
    },
    {
        "title": "Misspecified Beliefs about Time Lags",
        "authors": [
            "Yingkai Li",
            "Harry Pei"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We examine the long-term behavior of a Bayesian agent who has a misspecified\nbelief about the time lag between actions and feedback, and learns about the\npayoff consequences of his actions over time. Misspecified beliefs about time\nlags result in attribution errors, which have no long-term effect when the\nagent's action converges, but can lead to arbitrarily large long-term\ninefficiencies when his action cycles. Our proof uses concentration\ninequalities to bound the frequency of action switches, which are useful to\nstudy learning problems with history dependence. We apply our methods to study\na policy choice game between a policy-maker who has a correctly specified\nbelief about the time lag and the public who has a misspecified belief.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.07238v1"
    },
    {
        "title": "Negative votes to depolarize politics",
        "authors": [
            "Karthik H. Shankar"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  The controversies around the 2020 US presidential elections certainly casts\nserious concerns on the efficiency of the current voting system in representing\nthe people's will. Is the naive Plurality voting suitable in an extremely\npolarized political environment? Alternate voting schemes are gradually gaining\npublic support, wherein the voters rank their choices instead of just voting\nfor their first preference. However they do not capture certain crucial aspects\nof voter preferences like disapprovals and negativities against candidates. I\nargue that these unexpressed negativities are the predominant source of\npolarization in politics. I propose a voting scheme with an explicit expression\nof these negative preferences, so that we can simultaneously decipher the\npopularity as well as the polarity of each candidate. The winner is picked by\nan optimal tradeoff between the most popular and the least polarizing\ncandidate. By penalizing the candidates for their polarization, we can\ndiscourage the divisive campaign rhetorics and pave way for potential third\nparty candidates.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.13657v1"
    },
    {
        "title": "Evolutionarily Stable (Mis)specifications: Theory and Applications",
        "authors": [
            "Kevin He",
            "Jonathan Libgober"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Toward explaining the persistence of biased inferences, we propose a\nframework to evaluate competing (mis)specifications in strategic settings.\nAgents with heterogeneous (mis)specifications coexist and draw Bayesian\ninferences about their environment through repeated play. The relative\nstability of (mis)specifications depends on their adherents' equilibrium\npayoffs. A key mechanism is the learning channel: the endogeneity of perceived\nbest replies due to inference. We characterize when a rational society is only\nvulnerable to invasion by some misspecification through the learning channel.\nThe learning channel leads to new stability phenomena, and can confer an\nevolutionary advantage to otherwise detrimental biases in economically relevant\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.15007v4"
    },
    {
        "title": "Monotone additive statistics",
        "authors": [
            "Xiaosheng Mu",
            "Luciano Pomatto",
            "Philipp Strack",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The expectation is an example of a descriptive statistic that is monotone\nwith respect to stochastic dominance, and additive for sums of independent\nrandom variables. We provide a complete characterization of such statistics,\nand explore a number of applications to models of individual and group\ndecision-making. These include a representation of stationary monotone time\npreferences, extending the work of Fishburn and Rubinstein (1982) to time\nlotteries. This extension offers a new perspective on risk attitudes toward\ntime, as well as on the aggregation of multiple discount factors. We also offer\na novel class of nonexpected utility preferences over gambles which satisfy\ninvariance to background risk as well as betweenness, but are versatile enough\nto capture mixed risk attitudes.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00618v5"
    },
    {
        "title": "Games on Endogenous Networks",
        "authors": [
            "Evan Sadler",
            "Benjamin Golub"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study network games in which players choose both the partners with whom\nthey associate and an action level (e.g., effort) that creates spillovers for\nthose partners. We introduce a framework and two solution concepts, extending\nstandard approaches for analyzing each choice in isolation: Nash equilibrium in\nactions and pairwise stability in links. Our main results show that, under\nsuitable order conditions on incentives, stable networks take simple forms. The\nfirst condition concerns whether links create positive or negative payoff\nspillovers. The second concerns whether actions are strategic complements to\nlinks, or strategic substitutes. Together, these conditions yield a taxonomy of\nthe relationship between network structure and economic primitives organized\naround two network architectures: ordered overlapping cliques and nested split\ngraphs. We apply our model to understand the consequences of competition for\nstatus, to microfound matching models that assume clique formation, and to\ninterpret empirical findings that highlight unintended consequences of group\ndesign.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01587v8"
    },
    {
        "title": "Discord and Harmony in Networks",
        "authors": [
            "Andrea Galeotti",
            "Benjamin Golub",
            "Sanjeev Goyal",
            "Rithvik Rao"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Consider a coordination game played on a network, where agents prefer taking\nactions closer to those of their neighbors and to their own ideal points in\naction space. We explore how the welfare outcomes of a coordination game depend\non network structure and the distribution of ideal points throughout the\nnetwork. To this end, we imagine a benevolent or adversarial planner who\nintervenes, at a cost, to change ideal points in order to maximize or minimize\nutilitarian welfare subject to a constraint. A complete characterization of\noptimal interventions is obtained by decomposing interventions into principal\ncomponents of the network's adjacency matrix. Welfare is most sensitive to\ninterventions proportional to the last principal component, which focus on\nlocal disagreement. A welfare-maximizing planner optimally works to reduce\nlocal disagreement, bringing the ideal points of neighbors closer together,\nwhereas a malevolent adversary optimally drives neighbors' ideal points apart\nto decrease welfare. Such welfare-maximizing/minimizing interventions are very\ndifferent from ones that would be done to change some traditional measures of\ndiscord, such as the cross-sectional variation of equilibrium actions. In fact,\nan adversary sowing disagreement to maximize her impact on welfare will\nminimize her impact on global variation in equilibrium actions, underscoring a\ntension between improving welfare and increasing global cohesion of equilibrium\nbehavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.13309v1"
    },
    {
        "title": "Beyond Unbounded Beliefs: How Preferences and Information Interplay in\n  Social Learning",
        "authors": [
            "Navin Kartik",
            "SangMok Lee",
            "Tianhao Liu",
            "Daniel Rappoport"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  When does society eventually learn the truth, or take the correct action, via\nobservational learning? In a general model of sequential learning over social\nnetworks, we identify a simple condition for learning dubbed excludability.\nExcludability is a joint property of agents' preferences and their information.\nWe develop two classes of preferences and information that jointly satisfy\nexcludability: (i) for a one-dimensional state, preferences with\nsingle-crossing differences and a new informational condition, directionally\nunbounded beliefs; and (ii) for a multi-dimensional state, intermediate\npreferences and subexponential location-shift information. These applications\nexemplify that with multiple states \"unbounded beliefs\" is not only unnecessary\nfor learning, but incompatible with familiar informational structures like\nnormal information. Unbounded beliefs demands that a single agent can identify\nthe correct action. Excludability, on the other hand, only requires that a\nsingle agent must be able to displace any wrong action, even if she cannot take\nthe correct action.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.02754v5"
    },
    {
        "title": "Purchase history and product personalization",
        "authors": [
            "Laura Doval",
            "Vasiliki Skreta"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Product personalization opens the door to price discrimination. A rich\nproduct line allows firms to better tailor products to consumers' tastes, but\nthe mere choice of a product carries valuable information about consumers that\ncan be leveraged for price discrimination. We study this trade-off in an\nupstream-downstream model, where a consumer buys a good of variable quality\nupstream, followed by an indivisible good downstream. The downstream firm's use\nof the consumer's purchase history for price discrimination introduces a novel\ndistortion: The upstream firm offers a subset of the products that it would\noffer if, instead, it could jointly design its product line and downstream\npricing. By controlling the degree of product personalization the upstream firm\ncurbs ratcheting forces that result from the consumer facing downstream price\ndiscrimination.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.11504v5"
    },
    {
        "title": "Moving from Linear to Conic Markets for Electricity",
        "authors": [
            "Anubhav Ratha",
            "Pierre Pinson",
            "Hélène Le Cadre",
            "Ana Virag",
            "Jalal Kazempour"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose a new forward electricity market framework that admits\nheterogeneous market participants with second-order cone strategy sets, who\naccurately express the nonlinearities in their costs and constraints through\nconic bids, and a network operator facing conic operational constraints. In\ncontrast to the prevalent linear-programming-based electricity markets, we\nhighlight how the inclusion of second-order cone constraints improves\nuncertainty-, asset- and network-awareness of the market, which is key to the\nsuccessful transition towards an electricity system based on weather-dependent\nrenewable energy sources. We analyze our general market-clearing proposal using\nconic duality theory to derive efficient spatially-differentiated prices for\nthe multiple commodities, comprising of energy and flexibility services. Under\nthe assumption of perfect competition, we prove the equivalence of the\ncentrally-solved market-clearing optimization problem to a competitive spatial\nprice equilibrium involving a set of rational and self-interested participants\nand a price setter. Finally, under common assumptions, we prove that moving\ntowards conic markets does not incur the loss of desirable economic properties\nof markets, namely market efficiency, cost recovery and revenue adequacy. Our\nnumerical studies focus on the specific use case of uncertainty-aware market\ndesign and demonstrate that the proposed conic market brings advantages over\nexisting alternatives within the linear programming market framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.12122v3"
    },
    {
        "title": "Perov's Contraction Principle and Dynamic Programming with Stochastic\n  Discounting",
        "authors": [
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper shows the usefulness of Perov's contraction principle, which\ngeneralizes Banach's contraction principle to a vector-valued metric, for\nstudying dynamic programming problems in which the discount factor can be\nstochastic. The discounting condition $\\beta<1$ is replaced by $\\rho(B)<1$,\nwhere $B$ is an appropriate nonnegative matrix and $\\rho$ denotes the spectral\nradius. Blackwell's sufficient condition is also generalized in this setting.\nApplications to asset pricing and optimal savings are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.14173v2"
    },
    {
        "title": "Star-shaped Risk Measures",
        "authors": [
            "Erio Castagnoli",
            "Giacomo Cattelan",
            "Fabio Maccheroni",
            "Claudio Tebaldi",
            "Ruodu Wang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper monetary risk measures that are positively superhomogeneous,\ncalled star-shaped risk measures, are characterized and their properties\nstudied. The measures in this class, which arise when the controversial\nsubadditivity property of coherent risk measures is dispensed with and positive\nhomogeneity is weakened, include all practically used risk measures, in\nparticular, both convex risk measures and Value-at-Risk. From a financial\nviewpoint, our relaxation of convexity is necessary to quantify the capital\nrequirements for risk exposure in the presence of liquidity risk, competitive\ndelegation, or robust aggregation mechanisms. From a decision theoretical\nperspective, star-shaped risk measures emerge from variational preferences when\nrisk mitigation strategies can be adopted by a rational decision maker.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.15790v3"
    },
    {
        "title": "Wealth Redistribution and Mutual Aid: Comparison using\n  Equivalent/Nonequivalent Exchange Models of Econophysics",
        "authors": [
            "Takeshi Kato"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Given the wealth inequality worldwide, there is an urgent need to identify\nthe mode of wealth exchange through which it arises. To address the research\ngap regarding models that combine equivalent exchange and redistribution, this\nstudy compares an equivalent market exchange with redistribution based on power\ncenters and a nonequivalent exchange with mutual aid using the Polanyi,\nGraeber, and Karatani modes of exchange. Two new exchange models based on\nmulti-agent interactions are reconstructed following an econophysics approach\nfor evaluating the Gini index (inequality) and total exchange (economic flow).\nExchange simulations indicate that the evaluation parameter of the total\nexchange divided by the Gini index can be expressed by the same saturated\ncurvilinear approximate equation using the wealth transfer rate and time period\nof redistribution and the surplus contribution rate of the wealthy and the\nsaving rate. However, considering the coercion of taxes and its associated\ncosts and independence based on the morality of mutual aid, a nonequivalent\nexchange without return obligation is preferred. This is oriented toward\nGraeber's baseline communism and Karatani's mode of exchange D, with\nimplications for alternatives to the capitalist economy.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00091v1"
    },
    {
        "title": "Regret theory, Allais' Paradox, and Savage's omelet",
        "authors": [
            "Vardan G. Bardakhchyan",
            "Armen E. Allahverdyan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study a sufficiently general regret criterion for choosing between two\nprobabilistic lotteries. For independent lotteries, the criterion is consistent\nwith stochastic dominance and can be made transitive by a unique choice of the\nregret function. Together with additional (and intuitively meaningful)\nsuper-additivity property, the regret criterion resolves the Allais' paradox\nincluding the cases were the paradox disappears, and the choices agree with the\nexpected utility. This superadditivity property is also employed for\nestablishing consistency between regret and stochastic dominance for dependent\nlotteries. Furthermore, we demonstrate how the regret criterion can be used in\nSavage's omelet, a classical decision problem in which the lottery outcomes are\nnot fully resolved. The expected utility cannot be used in such situations, as\nit discards important aspects of lotteries.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02447v1"
    },
    {
        "title": "Cutting a Cake Fairly for Groups Revisited",
        "authors": [
            "Erel Segal-Halevi",
            "Warut Suksompong"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Cake cutting is a classic fair division problem, with the cake serving as a\nmetaphor for a heterogeneous divisible resource. Recently, it was shown that\nfor any number of players with arbitrary preferences over a cake, it is\npossible to partition the players into groups of any desired size and divide\nthe cake among the groups so that each group receives a single contiguous piece\nand every player is envy-free. For two groups, we characterize the group sizes\nfor which such an assignment can be computed by a finite algorithm, showing\nthat the task is possible exactly when one of the groups is a singleton. We\nalso establish an analogous existence result for chore division, and show that\nthe result does not hold for a mixed cake.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09061v1"
    },
    {
        "title": "Network-based Referral Mechanism in a Crowdfunding-based Marketing\n  Pattern",
        "authors": [
            "Yongli Li",
            "Zhi-Ping Fan",
            "Wei Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Crowdfunding is gradually becoming a modern marketing pattern. By noting that\nthe success of crowdfunding depends on network externalities, our research aims\nto utilize them to provide an applicable referral mechanism in a\ncrowdfunding-based marketing pattern. In the context of network externalities,\nmeasuring the value of leading customers is chosen as the key to coping with\nthe research problem by considering that leading customers take a critical\nstance in forming a referral network. Accordingly, two sequential-move game\nmodels (i.e., basic model and extended model) were established to measure the\nvalue of leading customers, and a skill of matrix transformation was adopted to\nsolve the model by transforming a complicated multi-sequence game into a simple\nsimultaneous-move game. Based on the defined value of leading customers, a\nnetwork-based referral mechanism was proposed by exploring exactly how many\nawards are allocated along the customer sequence to encourage the leading\ncustomers' actions of successful recommendation and by demonstrating two\ngeneral rules of awarding the referrals in our model setting. Moreover, the\nproposed solution approach helps deepen an understanding of the effect of the\nleading position, which is meaningful for designing more numerous referral\napproaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.03070v1"
    },
    {
        "title": "The strategy of conflict and cooperation",
        "authors": [
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  This paper introduces a unified framework called cooperative extensive form\ngames, which (i) generalizes standard non-cooperative games, and (ii) allows\nfor more complex coalition formation dynamics than previous concepts like\ncoalition-proof Nash equilibrium. Central to this framework is a novel solution\nconcept called cooperative equilibrium system (CES). CES differs from Nash\nequilibrium in two important respects. First, a CES is immune to both\nunilateral and multilateral `credible' deviations. Second, unlike Nash\nequilibrium, whose stability relies on the assumption that the strategies of\nnon-deviating players are held fixed, CES allows for the possibility that\nplayers may regroup and adjust their strategies in response to a deviation. The\nmain result establishes that every cooperative extensive form game, possibly\nwith imperfect information, possesses a CES. For games with perfect\ninformation, the proof is constructive. This framework is broadly applicable in\ncontexts such as oligopolistic markets and dynamic political bargaining.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.06750v7"
    },
    {
        "title": "Multilateral Index Number Systems for International Price Comparisons:\n  Properties, Existence and Uniqueness",
        "authors": [
            "Gholamreza Hajargasht",
            "Prasada Rao"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  Over the past five decades a number of multilateral index number systems have\nbeen proposed for spatial and cross-country price comparisons. These\nmultilateral indexes are usually expressed as solutions to systems of linear or\nnonlinear equations. In this paper, we provide general theorems that can be\nused to establish necessary and sufficient conditions for the existence and\nuniqueness of the Geary-Khamis, IDB, Neary and Rao indexes as well as potential\nnew systems including two generalized systems of index numbers. One of our main\nresults is that the necessary and sufficient conditions for existence and\nuniqueness of solutions can often be stated in terms of graph-theoretic\nconcepts and a verifiable condition based on observed quantities of\ncommodities.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.04197v2"
    },
    {
        "title": "Solving the Reswitching Paradox in the Sraffian Theory of Capital",
        "authors": [
            "Carlo Milana"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  The possibility of re-switching of techniques in Piero Sraffa's intersectoral\nmodel, namely the returning capital-intensive techniques with monotonic changes\nin the profit rate, is traditionally considered as a paradox putting at stake\nthe viability of the neoclassical theory of production. It is argued here that\nthis phenomenon can be rationalized within the neoclassical paradigm. Sectoral\ninterdependencies can give rise to non-monotonic effects of progressive\nvariations in income distribution on relative prices. The re-switching of\ntechniques is, therefore, the result of cost-minimizing technical choices\nfacing returning ranks of relative input prices in full consistency with the\nneoclassical perspective.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.01189v5"
    },
    {
        "title": "Competing Models",
        "authors": [
            "Jose Luis Montiel Olea",
            "Pietro Ortoleva",
            "Mallesh M Pai",
            "Andrea Prat"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Different agents need to make a prediction. They observe identical data, but\nhave different models: they predict using different explanatory variables. We\nstudy which agent believes they have the best predictive ability -- as measured\nby the smallest subjective posterior mean squared prediction error -- and show\nhow it depends on the sample size. With small samples, we present results\nsuggesting it is an agent using a low-dimensional model. With large samples, it\nis generally an agent with a high-dimensional model, possibly including\nirrelevant variables, but never excluding relevant ones. We apply our results\nto characterize the winning model in an auction of productive assets, to argue\nthat entrepreneurs and investors with simple models will be over-represented in\nnew sectors, and to understand the proliferation of \"factors\" that explain the\ncross-sectional variation of expected stock returns in the asset-pricing\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.03809v5"
    },
    {
        "title": "Necessary and sufficient condition for equilibrium of the Hotelling\n  model",
        "authors": [
            "Satoshi Hayashi",
            "Naoki Tsuge"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We study a model of vendors competing to sell a homogeneous product to\ncustomers spread evenly along a linear city. This model is based on Hotelling's\ncelebrated paper in 1929. Our aim in this paper is to present a necessary and\nsufficient condition for the equilibrium. This yields a representation for the\nequilibrium. To achieve this, we first formulate the model mathematically.\nNext, we prove that the condition holds if and only if vendors are equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.06200v1"
    },
    {
        "title": "Behavioural Macroeconomic Policy: New perspectives on time inconsistency",
        "authors": [
            "Michelle Baddeley"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This paper brings together divergent approaches to time inconsistency from\nmacroeconomic policy and behavioural economics. Behavioural discount functions\nfrom behavioural microeconomics are embedded into a game-theoretic analysis of\ntemptation versus enforcement to construct an encompassing model, nesting\ncombinations of time consistent and time inconsistent preferences. The analysis\npresented in this paper shows that, with hyperbolic/quasihyperbolic\ndiscounting, the enforceable range of inflation targets is narrowed. This\nsuggests limits to the effectiveness of monetary targets, under certain\nconditions. The paper concludes with a discussion of monetary policy\nimplications, explored specifically in the light of current macroeconomic\npolicy debates.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.07858v1"
    },
    {
        "title": "Optimal auctions for networked markets with externalities",
        "authors": [
            "Benjamin Heymann",
            "Alejandro Jofré"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Motivated by the problem of market power in electricity markets, we\nintroduced in previous works a mechanism for simplified markets of two agents\nwith linear cost. In standard procurement auctions, the market power resulting\nfrom the quadratic transmission losses allows the producers to bid above their\ntrue values, which are their production cost. The mechanism proposed in the\nprevious paper optimally reduces the producers' margin to the society's\nbenefit. In this paper, we extend those results to a more general market made\nof a finite number of agents with piecewise linear cost functions, which makes\nthe problem more difficult, but simultaneously more realistic. We show that the\nmethodology works for a large class of externalities. We also provide an\nalgorithm to solve the principal allocation problem. Our contribution provides\na benchmark to assess the sub-optimality of the mechanisms used in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10080v1"
    },
    {
        "title": "Microfoundations of Discounting",
        "authors": [
            "Alexander T. I. Adamou",
            "Yonatan Berman",
            "Diomides P. Mavroyiannis",
            "Ole B. Peters"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  An important question in economics is how people choose between different\npayments in the future. The classical normative model predicts that a decision\nmaker discounts a later payment relative to an earlier one by an exponential\nfunction of the time between them. Descriptive models use non-exponential\nfunctions to fit observed behavioral phenomena, such as preference reversal.\nHere we propose a model of discounting, consistent with standard axioms of\nchoice, in which decision makers maximize the growth rate of their wealth. Four\nspecifications of the model produce four forms of discounting -- no\ndiscounting, exponential, hyperbolic, and a hybrid of exponential and\nhyperbolic -- two of which predict preference reversal. Our model requires no\nassumption of behavioral bias or payment risk.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.02137v3"
    },
    {
        "title": "Optimal Control of Prevention and Treatment in a Basic\n  Macroeconomic-Epidemiological Model",
        "authors": [
            "Davide La Torre",
            "Tufail Malik",
            "Simone Marsiglio"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We analyze the optimal control of disease prevention and treatment in a basic\nSIS model. We develop a simple macroeconomic setup in which the social planner\ndetermines how to optimally intervene, through income taxation, in order to\nminimize the social cost, inclusive of infection and economic costs, of the\nspread of an epidemic disease. The disease lowers economic production and thus\nincome by reducing the size of the labor force employed in productive\nactivities, tightening thus the economy's overall resources constraint. We\nconsider a framework in which the planner uses the collected tax revenue to\nintervene in either prevention (aimed at reducing the rate of infection) or\ntreatment (aimed at increasing the speed of recovery). Both optimal prevention\nand treatment policies allow the economy to achieve a disease-free equilibrium\nin the long run but their associated costs are substantially different along\nthe transitional dynamic path. By quantifying the social costs associated with\nprevention and treatment we determine which policy is most cost-effective under\ndifferent circumstances, showing that prevention (treatment) is desirable\nwhenever the infectivity rate is low (high).\n",
        "pdf_link": "http://arxiv.org/pdf/1910.03383v1"
    },
    {
        "title": "Measuring the Completeness of Theories",
        "authors": [
            "Drew Fudenberg",
            "Jon Kleinberg",
            "Annie Liang",
            "Sendhil Mullainathan"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  We use machine learning to provide a tractable measure of the amount of\npredictable variation in the data that a theory captures, which we call its\n\"completeness.\" We apply this measure to three problems: assigning certain\nequivalents to lotteries, initial play in games, and human generation of random\nsequences. We discover considerable variation in the completeness of existing\nmodels, which sheds light on whether to focus on developing better models with\nthe same features or instead to look for new features that will improve\npredictions. We also illustrate how and why completeness varies with the\nexperiments considered, which highlights the role played in choosing which\nexperiments to run.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.07022v1"
    },
    {
        "title": "Building social networks under consent: A survey",
        "authors": [
            "Robert P. Gilles"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  This survey explores the literature on game-theoretic models of network\nformation under the hypothesis of mutual consent in link formation. The\nintroduction of consent in link formation imposes a coordination problem in the\nnetwork formation process. This survey explores the conclusions from this\ntheory and the various methodologies to avoid the main pitfalls. The main\ninsight originates from Myerson's work on mutual consent in link formation and\nhis main conclusion that the empty network (the network without any links)\nalways emerges as a strong Nash equilibrium in any game-theoretic model of\nnetwork formation under mutual consent and positive link formation costs.\nJackson and Wolinsky introduced a cooperative framework to avoid this main\npitfall. They devised the notion of a pairwise stable network to arrive at\nequilibrium networks that are mainly non-trivial. Unfortunately, this notion of\npairwise stability requires coordinated action by pairs of decision makers in\nlink formation. I survey the possible solutions in a purely non-cooperative\nframework of network formation under mutual consent by exploring potential\nrefinements of the standard Nash equilibrium concept to explain the emergence\nof non-trivial networks. This includes the notions of unilateral and monadic\nstability. The first one is founded on advanced rational reasoning of\nindividuals about how others would respond to one's efforts to modify the\nnetwork. The latter incorporates trusting, boundedly rational behaviour into\nthe network formation process. The survey is concluded with an initial\nexploration of external correlation devices as an alternative framework to\naddress mutual consent in network formation.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11693v2"
    },
    {
        "title": "Hipsters and the Cool: A Game Theoretic Analysis of Social Identity,\n  Trends and Fads",
        "authors": [
            "Russell Golman",
            "Aditi Jain",
            "Sonica Saraf"
        ],
        "category": "econ.TH",
        "published_year": "2019",
        "summary": "  Cultural trends and popularity cycles can be observed all around us, yet our\ntheories of social influence and identity expression do not explain what\nperpetuates these complex, often unpredictable social dynamics. We propose a\ntheory of social identity expression based on the opposing, but not mutually\nexclusive, motives to conform and to be unique among one's neighbors in a\nsocial network. We then model the social dynamics that arise from these\nmotives. We find that the dynamics typically enter random walks or stochastic\nlimit cycles rather than converging to a static equilibrium. We also prove that\nwithout social network structure or, alternatively, without the uniqueness\nmotive, reasonable adaptive dynamics would necessarily converge to equilibrium.\nThus, we show that nuanced psychological assumptions (recognizing preferences\nfor uniqueness along with conformity) and realistic social network structure\nare both necessary for explaining how complex, unpredictable cultural trends\nemerge.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13385v1"
    },
    {
        "title": "Reinforcement Learning in Economics and Finance",
        "authors": [
            "Arthur Charpentier",
            "Romuald Elie",
            "Carl Remlinger"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Reinforcement learning algorithms describe how an agent can learn an optimal\naction policy in a sequential decision process, through repeated experience. In\na given environment, the agent policy provides him some running and terminal\nrewards. As in online learning, the agent learns sequentially. As in\nmulti-armed bandit problems, when an agent picks an action, he can not infer\nex-post the rewards induced by other action choices. In reinforcement learning,\nhis actions have consequences: they influence not only rewards, but also future\nstates of the world. The goal of reinforcement learning is to find an optimal\npolicy -- a mapping from the states of the world to the set of actions, in\norder to maximize cumulative reward, which is a long term strategy. Exploring\nmight be sub-optimal on a short-term horizon but could lead to optimal\nlong-term ones. Many problems of optimal control, popular in economics for more\nthan forty years, can be expressed in the reinforcement learning framework, and\nrecent advances in computational science, provided in particular by deep\nlearning algorithms, can be used by economists in order to solve complex\nbehavioral problems. In this article, we propose a state-of-the-art of\nreinforcement learning techniques, and present applications in economics, game\ntheory, operation research and finance.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.10014v1"
    },
    {
        "title": "On the Structure of Stable Tournament Solutions",
        "authors": [
            "Felix Brandt",
            "Markus Brill",
            "Hans Georg Seedig",
            "Warut Suksompong"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  A fundamental property of choice functions is stability, which, loosely\nspeaking, prescribes that choice sets are invariant under adding and removing\nunchosen alternatives. We provide several structural insights that improve our\nunderstanding of stable choice functions. In particular, (i) we show that every\nstable choice function is generated by a unique simple choice function, which\nnever excludes more than one alternative, (ii) we completely characterize which\nsimple choice functions give rise to stable choice functions, and (iii) we\nprove a strong relationship between stability and a new property of tournament\nsolutions called local reversal symmetry. Based on these findings, we provide\nthe first concrete tournament---consisting of 24 alternatives---in which the\ntournament equilibrium set fails to be stable. Furthermore, we prove that there\nis no more discriminating stable tournament solution than the bipartisan set\nand that the bipartisan set is the unique most discriminating tournament\nsolution which satisfies standard properties proposed in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01651v1"
    },
    {
        "title": "Manipulation-Proof Machine Learning",
        "authors": [
            "Daniel Björkegren",
            "Joshua E. Blumenstock",
            "Samsun Knight"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  An increasing number of decisions are guided by machine learning algorithms.\nIn many settings, from consumer credit to criminal justice, those decisions are\nmade by applying an estimator to data on an individual's observed behavior. But\nwhen consequential decisions are encoded in rules, individuals may\nstrategically alter their behavior to achieve desired outcomes. This paper\ndevelops a new class of estimator that is stable under manipulation, even when\nthe decision rule is fully transparent. We explicitly model the costs of\nmanipulating different behaviors, and identify decision rules that are stable\nin equilibrium. Through a large field experiment in Kenya, we show that\ndecision rules estimated with our strategy-robust method outperform those based\non standard supervised learning approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.03865v1"
    },
    {
        "title": "Mean Field Game Approach to Bitcoin Mining",
        "authors": [
            "Charles Bertucci",
            "Louis Bertucci",
            "Jean-Michel Lasry",
            "Pierre-Louis Lions"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We present an analysis of the Proof-of-Work consensus algorithm, used on the\nBitcoin blockchain, using a Mean Field Game framework. Using a master equation,\nwe provide an equilibrium characterization of the total computational power\ndevoted to mining the blockchain (hashrate). From a simple setting we show how\nthe master equation approach allows us to enrich the model by relaxing most of\nthe simplifying assumptions. The essential structure of the game is preserved\nacross all the enrichments. In deterministic settings, the hashrate ultimately\nreaches a steady state in which it increases at the rate of technological\nprogress. In stochastic settings, there exists a target for the hashrate for\nevery possible random state. As a consequence, we show that in equilibrium the\nsecurity of the underlying blockchain is either $i)$ constant, or $ii)$\nincreases with the demand for the underlying cryptocurrency.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.08167v1"
    },
    {
        "title": "The Category of Node-and-Choice Extensive-Form Games",
        "authors": [
            "Peter A. Streufert"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper develops the category $\\mathbf{NCG}$. Its objects are\nnode-and-choice games, which include essentially all extensive-form games. Its\nmorphisms allow arbitrary transformations of a game's nodes, choices, and\nplayers, as well as monotonic transformations of the utility functions of the\ngame's players. Among the morphisms are subgame inclusions. Several\ncharacterizations and numerous properties of the isomorphisms are derived. For\nexample, it is shown that isomorphisms preserve the game-theoretic concepts of\nno-absentmindedness, perfect-information, and (pure-strategy) Nash-equilibrium.\nFinally, full subcategories are defined for choice-sequence games and\nchoice-set games, and relationships among these two subcategories and\n$\\mathbf{NCG}$ itself are expressed and derived via isomorphic inclusions and\nequivalences.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.11196v2"
    },
    {
        "title": "Soft Affirmative Action and Minority Recruitment",
        "authors": [
            "Daniel Fershtman",
            "Alessandro Pavan"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We study search, evaluation, and selection of candidates of unknown quality\nfor a position. We examine the effects of \"soft\" affirmative action policies\nincreasing the relative percentage of minority candidates in the candidate\npool. We show that, while meant to encourage minority hiring, such policies may\nbackfire if the evaluation of minority candidates is noisier than that of\nnon-minorities. This may occur even if minorities are at least as qualified and\nas valuable as non-minorities. The results provide a possible explanation for\nwhy certain soft affirmative action policies have proved counterproductive,\neven in the absence of (implicit) biases.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.14953v1"
    },
    {
        "title": "Is there a Golden Parachute in Sannikov's principal-agent problem?",
        "authors": [
            "Dylan Possamaï",
            "Nizar Touzi"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper provides a complete review of the continuous-time optimal\ncontracting problem introduced by Sannikov, in the extended context allowing\nfor possibly different discount rates for both parties. The agent's problem is\nto seek for optimal effort, given the compensation scheme proposed by the\nprincipal over a random horizon. Then, given the optimal agent's response, the\nprincipal determines the best compensation scheme in terms of running payment,\nretirement, and lump-sum payment at retirement. A Golden Parachute is a\nsituation where the agent ceases any effort at some positive stopping time, and\nreceives a payment afterwards, possibly under the form of a lump sum payment,\nor of a continuous stream of payments. We show that a Golden Parachute only\nexists in certain specific circumstances. This is in contrast with the results\nclaimed by Sannikov, where the only requirement is a positive agent's marginal\ncost of effort at zero. Namely, we show that there is no Golden Parachute if\nthis parameter is too large. Similarly, in the context of a concave marginal\nutility, there is no Golden Parachute if the agent's utility function has a too\nnegative curvature at zero. In the general case, we prove that an agent with\npositive reservation utility is either never retired by the principal, or\nretired above some given threshold (as in Sannikov's solution). We show that\ndifferent discount factors induce a face-lifted utility function, which allows\nto reduce the analysis to a setting similar to the equal discount rates one.\nFinally, we also confirm that an agent with small reservation utility may have\nan informational rent, meaning that the principal optimally offers him a\ncontract with strictly higher utility than his participation value.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.05529v2"
    },
    {
        "title": "How Flexible is that Functional Form? Quantifying the Restrictiveness of\n  Theories",
        "authors": [
            "Drew Fudenberg",
            "Wayne Gao",
            "Annie Liang"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We propose a restrictiveness measure for economic models based on how well\nthey fit synthetic data from a pre-defined class. This measure, together with a\nmeasure for how well the model fits real data, outlines a Pareto frontier,\nwhere models that rule out more regularities, yet capture the regularities that\nare present in real data, are preferred. To illustrate our approach, we\nevaluate the restrictiveness of popular models in two laboratory settings --\ncertainty equivalents and initial play -- and in one field setting -- takeup of\nmicrofinance in Indian villages. The restrictiveness measure reveals new\ninsights about each of the models, including that some economic models with\nonly a few parameters are very flexible.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09213v4"
    },
    {
        "title": "On Statistical Discrimination as a Failure of Social Learning: A\n  Multi-Armed Bandit Approach",
        "authors": [
            "Junpei Komiyama",
            "Shunya Noda"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We analyze statistical discrimination in hiring markets using a multi-armed\nbandit model. Myopic firms face workers arriving with heterogeneous observable\ncharacteristics. The association between the worker's skill and characteristics\nis unknown ex ante; thus, firms need to learn it. Laissez-faire causes\nperpetual underestimation: minority workers are rarely hired, and therefore,\nthe underestimation tends to persist. Even a marginal imbalance in the\npopulation ratio frequently results in perpetual underestimation. We propose\ntwo policy solutions: a novel subsidy rule (the hybrid mechanism) and the\nRooney Rule. Our results indicate that temporary affirmative actions\neffectively alleviate discrimination stemming from insufficient data.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.01079v6"
    },
    {
        "title": "Social networks, confirmation bias and shock elections",
        "authors": [
            "Edoardo Gallo",
            "Alastair Langtry"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In recent years online social networks have become increasingly prominent in\npolitical campaigns and, concurrently, several countries have experienced shock\nelection outcomes. This paper proposes a model that links these two phenomena.\nIn our set-up, the process of learning from others on a network is influenced\nby confirmation bias, i.e. the tendency to ignore contrary evidence and\ninterpret it as consistent with one's own belief. When agents pay enough\nattention to themselves, confirmation bias leads to slower learning in any\nsymmetric network, and it increases polarization in society. We identify a\nsubset of agents that become more/less influential with confirmation bias. The\nsocially optimal network structure depends critically on the information\navailable to the social planner. When she cannot observe agents' beliefs, the\noptimal network is symmetric, vertex-transitive and has no self-loops. We\nexplore the implications of these results for electoral outcomes and media\nmarkets. Confirmation bias increases the likelihood of shock elections, and it\npushes fringe media to take a more extreme ideology.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.00520v1"
    },
    {
        "title": "Endogenous structural transformation in economic development",
        "authors": [
            "Justin Y. F. Lin",
            "Haipeng Xing"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper extends Xing's (2023abcd) optimal growth models of catching-up\neconomies from the case of production function switching to that of economic\nstructure switching and argues how a country develops its economy by endogenous\nstructural transformation and efficient resource allocation in a market\nmechanism. To achieve this goal, the paper first summarizes three attributes of\neconomic structures from the literature, namely, structurality, durationality,\nand transformality, and discuss their implications for methods of economic\nmodeling. Then, with the common knowledge assumption, the paper extends Xing's\n(2023a) optimal growth model that is based on production function switching and\nconsiders an extended Ramsey model with endogenous structural transformation in\nwhich the social planner chooses the optimal industrial structure, recource\nallocation with the chosen structure, and consumption to maximize the\nrepresentative household's total utility subject to the resource constraint.\nThe paper next establishes the mathematical underpinning of the static,\ndynamic, and switching equilibria. The Ramsey growth model and its equilibria\nare then extended to economies with complicated economic structures consisting\nof hierarchical production, technology adoption and innovation, infrastructure,\nand economic and political institutions. The paper concludes with a brief\ndiscussion of applications of the proposed methodology to economic development\nproblems in other scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.03695v3"
    },
    {
        "title": "Persuasion Produces the (Diamond) Paradox",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  This paper extends the sequential search model of Wolinsky (1986) by allowing\nfirms to choose how much match value information to disclose to visiting\nconsumers. This restores the Diamond paradox (Diamond 1971): there exist no\nsymmetric equilibria in which consumers engage in active search, so consumers\nobtain zero surplus and firms obtain monopoly profits. Modifying the scenario\nto one in which prices are advertised, we discover that the no-active-search\nresult persists, although the resulting symmetric equilibria are ones in which\nfirms price at marginal cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.13900v4"
    },
    {
        "title": "Best-response dynamics, playing sequences, and convergence to\n  equilibrium in random games",
        "authors": [
            "Torsten Heinrich",
            "Yoojin Jang",
            "Luca Mungo",
            "Marco Pangallo",
            "Alex Scott",
            "Bassel Tarbush",
            "Samuel Wiese"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We analyze the performance of the best-response dynamic across all\nnormal-form games using a random games approach. The playing sequence -- the\norder in which players update their actions -- is essentially irrelevant in\ndetermining whether the dynamic converges to a Nash equilibrium in certain\nclasses of games (e.g. in potential games) but, when evaluated across all\npossible games, convergence to equilibrium depends on the playing sequence in\nan extreme way. Our main asymptotic result shows that the best-response dynamic\nconverges to a pure Nash equilibrium in a vanishingly small fraction of all\n(large) games when players take turns according to a fixed cyclic order. By\ncontrast, when the playing sequence is random, the dynamic converges to a pure\nNash equilibrium if one exists in almost all (large) games.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.04222v3"
    },
    {
        "title": "Relief and Stimulus in A Cross-sector Multi-product Scarce Resource\n  Supply Chain Network",
        "authors": [
            "Xiaowei Hu",
            "Peng Li"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In the era of a growing population, systemic changes to the world, and the\nrising risk of crises, humanity has been facing an unprecedented challenge of\nresource scarcity. Confronting and addressing the issues concerning the scarce\nresource's conservation, competition, and stimulation by grappling its\ncharacteristics and adopting viable policy instruments calls the\ndecision-maker's attention with a paramount priority. In this paper, we develop\nthe first general decentralized cross-sector supply chain network model that\ncaptures the unique features of scarce resources under a unifying fiscal policy\nscheme. We formulate the problem as a network equilibrium model with\nfinite-dimensional variational inequality theories. We then characterize the\nnetwork equilibrium with a set of classic theoretical properties, as well as\nwith a set of properties that are novel to the network games application\nliterature, namely, the lowest eigenvalue of the game Jacobian. Lastly, we\nprovide a series of illustrative examples, including a medical glove supply\nnetwork, to showcase how our model can be used to investigate the efficacy of\nthe imposed policies in relieving supply chain distress and stimulating\nwelfare. Our managerial insights inform and expand the political dialogues on\nfiscal policy design, public resource legislation, social welfare\nredistribution, and supply chain practice toward sustainability.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.09373v3"
    },
    {
        "title": "Robust Experimentation in the Continuous Time Bandit Problem",
        "authors": [
            "Farzad Pourbabaee"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the experimentation dynamics of a decision maker (DM) in a two-armed\nbandit setup (Bolton and Harris (1999)), where the agent holds ambiguous\nbeliefs regarding the distribution of the return process of one arm and is\ncertain about the other one. The DM entertains Multiplier preferences a la\nHansen and Sargent (2001), thus we frame the decision making environment as a\ntwo-player differential game against nature in continuous time. We characterize\nthe DM value function and her optimal experimentation strategy that turns out\nto follow a cut-off rule with respect to her belief process. The belief\nthreshold for exploring the ambiguous arm is found in closed form and is shown\nto be increasing with respect to the ambiguity aversion index. We then study\nthe effect of provision of an unambiguous information source about the\nambiguous arm. Interestingly, we show that the exploration threshold rises\nunambiguously as a result of this new information source, thereby leading to\nmore conservatism. This analysis also sheds light on the efficient time to\nreach for an expert opinion.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.00102v1"
    },
    {
        "title": "A Rational Inattention Theory of Echo Chamber",
        "authors": [
            "Lin Hu",
            "Anqi Li",
            "Xu Tan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We develop a rational inattention theory of echo chambers, where players\nallocate limited attention across biased primary sources and other players to\ngather information about an uncertain state. The resulting Poisson attention\nnetwork transmits information from the primary source to a player either\ndirectly or indirectly through other players. Rational inattention creates\nheterogeneous information demands among players who are biased toward different\ndecisions. In an echo-chamber equilibrium, each player focuses on his\nown-biased source and like-minded friends, who attend to the same primary\nsource as his and can serve as secondary sources if the attention channel from\nthe primary source to him is disrupted. We establish conditions for the\nemergence of echo-chamber equilibria, characterize the attention networks\nwithin echo chambers, and offer insights for designing and regulating\ninformation platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.10657v8"
    },
    {
        "title": "Search and Competition with Flexible Investigations",
        "authors": [
            "Vasudha Jain",
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We modify the standard model of price competition with horizontally\ndifferentiated products, imperfect information, and search frictions by\nallowing consumers to flexibly acquire information about a product's match\nvalue during their visits. We characterize a consumer's optimal search and\ninformation acquisition protocol and analyze the pricing game between firms.\nNotably, we establish that in search markets there are fundamental differences\nbetween search frictions and information frictions, which affect market prices,\nprofits, and consumer welfare in markedly different ways. Although higher\nsearch costs beget higher prices (and profits for firms), higher information\nacquisition costs lead to lower prices and may benefit consumers. We discuss\nimplications of our findings for policies concerning disclosure rules and\nhidden fees.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.13159v1"
    },
    {
        "title": "Reputational Bargaining with Ultimatum Opportunities",
        "authors": [
            "Mehmet Ekmekci",
            "Hanzhe Zhang"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study two-sided reputational bargaining with opportunities to issue an\nultimatum -- threats to force dispute resolution. Each player is either a\njustified type, who never concedes and issues an ultimatum whenever an\nopportunity arrives, or an unjustified type, who can concede, wait, or bluff\nwith an ultimatum. In equilibrium, the presence of ultimatum opportunities can\nharm or benefit a player by decelerating or accelerating reputation building.\nWhen only one player can issue an ultimatum, equilibrium play is unique. The\nhazard rate of dispute resolution is discontinuous and piecewise monotonic in\ntime. As the probabilities of being justified vanish, agreement is immediate\nand efficient, and if the set of justifiable demands is rich, payoffs modify\nAbreu and Gul (2000), with the discount rate replaced by the ultimatum\nopportunity arrival rate if the former is smaller. When both players' ultimatum\nopportunities arrive sufficiently fast, there may exist multiple equilibria in\nwhich their reputations do not build up and negotiation lasts forever.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.01581v1"
    },
    {
        "title": "Sustainability of Collusion and Market Transparency in a Sequential\n  Search Market: a Generalization",
        "authors": [
            "Jacopo De Tullio",
            "Giuseppe Puleio"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The present work generalizes the analytical results of Petrikaite (2016) to a\nmarket where more than two firms interact. As a consequence, for a generic\nnumber of firms in the oligopoly model described by Janssen et al (2005), the\nrelationship between the critical discount factor which sustains the monopoly\ncollusive allocation and the share of perfectly informed buyers is\nnon-monotonic, reaching a unique internal point of minimum. The first section\nlocates the work within the proper economic framework. The second section hosts\nthe analytical computations and the mathematical reasoning needed to derive the\ndesired generalization, which mainly relies on the Leibniz rule for the\ndifferentiation under the integral sign and the Bounded Convergence Theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.02094v1"
    },
    {
        "title": "Learning from zero: how to make consumption-saving decisions in a\n  stochastic environment with an AI algorithm",
        "authors": [
            " Rui",
            " Shi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This exercise proposes a learning mechanism to model economic agent's\ndecision-making process using an actor-critic structure in the literature of\nartificial intelligence. It is motivated by the psychology literature of\nlearning through reinforcing good or bad decisions. In a model of an\nenvironment, to learn to make decisions, this AI agent needs to interact with\nits environment and make explorative actions. Each action in a given state\nbrings a reward signal to the agent. These interactive experience is saved in\nthe agent's memory, which is then used to update its subjective belief of the\nworld. The agent's decision-making strategy is formed and adjusted based on\nthis evolving subjective belief. This agent does not only take an action that\nit knows would bring a high reward, it also explores other possibilities. This\nis the process of taking explorative actions, and it ensures that the agent\nnotices changes in its environment and adapt its subjective belief and\ndecisions accordingly. Through a model of stochastic optimal growth, I\nillustrate that the economic agent under this proposed learning structure is\nadaptive to changes in an underlying stochastic process of the economy. AI\nagents can differ in their levels of exploration, which leads to different\nexperience in the same environment. This reflects on to their different\nlearning behaviours and welfare obtained. The chosen economic structure\npossesses the fundamental decision making problems of macroeconomic models,\ni.e., how to make consumption-saving decisions in a lifetime, and it can be\ngeneralised to other decision-making processes and economic models.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10099v2"
    },
    {
        "title": "A Category for Extensive-Form Games",
        "authors": [
            "Peter A. Streufert"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper introduces Gm, which is a category for extensive-form games. It\nalso provides some applications.\n  The category's objects are games, which are understood to be sets of nodes\nwhich have been endowed with edges, information sets, actions, players, and\nutility functions. Its arrows are functions from source nodes to target nodes\nthat preserve the additional structure. For instance, a game's information-set\ncollection is newly regarded as a topological basis for the game's\ndecision-node set, and thus a morphism's continuity serves to preserve\ninformation sets. Given these definitions, a game monomorphism is characterized\nby the property of not mapping two source runs (plays) to the same target run.\nFurther, a game isomorphism is characterized as a bijection whose restriction\nto decision nodes is a homeomorphism, whose induced player transformation is\ninjective, and which strictly preserves the ordinal content of the utility\nfunctions.\n  The category is then applied to some game-theoretic concepts beyond the\ndefinition of a game. A Selten subgame is characterized as a special kind of\ncategorical subgame, and game isomorphisms are shown to preserve strategy sets,\nNash equilibria, Selten subgames, subgame-perfect equilibria,\nperfect-information, and no-absentmindedness. Further, it is shown that the\nfull subcategory for distinguished-action sequence games is essentially wide in\nthe category of all games, and that the full subcategory of action-set games is\nessentially wide in the full subcategory for games with no-absentmindedness.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11398v1"
    },
    {
        "title": "Multi-Dimensional Screening: Buyer-Optimal Learning and Informational\n  Robustness",
        "authors": [
            "Rahul Deb",
            "Anne-Katrin Roesler"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A monopolist seller of multiple goods screens a buyer whose type is initially\nunknown to both but drawn from a commonly known distribution. The buyer\nprivately learns about his type via a signal. We derive the seller's optimal\nmechanism in two different information environments. We begin by deriving the\nbuyer-optimal outcome. Here, an information designer first selects a signal,\nand then the seller chooses an optimal mechanism in response; the designer's\nobjective is to maximize consumer surplus. Then, we derive the optimal\ninformationally robust mechanism. In this case, the seller first chooses the\nmechanism, and then nature picks the signal that minimizes the seller's\nprofits. We derive the relation between both problems and show that the optimal\nmechanism in both cases takes the form of pure bundling.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.12304v1"
    },
    {
        "title": "Ordered Reference Dependent Choice",
        "authors": [
            "Xi Zhi Lim"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies how violations of structural assumptions like expected\nutility and exponential discounting can be connected to basic rationality\nviolations, even though these assumptions are typically regarded as independent\nbuilding blocks in decision theory. A reference-dependent generalization of\nbehavioral postulates captures preference shifts in various choice domains.\nWhen reference points are fixed, canonical models hold; otherwise,\nreference-dependent preference parameters (e.g., CARA coefficients, discount\nfactors) give rise to \"non-standard\" behavior. The framework allows us to study\nrisk, time, and social preferences collectively, where seemingly independent\nanomalies are interconnected through the lens of reference-dependent choice.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.12915v5"
    },
    {
        "title": "An algebraic approach to revealed preferences",
        "authors": [
            "Mikhail Freer",
            "Cesar Martinelli"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose and develop an algebraic approach to revealed preference. Our\napproach dispenses with non algebraic structure, such as topological\nassumptions. We provide algebraic axioms of revealed preference that subsume\nprevious, classical revealed preference axioms, as well as generate new axioms\nfor behavioral theories, and show that a data set is rationalizable if and only\nif it is consistent with an algebraic axiom.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.15175v1"
    },
    {
        "title": "Modeling the out-of-equilibrium dynamics of bounded rationality and\n  economic constraints",
        "authors": [
            "Oliver Richters"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The analogies between economics and classical mechanics can be extended from\nconstrained optimization to constrained dynamics by formalizing economic\n(constraint) forces and economic power in analogy to physical (constraint)\nforces in Lagrangian mechanics. In the differential-algebraic equation\nframework of General Constrained Dynamics (GCD), households, firms, banks, and\nthe government employ forces to change economic variables according to their\ndesire and their power to assert their interest. These ex-ante forces are\ncompleted by constraint forces from unanticipated system constraints to yield\nthe ex-post dynamics. The flexible out-of-equilibrium model can combine\nKeynesian concepts such as the balance sheet approach and slow adaptation of\nprices and quantities with bounded rationality (gradient climbing) and\ninteracting agents discussed in behavioral economics and agent-based models.\nThe framework integrates some elements of different schools of thought and\novercomes some restrictions inherent to optimization approaches, such as the\nassumption of markets operating in or close to equilibrium. Depending on the\nparameter choice for power relations and adaptation speeds, the model\nnevertheless can converge to a neoclassical equilibrium, and reacts to an\nausterity shock in a neoclassical or post-Keynesian way.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.00483v2"
    },
    {
        "title": "The Smoothed Satisfaction of Voting Axioms",
        "authors": [
            "Lirong Xia"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We initiate the work towards a comprehensive picture of the smoothed\nsatisfaction of voting axioms, to provide a finer and more realistic foundation\nfor comparing voting rules. We adopt the smoothed social choice framework,\nwhere an adversary chooses arbitrarily correlated \"ground truth\" preferences\nfor the agents, on top of which random noises are added. We focus on\ncharacterizing the smoothed satisfaction of two well-studied voting axioms:\nCondorcet criterion and participation. We prove that for any fixed number of\nalternatives, when the number of voters $n$ is sufficiently large, the smoothed\nsatisfaction of the Condorcet criterion under a wide range of voting rules is\n$1$, $1-\\exp(-\\Theta(n))$, $\\Theta(n^{-0.5})$, $ \\exp(-\\Theta(n))$, or being\n$\\Theta(1)$ and $1-\\Theta(1)$ at the same time; and the smoothed satisfaction\nof participation is $1-\\Theta(n^{-0.5})$. Our results address open questions by\nBerg and Lepelley in 1994 for these rules, and also confirm the following\nhigh-level message: the Condorcet criterion is a bigger concern than\nparticipation under realistic models.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.01947v1"
    },
    {
        "title": "Interdependence of Growth, Structure, Size and Resource Consumption\n  During an Economic Growth Cycle",
        "authors": [
            "Carey W. King"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  All economies require physical resource consumption to grow and maintain\ntheir structure. The modern economy is additionally characterized by private\ndebt. The Human and Resources with MONEY (HARMONEY) economic growth model links\nthese features using a stock and flow consistent framework in physical and\nmonetary units. Via an updated version, we explore the interdependence of\ngrowth and three major structural metrics of an economy. First, we show that\nrelative decoupling of gross domestic product (GDP) from resource consumption\nis an expected pattern that occurs because of physical limits to growth, not a\nresponse to avoid physical limits. While an increase in resource efficiency of\noperating capital does increase the level of relative decoupling, so does a\nchange in pricing from one based on full costs to one based only on marginal\ncosts that neglects depreciation and interest payments leading to higher debt\nratios. Second, if assuming full labor bargaining power for wages, when a\npreviously-growing economy reaches peak resource extraction and GDP, wages\nremain high but profits and debt decline to zero. By removing bargaining power,\nprofits can remain positive at the expense of declining wages. Third, the\ndistribution of intermediate transactions within the input-output table of the\nmodel follows the same temporal pattern as in the post-World War II U.S.\neconomy. These results indicate that the HARMONEY framework enables realistic\ninvestigation of interdependent structural change and trade-offs between\neconomic distribution, size, and resources consumption.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.02512v1"
    },
    {
        "title": "Unifying Revealed Preference and Revealed Rational Inattention",
        "authors": [
            "Kunal Pattanayak",
            "Vikram Krishnamurthy"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper unifies two key results from economic theory, namely, revealed\nrational inattention and classical revealed preference. Revealed rational\ninattention tests for rationality of information acquisition for Bayesian\ndecision makers. On the other hand, classical revealed preference tests for\nutility maximization under known budget constraints. Our first result is an\nequivalence result - we unify revealed rational inattention and revealed\npreference through an equivalence map over decision parameters and partial\norder for payoff monotonicity over the decision space in both setups. Second,\nwe exploit the unification result computationally to extend robustness measures\nfor goodness-of-fit of revealed preference tests in the literature to revealed\nrational inattention. This extension facilitates quantifying how well a\nBayesian decision maker's actions satisfy rational inattention. Finally, we\nillustrate the significance of the unification result on a real-world YouTube\ndataset comprising thumbnail, title and user engagement metadata from\napproximately 140,000 videos. We compute the Bayesian analog of robustness\nmeasures from revealed preference literature on YouTube metadata features\nextracted from a deep auto-encoder, i.e., a deep neural network that learns\nlow-dimensional features of the metadata. The computed robustness values show\nthat YouTube user engagement fits the rational inattention model remarkably\nwell. All our numerical experiments are completely reproducible.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.14486v4"
    },
    {
        "title": "Centralized Matching with Incomplete Information",
        "authors": [
            "Marcelo Ariel Fernandez",
            "Kirill Rudov",
            "Leeat Yariv"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study the impacts of incomplete information on centralized one-to-one\nmatching markets. We focus on the commonly used Deferred Acceptance mechanism\n(Gale and Shapley, 1962). We show that many complete-information results are\nfragile to a small infusion of uncertainty about others' preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04098v1"
    },
    {
        "title": "Semi-Random Impossibilities of Condorcet Criterion",
        "authors": [
            "Lirong Xia"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  The Condorcet criterion (CC) is a classical and well-accepted criterion for\nvoting. Unfortunately, it is incompatible with many other desiderata including\nparticipation (Par), half-way monotonicity (HM), Maskin monotonicity (MM), and\nstrategy-proofness (SP). Such incompatibilities are often known as\nimpossibility theorems, and are proved by worst-case analysis. Previous work\nhas investigated the likelihood for these impossibilities to occur under\ncertain models, which are often criticized of being unrealistic.\n  We strengthen previous work by proving the first set of semi-random\nimpossibilities for voting rules to satisfy CC and the more general, group\nversions of the four desiderata: for any sufficiently large number of voters\n$n$, any size of the group $1\\le B\\le \\sqrt n$, any voting rule $r$, and under\na large class of {\\em semi-random} models that include Impartial Culture, the\nlikelihood for $r$ to satisfy CC and Par, CC and HM, CC and MM, or CC and SP is\n$1-\\Omega(\\frac{B}{\\sqrt n})$. This matches existing lower bounds for CC and\nPar ($B=1$) and CC and SP ($B\\le \\sqrt n$), showing that many commonly-studied\nvoting rules are already asymptotically optimal in such cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.06435v2"
    },
    {
        "title": "Comparing Intellectual property policy in the Global North and South --\n  A one-size-fits-all policy for economic prosperity?",
        "authors": [
            "S Sidhartha Narayan",
            "Malavika Ranjan",
            "Madhumitha Raghuraman"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper attempts to analyse policymaking in the field of Intellectual\nProperty (IP) as an instrument of economic growth across the Global North and\nSouth. It begins by studying the links between economic growth and IP, followed\nby an understanding of Intellectual Property Rights (IPR) development in the\nUS, a leading proponent of robust IPR protection internationally. The next\nsection compares the IPR in the Global North and South and undertakes an\nanalysis of the diverse factors that result in these differences. The paper\nuses the case study of the Indian Pharmaceutical Industry to understand how IPR\nmay differentially affect economies and conclude that there may not yet be a\none size fits all policy for the adoption of Intellectual Property Rights.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.06855v2"
    },
    {
        "title": "Data Sharing Markets",
        "authors": [
            "Mohammad Rasouli",
            "Michael I. Jordan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  With the growing use of distributed machine learning techniques, there is a\ngrowing need for data markets that allows agents to share data with each other.\nNevertheless data has unique features that separates it from other commodities\nincluding replicability, cost of sharing, and ability to distort. We study a\nsetup where each agent can be both buyer and seller of data. For this setup, we\nconsider two cases: bilateral data exchange (trading data with data) and\nunilateral data exchange (trading data with money). We model bilateral sharing\nas a network formation game and show the existence of strongly stable outcome\nunder the top agents property by allowing limited complementarity. We propose\nordered match algorithm which can find the stable outcome in O(N^2) (N is the\nnumber of agents). For the unilateral sharing, under the assumption of additive\ncost structure, we construct competitive prices that can implement any social\nwelfare maximizing outcome. Finally for this setup when agents have private\ninformation, we propose mixed-VCG mechanism which uses zero cost data\ndistortion of data sharing with its isolated impact to achieve budget balance\nwhile truthfully implementing socially optimal outcomes to the exact level of\nbudget imbalance of standard VCG mechanisms. Mixed-VCG uses data distortions as\ndata money for this purpose. We further relax zero cost data distortion\nassumption by proposing distorted-mixed-VCG. We also extend our model and\nresults to data sharing via incremental inquiries and differential privacy\ncosts.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.08630v2"
    },
    {
        "title": "Sustainability of Global Economy as a Quantum Circuit",
        "authors": [
            "Antonino Claudio Bonan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In economy, viewed as a quantum system working as a circuit, each process at\nthe microscale is a quantum gate among agents. The global configuration of\neconomy is addressed by optimizing the sustainability of the whole circuit.\nThis is done in terms of geodesics, starting from some approximations. A\nsimilar yet somehow different approach is applied for the closed system of the\nwhole and for economy as an open system. Computations may partly be explicit,\nespecially when the reality is represented in a simplified way. The circuit can\nbe also optimized by minimizing its complexity, with a partly similar\nformalism, yet generally not along the same paths.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09032v1"
    },
    {
        "title": "Specifying a Game-Theoretic Extensive Form as an Abstract 5-ary Relation",
        "authors": [
            "Peter A. Streufert"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper specifies an extensive form as a 5-ary relation (that is, as a set\nof quintuples) which satisfies eight abstract axioms. Each quintuple is\nunderstood to list a player, a situation (that is, a name for an information\nset), a decision node, an action, and a successor node. Accordingly, the axioms\nare understood to specify abstract relationships between players, situations,\nnodes, and actions. Such an extensive form is called a \"pentaform\". Finally, a\n\"pentaform game\" is defined to be a pentaform together with utility functions.\n  To ground this new specification in the literature, the paper defines the\nconcept of a \"traditional game\" to represent the literature's many\nspecifications of finite-horizon and infinite-horizon games. The paper's main\nresult is to construct an intuitive bijection between pentaform games and\ntraditional games. Secondary results concern disaggregating pentaforms by\nsubsets, constructing pentaforms by unions, and initial pentaform applications\nto Selten subgames and perfect-recall (an extensive application to dynamic\nprogramming is in Streufert 2023, arXiv:2302.03855).\n",
        "pdf_link": "http://arxiv.org/pdf/2107.10801v7"
    },
    {
        "title": "Peace through bribing",
        "authors": [
            "Jingfeng Lu",
            "Zongwei Lu",
            "Christian Riis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study a model in which before a conflict between two parties escalates\ninto a war (in the form of an all-pay auction), a party can offer a\ntake-it-or-leave-it bribe to the other for a peaceful settlement. In contrast\nto the received literature, we find that peace security is impossible in our\nmodel. We characterize the necessary and sufficient conditions for peace\nimplementability. Furthermore, we find that separating equilibria do not exist\nand the number of (on-path) bribes in any non-peaceful equilibria is at most\ntwo. We also consider a requesting model and characterize the necessary and\nsufficient conditions for the existence of robust peaceful equilibria, all of\nwhich are sustained by the identical (on-path) request. Contrary to the bribing\nmodel, peace security is possible in the requesting model.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11575v3"
    },
    {
        "title": "Stable Voting",
        "authors": [
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose a new single-winner voting system using ranked ballots: Stable\nVoting. The motivating principle of Stable Voting is that if a candidate A\nwould win without another candidate B in the election, and A beats B in a\nhead-to-head majority comparison, then A should still win in the election with\nB included (unless there is another candidate A' who has the same kind of claim\nto winning, in which case a tiebreaker may choose between such candidates). We\ncall this principle Stability for Winners (with Tiebreaking). Stable Voting\nsatisfies this principle while also having a remarkable ability to avoid tied\noutcomes in elections even with small numbers of voters.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.00542v9"
    },
    {
        "title": "Fairer Chess: A Reversal of Two Opening Moves in Chess Creates Balance\n  Between White and Black",
        "authors": [
            "Steven J. Brams",
            "Mehmet S. Ismail"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Unlike tic-tac-toe or checkers, in which optimal play leads to a draw, it is\nnot known whether optimal play in chess ends in a win for White, a win for\nBlack, or a draw. But after White moves first in chess, if Black has a double\nmove followed by a double move of White and then alternating play, play is more\nbalanced because White does not always tie or lead in moves. Symbolically,\nBalanced Alternation gives the following move sequence: After White's (W)\ninitial move, first Black (B) and then White each have two moves in a row\n(BBWW), followed by the alternating sequence, beginning with W, which\naltogether can be written as WB/BW/WB/WB/WB... (the slashes separate\nalternating pairs of moves). Except for reversal of the 3rd and 4th moves from\nWB to BW, this is the standard chess sequence. Because Balanced Alternation\nlies between the standard sequence, which favors White, and a comparable\nsequence that favors Black, it is highly likely to produce a draw with optimal\nplay, rendering chess fairer. This conclusion is supported by a computer\nanalysis of chess openings and how they would play out under Balanced\nAlternation.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02547v2"
    },
    {
        "title": "Grade Inflation and Stunted Effort in a Curved Economics Course",
        "authors": [
            "Alex Garivaltis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  To protect his teaching evaluations, an economics professor uses the\nfollowing exam curve: if the class average falls below a known target, $m$,\nthen all students will receive an equal number of free points so as to bring\nthe mean up to $m$. If the average is above $m$ then there is no curve; curved\ngrades above $100\\%$ will never be truncated to $100\\%$ in the gradebook. The\n$n$ students in the course all have Cobb-Douglas preferences over the\ngrade-leisure plane; effort corresponds exactly to earned (uncurved) grades in\na $1:1$ fashion. The elasticity of each student's utility with respect to his\ngrade is his ability parameter, or relative preference for a high score. I\nfind, classify, and give complete formulas for all the pure Nash equilibria of\nmy own game, which my students have been playing for some eight semesters. The\ngame is supermodular, featuring strategic complementarities, negative\nspillovers, and nonsmooth payoffs that generate non-convexities in the reaction\ncorrespondence. The $n+2$ types of equilibria are totally ordered with respect\nto effort and Pareto preference, and the lowest $n+1$ of these types are\ntotally ordered in grade-leisure space. In addition to the no-curve\n(\"try-hard\") and curved interior equilibria, we have the \"$k$-don't care\"\nequilibria, whereby the $k$ lowest-ability students are no-shows. As the class\nsize becomes infinite in the curved interior equilibrium, all students increase\ntheir leisure time by a fixed percentage, i.e., $14\\%$, in response to the\ndisincentive, which amplifies any pre-existing ability differences. All\nstudents' grades inflate by this same (endogenous) factor, say, $1.14$ times\nwhat they would have been under the correct standard.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.03709v3"
    },
    {
        "title": "Benefits of marriage as a search strategy",
        "authors": [
            "Davi B. Costa"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We propose and investigate a model for mate searching and marriage in large\nsocieties based on a stochastic matching process and simple decision rules.\nAgents have preferences among themselves given by some probability\ndistribution. They randomly search for better mates, forming new couples and\nbreaking apart in the process. Marriage is implemented in the model by adding\nthe decision of stopping searching for a better mate when the affinity between\na couple is higher than a certain fixed amount. We show that the average\nutility in the system with marriage can be higher than in the system without\nit. Part of our results can be summarized in what sounds like a piece of\nadvice: don't marry the first person you like and don't search for the love of\nyour life, but get married if you like your partner more than a sigma above\naverage. We also find that the average utility attained in our stochastic model\nis smaller than the one associated with a stable matching achieved using the\nGale-Shapley algorithm. This can be taken as a formal argument in favor of a\ncentral planner (perhaps an app) with the information to coordinate the\nmarriage market in order to set a stable matching. To roughly test the adequacy\nof our model to describe existent societies, we compare the evolution of the\nfraction of married couples in our model with real-world data and obtain good\nagreement. In the last section, we formulate the model in the limit of an\ninfinite number of agents and find an analytical expression for the evolution\nof the system.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04885v2"
    },
    {
        "title": "Risk Preferences in Time Lotteries",
        "authors": [
            "Yonatan Berman",
            "Mark Kirstein"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  An important but understudied question in economics is how people choose when\nfacing uncertainty in the timing of events. Here we study preferences over time\nlotteries, in which the payment amount is certain but the payment time is\nuncertain. Expected discounted utility theory (EDUT) predicts decision makers\nto be risk-seeking over time lotteries. We explore a normative model of\ngrowth-optimality, in which decision makers maximise the long-term growth rate\nof their wealth. Revisiting experimental evidence on time lotteries, we find\nthat growth-optimality accords better with the evidence than EDUT. We outline\nfuture experiments to scrutinise further the plausibility of growth-optimality.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.08366v1"
    },
    {
        "title": "The Continuity Postulate in Economic Theory: A Deconstruction and an\n  Integration",
        "authors": [
            "Metin Uyanik",
            "M. Ali Khan"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper presents six theorems and ten propositions that can be read as\ndeconstructing and integrating the continuity postulate under the rubric of\npioneering work of Eilenberg, Wold, von Neumann-Morgenstern, Herstein-Milnor\nand Debreu. Its point of departure is the fact that the adjective continuous\napplied to a function or a binary relation does not acknowledge the many\nmeanings that can be given to the concept it names, and that under a variety of\ntechnical mathematical structures, its many meanings can be whittled down to\nnovel and unexpected equivalences that have been missed in the theory of\nchoice. Specifically, it provides a systematic investigation of the two-way\nrelation between restricted and full continuity of a function and a binary\nrelation that, under convex, monotonic and differentiable structures, draws out\nthe behavioral implications of the postulate.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.11736v2"
    },
    {
        "title": "Uncertainty in Mechanism Design",
        "authors": [
            "Giuseppe Lopomo",
            "Luca Rigotti",
            "Chris Shannon"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the design of mechanisms that are robust to\nmisspecification. We introduce a novel notion of robustness that connects a\nvariety of disparate approaches and study its implications in a wide class of\nmechanism design problems. This notion is quantifiable, allowing us to\nformalize and answer comparative statics questions relating the nature and\ndegree of misspecification to sharp predictions regarding features of feasible\nmechanisms. This notion also has a behavioral foundation which reflects the\nperception of ambiguity, thus allowing the degree of misspecification to emerge\nendogenously. In a number of standard settings, robustness to arbitrarily small\namounts of misspecification generates a discontinuity in the set of feasible\nmechanisms and uniquely selects simple, ex post incentive compatible mechanisms\nsuch as second-price auctions. Robustness also sheds light on the value of\nprivate information and the prevalence of full or virtual surplus extraction.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12633v1"
    },
    {
        "title": "Submission Fees in Risk-Taking Contests",
        "authors": [
            "Mark Whitmeyer"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper investigates stochastic continuous time contests with a twist: the\ndesigner requires that contest participants incur some cost to submit their\nentries. When the designer wishes to maximize the (expected) performance of the\ntop performer, a strictly positive submission fee is optimal. When the designer\nwishes to maximize total (expected) performance, either the highest submission\nfee or the lowest submission fee is optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.13506v1"
    },
    {
        "title": "Persuasion and Welfare",
        "authors": [
            "Laura Doval",
            "Alex Smolin"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Information policies such as scores, ratings, and recommendations are\nincreasingly shaping society's choices in high-stakes domains. We provide a\nframework to study the welfare implications of information policies on a\npopulation of heterogeneous individuals. We define and characterize the Bayes\nwelfare set, consisting of the population's utility profiles that are feasible\nunder some information policy. The Pareto frontier of this set can be recovered\nby a series of standard Bayesian persuasion problems, in which a utilitarian\nplanner takes the role of the information designer. We provide necessary and\nsufficient conditions under which an information policy exists that Pareto\ndominates the no-information policy. We illustrate our results with\napplications to data leakage, price discrimination, and credit ratings.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.03061v4"
    },
    {
        "title": "Deviation-Based Learning: Training Recommender Systems Using Informed\n  User Choice",
        "authors": [
            "Junpei Komiyama",
            "Shunya Noda"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper proposes a new approach to training recommender systems called\ndeviation-based learning. The recommender and rational users have different\nknowledge. The recommender learns user knowledge by observing what action users\ntake upon receiving recommendations. Learning eventually stalls if the\nrecommender always suggests a choice: Before the recommender completes\nlearning, users start following the recommendations blindly, and their choices\ndo not reflect their knowledge. The learning rate and social welfare improve\nsubstantially if the recommender abstains from recommending a particular choice\nwhen she predicts that multiple alternatives will produce a similar payoff.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.09816v2"
    },
    {
        "title": "Ignorance is Bliss: A Game of Regret",
        "authors": [
            "Claudia Cerrone",
            "Francesco Feri",
            "Philip R. Neary"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  An individual can only experience regret if she learns about an unchosen\nalternative. In many situations, learning about an unchosen alternative is\npossible only if someone else chose it. We develop a model where the ex-post\ninformation available to each regret averse individual depends both on their\nown choice and on the choices of others, as others can reveal ex-post\ninformation about what might have been. This implies that what appears to be a\nseries of isolated single-person decision problems is in fact a rich\nmulti-player behavioural game, the regret game, where the psychological payoffs\nthat depend on ex-post information are interconnected. For an open set of\nparameters, the regret game is a coordination game with multiple equilibria,\ndespite the fact that all individuals possess a uniquely optimal choice in\nisolation. We experimentally test this prediction and find support for it.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.10968v3"
    },
    {
        "title": "Noise, fake news, and tenacious Bayesians",
        "authors": [
            "Dorje C. Brody"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A modelling framework, based on the theory of signal processing, for\ncharacterising the dynamics of systems driven by the unravelling of information\nis outlined, and is applied to describe the process of decision making. The\nmodel input of this approach is the specification of the flow of information.\nThis enables the representation of (i) reliable information, (ii) noise, and\n(iii) disinformation, in a unified framework. Because the approach is designed\nto characterise the dynamics of the behaviour of people, it is possible to\nquantify the impact of information control, including those resulting from the\ndissemination of disinformation. It is shown that if a decision maker assigns\nan exceptionally high weight on one of the alternative realities, then under\nthe Bayesian logic their perception hardly changes in time even if evidences\npresented indicate that this alternative corresponds to a false reality. Thus\nconfirmation bias need not be incompatible with Bayesian updating. By observing\nthe role played by noise in other areas of natural sciences, where noise is\nused to excite the system away from false attractors, a new approach to tackle\nthe dark forces of fake news is proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.03432v3"
    },
    {
        "title": "Expanding Multi-Market Monopoly and Nonconcavity in the Value of\n  Information",
        "authors": [
            "Stefan Behringer"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this paper I investigate a Bayesian inverse problem in the specific\nsetting of a price setting monopolist facing a randomly growing demand in\nmultiple possibly interconnected markets. Investigating the Value of\nInformation of a signal to the monopolist in a fully dynamic discrete model\nemploying the Kalman-Bucy-Stratonovich filter, we find that it may be\nnon-monotonic in the variance of the signal. In the classical static settings\nof the Value of Information literature this relationship may be convex or\nconcave, but is always monotonic. The existence of the non-monotonicity depends\ncritically on the exogenous growth rate of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.00839v1"
    },
    {
        "title": "A Finite Characterization of Perfect Equilibria",
        "authors": [
            "Ivonne Callejas",
            "Srihari Govindan",
            "Lucas Pahl"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Govindan and Klumpp [7] provided a characterization of perfect equilibria\nusing Lexicographic Probability Systems (LPSs). Their characterization was\nessentially finite in that they showed that there exists a finite bound on the\nnumber of levels in the LPS, but they did not compute it explicitly. In this\nnote, we draw on two recent developments in Real Algebraic Geometry to obtain a\nformula for this bound.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.01638v1"
    },
    {
        "title": "Aggregation of Models, Choices, Beliefs, and Preferences",
        "authors": [
            "Hamed Hamze Bajgiran",
            "Houman Owhadi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  A natural notion of rationality/consistency for aggregating models is that,\nfor all (possibly aggregated) models $A$ and $B$, if the output of model $A$ is\n$f(A)$ and if the output model $B$ is $f(B)$, then the output of the model\nobtained by aggregating $A$ and $B$ must be a weighted average of $f(A)$ and\n$f(B)$. Similarly, a natural notion of rationality for aggregating preferences\nof ensembles of experts is that, for all (possibly aggregated) experts $A$ and\n$B$, and all possible choices $x$ and $y$, if both $A$ and $B$ prefer $x$ over\n$y$, then the expert obtained by aggregating $A$ and $B$ must also prefer $x$\nover $y$. Rational aggregation is an important element of uncertainty\nquantification, and it lies behind many seemingly different results in economic\ntheory: spanning social choice, belief formation, and individual decision\nmaking. Three examples of rational aggregation rules are as follows. (1) Give\neach individual model (expert) a weight (a score) and use weighted averaging to\naggregate individual or finite ensembles of models (experts). (2) Order/rank\nindividual model (expert) and let the aggregation of a finite ensemble of\nindividual models (experts) be the highest-ranked individual model (expert) in\nthat ensemble. (3) Give each individual model (expert) a weight, introduce a\nweak order/ranking over the set of models/experts, aggregate $A$ and $B$ as the\nweighted average of the highest-ranked models (experts) in $A$ or $B$. Note\nthat (1) and (2) are particular cases of (3). In this paper, we show that all\nrational aggregation rules are of the form (3). This result unifies aggregation\nprocedures across different economic environments. Following the main\nrepresentation, we show applications and extensions of our representation in\nvarious separated economics topics such as belief formation, choice theory, and\nsocial welfare economics.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.11630v1"
    },
    {
        "title": "Aggregation of Pareto optimal models",
        "authors": [
            "Hamed Hamze Bajgiran",
            "Houman Owhadi"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In statistical decision theory, a model is said to be Pareto optimal (or\nadmissible) if no other model carries less risk for at least one state of\nnature while presenting no more risk for others. How can you rationally\naggregate/combine a finite set of Pareto optimal models while preserving Pareto\nefficiency? This question is nontrivial because weighted model averaging does\nnot, in general, preserve Pareto efficiency. This paper presents an answer in\nfour logical steps: (1) A rational aggregation rule should preserve Pareto\nefficiency (2) Due to the complete class theorem, Pareto optimal models must be\nBayesian, i.e., they minimize a risk where the true state of nature is averaged\nwith respect to some prior. Therefore each Pareto optimal model can be\nassociated with a prior, and Pareto efficiency can be maintained by aggregating\nPareto optimal models through their priors. (3) A prior can be interpreted as a\npreference ranking over models: prior $\\pi$ prefers model A over model B if the\naverage risk of A is lower than the average risk of B. (4) A\nrational/consistent aggregation rule should preserve this preference ranking:\nIf both priors $\\pi$ and $\\pi'$ prefer model A over model B, then the prior\nobtained by aggregating $\\pi$ and $\\pi'$ must also prefer A over B. Under these\nfour steps, we show that all rational/consistent aggregation rules are as\nfollows: Give each individual Pareto optimal model a weight, introduce a weak\norder/ranking over the set of Pareto optimal models, aggregate a finite set of\nmodels S as the model associated with the prior obtained as the weighted\naverage of the priors of the highest-ranked models in S. This result shows that\nall rational/consistent aggregation rules must follow a generalization of\nhierarchical Bayesian modeling. Following our main result, we present\napplications to Kernel smoothing, time-depreciating models, and voting\nmechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.04161v1"
    },
    {
        "title": "Stability analysis of heterogeneous oligopoly games of increasing\n  players with quadratic costs",
        "authors": [
            "Xiaoliang Li"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  In this discussion draft, we explore heterogeneous oligopoly games of\nincreasing players with quadratic costs, where the market is supposed to have\nthe isoelastic demand. For each of the models considered in this draft, we\nanalytically investigate the necessary and sufficient condition of the local\nstability of its positive equilibrium. Furthermore, we rigorously prove that\nthe stability regions are enlarged as the number of involved firms is\nincreasing.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.13844v1"
    },
    {
        "title": "Learning in Repeated Interactions on Networks",
        "authors": [
            "Wanying Huang",
            "Philipp Strack",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  We study how long-lived, rational agents learn in a social network. In every\nperiod, after observing the past actions of his neighbors, each agent receives\na private signal, and chooses an action whose payoff depends only on the state.\nSince equilibrium actions depend on higher order beliefs, it is difficult to\ncharacterize behavior. Nevertheless, we show that regardless of the size and\nshape of the network, the utility function, and the patience of the agents, the\nspeed of learning in any equilibrium is bounded from above by a constant that\nonly depends on the private signal distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.14265v5"
    },
    {
        "title": "Private Private Information",
        "authors": [
            "Kevin He",
            "Fedor Sandomirskiy",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  Private signals model noisy information about an unknown state. Although\nthese signals are called \"private,\" they may still carry information about each\nother. Our paper introduces the concept of private private signals, which\ncontain information about the state but not about other signals. To achieve\nprivacy, signal quality may need to be sacrificed. We study the informativeness\nof private private signals and characterize those that are optimal in the sense\nthat they cannot be made more informative without violating privacy. We discuss\nimplications for privacy in recommendation systems, information design, causal\ninference, and mechanism design.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.14356v4"
    },
    {
        "title": "Polytope-form games and Index/Degree Theories for Extensive-form games",
        "authors": [
            "Lucas Pahl"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We present an index theory of equilibria for extensive form games. This\nrequires developing an index theory for games where the strategy sets of\nplayers are general polytopes and their payoff functions are multiaffine in the\nproduct of these polytopes. Such polytopes arise from identifying\n(topologically) equivalent mixed strategies of a normal form game.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02098v4"
    },
    {
        "title": "Artificial Intelligence and Spontaneous Collusion",
        "authors": [
            "Martino Banchio",
            "Giacomo Mantegazza"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We develop a tractable model for studying strategic interactions between\nlearning algorithms. We uncover a mechanism responsible for the emergence of\nalgorithmic collusion. We observe that algorithms periodically coordinate on\nactions that are more profitable than static Nash equilibria. This novel\ncollusive channel relies on an endogenous statistical linkage in the\nalgorithms' estimates which we call spontaneous coupling. The model's\nparameters predict whether the statistical linkage will appear, and what market\nstructures facilitate algorithmic collusion. We show that spontaneous coupling\ncan sustain collusion in prices and market shares, complementing experimental\nfindings in the literature. Finally, we apply our results to design algorithmic\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05946v5"
    },
    {
        "title": "Artificial Intelligence and Auction Design",
        "authors": [
            "Martino Banchio",
            "Andrzej Skrzypacz"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Motivated by online advertising auctions, we study auction design in repeated\nauctions played by simple Artificial Intelligence algorithms (Q-learning). We\nfind that first-price auctions with no additional feedback lead to\ntacit-collusive outcomes (bids lower than values), while second-price auctions\ndo not. We show that the difference is driven by the incentive in first-price\nauctions to outbid opponents by just one bid increment. This facilitates\nre-coordination on low bids after a phase of experimentation. We also show that\nproviding information about lowest bid to win, as introduced by Google at the\ntime of switch to first-price auctions, increases competitiveness of auctions.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05947v1"
    },
    {
        "title": "The Impact of a Coalition: Assessing the Likelihood of Voter Influence\n  in Large Elections",
        "authors": [
            "Lirong Xia"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  For centuries, it has been widely believed that the influence of a small\ncoalition of voters is negligible in a large election. Consequently, there is a\nlarge body of literature on characterizing the likelihood for an election to be\ninfluenced when the votes follow certain distributions, especially the\nlikelihood of being manipulable by a single voter under the i.i.d. uniform\ndistribution, known as the Impartial Culture (IC).\n  In this paper, we extend previous studies in three aspects: (1) we propose a\nmore general semi-random model, where a distribution adversary chooses a\nworst-case distribution and then a contamination adversary modifies up to\n$\\psi$ portion of the data, (2) we consider many coalitional influence\nproblems, including coalitional manipulation, margin of victory, and various\nvote controls and bribery, and (3) we consider arbitrary and variable coalition\nsize $B$. Our main theorem provides asymptotically tight bounds on the\nsemi-random likelihood of the existence of a size-$B$ coalition that can\nsuccessfully influence the election under a wide range of voting rules.\nApplications of the main theorem and its proof techniques resolve long-standing\nopen questions about the likelihood of coalitional manipulability under IC, by\nshowing that the likelihood is $\\Theta\\left(\\min\\left\\{\\frac{B}{\\sqrt n},\n1\\right\\}\\right)$ for many commonly-studied voting rules.\n  The main technical contribution is a characterization of the semi-random\nlikelihood for a Poisson multinomial variable (PMV) to be unstable, which we\nbelieve to be a general and useful technique with independent interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06411v4"
    },
    {
        "title": "Beckmann's approach to multi-item multi-bidder auctions",
        "authors": [
            "Alexander V. Kolesnikov",
            "Fedor Sandomirskiy",
            "Aleh Tsyvinski",
            "Alexander P. Zimin"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We consider the problem of revenue-maximizing Bayesian auction design with\nseveral bidders having independent private values over several items. We show\nthat it can be reduced to the problem of continuous optimal transportation\nintroduced by Beckmann (1952) where the optimal transportation flow generalizes\nthe concept of ironed virtual valuations to the multi-item setting. We\nestablish the strong duality between the two problems and the existence of\nsolutions. The results rely on insights from majorization and optimal\ntransportation theories and on the characterization of feasible interim\nmechanisms by Hart and Reny (2015).\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06837v2"
    },
    {
        "title": "Describing Sen's Transitivity Condition in Inequalities and Equations",
        "authors": [
            "Fujun Hou"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In social choice theory, Sen's value restriction condition is a sufficiency\ncondition restricted to individuals' ordinal preferences so as to obtain a\ntransitive social preference under the majority decision rule. In this article,\nSen's transitivity condition is described by use of inequality and equation.\nFirst, for a triple of alternatives, an individual's preference is represented\nby a preference map, whose entries are sets containing the ranking position or\npositions derived from the individual's preference over that triple of those\nalternatives. Second, by using the union operation of sets and the cardinality\nconcept, Sen's transitivity condition is described by inequalities. Finally, by\nusing the membership function of sets, Sen's transitivity condition is further\ndescribed by equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.05105v1"
    },
    {
        "title": "Impacts of Public Information on Flexible Information Acquisition",
        "authors": [
            "Takashi Ui"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Interacting agents receive public information at no cost and flexibly acquire\nprivate information at a cost proportional to entropy reduction. When a\npolicymaker provides more public information, agents acquire less private\ninformation, thus lowering information costs. Does more public information\nraise or reduce uncertainty faced by agents? Is it beneficial or detrimental to\nwelfare? To address these questions, we examine the impacts of public\ninformation on flexible information acquisition in a linear-quadratic-Gaussian\ngame with arbitrary quadratic material welfare. More public information raises\nuncertainty if and only if the game exhibits strategic complementarity, which\ncan be harmful to welfare. However, when agents acquire a large amount of\ninformation, more provision of public information increases welfare through a\nsubstantial reduction in the cost of information. We give a necessary and\nsufficient condition for welfare to increase with public information and\nidentify optimal public information disclosure, which is either full or partial\ndisclosure depending upon the welfare function and the slope of the best\nresponse.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.09250v2"
    },
    {
        "title": "Optimal preference satisfaction for conflict-free joint decisions",
        "authors": [
            "Hiroaki Shinkawa",
            "Nicolas Chauvet",
            "Guillaume Bachelier",
            "André Röhm",
            "Ryoichi Horisaki",
            "Makoto Naruse"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We all have preferences when multiple choices are available. If we insist on\nsatisfying our preferences only, we may suffer a loss due to conflicts with\nother people's identical selections. Such a case applies when the choice cannot\nbe divided into multiple pieces due to the intrinsic nature of the resources.\nFormer studies, such as the top trading cycle, examined how to conduct fair\njoint decision-making while avoiding decision conflicts from the perspective of\ngame theory when multiple players have their own deterministic preference\nprofiles. However, in reality, probabilistic preferences can naturally appear\nin relation to the stochastic decision-making of humans. Here, we theoretically\nderive conflict-free joint decision-making that can satisfy the probabilistic\npreferences of all individual players. More specifically, we mathematically\nprove the conditions wherein the deviation of the resultant chance of obtaining\neach choice from the individual preference profile, which we call the loss,\nbecomes zero, meaning that all players' satisfaction is perfectly appreciated\nwhile avoiding decision conflicts. Furthermore, even in situations where\nzero-loss conflict-free joint decision-making is unachievable, we show how to\nderive joint decision-making that accomplishes the theoretical minimum loss\nwhile ensuring conflict-free choices. Numerical demonstrations are also shown\nwith several benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00799v1"
    },
    {
        "title": "A Market for Trading Forecasts: A Wagering Mechanism",
        "authors": [
            "Aitazaz Ali Raja",
            "Pierre Pinson",
            "Jalal Kazempour",
            "Sergio Grammatico"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In many areas of industry and society, e.g., energy, healthcare, logistics,\nagents collect vast amounts of data that they deem proprietary. These data\nowners extract predictive information of varying quality and relevance from\ndata depending on quantity, inherent information content, and their own\ntechnical expertise. Aggregating these data and heterogeneous predictive\nskills, which are distributed in terms of ownership, can result in a higher\ncollective value for a prediction task. In this paper, we envision a platform\nfor improving predictions via implicit pooling of private information in return\nfor possible remuneration. Specifically, we design a wagering-based forecast\nelicitation market platform, where a buyer intending to improve their forecasts\nposts a prediction task, and sellers respond to it with their forecast reports\nand wagers. This market delivers an aggregated forecast to the buyer\n(pre-event) and allocates a payoff to the sellers (post-event) for their\ncontribution. We propose a payoff mechanism and prove that it satisfies several\ndesirable economic properties, including those specific to electronic\nplatforms. Furthermore, we discuss the properties of the forecast aggregation\noperator and scoring rules to emphasize their effect on the sellers' payoff.\nFinally, we provide numerical examples to illustrate the structure and\nproperties of the proposed market platform.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.02668v2"
    },
    {
        "title": "Social learning via actions in bandit environments",
        "authors": [
            "Aroon Narayanan"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  I study a game of strategic exploration with private payoffs and public\nactions in a Bayesian bandit setting. In particular, I look at cascade\nequilibria, in which agents switch over time from the risky action to the\nriskless action only when they become sufficiently pessimistic. I show that\nthese equilibria exist under some conditions and establish their salient\nproperties. Individual exploration in these equilibria can be more or less than\nthe single-agent level depending on whether the agents start out with a common\nprior or not, but the most optimistic agent always underexplores. I also show\nthat allowing the agents to write enforceable ex-ante contracts will lead to\nthe most ex-ante optimistic agent to buy all payoff streams, providing an\nexplanation to the buying out of smaller start-ups by more established firms.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.06107v1"
    },
    {
        "title": "Collective strategy condensation towards class-separated societies",
        "authors": [
            "Claudius Gros"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In physics, the wavefunctions of bosonic particles collapse when the system\nundergoes a Bose-Einstein condensation. In game theory, the strategy of an\nagent describes the probability to engage in a certain course of action.\nStrategies are expected to differ in competitive situations, namely when there\nis a penalty to do the same as somebody else. We study what happens when agents\nare interested how they fare not only in absolute terms, but also relative to\nothers. This preference, denoted envy, is shown to induce the emergence of\ndistinct social classes via a collective strategy condensation transition.\nMembers of the lower class pursue identical strategies, in analogy to the\nBose-Einstein condensation, with the upper class remaining individualistic.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.03421v1"
    },
    {
        "title": "Bounded Rationality and Animal Spirits: A Fluctuation-Response Approach\n  to Slutsky Matrices",
        "authors": [
            "Jerome Garnier-Brun",
            "Jean-Philippe Bouchaud",
            "Michael Benzaquen"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The Slutsky equation, central in consumer choice theory, is derived from the\nusual hypotheses underlying most standard models in Economics, such as full\nrationality, homogeneity, and absence of interactions. We present a statistical\nphysics framework that allows us to relax such assumptions. We first derive a\ngeneral fluctuation-response formula that relates the Slutsky matrix to\nspontaneous fluctuations of consumption rather than to response to changing\nprices and budget. We then show that, within our hypotheses, the symmetry of\nthe Slutsky matrix remains valid even when agents are only boundedly rational\nbut non-interacting. We then propose a model where agents are influenced by the\nchoice of others, leading to a phase transition beyond which consumption is\ndominated by herding (or `\"fashion\") effects. In this case, the individual\nSlutsky matrix is no longer symmetric, even for fully rational agents. The\nvicinity of the transition features a peak in asymmetry.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.04468v1"
    },
    {
        "title": "Islamic and capitalist economies: Comparison using econophysics models\n  of wealth exchange and redistribution",
        "authors": [
            "Takeshi Kato"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Islamic and capitalist economies have several differences, the most\nfundamental being that the Islamic economy is characterized by the prohibition\nof interest (riba) and speculation (gharar) and the enforcement of\nShariah-compliant profit-loss sharing (mudaraba, murabaha, salam, etc.) and\nwealth redistribution (waqf, sadaqah, and zakat). In this study, I apply new\neconophysics models of wealth exchange and redistribution to quantitatively\ncompare these characteristics to those of capitalism and evaluate wealth\ndistribution and disparity using a simulation. Specifically, regarding\nexchange, I propose a loan interest model representing finance capitalism and\nriba and a joint venture model representing shareholder capitalism and\nmudaraba; regarding redistribution, I create a transfer model representing\ninheritance tax and waqf. As exchanges are repeated from an initial uniform\ndistribution of wealth, wealth distribution approaches a power-law distribution\nmore quickly for the loan interest than the joint venture model; and the Gini\nindex, representing disparity, rapidly increases. The joint venture model's\nGini index increases more slowly, but eventually, the wealth distribution in\nboth models becomes a delta distribution, and the Gini index gradually\napproaches 1. Next, when both models are combined with the transfer model to\nredistribute wealth in every given period, the loan interest model has a larger\nGini index than the joint venture model, but both converge to a Gini index of\nless than 1. These results quantitatively reveal that in the Islamic economy,\ndisparity is restrained by prohibiting riba and promoting reciprocal exchange\nin mudaraba and redistribution through waqf. Comparing Islamic and capitalist\neconomies provides insights into the benefits of economically embracing the\nethical practice of mutual aid and suggests guidelines for an alternative to\ncapitalism.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.05443v2"
    },
    {
        "title": "Optimal Verification of Rumors in Networks",
        "authors": [
            "Luca Paolo Merlino",
            "Nicole Tabasso"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study the diffusion of a true and a false message when agents are biased\nand able to verify messages. As a recipient of a rumor who verifies it becomes\ninformed of the truth, a higher rumor prevalence can increase the prevalence of\nthe truth. We uncover conditions such that this happens and discuss policy\nimplications. Specifically, a planner aiming to maximize the prevalence of the\ntruth should allow rumors to circulate if: verification overcomes ignorance of\nmessages, transmission of information is relatively low, and the planner's\nbudget to induce verification is neither too low nor too high.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01830v2"
    },
    {
        "title": "Learning Underspecified Models",
        "authors": [
            "In-Koo Cho",
            "Jonathan Libgober"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper examines whether one can learn to play an optimal action while\nonly knowing part of true specification of the environment. We choose the\noptimal pricing problem as our laboratory, where the monopolist is endowed with\nan underspecified model of the market demand, but can observe market outcomes.\nIn contrast to conventional learning models where the model specification is\ncomplete and exogenously fixed, the monopolist has to learn the specification\nand the parameters of the demand curve from the data. We formulate the learning\ndynamics as an algorithm that forecast the optimal price based on the data,\nfollowing the machine learning literature (Shalev-Shwartz and Ben-David\n(2014)). Inspired by PAC learnability, we develop a new notion of learnability\nby requiring that the algorithm must produce an accurate forecast with a\nreasonable amount of data uniformly over the class of models consistent with\nthe part of the true specification. In addition, we assume that the monopolist\nhas a lexicographic preference over the payoff and the complexity cost of the\nalgorithm, seeking an algorithm with a minimum number of parameters subject to\nPAC-guaranteeing the optimal solution (Rubinstein (1986)). We show that for the\nset of demand curves with strictly decreasing uniformly Lipschitz continuous\nmarginal revenue curve, the optimal algorithm recursively estimates the slope\nand the intercept of the linear demand curve, even if the actual demand curve\nis not linear. The monopolist chooses a misspecified model to save\ncomputational cost, while learning the true optimal decision uniformly over the\nset of underspecified demand curves.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.10140v1"
    },
    {
        "title": "Confirmation Bias in Social Networks",
        "authors": [
            "Marcos R. Fernandes"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In this study, I present a theoretical social learning model to investigate\nhow confirmation bias affects opinions when agents exchange information over a\nsocial network. Hence, besides exchanging opinions with friends, agents observe\na public sequence of potentially ambiguous signals and interpret it according\nto a rule that includes confirmation bias. First, this study shows that\nregardless of level of ambiguity both for people or networked society, only two\ntypes of opinions can be formed, and both are biased. However, one opinion type\nis less biased than the other depending on the state of the world. The size of\nboth biases depends on the ambiguity level and relative magnitude of the state\nand confirmation biases. Hence, long-run learning is not attained even when\npeople impartially interpret ambiguity. Finally, analytically confirming the\nprobability of emergence of the less-biased consensus when people are connected\nand have different priors is difficult. Hence, I used simulations to analyze\nits determinants and found three main results: i) some network topologies are\nmore conducive to consensus efficiency, ii) some degree of partisanship\nenhances consensus efficiency even under confirmation bias and iii)\nopen-mindedness (i.e. when partisans agree to exchange opinions with opposing\npartisans) might inhibit efficiency in some cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.12594v3"
    },
    {
        "title": "Incentivizing Hidden Types in Secretary Problem",
        "authors": [
            "Longjian Li",
            "Alexis Akira Toda"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We study a game between $N$ job applicants who incur a cost $c$ (relative to\nthe job value) to reveal their type during interviews and an administrator who\nseeks to maximize the probability of hiring the best. We define a full learning\nequilibrium and prove its existence, uniqueness, and optimality. In\nequilibrium, the administrator accepts the current best applicant $n$ with\nprobability $c$ if $n<n^*$ and with probability 1 if $n\\ge n^*$ for a threshold\n$n^*$ independent of $c$. In contrast to the case without cost, where the\nsuccess probability converges to $1/\\mathrm{e}\\approx 0.37$ as $N$ tends to\ninfinity, with cost the success probability decays like $N^{-c}$.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05897v2"
    },
    {
        "title": "Generic catastrophic poverty when selfish investors exploit a degradable\n  common resource",
        "authors": [
            "Claudius Gros"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The productivity of a common pool of resources may degrade when overly\nexploited by a number of selfish investors, a situation known as the tragedy of\nthe commons (TOC). Without regulations, agents optimize the size of their\nindividual investments into the commons by balancing incurring costs with the\nreturns received. The resulting Nash equilibrium involves a self-consistency\nloop between individual investment decisions and the state of the commons. As a\nconsequence, several non-trivial properties emerge. For $N$ investing actors we\nprove rigorously that typical payoffs do not scale as $1/N$, the expected\nresult for cooperating agents, but as $(1/N)^2$. Payoffs are hence reduced with\nregard to the functional dependence on $N$, a situation denoted catastrophic\npoverty. We show that catastrophic poverty results from a fine-tuned balance\nbetween returns and costs. Additionally, a finite number of oligarchs may be\npresent. Oligarchs are characterized by payoffs that are finite and not\ndecreasing when $N$ increases. Our results hold for generic classes of models,\nincluding convex and moderately concave cost functions. For strongly concave\ncost functions the Nash equilibrium undergoes a collective reorganization,\nbeing characterized instead by entry barriers and sudden death forced market\nexits.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.08171v2"
    },
    {
        "title": "Gately Values of Cooperative Games",
        "authors": [
            "Robert P. Gilles",
            "Lina Mallozzi"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We investigate Gately's solution concept for cooperative games with\ntransferable utilities. Gately's conception introduced a bargaining solution\nthat minimises the maximal quantified ``propensity to disrupt'' the negotiation\nprocess of the players over the allocation of the generated collective payoffs.\nGately's solution concept is well-defined for a broad class of games. We also\nconsider a generalisation based on a parameter-based quantification of the\npropensity to disrupt. Furthermore, we investigate the relationship of these\ngeneralised Gately values with the Core and the Nucleolus and show that\nGately's solution is in the Core for all regular 3-player games. We identify\nexact conditions under which generally these Gately values are Core imputations\nfor arbitrary regular cooperative games. Finally, we investigate the\nrelationship of the Gately value with the Shapley value.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.10189v2"
    },
    {
        "title": "\"Calibeating\": Beating Forecasters at Their Own Game",
        "authors": [
            "Dean P. Foster",
            "Sergiu Hart"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In order to identify expertise, forecasters should not be tested by their\ncalibration score, which can always be made arbitrarily small, but rather by\ntheir Brier score. The Brier score is the sum of the calibration score and the\nrefinement score; the latter measures how good the sorting into bins with the\nsame forecast is, and thus attests to \"expertise.\" This raises the question of\nwhether one can gain calibration without losing expertise, which we refer to as\n\"calibeating.\" We provide an easy way to calibeat any forecast, by a\ndeterministic online procedure. We moreover show that calibeating can be\nachieved by a stochastic procedure that is itself calibrated, and then extend\nthe results to simultaneously calibeating multiple procedures, and to\ndeterministic procedures that are continuously calibrated.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04892v2"
    },
    {
        "title": "Calibrated Forecasts: The Minimax Proof",
        "authors": [
            "Sergiu Hart"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A formal write-up of the simple proof (1995) of the existence of calibrated\nforecasts by the minimax theorem, which moreover shows that $N^3$ periods\nsuffice to guarantee a calibration error of at most $1/N$.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05863v2"
    },
    {
        "title": "Posterior Probabilities: Dominance and Optimism",
        "authors": [
            "Sergiu Hart",
            "Yosef Rinott"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  The Bayesian posterior probability of the true state is stochastically\ndominated by that same posterior under the probability law of the true state.\nThis generalizes to notions of \"optimism\" about posterior probabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.11601v1"
    },
    {
        "title": "Strategyproofness-Exposing Mechanism Descriptions",
        "authors": [
            "Yannai A. Gonczarowski",
            "Ori Heffetz",
            "Clayton Thomas"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A menu description presents a mechanism to player $i$ in two steps. Step (1)\nuses the reports of other players to describe $i$'s menu: the set of $i$'s\npotential outcomes. Step (2) uses $i$'s report to select $i$'s favorite outcome\nfrom her menu. Can menu descriptions better expose strategyproofness, without\nsacrificing simplicity? We propose a new, simple menu description of Deferred\nAcceptance. We prove that -- in contrast with other common matching mechanisms\n-- this menu description must differ substantially from the corresponding\ntraditional description. We demonstrate, with a lab experiment on two\nelementary mechanisms, the promise and challenges of menu descriptions.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.13148v2"
    },
    {
        "title": "Measurement of Trustworthiness of the Online Reviews",
        "authors": [
            "Dipankar Das"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  In electronic commerce (e-commerce)markets, a decision-maker faces a\nsequential choice problem. Third-party intervention plays an important role in\nmaking purchase decisions in this choice process. For instance, while\npurchasing products/services online, a buyer's choice or behavior is often\naffected by the overall reviewers' ratings, feedback, etc. Moreover, the\nreviewer is also a decision-maker. After purchase, the decision-maker would put\nforth their reviews for the product, online. Such reviews would affect the\npurchase decision of another potential buyer, who would read the reviews before\nconforming to his/her final purchase. The question that arises is \\textit{how\ntrustworthy are these review reports and ratings?} The trustworthiness of these\nreview reports and ratings is based on whether the reviewer is a rational or an\nirrational person. Indexing the reviewer's rationality could be a way to\nquantify a reviewer's rationality but it does not communicate the history of\nhis/her behavior. In this article, the researcher aims at formally deriving a\nrationality pattern function and thereby, the degree of rationality of the\ndecision-maker or the reviewer in the sequential choice problem in the\ne-commerce markets. Applying such a rationality pattern function could make it\neasier to quantify the rational behavior of an agent who participates in the\ndigital markets. This, in turn, is expected to minimize the information\nasymmetry within the decision-making process and identify the paid reviewers or\nmanipulative reviews.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00815v2"
    },
    {
        "title": "An Axiomatic Characterization of Split Cycle",
        "authors": [
            "Yifeng Ding",
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  A number of rules for resolving majority cycles in elections have been\nproposed in the literature. Recently, Holliday and Pacuit (Journal of\nTheoretical Politics 33 (2021) 475-524) axiomatically characterized the class\nof rules refined by one such cycle-resolving rule, dubbed Split Cycle: in each\nmajority cycle, discard the majority preferences with the smallest majority\nmargin. They showed that any rule satisfying five standard axioms plus a\nweakening of Arrow's Independence of Irrelevant Alternatives (IIA), called\nCoherent IIA, is refined by Split Cycle. In this paper, we go further and show\nthat Split Cycle is the only rule satisfying the axioms of Holliday and Pacuit\ntogether with two additional axioms, which characterize the class of rules that\nrefine Split Cycle: Coherent Defeat and Positive Involvement in Defeat.\nCoherent Defeat states that any majority preference not occurring in a cycle is\nretained, while Positive Involvement in Defeat is closely related to the\nwell-known axiom of Positive Involvement (as in J. Perez, Social Choice and\nWelfare 18 (2001) 601-616). We characterize Split Cycle not only as a\ncollective choice rule but also as a social choice correspondence, over both\nprofiles of linear ballots and profiles of ballots allowing ties.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.12503v3"
    },
    {
        "title": "On the Emergence of Cooperation in the Repeated Prisoner's Dilemma",
        "authors": [
            "Maximilian Schaefer"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Using simulations between pairs of $\\epsilon$-greedy q-learners with\none-period memory, this article demonstrates that the potential function of the\nstochastic replicator dynamics (Foster and Young, 1990) allows it to predict\nthe emergence of error-proof cooperative strategies from the underlying\nparameters of the repeated prisoner's dilemma. The observed cooperation rates\nbetween q-learners are related to the ratio between the kinetic energy exerted\nby the polar attractors of the replicator dynamics under the grim trigger\nstrategy. The frontier separating the parameter space conducive to cooperation\nfrom the parameter space dominated by defection can be found by setting the\nkinetic energy ratio equal to a critical value, which is a function of the\ndiscount factor, $f(\\delta) = \\delta/(1-\\delta)$, multiplied by a correction\nterm to account for the effect of the algorithms' exploration probability. The\ngradient at the frontier increases with the distance between the game\nparameters and the hyperplane that characterizes the incentive compatibility\nconstraint for cooperation under grim trigger.\n  Building on literature from the neurosciences, which suggests that\nreinforcement learning is useful to understanding human behavior in risky\nenvironments, the article further explores the extent to which the frontier\nderived for q-learners also explains the emergence of cooperation between\nhumans. Using metadata from laboratory experiments that analyze human choices\nin the infinitely repeated prisoner's dilemma, the cooperation rates between\nhumans are compared to those observed between q-learners under similar\nconditions. The correlation coefficients between the cooperation rates observed\nfor humans and those observed for q-learners are consistently above $0.8$. The\nfrontier derived from the simulations between q-learners is also found to\npredict the emergence of cooperation between humans.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.15331v2"
    },
    {
        "title": "Influence of rationality levels on dynamics of heterogeneous Cournot\n  duopolists with quadratic costs",
        "authors": [
            "Xiaoliang Li",
            "Yihuo Jiang"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper is intended to investigate the dynamics of heterogeneous Cournot\nduopoly games, where the first players adopt identical gradient adjustment\nmechanisms but the second players are endowed with distinct rationality levels.\nBased on tools of symbolic computations, we introduce a new approach and use it\nto establish rigorous conditions of the local stability for these models. We\nanalytically investigate the bifurcations and prove that the period-doubling\nbifurcation is the only possible bifurcation that may occur for all the\nconsidered models. The most important finding of our study is regarding the\ninfluence of players' rational levels on the stability of heterogeneous\nduopolistic competition. It is derived that the stability region of the model\nwhere the second firm is rational is the smallest, while that of the one where\nthe second firm is boundedly rational is the largest. This fact is\ncounterintuitive and contrasts with relative conclusions in the existing\nliterature. Furthermore, we also provide numerical simulations to demonstrate\nthe emergence of complex dynamics such as periodic solutions with different\norders and strange attractors.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07128v1"
    },
    {
        "title": "The Investment Management Game: Extending the Scope of the Notion of\n  Core",
        "authors": [
            "Vijay V. Vazirani"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The core is a dominant solution concept in economics and cooperative game\ntheory; it is predominantly used for profit, equivalently cost or utility,\nsharing. This paper demonstrates the versatility of this notion by proposing a\ncompletely different use: in a so-called investment management game, which is a\ngame against nature rather than a cooperative game. This game has only one\nagent whose strategy set is all possible ways of distributing her money among\ninvestment firms. The agent wants to pick a strategy such that in each of\nexponentially many future scenarios, sufficient money is available in the right\nfirms so she can buy an optimal investment for that scenario. Such a strategy\nconstitutes a core imputation under a broad interpretation, though traditional\nformal framework, of the core. Our game is defined on perfect graphs, since the\nmaximum stable set problem can be solved in polynomial time for such graphs. We\ncompletely characterize the core of this game, analogous to Shapley and Shubik\ncharacterization of the core of the assignment game. A key difference is the\nfollowing technical novelty: whereas their characterization follows from total\nunimodularity, ours follows from total dual integrality\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00608v5"
    },
    {
        "title": "Dynamic Programming for Pure-Strategy Subgame Perfection in an Arbitrary\n  Game",
        "authors": [
            "Peter A. Streufert"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper uses value functions to characterize the pure-strategy\nsubgame-perfect equilibria of an arbitrary, possibly infinite-horizon game. It\nspecifies the game's extensive form as a pentaform (Streufert 2023p,\narXiv:2107.10801v4), which is a set of quintuples formalizing the abstract\nrelationships between nodes, actions, players, and situations (situations\ngeneralize information sets). Because a pentaform is a set, this paper can\nexplicitly partition the game form into piece forms, each of which starts at a\n(Selten) subroot and contains all subsequent nodes except those that follow a\nsubsequent subroot. Then the set of subroots becomes the domain of a value\nfunction, and the piece-form partition becomes the framework for a value\nrecursion which generalizes the Bellman equation from dynamic programming. The\nmain results connect the value recursion with the subgame-perfect equilibria of\nthe original game, under the assumptions of upper- and lower-convergence.\nFinally, a corollary characterizes subgame perfection as the absence of an\nimproving one-piece deviation.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03855v3"
    },
    {
        "title": "Zero-Knowledge Mechanisms",
        "authors": [
            "Ran Canetti",
            "Amos Fiat",
            "Yannai A. Gonczarowski"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A powerful feature in mechanism design is the ability to irrevocably commit\nto the rules of a mechanism. Commitment is achieved by public declaration,\nwhich enables players to verify incentive properties in advance and the outcome\nin retrospect. However, public declaration can reveal superfluous information\nthat the mechanism designer might prefer not to disclose, such as her target\nfunction or private costs. Avoiding this may be possible via a trusted\nmediator; however, the availability of a trusted mediator, especially if\nmechanism secrecy must be maintained for years, might be unrealistic. We\npropose a new approach to commitment, and show how to commit to, and run, any\ngiven mechanism without disclosing it, while enabling the verification of\nincentive properties and the outcome -- all without the need for any mediators.\nOur framework is based on zero-knowledge proofs -- a cornerstone of modern\ncryptographic theory. Applications include non-mediated bargaining with hidden\nyet binding offers.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05590v1"
    },
    {
        "title": "A Tractable Truthful Profit Maximization Mechanism Design with\n  Autonomous Agents",
        "authors": [
            "Mina Montazeri",
            "Hamed Kebriaei",
            "Babak N. Araabi"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Task allocation is a crucial process in modern systems, but it is often\nchallenged by incomplete information about the utilities of participating\nagents. In this paper, we propose a new profit maximization mechanism for the\ntask allocation problem, where the task publisher seeks an optimal incentive\nfunction to maximize its own profit and simultaneously ensure the truthful\nannouncing of the agent's private information (type) and its participation in\nthe task, while an autonomous agent aims at maximizing its own utility function\nby deciding on its participation level and announced type. Our mechanism stands\nout from the classical contract theory-based truthful mechanisms as it empowers\nagents to make their own decisions about their level of involvement, making it\nmore practical for many real-world task allocation scenarios. It has been\nproven that by considering a linear form of incentive function consisting of\ntwo decision functions for the task publisher the mechanism's goals are met.\nThe proposed truthful mechanism is initially modeled as a non-convex functional\noptimization with the double continuum of constraints, nevertheless, we\ndemonstrate that by deriving an equivalent form of the incentive constraints,\nit can be reformulated as a tractable convex optimal control problem. Further,\nwe propose a numerical algorithm to obtain the solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05677v1"
    },
    {
        "title": "Time-inconsistent contract theory",
        "authors": [
            "Camilo Hernández",
            "Dylan Possamaï"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper investigates the moral hazard problem in finite horizon with both\ncontinuous and lump-sum payments, involving a time-inconsistent sophisticated\nagent and a standard utility maximiser principal. Building upon the so-called\ndynamic programming approach in Cvitani\\'c, Possama\\\"i, and Touzi [18] and the\nrecently available results in Hern\\'andez and Possama\\\"i [43], we present a\nmethodology that covers the previous contracting problem. Our main contribution\nconsists in a characterisation of the moral hazard problem faced by the\nprincipal. In particular, it shows that under relatively mild technical\nconditions on the data of the problem, the supremum of the principal's expected\nutility over a smaller restricted family of contracts is equal to the supremum\nover all feasible contracts. Nevertheless, this characterisation yields, as far\nas we know, a novel class of control problems that involve the control of a\nforward Volterra equation via Volterra-type controls, and infinite-dimensional\nstochastic target constraints. Despite the inherent challenges associated to\nsuch a problem, we study the solution under three different specifications of\nutility functions for both the agent and the principal, and draw qualitative\nimplications from the form of the optimal contract. The general case remains\nthe subject of future research.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.01601v1"
    },
    {
        "title": "Q-learning with biased policy rules",
        "authors": [
            "Olivier Compte"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In dynamic environments, Q-learning is an automaton that (i) provides\nestimates (Q-values) of the continuation values associated with each available\naction; and (ii) follows the naive policy of almost always choosing the action\nwith highest Q-value. We consider a family of automata that are based on\nQ-values but whose policy may systematically favor some actions over others,\nfor example through a bias that favors cooperation. In the spirit of Compte and\nPostlewaite [2018], we look for equilibrium biases within this family of\nQ-based automata. We examine classic games under various monitoring\ntechnologies and find that equilibrium biases may strongly foster collusion.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12647v2"
    },
    {
        "title": "To AI or not to AI, to Buy Local or not to Buy Local: A Mathematical\n  Theory of Real Price",
        "authors": [
            "Huan Cai",
            "Catherine Xu",
            "Weiyu Xu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In the past several decades, the world's economy has become increasingly\nglobalized. On the other hand, there are also ideas advocating the practice of\n``buy local'', by which people buy locally produced goods and services rather\nthan those produced farther away. In this paper, we establish a mathematical\ntheory of real price that determines the optimal global versus local spending\nof an agent which achieves the agent's optimal tradeoff between spending and\nobtained utility. Our theory of real price depends on the asymptotic analysis\nof a Markov chain transition probability matrix related to the network of\nproducers and consumers. We show that the real price of a product or service\ncan be determined from the involved Markov chain matrix, and can be\ndramatically different from the product's label price. In particular, we show\nthat the label prices of products and services are often not ``real'' or\ndirectly ``useful'': given two products offering the same myopic utility, the\none with lower label price may not necessarily offer better asymptotic utility.\nThis theory shows that the globality or locality of the products and services\ndoes have different impacts on the spending-utility tradeoff of a customer. The\nestablished mathematical theory of real price can be used to determine whether\nto adopt or not to adopt certain artificial intelligence (AI) technologies from\nan economic perspective.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.05134v1"
    },
    {
        "title": "Robust Auction Design with Support Information",
        "authors": [
            "Jerry Anunrojwong",
            "Santiago R. Balseiro",
            "Omar Besbes"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  A seller wants to sell an item to $n$ buyers. Buyer valuations are drawn\ni.i.d. from a distribution unknown to the seller; the seller only knows that\nthe support is included in $[a, b]$. To be robust, the seller chooses a DSIC\nmechanism that optimizes the worst-case performance relative to the ideal\nexpected revenue the seller could have collected with knowledge of buyers'\nvaluations. Our analysis unifies the regret and the ratio objectives.\n  For these objectives, we derive an optimal mechanism and the corresponding\nperformance in quasi-closed form, as a function of the support information $[a,\nb]$ and the number of buyers $n$. Our analysis reveals three regimes of support\ninformation and a new class of robust mechanisms. i.) When $a/b$ is below a\nthreshold, the optimal mechanism is a second-price auction (SPA) with random\nreserve, a focal class in earlier literature. ii.) When $a/b$ is above another\nthreshold, SPAs are strictly suboptimal, and an optimal mechanism belongs to a\nclass of mechanisms we introduce, which we call pooling auctions (POOL);\nwhenever the highest value is above a threshold, the mechanism still allocates\nto the highest bidder, but otherwise the mechanism allocates to a uniformly\nrandom buyer, i.e., pools low types. iii.) When $a/b$ is between two\nthresholds, a randomization between SPA and POOL is optimal.\n  We also characterize optimal mechanisms within nested central subclasses of\nmechanisms: standard mechanisms that only allocate to the highest bidder, SPA\nwith random reserve, and SPA with no reserve. We show strict separations in\nterms of performance across classes, implying that deviating from standard\nmechanisms is necessary for robustness.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.09065v3"
    },
    {
        "title": "Context-Dependent Heterogeneous Preferences: A Comment on Barseghyan and\n  Molinari (2023)",
        "authors": [
            "Matias D. Cattaneo",
            "Xinwei Ma",
            "Yusufcan Masatlioglu"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Barseghyan and Molinari (2023) give sufficient conditions for\nsemi-nonparametric point identification of parameters of interest in a mixture\nmodel of decision-making under risk, allowing for unobserved heterogeneity in\nutility functions and limited consideration. A key assumption in the model is\nthat the heterogeneity of risk preferences is unobservable but\ncontext-independent. In this comment, we build on their insights and present\nidentification results in a setting where the risk preferences are allowed to\nbe context-dependent.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10934v1"
    },
    {
        "title": "Rational social distancing in epidemics with uncertain vaccination\n  timing",
        "authors": [
            "Simon K. Schnyder",
            "John J. Molina",
            "Ryoichi Yamamoto",
            "Matthew S. Turner"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  During epidemics people may reduce their social and economic activity to\nlower their risk of infection. Such social distancing strategies will depend on\ninformation about the course of the epidemic but also on when they expect the\nepidemic to end, for instance due to vaccination. Typically it is difficult to\nmake optimal decisions, because the available information is incomplete and\nuncertain. Here, we show how optimal decision-making depends on information\nabout vaccination timing in a differential game in which individual\ndecision-making gives rise to Nash equilibria, and the arrival of the vaccine\nis described by a probability distribution. We predict stronger social\ndistancing the earlier the vaccination is expected and also the more sharply\npeaked its probability distribution. In particular, equilibrium social\ndistancing only meaningfully deviates from the no-vaccination equilibrium\ncourse if the vaccine is expected to arrive before the epidemic would have run\nits course. We demonstrate how the probability distribution of the vaccination\ntime acts as a generalised form of discounting, with the special case of an\nexponential vaccination time distribution directly corresponding to regular\nexponential discounting.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13618v2"
    },
    {
        "title": "House-Swapping with Objective Indifferences",
        "authors": [
            "Will Sandholtz",
            "Andrew Tai"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the classic house-swapping problem of Shapley and Scarf (1974) in a\nsetting where agents may have \"objective\" indifferences, i.e., indifferences\nthat are shared by all agents. In other words, if any one agent is indifferent\nbetween two houses, then all agents are indifferent between those two houses.\nThe most direct interpretation is the presence of multiple copies of the same\nobject. Our setting is a special case of the house-swapping problem with\ngeneral indifferences. We derive a simple, easily interpretable algorithm that\nproduces the unique strict core allocation of the house-swapping market, if it\nexists. Our algorithm runs in square polynomial time, a substantial improvement\nover the cubed time methods for the more general problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.09529v1"
    },
    {
        "title": "Would Friedman Burn your Tokens?",
        "authors": [
            "Aggelos Kiayias",
            "Philip Lazos",
            "Jan Christoph Schlegel"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Cryptocurrencies come with a variety of tokenomic policies as well as\naspirations of desirable monetary characteristics that have been described by\nproponents as 'sound money' or even 'ultra sound money.' These propositions are\ntypically devoid of economic analysis so it is a pertinent question how such\naspirations fit in the wider context of monetary economic theory. In this work,\nwe develop a framework that determines the optimal token supply policy of a\ncryptocurrency, as well as investigate how such policy may be algorithmically\nimplemented. Our findings suggest that the optimal policy complies with the\nFriedman rule and it is dependent on the risk free rate, as well as the growth\nof the cryptocurrency platform. Furthermore, we demonstrate a wide set of\nconditions under which such policy can be implemented via contractions and\nexpansions of token supply that can be realized algorithmically with block\nrewards, taxation of consumption and burning the proceeds, and blockchain\noracles.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17025v1"
    },
    {
        "title": "Algorithms, Incentives, and Democracy",
        "authors": [
            "Elizabeth Maggie Penn",
            "John W. Patty"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Classification algorithms are increasingly used in areas such as housing,\ncredit, and law enforcement in order to make decisions affecting peoples'\nlives. These algorithms can change individual behavior deliberately (a fraud\nprediction algorithm deterring fraud) or inadvertently (content sorting\nalgorithms spreading misinformation), and they are increasingly facing public\nscrutiny and regulation. Some of these regulations, like the elimination of\ncash bail in some states, have focused on \\textit{lowering the stakes of\ncertain classifications}. In this paper we characterize how optimal\nclassification by an algorithm designer can affect the distribution of behavior\nin a population -- sometimes in surprising ways. We then look at the effect of\ndemocratizing the rewards and punishments, or stakes, to algorithmic\nclassification to consider how a society can potentially stem (or facilitate!)\npredatory classification. Our results speak to questions of algorithmic\nfairness in settings where behavior and algorithms are interdependent, and\nwhere typical measures of fairness focusing on statistical accuracy across\ngroups may not be appropriate.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.02319v1"
    },
    {
        "title": "Resilient Information Aggregation",
        "authors": [
            "Itai Arieli",
            "Ivan Geffner",
            "Moshe Tennenholtz"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In an information aggregation game, a set of senders interact with a receiver\nthrough a mediator. Each sender observes the state of the world and\ncommunicates a message to the mediator, who recommends an action to the\nreceiver based on the messages received. The payoff of the senders and of the\nreceiver depend on both the state of the world and the action selected by the\nreceiver. This setting extends the celebrated cheap talk model in two aspects:\nthere are many senders (as opposed to just one) and there is a mediator. From a\npractical perspective, this setting captures platforms in which strategic\nexperts advice is aggregated in service of action recommendations to the user.\nWe aim at finding an optimal mediator/platform that maximizes the users'\nwelfare given highly resilient incentive compatibility requirements on the\nequilibrium selected: we want the platform to be incentive compatible for the\nreceiver/user when selecting the recommended action, and we want it to be\nresilient against group deviations by the senders/experts. We provide highly\npositive answers to this challenge, manifested through efficient algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.05054v1"
    },
    {
        "title": "A Model of Competitive Assortment Planning Algorithm",
        "authors": [
            "Dipankar Das"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  With a novel search algorithm or assortment planning or assortment\noptimization algorithm that takes into account a Bayesian approach to\ninformation updating and two-stage assortment optimization techniques, the\ncurrent research provides a novel concept of competitiveness in the digital\nmarketplace. Via the search algorithm, there is competition between the\nplatform, vendors, and private brands of the platform. The current paper\nsuggests a model and discusses how competition and collusion arise in the\ndigital marketplace through assortment planning or assortment optimization\nalgorithm. Furthermore, it suggests a model of an assortment algorithm free\nfrom collusion between the platform and the large vendors. The paper's major\nconclusions are that collusive assortment may raise a product's purchase\nlikelihood but fail to maximize expected revenue. The proposed assortment\nplanning, on the other hand, maintains competitiveness while maximizing\nexpected revenue.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.09479v1"
    },
    {
        "title": "Duopoly insurers' incentives for data quality under a mandatory cyber\n  data sharing regime",
        "authors": [
            "Carlos Barreto",
            "Olof Reinert",
            "Tobias Wiesinger",
            "Ulrik Franke"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We study the impact of data sharing policies on cyber insurance markets.\nThese policies have been proposed to address the scarcity of data about cyber\nthreats, which is essential to manage cyber risks. We propose a Cournot duopoly\ncompetition model in which two insurers choose the number of policies they\noffer (i.e., their production level) and also the resources they invest to\nensure the quality of data regarding the cost of claims (i.e., the data quality\nof their production cost). We find that enacting mandatory data sharing\nsometimes creates situations in which at most one of the two insurers invests\nin data quality, whereas both insurers would invest when information sharing is\nnot mandatory. This raises concerns about the merits of making data sharing\nmandatory.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.00795v1"
    },
    {
        "title": "Interest Rate Dynamics and Commodity Prices",
        "authors": [
            "Christophe Gouel",
            "Qingyin Ma",
            "John Stachurski"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In economic studies and popular media, interest rates are routinely cited as\na major factor behind commodity price fluctuations. At the same time, the\ntransmission channels are far from transparent, leading to long-running debates\non the sign and magnitude of interest rate effects. Purely empirical studies\nstruggle to address these issues because of the complex interactions between\ninterest rates, prices, supply changes, and aggregate demand. To move this\ndebate to a solid footing, we extend the competitive storage model to include\nstochastically evolving interest rates. We establish general conditions for\nexistence and uniqueness of solutions and provide a systematic theoretical and\nquantitative analysis of the interactions between interest rates and prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.07577v2"
    },
    {
        "title": "Game Connectivity and Adaptive Dynamics",
        "authors": [
            "Tom Johnston",
            "Michael Savery",
            "Alex Scott",
            "Bassel Tarbush"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We analyse the typical structure of games in terms of the connectivity\nproperties of their best-response graphs. Our central result shows that almost\nevery game that is 'generic' (without indifferences) and has a pure Nash\nequilibrium and a 'large' number of players is connected, meaning that every\naction profile that is not a pure Nash equilibrium can reach every pure Nash\nequilibrium via best-response paths. This has important implications for\ndynamics in games. In particular, we show that there are simple, uncoupled,\nadaptive dynamics for which period-by-period play converges almost surely to a\npure Nash equilibrium in almost every large generic game that has one (which\ncontrasts with the known fact that there is no such dynamic that leads almost\nsurely to a pure Nash equilibrium in every generic game that has one). We build\non recent results in probabilistic combinatorics for our characterisation of\ngame connectivity.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10609v4"
    },
    {
        "title": "Theoretical Foundations of Community Rating by a Private Monopolist\n  Insurer: Framework, Regulation, and Numerical Analysis",
        "authors": [
            "Yann Braouezec",
            "John Cagnol"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Community rating is a policy that mandates uniform premium regardless of the\nrisk factors. In this paper, our focus narrows to the single contract\ninterpretation wherein we establish a theoretical framework for community\nrating using Stiglitz's (1977) monopoly model in which there is a continuum of\nagents. We exhibit profitability conditions and show that, under mild\nregularity conditions, the optimal premium is unique and satisfies the inverse\nelasticity rule. Our numerical analysis, using realistic parameter values,\nreveals that under regulation, a 10% increase in indemnity is possible with\nminimal impact on other variables.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.15269v2"
    },
    {
        "title": "A new economic and financial theory of money",
        "authors": [
            "Michael E. Glinsky",
            "Sharon Sievert"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper fundamentally reformulates economic and financial theory to\ninclude electronic currencies. The valuation of the electronic currencies will\nbe based on macroeconomic theory and the fundamental equation of monetary\npolicy, not the microeconomic theory of discounted cash flows. The view of\nelectronic currency as a transactional equity associated with tangible assets\nof a sub-economy will be developed, in contrast to the view of stock as an\nequity associated mostly with intangible assets of a sub-economy. The view will\nbe developed of the electronic currency management firm as an entity\nresponsible for coordinated monetary (electronic currency supply and value\nstabilization) and fiscal (investment and operational) policies of a\nsubstantial (for liquidity of the electronic currency) sub-economy. The risk\nmodel used in the valuations and the decision-making will not be the\nubiquitous, yet inappropriate, exponential risk model that leads to discount\nrates, but will be multi time scale models that capture the true risk. The\ndecision-making will be approached from the perspective of true systems control\nbased on a system response function given by the multi scale risk model and\nsystem controllers that utilize the Deep Reinforcement Learning, Generative\nPretrained Transformers, and other methods of Generative Artificial\nIntelligence (genAI). Finally, the sub-economy will be viewed as a nonlinear\ncomplex physical system with both stable equilibriums that are associated with\nshort-term exploitation, and unstable equilibriums that need to be stabilized\nwith active nonlinear control based on the multi scale system response\nfunctions and genAI.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04986v8"
    },
    {
        "title": "Impact of resource availability and conformity effect on sustainability\n  of common-pool resources",
        "authors": [
            "Chengyi Tu",
            "Renfei Chen",
            "Ying Fan",
            "Xuwei Pan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Sustainability of common-pool resources hinges on the interplay between human\nand environmental systems. However, there is still a lack of a novel and\ncomprehensive framework for modelling extraction of common-pool resources and\ncooperation of human agents that can account for different factors that shape\nthe system behavior and outcomes. In particular, we still lack a critical value\nfor ensuring resource sustainability under different scenarios. In this paper,\nwe present a novel framework for studying resource extraction and cooperation\nin human-environmental systems for common-pool resources. We explore how\ndifferent factors, such as resource availability and conformity effect,\ninfluence the players' decisions and the resource outcomes. We identify\ncritical values for ensuring resource sustainability under various scenarios.\nWe demonstrate the observed phenomena are robust to the complexity and\nassumptions of the models and discuss implications of our study for policy and\npractice, as well as the limitations and directions for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.07577v2"
    },
    {
        "title": "Coalitional Manipulations and Immunity of the Shapley Value",
        "authors": [
            "Christian Basteck",
            "Frank Huettner"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We consider manipulations in the context of coalitional games, where a\ncoalition aims to increase the total payoff of its members. An allocation rule\nis immune to coalitional manipulation if no coalition can benefit from internal\nreallocation of worth on the level of its subcoalitions\n(reallocation-proofness), and if no coalition benefits from a lower worth while\nall else remains the same (weak coalitional monotonicity). Replacing additivity\nin Shapley's original characterization by these requirements yields a new\nfoundation of the Shapley value, i.e., it is the unique efficient and symmetric\nallocation rule that awards nothing to a null player and is immune to\ncoalitional manipulations. We further find that for efficient allocation rules,\nreallocation-proofness is equivalent to constrained marginality, a weaker\nvariant of Young's marginality axiom. Our second characterization improves upon\nYoung's characterization by weakening the independence requirement intrinsic to\nmarginality.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.20415v1"
    },
    {
        "title": "Ultimatum game: regret or fairness?",
        "authors": [
            "Lida H. Aleksanyan",
            "Armen E. Allahverdyan",
            "Vardan G. Bardakhchyan"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In the ultimatum game, the challenge is to explain why responders reject\nnon-zero offers thereby defying classical rationality. Fairness and related\nnotions have been the main explanations so far. We explain this rejection\nbehavior via the following principle: if the responder regrets less about\nlosing the offer than the proposer regrets not offering the best option, the\noffer is rejected. This principle qualifies as a rational punishing behavior\nand it replaces the experimentally falsified classical rationality (the subgame\nperfect Nash equilibrium) that leads to accepting any non-zero offer. The\nprinciple is implemented via the transitive regret theory for probabilistic\nlotteries. The expected utility implementation is a limiting case of this. We\nshow that several experimental results normally prescribed to fairness and\nintent-recognition can be given an alternative explanation via rational\npunishment; e.g. the comparison between \"fair\" and \"superfair\", the behavior\nunder raising the stakes etc. Hence we also propose experiments that can\ndistinguish these two scenarios (fairness versus regret-based punishment). They\nassume different utilities for the proposer and responder. We focus on the\nmini-ultimatum version of the game and also show how it can emerge from a more\ngeneral setup of the game.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03814v1"
    },
    {
        "title": "Dynamics of buyer populations in fresh product markets",
        "authors": [
            "Ali Ellouze",
            "Bastien Fernandez"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Based on empirical evidences and previous studies, we introduce and\nmathematically study a perception-driven model for the dynamics of buyer\npopulations in markets of perishable goods. Buyer behaviours are driven partly\nby some loyalty to the sellers that they previously purchased at, and partly by\nthe sensitivity to the intrinsic attractiveness of each seller in the market.\nOn the other hand, the sellers update they attractiveness in time according to\nthe difference between the volume of their clientele and the mean volume of\nbuyers in the market, optimising either their profit when this difference is\nfavourable or their competitiveness otherwise. While this negative feedback\nmechanism is a source of instability that promotes oscillatory behaviour, our\nanalysis identifies the critical features of the dynamics that are responsible\nfor the asymptotic stability of the stationary states, both in their immediate\nneighbourhood and globally in phase space. Altogether, this study provides\nmathematical insights into the consequences of introducing feedback into\nbuyer-seller interactions in such markets, with emphasis on identifying\nconditions for long term constancy of clientele volumes.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03987v2"
    },
    {
        "title": "Common Knowledge, Regained",
        "authors": [
            "Yannai A. Gonczarowski",
            "Yoram Moses"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  For common knowledge to arise in dynamic settings, all players must\nsimultaneously come to know it has arisen. Consequently, common knowledge\ncannot arise in many realistic settings with timing frictions. This\ncounterintuitive observation of Halpern and Moses (1990) was discussed by Arrow\net al. (1987) and Aumann (1989), was called a paradox by Morris (2014), and has\nevaded satisfactory resolution for four decades. We resolve this paradox by\nproposing a new definition for common knowledge, which coincides with the\ntraditional one in static settings but is more permissive in dynamic settings.\nUnder our definition, common knowledge can arise without simultaneity,\nparticularly in canonical examples of the Haplern-Moses paradox. We demonstrate\nits usefulness by deriving for it an agreement theorem \\`a la Aumann (1976),\nshowing it arises in the setting of Geanakoplos and Polemarchakis (1982) with\ntiming frictions added, and applying it to characterize equilibrium behavior in\na dynamic coordination game.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.04374v2"
    },
    {
        "title": "Best Complete Approximations of Preference Relations",
        "authors": [
            "Hiroki Nishimura",
            "Efe A. Ok"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  We investigate the problem of approximating an incomplete preference relation\n$\\succsim$ on a finite set by a complete preference relation. We aim to obtain\nthis approximation in such a way that the choices on the basis of two\npreferences, one incomplete, the other complete, have the smallest possible\ndiscrepancy in the aggregate. To this end, we use the top-difference metric on\npreferences, and define a best complete approximation of $\\succsim$ as a\ncomplete preference relation nearest to $\\succsim$ relative to this metric. We\nprove that such an approximation must be a maximal completion of $\\succsim$,\nand that it is, in fact, any one completion of $\\succsim$ with the largest\nindex. Finally, we use these results to provide a sufficient condition for the\nbest complete approximation of a preference to be its canonical completion.\nThis leads to closed-form solutions to the best approximation problem in the\ncase of several incomplete preference relations of interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06641v1"
    },
    {
        "title": "Algorithmic Fairness with Feedback",
        "authors": [
            "John W. Patty",
            "Elizabeth Maggie Penn"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  The field of algorithmic fairness has rapidly emerged over the past 15 years\nas algorithms have become ubiquitous in everyday lives. Algorithmic fairness\ntraditionally considers statistical notions of fairness algorithms might\nsatisfy in decisions based on noisy data. We first show that these are\ntheoretically disconnected from welfare-based notions of fairness. We then\ndiscuss two individual welfare-based notions of fairness, envy freeness and\nprejudice freeness, and establish conditions under which they are equivalent to\nerror rate balance and predictive parity, respectively. We discuss the\nimplications of these findings in light of the recently discovered\nimpossibility theorem in algorithmic fairness (Kleinberg, Mullainathan, &\nRaghavan (2016), Chouldechova (2017)).\n",
        "pdf_link": "http://arxiv.org/pdf/2312.03155v1"
    },
    {
        "title": "WE economy: Potential of mutual aid distribution based on moral\n  responsibility and risk vulnerability",
        "authors": [
            "Takeshi Kato"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Reducing wealth inequality and disparity is a global challenge. The economic\nsystem is mainly divided into (1) gift and reciprocity, (2) power and\nredistribution, (3) market exchange, and (4) mutual aid without reciprocal\nobligations. The current inequality stems from a capitalist economy consisting\nof (2) and (3). To sublimate (1), which is the human economy, to (4), the\nconcept of a \"mixbiotic society\" has been proposed in the philosophical realm.\nThis is a society in which free and diverse individuals, \"I,\" mix with each\nother, recognize their respective \"fundamental incapability\" and sublimate them\ninto \"WE\" solidarity. The economy in this society must have moral\nresponsibility as a coadventurer and consideration for vulnerability to risk.\nTherefore, I focus on two factors of mind perception: moral responsibility and\nrisk vulnerability, and propose a novel model of wealth distribution following\nan econophysical approach. Specifically, I developed a joint-venture model, a\nredistribution model in the joint-venture model, and a \"WE economy\" model. A\nsimulation comparison of a combination of the joint ventures and redistribution\nwith the WE economies reveals that WE economies are effective in reducing\ninequality and resilient in normalizing wealth distribution as advantages, and\nsusceptible to free riders as disadvantages. However, this disadvantage can be\ncompensated for by fostering consensus and fellowship, and by complementing it\nwith joint ventures. This study essentially presents the effectiveness of moral\nresponsibility, the complementarity between the WE economy and the joint\neconomy, and the direction of the economy toward reducing inequality. Future\nchallenges are to develop the WE economy model based on real economic analysis\nand psychology, as well as to promote WE economy fieldwork for worker coops and\nplatform cooperatives to realize a desirable mixbiotic society.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.06927v1"
    },
    {
        "title": "LQG Information Design",
        "authors": [
            "Masaki Miyashita",
            "Takashi Ui"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  This paper addresses information design with linear best responses of agents,\nquadratic objective functions of an information designer, and a payoff state\ndistributed according to a Gaussian distribution. We formulate the problem as\nsemidefinite programming (SDP) and use the duality principle to characterize an\noptimal information structure. There exists a Gaussian information structure\nthat is optimal among all information structures. A necessary and sufficient\ncondition for optimality is that the realizations of the induced action profile\nand a state satisfy linear constraints derived from the primal and dual SDP. As\na result, an observed action profile typically reveals the true state even if\nindividual agents have only partial knowledge. In symmetric network games, an\noptimal information structure inherits this symmetry, which facilitates the\ncomputation of an optimal information structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.09479v2"
    },
    {
        "title": "Stochastic Control Barrier Functions for Economics",
        "authors": [
            "David van Wijk"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  Control barrier functions (CBFs) and safety-critical control have seen a\nrapid increase in popularity in recent years, predominantly applied to systems\nin aerospace, robotics and neural network controllers. Control barrier\nfunctions can provide a computationally efficient method to monitor arbitrary\nprimary controllers and enforce state constraints to ensure overall system\nsafety. One area that has yet to take advantage of the benefits offered by CBFs\nis the field of finance and economics. This manuscript re-introduces three\napplications of traditional control to economics, and develops and implements\nCBFs for such problems. We consider the problem of optimal advertising for the\ndeterministic and stochastic case and Merton's portfolio optimization problem.\nNumerical simulations are used to demonstrate the effectiveness of using\ntraditional control solutions in tandem with CBFs and stochastic CBFs to solve\nsuch problems in the presence of state constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.12612v2"
    },
    {
        "title": "An extension of May's Theorem to three alternatives: axiomatizing\n  Minimax voting",
        "authors": [
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  May's Theorem [K. O. May, Econometrica 20 (1952) 680-684] characterizes\nmajority voting on two alternatives as the unique preferential voting method\nsatisfying several simple axioms. Here we show that by adding some desirable\naxioms to May's axioms, we can uniquely determine how to vote on three\nalternatives (setting aside tiebreaking). In particular, we add two axioms\nstating that the voting method should mitigate spoiler effects and avoid the\nso-called strong no show paradox. We prove a theorem stating that any\npreferential voting method satisfying our enlarged set of axioms, which\nincludes some weak homogeneity and preservation axioms, must choose from among\nthe Minimax winners in all three-alternative elections. When applied to more\nthan three alternatives, our axioms also distinguish Minimax from other known\nvoting methods that coincide with or refine Minimax for three alternatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14256v3"
    },
    {
        "title": "An impossibility theorem concerning positive involvement in voting",
        "authors": [
            "Wesley H. Holliday"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In social choice theory with ordinal preferences, a voting method satisfies\nthe axiom of positive involvement if adding to a preference profile a voter who\nranks an alternative uniquely first cannot cause that alternative to go from\nwinning to losing. In this note, we prove a new impossibility theorem\nconcerning this axiom: there is no ordinal voting method satisfying positive\ninvolvement that also satisfies the Condorcet winner and loser criteria,\nresolvability, and a common invariance property for Condorcet methods, namely\nthat the choice of winners depends only on the ordering of majority margins by\nsize.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.05657v4"
    },
    {
        "title": "Subjective Causality",
        "authors": [
            "Joseph Y. Halpern",
            "Evan Piermont"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We show that it is possible to understand and identify a decision maker's\nsubjective causal judgements by observing her preferences over interventions.\nFollowing Pearl [2000], we represent causality using causal models (also called\nstructural equations models), where the world is described by a collection of\nvariables, related by equations. We show that if a preference relation over\ninterventions satisfies certain axioms (related to standard axioms regarding\ncounterfactuals), then we can define (i) a causal model, (ii) a probability\ncapturing the decision-maker's uncertainty regarding the external factors in\nthe world and (iii) a utility on outcomes such that each intervention is\nassociated with an expected utility and such that intervention $A$ is preferred\nto $B$ iff the expected utility of $A$ is greater than that of $B$. In\naddition, we characterize when the causal model is unique. Thus, our results\nallow a modeler to test the hypothesis that a decision maker's preferences are\nconsistent with some causal model and to identify causal judgements from\nobserved behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.10937v1"
    },
    {
        "title": "A Characterization of Optimal Queueing Regimes",
        "authors": [
            "Marco Scarsini",
            "Eran Shmaya"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider an M/M/1 queueing model where customers can strategically decide\nto enter or leave the queue. We characterize the class of queueing regimes such\nthat, for any parameters of the model, the socially efficient behavior is an\nequilibrium outcome.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.13812v3"
    },
    {
        "title": "Random partitions, potential, value, and externalities",
        "authors": [
            "André Casajus",
            "Yukihiko Funaki",
            "Frank Huettner"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  The Shapley value equals a player's contribution to the potential of a game.\nThe potential is a most natural one-number summary of a game, which can be\ncomputed as the expected accumulated worth of a random partition of the\nplayers. This computation integrates the coalition formation of all players and\nreadily extends to games with externalities. We investigate those potential\nfunctions for games with externalities that can be computed this way. It turns\nout that the potential that corresponds to the MPW solution introduced by\nMacho-Stadler et al. (2007, J. Econ. Theory 135, 339--356) is unique in the\nfollowing sense. It is obtained as the expected accumulated worth of a random\npartition, it generalizes the potential for games without externalities, and it\ninduces a solution that satisfies the null player property even in the presence\nof externalities.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.00394v2"
    },
    {
        "title": "Comparative Statics for Optimal Stopping Problems in Nonstationary\n  Environments",
        "authors": [
            "Théo Durandard",
            "Matteo Camboni"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  How do decisions change with the economic environment and with time? This\npaper studies general nonstationary stopping problems and provides the\nmethodological tools to answer these questions. First, we identify conditions\nthat ensure a monotone relation between decisions' timing and outcomes. These\nconditions apply to a prevalent class of economic environments. Second, we\ndevelop a theory of monotone comparative statics for stopping problems,\noffering general and unifying qualitative insights into the decision-maker's\nvalue and stopping behavior. We apply our results to models of information\nacquisition, bankruptcy, irreversible investment, and option pricing to explain\ndocumented patterns at odds with current theories.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.06999v2"
    },
    {
        "title": "Reputational Algorithm Aversion",
        "authors": [
            "Gregory Weitzner"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  People are often reluctant to incorporate information produced by algorithms\ninto their decisions, a phenomenon called ``algorithm aversion''. This paper\nshows how algorithm aversion arises when the choice to follow an algorithm\nconveys information about a human's ability. I develop a model in which workers\nmake forecasts of an uncertain outcome based on their own private information\nand an algorithm's signal. Low-skill workers receive worse information than the\nalgorithm and hence should always follow the algorithm's signal, while\nhigh-skill workers receive better information than the algorithm and should\nsometimes override it. However, due to reputational concerns, low-skill workers\ninefficiently override the algorithm to increase the likelihood they are\nperceived as high-skill. The model provides a fully rational microfoundation\nfor algorithm aversion that aligns with the broad concern that AI systems will\ndisplace many types of workers.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15418v3"
    },
    {
        "title": "Wisdom and Foolishness of Noisy Matching Markets",
        "authors": [
            "Kenny Peng",
            "Nikhil Garg"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We consider a many-to-one matching market where colleges share true\npreferences over students but make decisions using only independent noisy\nrankings. Each student has a true value $v$, but each college $c$ ranks the\nstudent according to an independently drawn estimated value $v + X_c$ for\n$X_c\\sim \\mathcal{D}.$ We ask a basic question about the resulting stable\nmatching: How noisy is the set of matched students? Two striking effects can\noccur in large markets (i.e., with a continuum of students and a large number\nof colleges). When $\\mathcal{D}$ is light-tailed, noise is fully attenuated:\nonly the highest-value students are matched. When $\\mathcal{D}$ is long-tailed,\nnoise is fully amplified: students are matched uniformly at random. These\nresults hold for any distribution of student preferences over colleges, and\nextend to when only subsets of colleges agree on true student valuations\ninstead of the entire market. More broadly, our framework provides a tractable\napproach to analyze implications of imperfect preference formation in large\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.16771v1"
    },
    {
        "title": "Resolute and symmetric mechanisms for two-sided matching problems",
        "authors": [
            "Daniela Bubboloni",
            "Michele Gori",
            "Claudia Meo"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We focus on the one-to-one two-sided matching model with two disjoint sets of\nagents of equal size, where each agent in a set has preferences on the agents\nin the other set modeled by a linear order. A matching mechanism associates a\nset of matchings to each preference profile; resoluteness, that is the\ncapability to select a unique matching, and stability are important properties\nfor a matching mechanism. The two versions of the deferred acceptance algorithm\nare resolute and stable matching mechanisms but they are unfair since they\nstrongly favor one side of the market. We introduce a property for matching\nmechanisms that relates to fairness; such property, called symmetry, captures\ndifferent levels of fairness and generalizes existing notions. We provide\nseveral possibility and impossibility results mainly involving the most general\nnotion of symmetry, known as gender fairness, resoluteness, stability, weak\nPareto optimality and minimal optimality. In particular, we prove that:\nresolute, gender fair matching mechanisms exist if and only if each side of the\nmarket consists of an odd number of agents; there exists no resolute, gender\nfair, minimally optimal matching mechanism. Those results are obtained by\nemploying algebraic methods based on group theory, an approach not yet explored\nin matching theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01404v2"
    },
    {
        "title": "Decision making in stochastic extensive form I: Stochastic decision\n  forests",
        "authors": [
            "E. Emanuel Rapsch"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A general theory of stochastic decision forests is developed to bridge two\nconcepts of information flow: decision trees and refined partitions on the one\nside, filtrations from probability theory on the other. Instead of the\ntraditional \"nature\" agent, this framework uses a single lottery draw to select\na tree of a given decision forest. Each \"personal\" agent receives dynamic\nupdates from an own oracle on the lottery outcome and makes partition-refining\nchoices adapted to this information. This theory addresses a key limitation of\nexisting approaches in extensive form theory, which struggle to model\ncontinuous-time stochastic processes, such as Brownian motion, as outcomes of\n\"nature\" decision making. Additionally, a class of stochastic decision forests\nbased on time-indexed action paths is constructed, encompassing a wide range of\nmodels from the literature and laying the groundwork for an approximation\ntheory for stochastic differential games in extensive form.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.12332v2"
    },
    {
        "title": "Blackwell-Monotone Information Costs",
        "authors": [
            "Xiaoyu Cheng",
            "Yonggyun Kim"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A Blackwell-monotone information cost function assigns higher costs to\nBlackwell more informative experiments. This paper provides simple necessary\nand sufficient conditions for a cost function to be Blackwell monotone over\nfinite experiments. The key condition involves a system of linear differential\ninequalities. By using this characterization, we show that when a cost function\nis additively separable, it is Blackwell monotone if and only if it is the sum\nof sublinear functions. This identifies a wide range of practical information\ncost functions. Finally, we apply our results to bargaining and persuasion\nproblems with costly information, broadening and strengthening earlier\nfindings.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.15158v2"
    },
    {
        "title": "Identifying Heterogeneous Decision Rules From Choices When Menus Are\n  Unobserved",
        "authors": [
            "Larry G Epstein",
            "Kaushil Patel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Given only aggregate choice data and limited information about how menus are\ndistributed across the population, we describe what can be inferred robustly\nabout the distribution of preferences (or more general decision rules). We\nstrengthen and generalize existing results on such identification and provide\nan alternative analytical approach to study the problem. We show further that\nour model and results are applicable, after suitable reinterpretation, to other\ncontexts. One application is to the robust identification of the distribution\nof updating rules given only the population distribution of beliefs and limited\ninformation about heterogeneous information sources.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.09500v1"
    },
    {
        "title": "Organizational Selection of Innovation",
        "authors": [
            "Lucas Böttcher",
            "Ronald Klingebiel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Budgetary constraints force organizations to pursue only a subset of possible\ninnovation projects. Identifying which subset is most promising is an\nerror-prone exercise, and involving multiple decision makers may be prudent.\nThis raises the question of how to most effectively aggregate their collective\nnous. Our model of organizational portfolio selection provides some first\nanswers. We show that portfolio performance can vary widely. Delegating\nevaluation makes sense when organizations employ the relevant experts and can\nassign projects to them. In most other settings, aggregating the impressions of\nmultiple agents leads to better performance than delegation. In particular,\nletting agents rank projects often outperforms alternative aggregation rules --\nincluding averaging agents' project scores as well as counting their approval\nvotes -- especially when organizations have tight budgets and can select only a\nfew project alternatives out of many.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.09843v1"
    },
    {
        "title": "Comparing experiments in discounted problems",
        "authors": [
            "Ludovic Renou",
            "Xavier Venel"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper compares statistical experiments in discounted problems, ranging\nfrom the simplest ones where the state is fixed and the flow of information\nexogenous to more complex ones, where the decision-maker controls the flow of\ninformation or the state changes over time.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.16458v2"
    },
    {
        "title": "The Limits of Interval-Regulated Price Discrimination",
        "authors": [
            "Kamesh Munagala",
            "Yiheng Shen",
            "Renzhe Xu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  In this paper, we study third-degree price discrimination in a model first\npresented in Bergemann, Brooks, and Morris [2015]. Since such price\ndiscrimination might create market segments with vastly different posted\nprices, we consider regulating these prices, specifically, via restricting them\nto lie within an interval. Given a price interval, we consider segmentations of\nthe market where a seller, who is oblivious to the existence of such\nregulation, still posts prices within the price interval. We show the following\nsurprising result: For any market and price interval where such segmentation is\nfeasible, there is always a different segmentation that optimally transfers all\nexcess surplus to the consumers. In addition, we characterize the entire space\nof buyer and seller surplus that are achievable by such segmentation, including\nmaximizing seller surplus, and simultaneously minimizing buyer and seller\nsurplus.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.06023v1"
    },
    {
        "title": "A Mechanism for Optimizing Media Recommender Systems",
        "authors": [
            "Brian McFadden"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A mechanism is described that addresses the fundamental trade off between\nmedia producers who want to increase reach and consumers who provide attention\nbased on the rate of utility received, and where overreach negatively impacts\nthat rate. An optimal solution can be achieved when the media source considers\nthe impact of overreach in a cost function used in determining the optimal\ndistribution of content to maximize individual consumer utility and\nparticipation. The result is a Nash equilibrium between producer and consumer\nthat is also Pareto efficient. Comparison with the literature on Recommender\nsystems highlights the advantages of the mechanism, including identifying an\noptimal content volume for the consumer and improvements for optimizing with\nmultiple objectives. A practical algorithm for generating the optimal\ndistribution for each consumer is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.16212v2"
    },
    {
        "title": "Battery Operations in Electricity Markets: Strategic Behavior and\n  Distortions",
        "authors": [
            "Jerry Anunrojwong",
            "Santiago R. Balseiro",
            "Omar Besbes",
            "Bolun Xu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Electric power systems are undergoing a major transformation as they\nintegrate intermittent renewable energy sources, and batteries to smooth out\nvariations in renewable energy production. As privately-owned batteries grow\nfrom their role as marginal \"price-takers\" to significant players in the\nmarket, a natural question arises: How do batteries operate in electricity\nmarkets, and how does the strategic behavior of decentralized batteries distort\ndecisions compared to centralized batteries?\n  We propose an analytically tractable model that captures salient features of\nthe highly complex electricity market. We derive in closed form the resulting\nbattery behavior and generation cost in three operating regimes: (i) no\nbattery, (ii) centralized battery, and (ii) decentralized profit-maximizing\nbattery. We establish that a decentralized battery distorts its discharge\ndecisions in three ways. First, there is quantity withholding, i.e.,\ndischarging less than centrally optimal. Second, there is a shift in\nparticipation from day-ahead to real-time, i.e., postponing some of its\ndischarge from day-ahead to real-time. Third, there is reduction in real-time\nresponsiveness, or discharging less in response to smoothing real-time demand\nthan centrally optimal. We quantify each of the three forms of distortions in\nterms of market fundamentals. To illustrate our results, we calibrate our model\nto Los Angeles and Houston and show that the loss from incentive misalignment\ncould be consequential.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18685v1"
    },
    {
        "title": "No Screening is More Efficient with Multiple Objects",
        "authors": [
            "Shunya Noda",
            "Genta Okada"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study efficient mechanism design for allocating multiple heterogeneous\nobjects. We aim to maximize the residual surplus, the total value generated\nfrom an allocation minus the costs for screening agents' values. We discover a\nrobust trend indicating that no-screening mechanisms such as serial\ndictatorship with exogenous priority order tend to perform better as the\nvariety of goods increases. We analyze the underlying reasons by characterizing\nefficient mechanisms in a stylized environment. We also apply an automated\nmechanism design approach to numerically derive efficient mechanisms and\nvalidate the trend in general environments. Building on this implication, we\npropose the register-invite-book system (RIB) as an efficient system for\nscheduling vaccination against pandemic diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.10077v1"
    },
    {
        "title": "Fair Combinatorial Auction for Blockchain Trade Intents: Being Fair\n  without Knowing What is Fair",
        "authors": [
            "Andrea Canidio",
            "Felix Henneke"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Blockchain trade intent auctions currently intermediate approximately USD 5\nbillion monthly. Due to production complementarities, the auction is\ncombinatorial: when multiple trade intents from different traders are auctioned\noff simultaneously, a bidder (here called solver) can generate additional\nefficiencies by winning a batch of multiple trade intents. However, sharing\nthese additional efficiencies between traders is problematic: because of market\nfrictions and fees (solvers' private information), the auctioneer does not know\nhow much each trader would have received had its trade been auctioned off\nindividually. We formalize this problem and study the most commonly used\nauction formats: batch auctions and multiple simultaneous auctions. We also\npropose a novel fair combinatorial auction that combines batch auction and\nmultiple simultaneous auctions: solvers submit individual-trade bids and\nbatched bids, but batched bids are considered only if they are better for all\ntraders relative to the outcome of the simultaneous auctions constructed using\nthe individual-trade bids. We find a trade-off between the fairness guarantees\nprovided in equilibrium by the auction (i.e., the minimum each trader can\nexpect to receive) and the expected value of the assets returned to the\ntraders. Also, the amount that each trader receives in the equilibrium of the\nfair combinatorial auction may be higher or lower than what they receive in the\nequilibrium of the simultaneous auctions used as a benchmark for fairness.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.12225v2"
    },
    {
        "title": "Semi-Separable Mechanisms in Multi-Item Robust Screening",
        "authors": [
            "Shixin Wang"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  It is generally challenging to characterize the optimal selling mechanism\neven when the seller knows the buyer's valuation distributions in multi-item\nscreening. An insightful and significant result in robust mechanism design\nliterature is that if the seller knows only marginal distributions of the\nbuyer's valuation, then separable mechanisms, in which all items are sold\nindependently, are robustly optimal under the maximin revenue objectives. While\nthe separable mechanism is simple to implement, the literature also indicates\nthat separate selling can not guarantee any substantial fraction of the\npotential optimal revenue for given distributions. To design a simple mechanism\nwith a good performance guarantee, we introduce a novel class of mechanisms,\ntermed \"semi-separable mechanism\". In these mechanisms, the allocation and\npayment rule of each item is a function solely of the corresponding item's\nvaluation, which retains the separable mechanism's practical simplicity.\nHowever, the design of the allocation and payment function is enhanced by\nleveraging the joint distributional information, thereby improving the\nperformance guarantee against the hindsight optimal revenue. We establish that\na semi-separable mechanism achieves the optimal performance ratio among all\nincentive-compatible and individually rational mechanisms when only marginal\nsupport information is known. This result demonstrates that the semi-separable\nmechanisms ensure both the interpretation and implementation simplicity, and\nperformance superiority. Our framework is also applicable to scenarios where\nthe seller possesses information about the aggregate valuations of product\nbundles within any given partition of the product set. Furthermore, our results\nalso provide guidelines for the multi-item screening problem with non-standard\nambiguity sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.13580v1"
    },
    {
        "title": "The Asymptotic Cost of Complexity",
        "authors": [
            "Martin W Cripps"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We propose a measure of learning efficiency for non-finite state spaces. We\ncharacterize the complexity of a learning problem by the metric entropy of its\nstate space. We then describe how learning efficiency is determined by this\nmeasure of complexity. This is, then, applied to two models where agents learn\nhigh-dimensional states.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.14949v1"
    },
    {
        "title": "On Mechanism Underlying Algorithmic Collusion",
        "authors": [
            "Zhang Xu",
            "Wei Zhao"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Two issues of algorithmic collusion are addressed in this paper. First, we\nshow that in a general class of symmetric games, including Prisoner's Dilemma,\nBertrand competition, and any (nonlinear) mixture of first and second price\nauction, only (strict) Nash Equilibrium (NE) is stochastically stable.\nTherefore, the tacit collusion is driven by failure to learn NE due to\ninsufficient learning, instead of learning some strategies to sustain collusive\noutcomes. Second, we study how algorithms adapt to collusion in real\nsimulations with insufficient learning. Extensive explorations in early stages\nand discount factors inflates the Q-value, which interrupts the sequential and\nalternative price undercut and leads to bilateral rebound. The process is\niterated, making the price curves like Edgeworth cycles. When both exploration\nrate and Q-value decrease, algorithms may bilaterally rebound to relatively\nhigh common price level by coincidence, and then get stuck. Finally, we\naccommodate our reasoning to simulation outcomes in the literature, including\noptimistic initialization, market design and algorithm design.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.01147v1"
    },
    {
        "title": "On the Formation of Steady Coalitions",
        "authors": [
            "Dylan Laplace Mermoud"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies the formation of the grand coalition of a cooperative game\nby investigating its possible internal dynamics. Each coalition is capable of\nforcing all players to reconsider the current state of the game when it does\nnot provide sufficient payoff. Different coalitions may ask for contradictory\nevolutions, leading to the impossibility of the grand coalition forming. In\nthis paper, we give a characterization of the impossibility, for a given state,\nof finding a new state dominating the previous one such that each aggrieved\ncoalition has a satisfactory payoff. To do so, we develop new polyhedral tools\nrelated to a new family of polyhedra, appearing in numerous situations in\ncooperative game theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.05087v2"
    },
    {
        "title": "A Firm Link: Overall, Between- and Within-Firm Inequality Through the\n  Lens of a Sorting Model",
        "authors": [
            "Paweł Gola",
            "Yuejun Zhao"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper provides a new theory of the observed co-movement between overall\nwage inequality and its between-firm component. We develop and solve\nanalytically a frictionless sorting model with two-sided heterogeneity, in\nwhich firms consist of distributions of tasks, choose how many workers to\nemploy and reward their workers both through wages and amenities. We show that,\nfor empirically-relevant parameter ranges, overall and between-firm inequality\nare firmly linked: A change in any of the models' primitives increases overall\nwage inequality if and only if it also increases the ratio of between-firm to\noverall inequality. Subsequently, we calibrate the model to match the Norwegian\neconomy and find that the increase in wage inequality from 1995 to 2014 had a\ndifferent primary cause (raising span-of-control cost) than the accompanying\nrise in welfare inequality (increased skill variance), and that the apparent\ndecrease in wage inequality after 2015 masked a continued increase in welfare\ninequality.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.11532v1"
    },
    {
        "title": "Strategic Irreversible Investment",
        "authors": [
            "Jan-Henrik Steg"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  This paper studies oligopolistic irreversible investment with closed-loop\nstrategies. These permit fully dynamic interactions that result in much richer\nstrategic behavior than previous studies with open-loop strategies allow. The\ntradeoff between preemption incentives and the option value of waiting becomes\ndistinctly visible. Strategies that depend on present capital stocks enable\ncredible reactions that deter from excessive preemption and support positive\noption values in equilibrium. Simpler strategies lead into a \"preemption trap\"\nwith perfectly competitive outcome and zero net present values. To obtain these\nresults, a novel concept of Markov perfect equilibrium is developed that copes\nwith optimal investment taking the form of singular control.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.17673v1"
    },
    {
        "title": "Loss Aversion and State-Dependent Linear Utility Functions for Monetary\n  Returns",
        "authors": [
            "Somdeb Lahiri"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We present a theory of expected utility with state-dependent linear utility\nfunctions for monetary returns, that incorporates the possibility of\nloss-aversion. Our results relate to first order stochastic dominance,\nmean-preserving spread, increasing-concave linear utility profiles and risk\naversion. As an application of the expected utility theory developed here, we\nanalyze the contract that a monopolist would offer in an insurance market that\nallowed for partial coverage of loss.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19030v3"
    },
    {
        "title": "Robust Market Interventions",
        "authors": [
            "Andrea Galeotti",
            "Benjamin Golub",
            "Sanjeev Goyal",
            "Eduard Talamàs",
            "Omer Tamuz"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  When can interventions in markets be designed to increase surplus robustly --\ni.e., with high probability -- accounting for uncertainty due to imprecise\ninformation about economic primitives? In a setting with many strategic firms,\neach possessing some market power, we present conditions for such interventions\nto exist. The key condition, recoverable structure, requires large-scale\ncomplementarities among families of products. The analysis works by decomposing\nthe incidence of interventions in terms of principal components of a Slutsky\nmatrix. Under recoverable structure, a noisy signal of this matrix reveals\nenough about these principal components to design robust interventions. Our\nresults demonstrate the usefulness of spectral methods for analyzing\nimperfectly observed strategic interactions with many agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03026v2"
    },
    {
        "title": "Market efficiency, informational asymmetry and pseudo-collusion of\n  adaptively learning agents",
        "authors": [
            "Aleksei Pastushkov"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We examine the dynamics of informational efficiency in a market with\nasymmetrically informed, boundedly rational traders who adaptively learn\noptimal strategies using simple multiarmed bandit (MAB) algorithms. The\nstrategies available to the traders have two dimensions: on the one hand, the\ntraders must endogenously choose whether to acquire a costly information\nsignal, on the other, they must determine how aggressively they trade by\nchoosing the share of their wealth to be invested in the risky asset. Our study\ncontributes to two strands of literature: the literature comparing the effects\nof competitive and strategic behavior on asset price efficiency under costly\ninformation as well as the actively growing literature on algorithmic tacit\ncollusion and pseudo-collusion in financial markets. We find that for certain\nmarket environments (with low information costs) our model reproduces the\nresults of Kyle [1989] in that the ability of traders to trade strategically\nleads to worse price efficiency compared to the purely competitive case. For\nother environments (with high information costs), on the other hand, our\nresults show that a market with strategically acting traders can be more\nefficient than a purely competitive one. Furthermore, we obtain novel results\non the ability of independently learning traders to coordinate on a\npseudo-collusive behavior, leading to non-competitive pricing. Contrary to some\nrecent contributions (see e.g. [Cartea et al. 2022]), we find that the\npseudo-collusive behavior in our model is robust to a large number of agents,\ndemonstrating that even in the setting of financial markets with a large number\nof independently learning traders non-competitive pricing and pseudo-collusive\nbehavior can frequently arise.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05032v1"
    },
    {
        "title": "The Shapley index for music streaming platforms",
        "authors": [
            "Gustavo Bergantiños",
            "Juan D. Moreno-Ternero"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  We study an index to measure the popularity of artists in music streaming\nplatforms. This index, which can be used to allocate the amount raised via paid\nsubscriptions among participating artists, is based on the Shapley value, a\ncenterpiece in cooperative game theory. We characterize this Shapley index\ncombining several axioms formalizing principles with normative appeal. This\npermits to place the index in the literature, as an alternative to the\nwell-known (and widely used in the industry) pro-rata and user-centric indices.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.07166v1"
    },
    {
        "title": "Revealed Information",
        "authors": [
            "Laura Doval",
            "Ran Eilat",
            "Tianhao Liu",
            "Yangfan Zhou"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  An analyst observes the frequency with which a decision maker (DM) takes\nactions, but does not observe the frequency of actions conditional on the\npayoff-relevant state. We ask when can the analyst rationalize the DM's choices\nas if the DM first learns something about the state before taking action. We\nprovide a support function characterization of the triples of utility\nfunctions, prior beliefs, and (marginal) distributions over actions such that\nthe DM's action distribution is consistent with information given the agent's\nprior and utility function. Assumptions on the cardinality of the state space\nand the utility function allow us to refine this characterization, obtaining a\nsharp system of finitely many inequalities the utility function, prior, and\naction distribution must satisfy. We apply our characterization to study\ncomparative statics and ring-network games, and to identify conditions under\nwhich a data set is consistent with a public information structure in\nfirst-order Bayesian persuasion games. We characterize the set of distributions\nover posterior beliefs that are consistent with the DM's choices. Assuming the\nfirst-order approach applies, we extend our results to settings with a\ncontinuum of actions and/or states.%\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13293v1"
    },
    {
        "title": "Decision making in stochastic extensive form II: Stochastic extensive\n  forms and games",
        "authors": [
            "E. Emanuel Rapsch"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A general theory of stochastic extensive forms is developed to bridge two\nconcepts of information flow: decision trees and refined partitions on the one\nside, filtrations from probability theory on the other. Instead of the\ntraditional \"nature\" agent, this framework uses a single lottery draw to select\na tree of a given decision forest. Each \"personal\" agent receives dynamic\nupdates from an own oracle on the lottery outcome and makes partition-refining\nchoices adapted to this information. This theory addresses a key limitation of\nexisting approaches in extensive form theory, which struggle to model\ncontinuous-time stochastic processes, such as Brownian motion, as outcomes of\n\"nature\" decision making. Additionally, a class of stochastic extensive forms\nbased on time-indexed action paths is constructed, encompassing a wide range of\nmodels from the literature and laying the groundwork for an approximation\ntheory for stochastic differential games in extensive form.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17587v1"
    },
    {
        "title": "Characterizations of voting rules based on majority margins",
        "authors": [
            "Yifeng Ding",
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "category": "econ.TH",
        "published_year": "2025",
        "summary": "  In the context of voting with ranked ballots, an important class of voting\nrules is the class of margin-based rules (also called pairwise rules). A voting\nrule is margin-based if whenever two elections generate the same head-to-head\nmargins of victory or loss between candidates, then the voting rule yields the\nsame outcome in both elections. Although this is a mathematically natural\ninvariance property to consider, whether it should be regarded as a normative\naxiom on voting rules is less clear. In this paper, we address this question\nfor voting rules with any kind of output, whether a set of candidates, a\nranking, a probability distribution, etc. We prove that a voting rule is\nmargin-based if and only if it satisfies some axioms with clearer normative\ncontent. A key axiom is what we call Preferential Equality, stating that if two\nvoters both rank a candidate $x$ immediately above a candidate $y$, then either\nvoter switching to rank $y$ immediately above $x$ will have the same effect on\nthe election outcome as if the other voter made the switch, so each voter's\npreference for $y$ over $x$ is treated equally.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08595v1"
    },
    {
        "title": "Optimal Resource Allocation over Networks via Lottery-Based Mechanisms",
        "authors": [
            "Soham R. Phade",
            "Venkat Anantharam"
        ],
        "category": "econ.TH",
        "published_year": "2018",
        "summary": "  We show that, in a resource allocation problem, the ex ante aggregate utility\nof players with cumulative-prospect-theoretic preferences can be increased over\ndeterministic allocations by implementing lotteries. We formulate an\noptimization problem, called the system problem, to find the optimal lottery\nallocation. The system problem exhibits a two-layer structure comprised of a\npermutation profile and optimal allocations given the permutation profile. For\nany fixed permutation profile, we provide a market-based mechanism to find the\noptimal allocations and prove the existence of equilibrium prices. We show that\nthe system problem has a duality gap, in general, and that the primal problem\nis NP-hard. We then consider a relaxation of the system problem and derive some\nqualitative features of the optimal lottery structure.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.00501v1"
    },
    {
        "title": "Fair Prediction with Endogenous Behavior",
        "authors": [
            "Christopher Jung",
            "Sampath Kannan",
            "Changhwa Lee",
            "Mallesh M. Pai",
            "Aaron Roth",
            "Rakesh Vohra"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  There is increasing regulatory interest in whether machine learning\nalgorithms deployed in consequential domains (e.g. in criminal justice) treat\ndifferent demographic groups \"fairly.\" However, there are several proposed\nnotions of fairness, typically mutually incompatible. Using criminal justice as\nan example, we study a model in which society chooses an incarceration rule.\nAgents of different demographic groups differ in their outside options (e.g.\nopportunity for legal employment) and decide whether to commit crimes. We show\nthat equalizing type I and type II errors across groups is consistent with the\ngoal of minimizing the overall crime rate; other popular notions of fairness\nare not.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.07147v1"
    },
    {
        "title": "A Practical Approach to Social Learning",
        "authors": [
            "Amir Ban",
            "Moran Koren"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  Models of social learning feature either binary signals or abstract signal\nstructures often deprived of micro-foundations. Both models are limited when\nanalyzing interim results or performing empirical analysis. We present a method\nof generating signal structures which are richer than the binary model, yet are\ntractable enough to perform simulations and empirical analysis. We demonstrate\nthe method's usability by revisiting two classical papers: (1) we discuss the\neconomic significance of unbounded signals Smith and Sorensen (2000); (2) we\nuse experimental data from Anderson and Holt (1997) to perform econometric\nanalysis. Additionally, we provide a necessary and sufficient condition for the\noccurrence of action cascades.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.11017v1"
    },
    {
        "title": "Stochastic stability of agglomeration patterns in an urban retail model",
        "authors": [
            "Minoru Osawa",
            "Takashi Akamatsu",
            "Yosuke Kogure"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  We consider a model of urban spatial structure proposed by Harris and Wilson\n(Environment and Planning A, 1978). The model consists of fast dynamics, which\nrepresent spatial interactions between locations by the entropy-maximizing\nprinciple, and slow dynamics, which represent the evolution of the spatial\ndistribution of local factors that facilitate such spatial interactions. One\nknown limitation of the Harris and Wilson model is that it can have multiple\nlocally stable equilibria, leading to a dependence of predictions on the\ninitial state. To overcome this, we employ equilibrium refinement by stochastic\nstability. We build on the fact that the model is a large-population potential\ngame and that stochastically stable states in a potential game correspond to\nglobal potential maximizers. Unlike local stability under deterministic\ndynamics, the stochastic stability approach allows a unique and unambiguous\nprediction for urban spatial configurations. We show that, in the most likely\nspatial configuration, the number of retail agglomerations decreases either\nwhen shopping costs for consumers decrease or when the strength of\nagglomerative effects increases.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.06778v1"
    },
    {
        "title": "Allocating marketing resources over social networks: A long-term\n  analysis",
        "authors": [
            "Vineeth S. Varma",
            "Samson Lasaulce",
            "Julien Mounthanyvong",
            "Irinel-Constantin Morarescu"
        ],
        "category": "econ.TH",
        "published_year": "2020",
        "summary": "  In this paper, we consider a network of consumers who are under the combined\ninfluence of their neighbors and external influencing entities (the marketers).\nThe consumers' opinion follows a hybrid dynamics whose opinion jumps are due to\nthe marketing campaigns. By using the relevant static game model proposed\nrecently in [1], we prove that although the marketers are in competition and\ntherefore create tension in the network, the network reaches a consensus.\nExploiting this key result, we propose a coopetition marketing strategy which\ncombines the one-shot Nash equilibrium actions and a policy of no advertising.\nUnder reasonable sufficient conditions, it is proved that the proposed\ncoopetition strategy profile Pareto-dominates the one-shot Nash equilibrium\nstrategy. This is a very encouraging result to tackle the much more challenging\nproblem of designing Pareto-optimal and equilibrium strategies for the\nconsidered dynamical marketing game.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.09268v1"
    },
    {
        "title": "Rational social distancing policy during epidemics with limited\n  healthcare capacity",
        "authors": [
            "Simon K. Schnyder",
            "John J. Molina",
            "Ryoichi Yamamoto",
            "Matthew S. Turner"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Epidemics of infectious diseases posing a serious risk to human health have\noccurred throughout history. During recent epidemics there has been much debate\nabout policy, including how and when to impose restrictions on behaviour.\nPolicymakers must balance a complex spectrum of objectives, suggesting a need\nfor quantitative tools. Whether health services might be `overwhelmed' has\nemerged as a key consideration. Here we show how costly interventions, such as\ntaxes or subsidies on behaviour, can be used to exactly align individuals'\ndecision making with government preferences even when these are not aligned. In\norder to achieve this, we develop a nested optimisation algorithm of both the\ngovernment intervention strategy and the resulting equilibrium behaviour of\nindividuals. We focus on a situation in which the capacity of the healthcare\nsystem to treat patients is limited and identify conditions under which the\ndisease dynamics respect the capacity limit. We find an extremely sharp drop in\npeak infections at a critical maximum infection cost in the government's\nobjective function. This is in marked contrast to the gradual reduction of\ninfections if individuals make decisions without government intervention. We\nfind optimal interventions vary less strongly in time when interventions are\ncostly to the government and that the critical cost of the policy switch\ndepends on how costly interventions are.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00684v2"
    },
    {
        "title": "A self-contained karma economy for the dynamic allocation of common\n  resources",
        "authors": [
            "Ezzat Elokda",
            "Saverio Bolognani",
            "Andrea Censi",
            "Florian Dörfler",
            "Emilio Frazzoli"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  This paper presents karma mechanisms, a novel approach to the repeated\nallocation of a scarce resource among competing agents over an infinite time.\nExamples include deciding which ride hailing trip requests to serve during peak\ndemand, granting the right of way in intersections or lane mergers, or\nadmitting internet content to a regulated fast channel. We study a simplified\nyet insightful formulation of these problems where at every instant two agents\nfrom a large population get randomly matched to compete over the resource. The\nintuitive interpretation of a karma mechanism is \"If I give in now, I will be\nrewarded in the future.\" Agents compete in an auction-like setting where they\nbid units of karma, which circulates directly among them and is self-contained\nin the system. We demonstrate that this allows a society of self-interested\nagents to achieve high levels of efficiency without resorting to a (possibly\nproblematic) monetary pricing of the resource. We model karma mechanisms as\ndynamic population games and guarantee the existence of a stationary Nash\nequilibrium. We then analyze the performance at the stationary Nash equilibrium\nnumerically. For the case of homogeneous agents, we compare different mechanism\ndesign choices, showing that it is possible to achieve an efficient and ex-post\nfair allocation when the agents are future aware. Finally, we test the\nrobustness against agent heterogeneity and propose remedies to some of the\nobserved phenomena via karma redistribution.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00495v3"
    },
    {
        "title": "Stochastic Equilibrium the Lucas Critique and Keynesian Economics",
        "authors": [
            "David Staines"
        ],
        "category": "econ.TH",
        "published_year": "2023",
        "summary": "  In this paper, a mathematically rigorous solution overturns existing wisdom\nregarding New Keynesian Dynamic Stochastic General Equilibrium. I develop a\nformal concept of stochastic equilibrium. I prove uniqueness and necessity,\nwhen agents are patient, with general application. Existence depends on\nappropriately specified eigenvalue conditions. Otherwise, no solution of any\nkind exists. I construct the equilibrium with Calvo pricing. I provide novel\ncomparative statics with the non-stochastic model of mathematical significance.\nI uncover a bifurcation between neighbouring stochastic systems and\napproximations taken from the Zero Inflation Non-Stochastic Steady State\n(ZINSS). The correct Phillips curve agrees with the zero limit from the trend\ninflation framework. It contains a large lagged inflation coefficient and a\nsmall response to expected inflation. Price dispersion can be first or second\norder depending how shocks are scaled. The response to the output gap is always\nmuted and is zero at standard parameters. A neutrality result is presented to\nexplain why and align Calvo with Taylor pricing. Present and lagged demand\nshocks enter the Phillips curve so there is no Divine Coincidence and the\nsystem is identified from structural shocks alone. The lagged inflation slope\nis increasing in the inflation response, embodying substantive policy\ntrade-offs. The Taylor principle is reversed, inactive settings are necessary,\npointing towards inertial policy. The observational equivalence idea of the\nLucas critique is disproven. The bifurcation results from the breakdown of the\nconstraints implied by lagged nominal rigidity, associated with cross-equation\ncancellation possible only at ZINSS. There is a dual relationship between\nrestrictions on the econometrician and constraints on repricing firms. Thus, if\nthe model is correct, goodness of fit will jump.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.16214v4"
    },
    {
        "title": "Persuasion, Delegation, and Private Information in Algorithm-Assisted\n  Decisions",
        "authors": [
            "Ruqing Xu"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  A principal designs an algorithm that generates a publicly observable\nprediction of a binary state. She must decide whether to act directly based on\nthe prediction or to delegate the decision to an agent with private information\nbut potential misalignment. We study the optimal design of the prediction\nalgorithm and the delegation rule in such environments. Three key findings\nemerge: (1) Delegation is optimal if and only if the principal would make the\nsame binary decision as the agent had she observed the agent's information. (2)\nProviding the most informative algorithm may be suboptimal even if the\nprincipal can act on the algorithm's prediction. Instead, the optimal algorithm\nmay provide more information about one state and restrict information about the\nother. (3) Well-intentioned policies aiming to provide more information, such\nas keeping a \"human-in-the-loop\" or requiring maximal prediction accuracy,\ncould strictly worsen decision quality compared to systems with no human or no\nalgorithmic assistance. These findings predict the underperformance of\nhuman-machine collaborations if no measures are taken to mitigate common\npreference misalignment between algorithms and human decision-makers.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09384v2"
    },
    {
        "title": "Prediction-sharing During Training and Inference",
        "authors": [
            "Yotam Gafni",
            "Ronen Gradwohl",
            "Moshe Tennenholtz"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Two firms are engaged in a competitive prediction task. Each firm has two\nsources of data -- labeled historical data and unlabeled inference-time data --\nand uses the former to derive a prediction model, and the latter to make\npredictions on new instances. We study data-sharing contracts between the\nfirms. The novelty of our study is to introduce and highlight the differences\nbetween contracts that share prediction models only, contracts to share\ninference-time predictions only, and contracts to share both. Our analysis\nproceeds on three levels. First, we develop a general Bayesian framework that\nfacilitates our study. Second, we narrow our focus to two natural settings\nwithin this framework: (i) a setting in which the accuracy of each firm's\nprediction model is common knowledge, but the correlation between the\nrespective models is unknown; and (ii) a setting in which two hypotheses exist\nregarding the optimal predictor, and one of the firms has a structural\nadvantage in deducing it. Within these two settings we study optimal contract\nchoice. More specifically, we find the individually rational and Pareto-optimal\ncontracts for some notable cases, and describe specific settings where each of\nthe different sharing contracts emerge as optimal. Finally, in the third level\nof our analysis we demonstrate the applicability of our concepts in a synthetic\nsimulation using real loan data.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.17515v1"
    },
    {
        "title": "Nash epidemics",
        "authors": [
            "Simon K. Schnyder",
            "John J. Molina",
            "Ryoichi Yamamoto",
            "Matthew S. Turner"
        ],
        "category": "econ.TH",
        "published_year": "2024",
        "summary": "  Faced with a dangerous epidemic humans will spontaneously social distance to\nreduce their risk of infection at a socio-economic cost. Compartmentalised\nepidemic models have been extended to include this endogenous decision making:\nIndividuals choose their behaviour to optimise a utility function,\nself-consistently giving rise to population behaviour. Here we study the\nproperties of the resulting Nash equilibria, in which no member of the\npopulation can gain an advantage by unilaterally adopting different behaviour.\nWe leverage a new analytic solution to obtain, (1) a simple relationship\nbetween rational social distancing behaviour and the current number of\ninfections; (2) new scaling results for how the infection peak and number of\ntotal cases depend on the cost of contracting the disease; (3) characteristic\ninfection costs that divide regimes of strong and weak behavioural response and\ndepend only on the basic reproduction number of the disease; (4) a closed form\nexpression for the value of the utility. We discuss how these analytic results\nprovide a deep and intuitive understanding into the disease dynamics, useful\nfor both individuals and policymakers. In particular the relationship between\nsocial distancing and infections represents a heuristic that could be\ncommunicated to the population to encourage, or \"bootstrap\", rational\nbehaviour.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.04366v1"
    },
    {
        "title": "Rational Pricing of Leveraged ETF Expense Ratios",
        "authors": [
            "Alex Garivaltis"
        ],
        "category": "econ.TH",
        "published_year": "2021",
        "summary": "  This paper studies the general relationship between the gearing ratio of a\nLeveraged ETF and its corresponding expense ratio, viz., the investment\nmanagement fees that are charged for the provision of this levered financial\nservice. It must not be possible for an investor to combine two or more LETFs\nin such a way that his (continuously-rebalanced) LETF portfolio can match the\ngearing ratio of a given, professionally managed product and, at the same time,\nenjoy lower weighted-average expenses than the existing LETF. Given a finite\nset of LETFs that exist in the marketplace, I give necessary and sufficient\nconditions for these products to be undominated in the price-gearing plane. In\na beautiful application of the duality theorem of linear programming, I prove a\nkind of two-fund theorem for LETFs: given a target gearing ratio for the\ninvestor, the cheapest way to achieve it is to combine (uniquely) the two\nnearest undominated LETF products that bracket it on the leverage axis. This\nalso happens to be the implementation that has the lowest annual turnover. For\nthe writer's enjoyment, we supply a second proof of the Main Theorem on LETFs\nthat is based on Carath\\'eodory's theorem in convex geometry. Thus, say, a\ntriple-leveraged (\"UltraPro\") exchange-traded product should never be mixed\nwith cash, if the investor is able to trade in the underlying index. In terms\nof financial innovation, our two-fund theorem for LETFs implies that the\nintroduction of new, undominated 2.5x products would increase the welfare of\nall investors whose preferred gearing ratios lie between 2x (\"Ultra\") and 3x\n(\"UltraPro\"). Similarly for a 1.5x product.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.14820v2"
    },
    {
        "title": "Smooth Calibration, Leaky Forecasts, Finite Recall, and Nash Dynamics",
        "authors": [
            "Dean P. Foster",
            "Sergiu Hart"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  We propose to smooth out the calibration score, which measures how good a\nforecaster is, by combining nearby forecasts. While regular calibration can be\nguaranteed only by randomized forecasting procedures, we show that smooth\ncalibration can be guaranteed by deterministic procedures. As a consequence, it\ndoes not matter if the forecasts are leaked, i.e., made known in advance:\nsmooth calibration can nevertheless be guaranteed (while regular calibration\ncannot). Moreover, our procedure has finite recall, is stationary, and all\nforecasts lie on a finite grid. To construct the procedure, we deal also with\nthe related setups of online linear regression and weak calibration. Finally,\nwe show that smooth calibration yields uncoupled finite-memory dynamics in\nn-person games \"smooth calibrated learning\" in which the players play\napproximate Nash equilibria in almost all periods (by contrast, calibrated\nlearning, which uses regular calibration, yields only that the time-averages of\nplay are approximate correlated equilibria).\n",
        "pdf_link": "http://arxiv.org/pdf/2210.07152v1"
    },
    {
        "title": "Forecast Hedging and Calibration",
        "authors": [
            "Dean P. Foster",
            "Sergiu Hart"
        ],
        "category": "econ.TH",
        "published_year": "2022",
        "summary": "  Calibration means that forecasts and average realized frequencies are close.\nWe develop the concept of forecast hedging, which consists of choosing the\nforecasts so as to guarantee that the expected track record can only improve.\nThis yields all the calibration results by the same simple basic argument while\ndifferentiating between them by the forecast-hedging tools used: deterministic\nand fixed point based versus stochastic and minimax based. Additional\ncontributions are an improved definition of continuous calibration, ensuing\ngame dynamics that yield Nash equilibria in the long run, and a new calibrated\nforecasting procedure for binary events that is simpler than all known such\nprocedures.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.07169v1"
    }
]