[
    {
        "title": "On three filtering problems arising in mathematical finance",
        "authors": [
            "Damiano Brigo",
            "Bernard Hanzon"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  Three situations in which filtering theory is used in mathematical finance\nare illustrated at different levels of detail. The three problems originate\nfrom the following different works: 1) On estimating the stochastic volatility\nmodel from observed bilateral exchange rate news, by R. Mahieu, and P.\nSchotman; 2) A state space approach to estimate multi-factors CIR models of the\nterm structure of interest rates, by A.L.J. Geyer, and S. Pichler; 3)\nRisk-minimizing hedging strategies under partial observation in pricing\nfinancial derivatives, by P. Fischer, E. Platen, and W. J. Runggaldier; In the\nfirst problem we propose to use a recent nonlinear filtering technique based on\ngeometry to estimate the volatility time series from observed bilateral\nexchange rates. The model used here is the stochastic volatility model. The\nfilters that we propose are known as projection filters, and a brief derivation\nof such filters is given. The second problem is introduced in detail, and a\npossible use of different filtering techniques is hinted at. In fact the\nfilters used for this problem in 2) and part of the literature can be\ninterpreted as projection filters and we will make some remarks on how more\ngeneral and possibly more suitable projection filters can be constructed. The\nthird problem is only presented shortly.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.4050v1"
    },
    {
        "title": "A method of moments approach to pricing double barrier contracts driven\n  by a general class of jump diffusions",
        "authors": [
            "Bjorn Eriksson",
            "Martijn Pistorius"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  We present the method of moments approach to pricing barrier-type options\nwhen the underlying is modelled by a general class of jump diffusions. By\ngeneral principles the option prices are linked to certain infinite dimensional\nlinear programming problems. Subsequently approximating those systems by finite\ndimensional linear programming problems, upper and lower bounds for the prices\nof such options are found. As numerical illustration we apply the method to the\nvaluation of several barrier-type options (double barrier knockout option,\nAmerican corridor and double no touch) under a number of different models,\nincluding a case with deterministic interest rates, and compare with Monte\nCarlo simulation results. In all cases we find tight bounds with short\nexecution times. Theoretical convergence results are also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.4548v1"
    },
    {
        "title": "Optimal systems of subalgebras for a nonlinear Black-Scholes equation",
        "authors": [
            "Maxim Bobrov"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  The main object of our study is a four dimensional Lie algebra which\ndescribes the symmetry properties of a nonlinear Black-Scholes model. This\nmodel implements a feedback effect which is typical for an illiquid market. The\nstructure of the Lie algebra depends on one parameter, i.e. we have to do with\na one-parametric family of algebras. We provide a classification of these\nalgebras using Patera--Winternitz method. Optimal systems of one-, two- and\nthree- dimensional subalgebras are described for the family of symmetry\nalgebras of the nonlinear Black-Scholes equation. The optimal systems give us\nthe possibility to describe a complete set of invariant solutions to the\nequation.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.2826v1"
    },
    {
        "title": "Bayesian inference with an adaptive proposal density for GARCH models",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We perform the Bayesian inference of a GARCH model by the Metropolis-Hastings\nalgorithm with an adaptive proposal density. The adaptive proposal density is\nassumed to be the Student's t-distribution and the distribution parameters are\nevaluated by using the data sampled during the simulation. We apply the method\nfor the QGARCH model which is one of asymmetric GARCH models and make empirical\nstudies for for Nikkei 225, DAX and Hang indexes. We find that autocorrelation\ntimes from our method are very small, thus the method is very efficient for\ngenerating uncorrelated Monte Carlo data. The results from the QGARCH model\nshow that all the three indexes show the leverage effect, i.e. the volatility\nis high after negative observations.\n",
        "pdf_link": "http://arxiv.org/pdf/0908.2982v1"
    },
    {
        "title": "Markov Chain Monte Carlo on Asymmetric GARCH Model Using the Adaptive\n  Construction Scheme",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We perform Markov chain Monte Carlo simulations for a Bayesian inference of\nthe GJR-GARCH model which is one of asymmetric GARCH models. The adaptive\nconstruction scheme is used for the construction of the proposal density in the\nMetropolis-Hastings algorithm and the parameters of the proposal density are\ndetermined adaptively by using the data sampled by the Markov chain Monte Carlo\nsimulation. We study the performance of the scheme with the artificial\nGJR-GARCH data. We find that the adaptive construction scheme samples GJR-GARCH\nparameters effectively and conclude that the Metropolis-Hastings algorithm with\nthe adaptive construction scheme is an efficient method to the Bayesian\ninference of the GJR-GARCH model.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.1478v1"
    },
    {
        "title": "Defaultable bonds with an infinite number of Levy factors",
        "authors": [
            "Jacek Jakubowski",
            "Mariusz Nieweglowski"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  A market with defaultable bonds where the bond dynamics is in a\nHeath-Jarrow-Morton setting and the forward rates are driven by an infinite\nnumber of Levy factors is considered. The setting includes rating migrations\ndriven by a Markov chain. All basic types of recovery are investigated. We\nformulate necessary and sufficient conditions (generalized HJM conditions)\nunder which the market is arbitrage free. Connections with consistency\nconditions are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.4089v1"
    },
    {
        "title": "On the Performance of Delta Hedging Strategies in Exponential Lévy\n  Models",
        "authors": [
            "Stephan Denkl",
            "Martina Goy",
            "Jan Kallsen",
            "Johannes Muhle-Karbe",
            "Arnd Pauwels"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We consider the performance of non-optimal hedging strategies in exponential\nL\\'evy models. Given that both the payoff of the contingent claim and the\nhedging strategy admit suitable integral representations, we use the Laplace\ntransform approach of Hubalek et al. (2006) to derive semi-explicit formulas\nfor the resulting mean squared hedging error in terms of the cumulant\ngenerating function of the underlying L\\'evy process. In two numerical\nexamples, we apply these results to compare the efficiency of the Black-Scholes\nhedge and the model delta to the mean-variance optimal hedge in a normal\ninverse Gaussian and a diffusion-extended CGMY L\\'evy model.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.4859v3"
    },
    {
        "title": "Appraisal of a contour integral method for the Black-Scholes and Heston\n  equations",
        "authors": [
            "K. J. in 't Hout",
            "J. A. C. Weideman"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  A contour integral method recently proposed by Weideman [IMA J. Numer. Anal.,\nto appear] for integrating semi-discrete advection-diffusion PDEs, is extended\nfor application to some of the important equations of mathematical finance.\nUsing estimates for the numerical range of the spatial operator, optimal\ncontour parameters are derived theoretically and tested numerically. Test\nexamples presented are the Black-Scholes PDE in one space dimension and the\nHeston PDE in two dimensions. In the latter case efficiency is compared to ADI\nsplitting schemes for solving this problem. In the examples it is found that\nthe contour integral method is superior for the range of medium to high\naccuracy requirements. Further improvements to the current implementation of\nthe contour integral method are suggested.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.0434v2"
    },
    {
        "title": "Simulation de trajectoires de processus continus",
        "authors": [
            "Frédéric Planchet",
            "Pierre-Emanuel Thérond"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Continuous time stochastic processes are useful models especially for\nfinancial and insurance purposes. The numerical simulation of such models is\ndependant of the time discrete discretization, of the parametric estimation and\nof the choice of a random number generator. The aim of this paper is to provide\nthe tools for the practical implementation of diffusion processes simulation,\nparticularly for insurance contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.1909v1"
    },
    {
        "title": "Sequential optimizing investing strategy with neural networks",
        "authors": [
            "Ryo Adachi",
            "Akimichi Takemura"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In this paper we propose an investing strategy based on neural network models\ncombined with ideas from game-theoretic probability of Shafer and Vovk. Our\nproposed strategy uses parameter values of a neural network with the best\nperformance until the previous round (trading day) for deciding the investment\nin the current round. We compare performance of our proposed strategy with\nvarious strategies including a strategy based on supervised neural network\nmodels and show that our procedure is competitive with other strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.2265v1"
    },
    {
        "title": "Basket Options Valuation for a Local Volatility Jump-Diffusion Model\n  with the Asymptotic Expansion Method",
        "authors": [
            "Guoping Xu",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In this paper we discuss the basket options valuation for a jump-diffusion\nmodel. The underlying asset prices follow some correlated local volatility\ndiffusion processes with systematic jumps. We derive a forward partial integral\ndifferential equation (PIDE) for general stochastic processes and use the\nasymptotic expansion method to approximate the conditional expectation of the\nstochastic variance associated with the basket value process. The numerical\ntests show that the suggested method is fast and accurate in comparison with\nthe Monte Carlo and other methods in most cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1848v1"
    },
    {
        "title": "Computational LPPL Fit to Financial Bubbles",
        "authors": [
            "Vincenzo Liberatore"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The log-periodic power law (LPPL) is a model of asset prices during\nendogenous bubbles. If the on-going development of a bubble is suspected, asset\nprices can be fit numerically to the LPPL law. The best solutions can then\nindicate whether a bubble is in progress and, if so, the bubble critical time\n(i.e., when the bubble is expected to burst). Consequently, the LPPL model is\nuseful only if the data can be fit to the model with algorithms that are\naccurate and computationally efficient. In this paper, we address primarily the\ncomputational efficiency and secondarily the precision of the LPPL non-linear\nleast-square fit. Specifically, we present a parallel Levenberg-Marquardt\nalgorithm (LMA) for LPPL least-square fit that sped up computation of more than\na factor of four over a sequential LMA on historical and synthetic price\nseries. Additionally, we isolate a linear sub-structure of the LPPL\nleast-square fit that can be paired with an exact computation of the Jacobian,\ngive new settings for the Levenberg-Marquardt damping factor, and describe a\nheuristic method to choose initial solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.2920v2"
    },
    {
        "title": "Indifference of Defaultable Bonds with Stochastic Intensity models",
        "authors": [
            "Regis Houssou",
            "Olivier Besson"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The utility-based pricing of defaultable bonds in the case of stochastic\nintensity models of default risk is discussed. The Hamilton-Jacobi- Bellman\n(HJB) equations for the value functions is derived. A finite difference method\nis used to solve this problem. The yield-spreads for both buyer and seller are\nextracted. The behaviour of the spread curve given the default intensity is\nanalyzed. Finally the impacts of the risk aversion and the correlation\ncoefficient are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.4118v1"
    },
    {
        "title": "Dynamics on/in financial markets: dynamical decoupling and stylized\n  facts",
        "authors": [
            "Stefan Reimann",
            "Andreas Tupak"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Stylized facts can be regarded as constraints for any modeling attempt of\nprice dynamics on a financial market, in that an empirically reasonable model\nhas to reproduce these stylized facts at least qualitatively. The dynamics of\nmarket prices is modeled on a macro-level as the result of the dynamic coupling\nof two dynamical components. The degree of their dynamical decoupling is shown\nto have a significant impact on the stochastic properties of return trials such\nas the return distribution, volatility clustering, and the multifractal\nbehavior of time scales of asset returns. Particularly we observe a cross over\nin the return distribution from a Gaussian-like to a Levy-like shape when the\ndegree of decoupling increases. In parallel, the larger the degree of\ndecoupling is the more pronounced is volatility clustering. These findings\nsuggest that the considerations of time in an economic system, in general, and\nthe coupling of constituting processes is essential for understanding the\nbehavior of a financial market.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1522v1"
    },
    {
        "title": "Fast Correlation Greeks by Adjoint Algorithmic Differentiation",
        "authors": [
            "Luca Capriotti",
            "Mike Giles"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We show how Adjoint Algorithmic Differentiation (AAD) allows an extremely\nefficient calculation of correlation Risk of option prices computed with Monte\nCarlo simulations. A key point in the construction is the use of binning to\nsimultaneously achieve computational efficiency and accurate confidence\nintervals. We illustrate the method for a copula-based Monte Carlo computation\nof claims written on a basket of underlying assets, and we test it numerically\nfor Portfolio Default Options. For any number of underlying assets or names in\na portfolio, the sensitivities of the option price with respect to all the\npairwise correlations is obtained at a computational cost which is at most 4\ntimes the cost of calculating the option value itself. For typical\napplications, this results in computational savings of several order of\nmagnitudes with respect to standard methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1855v1"
    },
    {
        "title": "Smooth Value Functions for a Class of Nonsmooth Utility Maximization\n  Problems",
        "authors": [
            "Baojun Bian",
            "Sheng Miao",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In this paper we prove that there exists a smooth classical solution to the\nHJB equation for a large class of constrained problems with utility functions\nthat are not necessarily differentiable or strictly concave. The value function\nis smooth if admissible controls satisfy an integrability condition or if it is\ncontinuous on the closure of its domain. The key idea is to work on the dual\ncontrol problem and the dual HJB equation. We construct a smooth, strictly\nconvex solution to the dual HJB equation and show that its conjugate function\nis a smooth, strictly concave solution to the primal HJB equation satisfying\nthe terminal and boundary conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.3956v1"
    },
    {
        "title": "Analysis of the sensitivity to discrete dividends : A new approach for\n  pricing vanillas",
        "authors": [
            "Arnaud Gocsei",
            "Fouad Sahel"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The incorporation of a dividend yield in the classical option pricing model\nof Black- Scholes results in a minor modification of the Black-Scholes formula,\nsince the lognormal dynamic of the underlying asset is preserved. However,\nmarket makers prefer to work with cash dividends with fixed value instead of a\ndividend yield. Since there is no closed-form solution for the price of a\nEuropean Call in this case, many methods have been proposed in the literature\nto approximate it. Here, we present a new approach. We derive an exact analytic\nformula for the sensitivity to dividends of an European option. We use this\nresult to elaborate a proxy which possesses the same Taylor expansion around 0\nwith respect to the dividends as the exact price. The obtained approximation is\nvery fast to compute (the same complexity than the usual Black-Scholes formula)\nand numerical tests show the extreme accuracy of the method for all practical\ncases.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.3880v1"
    },
    {
        "title": "Numerical methods for optimal insurance demand under marked point\n  processes shocks",
        "authors": [
            "Mohamed Mnif"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  This paper deals with numerical solutions of maximizing expected utility from\nterminal wealth under a non-bankruptcy constraint. The wealth process is\nsubject to shocks produced by a general marked point process. The problem of\nthe agent is to derive the optimal insurance strategy which allows \"lowering\"\nthe level of the shocks. This optimization problem is related to a suitable\ndual stochastic control problem in which the delicate boundary constraints\ndisappear. In Mnif \\cite{mnif10}, the dual value function is characterized as\nthe unique viscosity solution of the corresponding Hamilton Jacobi Bellman\nVariational Inequality (HJBVI in short). We characterize the optimal insurance\nstrategy by the solution of the variational inequality which we solve\nnumerically by using an algorithm based on policy iterations.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.0635v1"
    },
    {
        "title": "Constrained NonSmooth Utility Maximization on the Positive Real Line",
        "authors": [
            "Nicholas Westray",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We maximize the expected utility of terminal wealth in an incomplete market\nwhere there are cone constraints on the investor's portfolio process and the\nutility function is not assumed to be strictly concave or differentiable. We\nestablish the existence of the optimal solutions to the primal and dual\nproblems and their dual relationship. We simplify the present proofs in this\narea and extend the existing duality theory to the constrained nonsmooth\nsetting.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.4055v1"
    },
    {
        "title": "Stability of central finite difference schemes for the Heston PDE",
        "authors": [
            "K. J. in 't Hout",
            "K. Volders"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  This paper deals with stability in the numerical solution of the prominent\nHeston partial differential equation from mathematical finance. We study the\nwell-known central second-order finite difference discretization, which leads\nto large semi-discrete systems with non-normal matrices A. By employing the\nlogarithmic spectral norm we prove practical, rigorous stability bounds. Our\ntheoretical stability results are illustrated by ample numerical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.6532v1"
    },
    {
        "title": "Swing Options Valuation: a BSDE with Constrained Jumps Approach",
        "authors": [
            "Marie Bernhart",
            "Huyên Pham",
            "Peter Tankov",
            "Xavier Warin"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We introduce a new probabilistic method for solving a class of impulse\ncontrol problems based on their representations as Backward Stochastic\nDifferential Equations (BSDEs for short) with constrained jumps. As an example,\nour method is used for pricing Swing options. We deal with the jump constraint\nby a penalization procedure and apply a discrete-time backward scheme to the\nresulting penalized BSDE with jumps. We study the convergence of this numerical\nmethod, with respect to the main approximation parameters: the jump intensity\n$\\lambda$, the penalization parameter $p > 0$ and the time step. In particular,\nwe obtain a convergence rate of the error due to penalization of order\n$(\\lambda p)^{\\alpha - \\frac{1}{2}}, \\forall \\alpha \\in \\left(0,\n\\frac{1}{2}\\right)$. Combining this approach with Monte Carlo techniques, we\nthen work out the valuation problem of (normalized) Swing options in the Black\nand Scholes framework. We present numerical tests and compare our results with\na classical iteration method.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.0975v1"
    },
    {
        "title": "The computation of Greeks with multilevel Monte Carlo",
        "authors": [
            "Sylvestre Burgos",
            "M. B. Giles"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We study the use of the multilevel Monte Carlo technique in the context of\nthe calculation of Greeks. The pathwise sensitivity analysis differentiates the\npath evolution and reduces the payoff's smoothness. This leads to new\nchallenges: the inapplicability of pathwise sensitivities to non-Lipschitz\npayoffs often makes the use of naive algorithms impossible. These challenges\ncan be addressed in three different ways: payoff smoothing using conditional\nexpectations of the payoff before maturity; approximating the previous\ntechnique with path splitting for the final timestep; using of a hybrid\ncombination of pathwise sensitivity and the Likelihood Ratio Method. We\ninvestigate the strengths and weaknesses of these alternatives in different\nmultilevel Monte Carlo settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.1348v1"
    },
    {
        "title": "Bayesian Model Choice of Grouped t-copula",
        "authors": [
            "Xiaolin Luo",
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  One of the most popular copulas for modeling dependence structures is\nt-copula. Recently the grouped t-copula was generalized to allow each group to\nhave one member only, so that a priori grouping is not required and the\ndependence modeling is more flexible. This paper describes a Markov chain Monte\nCarlo (MCMC) method under the Bayesian inference framework for estimating and\nchoosing t-copula models. Using historical data of foreign exchange (FX) rates\nas a case study, we found that Bayesian model choice criteria overwhelmingly\nfavor the generalized t-copula. In addition, all the criteria also agree on the\nsecond most likely model and these inferences are all consistent with classical\nlikelihood ratio tests. Finally, we demonstrate the impact of model choice on\nthe conditional Value-at-Risk for portfolios of six major FX rates.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.0606v1"
    },
    {
        "title": "Defaultable Bonds via HKA",
        "authors": [
            "Yuta Inoue",
            "Takahiro Tsuchiya"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  To construct a no-arbitrage defaultable bond market, we work on the state\nprice density framework. Using the heat kernel approach (HKA for short) with\nthe killing of a Markov process, we construct a single defaultable bond market\nthat enables an explicit expression of a defaultable bond and credit spread\nunder quadratic Gaussian settings. Some simulation results show that the model\nis not only tractable but realistic.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.4541v1"
    },
    {
        "title": "Exact Simulation of the 3/2 Model",
        "authors": [
            "Jan Baldeaux"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  This paper discusses the exact simulation of the stock price process\nunderlying the 3/2 model. Using a result derived by Craddock and Lennox using\nLie Symmetry Analysis, we adapt the Broadie-Kaya algorithm for the simulation\nof affine processes to the 3/2 model. We also discuss variance reduction\ntechniques and find that conditional Monte Carlo techniques combined with\nquasi-Monte Carlo point sets result in significant variance reductions.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.3297v2"
    },
    {
        "title": "Analytic results and weighted Monte Carlo simulations for CDO pricing",
        "authors": [
            "Marcell Stippinger",
            "Bálint Vető",
            "Éva Rácz",
            "Zsolt Bihary"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We explore the possibilities of importance sampling in the Monte Carlo\npricing of a structured credit derivative referred to as Collateralized Debt\nObligation (CDO). Modeling a CDO contract is challenging, since it depends on a\npool of (typically about 100) assets, Monte Carlo simulations are often the\nonly feasible approach to pricing. Variance reduction techniques are therefore\nof great importance. This paper presents an exact analytic solution using\nLaplace-transform and MC importance sampling results for an easily tractable\nintensity-based model of the CDO, namely the compound Poissonian. Furthermore\nanalytic formulae are derived for the reweighting efficiency. The computational\ngain is appealing, nevertheless, even in this basic scheme, a phase transition\ncan be found, rendering some parameter regimes out of reach. A\nmodel-independent transform approach is also presented for CDO pricing.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.5416v1"
    },
    {
        "title": "Comparison of Two Numerical Methods for Computation of American Type of\n  the Floating Strike Asian Option",
        "authors": [
            "J. D. Kandilarov",
            "D. Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We present a numerical approach for solving the free boundary problem for the\nBlack-Scholes equation for pricing American style of floating strike Asian\noptions. A fixed domain transformation of the free boundary problem into a\nparabolic equation defined on a fixed spatial domain is performed. As a result\na nonlinear time-dependent term is involved in the resulting equation. Two new\nnumerical algorithms are proposed. In the first algorithm a predictor-corrector\nscheme is used. The second one is based on the Newton method. Computational\nexperiments, confirming the accuracy of the algorithms are presented and\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.0020v1"
    },
    {
        "title": "Pricing of average strike Asian call option using numerical PDE methods",
        "authors": [
            "Abhishek Kumar",
            "Ashwin Waikos",
            "Siddhartha P. Chakrabarty"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper, a standard PDE for the pricing of arithmetic average strike\nAsian call option is presented. A Crank-Nicolson Implicit Method and a Higher\nOrder Compact finite difference scheme for this pricing problem is derived.\nBoth these schemes were implemented for various values of risk free rate and\nvolatility. The option prices for the same set of values of risk free rate and\nvolatility was also computed using Monte Carlo simulation. The comparative\nresults of the two numerical PDE methods shows close match with the Monte Carlo\nresults, with the Higher Order Compact scheme exhibiting a better match. To the\nbest of our knowledge, this is the first work to use the numerical PDE approach\nfor pricing Asian call options with average strike.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.1999v1"
    },
    {
        "title": "Duality and Convergence for Binomial Markets with Friction",
        "authors": [
            "Yan Dolinsky",
            "Halil Mete Soner"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We prove limit theorems for the super-replication cost of European options in\na Binomial model with friction. The examples covered are markets with\nproportional transaction costs and the illiquid markets. The dual\nrepresentation for the super-replication cost in these models are obtained and\nused to prove the limit theorems. In particular, the existence of the liquidity\npremium for the continuous time limit of the model proposed in [6] is proved.\nHence, this paper extends the previous convergence result of [13] to the\ngeneral non-Markovian case. Moreover, the special case of small transaction\ncosts yields, in the continuous limit, the $G$-expectation of Peng as earlier\nproved by Kusuoka in [14].\n",
        "pdf_link": "http://arxiv.org/pdf/1106.2095v1"
    },
    {
        "title": "Multilevel Monte Carlo method for jump-diffusion SDEs",
        "authors": [
            "Yuan Xia"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We investigate the extension of the multilevel Monte Carlo path simulation\nmethod to jump-diffusion SDEs. We consider models with finite rate activity,\nusing a jump-adapted discretisation in which the jump times are computed and\nadded to the standard uniform dis- cretisation times. The key component in\nmultilevel analysis is the calculation of an expected payoff difference between\na coarse path simulation and a fine path simulation with twice as many\ntimesteps. If the Poisson jump rate is constant, the jump times are the same on\nboth paths and the multilevel extension is relatively straightforward, but the\nimplementation is more complex in the case of state-dependent jump rates for\nwhich the jump times naturally differ.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.4730v1"
    },
    {
        "title": "Multiplicative noise, fast convolution, and pricing",
        "authors": [
            "Giacomo Bormetti",
            "Sofia Cazzaniga"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this work we detail the application of a fast convolution algorithm\ncomputing high dimensional integrals to the context of multiplicative noise\nstochastic processes. The algorithm provides a numerical solution to the\nproblem of characterizing conditional probability density functions at\narbitrary time, and we applied it successfully to quadratic and piecewise\nlinear diffusion processes. The ability in reproducing statistical features of\nfinancial return time series, such as thickness of the tails and scaling\nproperties, makes this processes appealing for option pricing. Since exact\nanalytical results are missing, we exploit the fast convolution as a numerical\nmethod alternative to the Monte Carlo simulation both in objective and risk\nneutral settings. In numerical sections we document how fast convolution\noutperforms Monte Carlo both in velocity and efficiency terms.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.1451v1"
    },
    {
        "title": "Adjoints and Automatic (Algorithmic) Differentiation in Computational\n  Finance",
        "authors": [
            "Cristian Homescu"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Two of the most important areas in computational finance: Greeks and,\nrespectively, calibration, are based on efficient and accurate computation of a\nlarge number of sensitivities. This paper gives an overview of adjoint and\nautomatic differentiation (AD), also known as algorithmic differentiation,\ntechniques to calculate these sensitivities. When compared to finite difference\napproximation, this approach can potentially reduce the computational cost by\nseveral orders of magnitude, with sensitivities accurate up to machine\nprecision. Examples and a literature survey are also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.1831v1"
    },
    {
        "title": "Fast resolution of a single factor Heath-Jarrow-Morton model with\n  stochastic volatility",
        "authors": [
            "Eusebio Valero",
            "Manuel Torrealba",
            "Lucas Lacasa",
            "François Fraysse"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  This paper considers the single factor Heath-Jarrow-Morton model for the\ninterest rate curve with stochastic volatility. Its natural formulation,\ndescribed in terms of stochastic differential equations, is solved through\nMonte Carlo simulations, that usually involve rather large computation time,\ninefficient from a practical (financial) perspective. This model turns to be\nMarkovian in three dimensions and therefore it can be mapped into a 3D partial\ndifferential equations problem. We propose an optimized numerical method to\nsolve the 3D PDE model in both low computation time and reasonable accuracy, a\nfundamental criterion for practical purposes. The spatial and temporal\ndiscretization are performed using finite-difference and Crank-Nicholson\nschemes respectively, and the computational efficiency is largely increased\nperforming a scale analysis and using Alternating Direction Implicit schemes.\nSeveral numerical considerations such as convergence criteria or computation\ntime are analyzed and discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.1688v1"
    },
    {
        "title": "Arbitrage-free Self-organizing Markets with GARCH Properties: Generating\n  them in the Lab with a Lattice Model",
        "authors": [
            "B. Dupoyet",
            "H. R. Fiebig",
            "D. P. Musgrove"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We extend our studies of a quantum field model defined on a lattice having\nthe dilation group as a local gauge symmetry. The model is relevant in the\ncross-disciplinary area of econophysics. A corresponding proposal by Ilinski\naimed at gauge modeling in non-equilibrium pricing is realized as a numerical\nsimulation of the one-asset version. The gauge field background enforces\nminimal arbitrage, yet allows for statistical fluctuations. The new feature\nadded to the model is an updating prescription for the simulation that drives\nthe model market into a self-organized critical state. Taking advantage of some\nflexibility of the updating prescription, stylized features and dynamical\nbehaviors of real-world markets are reproduced in some detail.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.2379v1"
    },
    {
        "title": "Quasi-Monte Carlo methods for the Heston model",
        "authors": [
            "Jan Baldeaux",
            "Dale Roberts"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In this paper, we discuss the application of quasi-Monte Carlo methods to the\nHeston model. We base our algorithms on the Broadie-Kaya algorithm, an exact\nsimulation scheme for the Heston model. As the joint transition densities are\nnot available in closed-form, the Linear Transformation method due to Imai and\nTan, a popular and widely applicable method to improve the effectiveness of\nquasi-Monte Carlo methods, cannot be employed in the context of path-dependent\noptions when the underlying price process follows the Heston model.\nConsequently, we tailor quasi-Monte Carlo methods directly to the Heston model.\nThe contributions of the paper are threefold: We firstly show how to apply\nquasi-Monte Carlo methods in the context of the Heston model and the SVJ model,\nsecondly that quasi-Monte Carlo methods improve on Monte Carlo methods, and\nthirdly how to improve the effectiveness of quasi-Monte Carlo methods by using\nbridge constructions tailored to the Heston and SVJ models. Finally, we provide\nsome extensions for computing greeks, barrier options, multidimensional and\nmulti-asset pricing, and the 3/2 model.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.3217v2"
    },
    {
        "title": "Counterparty Risk Valuation: A Marked Branching Diffusion Approach",
        "authors": [
            "Pierre Henry-Labordere"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  The purpose of this paper is to design an algorithm for the computation of\nthe counterparty risk which is competitive in regards of a brute force\n\"Monte-Carlo of Monte-Carlo\" method (with nested simulations). This is achieved\nusing marked branching diffusions describing a Galton-Watson random tree. Such\nan algorithm leads at the same time to a computation of the (bilateral)\ncounterparty risk when we use the default-risky or counterparty-riskless option\nvalues as mark-to-market. Our method is illustrated by various numerical\nexamples.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2369v1"
    },
    {
        "title": "Fast computation of vanilla prices in time-changed models and implied\n  volatilities using rational approximations",
        "authors": [
            "Martijn Pistorius",
            "Johannes Stolte"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We present a new numerical method to price vanilla options quickly in\ntime-changed Brownian motion models. The method is based on rational function\napproximations of the Black-Scholes formula. Detailed numerical results are\ngiven for a number of widely used models. In particular, we use the\nvariance-gamma model, the CGMY model and the Heston model without correlation\nto illustrate our results. Comparison to the standard fast Fourier transform\nmethod with respect to accuracy and speed appears to favour the newly developed\nmethod in the cases considered. We present error estimates for the option\nprices. Additionally, we use this method to derive a procedure to compute, for\na given set of arbitrage-free European call option prices, the corresponding\nBlack-Scholes implied volatility surface. To achieve this, rational function\napproximations of the inverse of the Black-Scholes formula are used. We are\nthus able to work out implied volatilities more efficiently than one can by the\nuse of other common methods. Error estimates are presented for a wide range of\nparameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6899v1"
    },
    {
        "title": "The potential approach in practice",
        "authors": [
            "Tino Kluge",
            "L. C. G. Rogers"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  The potential approach is a general and simple method for modelling interest\nrates, foreign exchange rates, and in principle other types of financial\nassets. This paper takes data on some liquid interest rate derivatives, and\nfits potential models using a small finite-state Markov chain as the base\nMarkov process.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.5718v1"
    },
    {
        "title": "Interlinkages and structural changes in cross-border liabilities: a\n  network approach",
        "authors": [
            "Alessandro Spelta",
            "Tanya Araújo"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We study the international interbank market through a geometrical and a\ntopological analysis of empirical data. The geometrical analysis of the time\nseries of cross-country liabilities shows that the systematic information of\nthe interbank international market is contained in a space of small dimension,\nfrom which a topological characterization could be conveniently carried out.\nWeighted and complete networks of financial linkages across countries are\ndeveloped, for which continuous clustering, degree centrality and closeness\ncentrality are computed. The behavior of these topological coefficients reveals\nan important modification acting in the financial linkages in the period\n1997-2011. Here we show that, besides the generalized clustering increase,\nthere is a persistent increment in the degree of connectivity and in the\ncloseness centrality of some countries. These countries seem to correspond to\ncritical locations where tax policies might provide opportunities to shift\ndebts. Such critical locations highlight the role that specific countries play\nin the network structure and helps to situates the turbulent period that has\nbeen characterizing the global financial system since the Summer 2007 as the\ncounterpart of a larger structural change going on for a more than one decade.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.5675v1"
    },
    {
        "title": "A New Kind of Finance",
        "authors": [
            "Philip Z. Maymin"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Finance has benefited from the Wolfram's NKS approach but it can and will\nbenefit even more in the future, and the gains from the influence may actually\nbe concentrated among practitioners who unintentionally employ those principles\nas a group.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.1588v1"
    },
    {
        "title": "Multilevel Monte Carlo methods for applications in finance",
        "authors": [
            "Mike Giles",
            "Lukasz Szpruch"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Since Giles introduced the multilevel Monte Carlo path simulation method\n[18], there has been rapid development of the technique for a variety of\napplications in computational finance. This paper surveys the progress so far,\nhighlights the key features in achieving a high rate of multilevel variance\nconvergence, and suggests directions for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.1377v1"
    },
    {
        "title": "An Asymptotic Expansion Formula for Up-and-Out Barrier Option Price\n  under Stochastic Volatility Model",
        "authors": [
            "Takashi Kato",
            "Akihiko Takahashi",
            "Toshihiro Yamada"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This paper derives a new semi closed-form approximation formula for pricing\nan up-and-out barrier option under a certain type of stochastic volatility\nmodel including SABR model by applying a rigorous asymptotic expansion method\ndeveloped by Kato, Takahashi and Yamada (2012). We also demonstrate the\nvalidity of our approximation method through numerical examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.3306v1"
    },
    {
        "title": "Analysis of multilevel Monte Carlo path simulation using the Milstein\n  discretisation",
        "authors": [
            "Michael B. Giles",
            "Kristian Debrabant",
            "Andreas Rößler"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  The multilevel Monte Carlo path simulation method introduced by Giles ({\\it\nOperations Research}, 56(3):607-617, 2008) exploits strong convergence\nproperties to improve the computational complexity by combining simulations\nwith different levels of resolution. In this paper we analyse its efficiency\nwhen using the Milstein discretisation; this has an improved order of strong\nconvergence compared to the standard Euler-Maruyama method, and it is proved\nthat this leads to an improved order of convergence of the variance of the\nmultilevel estimator. Numerical results are also given for basket options to\nillustrate the relevance of the analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.4676v3"
    },
    {
        "title": "An extension of Paulsen-Gjessing's risk model with stochastic return on\n  investments",
        "authors": [
            "Chuancun Yin",
            "Yuzhen Wen"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We consider in this paper a general two-sided jump-diffusion risk model that\nallows for risky investments as well as for correlation between the two\nBrownian motions driving insurance risk and investment return. We first\nintroduce the model and then find the integro-differential equations satisfied\nby the Gerber-Shiu functions as well as the expected discounted penalty\nfunctions at ruin caused by a claim or by oscillation; We also study the\ndividend problem for the threshold and barrier strategies, the moments and\nmoment-generating function of the total discounted dividends until ruin are\ndiscussed. Some examples are given for special cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6757v1"
    },
    {
        "title": "The first passage time problem for mixed-exponential jump processes with\n  applications in insurance and finance",
        "authors": [
            "Chuancun Yin",
            "Yuzhen Wen",
            "Zhaojun Zong",
            "Ying Shen"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This paper stidies the first passage times to constant boundaries for\nmixed-exponential jump diffusion processes. Explicit solutions of the Laplace\ntransforms of the distribution of the first passage times, the joint\ndistribution of the first passage times and undershoot (overshoot) are\nobtained. As applications, we present explicit expression of the Gerber-Shiu\nfunctions for surplus processes with two-sided jumps, present the analytical\nsolutions for popular path-dependent options such as lookback and barrier\noptions in terms of Laplace transforms and give a closed-form expression on the\nprice of the zero-coupon bond under a structural credit risk model with jumps.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6762v2"
    },
    {
        "title": "Pricing American options via multi-level approximation methods",
        "authors": [
            "Denis Belomestny",
            "Fabian Dickmann",
            "Tigran Nagapetyan"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In this article we propose a novel approach to reduce the computational\ncomplexity of various approximation methods for pricing discrete time American\noptions. Given a sequence of continuation values estimates corresponding to\ndifferent levels of spatial approximation and time discretization, we propose a\nmulti-level low biased estimate for the price of an American option. It turns\nout that the resulting complexity gain can be rather high and can even reach\nthe order (\\varepsilon^{-1}) with (\\varepsilon) denoting the desired precision.\nThe performance of the proposed multilevel algorithm is illustrated by a\nnumerical example of pricing Bermudan max-call options.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.1334v2"
    },
    {
        "title": "Pricing approximations and error estimates for local Lévy-type models\n  with default",
        "authors": [
            "Matthew Lorig",
            "Stefano Pagliarani",
            "Andrea Pascucci"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We find approximate solutions of partial integro-differential equations,\nwhich arise in financial models when defaultable assets are described by\ngeneral scalar L\\'evy-type stochastic processes. We derive rigorous error\nbounds for the approximate solutions. We also provide numerical examples\nillustrating the usefulness and versatility of our methods in a variety of\nfinancial settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.1849v5"
    },
    {
        "title": "Pricing TARN Using a Finite Difference Method",
        "authors": [
            "Xiaolin Luo",
            "Pavel Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Typically options with a path dependent payoff, such as Target Accumulation\nRedemption Note (TARN), are evaluated by a Monte Carlo method. This paper\ndescribes a finite difference scheme for pricing a TARN option. Key steps in\nthe proposed scheme involve tracking of multiple one-dimensional finite\ndifference solutions, application of jump conditions at each cash flow exchange\ndate, and a cubic spline interpolation of results after each jump. Since a\nfinite difference scheme for TARN has significantly different features from a\ntypical finite difference scheme for options with a path independent payoff, we\ngive a step by step description on the implementation of the scheme, which is\nnot available in the literature. The advantages of the proposed finite\ndifference scheme over the Monte Carlo method are illustrated by examples with\nthree different knockout types. In the case of constant or time dependent\nvolatility models (where Monte Carlo requires simulation at cash flow dates\nonly), the finite difference method can be faster by an order of magnitude than\nthe Monte Carlo method to achieve the same accuracy in price. Finite difference\nmethod can be even more efficient in comparison with Monte Carlo in the case of\nlocal volatility model where Monte Carlo requires significantly larger number\nof time steps. In terms of robust and accurate estimation of Greeks, the\nadvantage of the finite difference method will be even more pronounced.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7563v2"
    },
    {
        "title": "CORN: Correlation-Driven Nonparametric Learning Approach for Portfolio\n  Selection -- an Online Appendix",
        "authors": [
            "Bin Li",
            "Dingjiang Huang",
            "Steven C. H. Hoi"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This appendix proves CORN's universal consistency. One of Bin's PhD thesis\nexaminer (Special thanks to Vladimir Vovk from Royal Holloway, University of\nLondon) suggested that CORN is universal and provided sketch proof of Lemma\n1.6, which is the key of this proof. Based on the proof in Gy\\\"prfi et al.\n[2006], we thus prove CORN's universal consistency. Note that the notations in\nthis appendix follows Gy\\\"orfi et al. [2006].\n",
        "pdf_link": "http://arxiv.org/pdf/1306.1378v1"
    },
    {
        "title": "Explicit implied volatilities for multifactor local-stochastic\n  volatility models",
        "authors": [
            "Matthew Lorig",
            "Stefano Pagliarani",
            "Andrea Pascucci"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We consider an asset whose risk-neutral dynamics are described by a general\nclass of local-stochastic volatility models and derive a family of asymptotic\nexpansions for European-style option prices and implied volatilities. Our\nimplied volatility expansions are explicit; they do not require any special\nfunctions nor do they require numerical integration. To illustrate the accuracy\nand versatility of our method, we implement it under five different model\ndynamics: CEV local volatility, quadratic local volatility, Heston stochastic\nvolatility, $3/2$ stochastic volatility, and SABR local-stochastic volatility.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.5447v4"
    },
    {
        "title": "On Modeling Economic Default Time: A Reduced-Form Model Approach",
        "authors": [
            "Jia-Wen Gu",
            "Bo Jiang",
            "Wai-Ki Ching",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In the aftermath of the global financial crisis, much attention has been paid\nto investigating the appropriateness of the current practice of default risk\nmodeling in banking, finance and insurance industries. A recent empirical study\nby Guo et al.(2008) shows that the time difference between the economic and\nrecorded default dates has a significant impact on recovery rate estimates. Guo\net al.(2011) develop a theoretical structural firm asset value model for a firm\ndefault process that embeds the distinction of these two default times. To be\nmore consistent with the practice, in this paper, we assume the market\nparticipants cannot observe the firm asset value directly and developed a\nreduced-form model to characterize the economic and recorded default times. We\nderive the probability distribution of these two default times. The numerical\nstudy on the difference between these two shows that our proposed model can\nboth capture the features and fit the empirical data.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.6402v1"
    },
    {
        "title": "A note on Keen's model: The limits of Schumpeter's \"Creative\n  Destruction\"",
        "authors": [
            "Glenn Ierley"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This paper presents a general solution for a recent model by Keen for\nendogenous money creation. The solution provides an analytic framework that\nexplains all significant dynamical features of Keen's model and their\nparametric dependence, including an exact result for both the period and\nsubsidence rate of the Great Moderation. It emerges that Keen's model has just\ntwo possible long term solutions: stable growth or terminal collapse. While\ncollapse can come about immediately from economies that are nonviable by virtue\nof unsuitable parameters or initial conditions, in general the collapse is\npreceded by an interval of exponential growth. In first approximation, the\nduration of that exponential growth is half a period of a sinusoidal\noscillation. The period is determined by reciprocal of the imaginary part of\none root of a certain quintic polynomial. The real part of the same root\ndetermines the rate of growth of the economy. The coefficients of that\npolynomial depend in a complicated way upon the numerous parameters in the\nproblem and so, therefore, the pattern of roots. For a favorable choice of\nparameters, the salient root is purely real. This is the circumstance that\nadmits the second possible long term solution, that of indefinite stable\ngrowth, i.e. an infinite period.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.6583v1"
    },
    {
        "title": "Over-the-counter market models with several assets",
        "authors": [
            "Alain Bélanger",
            "Gaston Giroux",
            "Miguel Moisan-Poisson"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We study two classes of over-the-counter markets specified by systems of\nODE's, in the spirit of Duffie-Garleanu-Pedersen, Econometrica, 2005. We first\ncompute the steady states for many of these ODE's. Then we obtain the prices at\nwhich investors trade with each other at these steady states. Finally, we study\nthe stability of the solutions of these ODE's.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.2957v1"
    },
    {
        "title": "A Taylor series approach to pricing and implied vol for LSV models",
        "authors": [
            "Matthew Lorig",
            "Stefano Pagliarani",
            "Andrea Pascucci"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Using classical Taylor series techniques, we develop a unified approach to\npricing and implied volatility for European-style options in a general\nlocal-stochastic volatility setting. Our price approximations require only a\nnormal CDF and our implied volatility approximations are fully explicit (ie,\nthey require no special functions, no infinite series and no numerical\nintegration). As such, approximate prices can be computed as efficiently as\nBlack-Scholes prices, and approximate implied volatilities can be computed\nnearly instantaneously.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.5019v1"
    },
    {
        "title": "Fast Convergence of Regress-Later Estimates in Least Squares Monte Carlo",
        "authors": [
            "Eric Beutner",
            "Janina Schweizer",
            "Antoon Pelsser"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Many problems in financial engineering involve the estimation of unknown\nconditional expectations across a time interval. Often Least Squares Monte\nCarlo techniques are used for the estimation. One method that can be combined\nwith Least Squares Monte Carlo is the \"Regress-Later\" method. Unlike\nconventional methods where the value function is regressed on a set of basis\nfunctions valued at the beginning of the interval, the \"Regress-Later\" method\nregresses the value function on a set of basis functions valued at the end of\nthe interval. The conditional expectation across the interval is then computed\nexactly for each basis function. We provide sufficient conditions under which\nwe derive the convergence rate of Regress-Later estimators. Importantly, our\nresults hold on non-compact sets. We show that the Regress-Later method is\ncapable of converging significantly faster than conventional methods and\nprovide an explicit example. Achieving faster convergence speed provides a\nstrong motivation for using Regress-Later methods in estimating conditional\nexpectations across time.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5274v2"
    },
    {
        "title": "Asymptotic expansion for characteristic function in Heston stochastic\n  volatility model with fast mean-reverting correction",
        "authors": [
            "Ankush Agarwal"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In this note, we derive the characteristic function expansion for logarithm\nof the underlying asset price in corrected Heston model as proposed by Fouque\nand Lorig.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3572v1"
    },
    {
        "title": "Exact simulation pricing with Gamma processes and their extensions",
        "authors": [
            "Lancelot F. James",
            "Dohyun Kim",
            "Zhiyuan Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Exact path simulation of the underlying state variable is of great practical\nimportance in simulating prices of financial derivatives or their sensitivities\nwhen there are no analytical solutions for their pricing formulas. However, in\ngeneral, the complex dependence structure inherent in most nontrivial\nstochastic volatility (SV) models makes exact simulation difficult. In this\npaper, we present a nontrivial SV model that parallels the notable Heston SV\nmodel in the sense of admitting exact path simulation as studied by Broadie and\nKaya. The instantaneous volatility process of the proposed model is driven by a\nGamma process. Extensions to the model including superposition of independent\ninstantaneous volatility processes are studied. Numerical results show that the\nproposed model outperforms the Heston model and two other L\\'evy driven SV\nmodels in terms of model fit to the real option data. The ability to exactly\nsimulate some of the path-dependent derivative prices is emphasized. Moreover,\nthis is the first instance where an infinite-activity volatility process can be\napplied exactly in such pricing contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.6526v2"
    },
    {
        "title": "A central limit theorem for Latin hypercube sampling with dependence and\n  application to exotic basket option pricing",
        "authors": [
            "Christoph Aistleitner",
            "Markus Hofer",
            "Robert Tichy"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We consider the problem of estimating $\\mathbb{E} [f(U^1, \\ldots, U^d)]$,\nwhere $(U^1, \\ldots, U^d)$ denotes a random vector with uniformly distributed\nmarginals. In general, Latin hypercube sampling (LHS) is a powerful tool for\nsolving this kind of high-dimensional numerical integration problem. In the\ncase of dependent components of the random vector $(U^1, \\ldots, U^d)$ one can\nachieve more accurate results by using Latin hypercube sampling with dependence\n(LHSD). We state a central limit theorem for the $d$-dimensional LHSD\nestimator, by this means generalising a result of Packham and Schmidt.\nFurthermore we give conditions on the function $f$ and the distribution of\n$(U^1, \\ldots, U^d)$ under which a reduction of variance can be achieved.\nFinally we compare the effectiveness of Monte Carlo and LHSD estimators\nnumerically in exotic basket option pricing problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.4698v1"
    },
    {
        "title": "Pricing of vanilla and first generation exotic options in the local\n  stochastic volatility framework: survey and new results",
        "authors": [
            "Alexander Lipton",
            "Andrey Gal",
            "Andris Lasis"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Stochastic volatility (SV) and local stochastic volatility (LSV) processes\ncan be used to model the evolution of various financial variables such as FX\nrates, stock prices, and so on. Considerable efforts have been devoted to\npricing derivatives written on underliers governed by such processes. Many\nissues remain, though, including the efficacy of the standard alternating\ndirection implicit (ADI) numerical methods for solving SV and LSV pricing\nproblems. In general, the amount of required computations for these methods is\nvery substantial. In this paper we address some of these issues and propose a\nviable alternative to the standard ADI methods based on Galerkin-Ritz ideas. We\nalso discuss various approaches to solving the corresponding pricing problems\nin a semi-analytical fashion. We use the fact that in the zero correlation case\nsome of the pricing problems can be solved analytically, and develop a\nclosed-form series expansion in powers of correlation. We perform a thorough\nbenchmarking of various numerical solutions by using analytical and\nsemi-analytical solutions derived in the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.5693v1"
    },
    {
        "title": "Accelerating Implicit Finite Difference Schemes Using a Hardware\n  Optimized Tridiagonal Solver for FPGAs",
        "authors": [
            "Samuel Palmer"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We present a design and implementation of the Thomas algorithm optimized for\nhardware acceleration on an FPGA, the Thomas Core. The hardware-based algorithm\ncombined with the custom data flow and low level parallelism available in an\nFPGA reduces the overall complexity from 8N down to 5N serial arithmetic\noperations, and almost halves the overall latency by parallelizing the two\ncostly divisions. Combining this with a data streaming interface, we reduce\nmemory overheads to 2 N-length vectors per N-tridiagonal system to be solved.\nThe Thomas Core allows for multiple independent tridiagonal systems to be\ncontinuously solved in parallel, providing an efficient and scalable\naccelerator for many numerical computations. Finally we present applications\nfor derivatives pricing problems using implicit finite difference schemes on an\nFPGA accelerated system and we investigate the use and limitations of\nfixed-point arithmetic in our algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.5094v2"
    },
    {
        "title": "The role of information in a two-traders market",
        "authors": [
            "F. Bagarello",
            "E. Haven"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In a very simple stock market, made by only two \\emph{initially equivalent}\ntraders, we discuss how the information can affect the performance of the\ntraders. More in detail, we first consider how the portfolios of the traders\nevolve in time when the market is \\emph{closed}. After that, we discuss two\nmodels in which an interaction with the outer world is allowed. We show that,\nin this case, the two traders behave differently, depending on \\textbf{i)} the\namount of information which they receive from outside; and \\textbf{ii)}the\nquality of this information.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6204v1"
    },
    {
        "title": "High-Order Splitting Methods for Forward PDEs and PIDEs",
        "authors": [
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  This paper is dedicated to the construction of high-order (in both space and\ntime) finite-difference schemes for both forward and backward PDEs and PIDEs,\nsuch that option prices obtained by solving both the forward and backward\nequations are consistent. This approach is partly inspired by Andreasen & Huge,\n2011 who reported a pair of consistent finite-difference schemes of first-order\napproximation in time for an uncorrelated local stochastic volatility model. We\nextend their approach by constructing schemes that are second-order in both\nspace and time and that apply to models with jumps and discrete dividends.\nTaking correlation into account in our approach is also not an issue.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.1804v1"
    },
    {
        "title": "Multilevel Monte Carlo For Exponential Lévy Models",
        "authors": [
            "Mike Giles",
            "Yuan Xia"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We apply multilevel Monte Carlo for option pricing problems using exponential\nL\\'{e}vy models with a uniform timestep discretisation to monitor the running\nmaximum required for lookback and barrier options. The numerical results\ndemonstrate the computational efficiency of this approach. We derive estimates\nof the convergence rate for the error introduced by the discrete monitoring of\nthe running supremum of a broad class of L\\'{e}vy processes. We use these to\nobtain upper bounds on the multilevel Monte Carlo variance convergence rate for\nthe Variance Gamma, NIG and $\\alpha$-stable processes used in the numerical\nexperiments. We also show numerical results and analysis of a trapezoidal\napproximation for Asian options.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.5309v2"
    },
    {
        "title": "The acceptance-rejection method for low-discrepancy sequences",
        "authors": [
            "Nguyet Nguyen",
            "Giray Ökten"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  Generation of pseudorandom numbers from different probability distributions\nhas been studied extensively in the Monte Carlo simulation literature. Two\nstandard generation techniques are the acceptance-rejection and inverse\ntransformation methods. An alternative approach to Monte Carlo simulation is\nthe quasi-Monte Carlo method, which uses low-discrepancy sequences, instead of\npseudorandom numbers, in simulation. Low-discrepancy sequences from different\ndistributions can be obtained by the inverse transformation method, just like\nfor pseudorandom numbers. In this paper, we will present an\nacceptance-rejection algorithm for low-discrepancy sequences. We will prove a\nconvergence result, and present error bounds. We will then use this\nacceptance-rejection algorithm to develop quasi-Monte Carlo versions of some\nwell known algorithms to generate beta and gamma distributions, and investigate\nthe efficiency of these algorithms numerically. We will also consider the\nsimulation of the variance gamma model, a model used in computational finance,\nwhere the generation of these probability distributions are needed. Our results\nshow that the acceptance-rejection technique can result in significant\nimprovements in computing time over the inverse transformation method in the\ncontext of low-discrepancy sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.5599v1"
    },
    {
        "title": "Multilevel path simulation for weak approximation schemes",
        "authors": [
            "Denis Belomestny",
            "Tigran Nagapetyan"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In this paper we discuss the possibility of using multilevel Monte Carlo\n(MLMC) methods for weak approximation schemes. It turns out that by means of a\nsimple coupling between consecutive time discretisation levels, one can achieve\nthe same complexity gain as under the presence of a strong convergence. We\nexemplify this general idea in the case of weak Euler scheme for L\\'evy driven\nstochastic differential equations, and show that, given a weak convergence of\norder $\\alpha\\geq 1/2,$ the complexity of the corresponding \"weak\" MLMC\nestimate is of order $\\varepsilon^{-2}\\log ^{2}(\\varepsilon).$ The numerical\nperformance of the new \"weak\" MLMC method is illustrated by several numerical\nexamples.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.2581v3"
    },
    {
        "title": "High Performance Financial Simulation Using Randomized Quasi-Monte Carlo\n  Methods",
        "authors": [
            "Linlin Xu",
            "Giray Ökten"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  GPU computing has become popular in computational finance and many financial\ninstitutions are moving their CPU based applications to the GPU platform. Since\nmost Monte Carlo algorithms are embarrassingly parallel, they benefit greatly\nfrom parallel implementations, and consequently Monte Carlo has become a focal\npoint in GPU computing. GPU speed-up examples reported in the literature often\ninvolve Monte Carlo algorithms, and there are software tools commercially\navailable that help migrate Monte Carlo financial pricing models to GPU.\n  We present a survey of Monte Carlo and randomized quasi-Monte Carlo methods,\nand discuss existing (quasi) Monte Carlo sequences in GPU libraries. We discuss\nspecific features of GPU architecture relevant for developing efficient (quasi)\nMonte Carlo methods. We introduce a recent randomized quasi-Monte Carlo method,\nand compare it with some of the existing implementations on GPU, when they are\nused in pricing caplets in the LIBOR market model and mortgage backed\nsecurities.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5526v1"
    },
    {
        "title": "Approximating the zero-coupon bond price in a general one-factor model\n  with constant coefficients",
        "authors": [
            "Beata Stehlikova"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We consider a general one-factor short rate model, in which the instantaneous\ninterest rate is driven by a univariate diffusion with time independent drift\nand volatility. We construct recursive formula for the coefficients of the\nTaylor expansion of the bond price and its logarithm around $\\tau=0$, where\n$\\tau$ is time to maturity. We provide numerical examples of convergence of the\npartial sums of the series and compare them with the known exact values in the\ncase of Cox-Ingersoll-Ross and Dothan model.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5673v1"
    },
    {
        "title": "Fast and Simple Method for Pricing Exotic Options using Gauss-Hermite\n  Quadrature on a Cubic Spline Interpolation",
        "authors": [
            "Xiaolin Luo",
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  There is a vast literature on numerical valuation of exotic options using\nMonte Carlo, binomial and trinomial trees, and finite difference methods. When\ntransition density of the underlying asset or its moments are known in closed\nform, it can be convenient and more efficient to utilize direct integration\nmethods to calculate the required option price expectations in a backward\ntime-stepping algorithm. This paper presents a simple, robust and efficient\nalgorithm that can be applied for pricing many exotic options by computing the\nexpectations using Gauss-Hermite integration quadrature applied on a cubic\nspline interpolation. The algorithm is fully explicit but does not suffer the\ninherent instability of the explicit finite difference counterpart. A `free'\nbonus of the algorithm is that it already contains the function for fast and\naccurate interpolation of multiple solutions required by many discretely\nmonitored path dependent options. For illustrations, we present examples of\npricing a series of American options with either Bermudan or continuous\nexercise features, and a series of exotic path-dependent options of target\naccumulation redemption note (TARN). Results of the new method are compared\nwith Monte Carlo and finite difference methods, including some of the most\nadvanced or best known finite difference algorithms in the literature. The\ncomparison shows that, despite its simplicity, the new method can rival with\nsome of the best finite difference algorithms in accuracy and at the same time\nit is significantly faster. Virtually the same algorithm can be applied to\nprice other path-dependent financial contracts such as Asian options and\nvariable annuities.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.6938v3"
    },
    {
        "title": "Exact solution of a generalized version of the Black-Scholes equation",
        "authors": [
            "Liviu-Adrian Cotfas",
            "Camelia Delcea",
            "Nicolae Cotfas"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We analyze a generalized version of the Black-Scholes equation depending on a\nparameter $a\\!\\in \\!(-\\infty,0)$. It satisfies the martingale condition and\ncoincides with the Black-Scholes equation in the limit case $a\\nearrow 0$. We\nshow that the generalized equation is exactly solvable in terms of Hermite\npolynomials and numerically compare its solution with the solution of the\nBlack-Scholes equation.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.2628v1"
    },
    {
        "title": "Valuation of Variable Annuities with Guaranteed Minimum Withdrawal and\n  Death Benefits via Stochastic Control Optimization",
        "authors": [
            "Xiaolin Luo",
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In this paper we present a numerical valuation of variable annuities with\ncombined Guaranteed Minimum Withdrawal Benefit (GMWB) and Guaranteed Minimum\nDeath Benefit (GMDB) under optimal policyholder behaviour solved as an optimal\nstochastic control problem. This product simultaneously deals with financial\nrisk, mortality risk and human behaviour. We assume that market is complete in\nfinancial risk and mortality risk is completely diversified by selling enough\npolicies and thus the annuity price can be expressed as appropriate\nexpectation. The computing engine employed to solve the optimal stochastic\ncontrol problem is based on a robust and efficient Gauss-Hermite quadrature\nmethod with cubic spline. We present results for three different types of death\nbenefit and show that, under the optimal policyholder behaviour, adding the\npremium for the death benefit on top of the GMWB can be problematic for\ncontracts with long maturities if the continuous fee structure is kept, which\nis ordinarily assumed for a GMWB contract. In fact for some long maturities it\ncan be shown that the fee cannot be charged as any proportion of the account\nvalue -- there is no solution to match the initial premium with the fair\nannuity price. On the other hand, the extra fee due to adding the death benefit\ncan be charged upfront or in periodic instalment of fixed amount, and it is\ncheaper than buying a separate life insurance.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.5453v2"
    },
    {
        "title": "A hybrid tree/finite-difference approach for Heston-Hull-White type\n  models",
        "authors": [
            "M. Briani",
            "L. Caramellino",
            "A. Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We study a hybrid tree-finite difference method which permits to obtain\nefficient and accurate European and American option prices in the Heston\nHull-White and Heston Hull-White2d models. Moreover, as a by-product, we\nprovide a new simulation scheme to be used for Monte Carlo evaluations.\nNumerical results show the reliability and the efficiency of the proposed\nmethods\n",
        "pdf_link": "http://arxiv.org/pdf/1503.03705v5"
    },
    {
        "title": "Anomalous volatility scaling in high frequency financial data",
        "authors": [
            "Noemi Nava",
            "T. Di Matteo",
            "Tomaso Aste"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Volatility of intra-day stock market indices computed at various time\nhorizons exhibits a scaling behaviour that differs from what would be expected\nfrom fractional Brownian motion (fBm). We investigate this anomalous scaling by\nusing empirical mode decomposition (EMD), a method which separates time series\ninto a set of cyclical components at different time-scales. By applying the EMD\nto fBm, we retrieve a scaling law that relates the variance of the components\nto a power law of the oscillating period. In contrast, when analysing 22\ndifferent stock market indices, we observe deviations from the fBm and Brownian\nmotion scaling behaviour. We discuss and quantify these deviations, associating\nthem to the characteristics of financial markets, with larger deviations\ncorresponding to less developed markets.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.08465v3"
    },
    {
        "title": "IMEX schemes for a Parabolic-ODE system of European Options with\n  Liquidity Shocks",
        "authors": [
            "W. Mudzimbabwe",
            "Lubin G. Vulkov"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  The coupled system, where one is a degenerate parabolic equation and the\nother has not a diffusion term arises in the modeling of European options with\nliquidity shocks. Two implicit-explicit (IMEX) schemes that preserve the\npositivity of the differential problem solution are constructed and analyzed.\nNumerical experiments confirm the theoretical results and illustrate the high\naccuracy and efficiency of the schemes in combination with Richardson\nextrapolation\n",
        "pdf_link": "http://arxiv.org/pdf/1503.09008v1"
    },
    {
        "title": "Application of Operator Splitting Methods in Finance",
        "authors": [
            "Karel in 't Hout",
            "Jari Toivanen"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Financial derivatives pricing aims to find the fair value of a financial\ncontract on an underlying asset. Here we consider option pricing in the partial\ndifferential equations framework. The contemporary models lead to\none-dimensional or multidimensional parabolic problems of the\nconvection-diffusion type and generalizations thereof. An overview of various\noperator splitting methods is presented for the efficient numerical solution of\nthese problems.\n  Splitting schemes of the Alternating Direction Implicit (ADI) type are\ndiscussed for multidimensional problems, e.g. given by stochastic volatility\n(SV) models. For jump models Implicit-Explicit (IMEX) methods are considered\nwhich efficiently treat the nonlocal jump operator. For American options an\neasy-to-implement operator splitting method is described for the resulting\nlinear complementarity problems.\n  Numerical experiments are presented to illustrate the actual stability and\nconvergence of the splitting schemes. Here European and American put options\nare considered under four asset price models: the classical Black-Scholes\nmodel, the Merton jump-diffusion model, the Heston SV model, and the Bates SV\nmodel with jumps.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.01022v1"
    },
    {
        "title": "Estimating the Algorithmic Complexity of Stock Markets",
        "authors": [
            "Olivier Brandouy",
            "Jean-Paul Delahaye",
            "Lin Ma"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Randomness and regularities in Finance are usually treated in probabilistic\nterms. In this paper, we develop a completely different approach in using a\nnon-probabilistic framework based on the algorithmic information theory\ninitially developed by Kolmogorov (1965). We present some elements of this\ntheory and show why it is particularly relevant to Finance, and potentially to\nother sub-fields of Economics as well. We develop a generic method to estimate\nthe Kolmogorov complexity of numeric series. This approach is based on an\niterative \"regularity erasing procedure\" implemented to use lossless\ncompression algorithms on financial data. Examples are provided with both\nsimulated and real-world financial time series. The contributions of this\narticle are twofold. The first one is methodological : we show that some\nstructural regularities, invisible with classical statistical tests, can be\ndetected by this algorithmic method. The second one consists in illustrations\non the daily Dow-Jones Index suggesting that beyond several well-known\nregularities, hidden structure may in this index remain to be identified.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.04296v1"
    },
    {
        "title": "Chebyshev Interpolation for Parametric Option Pricing",
        "authors": [
            "Maximilian Gaß",
            "Kathrin Glau",
            "Mirco Mahlstedt",
            "Maximilian Mair"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Recurrent tasks such as pricing, calibration and risk assessment need to be\nexecuted accurately and in real-time. Simultaneously we observe an increase in\nmodel sophistication on the one hand and growing demands on the quality of risk\nmanagement on the other. To address the resulting computational challenges, it\nis natural to exploit the recurrent nature of these tasks. We concentrate on\nParametric Option Pricing (POP) and show that polynomial interpolation in the\nparameter space promises to reduce run-times while maintaining accuracy. The\nattractive properties of Chebyshev interpolation and its tensorized extension\nenable us to identify criteria for (sub)exponential convergence and explicit\nerror bounds. We show that these results apply to a variety of European\n(basket) options and affine asset models. Numerical experiments confirm our\nfindings. Exploring the potential of the method further, we empirically\ninvestigate the efficiency of the Chebyshev method for multivariate and\npath-dependent options.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.04648v2"
    },
    {
        "title": "A State-Space Estimation of the Lee-Carter Mortality Model and\n  Implications for Annuity Pricing",
        "authors": [
            "Man Chung Fung",
            "Gareth W. Peters",
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  In this article we investigate a state-space representation of the Lee-Carter\nmodel which is a benchmark stochastic mortality model for forecasting\nage-specific death rates. Existing relevant literature focuses mainly on\nmortality forecasting or pricing of longevity derivatives, while the full\nimplications and methods of using the state-space representation of the\nLee-Carter model in pricing retirement income products is yet to be examined.\nThe main contribution of this article is twofold. First, we provide a rigorous\nand detailed derivation of the posterior distributions of the parameters and\nthe latent process of the Lee-Carter model via Gibbs sampling. Our assumption\nfor priors is slightly more general than the current literature in this area.\nMoreover, we suggest a new form of identification constraint not yet utilised\nin the actuarial literature that proves to be a more convenient approach for\nestimating the model under the state-space framework. Second, by exploiting the\nposterior distribution of the latent process and parameters, we examine the\npricing range of annuities, taking into account the stochastic nature of the\ndynamics of the mortality rates. In this way we aim to capture the impact of\nlongevity risk on the pricing of annuities. The outcome of our study\ndemonstrates that an annuity price can be more than 4% under-valued when\ndifferent assumptions are made on determining the survival curve constructed\nfrom the distribution of the forecasted death rates. Given that a typical\nannuity portfolio consists of a large number of policies with maturities which\nspan decades, we conclude that the impact of longevity risk on the accurate\npricing of annuities is a significant issue to be further researched. In\naddition, we find that mis-pricing is increasingly more pronounced for older\nages as well as for annuity policies having a longer maturity.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.00322v1"
    },
    {
        "title": "New Analytical Solutions of a Modified Black-Scholes Equation with the\n  European Put Option",
        "authors": [
            "Juan Ospina"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Using Maple, we compute some analytical solutions of a modified Black-Scholes\nequation, recently proposed, in the case of the European put option. We show\nthat the modified Black-Scholes equation with the European put option is\nexactly solvable in terms of associated Laguerre polynomials. We make some\nnumerical experiments with the analytical solutions and we compare our results\nwith the results derived from numerical experiments using the standard\nBlack-Scholes equation.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.03841v1"
    },
    {
        "title": "Dynamic Mode Decomposition for Financial Trading Strategies",
        "authors": [
            "Jordan Mann",
            "J. Nathan Kutz"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We demonstrate the application of an algorithmic trading strategy based upon\nthe recently developed dynamic mode decomposition (DMD) on portfolios of\nfinancial data. The method is capable of characterizing complex dynamical\nsystems, in this case financial market dynamics, in an equation-free manner by\ndecomposing the state of the system into low-rank terms whose temporal\ncoefficients in time are known. By extracting key temporal coherent structures\n(portfolios) in its sampling window, it provides a regression to a best fit\nlinear dynamical system, allowing for a predictive assessment of the market\ndynamics and informing an investment strategy. The data-driven analytics\ncapitalizes on stock market patterns, either real or perceived, to inform\nbuy/sell/hold investment decisions. Critical to the method is an associated\nlearning algorithm that optimizes the sampling and prediction windows of the\nalgorithm by discovering trading hot-spots. The underlying mathematical\nstructure of the algorithms is rooted in methods from nonlinear dynamical\nsystems and shows that the decomposition is an effective mathematical tool for\ndata-driven discovery of market patterns.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.04487v1"
    },
    {
        "title": "Bermudan options by simulation",
        "authors": [
            "L. C. G. Rogers"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  The aim of this study is to devise numerical methods for dealing with very\nhigh-dimensional Bermudan-style derivatives. For such problems, we quickly see\nthat we can at best hope for price bounds, and we can only use a simulation\napproach. We use the approach of Barraquand & Martineau which proposes that the\nreward process should be treated as if it were Markovian, and then uses this to\ngenerate a stopping rule and hence a lower bound on the price. Using the dual\napproach introduced by Rogers, and Haugh & Kogan, this approximate Markov\nprocess leads us to hedging strategies, and upper bounds on the price. The\nmethodology is generic, and is illustrated on eight examples of varying levels\nof difficulty. Run times are largely insensitive to dimension.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.06117v2"
    },
    {
        "title": "A mixed Monte Carlo and PDE variance reduction method for foreign\n  exchange options under the Heston-CIR model",
        "authors": [
            "Andrei Cozma",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  In this paper, the valuation of European and path-dependent options in\nforeign exchange (FX) markets is considered when the currency exchange rate\nevolves according to the Heston model combined with the Cox-Ingersoll-Ross\ndynamics for the stochastic domestic and foreign short interest rates. The\nmixed Monte Carlo/PDE method requires that we simulate only the paths of the\nsquared volatility and the two interest rates, while an \"inner\"\nBlack-Scholes-type expectation is evaluated by means of a PDE. This can lead to\na substantial variance reduction and complexity improvements under certain\ncircumstances depending on the contract and the model parameters. In this work,\nwe establish the uniform boundedness of moments of the exchange rate process\nand its approximation, and prove strong convergence in $L^p$ ($p\\geq1$) of the\nlatter. Then, we carry out a variance reduction analysis and obtain accurate\napproximations for quantities of interest. All theoretical contributions can be\nextended to multi-factor short rates in a straightforward manner. Finally, we\nillustrate the efficiency of the method for the four-factor Heston-CIR model\nthrough a detailed quantitative assessment.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.01479v3"
    },
    {
        "title": "A Hedged Monte Carlo Approach to Real Option Pricing",
        "authors": [
            "Edgardo Brigatti",
            "Felipe Macias",
            "Max O. Souza",
            "Jorge P. Zubelli"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  In this work we are concerned with valuing optionalities associated to invest\nor to delay investment in a project when the available information provided to\nthe manager comes from simulated data of cash flows under historical (or\nsubjective) measure in a possibly incomplete market. Our approach is suitable\nalso to incorporating subjective views from management or market experts and to\nstochastic investment costs. It is based on the Hedged Monte Carlo strategy\nproposed by Potters et al (2001) where options are priced simultaneously with\nthe determination of the corresponding hedging. The approach is particularly\nwell-suited to the evaluation of commodity related projects whereby the\navailability of pricing formulae is very rare, the scenario simulations are\nusually available only in the historical measure, and the cash flows can be\nhighly nonlinear functions of the prices.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.03577v1"
    },
    {
        "title": "Les indicateus avancés de l'inflation en RDCongo",
        "authors": [
            "Henry Ngongo"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This study aims to identify the leading of inflation indicators of monetary\npolicy in DRC. The results reveal that the most relevant inflation indicators\nusually come from the monetary origin than the real sector. Variance\ndecomposition analyzes place in the foreground the rate of exchange, the money\nsupply and the public consumption like the most relevant indicators. In order\nto achieve its goal of price stability and to support a strong economic growth,\nthe intermediate objective of the Central Bank baseded on the controle of the\nmoney supply seems to be less relevant. Relates to a high level of the\ndollarization, the central bank will be able to adopt either the strategy of\nnominal anchoring of the rate of exchange, this calls the return of the fixed\nexchange regime or to adopt a strategy of inflation targeting is to restore the\ncredibility of the monetary policy\n",
        "pdf_link": "http://arxiv.org/pdf/1509.06504v1"
    },
    {
        "title": "Consistent Pricing of VIX and Equity Derivatives with the 4/2 Stochastic\n  Volatility Plus Jumps Model",
        "authors": [
            "Wei Lin",
            "Shenghong Li",
            "Xingguo Luo",
            "Shane Chern"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  In this paper, we develop a 4/2 stochastic volatility plus jumps model,\nnamely, a new stochastic volatility model including the Heston model and 3/2\nmodel as special cases. Our model is highly tractable by applying the Lie\nsymmetries theory for PDEs, which means that the pricing procedure can be\nperformed efficiently. In fact, we obtain a closed-form solution for the joint\nFourier-Laplace transform so that equity and realized-variance derivatives can\nbe priced. We also employ our model to consistently price equity and VIX\nderivatives. In this process, the quasi-closed-form solutions for future and\noption prices are derived. Furthermore, through adopting data on daily VIX\nfuture and option prices, we investigate our model along with the Heston model\nand 3/2 model and compare their different performance in practice. Our result\nillustrates that the 4/2 model with an instantaneous volatility of the form\n$(a\\sqrt{V_t}+b/\\sqrt{V_t})$ for some constants $a, b$ presents considerable\nadvantages in pricing VIX derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.01172v2"
    },
    {
        "title": "Mathematical Foundations of Realtime Equity Trading. Liquidity Deficit\n  and Market Dynamics. Automated Trading Machines",
        "authors": [
            "Vladislav Gennadievich Malyshkin",
            "Ray Bakhramov"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We postulates, and then show experimentally, that liquidity deficit is the\ndriving force of the markets. In the first part of the paper a kinematic of\nliquidity deficit is developed. The calculus-like approach, which is based on\nRadon--Nikodym derivatives and their generalization, allows us to calculate\nimportant characteristics of observable market dynamics. In the second part of\nthe paper this calculus is used in an attempt to build a dynamic equation in\nthe form: future price tend to the value maximizing the number of shares traded\nper unit time. To build a practical automated trading machine P&L dynamics\ninstead of price dynamics is considered. This allows a trading automate\nresilient to catastrophic P&L drains to be built. The results are very\npromising, yet when all the fees and trading commissions are taken into\naccount, are close to breakeven. In the end of the paper important criteria for\nautomated trading systems are presented. We list the system types that can and\ncannot make money on the market. These criteria can be successfully applied not\nonly by automated trading machines, but also by a human trader.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.05510v5"
    },
    {
        "title": "Local Volatility Models in Commodity Markets and Online Calibration",
        "authors": [
            "Vinicius Albani",
            "Uri M. Ascher",
            "Jorge P. Zubelli"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We introduce a local volatility model for the valuation of options on\ncommodity futures by using European vanilla option prices. The corresponding\ncalibration problem is addressed within an online framework, allowing the use\nof multiple price surfaces. Since uncertainty in the observation of the\nunderlying future prices translates to uncertainty in data locations, we\npropose a model-based adjustment of such prices that improves reconstructions\nand smile adherence. In order to tackle the ill-posedness of the calibration\nproblem we incorporate a priori information through a judiciously designed\nTikhonov-type regularization. Extensive empirical tests with market as well as\nsynthetic data are used to demonstrate the effectiveness of the methodology and\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.04372v1"
    },
    {
        "title": "A Neural Network Approach to Efficient Valuation of Large Portfolios of\n  Variable Annuities",
        "authors": [
            "Seyed Amir Hejazi",
            "Kenneth R. Jackson"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  Managing and hedging the risks associated with Variable Annuity (VA) products\nrequire intraday valuation of key risk metrics for these products. The complex\nstructure of VA products and computational complexity of their accurate\nevaluation have compelled insurance companies to adopt Monte Carlo (MC)\nsimulations to value their large portfolios of VA products. Because the MC\nsimulations are computationally demanding, especially for intraday valuations,\ninsurance companies need more efficient valuation techniques. Recently, a\nframework based on traditional spatial interpolation techniques has been\nproposed that can significantly decrease the computational complexity of MC\nsimulation (Gan and Lin, 2015). However, traditional interpolation techniques\nrequire the definition of a distance function that can significantly impact\ntheir accuracy. Moreover, none of the traditional spatial interpolation\ntechniques provide all of the key properties of accuracy, efficiency, and\ngranularity (Hejazi et al., 2015). In this paper, we present a neural network\napproach for the spatial interpolation framework that affords an efficient way\nto find an effective distance function. The proposed approach is accurate,\nefficient, and provides an accurate granular view of the input portfolio. Our\nnumerical experiments illustrate the superiority of the performance of the\nproposed neural network approach compared to the traditional spatial\ninterpolation schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.07831v1"
    },
    {
        "title": "Derivative pricing as a transport problem: MPDATA solutions to\n  Black-Scholes-type equations",
        "authors": [
            "Sylwester Arabas",
            "Ahmad Farhat"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We discuss in this note applications of the Multidimensional Positive\nDefinite Advection Transport Algorithm (MPDATA) to numerical solutions of\npartial differential equations arising from stochastic models in quantitative\nfinance. In particular, we develop a framework for solving Black-Scholes-type\nequations by first transforming them into advection-diffusion problems, and\nnumerically integrating using an iterative explicit finite-difference approach,\nin which the Fickian term is represented as an additional advective term. We\ndiscuss the correspondence between transport phenomena and financial models,\nuncovering the possibility of expressing the no-arbitrage principle as a\nconservation law. We depict second-order accuracy in time and space of the\nembraced numerical scheme. This is done in a convergence analysis comparing\nMPDATA numerical solutions with classic Black-Scholes analytical formulae for\nthe valuation of European options. We demonstrate in addition a way of applying\nMPDATA to solve the free boundary problem (leading to a linear complementarity\nproblem) for the valuation of American options. We finally comment on the\npotential the MPDATA framework has with respect to being applied in tandem with\nmore complex models typically used in quantitive finance.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01751v5"
    },
    {
        "title": "Efficient exposure computation by risk factor decomposition",
        "authors": [
            "Cornelis S. L. de Graaf",
            "Drona Kandhai",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  The focus of this paper is the efficient computation of counterparty credit\nrisk exposure on portfolio level. Here, the large number of risk factors rules\nout traditional PDE-based techniques and allows only a relatively small number\nof paths for nested Monte Carlo simulations, resulting in large variances of\nestimators in practice. We propose a novel approach based on Kolmogorov forward\nand backward PDEs, where we counter the high dimensionality by a generalisation\nof anchored-ANOVA decompositions. By computing only the most significant terms\nin the decomposition, the dimensionality is reduced effectively, such that a\nsignificant computational speed-up arises from the high accuracy of PDE schemes\nin low dimensions compared to Monte Carlo estimation. Moreover, we show how\nthis truncated decomposition can be used as control variate for the full\nhigh-dimensional model, such that any approximation errors can be corrected\nwhile a substantial variance reduction is achieved compared to the standard\nsimulation approach. We investigate the accuracy for a realistic portfolio of\nexchange options, interest rate and cross-currency swaps under a fully\ncalibrated ten-factor model.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.01197v3"
    },
    {
        "title": "Efficient Valuation of SCR via a Neural Network Approach",
        "authors": [
            "Seyed Amir Hejazi",
            "Kenneth R. Jackson"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  As part of the new regulatory framework of Solvency II, introduced by the\nEuropean Union, insurance companies are required to monitor their solvency by\ncomputing a key risk metric called the Solvency Capital Requirement (SCR). The\nofficial description of the SCR is not rigorous and has lead researchers to\ndevelop their own mathematical frameworks for calculation of the SCR. These\nframeworks are complex and are difficult to implement. Recently, Bauer et al.\nsuggested a nested Monte Carlo (MC) simulation framework to calculate the SCR.\nBut the proposed MC framework is computationally expensive even for a simple\ninsurance product. In this paper, we propose incorporating a neural network\napproach into the nested simulation framework to significantly reduce the\ncomputational complexity in the calculation. We study the performance of our\nneural network approach in estimating the SCR for a large portfolio of an\nimportant class of insurance products called Variable Annuities (VAs). Our\nexperiments show that the proposed neural network approach is both efficient\nand accurate.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.01946v1"
    },
    {
        "title": "On the difference between locally risk-minimizing and delta hedging\n  strategies for exponential Lévy models",
        "authors": [
            "Takuji Arai",
            "Yuto Imai"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We discuss the difference between locally risk-minimizing and delta hedging\nstrategies for exponential L\\'evy models, where delta hedging strategies in\nthis paper are defined under the minimal martingale measure. We give firstly\nmodel-independent upper estimations for the difference. In addition we show\nnumerical examples for two typical exponential L\\'evy models: Merton models and\nvariance gamma models.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.09085v1"
    },
    {
        "title": "Numerical study of splitting methods for American option valuation",
        "authors": [
            "Karel in 't Hout",
            "Radoslav Valkov"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  This paper deals with the numerical approximation of American-style option\nvalues governed by partial differential complementarity problems. For a variety\nof one- and two-asset American options we investigate by ample numerical\nexperiments the temporal convergence behaviour of three modern splitting\nmethods: the explicit payoff approach, the Ikonen-Toivanen approach and the\nPeaceman-Rachford method. In addition, the temporal accuracy of these splitting\nmethods is compared to that of the penalty approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.09622v1"
    },
    {
        "title": "Strong order 1/2 convergence of full truncation Euler approximations to\n  the Cox-Ingersoll-Ross process",
        "authors": [
            "Andrei Cozma",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We study convergence properties of the full truncation Euler scheme for the\nCox-Ingersoll-Ross process in the regime where the boundary point zero is\ninaccessible. Under some conditions on the model parameters (precisely, when\nthe Feller ratio is greater than three), we establish the strong order 1/2\nconvergence in $L^{p}$ of the scheme to the exact solution. This is consistent\nwith the optimal rate of strong convergence for Euler approximations of\nstochastic differential equations with globally Lipschitz coefficients, despite\nthe fact that the diffusion coefficient in the Cox-Ingersoll-Ross model is not\nLipschitz.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.07321v2"
    },
    {
        "title": "Implied Stopping Rules for American Basket Options from Markovian\n  Projection",
        "authors": [
            "Christian Bayer",
            "Juho Häppölä",
            "Raúl Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This work addresses the problem of pricing American basket options in a\nmultivariate setting, which includes among others, the Bachelier and the\nBlack-Scholes models. In high dimensions, nonlinear partial differential\nequation methods for solving the problem become prohibitively costly due to the\ncurse of dimensionality. Instead, this work proposes to use a stopping rule\nthat depends on the dynamics of a low-dimensional Markovian projection of the\ngiven basket of assets. It is shown that the ability to approximate the\noriginal value function by a lower-dimensional approximation is a feature of\nthe dynamics of the system and is unaffected by the path-dependent nature of\nthe American basket option. Assuming that we know the density of the forward\nprocess and using the Laplace approximation, we first efficiently evaluate the\ndiffusion coefficient corresponding to the low-dimensional Markovian projection\nof the basket. Then, we approximate the optimal early-exercise boundary of the\noption by solving a Hamilton-Jacobi-Bellman partial differential equation in\nthe projected, low-dimensional space. The resulting near-optimal early-exercise\nboundary is used to produce an exercise strategy for the high-dimensional\noption, thereby providing a lower bound for the price of the American basket\noption. A corresponding upper bound is also provided. These bounds allow to\nassess the accuracy of the proposed pricing method. Indeed, our approximate\nearly-exercise strategy provides a straightforward lower bound for the American\nbasket option price. Following a duality argument due to Rogers, we derive a\ncorresponding upper bound solving only the low-dimensional optimal control\nproblem. Numerically, we show the feasibility of the method using baskets with\ndimensions up to fifty. In these examples, the resulting option price relative\nerrors are only of the order of few percent.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00558v4"
    },
    {
        "title": "An Alternative Estimation of Market Volatility based on Fuzzy Transform",
        "authors": [
            "Luigi Troiano",
            "Elena Mejuto Villa",
            "Pravesh Kriplani"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Realization of uncertainty of prices is captured by volatility, that is the\ntendency of prices to vary along a period of time. This is generally measured\nas standard deviation of daily returns. In this paper we propose and\ninvestigate the application of fuzzy transform and its inverse as an\nalternative measure of volatility. The measure obtained is compatible with the\ndefinition of risk measure given by Luce. A comparison with standard definition\nis performed by considering the NIFTY 50 stock market index within the period\nSept. 2000 - Feb. 2017.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.01348v1"
    },
    {
        "title": "Conduct Risk - distribution models with very thin Tails",
        "authors": [
            "Peter Mitic"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Regulatory requirements dictate that financial institutions must calculate\nrisk capital (funds that must be retained to cover future losses) at least\nannually. Procedures for doing this have been well-established for many years,\nbut recent developments in the treatment of conduct risk (the risk of loss due\nto the relationship between a financial institution and its customers) have\ncast doubt on 'standard' procedures. Regulations require that operational risk\nlosses should be aggregated by originating event. The effect is that a large\nnumber of small and medium-sized losses are aggregated into a small number of\nvery large losses, such that a risk capital calculation produces a hugely\ninflated result. To solve this problem, a novel distribution based on a\none-parameter probability density with an exponential of a fourth power is\nproposed, where the parameter is to be estimated. Symbolic computation is used\nto derive the necessary analytical expressions with which to formulate the\nproblem, and is followed by numeric calculations in R. Goodness-of-fit and\nparameter estimation are both determined by using a novel method developed\nspecifically for use with probability distribution functions. The results\ncompare favourably with an existing model that used a LogGamma Mixture density,\nfor which it was necessary to limit the frequency and severity of the losses.\nNo such limits were needed using the proposed exponential density.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06868v1"
    },
    {
        "title": "Standardised Reputation Measurement",
        "authors": [
            "Peter Mitic"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Well-defined formal definitions for sentiment and opinion are extended to\nincorporate the necessary elements to provide a formal quantitative definition\nof reputation. This definition takes the form of a time-based index, in which\neach element is a function of a collection of opinions mined during a given\ntime period. The resulting formal definition is validated against informal\nnotions of reputation. Practical aspects of data procurement to support such a\nreputation index are discussed. The assumption that all mined opinions comprise\na complete set is questioned. A case is made that unexpressed positive\nsentiment exists, and can be quantified.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.09955v1"
    },
    {
        "title": "Sequential Sampling for CGMY Processes via Decomposition of their Time\n  Changes",
        "authors": [
            "Chengwei Zhang",
            "Zhiyuan Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We present a new and easy-to-implement sequential sampling method for CGMY\nprocesses with either finite or infinite variation, exploiting the time change\nrepresentation of the CGMY model and a decomposition of its time change. We\nfind that the time change can be decomposed into two independent components.\nWhile the first component is a \\emph{finite} \\emph{generalized gamma\nconvolution} process whose increments can be sampled by either the exact double\nCFTP (\"coupling from the past\") method or an approximation scheme with high\nspeed and accuracy, the second component can easily be made arbitrarily small\nin the $L^1$ sense. Simulation results show that the proposed method is\nadvantageous over two existing methods under a model calibrated to historical\noption price data.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.00189v2"
    },
    {
        "title": "Feedback effect between Volatility of capital flows and financial\n  stability: evidence from Democratic Republic of Congo",
        "authors": [
            "Christian Pinshi"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Financial system being the place of metting capital flows (equality between\nsaving and investment), a volatility of capital flows can destroy the\nrobustness and good working of financial system, it means subvert financial\nstability. The same a weak financial system, few regulated and bad manage can\nexacerbate volatility of capital flows and finely undermine financial\nstability. The present study provides evidence on feedback effect between\nvolatility of capital flows and financial stability in Democratic republic of\nCongo (DRC), and estimate the contributions of macroeconomic and\nmacroprudential policies in the attenuation volatility of capital flows effects\non financial stability and in the prevention of instability financial.\nAssessment dynamic regression model a la Feldstein-Horioka we showed that\nfinancial system is widely supplied and financed by internationals capital\nflows. This implicate Congolese economy is financially mobile, that can be\ndangerous for financial stability. The study dynamic econometric of financial\nsystem's absolute size, we stipulate financial system has a systemic weight on\nreal economy. Hence a shock of financial system could have devastating effects\non Congolese economy. We estimate a vector autoregressive (VAR) model for prove\nthe bilateral causality and impacts of macroeconomic and macroprudential\npolicies. With regard to results, it proved on the one there is a feedback\neffect between volatility of capital flows and financial stability, on the\nother hand macroeconomic and macroprudential policies can't attenuate\nvolatility of capital flows and prevent instability financial. It prove\nmacroprudential approach is given a better result than monetary policy. The\nimplementation of framework macroprudential by Central Bank of Congo will be\nbeneficial in the realization of financial stability and attenuation volatility\nof capital flows.Keywords: Volatility of capital flows, financial stability,\nmacroeconomic and macroprudential policies\n",
        "pdf_link": "http://arxiv.org/pdf/1708.07636v1"
    },
    {
        "title": "Deep Stock Representation Learning: From Candlestick Charts to\n  Investment Decisions",
        "authors": [
            "Guosheng Hu",
            "Yuxin Hu",
            "Kai Yang",
            "Zehao Yu",
            "Flood Sung",
            "Zhihong Zhang",
            "Fei Xie",
            "Jianguo Liu",
            "Neil Robertson",
            "Timothy Hospedales",
            "Qiangwei Miemie"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We propose a novel investment decision strategy (IDS) based on deep learning.\nThe performance of many IDSs is affected by stock similarity. Most existing\nstock similarity measurements have the problems: (a) The linear nature of many\nmeasurements cannot capture nonlinear stock dynamics; (b) The estimation of\nmany similarity metrics (e.g. covariance) needs very long period historic data\n(e.g. 3K days) which cannot represent current market effectively; (c) They\ncannot capture translation-invariance. To solve these problems, we apply\nConvolutional AutoEncoder to learn a stock representation, based on which we\npropose a novel portfolio construction strategy by: (i) using the deeply\nlearned representation and modularity optimisation to cluster stocks and\nidentify diverse sectors, (ii) picking stocks within each cluster according to\ntheir Sharpe ratio (Sharpe 1994). Overall this strategy provides low-risk\nhigh-return portfolios. We use the Financial Times Stock Exchange 100 Index\n(FTSE 100) data for evaluation. Results show our portfolio outperforms FTSE 100\nindex and many well known funds in terms of total return in 2000 trading days.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.03803v3"
    },
    {
        "title": "Variance optimal hedging with application to Electricity markets",
        "authors": [
            "Xavier Warin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In Electricity markets, illiquidity, transaction costs and market price\ncharacteristics prevent managers to replicate exactly contracts. A residual\nrisk is always present and the hedging strategy depends on a risk criterion\nchosen. We present an algorithm to hedge a position for a mean variance\ncriterion taking into account the transaction cost and the small depth of the\nmarket. We show its effectiveness on a typical problem coming from the field of\nelectricity markets.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.03733v2"
    },
    {
        "title": "Price Optimisation for New Business",
        "authors": [
            "Maissa Tamraz",
            "Yaming Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This contribution is concerned with price optimisation of the new business\nfor a non-life product. Due to high competition in the insurance market,\nnon-life insurers are interested in increasing their conversion rates on new\nbusiness based on some profit level. In this respect, we consider the\ncompetition in the market to model the probability of accepting an offer for a\nspecific customer. We study two optimisation problems relevant for the insurer\nand present some algorithmic solutions for both continuous and discrete case.\nFinally, we provide some applications to a motor insurance dataset.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.07753v1"
    },
    {
        "title": "Fluctuation identities with continuous monitoring and their application\n  to price barrier options",
        "authors": [
            "Carolyn E. Phelan",
            "Daniele Marazzina",
            "Gianluca Fusai",
            "Guido Germano"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We present a numerical scheme to calculate fluctuation identities for\nexponential L\\'evy processes in the continuous monitoring case. This includes\nthe Spitzer identities for touching a single upper or lower barrier, and the\nmore difficult case of the two-barriers exit problem. These identities are\ngiven in the Fourier-Laplace domain and require numerical inverse transforms.\nThus we cover a gap in the literature that has mainly studied the discrete\nmonitoring case; indeed, there are no existing numerical methods that deal with\nthe continuous case. As a motivating application we price continuously\nmonitored barrier options with the underlying asset modelled by an exponential\nL\\'evy process. We perform a detailed error analysis of the method and develop\nerror bounds to show how the performance is limited by the truncation error of\nthe sinc-based fast Hilbert transform used for the Wiener-Hopf factorisation.\nBy comparing the results for our new technique with those for the discretely\nmonitored case (which is in the Fourier-$z$ domain) as the monitoring time step\napproaches zero, we show that the error convergence with continuous monitoring\nrepresents a limit for the discretely monitored scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.00077v1"
    },
    {
        "title": "A Numerical Method for Pricing Discrete Double Barrier Option by\n  Lagrange Interpolation on Jacobi Node",
        "authors": [
            "Amirhossein Sobhani",
            "Mariyan Milev"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this paper, a rapid and high accurate numerical method for pricing\ndiscrete single and double barrier knock-out call options is presented.\nAccording to the well-known Black-Scholes framework, the price of option in\neach monitoring date could be calculate by computing a recursive integral\nformula upon the heat equation solution. We have approximated these recursive\nsolutions with the aim of Lagrange interpolation on Jacobi polynomials node.\nAfter that, an operational matrix, that makes our computation significantly\nfast, has been driven. The most important feature of this method is that its\nCPU time dose not increase when the number of monitoring dates increases. The\nnumerical results confirm the accuracy and efficiency of the presented\nnumerical algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.01060v2"
    },
    {
        "title": "Efficient European and American option pricing under a jump-diffusion\n  process",
        "authors": [
            "Marcellino Gaudenzi",
            "Alice Spangaro",
            "Patrizia Stucchi"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  When the underlying asset displays oscillations, spikes or heavy-tailed\ndistributions, the lognormal diffusion process (for which Black and Scholes\ndeveloped their momentous option pricing formula) is inadequate: in order to\novercome these real world difficulties many models have been developed. Merton\nproposed a jump-diffusion model, where the dynamics of the price of the\nunderlying are subject to variations due to a Brownian process and also to\npossible jumps, driven by a compound Poisson process. Merton's model admits a\nseries solution for the European option price, and there have been a lot of\nattempts to obtain a discretisation of the Merton model with tree methods in\norder to price American or more complex options, e. g. Amin, the $O(n^3)$\nprocedure by Hilliard and Schwartz and the $O(n^{2.5})$ procedure by Dai et al.\nHere, starting from the implementation of the seven-nodes procedure by Hilliard\nand Schwartz, we prove theoretically that it is possible to reduce the\ncomplexity to $O(n \\ln n)$ in the European case and $O(n^2 \\ln n)$ in the\nAmerican put case. These theoretical results can be obtained through suitable\ntruncation of the lattice structure and the proofs provide closed formulas for\nthe truncation limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.08137v1"
    },
    {
        "title": "PrivySense: $\\underline{Pri}$ce $\\underline{V}$olatilit$\\underline{y}$\n  based $\\underline{Sen}$timent$\\underline{s}$ $\\underline{E}$stimation from\n  Financial News using Machine Learning",
        "authors": [
            "Raeid Saqur",
            "Nicole Langballe"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  As machine learning ascends the peak of computer science zeitgeist, the usage\nand experimentation with sentiment analysis using various forms of textual data\nseems pervasive. The effect is especially pronounced in formulating securities\ntrading strategies, due to a plethora of reasons including the relative ease of\nimplementation and the abundance of academic research suggesting automated\nsentiment analysis can be productively used in trading strategies. The source\ndata for such analyzers ranges a broad spectrum like social media feeds,\nmicro-blogs, real-time news feeds, ex-post financial data etc. The abstract\ntechnique underlying these analyzers involve supervised learning of sentiment\nclassification where the classifier is trained on annotated source corpus, and\naccuracy is measured by testing how well the classifiers generalizes on unseen\ntest data from the corpus. Post training, and validation of fitted models, the\nclassifiers are used to execute trading strategies, and the corresponding\nreturns are compared with appropriate benchmark returns (for e.g., the S&P500\nreturns).\n  In this paper, we introduce $\\underline{a\\ novel\\ technique\\ of\\ using\\\nprice\\ volatilities\\ to\\ empirically\\ determine\\ the\\ sentiment\\ in\\ news\\\ndata}$, instead of the traditional reverse approach. We also perform meta\nsentiment analysis by evaluating the efficacy of existing sentiment classifiers\nand the precise definition of sentiment from securities trading context. We\nscrutinize the efficacy of using human-annotated sentiment classification and\nthe tacit assumptions that introduces subjective bias in existing financial\nnews sentiment classifiers.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.00091v2"
    },
    {
        "title": "Transition probability of Brownian motion in the octant and its\n  application to default modeling",
        "authors": [
            "Vadim Kaushansky",
            "Alexander Lipton",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We derive a semi-analytic formula for the transition probability of\nthree-dimensional Brownian motion in the positive octant with absorption at the\nboundaries. Separation of variables in spherical coordinates leads to an\neigenvalue problem for the resulting boundary value problem in the two angular\ncomponents. The main theoretical result is a solution to the original problem\nexpressed as an expansion into special functions and an eigenvalue which has to\nbe chosen to allow a matching of the boundary condition. We discuss and test\nseveral computational methods to solve a finite-dimensional approximation to\nthis nonlinear eigenvalue problem. Finally, we apply our results to the\ncomputation of default probabilities and credit valuation adjustments in a\nstructural credit model with mutual liabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.00362v2"
    },
    {
        "title": "Numerical analysis on quadratic hedging strategies for normal inverse\n  Gaussian models",
        "authors": [
            "Takuji Arai",
            "Yuto Imai",
            "Ryo Nakashima"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The authors aim to develop numerical schemes of the two representative\nquadratic hedging strategies: locally risk minimizing and mean-variance hedging\nstrategies, for models whose asset price process is given by the exponential of\na normal inverse Gaussian process, using the results of Arai et al. \\cite{AIS},\nand Arai and Imai. Here normal inverse Gaussian process is a framework of\nL\\'evy processes frequently appeared in financial literature. In addition, some\nnumerical results are also introduced.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05597v1"
    },
    {
        "title": "Large-Scale Simulation of Multi-Asset Ising Financial Markets",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We perform a large-scale simulation of an Ising-based financial market model\nthat includes 300 asset time series. The financial system simulated by the\nmodel shows a fat-tailed return distribution and volatility clustering and\nexhibits unstable periods indicated by the volatility index measured as the\naverage of absolute-returns. Moreover, we determine that the cumulative risk\nfraction, which measures the system risk, changes at high volatility periods.\nWe also calculate the inverse participation ratio (IPR) and its higher-power\nversion, IPR6, from the absolute-return cross-correlation matrix. Finally, we\nshow that the IPR and IPR6 also change at high volatility periods.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05947v1"
    },
    {
        "title": "A First Option Calibration of the GARCH Diffusion Model by a PDE Method",
        "authors": [
            "Yiannis A. Papadopoulos",
            "Alan L. Lewis"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Time-series calibrations often suggest that the GARCH diffusion model could\nalso be a suitable candidate for option (risk-neutral) calibration. But unlike\nthe popular Heston model, it lacks a fast, semi-analytic solution for the\npricing of vanilla options, perhaps the main reason why it is not used in this\nway. In this paper we show how an efficient finite difference-based PDE solver\ncan effectively replace analytical solutions, enabling accurate option\ncalibrations in less than a minute. The proposed pricing engine is shown to be\nrobust under a wide range of model parameters and combines smoothly with\nblack-box optimizers. We use this approach to produce a first PDE calibration\nof the GARCH diffusion model to SPX options and present some benchmark results\nfor future reference.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.06141v1"
    },
    {
        "title": "Quantization Under the Real-world Measure: Fast and Accurate Valuation\n  of Long-dated Contracts",
        "authors": [
            "Ralph Rudd",
            "Thomas A. McWalter",
            "Joerg Kienitz",
            "Eckhard Platen"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  This paper provides a methodology for fast and accurate pricing of the\nlong-dated contracts that arise as the building blocks of insurance and pension\nfund agreements. It applies the recursive marginal quantization (RMQ) and joint\nrecursive marginal quantization (JRMQ) algorithms outside the framework of\ntraditional risk-neutral methods by pricing options under the real-world\nprobability measure, using the benchmark approach. The benchmark approach is\nreviewed, and the real-world pricing theorem is presented and applied to\nvarious long-dated claims to obtain less expensive prices than suggested by\ntraditional risk-neutral valuation. The growth-optimal portfolio (GOP), the\ncentral object of the benchmark approach, is modelled using the time-dependent\nconstant elasticity of variance model (TCEV). Analytic European option prices\nare derived and the RMQ algorithm is used to efficiently and accurately price\nBermudan options on the GOP. The TCEV model is then combined with a $3/2$\nstochastic short-rate model and RMQ is used to price zero-coupon bonds and\nzero-coupon bond options, highlighting the departure from risk-neutral pricing.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07044v2"
    },
    {
        "title": "Fourth order compact scheme for option pricing under Merton and Kou\n  jump-diffusion models",
        "authors": [
            "Kuldip Singh Patel",
            "Mani Mehra"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this article, a three-time levels compact scheme is proposed to solve the\npartial integro-differential equation governing the option prices under\njump-diffusion models. In the proposed compact scheme, the second derivative\napproximation of unknowns is approximated by the value of unknowns and their\nfirst derivative approximations which allow us to obtain a tri-diagonal system\nof linear equations for the fully discrete problem. Moreover, consistency and\nstability of the proposed compact scheme are proved. Due to the low regularity\nof typical initial conditions, the smoothing operator is employed to ensure the\nfourth-order convergence rate. Numerical illustrations for pricing European\noptions under Merton and Kou jump-diffusion models are presented to validate\nthe theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.07534v1"
    },
    {
        "title": "Compact finite difference method for pricing European and American\n  options under jump-diffusion models",
        "authors": [
            "Kuldip Singh Patel",
            "Mani Mehra"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this article, a compact finite difference method is proposed for pricing\nEuropean and American options under jump-diffusion models. Partial\nintegro-differential equation and linear complementary problem governing\nEuropean and American options respectively are discretized using Crank-Nicolson\nLeap-Frog scheme. In proposed compact finite difference method, the second\nderivative is approximated by the value of unknowns and their first derivative\napproximations which allow us to obtain a tri-diagonal system of linear\nequations for the fully discrete problem. Further, consistency and stability\nfor the fully discrete problem are also proved. Since jump-diffusion models do\nnot have smooth initial conditions, the smoothing operators are employed to\nensure fourth-order convergence rate. Numerical illustrations for pricing\nEuropean and American options under Merton jump-diffusion model are presented\nto validate the theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.09043v1"
    },
    {
        "title": "General multilevel Monte Carlo methods for pricing discretely monitored\n  Asian options",
        "authors": [
            "Nabil Kahale"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We describe general multilevel Monte Carlo methods that estimate the price of\nan Asian option monitored at $m$ fixed dates. Our approach yields unbiased\nestimators with standard deviation $O(\\epsilon)$ in $O(m + (1/\\epsilon)^{2})$\nexpected time for a variety of processes including the Black-Scholes model,\nMerton's jump-diffusion model, the Square-Root diffusion model, Kou's double\nexponential jump-diffusion model, the variance gamma and NIG exponential Levy\nprocesses and, via the Milstein scheme, processes driven by scalar stochastic\ndifferential equations. Using the Euler scheme, our approach estimates the\nAsian option price with root mean square error $O(\\epsilon)$ in\n$O(m+(\\ln(\\epsilon)/\\epsilon)^{2})$ expected time for processes driven by\nmultidimensional stochastic differential equations. Numerical experiments\nconfirm that our approach outperforms the conventional Monte Carlo method by a\nfactor of order $m$.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.09427v2"
    },
    {
        "title": "A Convergent Linear Regression Method for Forward-Backward Stochastic\n  Differential Equations with Jumps",
        "authors": [
            "Tingting Ye",
            "Liangliang Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we introduce a large class of convergent numerical methods,\nbased on (linear) basis function regression technique, to approximate the\nsolution to a forward-backward stochastic differential equation with jumps\n(FBSDEJ hereafter). Numerical experiment shows good applicability of the\nproposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.12105v4"
    },
    {
        "title": "Predicting digital asset market based on blockchain activity data",
        "authors": [
            "Zvezdin Besarabov",
            "Todor Kolev"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Blockchain technology shows significant results and huge potential for\nserving as an interweaving fabric that goes through every industry and market,\nallowing decentralized and secure value exchange, thus connecting our\ncivilization like never before. The standard approach for asset value\npredictions is based on market analysis with an LSTM neural network. Blockchain\ntechnologies, however, give us access to vast amounts of public data, such as\nthe executed transactions and the account balance distribution. We explore\nwhether analyzing this data with modern Deep Leaning techniques results in\nhigher accuracies than the standard approach. During a series of experiments on\nthe Ethereum blockchain, we achieved $4$ times error reduction with blockchain\ndata than an LSTM approach with trade volume data. By utilizing blockchain\naccount distribution histograms, spatial dataset modeling, and a Convolutional\narchitecture, the error was reduced further by 26\\%. The proposed methodologies\nare implemented in an open source cryptocurrency prediction framework, allowing\nthem to be used in other analysis contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.06696v1"
    },
    {
        "title": "High-order compact finite difference scheme for option pricing in\n  stochastic volatility with contemporaneous jump models",
        "authors": [
            "Bertram Düring",
            "Alexander Pitkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We extend the scheme developed in B. D\\\"uring, A. Pitkin, \"High-order compact\nfinite difference scheme for option pricing in stochastic volatility jump\nmodels\", 2019, to the so-called stochastic volatility with contemporaneous\njumps (SVCJ) model, derived by Duffie, Pan and Singleton. The performance of\nthe scheme is assessed through a number of numerical experiments, using\ncomparisons against a standard second-order central difference scheme. We\nobserve that the new high-order compact scheme achieves fourth order\nconvergence and discuss the effects on efficiency and computation time.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.13248v2"
    },
    {
        "title": "Calibrating rough volatility models: a convolutional neural network\n  approach",
        "authors": [
            "Henry Stone"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper we use convolutional neural networks to find the H\\\"older\nexponent of simulated sample paths of the rBergomi model, a recently proposed\nstock price model used in mathematical finance. We contextualise this as a\ncalibration problem, thereby providing a very practical and useful application.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.05315v3"
    },
    {
        "title": "Hierarchical adaptive sparse grids and quasi Monte Carlo for option\n  pricing under the rough Bergomi model",
        "authors": [
            "Christian Bayer",
            "Chiheb Ben Hammouda",
            "Raul Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The rough Bergomi (rBergomi) model, introduced recently in [5], is a\npromising rough volatility model in quantitative finance. It is a parsimonious\nmodel depending on only three parameters, and yet remarkably fits with\nempirical implied volatility surfaces. In the absence of analytical European\noption pricing methods for the model, and due to the non-Markovian nature of\nthe fractional driver, the prevalent option is to use the Monte Carlo (MC)\nsimulation for pricing. Despite recent advances in the MC method in this\ncontext, pricing under the rBergomi model is still a time-consuming task. To\novercome this issue, we have designed a novel, hierarchical approach, based on\ni) adaptive sparse grids quadrature (ASGQ), and ii) quasi-Monte Carlo (QMC).\nBoth techniques are coupled with a Brownian bridge construction and a\nRichardson extrapolation on the weak error. By uncovering the available\nregularity, our hierarchical methods demonstrate substantial computational\ngains with respect to the standard MC method, when reaching a sufficiently\nsmall relative error tolerance in the price estimates across different\nparameter constellations, even for very small values of the Hurst parameter.\nOur work opens a new research direction in this field, i.e., to investigate the\nperformance of methods other than Monte Carlo for pricing and calibrating under\nthe rBergomi model.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.08533v7"
    },
    {
        "title": "Gaussian Process Regression for Pricing Variable Annuities with\n  Stochastic Volatility and Interest Rate",
        "authors": [
            "Ludovic Goudenège",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper we investigate price and Greeks computation of a Guaranteed\nMinimum Withdrawal Benefit (GMWB) Variable Annuity (VA) when both stochastic\nvolatility and stochastic interest rate are considered together in the Heston\nHull-White model. We consider a numerical method the solves the dynamic control\nproblem due to the computing of the optimal withdrawal. Moreover, in order to\nspeed up the computation, we employ Gaussian Process Regression (GPR). Starting\nfrom observed prices previously computed for some known combinations of model\nparameters, it is possible to approximate the whole price function on a defined\ndomain. The regression algorithm consists of algorithm training and evaluation.\nThe first step is the most time demanding, but it needs to be performed only\nonce, while the latter is very fast and it requires to be performed only when\npredicting the target function. The developed method, as well as for the\ncalculation of prices and Greeks, can also be employed to compute the\nno-arbitrage fee, which is a common practice in the Variable Annuities sector.\nNumerical experiments show that the accuracy of the values estimated by GPR is\nhigh with very low computational cost. Finally, we stress out that the analysis\nis carried out for a GMWB annuity but it could be generalized to other\ninsurance products.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.00369v3"
    },
    {
        "title": "Variance Reduction Applied to Machine Learning for Pricing\n  Bermudan/American Options in High Dimension",
        "authors": [
            "Ludovic Goudenège",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper we propose an efficient method to compute the price of\nmulti-asset American options, based on Machine Learning, Monte Carlo\nsimulations and variance reduction technique. Specifically, the options we\nconsider are written on a basket of assets, each of them following a\nBlack-Scholes dynamics. In the wake of Ludkovski's approach (2018), we\nimplement here a backward dynamic programming algorithm which considers a\nfinite number of uniformly distributed exercise dates. On these dates, the\noption value is computed as the maximum between the exercise value and the\ncontinuation value, which is obtained by means of Gaussian process regression\ntechnique and Monte Carlo simulations. Such a method performs well for low\ndimension baskets but it is not accurate for very high dimension baskets. In\norder to improve the dimension range, we employ the European option price as a\ncontrol variate, which allows us to treat very large baskets and moreover to\nreduce the variance of price estimators. Numerical tests show that the proposed\nalgorithm is fast and reliable, and it can handle also American options on very\nlarge baskets of assets, overcoming the problem of the curse of dimensionality.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.11275v2"
    },
    {
        "title": "Discounted optimal stopping of a Brownian bridge, with application to\n  American options under pinning",
        "authors": [
            "Bernardo D'Auria",
            "Eduardo García-Portugués",
            "Abel Guada"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Mathematically, the execution of an American-style financial derivative is\ncommonly reduced to solving an optimal stopping problem. Breaking the general\nassumption that the knowledge of the holder is restricted to the price history\nof the underlying asset, we allow for the disclosure of future information\nabout the terminal price of the asset by modeling it as a Brownian bridge. This\nmodel may be used under special market conditions, in particular we focus on\nwhat in the literature is known as the \"pinning effect\", that is, when the\nprice of the asset approaches the strike price of a highly-traded option close\nto its expiration date. Our main mathematical contribution is in characterizing\nthe solution to the optimal stopping problem when the gain function includes\nthe discount factor. We show how to numerically compute the solution and we\nanalyze the effect of the volatility estimation on the strategy by computing\nthe confidence curves around the optimal stopping boundary. Finally, we compare\nour method with the optimal exercise time based on a geometric Brownian motion\nby using real data exhibiting pinning.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.11686v5"
    },
    {
        "title": "Image Processing Tools for Financial Time Series Classification",
        "authors": [
            "Bairui Du",
            "Delmiro Fernandez-Reyes",
            "Paolo Barucca"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The application of deep learning to time series forecasting is one of the\nmajor challenges in present machine learning. We propose a novel methodology\nthat combines machine learning and image processing methods to define and\npredict market states with intraday financial data. A wavelet transform is\napplied to the log-return of stock prices for both image extraction and\ndenoising. A convolutional neural network then extracts patterns from denoised\nwavelet images to classify daily time series, i.e. a market state is associated\nwith the binary prediction of the daily close price movement based on the\nwavelet image constructed from the price changes in the first hours of the day.\nThis method overcomes the low signal-to-noise ratio problem in financial time\nseries and gets a competitive prediction accuracy of the market states 'Up' and\n'Down' of financial data as tested on the S&P 500.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.06042v2"
    },
    {
        "title": "Analysis of Spin Financial Market by GARCH Model",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  A spin model is used for simulations of financial markets. To determine\nreturn volatility in the spin financial market we use the GARCH model often\nused for volatility estimation in empirical finance. We apply the Bayesian\ninference performed by the Markov Chain Monte Carlo method to the parameter\nestimation of the GARCH model. It is found that volatility determined by the\nGARCH model exhibits \"volatility clustering\" also observed in the real\nfinancial markets. Using volatility determined by the GARCH model we examine\nthe mixture-of-distribution hypothesis (MDH) suggested for the asset return\ndynamics. We find that the returns standardized by volatility are approximately\nstandard normal random variables. Moreover we find that the absolute\nstandardized returns show no significant autocorrelation. These findings are\nconsistent with the view of the MDH for the return dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.0118v1"
    },
    {
        "title": "Analytical and numerical results for American style of perpetual put\n  options through transformation into nonlinear stationary Black-Scholes\n  equations",
        "authors": [
            "Maria do Rosario Grossinho",
            "Yaser Faghan Kord",
            "Daniel Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We analyze and calculate the early exercise boundary for a class of\nstationary generalized Black-Scholes equations in which the volatility function\ndepends on the second derivative of the option price itself. A motivation for\nstudying the nonlinear Black Scholes equation with a nonlinear volatility\narises from option pricing models including, e.g., non-zero transaction costs,\ninvestors preferences, feedback and illiquid markets effects and risk from\nunprotected portfolio. We present a method how to transform the problem of\nAmerican style of perpetual put options into a solution of an ordinary\ndifferential equation and implicit equation for the free boundary position. We\nfinally present results of numerical approximation of the early exercise\nboundary, option price and their dependence on model parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.00356v1"
    },
    {
        "title": "Pricing American Call Options by the Black-Scholes Equation with a\n  Nonlinear Volatility Function",
        "authors": [
            "Maria do Rosario Grossinho",
            "Yaser Faghan Kord",
            "Daniel Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this paper we investigate a nonlinear generalization of the Black-Scholes\nequation for pricing American style call options in which the volatility term\nmay depend on the underlying asset price and the Gamma of the option. We\npropose a numerical method for pricing American style call options by means of\ntransformation of the free boundary problem for a nonlinear Black-Scholes\nequation into the so-called Gamma variational inequality with the new variable\ndepending on the Gamma of the option. We apply a modified projective successive\nover relaxation method in order to construct an effective numerical scheme for\ndiscretization of the Gamma variational inequality. Finally, we present several\ncomputational examples for the nonlinear Black-Scholes equation for pricing\nAmerican style call option under presence of variable transaction costs.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.00358v3"
    },
    {
        "title": "The Bitcoin price formation: Beyond the fundamental sources",
        "authors": [
            "Jamal Bouoiyour",
            "Refk Selmi"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Much significant research has been done to investigate various facets of the\nlink between Bitcoin price and its fundamental sources. This study goes beyond\nby looking into least to most influential factors-across the fundamental,\nmacroeconomic, financial, speculative and technical determinants as well as the\n2016 events-which drove the value of Bitcoin in times of economic and\ngeopolitical chaos. We use a Bayesian quantile regression to inspect how the\nstructure of dependence of Bitcoin price and its determinants varies across the\nentire conditional distribution of Bitcoin price movements. In doing so, three\ngroups of determinants were derived. The use of Bitcoin in trade and the\nuncertainty surrounding China's deepening slowdown, Brexit and India's\ndemonetization were found to be the most potential contributors of Bitcoin\nprice when the market is improving. The intense anxiety over Donald Trump being\nthe president of United States was shown to be a positive determinant pushing\nup the price of Bitcoin when the market is functioning around the normal mode.\nThe velocity of bitcoins in circulation, the gold price, the Venezuelan\ncurrency demonetization and the hash rate were found to be the fundamentals\ninfluencing the Bitcoin price when the market is heading into decline.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.01284v1"
    },
    {
        "title": "Forecasting the U.S. Real House Price Index",
        "authors": [
            "Vasilios Plakandaras",
            "Rangan Gupta",
            "Periklis Gogas",
            "Theophilos Papadimitriou"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The 2006 sudden and immense downturn in U.S. House Prices sparked the 2007\nglobal financial crisis and revived the interest about forecasting such\nimminent threats for economic stability. In this paper we propose a novel\nhybrid forecasting methodology that combines the Ensemble Empirical Mode\nDecomposition (EEMD) from the field of signal processing with the Support\nVector Regression (SVR) methodology that originates from machine learning. We\ntest the forecasting ability of the proposed model against a Random Walk (RW)\nmodel, a Bayesian Autoregressive and a Bayesian Vector Autoregressive model.\nThe proposed methodology outperforms all the competing models with half the\nerror of the RW model with and without drift in out-of-sample forecasting.\nFinally, we argue that this new methodology can be used as an early warning\nsystem for forecasting sudden house prices drops with direct policy\nimplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.04868v1"
    },
    {
        "title": "Pricing formulae for derivatives in insurance using the Malliavin\n  calculus",
        "authors": [
            "Caroline Hillairet",
            "Ying Jiao",
            "Anthony Réveillac"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this paper we provide a valuation formula for different classes of\nactuarial and financial contracts which depend on a general loss process, by\nusing the Malliavin calculus. In analogy with the celebrated Black-Scholes\nformula, we aim at expressing the expected cash flow in terms of a building\nblock. The former is related to the loss process which is a cumulated sum\nindexed by a doubly stochastic Poisson process of claims allowed to be\ndependent on the intensity and the jump times of the counting process. For\nexample, in the context of Stop-Loss contracts the building block is given by\nthe distribution function of the terminal cumulated loss, taken at the Value at\nRisk when computing the Expected Shortfall risk measure.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.05061v1"
    },
    {
        "title": "Agent Inspired Trading Using Recurrent Reinforcement Learning and LSTM\n  Neural Networks",
        "authors": [
            "David W. Lu"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  With the breakthrough of computational power and deep neural networks, many\nareas that we haven't explore with various techniques that was researched\nrigorously in past is feasible. In this paper, we will walk through possible\nconcepts to achieve robo-like trading or advising. In order to accomplish\nsimilar level of performance and generality, like a human trader, our agents\nlearn for themselves to create successful strategies that lead to the\nhuman-level long-term rewards. The learning model is implemented in Long Short\nTerm Memory (LSTM) recurrent structures with Reinforcement Learning or\nEvolution Strategies acting as agents The robustness and feasibility of the\nsystem is verified on GBPUSD trading.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.07338v1"
    },
    {
        "title": "Pricing Bitcoin Derivatives under Jump-Diffusion Models",
        "authors": [
            "Pablo Olivares"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In recent years cryptocurrency trading has captured the attention of\npractitioners and academics. The volume of the exchange with standard\ncurrencies has known a dramatic increasing of late. This paper addresses to the\nneed of models describing a bitcoin-US dollar exchange dynamic and their use to\nevaluate European option having bitcoin as underlying asset.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.07117v1"
    },
    {
        "title": "AutoAlpha: an Efficient Hierarchical Evolutionary Algorithm for Mining\n  Alpha Factors in Quantitative Investment",
        "authors": [
            "Tianping Zhang",
            "Yuanqi Li",
            "Yifei Jin",
            "Jian Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The multi-factor model is a widely used model in quantitative investment. The\nsuccess of a multi-factor model is largely determined by the effectiveness of\nthe alpha factors used in the model. This paper proposes a new evolutionary\nalgorithm called AutoAlpha to automatically generate effective formulaic alphas\nfrom massive stock datasets. Specifically, first we discover an inherent\npattern of the formulaic alphas and propose a hierarchical structure to quickly\nlocate the promising part of space for search. Then we propose a new Quality\nDiversity search based on the Principal Component Analysis (PCA-QD) to guide\nthe search away from the well-explored space for more desirable results. Next,\nwe utilize the warm start method and the replacement method to prevent the\npremature convergence problem. Based on the formulaic alphas we discover, we\npropose an ensemble learning-to-rank model for generating the portfolio. The\nbacktests in the Chinese stock market and the comparisons with several\nbaselines further demonstrate the effectiveness of AutoAlpha in mining\nformulaic alphas for quantitative trading.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08245v2"
    },
    {
        "title": "A hybrid approach for the implementation of the Heston model",
        "authors": [
            "Maya Briani",
            "Lucia Caramellino",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We propose a hybrid tree-finite difference method in order to approximate the\nHeston model. We prove the convergence by embedding the procedure in a\nbivariate Markov chain and we study the convergence of European and American\noption prices. We finally provide numerical experiments that give accurate\noption prices in the Heston model, showing the reliability and the efficiency\nof the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7178v4"
    },
    {
        "title": "Asymptotics for $d$-dimensional Lévy-type processes",
        "authors": [
            "Matthew Lorig",
            "Stefano Pagliarani",
            "Andrea Pascucci"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We consider a general d-dimensional Levy-type process with killing. Combining\nthe classical Dyson series approach with a novel polynomial expansion of the\ngenerator A(t) of the Levy-type process, we derive a family of asymptotic\napproximations for transition densities and European-style options prices.\nExamples of stochastic volatility models with jumps are provided in order to\nillustrate the numerical accuracy of our approach. The methods described in\nthis paper extend the results from Corielli et al. (2010), Pagliarani and\nPascucci (2013) and Lorig et al. (2013a) for Markov diffusions to Markov\nprocesses with jumps.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3153v2"
    },
    {
        "title": "Macroprudential oversight, risk communication and visualization",
        "authors": [
            "Peter Sarlin"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  This paper discusses the role of risk communication in macroprudential\noversight and of visualization in risk communication. Beyond the soar in data\navailability and precision, the transition from firm-centric to system-wide\nsupervision imposes vast data needs. Moreover, except for internal\ncommunication as in any organization, broad and effective external\ncommunication of timely information related to systemic risks is a key mandate\nof macroprudential supervisors, further stressing the importance of simple\nrepresentations of complex data. This paper focuses on the background and\ntheory of information visualization and visual analytics, as well as techniques\nwithin these fields, as potential means for risk communication. We define the\ntask of visualization in risk communication, discuss the structure of\nmacroprudential data, and review visualization techniques applied to systemic\nrisk. We conclude that two essential, yet rare, features for supporting the\nanalysis of big data and communication of risks are analytical visualizations\nand interactive interfaces. For visualizing the so-called macroprudential data\ncube, we provide the VisRisk platform with three modules: plots, maps and\nnetworks. While VisRisk is herein illustrated with five web-based interactive\nvisualizations of systemic risk indicators and models, the platform enables and\nis open to the visualization of any data from the macroprudential data cube.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4550v3"
    },
    {
        "title": "Leveraged {ETF} implied volatilities from {ETF} dynamics",
        "authors": [
            "Tim Leung",
            "Matthew Lorig",
            "Andrea Pascucci"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The growth of the exhange-traded fund (ETF) industry has given rise to the\ntrading of options written on ETFs and their leveraged counterparts {(LETFs)}.\nWe study the relationship between the ETF and LETF implied volatility surfaces\nwhen the underlying ETF is modeled by a general class of local-stochastic\nvolatility models. A closed-form approximation for prices is derived for\nEuropean-style options whose payoff depends on the terminal value of the ETF\nand/or LETF. Rigorous error bounds for this pricing approximation are\nestablished. A closed-form approximation for implied volatilities is also\nderived. We also discuss a scaling procedure for comparing implied volatilities\nacross leverage ratios. The implied volatility expansions and scalings are\ntested in three well-known settings: CEV, Heston and SABR.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6792v4"
    },
    {
        "title": "Approximations of Bond and Swaption Prices in a Black-Karasiński\n  Model",
        "authors": [
            "Andrzej Daniluk",
            "Rafał Muchorski"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We derive semi-analytic approximation formulae for bond and swaption prices\nin a Black-Karasi\\'{n}ski interest rate model. Approximations are obtained\nusing a novel technique based on the Karhunen-Lo\\`{e}ve expansion. Formulas are\neasily computable and prove to be very accurate in numerical tests. This makes\nthem useful for numerically efficient calibration of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.00697v1"
    },
    {
        "title": "Numerical analysis on local risk-minimization forexponential Lévy\n  models",
        "authors": [
            "Takuji Arai",
            "Yuto Imai",
            "Ryoichi Suzuki"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We illustrate how to compute local risk minimization (LRM) of call options\nfor exponential L\\'evy models. We have previously obtained a representation of\nLRM for call options; here we transform it into a form that allows use of the\nfast Fourier transform method suggested by Carr & Madan. In particular, we\nconsider Merton jump-diffusion models and variance gamma models as concrete\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.03898v1"
    },
    {
        "title": "Portfolio Optimization under Local-Stochastic Volatility: Coefficient\n  Taylor Series Approximations & Implied Sharpe Ratio",
        "authors": [
            "Matthew Lorig",
            "Ronnie Sircar"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We study the finite horizon Merton portfolio optimization problem in a\ngeneral local-stochastic volatility setting. Using model coefficient expansion\ntechniques, we derive approximations for the both the value function and the\noptimal investment strategy. We also analyze the `implied Sharpe ratio' and\nderive a series approximation for this quantity. The zeroth-order approximation\nof the value function and optimal investment strategy correspond to those\nobtained by Merton (1969) when the risky asset follows a geometric Brownian\nmotion. The first-order correction of the value function can, for general\nutility functions, be expressed as a differential operator acting on the\nzeroth-order term. For power utility functions, higher order terms can also be\ncomputed as a differential operator acting on the zeroth-order term. We give a\nrigorous accuracy bound for the higher order approximations in this case in\npure stochastic volatility models. A number of examples are provided in order\nto demonstrate numerically the accuracy of our approximations.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.06180v1"
    },
    {
        "title": "Nonparametric and arbitrage-free construction of call surfaces using\n  l1-recovery",
        "authors": [
            "Pierre M. Blacque-Florentin",
            "Badr Missaoui"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This paper is devoted to the application of an $l_1$ -minimisation technique\nto construct an arbitrage-free call-option surface. We propose a\nnononparametric approach to obtaining model-free call option surfaces that are\nperfectly consistent with market quotes and free of static arbitrage. The\napproach is inspired from the compressed-sensing framework that is used in\nsignal processing to deal with under-sampled signals. We address the problem of\nfitting the call-option surface to sparse option data. To illustrate the\nmethodology, we proceed to the construction of the whole call-price surface of\nthe S\\&P500 options, taking into account the arbitrage possibilities in the\ntime direction. The resulting object is a surface free of both butterfly and\ncalendar-spread arbitrage that matches the original market points. We then move\non to an FX application, namely the HKD/USD call-option surface.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.06997v2"
    },
    {
        "title": "Double-jump stochastic volatility model for VIX: evidence from VVIX",
        "authors": [
            "Xin Zang",
            "Jun Ni",
            "Jing-Zhi Huang",
            "Lan Wu"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  The paper studies the continuous-time dynamics of VIX with stochastic\nvolatility and jumps in VIX and volatility. Built on the general parametric\naffine model with stochastic volatility and jump in logarithm of VIX, we derive\na linear relation between the stochastic volatility factor and VVIX index. We\ndetect the existence of co-jump of VIX and VVIX and put forward a double-jump\nstochastic volatility model for VIX through its joint property with VVIX. With\nVVIX index as a proxy for the stochastic volatility, we use MCMC method to\nestimate the dynamics of VIX. Comparing nested models on VIX, we show the jump\nin VIX and the volatility factor is statistically significant. The jump\nintensity is also statedependent. We analyze the impact of jump factor on the\nVIX dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.07554v2"
    },
    {
        "title": "Option pricing in affine generalized Merton models",
        "authors": [
            "Christian Bayer",
            "John Schoenmakers"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  In this article we consider affine generalizations of the Merton jump\ndiffusion model [Merton, J. Fin. Econ., 1976] and the respective pricing of\nEuropean options. On the one hand, the Brownian motion part in the Merton model\nmay be generalized to a log-Heston model, and on the other hand, the jump part\nmay be generalized to an affine process with possibly state dependent jumps.\nWhile the characteristic function of the log-Heston component is known in\nclosed form, the characteristic function of the second component may be unknown\nexplicitly. For the latter component we propose an approximation procedure\nbased on the method introduced in [Belomestny et al., J. Func. Anal., 2009]. We\nconclude with some numerical examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.03677v1"
    },
    {
        "title": "Deep Learning Stock Volatility with Google Domestic Trends",
        "authors": [
            "Ruoxuan Xiong",
            "Eric P. Nichols",
            "Yuan Shen"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We have applied a Long Short-Term Memory neural network to model S&P 500\nvolatility, incorporating Google domestic trends as indicators of the public\nmood and macroeconomic factors. In a held-out test set, our Long Short-Term\nMemory model gives a mean absolute percentage error of 24.2%, outperforming\nlinear Ridge/Lasso and autoregressive GARCH benchmarks by at least 31%. This\nevaluation is based on an optimal observation and normalization scheme which\nmaximizes the mutual information between domestic trends and daily volatility\nin the training set. Our preliminary investigation shows strong promise for\nbetter predicting stock behavior via deep learning and neural network models.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.04916v3"
    },
    {
        "title": "Optimal decision for the market graph identification problem in sign\n  similarity network",
        "authors": [
            "V. A. Kalyagin",
            "P. A. Koldanov",
            "P. M. Pardalos"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Investigation of the market graph attracts a growing attention in market\nnetwork analysis. One of the important problem connected with market graph is\nto identify it from observations. Traditional way for the market graph\nidentification is to use a simple procedure based on statistical estimations of\nPearson correlations between pairs of stocks. Recently a new class of\nstatistical procedures for the market graph identification was introduced and\noptimality of these procedures in Pearson correlation Gaussian network was\nproved. However the obtained procedures have a high reliability only for\nGaussian multivariate distributions of stocks attributes. One of the way to\ncorrect this drawback is to consider a different networks generated by\ndifferent measures of pairwise similarity of stocks. A new and promising model\nin this context is the sign similarity network. In the present paper the market\ngraph identification problem in sign similarity network is considered. A new\nclass of statistical procedures for the market graph identification is\nintroduced and optimality of these procedures is proved. Numerical experiments\ndetect essential difference in quality of optimal procedures in sign similarity\nand Pearson correlation networks. In particular it is observed that the quality\nof optimal identification procedure in sign similarity network is not sensitive\nto the assumptions on distribution of stocks attributes.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.06449v1"
    },
    {
        "title": "Numerical analysis of an extended structural default model with mutual\n  liabilities and jump risk",
        "authors": [
            "Vadim Kaushansky",
            "Alexander Lipton",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We consider a structural default model in an interconnected banking network\nas in Lipton [International Journal of Theoretical and Applied Finance, 19(6),\n2016], with mutual obligations between each pair of banks. We analyse the model\nnumerically for two banks with jumps in their asset value processes.\nSpecifically, we develop a finite difference method for the resulting\ntwo-dimensional partial integro-differential equation, and study its stability\nand consistency. We then compute joint and marginal survival probabilities, as\nwell as prices of credit default swaps (CDS), first-to-default swaps (FTD),\ncredit and debt value adjustments (CVA and DVA). Finally, we calibrate the\nmodel to market data and assess the impact of jump risk.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.00030v1"
    },
    {
        "title": "Chebyshev Reduced Basis Function applied to Option Valuation",
        "authors": [
            "Javier de Frutos",
            "Victor Gaton"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We present a numerical method for the frequent pricing of financial\nderivatives that depends on a large number of variables. The method is based on\nthe construction of a polynomial basis to interpolate the value function of the\nproblem by means of a hierarchical orthogonalization process that allows to\nreduce the number of degrees of freedom needed to have an accurate\nrepresentation of the value function. In the paper we consider, as an example,\na GARCH model that depends on eight parameters and show that a very large\nnumber of contracts for different maturities and asset and parameters values\ncan be valued in a small computational time with the proposed procedure. In\nparticular the method is applied to the problem of model calibration. The\nmethod is easily generalizable to be used with other models or problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.01429v2"
    },
    {
        "title": "Analytic properties of American option prices under a modified\n  Black-Scholes equation with spatial fractional derivatives",
        "authors": [
            "Wenting Chen",
            "Kai Du",
            "Xinzi Qiu"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This paper investigates analytic properties of American option prices under\nthe finite moment log-stable (FMLS) model. Under this model the price of\nAmerican options is characterised by the free boundary problem of a fractional\npartial differential equation (FPDE) system. Using the technique of\napproximation we prove that the American put price under the FMLS model is\nconvex with respect the underlying price, and specify the impact of the tail\nindex on option prices.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.01515v1"
    },
    {
        "title": "A Spatial Interpolation Framework for Efficient Valuation of Large\n  Portfolios of Variable Annuities",
        "authors": [
            "Seyed Amir Hejazi",
            "Kenneth R. Jackson",
            "Guojun Gan"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Variable Annuity (VA) products expose insurance companies to considerable\nrisk because of the guarantees they provide to buyers of these products.\nManaging and hedging these risks requires insurers to find the value of key\nrisk metrics for a large portfolio of VA products. In practice, many companies\nrely on nested Monte Carlo (MC) simulations to find key risk metrics. MC\nsimulations are computationally demanding, forcing insurance companies to\ninvest hundreds of thousands of dollars in computational infrastructure per\nyear. Moreover, existing academic methodologies are focused on fair valuation\nof a single VA contract, exploiting ideas in option theory and regression. In\nmost cases, the computational complexity of these methods surpasses the\ncomputational requirements of MC simulations. Therefore, academic methodologies\ncannot scale well to large portfolios of VA contracts. In this paper, we\npresent a framework for valuing such portfolios based on spatial interpolation.\nWe provide a comprehensive study of this framework and compare existing\ninterpolation schemes. Our numerical results show superior performance, in\nterms of both computational efficiency and accuracy, for these methods compared\nto nested MC simulations. We also present insights into the challenge of\nfinding an effective interpolation scheme in this framework, and suggest\nguidelines that help us build a fully automated scheme that is efficient and\naccurate.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.04134v1"
    },
    {
        "title": "Approaches to Asian Option Pricing with Discrete Dividends",
        "authors": [
            "Jacob Lundgren",
            "Yuri Shpolyanskiy"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The method and characteristics of several approaches to the pricing of\ndiscretely monitored arithmetic Asian options on stocks with discrete, absolute\ndividends are described. The contrast between method behaviors for options with\nan Asian tail and those with monitoring throughout their lifespan is\nemphasized. Rates of convergence are confirmed, but greater focus is put on\nactual performance in regions of accuracy which are realistic for use by\npractitioners. A hybrid approach combining Curran's analytical approximation\nwith a two-dimensional finite difference method is examined with respect to the\nerrors caused by the approximating assumptions. For Asian tails of equidistant\nmonitoring dates, this method performs very well, but as the scenario deviates\nfrom the method's ideal conditions, the errors in the approximation grow\nunfeasible. For general monitoring straightforward solution of the full\nthree-dimensional partial differential equation by finite differences is highly\naccurate but suffers from rapid degradation in performance as the monitoring\ninterval increases. For options with long monitoring intervals a randomized\nquasi-Monte Carlo method with control variate variance reduction stands out as\na powerful alternative.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.00994v2"
    },
    {
        "title": "Invariance properties in the dynamic gaussian copula model *",
        "authors": [
            "Stéphane Crépey",
            "Shiqi Song"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We prove that the default times (or any of their minima) in the dynamic\nGaussian copula model of Cr{\\'e}pey, Jeanblanc, and Wu (2013) are invariance\ntimes in the sense of Cr{\\'e}pey and Song (2017), with related invariance\nprobability measures different from the pricing measure. This reflects a\ndeparture from the immersion property, whereby the default intensities of the\nsurviving names and therefore the value of credit protection spike at default\ntimes. These properties are in line with the wrong-way risk feature of\ncounterparty risk embedded in credit derivatives, i.e. the adverse dependence\nbetween the default risk of a counterparty and an underlying credit derivative\nexposure.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.03232v1"
    },
    {
        "title": "Estimating VaR in credit risk: Aggregate vs single loss distribution",
        "authors": [
            "M. Assadsolimani",
            "D. Chetalova"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Using Monte Carlo simulation to calculate the Value at Risk (VaR) as a\npossible risk measure requires adequate techniques. One of these techniques is\nthe application of a compound distribution for the aggregates in a portfolio.\nIn this paper, we consider the aggregated loss of Gamma distributed severities\nand estimate the VaR by introducing a new approach to calculate the quantile\nfunction of the Gamma distribution at high confidence levels. We then compare\nthe VaR obtained from the aggregation process with the VaR obtained from a\nsingle loss distribution where the severities are drawn first from an\nexponential and then from a truncated exponential distribution. We observe that\nthe truncated exponential distribution as a model for the severities yields\nresults closer to those obtained from the aggregation process. The deviations\ndepend strongly on the number of obligors in the portfolio, but also on the\namount of gross loss which truncates the exponential distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.04388v1"
    },
    {
        "title": "PyCaMa: Python for cash management",
        "authors": [
            "Francisco Salas-Molina",
            "Juan A. Rodríguez-Aguilar",
            "Pablo Díaz-García"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Selecting the best policy to keep the balance between what a company holds in\ncash and what is placed in alternative investments is by no means\nstraightforward. We here introduce PyCaMa, a Python module for multiobjective\ncash management based on linear programming that allows to derive optimal\npolicies for cash management with multiple bank accounts in terms of both cost\nand risk of policies.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.05005v2"
    },
    {
        "title": "Probability density of lognormal fractional SABR model",
        "authors": [
            "Jiro Akahori",
            "Xiaoming Song",
            "Tai-Ho Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Instantaneous volatility of logarithmic return in the lognormal fractional\nSABR model is driven by the exponentiation of a correlated fractional Brownian\nmotion. Due to the mixed nature of driving Brownian and fractional Brownian\nmotions, probability density for such a model is less studied in the\nliterature. We show in this paper a bridge representation for the joint density\nof the lognormal fractional SABR model in a Fourier space. Evaluating the\nbridge representation along a properly chosen deterministic path yields a small\ntime asymptotic expansion to the leading order for the probability density of\nthe fractional SABR model. A direct generalization of the representation to\njoint density at multiple times leads to a heuristic derivation of the large\ndeviations principle for the joint density in small time. Approximation of\nimplied volatility is readily obtained by applying the Laplace asymptotic\nformula to the call or put prices and comparing coefficients.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.08081v2"
    },
    {
        "title": "The Chebyshev method for the implied volatility",
        "authors": [
            "Kathrin Glau",
            "Paul Herold",
            "Dilip B. Madan",
            "Christian Pötz"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The implied volatility is a crucial element of any financial toolbox, since\nit is used for quoting and the hedging of options as well as for model\ncalibration. In contrast to the Black-Scholes formula its inverse, the implied\nvolatility, is not explicitly available and numerical approximation is\nrequired. We propose a bivariate interpolation of the implied volatility\nsurface based on Chebyshev polynomials. This yields a closed-form approximation\nof the implied volatility, which is easy to implement and to maintain. We prove\na subexponential error decay. This allows us to obtain an accuracy close to\nmachine precision with polynomials of a low degree. We compare the performance\nof the method in terms of runtime and accuracy to the most common reference\nmethods. In contrast to existing interpolation methods, the proposed method is\nable to compute the implied volatility for all relevant option data. In this\ncontext, numerical experiments confirm a considerable increase in efficiency,\nespecially for large data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.01797v1"
    },
    {
        "title": "Computational Analysis of the structural properties of Economic and\n  Financial Networks",
        "authors": [
            "Frank Emmert-Streib",
            "Aliyu Musa",
            "Kestutis Baltakys",
            "Juho Kanniainen",
            "Shailesh Tripathi",
            "Olli Yli-Harja",
            "Herbert Jodlbauer",
            "Matthias Dehmer"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In recent years, methods from network science are gaining rapidly interest in\neconomics and finance. A reason for this is that in a globalized world the\ninterconnectedness among economic and financial entities are crucial to\nunderstand and networks provide a natural framework for representing and\nstudying such systems. In this paper, we are surveying the use of networks and\nnetwork-based methods for studying economy related questions. We start with a\nbrief overview of graph theory and basic definitions. Then we discuss\ndescriptive network measures and network complexity measures for quantifying\nstructural properties of economic networks. Finally, we discuss different\nnetwork and tree structures as relevant for applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.04455v1"
    },
    {
        "title": "Efficient hedging in Bates model using high-order compact finite\n  differences",
        "authors": [
            "Bertram Düring",
            "Alexander Pitkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We evaluate the hedging performance of a high-order compact finite difference\nscheme from [4] for option pricing in Bates model. We compare the scheme's\nhedging performance to standard finite difference methods in different\nexamples. We observe that the new scheme outperforms a standard, second-order\ncentral finite difference approximation in all our experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.05542v1"
    },
    {
        "title": "$ε$-Monotone Fourier Methods for Optimal Stochastic Control in\n  Finance",
        "authors": [
            "Peter A. Forsyth",
            "George Labahn"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Stochastic control problems in finance often involve complex controls at\ndiscrete times. As a result numerically solving such problems, for example\nusing methods based on partial differential or integro-differential equations,\ninevitably give rise to low order accuracy, usually at most second order. In\nmany cases one can make use of Fourier methods to efficiently advance solutions\nbetween control monitoring dates and then apply numerical optimization methods\nacross decision times. However Fourier methods are not monotone and as a result\ngive rise to possible violations of arbitrage inequalities. This is problematic\nin the context of control problems, where the control is determined by\ncomparing value functions. In this paper we give a preprocessing step for\nFourier methods which involves projecting the Green's function onto the set of\nlinear basis functions. The resulting algorithm is guaranteed to be monotone\n(to within a tolerance), $\\ell_\\infty$-stable and satisfies an\n$\\epsilon$-discrete comparison principle. In addition the algorithm has the\nsame complexity per step as a standard Fourier method while at the same time\nhaving second order accuracy for smooth problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08450v2"
    },
    {
        "title": "Polynomial processes for power prices",
        "authors": [
            "Damir Filipovic",
            "Martin Larsson",
            "Tony Ware"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Polynomial processes have the property that expectations of polynomial\nfunctions (of degree $n$, say) of the future state of the process conditional\non the current state are given by polynomials (of degree $\\leq n$) of the\ncurrent state. Here we explore the application of polynomial processes in the\ncontext of structural models for energy prices. We focus on the example of\nAlberta power prices, derive one- and two-factor models for spot prices. We\nexamine their performance in numerical experiments, and demonstrate that the\nrichness of the dynamics they are able to generate makes them well suited for\nmodelling even extreme examples of energy price behaviour.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.10293v2"
    },
    {
        "title": "Dual control Monte Carlo method for tight bounds of value function under\n  Heston stochastic volatility model",
        "authors": [
            "Jingtang Ma",
            "Wenyuan Li",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The aim of this paper is to study the fast computation of the lower and upper\nbounds on the value function for utility maximization under the Heston\nstochastic volatility model with general utility functions. It is well known\nthere is a closed form solution of the HJB equation for power utility due to\nits homothetic property. It is not possible to get closed form solution for\ngeneral utilities and there is little literature on the numerical scheme to\nsolve the HJB equation for the Heston model. In this paper we propose an\nefficient dual control Monte Carlo method for computing tight lower and upper\nbounds of the value function. We identify a particular form of the dual control\nwhich leads to the closed form upper bound for a class of utility functions,\nincluding power, non-HARA and Yarri utilities. Finally, we perform some\nnumerical tests to see the efficiency, accuracy, and robustness of the method.\nThe numerical results support strongly our proposed scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.10487v1"
    },
    {
        "title": "Machine learning with kernels for portfolio valuation and risk\n  management",
        "authors": [
            "Lotfi Boudabsa",
            "Damir Filipovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We introduce a simulation method for dynamic portfolio valuation and risk\nmanagement building on machine learning with kernels. We learn the dynamic\nvalue process of a portfolio from a finite sample of its cumulative cash flow.\nThe learned value process is given in closed form thanks to a suitable choice\nof the kernel. We show asymptotic consistency and derive finite sample error\nbounds under conditions that are suitable for finance applications. Numerical\nexperiments show good results in large dimensions for a moderate training\nsample size.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.03726v8"
    },
    {
        "title": "Evaluating the Performance of Machine Learning Algorithms in Financial\n  Market Forecasting: A Comprehensive Survey",
        "authors": [
            "Lukas Ryll",
            "Sebastian Seidens"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  With increasing competition and pace in the financial markets, robust\nforecasting methods are becoming more and more valuable to investors. While\nmachine learning algorithms offer a proven way of modeling non-linearities in\ntime series, their advantages against common stochastic models in the domain of\nfinancial market prediction are largely based on limited empirical results. The\nsame holds true for determining advantages of certain machine learning\narchitectures against others. This study surveys more than 150 related articles\non applying machine learning to financial market forecasting. Based on a\ncomprehensive literature review, we build a table across seven main parameters\ndescribing the experiments conducted in these studies. Through listing and\nclassifying different algorithms, we also introduce a simple, standardized\nsyntax for textually representing machine learning algorithms. Based on\nperformance metrics gathered from papers included in the survey, we further\nconduct rank analyses to assess the comparative performance of different\nalgorithm classes. Our analysis shows that machine learning algorithms tend to\noutperform most traditional stochastic methods in financial market forecasting.\nWe further find evidence that, on average, recurrent neural networks outperform\nfeed forward neural networks as well as support vector machines which implies\nthe existence of exploitable temporal dependencies in financial time series\nacross multiple asset classes and geographies.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.07786v2"
    },
    {
        "title": "Mean-variance portfolio selection with tracking error penalization",
        "authors": [
            "William Lefebvre",
            "Gregoire Loeper",
            "Huyên Pham"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper studies a variation of the continuous-time mean-variance portfolio\nselection where a tracking-error penalization is added to the mean-variance\ncriterion. The tracking error term penalizes the distance between the\nallocation controls and a reference portfolio with same wealth and fixed\nweights. Such consideration is motivated as follows: (i) On the one hand, it is\na way to robustify the mean-variance allocation in case of misspecified\nparameters, by \"fitting\" it to a reference portfolio that can be agnostic to\nmarket parameters; (ii) On the other hand, it is a procedure to track a\nbenchmark and improve the Sharpe ratio of the resulting portfolio by\nconsidering a mean-variance criterion in the objective function. This problem\nis formulated as a McKean-Vlasov control problem. We provide explicit solutions\nfor the optimal portfolio strategy and asymptotic expansions of the portfolio\nstrategy and efficient frontier for small values of the tracking error\nparameter. Finally, we compare the Sharpe ratios obtained by the standard\nmean-variance allocation and the penalized one for four different reference\nportfolios: equal-weights, minimum-variance, equal risk contributions and\nshrinking portfolio. This comparison is done on a simulated misspecified model,\nand on a backtest performed with historical data. Our results show that in most\ncases, the penalized portfolio outperforms in terms of Sharpe ratio both the\nstandard mean-variance and the reference portfolio.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.08214v2"
    },
    {
        "title": "Short dated smile under Rough Volatility: asymptotics and numerics",
        "authors": [
            "Peter K. Friz",
            "Paul Gassiat",
            "Paolo Pigato"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In [Precise Asymptotics for Robust Stochastic Volatility Models; Ann. Appl.\nProbab. 2021] we introduce a new methodology to analyze large classes of\n(classical and rough) stochastic volatility models, with special regard to\nshort-time and small noise formulae for option prices, using the framework\n[Bayer et al; A regularity structure for rough volatility; Math. Fin. 2020]. We\ninvestigate here the fine structure of this expansion in large deviations and\nmoderate deviations regimes, together with consequences for implied volatility.\nWe discuss computational aspects relevant for the practical application of\nthese formulas. We specialize such expansions to prototypical rough volatility\nexamples and discuss numerical evidence.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.08814v2"
    },
    {
        "title": "Explicit solution simulation method for the 3/2 model",
        "authors": [
            "Iro René Kouarfate",
            "Michael A. Kouritzin",
            "Anne MacKay"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  An explicit weak solution for the 3/2 stochastic volatility model is obtained\nand used to develop a simulation algorithm for option pricing purposes. The 3/2\nmodel is a non-affine stochastic volatility model whose variance process is the\ninverse of a CIR process. This property is exploited here to obtain an explicit\nweak solution, similarly to Kouritzin (2018). A simulation algorithm based on\nthis solution is proposed and tested via numerical examples. The performance of\nthe resulting pricing algorithm is comparable to that of other popular\nsimulation algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.09058v2"
    },
    {
        "title": "A robust tree method for pricing American options with CIR stochastic\n  interest rate",
        "authors": [
            "Elisa Appolloni",
            "Lucia Caramellino",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We propose a robust and stable lattice method which permits to obtain very\naccurate American option prices in presence of CIR stochastic interest rate\nwithout any numerical restriction on its parameters. Numerical results show the\nreliability and the accuracy of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.0479v1"
    },
    {
        "title": "Monte Carlo approximation to optimal investment",
        "authors": [
            "L C G Rogers",
            "Pawel Zaczkowski"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This paper sets up a methodology for approximately solving optimal investment\nproblems using duality methods combined with Monte Carlo simulations. In\nparticular, we show how to tackle high dimensional problems in incomplete\nmarkets, where traditional methods fail due to the curse of dimensionality.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.3433v1"
    },
    {
        "title": "Calibration to American Options: Numerical Investigation of the\n  de-Americanization",
        "authors": [
            "Olena Burkovska",
            "Maximilian Gaß",
            "Kathrin Glau",
            "Mirco Mahlstedt",
            "Wim Schoutens",
            "Barbara Wohlmuth"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  American options are the reference instruments for the model calibration of a\nlarge and important class of single stocks. For this task, a fast and accurate\npricing algorithm is indispensable. The literature mainly discusses pricing\nmethods for American options that are based on Monte Carlo, tree and partial\ndifferential equation methods. We present an alternative approach that has\nbecome popular under the name de-Americanization in the financial industry. The\nmethod is easy to implement and enjoys fast run-times. Since it is based on ad\nhoc simplifications, however, theoretical results guaranteeing reliability are\nnot available. To quantify the resulting methodological risk, we empirically\ntest the performance of the de-Americanization method for calibration. We\nclassify the scenarios in which de-Americanization performs very well. However,\nwe also identify the cases where de-Americanization oversimplifies and can\nresult in large errors.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.06181v1"
    },
    {
        "title": "Regression-based complexity reduction of the nested Monte Carlo methods",
        "authors": [
            "Denis Belomestny",
            "Stefan Häfner",
            "Mikhail Urusov"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  In this paper we propose a novel dual regression-based approach for pricing\nAmerican options. This approach reduces the complexity of the nested Monte\nCarlo method and has especially simple form for time discretised diffusion\nprocesses. We analyse the complexity of the proposed approach both in the case\nof fixed and increasing number of exercise dates. The method is illustrated by\nseveral numerical examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.06344v4"
    },
    {
        "title": "Stratified regression-based variance reduction approach for weak\n  approximation schemes",
        "authors": [
            "Denis Belomestny",
            "Stefan Häfner",
            "Mikhail Urusov"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  In this paper we suggest a modification of the regression-based variance\nreduction approach recently proposed in Belomestny et al. This modification is\nbased on the stratification technique and allows for a further significant\nvariance reduction. The performance of the proposed approach is illustrated by\nseveral numerical examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.05255v2"
    },
    {
        "title": "Non-linear Time Series and Artificial Neural Networks of Red Hat\n  Volatility",
        "authors": [
            "José Igor Morlanes"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We extend the empirical results published in article \"Empirical Evidence on\nArbitrage by Changing the Stock Exchange\" by means of machine learning and\nadvanced econometric methodologies based on Smooth Transition Regression models\nand Artificial Neural Networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.01070v1"
    },
    {
        "title": "Estimating option prices using multilevel particle filters",
        "authors": [
            "P. P. Osei",
            "A. Jasra"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Option valuation problems are often solved using standard Monte Carlo (MC)\nmethods. These techniques can often be enhanced using several strategies\nespecially when one discretizes the dynamics of the underlying asset, of which\nwe assume follows a diffusion process. We consider the combination of two\nmethodologies in this direction. The first is the well-known multilevel Monte\nCarlo (MLMC) method, which is known to reduce the computational effort to\nachieve a given level of mean square error relative to MC in some cases.\nSequential Monte Carlo (or the particle filter (PF)) methods have also been\nshown to be beneficial in many option pricing problems potentially reducing\nvariances by large magnitudes (relative to MC). We propose a multilevel\nparticle filter (MLPF) as an alternative approach to price options. The\ncomputational savings obtained in using MLPF over PF for pricing both vanilla\nand exotic options is demonstrated via numerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.01734v1"
    },
    {
        "title": "On The Calibration of Short-Term Interest Rates Through a CIR Model",
        "authors": [
            "Giuseppe Orlando",
            "Rosa Maria Mininni",
            "Michele Bufalo"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  It is well known that the Cox-Ingersoll-Ross (CIR) stochastic model to study\nthe term structure of interest rates, as introduced in 1985, is inadequate for\nmodelling the current market environment with negative short interest rates.\nMoreover, the diffusion term in the rate dynamics goes to zero when short rates\nare small; both volatility and long-run mean do not change with time; they do\nnot fit with the skewed (fat tails) distribution of the interest rates, etc.\nThe aim of the present work is to suggest a new framework, which we call the\nCIR\\# model, that well fits the term structure of short interest rates so that\nthe market volatility structure is preserved as well as the analytical\ntractability of the original CIR model.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.03683v1"
    },
    {
        "title": "A new approach for American option pricing: The Dynamic Chebyshev method",
        "authors": [
            "Kathrin Glau",
            "Mirco Mahlstedt",
            "Christian Pötz"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We introduce a new method to price American options based on Chebyshev\ninterpolation. In each step of a dynamic programming time-stepping we\napproximate the value function with Chebyshev polynomials. The key advantage of\nthis approach is that it allows to shift the model-dependent computations into\nan offline phase prior to the time-stepping. In the offline part a family of\ngeneralised (conditional) moments is computed by an appropriate numerical\ntechnique such as a Monte Carlo, PDE or Fourier transform based method. Thanks\nto this methodological flexibility the approach applies to a large variety of\nmodels. Online, the backward induction is solved on a discrete Chebyshev grid,\nand no (conditional) expectations need to be computed. For each time step the\nmethod delivers a closed form approximation of the price function along with\nthe options' delta and gamma. Moreover, the same family of (conditional)\nmoments yield multiple outputs including the option prices for different\nstrikes, maturities and different payoff profiles. We provide a theoretical\nerror analysis and find conditions that imply explicit error bounds for a\nvariety of stock price models. Numerical experiments confirm the fast\nconvergence of prices and sensitivities. An empirical investigation of accuracy\nand runtime also shows an efficiency gain compared with the least-square\nMonte-Carlo method introduced by Longstaff and Schwartz (2001).\n",
        "pdf_link": "http://arxiv.org/pdf/1806.05579v1"
    },
    {
        "title": "Static and semi-static hedging as contrarian or conformist bets",
        "authors": [
            "Svetlana Boyarchenko",
            "Sergei Levendorskii"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper, we argue that, once the costs of maintaining the hedging\nportfolio are properly taken into account, semi-static portfolios should more\nproperly be thought of as separate classes of derivatives, with non-trivial,\nmodel-dependent payoff structures. We derive new integral representations for\npayoffs of exotic European options in terms of payoffs of vanillas, different\nfrom Carr-Madan representation, and suggest approximations of the idealized\nstatic hedging/replicating portfolio using vanillas available in the market. We\nstudy the dependence of the hedging error on a model used for pricing and show\nthat the variance of the hedging errors of static hedging portfolios can be\nsizably larger than the errors of variance-minimizing portfolios. We explain\nwhy the exact semi-static hedging of barrier options is impossible for\nprocesses with jumps, and derive general formulas for variance-minimizing\nsemi-static portfolio. We show that hedging using vanillas only leads to larger\nerrors than hedging using vanillas and first touch digitals. In all cases,\nefficient calculations of the weights of the hedging portfolios are in the dual\nspace using new efficient numerical methods for calculation of the Wiener-Hopf\nfactors and Laplace-Fourier inversion.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.02854v1"
    },
    {
        "title": "Physics and Derivatives: Effective-Potential Path-Integral\n  Approximations of Arrow-Debreu Densities",
        "authors": [
            "Luca Capriotti",
            "Ruggero Vaia"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We show how effective-potential path-integrals methods, stemming on a simple\nand nice idea originally due to Feynman and successfully employed in Physics\nfor a variety of quantum thermodynamics applications, can be used to develop an\naccurate and easy-to-compute semi-analytical approximation of transition\nprobabilities and Arrow-Debreu densities for arbitrary diffusions. We\nillustrate the accuracy of the method by presenting results for the\nBlack-Karasinski and the GARCH linear models, for which the proposed\napproximation provides remarkably accurate results, even in regimes of high\nvolatility, and for multi-year time horizons. The accuracy and the\ncomputational efficiency of the proposed approximation makes it a viable\nalternative to fully numerical schemes for a variety of derivatives pricing\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.03610v1"
    },
    {
        "title": "Low-rank tensor approximation for Chebyshev interpolation in parametric\n  option pricing",
        "authors": [
            "Kathrin Glau",
            "Daniel Kressner",
            "Francesco Statti"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Treating high dimensionality is one of the main challenges in the development\nof computational methods for solving problems arising in finance, where tasks\nsuch as pricing, calibration, and risk assessment need to be performed\naccurately and in real-time. Among the growing literature addressing this\nproblem, Gass et al. [14] propose a complexity reduction technique for\nparametric option pricing based on Chebyshev interpolation. As the number of\nparameters increases, however, this method is affected by the curse of\ndimensionality. In this article, we extend this approach to treat\nhigh-dimensional problems: Additionally exploiting low-rank structures allows\nus to consider parameter spaces of high dimensions. The core of our method is\nto express the tensorized interpolation in tensor train (TT) format and to\ndevelop an efficient way, based on tensor completion, to approximate the\ninterpolation coefficients. We apply the new method to two model problems:\nAmerican option pricing in the Heston model and European basket option pricing\nin the multi-dimensional Black-Scholes model. In these examples we treat\nparameter spaces of dimensions up to 25. The numerical results confirm the\nlow-rank structure of these problems and the effectiveness of our method\ncompared to advanced techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.04367v1"
    },
    {
        "title": "Building arbitrage-free implied volatility: Sinkhorn's algorithm and\n  variants",
        "authors": [
            "Hadrien De March",
            "Pierre Henry-Labordere"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We consider the classical problem of building an arbitrage-free implied\nvolatility surface from bid-ask quotes. We design a fast numerical procedure,\nfor which we prove the convergence, based on the Sinkhorn algorithm that has\nbeen recently used to solve efficiently (martingale) optimal transport\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.04456v3"
    },
    {
        "title": "PDE models for the valuation of a non callable defaultable coupon bond\n  under an extended JDCEV model",
        "authors": [
            "M. C. Calvo-Garrido",
            "S. Diop",
            "A. Pascucci",
            "C. Vázquez"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We consider a two-factor model for the valuation of a non callable\ndefaultable bond which pays coupons at certain given dates. The model under\nconsideration is the Jump to Default Constant Elasticity of Variance (JDCEV)\nmodel. The JDCEV model is an improvement of the reduced form approach, which\nunifies credit and equity models into a single framework allowing for\nstochastic and possible negative interest rates. From the mathematical point of\nview, the valuation involves two partial differential equation (PDE) problems\nfor each coupon. First, we obtain the existence of solution for these PDE\nproblems. In order to solve them, we propose appropriate numerical schemes\nbased on a Crank-Nicolson semi-Lagrangian method for time discretization\ncombined with bi-quadratic Lagrange finite elements for space discretization.\nOnce the numerical solutions of the PDEs are obtained, a post-processing\nprocedure is carried out in order to achieve the value of the bond. This\npost-processing includes the computation of an integral term which is\napproximated by using the composite trapezoidal rule. Finally, we present some\nnumerical results for real market bonds issued by different firms in order to\nillustrate the proper behaviour of the numerical schemes. Moreover, we obtain\nan agreement between the numerical results from the PDE approach and those ones\nobtained by applying a Monte Carlo technique and an asymptotic approximation\nmethod.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01099v1"
    },
    {
        "title": "Higher order approximation of call option prices under stochastic\n  volatility models",
        "authors": [
            "Archil Gulisashvili",
            "Raúl Merino",
            "Marc Lagunas",
            "Josep Vives"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In the present paper, a decomposition formula for the call price due to\nAl\\`{o}s is transformed into a Taylor type formula containing an infinite\nseries with stochastic terms. The new decomposition may be considered as an\nalternative to the decomposition of the call price found in a recent paper of\nAl\\`{o}s, Gatheral and Radoi\\v{c}i\\'{c}. We use the new decomposition to obtain\nvarious approximations to the call price in the Heston model with sharper\nestimates of the error term than in the previously known approximations. One of\nthe formulas obtained in the present paper has five significant terms and an\nerror estimate of the form $O(\\nu^{3}(\\left|\\rho\\right|+\\nu))$, where $\\nu$ is\nthe vol-vol parameter, and $\\rho$ is the correlation coefficient between the\nprice and the volatility in the Heston model. Another approximation formula\ncontains seven more terms and the error estimate is of the form\n$O(\\nu^4(1+|\\rho|)$. For the uncorrelated Hestom model ($\\rho=0$), we obtain a\nformula with four significant terms and an error estimate $O(\\nu^6)$. Numerical\nexperiments show that the new approximations to the call price perform\nespecially well in the high volatility mode.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.06315v1"
    },
    {
        "title": "A simple and efficient numerical method for pricing discretely monitored\n  early-exercise options",
        "authors": [
            "Min Huang",
            "Guo Luo"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We present a simple, fast, and accurate method for pricing a variety of\ndiscretely monitored options in the Black-Scholes framework, including\nautocallable structured products, single and double barrier options, and\nBermudan options. The method is based on a quadrature technique, and it employs\nonly elementary calculations and a fixed one-dimensional uniform grid. The\nconvergence rate is $O(1/N^4)$ and the complexity is $O(MN\\log N)$, where $N$\nis the number of grid points and $M$ is the number of observation dates.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.13407v2"
    },
    {
        "title": "Forecasting Implied Volatility Smile Surface via Deep Learning and\n  Attention Mechanism",
        "authors": [
            "Shengli Chen",
            "Zili Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  The implied volatility smile surface is the basis of option pricing, and the\ndynamic evolution of the option volatility smile surface is difficult to\npredict. In this paper, attention mechanism is introduced into LSTM, and a\nvolatility surface prediction method combining deep learning and attention\nmechanism is pioneeringly established. LSTM's forgetting gate makes it have\nstrong generalization ability, and its feedback structure enables it to\ncharacterize the long memory of financial volatility. The application of\nattention mechanism in LSTM networks can significantly enhance the ability of\nLSTM networks to select input features. The experimental results show that the\ntwo strategies constructed using the predicted implied volatility surfaces have\nhigher returns and Sharpe ratios than that the volatility surfaces are not\npredicted. This paper confirms that the use of AI to predict the implied\nvolatility surface has theoretical and economic value. The research method\nprovides a new reference for option pricing and strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.11059v1"
    },
    {
        "title": "Pricing and hedging American-style options with deep learning",
        "authors": [
            "Sebastian Becker",
            "Patrick Cheridito",
            "Arnulf Jentzen"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper we introduce a deep learning method for pricing and hedging\nAmerican-style options. It first computes a candidate optimal stopping policy.\nFrom there it derives a lower bound for the price. Then it calculates an upper\nbound, a point estimate and confidence intervals. Finally, it constructs an\napproximate dynamic hedging strategy. We test the approach on different\nspecifications of a Bermudan max-call option. In all cases it produces highly\naccurate prices and dynamic hedging strategies with small replication errors.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.11060v3"
    },
    {
        "title": "Hyperparameter Optimization for Forecasting Stock Returns",
        "authors": [
            "Sang Il Lee"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In recent years, hyperparameter optimization (HPO) has become an increasingly\nimportant issue in the field of machine learning for the development of more\naccurate forecasting models. In this study, we explore the potential of HPO in\nmodeling stock returns using a deep neural network (DNN). The potential of this\napproach was evaluated using technical indicators and fundamentals examined\nbased on the effect the regularization of dropouts and batch normalization for\nall input data. We found that the model using technical indicators and dropout\nregularization significantly outperforms three other models, showing a positive\npredictability of 0.53% in-sample and 1.11% out-of-sample, thereby indicating\nthe possibility of beating the historical average. We also demonstrate the\nstability of the model in terms of the changes in its feature importance over\ntime.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.10278v1"
    },
    {
        "title": "Reduction of valuation risk by Kalman filtering in business valuation\n  models",
        "authors": [
            "Rene Scheurwater"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  A recursive free cash flow model (FCFF) is proposed to determine the\ncorporate value of a company in an efficient market in which new market and\ncompany-specific information is modelled by additive white noise. The\nstochastic equations of the FCFF model are solved explicitly to obtain the\naverage corporate value and valuation risk. It is pointed out that valuation\nrisk can be reduced significantly by implementing a conventional two-step\nKalman filter in the recursive FCFF model, thus improving its predictive power.\nSystematic errors of the Kalman filter, caused by intermediate changes in risk\nand hence in the weighted average cost of capital (WACC), are detected by\nmeasuring the residuals. By including an additional adjustment step in the\nconventional Kalman filtering algorithm, it is shown that systematic errors can\nbe eliminated by recursively adjusting the WACC. The performance of the\nthree-step adaptive Kalman filter is tested by Monte Carlo simulation which\ndemonstrates the reliability and robustness against systematic errors. It is\nalso proved that the conventional and adaptive Kalman filtering algorithms can\nbe implemented into other valuation models such as the economic value added\nmodel (EVA) and free cash flow to equity model (FCFE).\n",
        "pdf_link": "http://arxiv.org/pdf/2005.10100v1"
    },
    {
        "title": "Finite Mixture Approximation of CARMA(p,q) Models",
        "authors": [
            "Lorenzo Mercuri",
            "Andrea Perchiazzo",
            "Edit Rroji"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper we show how to approximate the transition density of a CARMA(p,\nq) model driven by means of a time changed Brownian Motion based on the\nGauss-Laguerre quadrature. We then provide an analytical formula for option\nprices when the log price follows a CARMA(p, q) model. We also propose an\nestimation procedure based on the approximated likelihood density.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.10130v2"
    },
    {
        "title": "Financial option valuation by unsupervised learning with artificial\n  neural networks",
        "authors": [
            "Beatriz Salvador",
            "Cornelis W. Oosterlee",
            "Remco van der Meer"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Artificial neural networks (ANNs) have recently also been applied to solve\npartial differential equations (PDEs). In this work, the classical problem of\npricing European and American financial options, based on the corresponding PDE\nformulations, is studied. Instead of using numerical techniques based on finite\nelement or difference methods, we address the problem using ANNs in the context\nof unsupervised learning. As a result, the ANN learns the option values for all\npossible underlying stock values at future time points, based on the\nminimization of a suitable loss function. For the European option, we solve the\nlinear Black-Scholes equation, whereas for the American option, we solve the\nlinear complementarity problem formulation. Two-asset exotic option values are\nalso computed, since ANNs enable the accurate valuation of high-dimensional\noptions. The resulting errors of the ANN approach are assessed by comparing to\nthe analytic option values or to numerical reference solutions (for American\noptions, computed by finite elements).\n",
        "pdf_link": "http://arxiv.org/pdf/2005.12059v1"
    },
    {
        "title": "More Robust Pricing of European Options Based on Fourier Cosine Series\n  Expansions",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We present an alternative formula to price European options through cosine\nseries expansions, under models with a known characteristic function such as\nthe Heston stochastic volatility model. It is more robust across strikes and as\nfast as the original COS method.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.13248v2"
    },
    {
        "title": "A moment matching method for option pricing under stochastic interest\n  rates",
        "authors": [
            "Fabio Antonelli",
            "Alessandro Ramponi",
            "Sergio Scarlatti"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper we present a simple, but new, approximation methodology for\npricing a call option in a Black \\& Scholes market characterized by stochastic\ninterest rates. The method, based on a straightforward Gaussian moment matching\ntechnique applied to a conditional Black \\& Scholes formula, is quite general\nand it applies to various models, whether affine or not. To check its accuracy\nand computational time, we implement it for the CIR interest rate model\ncorrelated with the underlying, using the Monte Carlo simulations as a\nbenchmark. The method's performance turns out to be quite remarkable, even when\ncompared with analogous results obtained by the affine approximation technique\npresented in Grzelak and Oosterlee (2011) and by the expansion formula\nintroduced in Kim and Kunimoto (1999), as we show in the last section.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.14063v1"
    },
    {
        "title": "A backward Monte Carlo approach to exotic option pricing",
        "authors": [
            "Giacomo Bormetti",
            "Giorgia Callegaro",
            "Giulia Livieri",
            "Andrea Pallavicini"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We propose a novel algorithm which allows to sample paths from an underlying\nprice process in a local volatility model and to achieve a substantial variance\nreduction when pricing exotic options. The new algorithm relies on the\nconstruction of a discrete multinomial tree. The crucial feature of our\napproach is that -- in a similar spirit to the Brownian Bridge -- each random\npath runs backward from a terminal fixed point to the initial spot price. We\ncharacterize the tree in two alternative ways: in terms of the optimal grids\noriginating from the Recursive Marginal Quantization algorithm and following an\napproach inspired by the finite difference approximation of the diffusion's\ninfinitesimal generator. We assess the reliability of the new methodology\ncomparing the performance of both approaches and benchmarking them with\ncompetitor Monte Carlo methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.00848v1"
    },
    {
        "title": "Magic points in finance: Empirical integration for parametric option\n  pricing",
        "authors": [
            "Maximilian Gaß",
            "Kathrin Glau",
            "Maximilian Mair"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We propose an offline-online procedure for Fourier transform based option\npricing. The method supports the acceleration of such essential tasks of\nmathematical finance as model calibration, real-time pricing, and, more\ngenerally, risk assessment and parameter risk estimation. We adapt the\nempirical magic point interpolation method of Barrault, Nguyen, Maday and\nPatera (2004) to parametric Fourier pricing. In the offline phase, a quadrature\nrule is tailored to the family of integrands of the parametric pricing problem.\nIn the online phase, the quadrature rule then yields fast and accurate\napproximations of the option prices. Under analyticity assumptions the pricing\nerror decays exponentially. Numerical experiments in one dimension confirm our\ntheoretical findings and show a significant gain in efficiency, even for\nexamples beyond the scope of the theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.00884v3"
    },
    {
        "title": "Full and fast calibration of the Heston stochastic volatility model",
        "authors": [
            "Yiran Cui",
            "Sebastian del Baño Rollin",
            "Guido Germano"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This paper presents an algorithm for a complete and efficient calibration of\nthe Heston stochastic volatility model. We express the calibration as a\nnonlinear least squares problem. We exploit a suitable representation of the\nHeston characteristic function and modify it to avoid discontinuities caused by\nbranch switchings of complex functions. Using this representation, we obtain\nthe analytical gradient of the price of a vanilla option with respect to the\nmodel parameters, which is the key element of all variants of the objective\nfunction. The interdependency between the components of the gradient enables an\nefficient implementation which is around ten times faster than a numerical\ngradient. We choose the Levenberg-Marquardt method to calibrate the model and\ndo not observe multiple local minima reported in previous research.\nTwo-dimensional sections show that the objective function is shaped as a narrow\nvalley with a flat bottom. Our method is the fastest calibration of the Heston\nmodel developed so far and meets the speed requirement of practical trading.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.08718v2"
    },
    {
        "title": "Realized Volatility Analysis in A Spin Model of Financial Markets",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We calculate the realized volatility in the spin model of financial markets\nand examine the returns standardized by the realized volatility. We find that\nmoments of the standardized returns agree with the theoretical values of\nstandard normal variables. This is the first evidence that the return dynamics\nof the spin financial market is consistent with the view of the\nmixture-of-distribution hypothesis that also holds in the real financial\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.08997v1"
    },
    {
        "title": "Mixing LSMC and PDE Methods to Price Bermudan Options",
        "authors": [
            "David Farahany",
            "Kenneth Jackson",
            "Sebastian Jaimungal"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We develop a mixed least squares Monte Carlo-partial differential equation\n(LSMC-PDE) method for pricing Bermudan style options on assets whose volatility\nis stochastic. The algorithm is formulated for an arbitrary number of assets\nand volatility processes and we prove the algorithm converges almost surely for\na class of models. We also discuss two methods to improve the algorithm's\ncomputational complexity. Our numerical examples focus on the single ($2d$) and\nmulti-dimensional ($4d$) Heston models and we compare our hybrid algorithm with\nclassical LSMC approaches. In each case, we find that the hybrid algorithm\noutperforms standard LSMC in terms of estimating prices and optimal exercise\nboundaries.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.07216v3"
    },
    {
        "title": "A path integral based model for stocks and order dynamics",
        "authors": [
            "Giovanni Paolinelli",
            "Gianni Arioli"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We introduce a model for the short-term dynamics of financial assets based on\nan application to finance of quantum gauge theory, developing ideas of Ilinski.\nWe present a numerical algorithm for the computation of the probability\ndistribution of prices and compare the results with APPLE stocks prices and the\nS&P500 index.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.07904v1"
    },
    {
        "title": "Computing the CEV option pricing formula using the semiclassical\n  approximation of path integral",
        "authors": [
            "Axel A. Araneda",
            "Marcelo J. Villena"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The Constant Elasticity of Variance (CEV) model significantly outperforms the\nBlack-Scholes (BS) model in forecasting both prices and options. Furthermore,\nthe CEV model has a marked advantage in capturing basic empirical regularities\nsuch as: heteroscedasticity, the leverage effect, and the volatility smile. In\nfact, the performance of the CEV model is comparable to most stochastic\nvolatility models, but it is considerable easier to implement and calibrate.\nNevertheless, the standard CEV model solution, using the non-central chi-square\napproach, still presents high computational times, specially when: i) the\nmaturity is small, ii) the volatility is low, or iii) the elasticity of the\nvariance tends to zero. In this paper, a new numerical method for computing the\nCEV model is developed. This new approach is based on the semiclassical\napproximation of Feynman's path integral. Our simulations show that the method\nis efficient and accurate compared to the standard CEV solution considering the\npricing of European call options.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.10376v1"
    },
    {
        "title": "Thresholded ConvNet Ensembles: Neural Networks for Technical Forecasting",
        "authors": [
            "Sid Ghoshal",
            "Stephen J. Roberts"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Much of modern practice in financial forecasting relies on technicals, an\numbrella term for several heuristics applying visual pattern recognition to\nprice charts. Despite its ubiquity in financial media, the reliability of its\nsignals remains a contentious and highly subjective form of 'domain knowledge'.\nWe investigate the predictive value of patterns in financial time series,\napplying machine learning and signal processing techniques to 22 years of US\nequity data. By reframing technical analysis as a poorly specified, arbitrarily\npreset feature-extractive layer in a deep neural network, we show that better\nconvolutional filters can be learned directly from the data, and provide visual\nrepresentations of the features being identified. We find that an ensemble of\nshallow, thresholded CNNs optimised over different resolutions achieves\nstate-of-the-art performance on this domain, outperforming technical methods\nwhile retaining some of their interpretability.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.03192v2"
    },
    {
        "title": "Testing of Binary Regime Switching Models using Squeeze Duration\n  Analysis",
        "authors": [
            "Milan Kumar Das",
            "Anindya Goswami"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We have developed a statistical technique to test the model assumption of\nbinary regime switching extension of the geometric Brownian motion (GBM) model\nby proposing a new discriminating statistics. Given a time series data, we have\nidentified an admissible class of the regime switching candidate models for the\nstatistical inference. By performing several systematic experiments, we have\nsuccessfully shown that the sampling distribution of the test statistics\ndiffers drastically, if the model assumption changes from GBM to Markov\nmodulated GBM, or to semi-Markov modulated GBM. Furthermore, we have\nimplemented this statistics for testing the regime switching hypothesis with\nIndian sectoral indices.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.04393v2"
    },
    {
        "title": "Compact Finite Difference Scheme with Hermite Interpolation for Pricing\n  American Put Options Based on Regime Switching Model",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai",
            "Ruihua Liu"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We consider a system of coupled free boundary problems for pricing American\nput options with regime-switching. To solve this system, we first employ the\nlogarithmic transformation to map the free boundary for each regime to\nmulti-fixed intervals and then eliminate the first-order derivative in the\ntransformed model by taking derivatives to obtain a system of partial\ndifferential equations which we call the asset-delta-gamma-speed equations. As\nsuch, the fourth-order compact finite difference scheme can be used for solving\nthis system. The influence of other asset, delta, gamma, and speed options in\nthe present regime is estimated based on Hermite interpolations. Finally, the\nnumerical method is tested with several examples. Our results show that the\nscheme provides an accurate solution that is fast in computation as compared\nwith other existing numerical methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.04900v6"
    },
    {
        "title": "Personal Finance Decisions with Untruthful Advisors: an Agent-Based\n  Model",
        "authors": [
            "Loretta Mastroeni",
            "Maurizio Naldi",
            "Pierluigi Vellucci"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Investors usually resort to financial advisors to improve their investment\nprocess until the point of complete delegation on investment decisions. Surely,\nfinancial advice is potentially a correcting factor in investment decisions\nbut, in the past, the media and regulators blamed biased advisors for\nmanipulating the expectations of naive investors. In order to give an analytic\nformulation of the problem, we present an Agent-Based Model formed by\nindividual investors and a financial advisor. We parametrize the games by\nconsidering a compromise for the financial advisor (between a sufficient reward\nby bank and to keep his/her reputation), and a compromise for the customers\n(between the desired return and the proposed return by advisor). Then we obtain\nthe Nash equilibria and the best response functions of the resulting game. We\nalso describe the parameter regions in which these points result acceptable\nequilibria and the greediness/naivety of the customers emerge naturally from\nthe model. Finally, we focus on the efficiency of the best Nash equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.06759v1"
    },
    {
        "title": "Neural network for pricing and universal static hedging of contingent\n  claims",
        "authors": [
            "Vikranth Lokeshwar",
            "Vikram Bhardawaj",
            "Shashi Jain"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We present here a regress later based Monte Carlo approach that uses neural\nnetworks for pricing high-dimensional contingent claims. The choice of specific\narchitecture of the neural networks used in the proposed algorithm provides for\ninterpretability of the model, a feature that is often desirable in the\nfinancial context. Specifically, the interpretation leads us to demonstrate\nthat any contingent claim -- possibly high dimensional and path-dependent --\nunder the Markovian and the no-arbitrage assumptions, can be semi-statically\nhedged using a portfolio of short maturity options. We show how the method can\nbe used to obtain an upper and lower bound to the true price, where the lower\nbound is obtained by following a sub-optimal policy, while the upper bound by\nexploiting the dual formulation. Unlike other duality based upper bounds where\none typically has to resort to nested simulation for constructing\nsuper-martingales, the martingales in the current approach come at no extra\ncost, without the need for any sub-simulations. We demonstrate through\nnumerical examples the simplicity and efficiency of the method for both pricing\nand semi-static hedging of path-dependent options\n",
        "pdf_link": "http://arxiv.org/pdf/1911.11362v1"
    },
    {
        "title": "Tempered Stable Processes with Time Varying Exponential Tails",
        "authors": [
            "Young Shin Kim",
            "Kum-Hwan Roh",
            "Raphael Douady"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper, we introduce a new time series model having a stochastic\nexponential tail. This model is constructed based on the Normal Tempered Stable\ndistribution with a time-varying parameter. The model captures the stochastic\nexponential tail, which generates the volatility smile effect and volatility\nterm structure in option pricing. Moreover, the model describes the\ntime-varying volatility of volatility. We empirically show the stochastic\nskewness and stochastic kurtosis by applying the model to analyze S&P 500 index\nreturn data. We present the Monte-Carlo simulation technique for the parameter\ncalibration of the model for the S&P 500 option prices. We can see that the\nstochastic exponential tail makes the model better to analyze the market option\nprices by the calibration.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.07669v2"
    },
    {
        "title": "Valuing the quality option in agricultural commodity futures: a Monte\n  Carlo simulation based approach",
        "authors": [
            "Sanjay Mansabdar",
            "Hussain C Yaganti"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Agricultural commodity futures are often settled by delivery. Quality options\nthat allow the futures short to deliver one of several underlying assets are\ncommonly used in such contracts to prevent manipulation. Inclusion of these\noptions reduces the price of the futures contract and leads to degraded\ncontract hedging performance. Valuation of these options is a first step in\nassessing the impact of the quality options embedded into a futures contract.\nThis paper demonstrates a Monte Carlo simulation based approach to estimate the\nvalue of a quality option. In order to improve simulation efficiency, the\ntechnique of antithetic variables is used. This approach can help in the\nassessment of the impact of embedded quality options.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.11222v1"
    },
    {
        "title": "Optimal Asset Allocation For Outperforming A Stochastic Benchmark Target",
        "authors": [
            "Chendi Ni",
            "Yuying Li",
            "Peter Forsyth",
            "Ray Carroll"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We propose a data-driven Neural Network (NN) optimization framework to\ndetermine the optimal multi-period dynamic asset allocation strategy for\noutperforming a general stochastic target. We formulate the problem as an\noptimal stochastic control with an asymmetric, distribution shaping, objective\nfunction. The proposed framework is illustrated with the asset allocation\nproblem in the accumulation phase of a defined contribution pension plan, with\nthe goal of achieving a higher terminal wealth than a stochastic benchmark. We\ndemonstrate that the data-driven approach is capable of learning an adaptive\nasset allocation strategy directly from historical market returns, without\nassuming any parametric model of the financial market dynamics. Following the\noptimal adaptive strategy, investors can make allocation decisions simply\ndepending on the current state of the portfolio. The optimal adaptive strategy\noutperforms the benchmark constant proportion strategy, achieving a higher\nterminal wealth with a 90% probability, a 46% higher median terminal wealth,\nand a significantly more right-skewed terminal wealth distribution. We further\ndemonstrate the robustness of the optimal adaptive strategy by testing the\nperformance of the strategy on bootstrap resampled market data, which has\ndifferent distributions compared to the training data.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15384v1"
    },
    {
        "title": "Robust Product Markovian Quantization",
        "authors": [
            "Ralph Rudd",
            "Thomas A. McWalter",
            "Joerg Kienitz",
            "Eckhard Platen"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Recursive marginal quantization (RMQ) allows the construction of optimal\ndiscrete grids for approximating solutions to stochastic differential equations\nin d-dimensions. Product Markovian quantization (PMQ) reduces this problem to d\none-dimensional quantization problems by recursively constructing product\nquantizers, as opposed to a truly optimal quantizer. However, the standard\nNewton-Raphson method used in the PMQ algorithm suffers from numerical\ninstabilities, inhibiting widespread adoption, especially for use in\ncalibration. By directly specifying the random variable to be quantized at each\ntime step, we show that PMQ, and RMQ in one dimension, can be expressed as\nstandard vector quantization. This reformulation allows the application of the\naccelerated Lloyd's algorithm in an adaptive and robust procedure. Furthermore,\nin the case of stochastic volatility models, we extend the PMQ algorithm by\nusing higher-order updates for the volatility or variance process. We\nillustrate the technique for European options, using the Heston model, and more\nexotic products, using the SABR model.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15823v1"
    },
    {
        "title": "The Deep Parametric PDE Method: Application to Option Pricing",
        "authors": [
            "Kathrin Glau",
            "Linus Wunderlich"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We propose the deep parametric PDE method to solve high-dimensional\nparametric partial differential equations. A single neural network approximates\nthe solution of a whole family of PDEs after being trained without the need of\nsample solutions. As a practical application, we compute option prices in the\nmultivariate Black-Scholes model. After a single training phase, the prices for\ndifferent time, state and model parameters are available in milliseconds. We\nevaluate the accuracy in the price and a generalisation of the implied\nvolatility with examples of up to 25 dimensions. A comparison with alternative\nmachine learning approaches, confirms the effectiveness of the approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.06211v1"
    },
    {
        "title": "An approximate closed formula for European Mortgage Options",
        "authors": [
            "Manuel Lopez Galvan"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The aim of this paper is to investigate the use of close formula\napproximation for pricing European mortgage options. Under the assumption of\nlogistic duration and normal mortgage rates the underlying price at the option\nexpiry is approximated by shifted lognormal or regular lognormal distribution\nby matching moments. Once the price function is approximated by lognormal\ndistributions, the option price can be computed directly as an integration of\nthe distribution function over the payoff at the option expiry by using\nBlack-Scholes-Merton close formula. We will see that lower curvature levels\ncorrespond to positively skewness price distributions and in this case\nlognormal approximation leads to close parametric formula representation in\nterms of all model parameters. The proposed methodologies are tested against\nMonte Carlo approach under different market and contract parameters and the\ntests confirmed that the close form approximation have a very good accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.06645v1"
    },
    {
        "title": "A deep learning model for gas storage optimization",
        "authors": [
            "Nicolas Curin",
            "Michael Kettler",
            "Xi Kleisinger-Yu",
            "Vlatka Komaric",
            "Thomas Krabichler",
            "Josef Teichmann",
            "Hanna Wutte"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  To the best of our knowledge, the application of deep learning in the field\nof quantitative risk management is still a relatively recent phenomenon. In\nthis article, we utilize techniques inspired by reinforcement learning in order\nto optimize the operation plans of underground natural gas storage facilities.\nWe provide a theoretical framework and assess the performance of the proposed\nmethod numerically in comparison to a state-of-the-art least-squares\nMonte-Carlo approach. Due to the inherent intricacy originating from the\nhigh-dimensional forward market as well as the numerous constraints and\nfrictions, the optimization exercise can hardly be tackled by means of\ntraditional techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01980v2"
    },
    {
        "title": "Portfolio Performance Attribution via Shapley Value",
        "authors": [
            "Nicholas Moehle",
            "Stephen Boyd",
            "Andrew Ang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We consider an investment process that includes a number of features, each of\nwhich can be active or inactive. Our goal is to attribute or decompose an\nachieved performance to each of these features, plus a baseline value. There\nare many ways to do this, which lead to potentially different attributions in\nany specific case. We argue that a specific attribution method due to Shapley\nis the preferred method, and discuss methods that can be used to compute this\nattribution exactly, or when that is not practical, approximately.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.05799v1"
    },
    {
        "title": "Stock market's physical properties description based on Stokes law",
        "authors": [
            "Geoffrey Ducournau"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We propose in this paper to consider the stock market as a physical system\nassimilate to a fluid evolving in a macroscopic space subject to a Force that\ninfluences its movement over time where this last is arising from the collision\nbetween the supply and the demand of Financial agents. In fluid mechanics, this\nForce also results from the collisions of fluid molecules led by its physical\nproperty such as density, viscosity, and surface tension. The purpose of this\narticle is to show that the dynamism of the stock market behavior can be\nexplained qualitatively and quantitatively by considering the supply & demand\ncollision as the result of Financial agents physical properties defined by\nStokes Law. The first objective of this article is to show theoretically that\nfluid mechanics equations can be used to describe stock market physical\nproperties. The second objective based on the knowledge of stock market\nphysical properties is to propose an Econophysics analog of the stock market\nviscosity and Reynolds number to measure stock market conditions, whether\nlaminar, transitory, or turbulent. The Reynolds Number defined in this way can\nbe applied in research into the study and classification of stock market\ndynamics phases through for instance the creation of Econophysics analog of\nModdy diagram, this last could be seen as a physical way to quantify asset and\nstock index idiosyncratic risk. The last objective is to present evidence from\na computer simulation that the stock market behavior can be a priori, and\nposteriori explained by physical properties (viscosity & density) quantifiable\nby fluid mechanics law (Stokes law) and measurable with the stock market\nReynolds Number.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.00721v1"
    },
    {
        "title": "SWIFT calibration of the Heston model",
        "authors": [
            "Eudald Romo",
            "Luis Ortiz-Gracia"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In the present work, the European option pricing SWIFT method is extended for\nHeston model calibration. The computation of the option price gradient is\nsimplified thanks to the knowledge of the characteristic function in closed\nform. The proposed calibration machinery appears to be extremely fast, in\nparticular for a single expiry and multiples strikes, outperforming the\nstate-of-the-art method we compare with. Further, the a priori knowledge of\nSWIFT parameters makes possible a reliable and practical implementation of the\npresented calibration method. A wide set of stress, speed and convergence\nnumerical experiments is carried out, with deep in-the-money, at-the-money and\ndeep out-of-the-money options for very short and very long maturities.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.01570v1"
    },
    {
        "title": "Finite element solutions of the nonlinear RAPM Black-Scholes model",
        "authors": [
            "Dongming Wei",
            "Yogi Ahmad Erlangga",
            "Andrey Pak",
            "Laila Zhexembay"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  his paper presents finite element methods for solving numerically the\nRisk-Adjusted Pricing Methodology (RAPM) Black-Scholes model for option pricing\nwith transaction costs. Spatial finite element models based on P1 and/or P2\nelements are formulated using some group finite elements and numerical\nquadrature to handle the nonlinear term, in combination with a\nCrank-Nicolson-type temporal scheme. The temporal scheme is implemented using\nthe Rannacher approach. Spatial-temporal mesh-size ratios are observed for\ncontrolling the stability of our method. Our results compare favorably with the\nfinite difference results in the literature for the model.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.08380v1"
    },
    {
        "title": "Understanding Smart Contracts: Hype or Hope?",
        "authors": [
            "Elizaveta Zinovyeva",
            "Raphael C. G. Reule",
            "Wolfgang Karl Härdle"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Smart Contracts are commonly considered to be an important component or even\na key to many business solutions in an immense variety of sectors and promises\nto securely increase their individual efficiency in an ever more digitized\nenvironment. Introduced in the early 1990s, the technology has gained a lot of\nattention with its application to blockchain technology to an extent, that can\nbe considered a veritable hype. Reflecting the growing institutional interest,\nthis intertwined exploratory study between statistics, information technology,\nand law contrasts these idealistic stories with the data reality and provides a\nmandatory step of understanding the matter, before any further relevant\napplications are discussed as being \"factually\" able to replace traditional\nconstructions. Besides fundamental flaws and applica-tion difficulties of\ncurrently employed Smart Contracts, the technological drive and enthusiasm\nbacking it may however serve as a jump-off board for future developments\nthrusting well in the presently unshakeable traditional structures.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.08447v1"
    },
    {
        "title": "Pricing Energy Derivatives in Markets Driven by Tempered Stable and CGMY\n  Processes of Ornstein-Uhlenbeck Type",
        "authors": [
            "Piergiacomo Sabino"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this study we consider the pricing of energy derivatives when the\nevolution of spot prices follows a tempered stable or a CGMY driven Ornstein-\nUhlenbeck process. To this end, we first calculate the characteristic function\nof the transition law of such processes in closed form. This result is\ninstrumental for the derivation of non-arbitrage conditions such that the spot\ndynamics is consistent with the forward curve. Moreover, based on the results\nof Cufaro Petroni and Sabino (2020), we also conceive efficient algorithms for\nthe exact simulation of the skeleton of such processes and propose a novel\nprocedure when they coincide with compound Poisson processes of\nOrnstein-Uhlenbeck type. We illustrate the applicability of the theoretical\nfindings and the simulation algorithms in the context of the pricing different\ncontracts namely, strips of daily call options, Asian options with European\nstyle and swing options. Finally, we present an extension to future markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.13252v1"
    },
    {
        "title": "Nowcasting Stock Implied Volatility with Twitter",
        "authors": [
            "Thomas Dierckx",
            "Jesse Davis",
            "Wim Schoutens"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this study, we predict next-day movements of stock end-of-day implied\nvolatility using random forests. Through an ablation study, we examine the\nusefulness of different sources of predictors and expose the value of attention\nand sentiment features extracted from Twitter. We study the approach on a stock\nuniverse comprised of the 165 most liquid US stocks diversified across the 11\ntraditional market sectors using a sizeable out-of-sample period spanning over\nsix years. In doing so, we uncover that stocks in certain sectors, such as\nConsumer Discretionary, Technology, Real Estate, and Utilities are easier to\npredict than others. Further analysis shows that possible reasons for these\ndiscrepancies might be caused by either excess social media attention or low\noption liquidity. Lastly, we explore how our proposed approach fares throughout\ntime by identifying four underlying market regimes in implied volatility using\nhidden Markov models. We find that most added value is achieved in regimes\nassociated with lower implied volatility, but optimal regimes vary per market\nsector.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00248v1"
    },
    {
        "title": "Efficient Risk Estimation for the Credit Valuation Adjustment",
        "authors": [
            "Michael B. Giles",
            "Abdul-Lateef Haji-Ali",
            "Jonathan Spence"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The valuation of over-the-counter derivatives is subject to a series of\nvaluation adjustments known as xVA, which pose additional risks for financial\ninstitutions. Associated risk measures, such as the value-at-risk of an\nunderlying valuation adjustment, play an important role in managing these\nrisks. Monte Carlo methods are often regarded as inefficient for computing such\nmeasures. As an example, we consider the value-at-risk of the Credit Valuation\nAdjustment (CVA-VaR), which can be expressed using a triple nested expectation.\nTraditional Monte Carlo methods are often inefficient at handling several\nnested expectations. Utilising recent developments in multilevel nested\nsimulation for probabilities, we construct a hierarchical estimator of the\nCVA-VaR which reduces the computational complexity by 3 orders of magnitude\ncompared to standard Monte Carlo.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.05886v2"
    },
    {
        "title": "The Combinational Mutation Strategy of Differential Evolution Algorithm\n  for Pricing Vanilla Options and Its Implementation on Data during Covid-19\n  Pandemic",
        "authors": [
            "Werry Febrianti",
            "Kuntjoro Adji Sidarto",
            "Novriana Sumarti"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Investors always want to know about the profit and the risk that they will be\nget before buying some assets. Our main focus is getting the profit and the\nprobability of getting that profit using the differential evolution algorithm\nfor vanilla option pricing on data before and during COVID-19 pandemic.\nTherefore, we model the pricing of an option using a bi-objective optimization\nproblem using data before and during COVID-19 pandemic for one year expiration\ndate. We change this problem into an optimization problem using adaptive\nweighted sum method. We use metaheuristics algorithm like Differential\nEvolution (DE) algorithm to solve this bi-objective optimization problems. In\nthis paper, we also use modification of Differential Evolution for getting\nPareto optimal solutions on vanilla option pricing for all contract. The\nalgorithm is called Combinational Mutation Strategy of Differential Evolution\n(CmDE) algorithm. The results of our algorithm are satisfactory close to the\nreal option price in the market data. Besides that, we also compare our result\nwith the Black-Scholes results for validation. The results show that our\nresults can approximate the real market options more accurate than\nBlack-Scholes results. Hence, our bi-objective optimization using Combinational\nMutation Strategy of Differential Evolution algorithm can be used to\napproximate the market real vanilla option pricing before and during COVID-19\npandemic.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09261v1"
    },
    {
        "title": "An Optimal Control Strategy for Execution of Large Stock Orders Using\n  LSTMs",
        "authors": [
            "A. Papanicolaou",
            "H. Fu",
            "P. Krishnamurthy",
            "B. Healy",
            "F. Khorrami"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we simulate the execution of a large stock order with real\ndata and general power law in the Almgren and Chriss model. The example that we\nconsider is the liquidation of a large position executed over the course of a\nsingle trading day in a limit order book. Transaction costs are incurred\nbecause large orders walk the order book, that is, they consume order book\nliquidity beyond the best bid/ask. We model the order book with a power law\nthat is proportional to trading volume, and thus transaction costs are\ninversely proportional to a power of trading volume. We obtain a policy\napproximation by training a long short term memory (LSTM) neural network to\nminimize transaction costs accumulated when execution is carried out as a\nsequence of smaller suborders. Using historical S&P100 price and volume data,\nwe evaluate our LSTM strategy relative to strategies based on time-weighted\naverage price (TWAP) and volume-weighted average price (VWAP). For execution of\na single stock, the input to the LSTM is the cross section of data on all 100\nstocks, including prices, volumes, TWAPs and VWAPs. By using this data cross\nsection, the LSTM should be able to exploit inter-stock co-dependence in volume\nand price movements, thereby reducing transaction costs for the day. Our tests\non S&P100 data demonstrate that in fact this is so, as our LSTM strategy\nconsistently outperforms TWAP and VWAP-based strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09705v4"
    },
    {
        "title": "Valuation of the Convertible Bonds under Penalty TF model using Finite\n  Element Method",
        "authors": [
            "Rakhymzhan Kazbek",
            "Yogi Erlangga",
            "Yerlan Amanbek",
            "Dongming Wei"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, the TF system of two-coupled Black-Scholes equations for\npricing the convertible bonds is solved numerically by using the P1 and P2\nfinite elements with the inequality constraints approximated by the penalty\nmethod. The corresponding finite element ODE system is numerically solved by\nusing a modified Crank-Nicolson scheme, in which the non-linear system is\nsolved at each time step by the Newton-Raphson method for non-smooth functions.\nMoreover, the corresponding Greeks are also calculated by taking advantage of\nthe P1-P2 finite element approximation functions. Numerical solutions by the\nfinite element method compare favorably with the solutions by the finite\ndifference method in literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10734v1"
    },
    {
        "title": "A Deep Neural Network Algorithm for Linear-Quadratic Portfolio\n  Optimization with MGARCH and Small Transaction Costs",
        "authors": [
            "Andrew Papanicolaou",
            "Hao Fu",
            "Prashanth Krishnamurthy",
            "Farshad Khorrami"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We analyze a fixed-point algorithm for reinforcement learning (RL) of optimal\nportfolio mean-variance preferences in the setting of multivariate generalized\nautoregressive conditional-heteroskedasticity (MGARCH) with a small penalty on\ntrading. A numerical solution is obtained using a neural network (NN)\narchitecture within a recursive RL loop. A fixed-point theorem proves that NN\napproximation error has a big-oh bound that we can reduce by increasing the\nnumber of NN parameters. The functional form of the trading penalty has a\nparameter $\\epsilon>0$ that controls the magnitude of transaction costs. When\n$\\epsilon$ is small, we can implement an NN algorithm based on the expansion of\nthe solution in powers of $\\epsilon$. This expansion has a base term equal to a\nmyopic solution with an explicit form, and a first-order correction term that\nwe compute in the RL loop. Our expansion-based algorithm is stable, allows for\nfast computation, and outputs a solution that shows positive testing\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10869v2"
    },
    {
        "title": "Computation of the \"Enrichment\" of a Value Functions of an Optimization\n  Problem on Cumulated Transaction-Costs through a Generalized Lax-Hopf Formula",
        "authors": [
            "Luxi Chen"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The Lax-Hopf formula simplifies the value function of an intertemporal\noptimization (infinite dimensional) problem associated with a convex\ntransaction-cost function which depends only on the transactions (velocities)\nof a commodity evolution: it states that the value function is equal to the\nmarginal fonction of a finite dimensional problem with respect to durations and\naverage ransactions, much simpler to solve. The average velocity of the value\nfunction on a investment temporal window is regarded as an enrichment,\nproportional to the profit and inversely proportional to the investment\nduration. At optimum, the Lax-Hopf formula implies that the enrichment is equal\nto the cost of the average transaction on the investment temporal window. In\nthis study, we generalize the Lax-Hopf formula when the transaction-cost\nfunction depends also on time and commodity, for reducing the infinite\ndimensional problem to a finite dimensional problem. For that purpose, we\nintroduce the moderated ansaction-cost function which depends only on the\nduration and on a commodity. Here again, the generalized Lax-Hopf formula\nreduces the computation of the value function to the marginal fonction of an\noptimization problem on durations and commodities involving the moderated\ntransaction cost function. At optimum, the enrichment of the value function is\nstill equal to the moderated transition cost-function of average transaction.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1610v1"
    },
    {
        "title": "Pricing of basket options I",
        "authors": [
            "Alexander Kushpel"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  Pricing of high-dimensional options is a deep problem of the Theoretical\nFinancial Mathematics. In this article we present a new class of L\\'{e}vy\ndriven models of stock markets. In our opinion, any market model should be\nbased on a transparent and intuitively easily acceptable concept. In our case\nthis is a linear system of stochastic equations. Our market model is based on\nthe principle of inheritance, i.e. for the particular choice of parameters it\ncoincides with known models. Also, the model proposed is effectively\nnumerically realizable. For the class of models under cosideration, we give an\nexplicit representations of characteristic functions. This allows us us to\nconstruct a sequence of approximation formulas to price basket options. We show\nthat our approximation formulas have almost optimal rate of convergence in the\nsense of respective n-widths.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1856v1"
    },
    {
        "title": "Efficient tree methods for pricing digital barrier options",
        "authors": [
            "Elisa Appolloni",
            "Andrea Ligori"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We propose an efficient lattice procedure which permits to obtain European\nand American option prices under the Black and Scholes model for digital\noptions with barrier features. Numerical results show the accuracy of the\nproposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.2900v2"
    },
    {
        "title": "Estimate nothing",
        "authors": [
            "M. Duembgen",
            "L. C. G. Rogers"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In the econometrics of financial time series, it is customary to take some\nparametric model for the data, and then estimate the parameters from historical\ndata. This approach suffers from several problems. Firstly, how is estimation\nerror to be quantified, and then taken into account when making statements\nabout the future behaviour of the observed time series? Secondly, decisions may\nbe taken today committing to future actions over some quite long horizon, as in\nthe trading of derivatives; if the model is re-estimated at some intermediate\ntime, our earlier decisions would need to be revised - but the derivative has\nalready been traded at the earlier price. Thirdly, the exact form of the\nparametric model to be used is generally taken as given at the outset; other\ncompetitor models might possibly work better in some circumstances, but the\nmethodology does not allow them to be factored into the inference. What we\npropose here is a very simple (Bayesian) alternative approach to inference and\naction in financial econometrics which deals decisively with all these issues.\nThe key feature is that nothing is being estimated.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5666v1"
    },
    {
        "title": "Valuation of Barrier Options using Sequential Monte Carlo",
        "authors": [
            "Pavel V. Shevchenko",
            "Pierre Del Moral"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  Sequential Monte Carlo (SMC) methods have successfully been used in many\napplications in engineering, statistics and physics. However, these are seldom\nused in financial option pricing literature and practice. This paper presents\nSMC method for pricing barrier options with continuous and discrete monitoring\nof the barrier condition. Under the SMC method, simulated asset values rejected\ndue to barrier condition are re-sampled from asset samples that do not breach\nthe barrier condition improving the efficiency of the option price estimator;\nwhile under the standard Monte Carlo many simulated asset paths can be rejected\nby the barrier condition making it harder to estimate option price accurately.\nWe compare SMC with the standard Monte Carlo method and demonstrate that the\nextra effort to implement SMC when compared with the standard Monte Carlo is\nvery little while improvement in price estimate can be significant. Both\nmethods result in unbiased estimators for the price converging to the true\nvalue as $1/\\sqrt{M}$, where $M$ is the number of simulations (asset paths).\nHowever, the variance of SMC estimator is smaller and does not grow with the\nnumber of time steps when compared to the standard Monte Carlo. In this paper\nwe demonstrate that SMC can successfully be used for pricing barrier options.\nSMC can also be used for pricing other exotic options and also for cases with\nmany underlying assets and additional stochastic factors such as stochastic\nvolatility; we provide general formulas and references.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5294v2"
    },
    {
        "title": "Splitting and Matrix Exponential approach for jump-diffusion models with\n  Inverse Normal Gaussian, Hyperbolic and Meixner jumps",
        "authors": [
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  This paper is a further extension of the method proposed in Itkin, 2014 as\napplied to another set of jump-diffusion models: Inverse Normal Gaussian,\nHyperbolic and Meixner. To solve the corresponding PIDEs we accomplish few\nsteps. First, a second-order operator splitting on financial processes\n(diffusion and jumps) is applied to these PIDEs. To solve the diffusion\nequation, we use standard finite-difference methods. For the jump part, we\ntransform the jump integral into a pseudo-differential operator and construct\nits second order approximation on a grid which supersets the grid that we used\nfor the diffusion part. The proposed schemes are unconditionally stable in time\nand preserve positivity of the solution which is computed either via a matrix\nexponential, or via P'ade approximation of the matrix exponent. Various\nnumerical experiments are provided to justify these results.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6111v2"
    },
    {
        "title": "Perturbation analysis of a nonlinear equation arising in the\n  Schaefer-Schwartz model of interest rates",
        "authors": [
            "Beata Stehlikova"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We deal with the interest rate model proposed by Schaefer and Schwartz, which\nmodels the long rate and the spread, defined as the difference between the\nshort and the long rates. The approximate analytical formula for the bond\nprices suggested by the authors requires a computation of a certain constant,\ndefined via a nonlinear equation and an integral of a solution to a system of\nordinary differential equations. In this paper we use perturbation methods to\ncompute this constant. Coefficients of its expansion are given in a closed form\nand can be constructed to arbitrary order. However, our numerical results show\nthat a very good accuracy is achieved already after using a small number of\nterms.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.6321v1"
    },
    {
        "title": "Convergence of an Euler scheme for a hybrid stochastic-local volatility\n  model with stochastic rates in foreign exchange markets",
        "authors": [
            "Andrei Cozma",
            "Matthieu Mariapragassam",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We study the Heston-Cox-Ingersoll-Ross++ stochastic-local volatility model in\nthe context of foreign exchange markets and propose a Monte Carlo simulation\nscheme which combines the full truncation Euler scheme for the stochastic\nvolatility component and the stochastic domestic and foreign short interest\nrates with the log-Euler scheme for the exchange rate. We establish the\nexponential integrability of full truncation Euler approximations for the\nCox-Ingersoll-Ross process and find a lower bound on the explosion time of\nthese exponential moments. Under a full correlation structure and a realistic\nset of assumptions on the so-called leverage function, we prove the strong\nconvergence of the exchange rate approximations and deduce the convergence of\nMonte Carlo estimators for a number of vanilla and path-dependent options.\nThen, we perform a series of numerical experiments for an autocallable barrier\ndual currency note.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.06084v4"
    },
    {
        "title": "Valuation Algorithms for Structural Models of Financial\n  Interconnectedness",
        "authors": [
            "Johannes Hain",
            "Tom Fischer"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Much research in systemic risk is focused on default contagion. While this\ndemands an understanding of valuation, fewer articles specifically deal with\nthe existence, the uniqueness, and the computation of equilibrium prices in\nstructural models of interconnected financial systems. However, beyond\ncontagion research, these topics are also essential for risk-neutral pricing.\nIn this article, we therefore study and compare valuation algorithms in the\nstandard model of debt and equity cross-ownership which has crystallized in the\nwork of several authors over the past one and a half decades. Since known\nalgorithms have potentially infinite runtime, we develop a class of new\nalgorithms, which find exact solutions in finitely many calculation steps. A\nsimulation study for a range of financial system designs allows us to derive\nconclusions about the efficiency of different numerical methods under different\nsystem parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.07402v1"
    },
    {
        "title": "Liquidity costs: a new numerical methodology and an empirical study",
        "authors": [
            "Christophe Michel",
            "Victor Reutenauer",
            "Denis Talay",
            "Etienne Tanré"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We consider rate swaps which pay a fixed rate against a floating rate in\npresence of bid-ask spread costs. Even for simple models of bid-ask spread\ncosts, there is no explicit strategy optimizing an expected function of the\nhedging error. We here propose an efficient algorithm based on the stochastic\ngradient method to compute an approximate optimal strategy without solving a\nstochastic control problem. We validate our algorithm by numerical experiments.\nWe also develop several variants of the algorithm and discuss their\nperformances in terms of the numerical parameters and the liquidity cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.07404v2"
    },
    {
        "title": "Exponential integrability properties of Euler discretization schemes for\n  the Cox-Ingersoll-Ross process",
        "authors": [
            "Andrei Cozma",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We analyze exponential integrability properties of the Cox-Ingersoll-Ross\n(CIR) process and its Euler discretizations with various types of truncation\nand reflection at 0. These properties play a key role in establishing the\nfiniteness of moments and the strong convergence of numerical approximations\nfor a class of stochastic differential equations arising in finance. We prove\nthat both implicit and explicit Euler-Maruyama discretizations for the CIR\nprocess preserve the exponential integrability of the exact solution for a wide\nrange of parameters, and find lower bounds on the explosion time.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.00919v1"
    },
    {
        "title": "Interacting Default Intensity with Hidden Markov Process",
        "authors": [
            "Feng-Hui Yu",
            "Wai-Ki Ching",
            "Jia-Wen Gu",
            "Tak-Kuen Siu"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  In this paper we consider a reduced-form intensity-based credit risk model\nwith a hidden Markov state process. A filtering method is proposed for\nextracting the underlying state given the observation processes. The method may\nbe applied to a wide range of problems. Based on this model, we derive the\njoint distribution of multiple default times without imposing stringent\nassumptions on the form of default intensities. Closed-form formulas for the\ndistribution of default times are obtained which are then applied to solve a\nnumber of practical problems such as hedging and pricing credit derivatives.\nThe method and numerical algorithms presented may be applicable to various\nforms of default intensities.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.02902v1"
    },
    {
        "title": "Capital Valuation Adjustment and Funding Valuation Adjustment",
        "authors": [
            "Claudio Albanese",
            "Simone Caenazzo",
            "Stéphane Crépey"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  In the aftermath of the 2007 global financial crisis, banks started\nreflecting into derivative pricing the cost of capital and collateral funding\nthrough XVA metrics. Here XVA is a catch-all acronym whereby X is replaced by a\nletter such as C for credit, D for debt, F for funding, K for capital and so\non, and VA stands for valuation adjustment. This behaviour is at odds with\neconomies where markets for contingent claims are complete, whereby trades\nclear at fair valuations and the costs for capital and collateral are both\nirrelevant to investment decisions. In this paper, we set forth a mathematical\nformalism for derivative portfolio management in incomplete markets for banks.\nA particular emphasis is given to the problem of finding optimal strategies for\nretained earnings which ensure a sustainable dividend policy.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.03012v1"
    },
    {
        "title": "Numerical stability of a hybrid method for pricing options",
        "authors": [
            "Maya Briani",
            "Lucia Caramellino",
            "Giulia Terenzi",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We develop and study stability properties of a hybrid approximation of\nfunctionals of the Bates jump model with stochastic interest rate that uses a\ntree method in the direction of the volatility and the interest rate and a\nfinite-difference approach in order to handle the underlying asset price\nprocess. We also propose hybrid simulations for the model, following a binomial\ntree in the direction of both the volatility and the interest rate, and a\nspace-continuous approximation for the underlying asset price process coming\nfrom a Euler-Maruyama type scheme. We show that our methods allow to obtain\nefficient and accurate European and American option prices. Numerical\nexperiments are provided, and show the reliability and the efficiency of the\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.07225v4"
    },
    {
        "title": "GPU Computing in Bayesian Inference of Realized Stochastic Volatility\n  Model",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  The realized stochastic volatility (RSV) model that utilizes the realized\nvolatility as additional information has been proposed to infer volatility of\nfinancial time series. We consider the Bayesian inference of the RSV model by\nthe Hybrid Monte Carlo (HMC) algorithm. The HMC algorithm can be parallelized\nand thus performed on the GPU for speedup. The GPU code is developed with CUDA\nFortran. We compare the computational time in performing the HMC algorithm on\nGPU (GTX 760) and CPU (Intel i7-4770 3.4GHz) and find that the GPU can be up to\n17 times faster than the CPU. We also code the program with OpenACC and find\nthat appropriate coding can achieve the similar speedup with CUDA Fortran.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.08114v1"
    },
    {
        "title": "A Flexible Galerkin Scheme for Option Pricing in Lévy Models",
        "authors": [
            "Maximilian Gaß",
            "Kathrin Glau"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  One popular approach to option pricing in L\\'evy models is through solving\nthe related partial integro differential equation (PIDE). For the numerical\nsolution of such equations powerful Galerkin methods have been put forward e.g.\nby Hilber et al. (2013). As in practice large classes of models are maintained\nsimultaneously, flexibility in the driving L\\'evy model is crucial for the\nimplementation of these powerful tools. In this article we provide such a\nflexible finite element Galerkin method. To this end we exploit the Fourier\nrepresentation of the infinitesimal generator, i.e. the related symbol, which\nis explicitly available for the most relevant L\\'evy models. Empirical studies\nfor the Merton, NIG and CGMY model confirm the numerical feasibility of the\nmethod.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.08216v1"
    },
    {
        "title": "Numerical approximation of a cash-constrained firm value with investment\n  opportunities",
        "authors": [
            "Erwan Pierre",
            "Stéphane Villeneuve",
            "Xavier Warin"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We consider a singular control problem with regime switching that arises in\nproblems of optimal investment decisions of cash-constrained firms. The value\nfunction is proved to be the unique viscosity solution of the associated\nHamilton-Jacobi-Bellman equation.\n  Moreover, we give regularity properties of the value function as well as a\ndescription of the shape of the control regions. Based on these theoretical\nresults, a numerical deterministic approximation of the related HJB variational\ninequality is provided. We finally show that this numerical approximation\nconverges to the value function. This allows us to describe the investment and\ndividend optimal policies.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.09049v2"
    },
    {
        "title": "Unbiased Monte Carlo Simulation of Diffusion Processes",
        "authors": [
            "Louis Paulot"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  Monte Carlo simulations of diffusion processes often introduce bias in the\nfinal result, due to time discretization. Using an auxiliary Poisson process,\nit is possible to run simulations which are unbiased. In this article, we\npropose such a Monte Carlo scheme which converges to the exact value. We manage\nto keep the simulation variance finite in all cases, so that the strong law of\nlarge numbers guarantees the convergence. Moreover, the simulation noise is a\ndecreasing function of the Poisson process intensity. Our method handles\nmultidimensional processes with nonconstant drifts and nonconstant\nvariance-covariance matrices. It also encompasses stochastic interest rates.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.01998v1"
    },
    {
        "title": "Trading VIX Futures under Mean Reversion with Regime Switching",
        "authors": [
            "Jiao Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  This paper studies the optimal VIX futures trading problems under a\nregime-switching model. We consider the VIX as mean reversion dynamics with\ndependence on the regime that switches among a finite number of states. For the\ntrading strategies, we analyze the timings and sequences of the investor's\nmarket participation, which leads to several corresponding coupled system of\nvariational inequalities. The numerical approach is developed to solve these\noptimal double stopping problems by using projected-successive-over-relaxation\n(PSOR) method with Crank-Nicolson scheme. We illustrate the optimal boundaries\nvia numerical examples of two-state Markov chain model. In particular, we\nexamine the impacts of transaction costs and regime-switching timings on the\nVIX futures trading strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.07945v2"
    },
    {
        "title": "Fast calibration of the Libor Market Model with Stochastic Volatility\n  and Displaced Diffusion",
        "authors": [
            "Laurent Devineau",
            "Pierre-Edouard Arrouy",
            "Paul Bonnefoy",
            "Alexandre Boumezoued"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This paper demonstrates the efficiency of using Edgeworth and Gram-Charlier\nexpansions in the calibration of the Libor Market Model with Stochastic\nVolatility and Displaced Diffusion (DD-SV-LMM). Our approach brings together\ntwo research areas; first, the results regarding the SV-LMM since the work of\nWu and Zhang (2006), especially on the moment generating function, and second\nthe approximation of density distributions based on Edgeworth or Gram-Charlier\nexpansions. By exploring the analytical tractability of moments up to fourth\norder, we are able to perform an adjustment of the reference Bachelier model\nwith normal volatilities for skewness and kurtosis, and as a by-product to\nderive a smile formula relating the volatility to the moneyness with\ninterpretable parameters. As a main conclusion, our numerical results show a\n98% reduction in computational time for the DD-SV-LMM calibration process\ncompared to the classical numerical integration method developed by Heston\n(1993).\n",
        "pdf_link": "http://arxiv.org/pdf/1706.00263v1"
    },
    {
        "title": "Most-likely-path in Asian option pricing under local volatility models",
        "authors": [
            "Louis-Pierre Arguin",
            "Nien-Lin Liu",
            "Tai-Ho Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This article addresses the problem of approximating the price of options on\ndiscrete and continuous arithmetic average of the underlying, i.e. discretely\nand continuously monitored Asian options, in local volatility models. A\npath-integral-type expression for option prices is obtained using a Brownian\nbridge representation for the transition density between consecutive sampling\ntimes and a Laplace asymptotic formula. In the limit where the sampling time\nwindow approaches zero, the option price is found to be approximated by a\nconstrained variational problem on paths in time-price space. We refer to the\noptimizing path as the most-likely path (MLP). Approximation for the implied\nnormal volatility follows accordingly. The small-time asymptotics and the\nexistence of the MLP are also recovered rigorously using large deviation\ntheory.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.02408v2"
    },
    {
        "title": "Speed and biases of Fourier-based pricing choices: A numerical analysis",
        "authors": [
            "Ricardo Crisóstomo"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We compare the CPU effort and pricing biases of seven Fourier-based\nimplementations. Our analyses show that truncation and discretization errors\nsignificantly increase as we move away from the Black-Scholes-Merton framework.\nWe rank the speed and accuracy of the competing choices, showing which methods\nrequire smaller truncation ranges and which are the most efficient in terms of\nsampling densities. While all implementations converge well in the Bates\njump-diffusion model, Attari's formula is the only Fourier-based method that\ndoes not blow up for any Variance Gamma parameter values. In terms of speed,\nthe use of strike vector computations significantly improves the computational\nburden, rendering both fast Fourier transforms (FFT) and plain\ndelta-probability decompositions inefficient. We conclude that the multi-strike\nversion of the COS method is notably faster than any other implementation,\nwhereas the strike-optimized Carr Madan's formula is simultaneously faster and\nmore accurate than the FFT, thus questioning its use.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.05935v3"
    },
    {
        "title": "Singular Fourier-Padé Series Expansion of European Option Prices",
        "authors": [
            "Tat Lung Chan"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We apply a new numerical method, the singular Fourier-Pad\\'e (SFP) method\ninvented by Driscoll and Fornberg (2001, 2011), to price European-type options\nin L\\'evy and affine processes. The motivation behind this application is to\nreduce the inefficiency of current Fourier techniques when they are used to\napproximate piecewise continuous (non-smooth) probability density functions.\nWhen techniques such as fast Fourier transforms and Fourier series are applied\nto price and hedge options with non-smooth probability density functions, they\ncause the Gibbs phenomenon, accordingly, the techniques converge slowly for\ndensity functions with jumps in value or derivatives. This seriously adversely\naffects the efficiency and accuracy of these techniques. In this paper, we\nderive pricing formulae and their option Greeks using the SFP method to resolve\nthe Gibbs phenomenon and restore the global spectral convergence rate.\nMoreover, we show that our method requires a small number of terms to yield\nfast error convergence, and it is able to accurately price any European-type\noption deep in/out of the money and with very long/short maturities.\nFurthermore, we conduct an error-bound analysis of the SFP method in option\npricing. This new method performs favourably in numerical experiments compared\nwith existing techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.06709v3"
    },
    {
        "title": "Strong convergence rates for Euler approximations to a class of\n  stochastic path-dependent volatility models",
        "authors": [
            "Andrei Cozma",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We consider a class of stochastic path-dependent volatility models where the\nstochastic volatility, whose square follows the Cox-Ingersoll-Ross model, is\nmultiplied by a (leverage) function of the spot price, its running maximum, and\ntime. We propose a Monte Carlo simulation scheme which combines a log-Euler\nscheme for the spot process with the full truncation Euler scheme or the\nbackward Euler-Maruyama scheme for the squared stochastic volatility component.\nUnder some mild regularity assumptions and a condition on the Feller ratio, we\nestablish the strong convergence with order 1/2 (up to a logarithmic factor) of\nthe approximation process up to a critical time. The model studied in this\npaper contains as special cases Heston-type stochastic-local volatility models,\nthe state-of-the-art in derivative pricing, and a relatively new class of\npath-dependent volatility models. The present paper is the first to prove the\nconvergence of the popular Euler schemes with a positive rate, which is\nmoreover consistent with that for Lipschitz coefficients and hence optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.07375v2"
    },
    {
        "title": "Hilbert transform, spectral filters and option pricing",
        "authors": [
            "Carolyn E. Phelan",
            "Daniele Marazzina",
            "Gianluca Fusai",
            "Guido Germano"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We show how spectral filters can improve the convergence of numerical schemes\nwhich use discrete Hilbert transforms based on a sinc function expansion, and\nthus ultimately on the fast Fourier transform. This is relevant, for example,\nfor the computation of fluctuation identities, which give the distribution of\nthe maximum or the minimum of a random path, or the joint distribution at\nmaturity with the extrema staying below or above barriers. We use as examples\nthe methods by Feng and Linetsky (2008) and Fusai, Germano and Marazzina (2016)\nto price discretely monitored barrier options where the underlying asset price\nis modelled by an exponential L\\'evy process. Both methods show exponential\nconvergence with respect to the number of grid points in most cases, but are\nlimited to polynomial convergence under certain conditions. We relate these\nrates of convergence to the Gibbs phenomenon for Fourier transforms and achieve\nimproved results with spectral filtering.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.09755v2"
    },
    {
        "title": "DeepLOB: Deep Convolutional Neural Networks for Limit Order Books",
        "authors": [
            "Zihao Zhang",
            "Stefan Zohren",
            "Stephen Roberts"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We develop a large-scale deep learning model to predict price movements from\nlimit order book (LOB) data of cash equities. The architecture utilises\nconvolutional filters to capture the spatial structure of the limit order books\nas well as LSTM modules to capture longer time dependencies. The proposed\nnetwork outperforms all existing state-of-the-art algorithms on the benchmark\nLOB dataset [1]. In a more realistic setting, we test our model by using one\nyear market quotes from the London Stock Exchange and the model delivers a\nremarkably stable out-of-sample prediction accuracy for a variety of\ninstruments. Importantly, our model translates well to instruments which were\nnot part of the training set, indicating the model's ability to extract\nuniversal features. In order to better understand these features and to go\nbeyond a \"black box\" model, we perform a sensitivity analysis to understand the\nrationale behind the model predictions and reveal the components of LOBs that\nare most relevant. The ability to extract robust features which translate well\nto other instruments is an important property of our model which has many other\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.03668v6"
    },
    {
        "title": "Black Magic Investigation Made Simple: Monte Carlo Simulations and\n  Historical Back Testing of Momentum Cross-Over Strategies Using FRACTI\n  Patterns",
        "authors": [
            "Jorge Faleiro",
            "Edward Tsang"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  To promote economic stability, finance should be studied as a hard science,\nwhere scientific methods apply. When a trading strategy is proposed, the\nunderlying model should be transparent and defined robustly to allow other\nresearchers to understand and examine it thoroughly. Like any hard sciences,\nresults must be repeatable to allow researchers to collaborate, and build upon\neach other's results. Large-scale collaboration, when applying the steps of\nscientific investigation, is an efficient way to leverage \"crowd science\" to\naccelerate research in finance. In this paper, we demonstrate how a real world\nproblem in economics, an old problem still subject to a lot of debate, can be\nsolved by the application of a crowd-powered, collaborative scientific\ncomputational framework, fully supporting the process of investigation dictated\nby the modern scientific method. This paper provides a real end-to-end example\nof investigation to illustrate the use of the framework. We intentionally\nselected an example that is self-contained, complete, simple, accessible, and\nof constant debate in both academia and the industry: the performance of a\ntrading strategy used commonly in technical analysis. Claims of efficiency in\ntechnical analysis, referred derisively by some sources as \"Black Magic\", are\nof widespread use in mainstream media and usually met with a lot of\ncontroversy. In this paper we show that different researchers assess this\nstrategy differently, and the subsequent debate is due more to the lack of\nmethod than purpose. Most results reported are not repeatable by other\nresearchers. This is not satisfactory if we intend to approach finance as a\nhard science. To counterweight the status quo, we demonstrate what one could do\nby using collaborative and investigative features of contributions and\nleveraging the power of crowds.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.07949v1"
    },
    {
        "title": "A model for stocks dynamics based on a non-Gaussian path integral",
        "authors": [
            "Giovanni Paolinelli",
            "Gianni Arioli"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We introduce a model for the dynamics of stock prices based on a non\nquadratic path integral. The model is a generalization of Ilinski's path\nintegral model, more precisely we choose a different action, which can be tuned\nto different time scales. The result is a model with a very small number of\nparameters that provides very good fits of some stock prices and indices\nfluctuations.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01342v3"
    },
    {
        "title": "Computing Credit Valuation Adjustment solving coupled PIDEs in the Bates\n  model",
        "authors": [
            "Ludovic Goudenège",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Credit value adjustment (CVA) is the charge applied by financial institutions\nto the counterparty to cover the risk of losses on a counterpart default event.\nIn this paper we estimate such a premium under the Bates stochastic model\n(Bates [4]), which considers an underlying affected by both stochastic\nvolatility and random jumps. We propose an efficient method which improves the\nfinite-difference Monte Carlo (FDMC) approach introduced by de Graaf et al.\n[11]. In particular, the method we propose consists in replacing the Monte\nCarlo step of the FDMC approach with a finite difference step and the whole\nmethod relies on the efficient solution of two coupled partial\nintegro-differential equations (PIDE) which is done by employing the Hybrid\nTree-Finite Difference method developed by Briani et al. [6, 7, 8]. Moreover,\nthe direct application of the hybrid techniques in the original FDMC approach\nis also considered for comparison purposes. Several numerical tests prove the\neffectiveness and the reliability of the proposed approach when both European\nand American options are considered.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05328v1"
    },
    {
        "title": "A Language for Large-Scale Collaboration in Economics: A Streamlined\n  Computational Representation of Financial Models",
        "authors": [
            "Jorge Faleiro"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  This paper introduces Sigma, a domain-specific computational representation\nfor collaboration in large-scale for the field of economics. A computational\nrepresentation is not a programming language or a software platform. A\ncomputational representation is a domain-specific representation system based\non three specific elements: facets, contributions, and constraints of data.\nFacets are definable aspects that make up a subject or an object. Contributions\nare shareable and formal evidence, carrying specific properties, and produced\nas a result of a crowd-based scientific investigation. Constraints of data are\nrestrictions defining domain-specific rules of association between entities and\nrelationships. A computational representation serves as a layer of abstraction\nthat is required in order to define domain-specific concepts in computers, in a\nway these concepts can be shared in a crowd for the purposes of a controlled\nscientific investigation in large-scale by crowds. Facets, contributions, and\nconstraints of data are defined for any domain of knowledge by the application\nof a generic set of inputs, procedural steps, and products called a\nrepresentational process. The application of this generic process to our domain\nof knowledge, the field of economics, produces Sigma. Sigma is described in\nthis paper in terms of its three elements: facets (streaming, reactives,\ndistribution, and simulation), contributions (financial models, processors, and\nendpoints), and constraints of data (configuration, execution, and simulation\nmeta-model). Each element of the generic representational process and the Sigma\ncomputational representation is described and formalized in details.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06471v1"
    },
    {
        "title": "Enabling Scientific Crowds: The Theory of Enablers for Crowd-Based\n  Scientific Investigation",
        "authors": [
            "Jorge Faleiro"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Evidence shows that in a significant number of cases the current methods of\nresearch do not allow for reproducible and falsifiable procedures of scientific\ninvestigation. As a consequence, the majority of critical decisions at all\nlevels, from personal investment choices to overreaching global policies, rely\non some variation of try-and-error and are mostly non-scientific by definition.\nWe lack transparency for procedures and evidence, proper explanation of market\nevents, predictability on effects, or identification of causes. There is no\nclear demarcation of what is inherently scientific, and as a consequence, the\nline between fake and genuine is blurred. This paper presents highlights of the\nTheory of Enablers for Crowd-Based Scientific Investigation, or Theory of\nEnablers for short. The Theory of Enablers assumes the use of a next-generation\ninvestigative approach leveraging forces of human diversity, micro-specialized\ncrowds, and proper computer-assisted control methods associated with\naccessibility, reproducibility, communication, and collaboration. This paper\ndefines the set of very specific cognitive and non-cognitive enablers for\ncrowd-based scientific investigation: methods of proof, large-scale\ncollaboration, and a domain-specific computational representation. These\nenablers allow the application of procedures of structured scientific\ninvestigation powered by crowds, a collective brain in which neurons are human\ncollaborators\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07195v1"
    },
    {
        "title": "Exact Solutions for a GBM-type Stochastic Volatility Model having a\n  Stationary Distribution",
        "authors": [
            "Alan L. Lewis"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We find various exact solutions for a new stochastic volatility (SV) model:\nthe transition probability density, European-style option values, and (when it\nexists) the martingale defect. This may represent the first example of an SV\nmodel combining exact solutions, GBM-type volatility noise, and a stationary\nvolatility density.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.08635v2"
    },
    {
        "title": "A Splitting Strategy for the Calibration of Jump-Diffusion Models",
        "authors": [
            "Vinicius Albani",
            "Jorge Zubelli"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We present a detailed analysis and implementation of a splitting strategy to\nidentify simultaneously the local-volatility surface and the jump-size\ndistribution from quoted European prices. The underlying model consists of a\njump-diffusion driven asset with time and price dependent volatility. Our\napproach uses a forward Dupire-type partial-integro-differential equations for\nthe option prices to produce a parameter-to-solution map. The ill-posed inverse\nproblem for such map is then solved by means of a Tikhonov-type convex\nregularization. The proofs of convergence and stability of the algorithm are\nprovided together with numerical examples that substantiate the robustness of\nthe method both for synthetic and real data.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.02028v1"
    },
    {
        "title": "CVA and vulnerable options pricing by correlation expansions",
        "authors": [
            "Fabio Antonelli",
            "Alessandro Ramponi",
            "Sergio Scarlatti"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We consider the problem of computing the Credit Value Adjustment ({CVA}) of a\nEuropean option in presence of the Wrong Way Risk ({WWR}) in a default\nintensity setting. Namely we model the asset price evolution as solution to a\nlinear equation that might depend on different stochastic factors and we\nprovide an approximate evaluation of the option's price, by exploiting a\ncorrelation expansion approach, introduced in \\cite{AS}. We compare the\nnumerical performance of such a method with that recently proposed by Brigo et\nal. (\\cite{BR18}, \\cite{BRH18}) in the case of a call option driven by a GBM\ncorrelated with the CIR default intensity. We additionally report some\nnumerical evaluations obtained by other methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07294v1"
    },
    {
        "title": "The ETS challenges: a machine learning approach to the evaluation of\n  simulated financial time series for improving generation processes",
        "authors": [
            "Javier Franco-Pedroso",
            "Joaquin Gonzalez-Rodriguez",
            "Maria Planas",
            "Jorge Cubero",
            "Rafael Cobo",
            "Fernando Pablos"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  This paper presents an evaluation framework that attempts to quantify the\n\"degree of realism\" of simulated financial time series, whatever the simulation\nmethod could be, with the aim of discover unknown characteristics that are not\nbeing properly reproduced by such methods in order to improve them. For that\npurpose, the evaluation framework is posed as a machine learning problem in\nwhich some given time series examples have to be classified as simulated or\nreal financial time series. The \"challenge\" is proposed as an open competition,\nsimilar to those published at the Kaggle platform, in which participants must\nsend their classification results along with a description of the features and\nthe classifiers used. The results of these \"challenges\" have revealed some\ninteresting properties of financial data, and have lead to substantial\nimprovements in our simulation methods under research, some of which will be\ndescribed in this work.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07792v1"
    },
    {
        "title": "An Aspect of Optimal Regression Design for LSMC",
        "authors": [
            "Christian Weiß",
            "Zoran Nikolić"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Practitioners sometimes suggest to use a combination of Sobol sequences and\northonormal polynomials when applying an LSMC algorithm for evaluation of\noption prices or in the context of risk capital calculation under the Solvency\nII regime. In this paper, we give a theoretical justification why good\nimplementations of an LSMC algorithm should indeed combine these two features\nin order to assure numerical stability. Moreover, an explicit bound for the\nnumber of outer scenarios necessary to guarantee a prescribed degree of\nnumerical stability is derived. We embed our observations into a coherent\npresentation of the theoretical background of LSMC in the insurance setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08509v2"
    },
    {
        "title": "Solving Nonlinear and High-Dimensional Partial Differential Equations\n  via Deep Learning",
        "authors": [
            "Ali Al-Aradi",
            "Adolfo Correia",
            "Danilo Naiff",
            "Gabriel Jardim",
            "Yuri Saporito"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this work we apply the Deep Galerkin Method (DGM) described in Sirignano\nand Spiliopoulos (2018) to solve a number of partial differential equations\nthat arise in quantitative finance applications including option pricing,\noptimal execution, mean field games, etc. The main idea behind DGM is to\nrepresent the unknown function of interest using a deep neural network. A key\nfeature of this approach is the fact that, unlike other commonly used numerical\napproaches such as finite difference methods, it is mesh-free. As such, it does\nnot suffer (as much as other numerical methods) from the curse of\ndimensionality associated with highdimensional PDEs and PDE systems. The main\ngoals of this paper are to elucidate the features, capabilities and limitations\nof DGM by analyzing aspects of its implementation for a number of different\nPDEs and PDE systems. Additionally, we present: (1) a brief overview of PDEs in\nquantitative finance along with numerical methods for solving them; (2) a brief\noverview of deep learning and, in particular, the notion of neural networks;\n(3) a discussion of the theoretical foundations of DGM with a focus on the\njustification of why this method is expected to perform well.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08782v1"
    },
    {
        "title": "BDLOB: Bayesian Deep Convolutional Neural Networks for Limit Order Books",
        "authors": [
            "Zihao Zhang",
            "Stefan Zohren",
            "Stephen Roberts"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We showcase how dropout variational inference can be applied to a large-scale\ndeep learning model that predicts price movements from limit order books\n(LOBs), the canonical data source representing trading and pricing movements.\nWe demonstrate that uncertainty information derived from posterior predictive\ndistributions can be utilised for position sizing, avoiding unnecessary trades\nand improving profits. Further, we test our models by using millions of\nobservations across several instruments and markets from the London Stock\nExchange. Our results suggest that those Bayesian techniques not only deliver\nuncertainty information that can be used for trading but also improve\npredictive performance as stochastic regularisers. To the best of our\nknowledge, we are the first to apply Bayesian networks to LOBs.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.10041v1"
    },
    {
        "title": "Forecasting interest rates through Vasicek and CIR models: a\n  partitioning approach",
        "authors": [
            "Giuseppe Orlando",
            "Rosa Maria Mininni",
            "Michele Bufalo"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  The aim of this paper is to propose a new methodology that allows\nforecasting, through Vasicek and CIR models, of future expected interest rates\n(for each maturity) based on rolling windows from observed financial market\ndata. The novelty, apart from the use of those models not for pricing but for\nforecasting the expected rates at a given maturity, consists in an appropriate\npartitioning of the data sample. This allows capturing all the statistically\nsignificant time changes in volatility of interest rates, thus giving an\naccount of jumps in market dynamics. The performance of the new approach is\ncarried out for different term structures and is tested for both models. It is\nshown how the proposed methodology overcomes both the usual challenges (e.g.\nsimulating regime switching, volatility clustering, skewed tails, etc.) as well\nas the new ones added by the current market environment characterized by low to\nnegative interest rates.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.02246v2"
    },
    {
        "title": "Remarks on stochastic automatic adjoint differentiation and financial\n  models calibration",
        "authors": [
            "Dmitri Goloubentsev",
            "Evgeny Lakshtanov"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this work, we discuss the Automatic Adjoint Differentiation (AAD) for\nfunctions of the form $G=\\frac{1}{2}\\sum_1^m (Ey_i-C_i)^2$, which often appear\nin the calibration of stochastic models. { We demonstrate that it allows a\nperfect SIMD\\footnote{Single Input Multiple Data} parallelization and provide\nits relative computational cost. In addition we demonstrate that this\ntheoretical result is in concordance with numeric experiments.}\n",
        "pdf_link": "http://arxiv.org/pdf/1901.04200v2"
    },
    {
        "title": "A Probabilistic Approach to Nonparametric Local Volatility",
        "authors": [
            "Martin Tegnér",
            "Stephen Roberts"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  The local volatility model is a widely used for pricing and hedging financial\nderivatives. While its main appeal is its capability of reproducing any given\nsurface of observed option prices---it provides a perfect fit---the essential\ncomponent is a latent function which can be uniquely determined only in the\nlimit of infinite data. To (re)construct this function, numerous calibration\nmethods have been suggested involving steps of interpolation and extrapolation,\nmost often of parametric form and with point-estimate representations. We look\nat the calibration problem in a probabilistic framework with a nonparametric\napproach based on a Gaussian process prior. This immediately gives a way of\nencoding prior beliefs about the local volatility function and a hypothesis\nmodel which is highly flexible yet not prone to over-fitting. Besides providing\na method for calibrating a (range of) point-estimate(s), we draw posterior\ninference from the distribution over local volatility. This leads to a better\nunderstanding of uncertainty associated with the calibration in particular, and\nwith the model in general. Further, we infer dynamical properties of local\nvolatility by augmenting the hypothesis space with a time dimension. Ideally,\nthis provides predictive distributions not only locally, but also for entire\nsurfaces forward in time. We apply our approach to S&P 500 market data.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.06021v2"
    },
    {
        "title": "A Backward Simulation Method for Stochastic Optimal Control Problems",
        "authors": [
            "Zhiyi Shen",
            "Chengguo Weng"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  A number of optimal decision problems with uncertainty can be formulated into\na stochastic optimal control framework. The Least-Squares Monte Carlo (LSMC)\nalgorithm is a popular numerical method to approach solutions of such\nstochastic control problems as analytical solutions are not tractable in\ngeneral. This paper generalizes the LSMC algorithm proposed in Shen and Weng\n(2017) to solve a wide class of stochastic optimal control models. Our\nalgorithm has three pillars: a construction of auxiliary stochastic control\nmodel, an artificial simulation of the post-action value of state process, and\na shape-preserving sieve estimation method which equip the algorithm with a\nnumber of merits including bypassing forward simulation and control\nrandomization, evading extrapolating the value function, and alleviating\ncomputational burden of the tuning parameter selection. The efficacy of the\nalgorithm is corroborated by an application to pricing equity-linked insurance\nproducts.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.06715v1"
    },
    {
        "title": "Gaussian Process Regression for Derivative Portfolio Modeling and\n  Application to CVA Computations",
        "authors": [
            "Stéphane Crépey",
            "Matthew Dixon"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Modeling counterparty risk is computationally challenging because it requires\nthe simultaneous evaluation of all the trades with each counterparty under both\nmarket and credit risk. We present a multi-Gaussian process regression\napproach, which is well suited for OTC derivative portfolio valuation involved\nin CVA computation. Our approach avoids nested simulation or simulation and\nregression of cash flows by learning a Gaussian metamodel for the\nmark-to-market cube of a derivative portfolio. We model the joint posterior of\nthe derivatives as a Gaussian process over function space, with the spatial\ncovariance structure imposed on the risk factors. Monte-Carlo simulation is\nthen used to simulate the dynamics of the risk factors. The uncertainty in\nportfolio valuation arising from the Gaussian process approximation is\nquantified numerically. Numerical experiments demonstrate the accuracy and\nconvergence properties of our approach for CVA computations, including a\ncounterparty portfolio of interest rate swaps.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11081v2"
    },
    {
        "title": "Branching Particle Pricers with Heston Examples",
        "authors": [
            "Michael A. Kouritzin",
            "Anne MacKay"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  The use of sequential Monte Carlo within simulation for path-dependent option\npricing is proposed and evaluated. Recently, it was shown that explicit\nsolutions and importance sampling are valuable for efficient simulation of spot\nprice and volatility, especially for purposes of path-dependent option pricing.\nThe resulting simulation algorithm is an analog to the weighted particle\nfiltering algorithm that might be improved by resampling or branching. Indeed,\nsome branching algorithms are shown herein to improve pricing performance\nsubstantially while some resampling algorithms are shown to be less suitable in\ncertain cases. A historical property is given and explained as the\ndistinguishing feature between the sequential Monte Carlo algorithms that work\non path-dependent option pricing and those that do not. In particular, it is\nrecommended to use the so-called effective particle branching algorithm within\nimportance-sampling Monte Carlo methods for path-dependent option pricing. All\nrecommendations are based upon numeric comparison of option pricing problems in\nthe Heston model.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.00219v2"
    },
    {
        "title": "The Numerical Simulation of Quanto Option Prices Using Bayesian\n  Statistical Methods",
        "authors": [
            "Lisha Lin",
            "Yaqiong Li",
            "Rui Gao",
            "Jianhong Wu"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In the paper, the pricing of Quanto options is studied, where the underlying\nforeign asset and the exchange rate are correlated with each other. Firstly, we\nadopt Bayesian methods to estimate unknown parameters entering the pricing\nformula of Quanto options, including the volatility of stock, the volatility of\nexchange rate and the correlation. Secondly, we compute and predict prices of\ndifferent four types of Quanto options based on Bayesian posterior prediction\ntechniques and Monte Carlo methods. Finally, we provide numerical simulations\nto demonstrate the advantage of Bayesian method used in this paper comparing\nwith some other existing methods. This paper is a new application of the\nBayesian methods in the pricing of multi-asset options.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.04075v1"
    },
    {
        "title": "Option-based Equity Risk Premiums",
        "authors": [
            "Alan L. Lewis"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We construct the term structure of the (forward-looking, US market) equity\nrisk premium from SPX option chains. The method is \"model-light\". Risk-neutral\nprobability densities are estimated by fitting $N$-component Gaussian mixture\nmodels to option quotes, where $N$ is a small integer (here 4 or 5). These\ndensities are transformed to their real-world equivalents by exponential\ntilting with a single parameter: the Coefficient of Relative Risk Aversion\n$\\kappa$. From history, I estimate $\\kappa = 3 \\pm 0.5$. From the inferred\nreal-world densities, the equity risk premium is readily calculated. Three term\nstructures serve as examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.14522v2"
    },
    {
        "title": "Asymptotic expansion for the transition densities of stochastic\n  differential equations driven by the gamma processes",
        "authors": [
            "Fan Jiang",
            "Xin Zang",
            "Jingping Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper, enlightened by the asymptotic expansion methodology developed\nby Li(2013b) and Li and Chen (2016), we propose a Taylor-type approximation for\nthe transition densities of the stochastic differential equations (SDEs) driven\nby the gamma processes, a special type of Levy processes. After representing\nthe transition density as a conditional expectation of Dirac delta function\nacting on the solution of the related SDE, the key technical method for\ncalculating the expectation of multiple stochastic integrals conditional on the\ngamma process is presented. To numerically test the efficiency of our method,\nwe examine the pure jump Ornstein--Uhlenbeck (OU) model and its extensions to\ntwo jump-diffusion models. For each model, the maximum relative error between\nour approximated transition density and the benchmark density obtained by the\ninverse Fourier transform of the characteristic function is sufficiently small,\nwhich shows the efficiency of our approximated method.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.06218v1"
    },
    {
        "title": "Options on infectious diseases",
        "authors": [
            "Andrew Lesniewski",
            "Nicholas Lesniewski"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We present a parsimonious stochastic model for valuation of options on the\nfraction of infected individuals during an epidemic. The underlying stochastic\ndynamical system is a stochastic differential version of the SIR model of\nmathematical epidemiology.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07992v3"
    },
    {
        "title": "Bank financial stability, bank valuation and international oil prices:\n  Evidence from listed Russian public banks",
        "authors": [
            "Claudiu Albulescu"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Using data on 17 listed public banks from Russia over the period 2008 to\n2016, we analyze whether international oil prices affect the bank stability in\nan oil-dependent country. We posit that a decrease in international oil prices\nhas a negative long-run macroeconomic impact for an oil-exporting country,\nwhich further deteriorates the bank financial stability. More specifically, a\ndecrease in international oil prices leads for an oil-exporting country as\nRussia to a currency depreciation and to a deterioration of the fiscal stance.\nIn addition, given the positive correlation of oil and stock prices documented\nby numerous previous studies, a decrease in international oil prices represents\na negative signal for the stock markets investors, negatively affecting banks'\nshare prices and thus, their capacity to generate sustainable earnings. In this\ncontext, the bank financial stability can be menaced. With a focus on public\nlisted banks and using a Pool Mean Group (PMG) estimator, we show that an\nincrease in international oil prices and in the price to book value ratio has a\nlong-run positive effect on Russian public banks stability, and conversely.\nWhile positive oil-price shocks contribute to bank stability in the long run,\nan opposite effect is recorded for negative shocks. However, no significant\nimpact is documented in the short run. Our findings are robust to different\nbank stability specifications, different samples and control variables.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.12791v1"
    },
    {
        "title": "Note on simulation pricing of $π$-options",
        "authors": [
            "Zbigniew Palmowski",
            "Tomasz Serafin"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this work, we adapt a Monte Carlo algorithm introduced by Broadie and\nGlasserman (1997) to price a $\\pi$-option. This method is based on the\nsimulated price tree that comes from discretization and replication of possible\ntrajectories of the underlying asset's price. As a result this algorithm\nproduces the lower and the upper bounds that converge to the true price with\nthe increasing depth of the tree. Under specific parametrization, this\n$\\pi$-option is related to relative maximum drawdown and can be used in the\nreal-market environment to protect a portfolio against volatile and unexpected\nprice drops. We also provide some numerical analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.02076v2"
    },
    {
        "title": "Deep Importance Sampling",
        "authors": [
            "Benjamin Virrion"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We present a generic path-dependent importance sampling algorithm where the\nGirsanov induced change of probability on the path space is represented by a\nsequence of neural networks taking the past of the trajectory as an input. At\neach learning step, the neural networks' parameters are trained so as to reduce\nthe variance of the Monte Carlo estimator induced by this change of measure.\nThis allows for a generic path dependent change of measure which can be used to\nreduce the variance of any path-dependent financial payoff. We show in our\nnumerical experiments that for payoffs consisting of either a call, an\nasymmetric combination of calls and puts, a symmetric combination of calls and\nputs, a multi coupon autocall or a single coupon autocall, we are able to\nreduce the variance of the Monte Carlo estimators by factors between 2 and 9.\nThe numerical experiments also show that the method is very robust to changes\nin the parameter values, which means that in practice, the training can be done\noffline and only updated on a weekly basis.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.02692v2"
    },
    {
        "title": "Bond indifference prices and indifference yield curves",
        "authors": [
            "Matthew Lorig"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In a market with stochastic interest rates, we consider an investor who can\neither (i) invest all if his money in a savings account or (ii) purchase\nzero-coupon bonds and invest the remainder of his wealth in a savings account.\nThe indifference price of the bond is the price for which the investor could\nachieve the same expected utility under both scenarios. In an affine term\nstructure setting, under the assumption that an investor has a utility function\nin either exponential or power form, we show that the indifference price of a\nzero-coupon bond is the root of an integral expression. As an example, we\ncompute bond indifference prices and the corresponding indifference yield\ncurves in the Vasicek setting and interpret the results.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09201v1"
    },
    {
        "title": "Deep Local Volatility",
        "authors": [
            "Marc Chataigner",
            "Stéphane Crépey",
            "Matthew Dixon"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Deep learning for option pricing has emerged as a novel methodology for fast\ncomputations with applications in calibration and computation of Greeks.\nHowever, many of these approaches do not enforce any no-arbitrage conditions,\nand the subsequent local volatility surface is never considered. In this\narticle, we develop a deep learning approach for interpolation of European\nvanilla option prices which jointly yields the full surface of local\nvolatilities. We demonstrate the modification of the loss function or the feed\nforward network architecture to enforce (hard constraints approach) or favor\n(soft constraints approach) the no-arbitrage conditions and we specify the\nexperimental design parameters that are needed for adequate performance. A\nnovel component is the use of the Dupire formula to enforce bounds on the local\nvolatility associated with option prices, during the network fitting. Our\nmethodology is benchmarked numerically on real datasets of DAX vanilla options.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.10462v1"
    },
    {
        "title": "Editorial: Understanding Cryptocurrencies",
        "authors": [
            "Wolfgang Karl Härdle",
            "Campbell R. Harvey",
            "Raphael C. G. Reule"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Cryptocurrency refers to a type of digital asset that uses distributed\nledger, or blockchain, technology to enable a secure transaction. Although the\ntechnology is widely misunderstood, many central banks are considering\nlaunching their own national cryptocurrency. In contrast to most data in\nfinancial economics, detailed data on the history of every transaction in the\ncryptocurrency complex are freely available. Furthermore, empirically-oriented\nresearch is only now beginning, presenting an extraordinary research\nopportunity for academia. We provide some insights into the mechanics of\ncryptocurrencies, describing summary statistics and focusing on potential\nfuture research avenues in financial economics.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.14702v1"
    },
    {
        "title": "Equilibrium price in intraday electricity markets",
        "authors": [
            "René Aid",
            "Andrea Cosso",
            "Huyên Pham"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We formulate an equilibrium model of intraday trading in electricity markets.\nAgents face balancing constraints between their customers consumption plus\nintraday sales and their production plus intraday purchases. They have\ncontinuously updated forecast of their customers consumption at maturity with\ndecreasing volatility error. Forecasts are prone to idiosyncratic noise as well\nas common noise (weather). Agents production capacities are subject to\nindependent random outages, which are each modelled by a Markov chain. The\nequilibrium price is defined as the price that minimises trading cost plus\nimbalance cost of each agent and satisfies the usual market clearing condition.\nExistence and uniqueness of the equilibrium are proved, and we show that the\nequilibrium price and the optimal trading strategies are martingales. The main\neconomic insights are the following. (i) When there is no uncertainty on\ngeneration, it is shown that the market price is a convex combination of\nforecasted marginal cost of each agent, with deterministic weights.\nFurthermore, the equilibrium market price follows Almgren and Chriss's model\nand we identify the fundamental part as well as the permanent market impact. It\nturns out that heterogeneity across agents is a necessary condition for the\nSamuelson's effect to hold. (ii) When there is production uncertainty, the\nprice volatility becomes stochastic but converges to the case without\nproduction uncertainty when the number of agents increases to infinity.\nFurther, on a two-agent case, we show that the potential outages of a low\nmarginal cost producer reduces her sales position.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.09285v1"
    },
    {
        "title": "A Finite Element Approach to the Numerical Solutions of Leland's Mode",
        "authors": [
            "Dongming Wei",
            "Yogi Ahmad Erlangga",
            "Gulzat Zhumakhanova"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper, finite element method is applied to Leland's model for\nnumerical simulation of option pricing with transaction costs. Spatial finite\nelement models based on P1 and/or P2 elements are formulated in combination\nwith a Crank-Nicolson-type temporal scheme. The temporal scheme is implemented\nusing the Rannacher approach. Examples with several sets of parameter values\nare presented and compared with finite difference results in the literature.\nSpatial-temporal mesh-size ratios are observed for controlling the stability of\nour method. Our results compare favorably with the finite difference results in\nthe literature for the model.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.13541v1"
    },
    {
        "title": "Application of deep quantum neural networks to finance",
        "authors": [
            "Takayuki Sakuma"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The recent development of quantum computing gives us an opportunity to\nexplore its potential applications to many fields, with the field of finance\nbeing no exception. In this paper, we apply the deep quantum neural network\nproposed by Beer et al. (2020) and discuss such potential in the context of\nsimple experiments such as learning implied volatilities and option prices.\nFurthermore, Greeks such as delta and gamma, which are important measures in\nrisk management, can be computed analytically with the neural network, and our\nnumerical experiments show that the deep quantum neural network is a promising\ntechnique for solving such numerical problems arising in finance efficiently.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.07319v3"
    },
    {
        "title": "Solving path dependent PDEs with LSTM networks and path signatures",
        "authors": [
            "Marc Sabate-Vidales",
            "David Šiška",
            "Lukasz Szpruch"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Using a combination of recurrent neural networks and signature methods from\nthe rough paths theory we design efficient algorithms for solving parametric\nfamilies of path dependent partial differential equations (PPDEs) that arise in\npricing and hedging of path-dependent derivatives or from use of non-Markovian\nmodel, such as rough volatility models in Jacquier and Oumgari, 2019. The\nsolutions of PPDEs are functions of time, a continuous path (the asset price\nhistory) and model parameters. As the domain of the solution is infinite\ndimensional many recently developed deep learning techniques for solving PDEs\ndo not apply. Similarly as in Vidales et al. 2018, we identify the objective\nfunction used to learn the PPDE by using martingale representation theorem. As\na result we can de-bias and provide confidence intervals for then neural\nnetwork-based algorithm. We validate our algorithm using classical models for\npricing lookback and auto-callable options and report errors for approximating\nboth prices and hedging strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10630v1"
    },
    {
        "title": "Nowcasting Networks",
        "authors": [
            "Marc Chataigner",
            "Stephane Crepey",
            "Jiang Pu"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We devise a neural network based compression/completion methodology for\nfinancial nowcasting. The latter is meant in a broad sense encompassing\ncompletion of gridded values, interpolation, or outlier detection, in the\ncontext of financial time series of curves or surfaces (also applicable in\nhigher dimensions, at least in theory). In particular, we introduce an original\narchitecture amenable to the treatment of data defined at variable grid nodes\n(by far the most common situation in financial nowcasting applications, so that\nPCA or classical autoencoder methods are not applicable). This is illustrated\nby three case studies on real data sets. First, we introduce our approach on\nrepo curves data (with moving time-to-maturity as calendar time passes).\nSecond, we show that our approach outperforms elementary interpolation\nbenchmarks on an equity derivative surfaces data set (with moving\ntime-to-maturity again). We also obtain a satisfying performance for outlier\ndetection and surface completion. Third, we benchmark our approach against PCA\non at-the-money swaption surfaces redefined at constant expiry/tenor grid\nnodes. Our approach is then shown to perform as well as (even if not obviously\nbetter than) the PCA which, however, is not be applicable to the native, raw\ndata defined on a moving time-to-expiry grid).\n",
        "pdf_link": "http://arxiv.org/pdf/2011.13687v1"
    },
    {
        "title": "Pricing spread option with liquidity adjustments",
        "authors": [
            "Kevin Shuai Zhang",
            "Traian Pirvu"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We study the pricing and hedging of European spread options on correlated\nassets when, in contrast to the standard framework and consistent with\nimperfect liquidity markets, the trading in the stock market has a direct\nimpact on stocks prices. We consider a partial-impact and a full-impact model\nin which the price impact is caused by every trading strategy in the market.\nThe generalized Black-Scholes pricing partial differential equations (PDEs) are\nobtained and analysed. We perform a numerical analysis to exhibit the\nilliquidity effect on the replication strategy of the European spread option.\nCompared to the Black-Scholes model or a partial impact model, the trader in\nthe full impact model buys more stock to replicate the option, and this leads\nto a higher option price.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00223v1"
    },
    {
        "title": "Improved ACD-based financial trade durations prediction leveraging LSTM\n  networks and Attention Mechanism",
        "authors": [
            "Yong Shi",
            "Wei Dai",
            "Wen Long",
            "Bo Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The liquidity risk factor of security market plays an important role in the\nformulation of trading strategies. A more liquid stock market means that the\nsecurities can be bought or sold more easily. As a sound indicator of market\nliquidity, the transaction duration is the focus of this study. We concentrate\non estimating the probability density function p({\\Delta}t_(i+1) |G_i) where\n{\\Delta}t_(i+1) represents the duration of the (i+1)-th transaction, G_i\nrepresents the historical information at the time when the (i+1)-th transaction\noccurs. In this paper, we propose a new ultra-high-frequency (UHF) duration\nmodelling framework by utilizing long short-term memory (LSTM) networks to\nextend the conditional mean equation of classic autoregressive conditional\nduration (ACD) model while retaining the probabilistic inference ability. And\nthen the attention mechanism is leveraged to unveil the internal mechanism of\nthe constructed model. In order to minimize the impact of manual parameter\ntuning, we adopt fixed hyperparameters during the training process. The\nexperiments applied to a large-scale dataset prove the superiority of the\nproposed hybrid models. In the input sequence, the temporal positions which are\nmore important for predicting the next duration can be efficiently highlighted\nvia the added attention mechanism layer.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.02736v1"
    },
    {
        "title": "Day-ahead electricity price prediction applying hybrid models of\n  LSTM-based deep learning methods and feature selection algorithms under\n  consideration of market coupling",
        "authors": [
            "Wei Li",
            "Denis Mike Becker"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The availability of accurate day-ahead electricity price forecasts is pivotal\nfor electricity market participants. In the context of trade liberalisation and\nmarket harmonisation in the European markets, accurate price forecasting\nbecomes difficult for electricity market participants to obtain because\nelectricity forecasting requires the consideration of features from\never-growing coupling markets. This study provides a method of exploring the\ninfluence of market coupling on electricity price prediction. We apply\nstate-of-the-art long short-term memory (LSTM) deep neural networks combined\nwith feature selection algorithms for electricity price prediction under the\nconsideration of market coupling. LSTM models have a good performance in\nhandling nonlinear and complex problems and processing time series data. In our\nempirical study of the Nordic market, the proposed models obtain considerably\naccurate results. The results show that feature selection is essential to\nachieving accurate prediction, and features from integrated markets have an\nimpact on prediction. The feature importance analysis implies that the German\nmarket has a salient role in the price generation of Nord Pool.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05249v2"
    },
    {
        "title": "Extensive networks would eliminate the demand for pricing formulas",
        "authors": [
            "Jaegi Jeon",
            "Kyunghyun Park",
            "Jeonggyu Huh"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this study, we generate a large number of implied volatilities for the\nStochastic Alpha Beta Rho (SABR) model using a graphics processing unit (GPU)\nbased simulation and enable an extensive neural network to learn them. This\nmodel does not have any exact pricing formulas for vanilla options, and neural\nnetworks have an outstanding ability to approximate various functions.\nSurprisingly, the network reduces the simulation noises by itself, thereby\nachieving as much accuracy as the Monte-Carlo simulation. Extremely high\naccuracy cannot be attained via existing approximate formulas. Moreover, the\nnetwork is as efficient as the approaches based on the formulas. When\nevaluating based on high accuracy and efficiency, extensive networks can\neliminate the necessity of the pricing formulas for the SABR model. Another\nsignificant contribution is that a novel method is proposed to examine the\nerrors based on nonlinear regression. This approach is easily extendable to\nother pricing models for which it is hard to induce analytic formulas.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.09064v1"
    },
    {
        "title": "Oil-US Stock Market Nexus: Some insights about the New Coronavirus\n  Crisis",
        "authors": [
            "Claudiu Albulescu",
            "Michel Mina",
            "Cornel Oros"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We provide a new investigation of the relationship between oil and stock\nprices in the context of the outbreak of the new coronavirus crisis.\nSpecifically, we assess to what extent the uncertainty induced by COVID-19\naffects the interaction between oil and the United States (US) stock markets.\nTo this end, we use a wavelet approach and daily data from February 18, 2020 to\nAugust 15, 2020. We identify the lead-lag relationship between oil and stock\nprices, and the intensity of this relationship at different frequency cycles\nand moments in time. Our unique findings show that co-movements between oil and\nstock prices manifest at 3-5-day cycle and are stronger in the first part of\nMarch and the second part of April 2020, when oil prices are leading stock\nprices. The partial wavelet coherence analysis, controlling for the effect of\nCOVID-19 and US economic policy-induced uncertainty, reveals that the\ncoronavirus crisis amplifies the shock propagation between oil and stock\nprices.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.05273v1"
    },
    {
        "title": "The Efficient Hedging Frontier with Deep Neural Networks",
        "authors": [
            "Zheng Gong",
            "Carmine Ventre",
            "John O'Hara"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The trade off between risks and returns gives rise to multi-criteria\noptimisation problems that are well understood in finance, efficient frontiers\nbeing the tool to navigate their set of optimal solutions. Motivated by the\nrecent advances in the use of deep neural networks in the context of hedging\nvanilla options when markets have frictions, we introduce the Efficient Hedging\nFrontier (EHF) by enriching the pipeline with a filtering step that allows to\ntrade off costs and risks. This way, a trader's risk preference is matched with\nan expected hedging cost on the frontier, and the corresponding hedging\nstrategy can be computed with a deep neural network.\n  We further develop our framework to improve the EHF and find better hedging\nstrategies. By adding a random forest classifier to the pipeline to forecast\nmarket movements, we show how the frontier shifts towards lower costs and\nreduced risks, which indicates that the overall hedging performances have\nimproved. In addition, by designing a new recurrent neural network, we also\nfind strategies on the frontier where hedging costs are even lower.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.05280v1"
    },
    {
        "title": "Wavelet analysis and energy-based measures for oil-food price\n  relationship as a footprint of financialisation effect",
        "authors": [
            "Loretta Mastroeni",
            "Alessandro Mazzoccoli",
            "Greta Quaresima",
            "Pierluigi Vellucci"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this paper we exploit the wavelet analysis approach to investigate\noil-food price correlation and its determinants in the domains of time and\nfrequency. Wavelet analysis is able to differentiate high frequency from low\nfrequency movements which correspond, respectively, to short and long run\ndynamics. We show that the significant local correlation between food and oil\nis only apparent and this is mainly due both to the activity of commodity index\ninvestments and, to a lesser extent, to a growing demand from emerging\neconomies. Moreover, the activity of commodity index investments gives evidence\nof the overall financialisation process. In addition, we employ wavelet entropy\nto assess the predictability of the time series under consideration at\ndifferent frequencies. We find that some variables share a similar\npredictability structure with food and oil. These variables are the ones that\nmove the most along with oil and food. We also introduce a novel measure, the\nCross Wavelet Energy Entropy Measure (CWEEM), based on wavelet transformation\nand information entropy, with the aim of quantifying the intrinsic\npredictability of food and oil given demand from emerging economies, commodity\nindex investments, financial stress, and global economic activity. The results\nshow that these dynamics are best predicted by global economic activity at all\nfrequencies and by demand from emerging economies and commodity index\ninvestments at high frequencies only.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.11891v2"
    },
    {
        "title": "Efficient Least Squares Monte-Carlo Technique for PFE/EE Calculations",
        "authors": [
            "Yuriy Krepkiy",
            "Asif Lakhany",
            "Amber Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We describe a regression-based method, generally referred to as the Least\nSquares Monte Carlo (LSMC) method, to speed up exposure calculations of a\nportfolio. We assume that the portfolio contains several exotic derivatives\nthat are priced using Monte-Carlo on each real world scenario and time step.\nSuch a setting is often referred to as a Monte Carlo over a Monte Carlo or a\nNested Monte Carlo method.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07061v1"
    },
    {
        "title": "Effects of COVID-19 Vaccine Developments and Rollout on the Capital\n  Market -- A Case Study",
        "authors": [
            "Maximilian Vierlboeck",
            "Roshanak Rose Nilchiani"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Various companies have developed vaccines to combat the pandemic caused 2020\nby the virus COVID-19. Such vaccines and the distribution can have a major\nimpact on the success of pharmaceutical companies, which in turn can show\nitself in their valuation and stock price. This poses the question if and how\nthe trends or popularity of the companies might be connected to the value and\nstock price of said entities. To gain some insight into these questions, the\nwork at hand looks at five COVID vaccine development companies and evaluates\ntheir correlations over the development of the vaccine as well as after the\nrollout start. The process was conducted by using python including various\nlibraries. The result of this analysis was that there is a significant\ncorrelation between the Google Trend data and the respective stock prices\n(retrieved from yahoo! Finance) of the companies on average, where the time\nduring the development of the drugs is more positively correlated and the\npost-rollout periods show a shift to a slightly negative inclining correlation.\nFurthermore, it was found that the smaller companies based on their market cap\nshow a higher price volatility overall. In addition, higher average trend\nscores and thus popularity values were found after the rollout of the\nrespective companies. In conclusion, a correlations between the trend data and\nthe financial values have been found and corroborate the plots of the data. Due\nto the small size of the sample, the result cannot yet be considered\nstatistically significant, but possibility for expansion exists and is already\nbeing worked on.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.12267v1"
    },
    {
        "title": "Deep Kernel Gaussian Process Based Financial Market Predictions",
        "authors": [
            "Yong Shi",
            "Wei Dai",
            "Wen Long",
            "Bo Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The Gaussian Process with a deep kernel is an extension of the classic GP\nregression model and this extended model usually constructs a new kernel\nfunction by deploying deep learning techniques like long short-term memory\nnetworks. A Gaussian Process with the kernel learned by LSTM, abbreviated as\nGP-LSTM, has the advantage of capturing the complex dependency of financial\nsequential data, while retaining the ability of probabilistic inference.\nHowever, the deep kernel Gaussian Process has not been applied to forecast the\nconditional returns and volatility in financial market to the best of our\nknowledge. In this paper, grid search algorithm, used for performing\nhyper-parameter optimization, is integrated with GP-LSTM to predict both the\nconditional mean and volatility of stock returns, which are then combined\ntogether to calculate the conditional Sharpe Ratio for constructing a\nlong-short portfolio. The experiments are performed on a dataset covering all\nconstituents of Shenzhen Stock Exchange Component Index. Based on empirical\nresults, we find that the GP-LSTM model can provide more accurate forecasts in\nstock returns and volatility, which are jointly evaluated by the performance of\nconstructed portfolios. Further sub-period analysis of the experiment results\nindicates that the superiority of GP-LSTM model over the benchmark models stems\nfrom better performance in highly volatile periods.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.12293v1"
    },
    {
        "title": "Behavior of Liquidity Providers in Decentralized Exchanges",
        "authors": [
            "Lioba Heimbach",
            "Ye Wang",
            "Roger Wattenhofer"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Decentralized exchanges (DEXes) have introduced an innovative trading\nmechanism, where it is not necessary to match buy-orders and sell-orders to\nexecute a trade. DEXes execute each trade individually, and the exchange rate\nis automatically determined by the ratio of assets reserved in the market.\nTherefore, apart from trading, financial players can also liquidity providers,\nbenefiting from transaction fees from trades executed in DEXes. Although\nliquidity providers are essential for the functionality of DEXes, it is not\nclear how liquidity providers behave in such markets. In this paper, we aim to\nunderstand how liquidity providers react to market information and how they\nbenefit from providing liquidity in DEXes. We measure the operations of\nliquidity providers on Uniswap and analyze how they determine their investment\nstrategy based on market changes. We also reveal their returns and risks of\ninvestments in different trading pair categories, i.e., stable pairs, normal\npairs, and exotic pairs. Further, we investigate the movement of liquidity\nbetween trading pools. To the best of our knowledge, this is the first work\nthat systematically studies the behavior of liquidity providers in DEXes.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.13822v2"
    },
    {
        "title": "3D Tensor-based Deep Learning Models for Predicting Option Price",
        "authors": [
            "Muyang Ge",
            "Shen Zhou",
            "Shijun Luo",
            "Boping Tian"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Option pricing is a significant problem for option risk management and\ntrading. In this article, we utilize a framework to present financial data from\ndifferent sources. The data is processed and represented in a form of 2D\ntensors in three channels. Furthermore, we propose two deep learning models\nthat can deal with 3D tensor data. Experiments performed on the Chinese market\noption dataset prove the practicability of the proposed strategies over\ncommonly used ways, including B-S model and vector-based LSTM.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.02916v2"
    },
    {
        "title": "Pricing and Risk Analysis in Hyperbolic Local Volatility Model with\n  Quasi Monte Carlo",
        "authors": [
            "Julien Hok",
            "Sergei Kucherenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Local volatility models usually capture the surface of implied volatilities\nmore accurately than other approaches, such as stochastic volatility models. We\npresent the results of application of Monte Carlo (MC) and Quasi Monte Carlo\n(QMC) methods for derivative pricing and risk analysis based on Hyperbolic\nLocal Volatility Model. In high-dimensional integration QMC shows a superior\nperformance over MC if the effective dimension of an integrand is not too\nlarge. In application to derivative pricing and computation of Greeks effective\ndimensions depend on path discretization algorithms. The results presented for\nthe Asian option show the superior performance of the Quasi Monte Carlo methods\nespecially for the Brownian Bridge discretization scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.08421v1"
    },
    {
        "title": "More stochastic expansions for the pricing of vanilla options with cash\n  dividends",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  There is no exact closed form formula for pricing of European options with\ndiscrete cash dividends under the model where the underlying asset price\nfollows a piecewise lognormal process with jumps at dividend ex-dates. This\npaper presents alternative expansions based on the technique of Etore and\nGobet, leading to more robust first, second and third-order expansions across\nthe range of strikes and the range of dividend dates.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.12051v1"
    },
    {
        "title": "Price change prediction of ultra high frequency financial data based on\n  temporal convolutional network",
        "authors": [
            "Wei Dai",
            "Yuan An",
            "Wen Long"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Through in-depth analysis of ultra high frequency (UHF) stock price change\ndata, more reasonable discrete dynamic distribution models are constructed in\nthis paper. Firstly, we classify the price changes into several categories.\nThen, temporal convolutional network (TCN) is utilized to predict the\nconditional probability for each category. Furthermore, attention mechanism is\nadded into the TCN architecture to model the time-varying distribution for\nstock price change data. Empirical research on constituent stocks of Chinese\nShenzhen Stock Exchange 100 Index (SZSE 100) found that the TCN framework model\nand the TCN (attention) framework have a better overall performance than GARCH\nfamily models and the long short-term memory (LSTM) framework model for the\ndescription of the dynamic process of the UHF stock price change sequence. In\naddition, the scale of the dataset reached nearly 10 million, to the best of\nour knowledge, there has been no previous attempt to apply TCN to such a\nlarge-scale UHF transaction price dataset in Chinese stock market.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00261v1"
    },
    {
        "title": "A Data-driven Explainable Case-based Reasoning Approach for Financial\n  Risk Detection",
        "authors": [
            "Wei Li",
            "Florentina Paraschiv",
            "Georgios Sermpinis"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The rapid development of artificial intelligence methods contributes to their\nwide applications for forecasting various financial risks in recent years. This\nstudy introduces a novel explainable case-based reasoning (CBR) approach\nwithout a requirement of rich expertise in financial risk. Compared with other\nblack-box algorithms, the explainable CBR system allows a natural economic\ninterpretation of results. Indeed, the empirical results emphasize the\ninterpretability of the CBR system in predicting financial risk, which is\nessential for both financial companies and their customers. In addition, our\nresults show that the proposed automatic design CBR system has a good\nprediction performance compared to other artificial intelligence methods,\novercoming the main drawback of a standard CBR system of highly depending on\nprior domain knowledge about the corresponding field.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.08808v1"
    },
    {
        "title": "Adaptive Gradient Descent Methods for Computing Implied Volatility",
        "authors": [
            "Yixiao Lu",
            "Yihong Wang",
            "Tinggan Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this paper, a new numerical method based on adaptive gradient descent\noptimizers is provided for computing the implied volatility from the\nBlack-Scholes (B-S) option pricing model. It is shown that the new method is\nmore accurate than the close form approximation. Compared with the\nNewton-Raphson method, the new method obtains a reliable rate of convergence\nand tends to be less sensitive to the beginning point.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.07035v5"
    },
    {
        "title": "Community Detection in Cryptocurrencies with Potential Applications to\n  Portfolio Diversification",
        "authors": [
            "J. Gavin",
            "M. Crane"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this paper, the cross-correlations of cryptocurrency returns are analysed.\nThe paper examines one years worth of data for 146 cryptocurrencies from the\nperiod January 1 2019 to December 31 2019. The cross-correlations of these\nreturns are firstly analysed by comparing eigenvalues and eigenvector\ncomponents of the cross-correlation matrix C with Random Matrix Theory (RMT)\nassumptions. Results show that C deviates from these assumptions indicating\nthat C contains genuine information about the correlations between the\ndifferent cryptocurrencies. From here, Louvain community detection method is\napplied as a clustering mechanism and 15 community groupings are detected.\nFinally, PCA is completed on the standardised returns of each of these clusters\nto create a portfolio of cryptocurrencies for investment. This method selects a\nportfolio which contains a number of high value coins when compared back\nagainst their market ranking in the same year. In the interest of assessing\ncontinuity of the initial results, the method is also applied to a smaller\ndataset of the top 50 cryptocurrencies across three time periods of T = 125\ndays, which produces similar results. The results obtained in this paper show\nthat these methods could be useful for constructing a portfolio of optimally\nperforming cryptocurrencies.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.09763v1"
    },
    {
        "title": "Moving average options: Machine Learning and Gauss-Hermite quadrature\n  for a double non-Markovian problem",
        "authors": [
            "Ludovic Goudenège",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Evaluating moving average options is a tough computational challenge for the\nenergy and commodity market as the payoff of the option depends on the prices\nof a certain underlying observed on a moving window so, when a long window is\nconsidered, the pricing problem becomes high dimensional. We present an\nefficient method for pricing Bermudan style moving average options, based on\nGaussian Process Regression and Gauss-Hermite quadrature, thus named GPR-GHQ.\nSpecifically, the proposed algorithm proceeds backward in time and, at each\ntime-step, the continuation value is computed only in a few points by using\nGauss-Hermite quadrature, and then it is learned through Gaussian Process\nRegression. We test the proposed approach in the Black-Scholes model, where the\nGPR-GHQ method is made even more efficient by exploiting the positive\nhomogeneity of the continuation value, which allows one to reduce the problem\nsize. Positive homogeneity is also exploited to develop a binomial Markov\nchain, which is able to deal efficiently with medium-long windows. Secondly, we\ntest GPR-GHQ in the Clewlow-Strickland model, the reference framework for\nmodeling prices of energy commodities. Finally, we consider a challenging\nproblem which involves double non-Markovian feature, that is the rough-Bergomi\nmodel. In this case, the pricing problem is even harder since the whole history\nof the volatility process impacts the future distribution of the process. The\nmanuscript includes a numerical investigation, which displays that GPR-GHQ is\nvery accurate and it is able to handle options with a very long window, thus\novercoming the problem of high dimensionality.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.11141v1"
    },
    {
        "title": "Precise option pricing by the COS method--How to choose the truncation\n  range",
        "authors": [
            "Gero Junike",
            "Konstantin Pankrashkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The Fourier cosine expansion (COS) method is used for pricing European\noptions numerically very fast. To apply the COS method, a truncation range for\nthe density of the log-returns need to be provided. Using Markov's inequality,\nwe derive a new formula to obtain the truncation range and prove that the range\nis large enough to ensure convergence of the COS method within a predefined\nerror tolerance. We also show by several examples that the classical approach\nto determine the truncation range by cumulants may lead to serious mispricing.\nUsually, the computational time of the COS method is of similar magnitude in\nboth cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.01030v6"
    },
    {
        "title": "Fast Sampling from Time-Integrated Bridges using Deep Learning",
        "authors": [
            "Leonardo Perotti",
            "Lech A. Grzelak"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We propose a methodology to sample from time-integrated stochastic bridges,\nnamely random variables defined as $\\int_{t_1}^{t_2} f(Y(t))dt$ conditioned on\n$Y(t_1)\\!=\\!a$ and $Y(t_2)\\!=\\!b$, with $a,b\\in R$. The Stochastic Collocation\nMonte Carlo sampler and the Seven-League scheme are applied for this purpose.\nNotably, the distribution of the time-integrated bridge is approximated\nutilizing a polynomial chaos expansion built on a suitable set of stochastic\ncollocation points. Furthermore, artificial neural networks are employed to\nlearn the collocation points. The result is a robust, data-driven procedure for\nthe Monte Carlo sampling from conditional time-integrated processes, which\nguarantees high accuracy and generates thousands of samples in milliseconds.\nApplications, with a focus on finance, are presented here as well.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.13901v1"
    },
    {
        "title": "A General Approach for Lookback Option Pricing under Markov Models",
        "authors": [
            "Gongqiu Zhang",
            "Lingfei Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We propose a very efficient method for pricing various types of lookback\noptions under Markov models. We utilize the model-free representations of\nlookback option prices as integrals of first passage probabilities. We combine\nefficient numerical quadrature with continuous-time Markov chain approximation\nfor the first passage problem to price lookbacks. Our method is applicable to a\nvariety of models, including one-dimensional time-homogeneous and\ntime-inhomogeneous Markov processes, regime-switching models and stochastic\nlocal volatility models. We demonstrate the efficiency of our method through\nvarious numerical examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.00439v1"
    },
    {
        "title": "A fast Monte Carlo scheme for additive processes and option pricing",
        "authors": [
            "Michele Azzone",
            "Roberto Baviera"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this paper, we present a very fast Monte Carlo scheme for additive\nprocesses: the computational time is of the same order of magnitude of standard\nalgorithms for Brownian motions. We analyze in detail numerical error sources\nand propose a technique that reduces the two major sources of error. We also\ncompare our results with a benchmark method: the jump simulation with Gaussian\napproximation. We show an application to additive normal tempered stable\nprocesses, a class of additive processes that calibrates ``exactly\" the implied\nvolatility surface.Numerical results are relevant. This fast algorithm is also\nan accurate tool for pricing path-dependent discretely-monitoring options with\nerrors of one bp or below.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.08291v3"
    },
    {
        "title": "Matrix method stability and robustness of compact schemes for parabolic\n  PDEs",
        "authors": [
            "Anindya Goswami",
            "Kuldip Singh Patel"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The fully discrete problem for convection-diffusion equation is considered.\nIt comprises compact approximations for spatial discretization, and\nCrank-Nicolson scheme for temporal discretization. The expressions for the\nentries of inverse of tridiagonal Toeplitz matrix, and Gerschgorin circle\ntheorem have been applied to locate the eigenvalues of the amplification\nmatrix. An upper bound on the condition number of a relevant matrix is derived.\nIt is shown to be of order $\\mathcal{O}\\left(\\frac{\\delta v}{\\delta\nz^2}\\right)$, where $\\delta v$ and $\\delta z$ are time and space step sizes\nrespectively. Some numerical illustrations have been added to complement the\ntheoretical findings.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.05854v3"
    },
    {
        "title": "A semi-static replication approach to efficient hedging and pricing of\n  callable IR derivatives",
        "authors": [
            "Jori Hoencamp",
            "Shashi Jain",
            "Drona Kandhai"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We present a semi-static hedging algorithm for callable interest rate\nderivatives under an affine, multi-factor term-structure model. With a\ntraditional dynamic hedge, the replication portfolio needs to be updated\ncontinuously through time as the market moves. In contrast, we propose a\nsemi-static hedge that needs rebalancing on just a finite number of instances.\nWe show, taking as an example Bermudan swaptions, that callable interest rate\nderivatives can be replicated with an options portfolio written on a basket of\ndiscount bonds. The static portfolio composition is obtained by regressing the\ntarget option's value using an interpretable, artificial neural network.\nLeveraging on the approximation power of neural networks, we prove that the\nhedging error can be arbitrarily small for a sufficiently large replication\nportfolio. A direct, a lower bound, and an upper bound estimator for the\nrisk-neutral Bermudan swaption price is inferred from the hedging algorithm.\nAdditionally, closed-form error margins to the price statistics are determined.\nWe practically demonstrate the hedging and pricing performance through several\nnumerical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.01027v1"
    },
    {
        "title": "Solving Multi-Period Financial Planning Models: Combining Monte Carlo\n  Tree Search and Neural Networks",
        "authors": [
            "Afşar Onat Aydınhan",
            "Xiaoyue Li",
            "John M. Mulvey"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper introduces the MCTS algorithm to the financial world and focuses\non solving significant multi-period financial planning models by combining a\nMonte Carlo Tree Search algorithm with a deep neural network. The MCTS provides\nan advanced start for the neural network so that the combined method\noutperforms either approach alone, yielding competitive results. Several\ninnovations improve the computations, including a variant of the upper\nconfidence bound applied to trees (UTC) and a special lookup search. We compare\nthe two-step algorithm with employing dynamic programs/neural networks. Both\napproaches solve regime switching models with 50-time steps and transaction\ncosts with twelve asset categories. Heretofore, these problems have been\noutside the range of solvable optimization models via traditional algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07734v3"
    },
    {
        "title": "Toward an efficient hybrid method for pricing barrier options on assets\n  with stochastic volatility",
        "authors": [
            "Alexander Lipton",
            "Artur Sepp"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We combine the one-dimensional Monte Carlo simulation and the semi-analytical\none-dimensional heat potential method to design an efficient technique for\npricing barrier options on assets with correlated stochastic volatility. Our\napproach to barrier options valuation utilizes two loops. First we run the\nouter loop by generating volatility paths via the Monte Carlo method. Second,\nwe condition the price dynamics on a given volatility path and apply the method\nof heat potentials to solve the conditional problem in closed-form in the inner\nloop. We illustrate the accuracy and efficacy of our semi-analytical approach\nby comparing it with the two-dimensional Monte Carlo simulation and a hybrid\nmethod, which combines the finite-difference technique for the inner loop and\nthe Monte Carlo simulation for the outer loop. We apply our method for\ncomputation of state probabilities (Green function), survival probabilities,\nand values of call options with barriers. Our approach provides better accuracy\nand is orders of magnitude faster than the existing methods. s a by-product of\nour analysis, we generalize Willard's (1997) conditioning formula for valuation\nof path-independent options to path-dependent options and derive a novel\nexpression for the joint probability density for the value of drifted Brownian\nmotion and its running minimum.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07849v1"
    },
    {
        "title": "Can LSTM outperform volatility-econometric models?",
        "authors": [
            "German Rodikov",
            "Nino Antulov-Fantulin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Volatility prediction for financial assets is one of the essential questions\nfor understanding financial risks and quadratic price variation. However,\nalthough many novel deep learning models were recently proposed, they still\nhave a \"hard time\" surpassing strong econometric volatility models. Why is this\nthe case? The volatility prediction task is of non-trivial complexity due to\nnoise, market microstructure, heteroscedasticity, exogenous and asymmetric\neffect of news, and the presence of different time scales, among others. In\nthis paper, we analyze the class of long short-term memory (LSTM) recurrent\nneural networks for the task of volatility prediction and compare it with\nstrong volatility-econometric models.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.11581v1"
    },
    {
        "title": "On the weak convergence rate in the discretization of rough volatility\n  models",
        "authors": [
            "Christian Bayer",
            "Masaaki Fukasawa",
            "Shonosuke Nakahara"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We study the weak convergence rate in the discretization of rough volatility\nmodels. After showing a lower bound $2H$ under a general model, where $H$ is\nthe Hurst index of the volatility process, we give a sharper bound $H + 1/2$\nunder a linear model.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.02943v1"
    },
    {
        "title": "Regression Monte Carlo for Impulse Control",
        "authors": [
            "Mike Ludkovski"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  I develop a numerical algorithm for stochastic impulse control in the spirit\nof Regression Monte Carlo for optimal stopping. The approach consists in\ngenerating statistical surrogates (aka functional approximators) for the\ncontinuation function. The surrogates are recursively trained by empirical\nregression over simulated state trajectories. In parallel, the same surrogates\nare used to learn the intervention function characterizing the optimal impulse\namounts. I discuss appropriate surrogate types for this task, as well as the\nchoice of training sets. Case studies from forest rotation and irreversible\ninvestment illustrate the numerical scheme and highlight its flexibility and\nextensibility. Implementation in \\texttt{R} is provided as a publicly available\npackage posted on GitHub.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06539v1"
    },
    {
        "title": "The return of (I)DeFiX",
        "authors": [
            "Florentina Şoiman",
            "Guillaume Dumas",
            "Sonia Jimenez-Garces"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Decentralized Finance (DeFi) is a nascent set of financial services, using\ntokens, smart contracts, and blockchain technology as financial instruments. We\ninvestigate four possible drivers of DeFi returns: exposure to cryptocurrency\nmarket, the network effect, the investor's attention, and the valuation ratio.\nAs DeFi tokens are distinct from classical cryptocurrencies, we design a new\ndedicated market index, denoted DeFiX. First, we show that DeFi tokens returns\nare driven by the investor's attention on technical terms such as\n\"decentralized finance\" or \"DeFi\", and are exposed to their own network\nvariables and cryptocurrency market. We construct a valuation ratio for the\nDeFi market by dividing the Total Value Locked (TVL) by the Market\nCapitalization (MC). Our findings do not support the TVL/MC predictive power\nassumption. Overall, our empirical study shows that the impact of the\ncryptocurrency market on DeFi returns is stronger than any other considered\ndriver and provides superior explanatory power.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00251v1"
    },
    {
        "title": "The short-term effect of COVID-19 pandemic on China's crude oil futures\n  market: A study based on multifractal analysis",
        "authors": [
            "Shao Ying-Hui",
            "Liu Ying-Lin",
            "Yang Yan-Hong"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The ongoing COVID-19 shocked financial markets globally, including China's\ncrude oil future market, which is the third most traded crude oil futures after\nWTI and Brent. As China's first crude oil futures accessible to foreign\ninvestors, the Shanghai crude oil futures (SC) have attracted significant\ninterest since launch at the Shanghai International Energy Exchange. The impact\nof COVID-19 on the new crude oil futures is an important issue for investors\nand policy makers. Therefore this paper studies the short-term influence of\nCOVID-19 pandemic on SC via multifractal analysis. We compare market efficiency\nof SC before and during the pandemic with the multifractal detrended\nfluctuation analysis and other commonly-used random walk tests. Then we\ngenerate shuffled and surrogate data to investigate the components of\nmultifractal nature in SC. And we examine cross-correlations between SC returns\nand other financial assets returns as well as SC trading volume changes by the\nmultifractal detrended cross-correlation analysis. The results show that market\nefficiency of SC and its cross-correlations with other assets increase\nsignificantly after the outbreak of COVID-19. Besides that, the sources of its\nmultifractal nature have changed since the pandemic. The findings provide\nevidence for the short-term impacts of COVID-19 on SC. The results may have\nimportant implications for assets allocation, investment strategies and risk\nmonitoring.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.05199v1"
    },
    {
        "title": "Automatic Adjoint Differentiation for special functions involving\n  expectations",
        "authors": [
            "José Brito",
            "Andrei Goloubentsev",
            "Evgeny Goncharov"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We explain how to compute gradients of functions of the form $G = \\frac{1}{2}\n\\sum_{i=1}^{m} (E y_i - C_i)^2$, which often appear in the calibration of\nstochastic models, using Automatic Adjoint Differentiation and parallelization.\nWe expand on the work of arXiv:1901.04200 and give faster and easier to\nimplement approaches. We also provide an implementation of our methods and\napply the technique to calibrate European options.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.05204v2"
    },
    {
        "title": "Ensemble learning for portfolio valuation and risk management",
        "authors": [
            "Lotfi Boudabsa",
            "Damir Filipović"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We introduce an ensemble learning method for dynamic portfolio valuation and\nrisk management building on regression trees. We learn the dynamic value\nprocess of a derivative portfolio from a finite sample of its cumulative cash\nflow. The estimator is given in closed form. The method is fast and accurate,\nand scales well with sample size and path space dimension. The method can also\nbe applied to Bermudan style options. Numerical experiments show good results\nin moderate dimension problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.05926v1"
    },
    {
        "title": "CVA in fractional and rough volatility models",
        "authors": [
            "Elisa Alòs",
            "Fabio Antonelli",
            "Alessandro Ramponi",
            "Sergio Scarlatti"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this work we present a general representation formula for the price of a\nvulnerable European option, and the related CVA in stochastic (either rough or\nnot) volatility models for the underlying's price, when admitting correlation\nwith the default event. We specialize it for some volatility models and we\nprovide price approximations, based on the representation formula. We study\nnumerically their accuracy, comparing the results with Monte Carlo simulations,\nand we run a theoretical study of the error. We also introduce a seminal study\nof roughness influence on the claim's price.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.11554v1"
    },
    {
        "title": "Deep Stochastic Optimization in Finance",
        "authors": [
            "A. Max Reppen",
            "H. Mete Soner",
            "Valentin Tissot-Daguette"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper outlines, and through stylized examples evaluates a novel and\nhighly effective computational technique in quantitative finance. Empirical\nRisk Minimization (ERM) and neural networks are key to this approach. Powerful\nopen source optimization libraries allow for efficient implementations of this\nalgorithm making it viable in high-dimensional structures. The free-boundary\nproblems related to American and Bermudan options showcase both the power and\nthe potential difficulties that specific applications may face. The impact of\nthe size of the training data is studied in a simplified Merton type problem.\nThe classical option hedging problem exemplifies the need of market generators\nor large number of simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04604v1"
    },
    {
        "title": "Volatility-inspired $σ$-LSTM cell",
        "authors": [
            "German Rodikov",
            "Nino Antulov-Fantulin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Volatility models of price fluctuations are well studied in the econometrics\nliterature, with more than 50 years of theoretical and empirical findings. The\nrecent advancements in neural networks (NN) in the deep learning field have\nnaturally offered novel econometric modeling tools. However, there is still a\nlack of explainability and stylized knowledge about volatility modeling with\nneural networks; the use of stylized facts could help improve the performance\nof the NN for the volatility prediction task. In this paper, we investigate how\nthe knowledge about the \"physics\" of the volatility process can be used as an\ninductive bias to design or constrain a cell state of long short-term memory\n(LSTM) for volatility forecasting. We introduce a new type of $\\sigma$-LSTM\ncell with a stochastic processing layer, design its learning mechanism and show\ngood out-of-sample forecasting performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.07022v1"
    },
    {
        "title": "Differential learning methods for solving fully nonlinear PDEs",
        "authors": [
            "William Lefebvre",
            "Grégoire Loeper",
            "Huyên Pham"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We propose machine learning methods for solving fully nonlinear partial\ndifferential equations (PDEs) with convex Hamiltonian. Our algorithms are\nconducted in two steps. First the PDE is rewritten in its dual stochastic\ncontrol representation form, and the corresponding optimal feedback control is\nestimated using a neural network. Next, three different methods are presented\nto approximate the associated value function, i.e., the solution of the initial\nPDE, on the entire space-time domain of interest. The proposed deep learning\nalgorithms rely on various loss functions obtained either from regression or\npathwise versions of the martingale representation and its differential\nrelation, and compute simultaneously the solution and its derivatives. Compared\nto existing methods, the addition of a differential loss function associated to\nthe gradient, and augmented training sets with Malliavin derivatives of the\nforward process, yields a better estimation of the PDE's solution derivatives,\nin particular of the second derivative, which is usually difficult to\napproximate. Furthermore, we leverage our methods to design algorithms for\nsolving families of PDEs when varying terminal condition (e.g. option payoff in\nthe context of mathematical finance) by means of the class of DeepOnet neural\nnetworks aiming to approximate functional operators. Numerical tests illustrate\nthe accuracy of our methods on the resolution of a fully nonlinear PDE\nassociated to the pricing of options with linear market impact, and on the\nMerton portfolio selection problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.09815v1"
    },
    {
        "title": "Parameters identification for an inverse problem arising from a binary\n  option using a Bayesian inference approach",
        "authors": [
            "Yasushi Ota",
            "Yu Jiang",
            "Daiki Maki"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  No--arbitrage property provides a simple method for pricing financial\nderivatives. However, arbitrage opportunities exist among different markets in\nvarious fields, even for a very short time. By knowing that an arbitrage\nproperty exists, we can adopt a financial trading strategy. This paper\ninvestigates the inverse option problems (IOP) in the extended Black--Scholes\nmodel. We identify the model coefficients from the measured data and attempt to\nfind arbitrage opportunities in different financial markets using a Bayesian\ninference approach, which is presented as an IOP solution. The posterior\nprobability density function of the parameters is computed from the measured\ndata.The statistics of the unknown parameters are estimated by a Markov Chain\nMonte Carlo (MCMC) algorithm, which exploits the posterior state space. The\nefficient sampling strategy of the MCMC algorithm enables us to solve inverse\nproblems by the Bayesian inference technique. Our numerical results indicate\nthat the Bayesian inference approach can simultaneously estimate the unknown\ntrend and volatility coefficients from the measured data.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.11012v1"
    },
    {
        "title": "An Agent-Based Model With Realistic Financial Time Series: A Method for\n  Agent-Based Models Validation",
        "authors": [
            "Luis Goncalves de Faria"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper proposes a methodology to empirically validate an agent-based\nmodel (ABM) that generates artificial financial time series data comparable\nwith real-world financial data. The approach is based on comparing the results\nof the ABM against the stylised facts -- the statistical properties of the\nempirical time-series of financial data. The stylised facts appear to be\nuniversal and are observed across different markets, financial instruments and\ntime periods, hence they can serve to validate models of financial markets. If\na given model does not consistently replicate these stylised facts, then we can\nreject it as being empirically inadequate. We discuss each stylised fact, the\nempirical evidence for it, and introduce appropriate metrics for testing the\npresence of these in model generated data. Moreover we investigate the ability\nof our model to correctly reproduce these stylised facts. We validate our model\nagainst a comprehensive list of empirical phenomena that qualify as a stylised\nfact, of both low and high frequency financial data that can be addressed by\nmeans of a relatively simple ABM of financial markets. This procedure is able\nto show whether the model, as an abstraction of reality, has a meaningful\nempirical counterpart and the significance of this analysis for the purposes of\nABM validation and their empirical reliability.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09772v1"
    },
    {
        "title": "Accurate and consistent calculation of the mean and variance in\n  Monte-Carlo simulations",
        "authors": [
            "Jherek Healy"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In parallelized Monte-Carlo simulations, the order of summation is not always\nthe same. When the mean is calculated in running fashion, this may create an\nartificial randomness in results which ought to be reproducible. This note\ntakes a look at the problem and proposes to combine the running mean and\nvariance algorithm with an accurate and robust summing algorithm in order to\nincrease the accuracy and robustness of the Monte-Carlo estimates.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.10662v7"
    },
    {
        "title": "Stochastic arbitrage with market index options",
        "authors": [
            "Brendan K. Beare",
            "Juwon Seo",
            "Zhongxi Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Opportunities for stochastic arbitrage in an options market arise when it is\npossible to construct a portfolio of options which provides a positive option\npremium and which, when combined with a direct investment in the underlying\nasset, generates a payoff which stochastically dominates the payoff from the\ndirect investment in the underlying asset. We provide linear and mixed-integer\nlinear programs for computing the stochastic arbitrage opportunity providing\nthe maximum option premium to an investor. We apply our programs to 18 years of\ndata on monthly put and call options on the Standard & Poors 500 index,\nconfining attention to options with moderate moneyness, and using two\nspecifications of the underlying asset return distribution, one symmetric and\none skewed. The pricing of market index options with moderate moneyness appears\nto be broadly consistent with our skewed specification of market returns.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00949v3"
    },
    {
        "title": "Reinforcement Learning Portfolio Manager Framework with Monte Carlo\n  Simulation",
        "authors": [
            "Jungyu Ahn",
            "Sungwoo Park",
            "Jiwoon Kim",
            "Ju-hong Lee"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Asset allocation using reinforcement learning has advantages such as\nflexibility in goal setting and utilization of various information. However,\nexisting asset allocation methods do not consider the following viewpoints in\nsolving the asset allocation problem. First, State design without considering\nportfolio management and financial market characteristics. Second, Model\nOverfitting. Third, Model training design without considering the statistical\nstructure of financial time series data. To solve the problem of the existing\nasset allocation method using reinforcement learning, we propose a new\nreinforcement learning asset allocation method. First, the state of the\nportfolio managed by the model is considered as the state of the reinforcement\nlearning agent. Second, Monte Carlo simulation data are used to increase\ntraining data complexity to prevent model overfitting. These data can have\ndifferent patterns, which can increase the complexity of the data. Third, Monte\nCarlo simulation data are created considering various statistical structures of\nfinancial markets. We define the statistical structure of the financial market\nas the correlation matrix of the assets constituting the financial market. We\nshow experimentally that our method outperforms the benchmark at several test\nintervals.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.02458v1"
    },
    {
        "title": "Estimation of Historical volatility and Allocation strategies using\n  Variance Swaps",
        "authors": [
            "Lucio Fiorin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this memorie de fin d'etudes, we review some techniques to estimate\nhistorical volatility and to price Variance Swaps\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03164v1"
    },
    {
        "title": "Deep Weighted Monte Carlo: A hybrid option pricing framework using\n  neural networks",
        "authors": [
            "Sándor Kunsági-Máté",
            "Gábor Fáth",
            "István Csabai",
            "Gábor Molnár-Sáska"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Recent studies have demonstrated the efficiency of Variational Autoencoders\n(VAE) to compress high-dimensional implied volatility surfaces into a low\ndimensional representation. Although this method can be effectively used for\npricing vanilla options, it does not provide any explicit information about the\ndynamics of the underlying asset. In our work we present an effective way to\novercome this problem. We use a Weighted Monte Carlo approach to first generate\npaths from a simple a priori Brownian dynamics, and then calculate path weights\nto price options correctly. We develop and successfully train a neural network\nthat is able to assign these weights directly from the latent space. Combining\nthe encoder network of the VAE and this new \"weight assigner\" module, we are\nable to build a dynamic pricing framework which cleanses the volatility surface\nfrom irrelevant noise fluctuations, and then can price not just vanillas, but\nalso exotic options on this idealized vol surface. This pricing method can\nprovide relative value signals for option traders.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.14038v2"
    },
    {
        "title": "Multilevel Richardson-Romberg and Importance Sampling in Derivative\n  Pricing",
        "authors": [
            "Devang Sinha",
            "Siddhartha P. Chakrabarty"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this paper, we propose and analyze a novel combination of multilevel\nRichardson-Romberg (ML2R) and importance sampling algorithm, with the aim of\nreducing the overall computational time, while achieving desired\nroot-mean-squared error while pricing. We develop an idea to construct the\nMonte-Carlo estimator that deals with the parametric change of measure. We rely\non the Robbins-Monro algorithm with projection, in order to approximate optimal\nchange of measure parameter, for various levels of resolution in our multilevel\nalgorithm. Furthermore, we propose incorporating discretization schemes with\nhigher-order strong convergence, in order to simulate the underlying stochastic\ndifferential equations (SDEs) thereby achieving better accuracy. In order to do\nso, we study the Central Limit Theorem for the general multilevel algorithm.\nFurther, we study the asymptotic behavior of our estimator, thereby proving the\nStrong Law of Large Numbers. Finally, we present numerical results to\nsubstantiate the efficacy of our developed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.00821v1"
    },
    {
        "title": "Computing XVA for American basket derivatives by Machine Learning\n  techniques",
        "authors": [
            "Ludovic Goudenege",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Total value adjustment (XVA) is the change in value to be added to the price\nof a derivative to account for the bilateral default risk and the funding\ncosts. In this paper, we compute such a premium for American basket derivatives\nwhose payoff depends on multiple underlyings. In particular, in our model,\nthose underlying are supposed to follow the multidimensional Black-Scholes\nstochastic model. In order to determine the XVA, we follow the approach\nintroduced by Burgard and Kjaer \\cite{burgard2010pde} and afterward applied by\nArregui et al. \\cite{arregui2017pde,arregui2019monte} for the one-dimensional\nAmerican derivatives. The evaluation of the XVA for basket derivatives is\nparticularly challenging as the presence of several underlings leads to a\nhigh-dimensional control problem. We tackle such an obstacle by resorting to\nGaussian Process Regression, a machine learning technique that allows one to\naddress the curse of dimensionality effectively. Moreover, the use of numerical\ntechniques, such as control variates, turns out to be a powerful tool to\nimprove the accuracy of the proposed methods. The paper includes the results of\nseveral numerical experiments that confirm the goodness of the proposed\nmethodologies.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.06485v1"
    },
    {
        "title": "Physics-Informed Convolutional Transformer for Predicting Volatility\n  Surface",
        "authors": [
            "Soohan Kim",
            "Seok-Bae Yun",
            "Hyeong-Ohk Bae",
            "Muhyun Lee",
            "Youngjoon Hong"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Predicting volatility is important for asset predicting, option pricing and\nhedging strategies because it cannot be directly observed in the financial\nmarket. The Black-Scholes option pricing model is one of the most widely used\nmodels by market participants. Notwithstanding, the Black-Scholes model is\nbased on heavily criticized theoretical premises, one of which is the constant\nvolatility assumption. The dynamics of the volatility surface is difficult to\nestimate. In this paper, we establish a novel architecture based on\nphysics-informed neural networks and convolutional transformers. The\nperformance of the new architecture is directly compared to other well-known\ndeep-learning architectures, such as standard physics-informed neural networks,\nconvolutional long-short term memory (ConvLSTM), and self-attention ConvLSTM.\nNumerical evidence indicates that the proposed physics-informed convolutional\ntransformer network achieves a superior performance than other methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.10771v3"
    },
    {
        "title": "Quasi-Monte Carlo methods for calculating derivatives sensitivities on\n  the GPU",
        "authors": [
            "Paul Bilokon",
            "Sergei Kucherenko",
            "Casey Williams"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The calculation of option Greeks is vital for risk management. Traditional\npathwise and finite-difference methods work poorly for higher-order Greeks and\noptions with discontinuous payoff functions. The Quasi-Monte Carlo-based\nconditional pathwise method (QMC-CPW) for options Greeks allows the payoff\nfunction of options to be effectively smoothed, allowing for increased\nefficiency when calculating sensitivities. Also demonstrated in literature is\nthe increased computational speed gained by applying GPUs to highly\nparallelisable finance problems such as calculating Greeks. We pair QMC-CPW\nwith simulation on the GPU using the CUDA platform. We estimate the delta, vega\nand gamma Greeks of three exotic options: arithmetic Asian, binary Asian, and\nlookback. Not only are the benefits of QMC-CPW shown through variance reduction\nfactors of up to $1.0 \\times 10^{18}$, but the increased computational speed\nthrough usage of the GPU is shown as we achieve speedups over sequential CPU\nimplementations of more than $200$x for our most accurate method.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.11337v1"
    },
    {
        "title": "Multilevel Monte Carlo and its Applications in Financial Engineering",
        "authors": [
            "Devang Sinha",
            "Siddhartha P. Chakrabarty"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this article, we present a review of the recent developments on the topic\nof Multilevel Monte Carlo (MLMC) algorithm, in the paradigm of applications in\nfinancial engineering. We specifically focus on the recent studies conducted in\ntwo subareas, namely, option pricing and financial risk management. For the\nformer, the discussion involves incorporation of the importance sampling\nalgorithm, in conjunction with the MLMC estimator, thereby constructing a\nhybrid algorithm in order to achieve reduction for the overall variance of the\nestimator. In case of the latter, we discuss the studies carried out in order\nto construct an efficient algorithm in order to estimate the risk measures of\nValue-at-Risk (VaR) and Conditional Var (CVaR), in an efficient manner. In this\nregard, we briefly discuss the motivation and the construction of an adaptive\nsampling algorithm with an aim to efficiently estimate the nested expectation,\nwhich, in general is computationally expensive.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.14549v1"
    },
    {
        "title": "Modifications to a classic BFGS library for use with SIMD-equipped\n  hardware and an AAD library",
        "authors": [
            "Evgeny Goncharov",
            "Alexandre Rodrigues"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We introduce certain modifications of the BFGS method for functions that are\nnot parallelizable by nature (having consecutive operations only) taking\nadvantage of SIMD. We also provide a modified LBFGS\\texttt{++} library that\ntakes advantage of these modifications, and the use of AAD, and give an\ninterface for AAD users that takes advantage of the modified library\nautomatically. We give two examples to illustrate the performance. The modified\nlibrary is up to 3.8 times faster for European Swaption curve calibration in\nORE (not parallelizable) and 1.4 times faster for calibrating the LMM model by\na set of European options.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.14928v1"
    },
    {
        "title": "TechRank",
        "authors": [
            "Anita Mezzetti",
            "Loïc Maréchal",
            "Dimitri Percia David",
            "William Lacube",
            "Sébastien Gillard",
            "Michael Tsesmelis",
            "Thomas Maillart",
            "Alain Mermoud"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We introduce TechRank, a recursive algorithm based on a bi-partite graph with\nweighted nodes. We develop TechRank to link companies and technologies based on\nthe method of reflection. We allow the algorithm to incorporate exogenous\nvariables that reflect an investor's preferences. We calibrate the algorithm in\nthe cybersecurity sector. First, our results help estimate each entity's\ninfluence and explain companies' and technologies' ranking. Second, they\nprovide investors with a quantitative optimal ranking of technologies and thus,\nhelp them design their optimal portfolio. We propose this method as an\nalternative to traditional portfolio management and, in the case of private\nequity investments, as a new way to price assets for which cash flows are not\nobservable.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.07824v1"
    },
    {
        "title": "Hedonic Models of Real Estate Prices: GAM and Environmental Factors",
        "authors": [
            "Jason R. Bailey",
            "Davide Lauria",
            "W. Brent Lindquist",
            "Stefan Mittnik",
            "Svetlozar T. Rachev"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We consider the use of P-spline generalized additive hedonic models for real\nestate prices in large U.S. cities, contrasting their predictive efficiency\nagainst linear and polynomial based generalized linear models. Using intrinsic\nand extrinsic factors available from Redfin, we show that GAM models are\ncapable of describing 84% to 92% of the variance in the expected ln(sales\nprice), based upon 2021 data. As climate change is becoming increasingly\nimportant, we utilized the GAM model to examine the significance of\nenvironmental factors in two urban centers on the northwest coast. The results\nindicate city dependent differences in the significance of environmental\nfactors. We find that inclusion of the environmental factors increases the\nadjusted R-squared of the GAM model by less than one percent.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.14266v1"
    },
    {
        "title": "Newton Raphson Emulation Network for Highly Efficient Computation of\n  Numerous Implied Volatilities",
        "authors": [
            "Geon Lee",
            "Tae-Kyoung Kim",
            "Hyun-Gyoon Kim",
            "Jeonggyu Huh"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In finance, implied volatility is an important indicator that reflects the\nmarket situation immediately. Many practitioners estimate volatility using\niteration methods, such as the Newton--Raphson (NR) method. However, if\nnumerous implied volatilities must be computed frequently, the iteration\nmethods easily reach the processing speed limit. Therefore, we emulate the NR\nmethod as a network using PyTorch, a well-known deep learning package, and\noptimize the network further using TensorRT, a package for optimizing deep\nlearning models. Comparing the optimized emulation method with the NR function\nin SciPy, a popular implementation of the NR method, we demonstrate that the\nemulation network is up to 1,000 times faster than the benchmark function.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.15969v1"
    },
    {
        "title": "The importance of being scrambled: supercharged Quasi Monte Carlo",
        "authors": [
            "J. Hok",
            "S. Kucherenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In many financial applications Quasi Monte Carlo (QMC) based on Sobol\nlow-discrepancy sequences (LDS) outperforms Monte Carlo showing faster and more\nstable convergence. However, unlike MC QMC lacks a practical error estimate.\nRandomized QMC (RQMC) method combines the best of two methods. Application of\nscrambled LDS allow to compute confidence intervals around the estimated value,\nproviding a practical error bound. Randomization of Sobol' LDS by two methods:\nOwen's scrambling and digital shift are compared considering computation of\nAsian options and Greeks using hyperbolic local volatility model. RQMC\ndemonstrated the superior performance over standard QMC showing increased\nconvergence rates and providing practical error bounds.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.16548v2"
    },
    {
        "title": "Understanding the Maker Protocol",
        "authors": [
            "Jason Chen",
            "Kathy Fogel",
            "Kose John"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper discusses a decentralized finance (DeFi) application called\nMakerDAO. The Maker Protocol, built on the Ethereum blockchain, enables users\nto create and hold currency. Current elements of the Maker Protocol are the Dai\nstable coin, Maker Vaults, and Voting. MakerDAO governs the Maker Protocol by\ndeciding on key parameters (e.g., stability fees, collateral types and rates,\netc.) through the voting power of Maker (MKR) holders. The Maker Protocol is\none of the largest decentralized applications (DApps) on the Ethereum\nblockchain and is the first decentralized finance (DeFi) application to earn\nsignificant adoption. The objective of this paper is to analyze and discuss the\nsignificance, uses, and functions of this DeFi application.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.16899v1"
    },
    {
        "title": "On Pricing of Discrete Asian and Lookback Options under the Heston Model",
        "authors": [
            "Leonardo Perotti",
            "Lech A. Grzelak"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We propose a new, data-driven approach for efficient pricing of - fixed- and\nfloat-strike - discrete arithmetic Asian and Lookback options when the\nunderlying process is driven by the Heston model dynamics. The method proposed\nin this article constitutes an extension of our previous work, where the\nproblem of sampling from time-integrated stochastic bridges was addressed. The\nmodel relies on the Seven-League scheme, where artificial neural networks are\nemployed to \"learn\" the distribution of the random variable of interest\nutilizing stochastic collocation points. The method results in a robust\nprocedure for Monte Carlo pricing. Furthermore, semi-analytic formulae for\noption pricing are provided in a simplified, yet general, framework. The model\nguarantees high accuracy and a reduction of the computational time up to\nthousands of times compared to classical Monte Carlo pricing schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03638v2"
    },
    {
        "title": "Optimal performance of a tontine overlay subject to withdrawal\n  constraints",
        "authors": [
            "Peter A. Forsyth",
            "Kenneth R. Vetzal",
            "G. Westmacott"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We consider the holder of an individual tontine retirement account, with\nmaximum and minimum withdrawal amounts (per year) specified. The tontine\naccount holder initiates the account at age 65, and earns mortality credits\nwhile alive, but forfeits all wealth in the account upon death. The holder\ndesires to maximize total withdrawals, and minimize the expected shortfall,\nassuming the holder survives to age 95. The investor controls the amount\nwithdrawn each year and the fraction of the investments in stocks and bonds.\nThe optimal controls are determined based on a parametric model fitted to\nalmost a century of market data. The optimal control algorithm is based on\ndynamic programming and solution of a partial integro differential equation\n(PIDE) using Fourier methods. The optimal strategy (based on the parametric\nmodel) is tested out of sample using stationary block bootstrap resampling of\nthe historical data. In terms of an expected total withdrawal, expected\nshortfall (EW-ES) efficient frontier, the tontine overlay greatly outperforms\nan optimal strategy (without the tontine overlay), which in turn outperforms a\nconstant weight strategy with withdrawals based on the ubiquitous four per cent\nrule.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.10509v1"
    },
    {
        "title": "Investor base and idiosyncratic volatility of cryptocurrencies",
        "authors": [
            "Amin Izadyar",
            "Shiva Zamani"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper investigates how changes in investor base is related to\nidiosyncratic volatility in cryptocurrency markets. For each cryptocurrency, we\nset change in its subreddit followers as a proxy for the change in its investor\nbase, and find out that the latter can significantly increase cryptocurrencies\nidiosyncratic volatility. This finding is not subsumed by effects of size,\nmomentum, liquidity and volume and is robust to various measures of\nidiosyncratic volatility.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.13274v1"
    },
    {
        "title": "Pathwise CVA Regressions With Oversimulated Defaults",
        "authors": [
            "Lokman Abbas-Turki",
            "Stéphane Crépey",
            "Bouazza Saadeddine"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We consider the computation by simulation and neural net regression of\nconditional expectations, or more general elicitable statistics, of functionals\nof processes $(X, Y )$. Here an exogenous component $Y$ (Markov by itself) is\ntime-consuming to simulate, while the endogenous component $X$ (jointly Markov\nwith $Y$) is quick to simulate given $Y$, but is responsible for most of the\nvariance of the simulated payoff. To address the related variance issue, we\nintroduce a conditionally independent, hierarchical simulation scheme, where\nseveral paths of $X$ are simulated for each simulated path of $Y$. We analyze\nthe statistical convergence of the regression learning scheme based on such\nblock-dependent data. We derive heuristics on the number of paths of $Y$ and,\nfor each of them, of $X$, that should be simulated. The resulting algorithm is\nimplemented on a graphics processing unit (GPU) combining Python/CUDA and\nlearning with PyTorch. A CVA case study with a nested Monte Carlo benchmark\nshows that the hierarchical simulation technique is key to the success of the\nlearning approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.17005v1"
    },
    {
        "title": "Brazilian listed options with discrete dividends and the fast Laplace\n  transform",
        "authors": [
            "Maikon Araujo"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The Brazilian stock exchange (B3) has long used a strike-only adjustment to\naccount for dividends in its listed equity options. This adjustment still makes\nit necessary to account for discrete dividends when pricing either calls or\nputs. This work presents a numerical procedure, based on the fast Laplace\ntransform and its inverse, a procedure that can efficiently compute the\nBrazilian listed options' premium and the Greeks delta, gamma, and theta with\nhigh accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01315v1"
    },
    {
        "title": "Pricing Bermudan Swaption under Two Factor Hull-White Model with Fast\n  Gauss Transform",
        "authors": [
            "Tomohisa Yamakami",
            "Yuki Takeuchi"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper describes a fast and stable algorithm for evaluating Bermudan\nswaption under the two factor Hull-White model. We discretize the calculation\nof the expected value in the evaluation of Bermudan swaption by numerical\nintegration, and Gaussian kernel sums appears in it. The fast Gauss transform\ncan be applied to these Gaussian kernel sums, and it reduces computational\ncomplexity from $O(N^2)$ to $O(N)$ as grid points number $N$ of numerical\nintegration. We also propose to stabilize the computation under the condition\nthat the correlation is close to $-1$ by introducing the grid rotation.\nNumerical experiments using actual market data show that our method reduces the\ncomputation time significantly compared to the method without the fast Gauss\ntransform. They also show that the method of the grid rotation contributes to\ncomputational stability in the situations where the correlation is close to\n$-1$ and time step is short.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.08250v1"
    },
    {
        "title": "Convergence of the Euler--Maruyama particle scheme for a regularised\n  McKean--Vlasov equation arising from the calibration of local-stochastic\n  volatility models",
        "authors": [
            "Christoph Reisinger",
            "Maria Olympia Tsianni"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we study the Euler--Maruyama scheme for a particle method to\napproximate the McKean--Vlasov dynamics of calibrated local-stochastic\nvolatility (LSV) models. Given the open question of well-posedness of the\noriginal problem, we work with regularised coefficients and prove that under\ncertain assumptions on the inputs, the regularised model is well-posed. Using\nthis result, we prove the strong convergence of the Euler--Maruyama scheme to\nthe particle system with rate 1/2 in the step-size and obtain an explicit\ndependence of the error on the regularisation parameters. Finally, we implement\nthe particle method for the calibration of a Heston-type LSV model to\nillustrate the convergence in practice and to investigate how the choice of\nregularisation parameters affects the accuracy of the calibration.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00434v2"
    },
    {
        "title": "A Comparison of Reinforcement Learning and Deep Trajectory Based\n  Stochastic Control Agents for Stepwise Mean-Variance Hedging",
        "authors": [
            "Ali Fathi",
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We consider two data-driven approaches to hedging, Reinforcement Learning and\nDeep Trajectory-based Stochastic Optimal Control, under a stepwise\nmean-variance objective. We compare their performance for a European call\noption in the presence of transaction costs under discrete trading schedules.\nWe do this for a setting where stock prices follow Black-Scholes-Merton\ndynamics and the \"book-keeping\" price for the option is given by the\nBlack-Scholes-Merton model with the same parameters. This simulated data\nsetting provides a \"sanitized\" lab environment with simple enough features\nwhere we can conduct a detailed study of strengths, features, issues, and\nlimitations of these two approaches. However, the formulation is model free and\ncould allow any other setting with available book-keeping prices. We consider\nthis study as a first step to develop, test, and validate autonomous hedging\nagents, and we provide blueprints for such efforts that address various\nconcerns and requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.07996v2"
    },
    {
        "title": "Detecting Rough Volatility: A Filtering Approach",
        "authors": [
            "Camilla Damian",
            "Rüdiger Frey"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we focus on the estimation of historical volatility of asset\nprices from high-frequency data. Stochastic volatility models pose a major\nstatistical challenge: since in reality historical volatility is not\nobservable, its current level and, possibly, the parameters governing its\ndynamics have to be estimated from the observable time series of asset prices.\nTo complicate matters further, recent research has analyzed the rough behavior\nof volatility time series to challenge the common assumption that the\nvolatility process is a Brownian semimartingale. In order to tackle the arising\ninferential task efficiently in this setting, we use the fact that a fractional\nBrownian motion can be represented as a superposition of Markovian\nsemimartingales (Ornstein-Uhlenbeck processes) and we solve the filtering (and\nparameter estimation) problem by resorting to more standard techniques, such as\nparticle methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12612v1"
    },
    {
        "title": "The Economics of the DeLend Project: Agent-based Simulations",
        "authors": [
            "Frederico Dutilh Novaes",
            "Gabriel de Abreu Madeira",
            "Aurimar Cerqueira"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper presents our methodology to simulate the behavior of the DeLend\nPlatform. Such simulations are important to verify if the system is able to\nconnect the different sets of agents linked to the platform in a functional\nmanner. They also provide inputs to guide the choices of operational\nparameters, such as the platform spread, and strategies by DeLend, since they\nestimate how the key variables of interest respond to different policies. We\ndiscuss the methodology and provide examples meant to clarify the approach and\nto how we intend to use the tool in practice -- they should not be interpreted\nas representative of real life scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.03214v3"
    },
    {
        "title": "A parsimonious neural network approach to solve portfolio optimization\n  problems without using dynamic programming",
        "authors": [
            "Pieter M. van Staden",
            "Peter A. Forsyth",
            "Yuying Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We present a parsimonious neural network approach, which does not rely on\ndynamic programming techniques, to solve dynamic portfolio optimization\nproblems subject to multiple investment constraints. The number of parameters\nof the (potentially deep) neural network remains independent of the number of\nportfolio rebalancing events, and in contrast to, for example, reinforcement\nlearning, the approach avoids the computation of high-dimensional conditional\nexpectations. As a result, the approach remains practical even when considering\nlarge numbers of underlying assets, long investment time horizons or very\nfrequent rebalancing events. We prove convergence of the numerical solution to\nthe theoretical optimal solution of a large class of problems under fairly\ngeneral conditions, and present ground truth analyses for a number of popular\nformulations, including mean-variance and mean-conditional value-at-risk\nproblems. We also show that it is feasible to solve Sortino ratio-inspired\nobjectives (penalizing only the variance of wealth outcomes below the mean) in\ndynamic trading settings with the proposed approach. Using numerical\nexperiments, we demonstrate that if the investment objective functional is\nseparable in the sense of dynamic programming, the correct time-consistent\noptimal investment strategy is recovered, otherwise we obtain the correct\npre-commitment (time-inconsistent) investment strategy. The proposed approach\nremains agnostic as to the underlying data generating assumptions, and results\nare illustrated using (i) parametric models for underlying asset returns, (ii)\nstationary block bootstrap resampling of empirical returns, and (iii)\ngenerative adversarial network (GAN)-generated synthetic asset returns.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08968v1"
    },
    {
        "title": "On the number of terms in the COS method for European option pricing",
        "authors": [
            "Gero Junike"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The Fourier-cosine expansion (COS) method is used to price European options\nnumerically in a very efficient way. To apply the COS method, one has to\nspecify two parameters: a truncation range for the density of the log-returns\nand a number of terms N to approximate the truncated density by a cosine\nseries. How to choose the truncation range is already known. Here, we are able\nto find an explicit and useful bound for N as well for pricing and for the\nsensitivities, i.e., the Greeks Delta and Gamma, provided the density of the\nlog-returns is smooth. We further show that the COS method has an exponential\norder of convergence when the density is smooth and decays exponentially.\nHowever, when the density is smooth and has heavy tails, as in the Finite\nMoment Log Stable model, the COS method does not have exponential order of\nconvergence. Numerical experiments confirm the theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16012v13"
    },
    {
        "title": "Computing Volatility Surfaces using Generative Adversarial Networks with\n  Minimal Arbitrage Violations",
        "authors": [
            "Andrew Na",
            "Meixin Zhang",
            "Justin Wan"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we propose a generative adversarial network (GAN) approach for\nefficiently computing volatility surfaces. The idea is to make use of the\nspecial GAN neural architecture so that on one hand, we can learn volatility\nsurfaces from training data and on the other hand, enforce no-arbitrage\nconditions. In particular, the generator network is assisted in training by a\ndiscriminator that evaluates whether the generated volatility matches the\ntarget distribution. Meanwhile, our framework trains the GAN network to satisfy\nthe no-arbitrage constraints by introducing penalties as regularization terms.\nThe proposed GAN model allows the use of shallow networks which results in much\nless computational costs. In our experiments, we demonstrate the performance of\nthe proposed method by comparing with the state-of-the-art methods for\ncomputing implied and local volatility surfaces. We show that our GAN model can\noutperform artificial neural network (ANN) approaches in terms of accuracy and\ncomputational time.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.13128v3"
    },
    {
        "title": "Backward Hedging for American Options with Transaction Costs",
        "authors": [
            "Ludovic Goudenège",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this article, we introduce an algorithm called Backward Hedging, designed\nfor hedging European and American options while considering transaction costs.\nThe optimal strategy is determined by minimizing an appropriate loss function,\nwhich is based on either a risk measure or the mean squared error of the\nhedging strategy at maturity. The proposed algorithm moves backward in time,\ndetermining, for each time-step and different market states, the optimal\nhedging strategy that minimizes the loss function at the time the option is\nexercised, by assuming that the strategy used in the future for hedging the\nliability is the one determined at the previous steps of the algorithm. The\napproach avoids machine learning and instead relies on classic optimization\ntechniques, Monte Carlo simulations, and interpolations on a grid. Comparisons\nwith the Deep Hedging algorithm in various numerical experiments showcase the\nefficiency and accuracy of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.06805v2"
    },
    {
        "title": "Precision versus Shrinkage: A Comparative Analysis of Covariance\n  Estimation Methods for Portfolio Allocation",
        "authors": [
            "Sumanjay Dutta",
            "Shashi Jain"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we perform a comprehensive study of different covariance and\nprecision matrix estimation methods in the context of minimum variance\nportfolio allocation. The set of models studied by us can be broadly\ncategorized as: Gaussian Graphical Model (GGM) based methods, Shrinkage\nMethods, Thresholding and Random Matrix Theory (RMT) based methods. Among\nthese, GGM methods estimate the precision matrix directly while the other\napproaches estimate the covariance matrix. We perform a synthetic experiment to\nstudy the network learning and sample complexity performance of GGM methods.\nThereafter, we compare all the covariance and precision matrix estimation\nmethods in terms of their predictive ability for daily, weekly and monthly\nhorizons. We consider portfolio risk as an indicator of estimation error and\nemploy it as a loss function for comparison of the methods under consideration.\nWe find that GGM methods outperform shrinkage and other approaches. Our\nobservations for the performance of GGM methods are consistent with the\nsynthetic experiment. We also propose a new criterion for the hyperparameter\ntuning of GGM methods. Our tuning approach outperforms the existing methodology\nin the synthetic setup. We further perform an empirical experiment where we\nstudy the properties of the estimated precision matrix. The properties of the\nestimated precision matrices calculated using our tuning approach are in\nagreement with the algorithm performances observed in the synthetic experiment\nand the empirical experiment for predictive ability performance comparison.\nApart from this, we perform another synthetic experiment which demonstrates the\ndirect relation between estimation error of the precision matrix and portfolio\nrisk.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11298v1"
    },
    {
        "title": "Efficient Learning of Nested Deep Hedging using Multiple Options",
        "authors": [
            "Masanori Hirano",
            "Kentaro Imajo",
            "Kentaro Minami",
            "Takuya Shimada"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Deep hedging is a framework for hedging derivatives in the presence of market\nfrictions. In this study, we focus on the problem of hedging a given target\noption by using multiple options. To extend the deep hedging framework to this\nsetting, the options used as hedging instruments also have to be priced during\ntraining. While one might use classical pricing model such as the Black-Scholes\nformula, ignoring frictions can offer arbitrage opportunities which are\nundesirable for deep hedging learning. The goal of this study is to develop a\nnested deep hedging method. That is, we develop a fully-deep approach of deep\nhedging in which the hedging instruments are also priced by deep neural\nnetworks that are aware of frictions. However, since the prices of hedging\ninstruments have to be calculated under many different conditions, the entire\nlearning process can be computationally intractable. To overcome this problem,\nwe propose an efficient learning method for nested deep hedging. Our method\nconsists of three techniques to circumvent computational intractability, each\nof which reduces redundant computations during training. We show through\nexperiments that the Black-Scholes pricing of hedge instruments can admit\nsignificant arbitrage opportunities, which are not observed when the pricing is\nperformed by deep hedging. We also demonstrate that our proposed method\nsuccessfully reduces the hedging risks compared to a baseline method that does\nnot use options as hedging instruments.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.12264v1"
    },
    {
        "title": "Value-at-Risk-Based Portfolio Insurance: Performance Evaluation and\n  Benchmarking Against CPPI in a Markov-Modulated Regime-Switching Market",
        "authors": [
            "Peyman Alipour",
            "Ali Foroush Bastani"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Designing dynamic portfolio insurance strategies under market conditions\nswitching between two or more regimes is a challenging task in financial\neconomics. Recently, a promising approach employing the value-at-risk (VaR)\nmeasure to assign weights to risky and riskless assets has been proposed in\n[Jiang C., Ma Y. and An Y. \"The effectiveness of the VaR-based portfolio\ninsurance strategy: An empirical analysis\" , International Review of Financial\nAnalysis 18(4) (2009): 185-197]. In their study, the risky asset follows a\ngeometric Brownian motion with constant drift and diffusion coefficients. In\nthis paper, we first extend their idea to a regime-switching framework in which\nthe expected return of the risky asset and its volatility depend on an\nunobservable Markovian term which describes the cyclical nature of asset\nreturns in modern financial markets. We then analyze and compare the resulting\nVaR-based portfolio insurance (VBPI) strategy with the well-known constant\nproportion portfolio insurance (CPPI) strategy. In this respect, we employ a\nvariety of performance evaluation criteria such as Sharpe, Omega and Kappa\nratios to compare the two methods. Our results indicate that the CPPI strategy\nhas a better risk-return tradeoff in most of the scenarios analyzed and\nmaintains a relatively stable return profile for the resulting portfolio at the\nmaturity.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.12539v1"
    },
    {
        "title": "InProC: Industry and Product/Service Code Classification",
        "authors": [
            "Simerjot Kaur",
            "Andrea Stefanucci",
            "Sameena Shah"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Determining industry and product/service codes for a company is an important\nreal-world task and is typically very expensive as it involves manual curation\nof data about the companies. Building an AI agent that can predict these codes\nautomatically can significantly help reduce costs, and eliminate human biases\nand errors. However, unavailability of labeled datasets as well as the need for\nhigh precision results within the financial domain makes this a challenging\nproblem. In this work, we propose a hierarchical multi-class industry code\nclassifier with a targeted multi-label product/service code classifier\nleveraging advances in unsupervised representation learning techniques. We\ndemonstrate how a high quality industry and product/service code classification\nsystem can be built using extremely limited labeled dataset. We evaluate our\napproach on a dataset of more than 20,000 companies and achieved a\nclassification accuracy of more than 92\\%. Additionally, we also compared our\napproach with a dataset of 350 manually labeled product/service codes provided\nby Subject Matter Experts (SMEs) and obtained an accuracy of more than 96\\%\nresulting in real-life adoption within the financial domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13532v1"
    },
    {
        "title": "Parameter Estimation Methods of Required Rate of Return",
        "authors": [
            "Battulga Gankhuu"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this study, we introduce new estimation methods for the required rate of\nreturns on equity and liabilities of private and public companies using the\nstochastic dividend discount model (DDM). To estimate the required rate of\nreturn on equity, we use the maximum likelihood method, the Bayesian method,\nand the Kalman filtering. We also provide a method that evaluates the market\nvalues of liabilities. We apply the model to a set of firms from the S\\&P 500\nindex using historical dividend and price data over a 32--year period. Overall,\nthe suggested methods can be used to estimate the required rate of returns.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.19708v3"
    },
    {
        "title": "Monte Carlo simulation for Barndorff-Nielsen and Shephard model under\n  change of measure",
        "authors": [
            "Takuji Arai",
            "Yuto Imai"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The Barndorff-Nielsen and Shephard model is a representative jump-type\nstochastic volatility model. Still, no method exists to compute option prices\nnumerically for the non-martingale case with infinite active jumps. We develop\ntwo simulation methods for such a case under change of measure and conduct some\nnumerical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.05750v1"
    },
    {
        "title": "Failure of Fourier pricing techniques to approximate the Greeks",
        "authors": [
            "Tobias Behrens",
            "Gero Junike",
            "Wim Schoutens"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The Greeks Delta and Gamma of plain vanilla options play a fundamental role\nin finance, e.g., in hedging or risk management. These Greeks are approximated\nin many models such as the widely used Variance Gamma model by Fourier\ntechniques such as the Carr-Madan formula, the COS method or the Lewis formula.\nHowever, for some realistic market parameters, we show empirically that these\nthree Fourier methods completely fail to approximate the Greeks. As an\napplication we show that the Delta-Gamma VaR is severely underestimated in\nrealistic market environments. As a solution, we propose to use finite\ndifferences instead to obtain the Greeks.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.08421v6"
    },
    {
        "title": "Detecting Depegs: Towards Safer Passive Liquidity Provision on Curve\n  Finance",
        "authors": [
            "Thomas N. Cintra",
            "Maxwell P. Holloway"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We consider a liquidity provider's (LP's) exposure to stablecoin and liquid\nstaking derivative (LSD) depegs on Curve's StableSwap pools. We construct a\nsuite of metrics designed to detect potential asset depegs based on price and\ntrading data. Using our metrics, we fine-tune a Bayesian Online Changepoint\nDetection (BOCD) algorithm to alert LPs of potential depegs before or as they\noccur. We train and test our changepoint detection algorithm against Curve LP\ntoken prices for 13 StableSwap pools throughout 2022 and 2023, focusing on\nrelevant stablecoin and LSD depegs. We show that our model, trained on 2022 UST\ndata, is able to detect the USDC depeg in March of 2023 at 9pm UTC on March\n10th, approximately 5 hours before USDC dips below 99 cents, with few false\nalarms in the 17 months on which it is tested. Finally, we describe how this\nresearch may be used by Curve's liquidity providers, and how it may be extended\nto dynamically de-risk Curve pools by modifying parameters in anticipation of\npotential depegs. This research underpins an API developed to alert Curve LPs,\nin real-time, when their positions might be at risk.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.10612v1"
    },
    {
        "title": "Critical comparisons on deep learning approaches for foreign exchange\n  rate prediction",
        "authors": [
            "Zhu Bangyuan"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In a natural market environment, the price prediction model needs to be\nupdated in real time according to the data obtained by the system to ensure the\naccuracy of the prediction. In order to improve the user experience of the\nsystem, the price prediction function needs to use the fastest training model\nand the model prediction fitting effect of the best network as a predictive\nmodel. We conduct research on the fundamental theories of RNN, LSTM, and BP\nneural networks, analyse their respective characteristics, and discuss their\nadvantages and disadvantages to provide a reference for the selection of\nprice-prediction models.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06600v1"
    },
    {
        "title": "From characteristic functions to multivariate distribution functions and\n  European option prices by the damped COS method",
        "authors": [
            "Gero Junike",
            "Hauke Stier"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We provide a unified framework to obtain numerically certain quantities, such\nas the distribution function, absolute moments and prices of financial options,\nfrom the characteristic function of some (unknown) probability density function\nusing the Fourier-cosine expansion (COS) method. The classical COS method is\nnumerically very efficient in one-dimension, but it cannot deal very well with\ncertain integrands in general dimensions. Therefore, we introduce the damped\nCOS method, which can handle a large class of integrands very efficiently. We\nprove the convergence of the (damped) COS method and study its order of\nconvergence. The method converges exponentially if the characteristic function\ndecays exponentially. To apply the (damped) COS method, one has to specify two\nparameters: a truncation range for the multivariate density and the number of\nterms to approximate the truncated density by a cosine series. We provide an\nexplicit formula for the truncation range and an implicit formula for the\nnumber of terms. Numerical experiments up to five dimensions confirm the\ntheoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12843v7"
    },
    {
        "title": "Bayesian framework for characterizing cryptocurrency market dynamics,\n  structural dependency, and volatility using potential field",
        "authors": [
            "Anoop C V",
            "Neeraj Negi",
            "Anup Aprem"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Identifying the structural dependence between the cryptocurrencies and\npredicting market trend are fundamental for effective portfolio management in\ncryptocurrency trading. In this paper, we present a unified Bayesian framework\nbased on potential field theory and Gaussian Process to characterize the\nstructural dependency of various cryptocurrencies, using historic price\ninformation. The following are our significant contributions: (i) Proposed a\nnovel model for cryptocurrency price movements as a trajectory of a dynamical\nsystem governed by a time-varying non-linear potential field. (ii) Validated\nthe existence of the non-linear potential function in cryptocurrency market\nthrough Lyapunov stability analysis. (iii) Developed a Bayesian framework for\ninferring the non-linear potential function from observed cryptocurrency\nprices. (iv) Proposed that attractors and repellers inferred from the potential\nfield are reliable cryptocurrency market indicators, surpassing existing\nattributes, such as, mean, open price or close price of an observation window,\nin the literature. (v) Analysis of cryptocurrency market during various Bitcoin\ncrash durations from April 2017 to November 2021, shows that attractors\ncaptured the market trend, volatility, and correlation. In addition, attractors\naids explainability and visualization. (vi) The structural dependence inferred\nby the proposed approach was found to be consistent with results obtained using\nthe popular wavelet coherence approach. (vii) The proposed market indicators\n(attractors and repellers) can be used to improve the prediction performance of\nstate-of-art deep learning price prediction models. As, an example, we show\nimprovement in Litecoin price prediction up to a horizon of 12 days.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.01013v1"
    },
    {
        "title": "Reconstructing cryptocurrency processes via Markov chains",
        "authors": [
            "Tanya Araújo",
            "Paulo Barbosa"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The growing attention on cryptocurrencies has led to increasing research on\ndigital stock markets. Approaches and tools usually applied to characterize\nstandard stocks have been applied to the digital ones. Among these tools is the\nidentification of processes of market fluctuations. Being interesting\nstochastic processes, the usual statistical methods are appropriate tools for\ntheir reconstruction. There, besides chance, the description of a behavioural\ncomponent shall be present whenever a deterministic pattern is ever found.\nMarkov approaches are at the leading edge of this endeavour. In this paper,\nMarkov chains of orders one to eight are considered as a way to forecast the\ndynamics of three major cryptocurrencies. It is accomplished using an empirical\nbasis of intra-day returns. Besides forecasting, we investigate the existence\nof eventual long-memory components in each of those stochastic processes.\nResults show that predictions obtained from using the empirical probabilities\nare better than random choices.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.07626v1"
    },
    {
        "title": "To the Moon: Analyzing Collective Trading Events on the Wings of\n  Sentiment Analysis",
        "authors": [
            "Tim Matthies",
            "Thomas Löhden",
            "Stephan Leible",
            "Jun-Patrick Raabe"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This research investigates the growing trend of retail investors\nparticipating in certain stocks by organizing themselves on social media\nplatforms, particularly Reddit. Previous studies have highlighted a notable\nassociation between Reddit activity and the volatility of affected stocks. This\nstudy seeks to expand the analysis to Twitter, which is among the most\nimpactful social media platforms. To achieve this, we collected relevant tweets\nand analyzed their sentiment to explore the correlation between Twitter\nactivity, sentiment, and stock volatility. The results reveal a significant\nrelationship between Twitter activity and stock volatility but a weak link\nbetween tweet sentiment and stock performance. In general, Twitter activity and\nsentiment appear to play a less critical role in these events than Reddit\nactivity. These findings offer new theoretical insights into the impact of\nsocial media platforms on stock market dynamics, and they may practically\nassist investors and regulators in comprehending these phenomena better.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09968v1"
    },
    {
        "title": "The Potential of Quantum Techniques for Stock Price Prediction",
        "authors": [
            "Naman S",
            "Gaurang B",
            "Neel S",
            "Aswath Babu H"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We explored the potential applications of various Quantum Algorithms for\nstock price prediction by conducting a series of experimental simulations using\nboth Classical as well as Quantum Hardware. Firstly, we extracted various stock\nprice indicators, such as Moving Averages (MA), Average True Range (ATR), and\nAroon, to gain insights into market trends and stock price movements. Next, we\nemployed Quantum Annealing (QA) for feature selection and Principal Component\nAnalysis (PCA) for dimensionality reduction. Further, we transformed the stock\nprice prediction task essentially into a classification problem. We trained the\nQuantum Support Vector Machine (QSVM) to predict price movements (whether up or\ndown) contrasted their performance with classical models and analyzed their\naccuracy on a dataset formulated using Quantum Annealing and PCA individually.\nWe focused on the stock price prediction and binary classification of stock\nprices for four different companies, namely Apple, Visa, Johnson and Jonson,\nand Honeywell. We primarily used the real-time stock data of the raw stock\nprices of these companies. We compared various Quantum Computing techniques\nwith their classical counterparts in terms of accuracy and F-score of the\nprediction model. Through these experimental simulations, we shed light on the\npotential advantages and limitations of Quantum Algorithms in stock price\nprediction and contribute to the growing body of knowledge at the intersection\nof Quantum Computing and Finance.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.13642v1"
    },
    {
        "title": "The Financial Market of Environmental Indices",
        "authors": [
            "Thisari K. Mahanama",
            "Abootaleb Shirvani",
            "Svetlozar Rachev",
            "Frank J. Fabozzi"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper introduces the concept of a global financial market for\nenvironmental indices, addressing sustainability concerns and aiming to attract\ninstitutional investors. Risk mitigation measures are implemented to manage\ninherent risks associated with investments in this new financial market. We\nmonetize the environmental indices using quantitative measures and construct\ncountry-specific environmental indices, enabling them to be viewed as\ndollar-denominated assets. Our primary goal is to encourage the active\nengagement of institutional investors in portfolio analysis and trading within\nthis emerging financial market. To evaluate and manage investment risks, our\napproach incorporates financial econometric theory and dynamic asset pricing\ntools. We provide an econometric analysis that reveals the relationships\nbetween environmental and economic indicators in this market. Additionally, we\nderive financial put options as insurance instruments that can be employed to\nmanage investment risks. Our factor analysis identifies key drivers in the\nglobal financial market for environmental indices. To further evaluate the\nmarket's performance, we employ pricing options, efficient frontier analysis,\nand regression analysis. These tools help us assess the efficiency and\neffectiveness of the market. Overall, our research contributes to the\nunderstanding and development of the global financial market for environmental\nindices.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.15661v1"
    },
    {
        "title": "Introducing the $σ$-Cell: Unifying GARCH, Stochastic Fluctuations\n  and Evolving Mechanisms in RNN-based Volatility Forecasting",
        "authors": [
            "German Rodikov",
            "Nino Antulov-Fantulin"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper introduces the $\\sigma$-Cell, a novel Recurrent Neural Network\n(RNN) architecture for financial volatility modeling. Bridging traditional\neconometric approaches like GARCH with deep learning, the $\\sigma$-Cell\nincorporates stochastic layers and time-varying parameters to capture dynamic\nvolatility patterns. Our model serves as a generative network, approximating\nthe conditional distribution of latent variables. We employ a\nlog-likelihood-based loss function and a specialized activation function to\nenhance performance. Experimental results demonstrate superior forecasting\naccuracy compared to traditional GARCH and Stochastic Volatility models, making\nthe next step in integrating domain knowledge with neural networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01565v1"
    },
    {
        "title": "Fourier Neural Network Approximation of Transition Densities in Finance",
        "authors": [
            "Rong Du",
            "Duy-Minh Dang"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper introduces FourNet, a novel single-layer feed-forward neural\nnetwork (FFNN) method designed to approximate transition densities for which\nclosed-form expressions of their Fourier transforms, i.e. characteristic\nfunctions, are available. A unique feature of FourNet lies in its use of a\nGaussian activation function, enabling exact Fourier and inverse Fourier\ntransformations and drawing analogies with the Gaussian mixture model. We\nmathematically establish FourNet's capacity to approximate transition densities\nin the $L_2$-sense arbitrarily well with finite number of neurons. The\nparameters of FourNet are learned by minimizing a loss function derived from\nthe known characteristic function and the Fourier transform of the FFNN,\ncomplemented by a strategic sampling approach to enhance training. We derive\npractical bounds for the $L_2$ estimation error and the potential pointwise\nloss of nonnegativity in FourNet for $d$-dimensions ($d\\ge 1$), highlighting\nits robustness and applicability in practical settings. FourNet's accuracy and\nversatility are demonstrated through a wide range of dynamics common in\nquantitative finance, including L\\'{e}vy processes and the Heston stochastic\nvolatility models-including those augmented with the self-exciting Queue-Hawkes\njump process.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.03966v3"
    },
    {
        "title": "Monte Carlo Simulation for Trading Under a Lévy-Driven Mean-Reverting\n  Framework",
        "authors": [
            "Tim Leung",
            "Kevin W. Lu"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We present a Monte Carlo approach to pairs trading on mean-reverting spreads\nmodeled by L\\'evy-driven Ornstein-Uhlenbeck processes. Specifically, we focus\non using a variance gamma driving process, an infinite activity pure jump\nprocess to allow for more flexible models of the price spread than is available\nin the classical model. However, this generalization comes at the cost of not\nhaving analytic formulas, so we apply Monte Carlo methods to determine optimal\ntrading levels and develop a variance reduction technique using control\nvariates. Within this framework, we numerically examine how the optimal trading\nstrategies are affected by the parameters of the model. In addition, we extend\nour method to bivariate spreads modeled using a weak variance alpha-gamma\ndriving process, and explore the effect of correlation on these trades.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.05512v2"
    },
    {
        "title": "A monotone numerical integration method for mean-variance portfolio\n  optimization under jump-diffusion models",
        "authors": [
            "Hanwen Zhang",
            "Duy-Minh Dang"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We develop a efficient, easy-to-implement, and strictly monotone numerical\nintegration method for Mean-Variance (MV) portfolio optimization in realistic\ncontexts, which involve jump-diffusion dynamics of the underlying controlled\nprocesses, discrete rebalancing, and the application of investment constraints,\nnamely no-bankruptcy and leverage. A crucial element of the MV portfolio\noptimization formulation over each rebalancing interval is a convolution\nintegral, which involves a conditional density of the logarithm of the amount\ninvested in the risky asset. Using a known closed-form expression for the\nFourier transform of this density, we derive an infinite series representation\nfor the conditional density where each term is strictly positive and explicitly\ncomputable. As a result, the convolution integral can be readily approximated\nthrough a monotone integration scheme, such as a composite quadrature rule\ntypically available in most programming languages. The computational complexity\nof our method is an order of magnitude lower than that of existing monotone\nfinite difference methods. To further enhance efficiency, we propose an\nimplementation of the scheme via Fast Fourier Transforms, exploiting the\nToeplitz matrix structure. The proposed monotone scheme is proven to be both\n$\\ell_{\\infty}$-stable and pointwise consistent, and we rigorously establish\nits pointwise convergence to the unique solution of the MV portfolio\noptimization problem. We also intuitively demonstrate that, as the rebalancing\ntime interval approaches zero, the proposed scheme converges to a continuously\nobserved impulse control formulation for MV optimization expressed as a\nHamilton-Jacobi-Bellman Quasi-Variational Inequality. Numerical results show\nremarkable agreement with benchmark solutions obtained through finite\ndifferences and Monte Carlo simulation, underscoring the effectiveness of our\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.05977v1"
    },
    {
        "title": "Weak Markovian Approximations of Rough Heston",
        "authors": [
            "Christian Bayer",
            "Simon Breneis"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The rough Heston model is a very popular recent model in mathematical\nfinance; however, the lack of Markov and semimartingale properties poses\nsignificant challenges in both theory and practice. A way to resolve this\nproblem is to use Markovian approximations of the model. Several previous works\nhave shown that these approximations can be very accurate even when the number\nof additional factors is very low. Existing error analysis is largely based on\nthe strong error, corresponding to the $L^2$ distance between the kernels.\nExtending earlier results by [Abi Jaber and El Euch, SIAM Journal on Financial\nMathematics 10(2):309--349, 2019], we show that the weak error of the Markovian\napproximations can be bounded using the $L^1$-error in the kernel approximation\nfor general classes of payoff functions for European style options. Moreover,\nwe give specific Markovian approximations which converge super-polynomially in\nthe number of dimensions, and illustrate their numerical superiority in option\npricing compared to previously existing approximations. The new approximations\nalso work for the hyper-rough case $H > -1/2$.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.07023v1"
    },
    {
        "title": "Optimal Entry and Exit with Signature in Statistical Arbitrage",
        "authors": [
            "Boming Ning",
            "Prakash Chakraborty",
            "Kiseop Lee"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we explore an optimal timing strategy for the trading of price\nspreads exhibiting mean-reverting characteristics. A sequential optimal\nstopping framework is formulated to analyze the optimal timings for both\nentering and subsequently liquidating positions, all while considering the\nimpact of transaction costs. Then we leverages a refined signature optimal\nstopping method to resolve this sequential optimal stopping problem, thereby\nunveiling the precise entry and exit timings that maximize gains. Our framework\noperates without any predefined assumptions regarding the dynamics of the\nunderlying mean-reverting spreads, offering adaptability to diverse scenarios.\nNumerical results are provided to demonstrate its superior performance when\ncomparing with conventional mean reversion trading rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.16008v4"
    },
    {
        "title": "A semi-Lagrangian $ε$-monotone Fourier method for continuous\n  withdrawal GMWBs under jump-diffusion with stochastic interest rate",
        "authors": [
            "Yaowen Lu",
            "Duy-Minh Dang"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We develop an efficient pricing approach for guaranteed minimum withdrawal\nbenefits (GMWBs) with continuous withdrawals under a realistic modeling setting\nwith jump-diffusions and stochastic interest rate. Utilizing an impulse\nstochastic control framework, we formulate the no-arbitrage GMWB pricing\nproblem as a time-dependent Hamilton-Jacobi-Bellman (HJB) Quasi-Variational\nInequality (QVI) having three spatial dimensions with cross derivative terms.\nThrough a novel numerical approach built upon a combination of a\nsemi-Lagrangian method and the Green's function of an associated linear partial\nintegro-differential equation, we develop an $\\epsilon$-monotone Fourier\npricing method, where $\\epsilon > 0$ is a monotonicity tolerance. Together with\na provable strong comparison result for the HJB-QVI, we mathematically\ndemonstrate convergence of the proposed scheme to the viscosity solution of the\nHJB-QVI as $\\epsilon \\to 0$. We present a comprehensive study of the impact of\nsimultaneously considering jumps in the sub-account process and stochastic\ninterest rate on the no-arbitrage prices and fair insurance fees of GMWBs, as\nwell as on the holder's optimal withdrawal behaviors.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.00606v1"
    },
    {
        "title": "Efficient option pricing in the rough Heston model using weak simulation\n  schemes",
        "authors": [
            "Christian Bayer",
            "Simon Breneis"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We provide an efficient and accurate simulation scheme for the rough Heston\nmodel in the standard ($H>0$) as well as the hyper-rough regime ($H > -1/2$).\nThe scheme is based on low-dimensional Markovian approximations of the rough\nHeston process derived in [Bayer and Breneis, arXiv:2309.07023], and provides\nweak approximation to the rough Heston process. Numerical experiments show that\nthe new scheme exhibits second order weak convergence, while the computational\ncost increases linear with respect to the number of time steps. In comparison,\nexisting schemes based on discretization of the underlying stochastic Volterra\nintegrals such as Gatheral's HQE scheme show a quadratic dependence of the\ncomputational cost. Extensive numerical tests for standard and path-dependent\nEuropean options and Bermudan options show the method's accuracy and\nefficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04146v1"
    },
    {
        "title": "A generalization of the rational rough Heston approximation",
        "authors": [
            "Jim Gatheral",
            "Radoš Radoičić"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Previously, in [GR19], we derived a rational approximation of the solution of\nthe rough Heston fractional ODE in the special case \\lambda = 0, which\ncorresponds to a pure power-law kernel. In this paper we extend this solution\nto the general case of the Mittag-Leffler kernel with \\lambda \\geq 0. We\nprovide numerical evidence of the convergence of the solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09181v2"
    },
    {
        "title": "Quantifying the relative importance of the spatial and temporal\n  resolution in energy systems optimisation model",
        "authors": [
            "Nandi Moksnes",
            "William Usher"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  An increasing number of studies using energy system optimisation models are\nconducted with higher spatial and temporal resolution. This comes with a\ncomputational cost which places a limit on the size, complexity, and detail of\nthe model. In this paper, we explore the relative importance of structural\naspects of energy system models, spatial and temporal resolution, compared to\nuncertainties in input parameters such as final energy demand, discount rate\nand capital costs. We use global sensitivity analysis to uncover these\ninteractions for two developing countries, Kenya, and Benin, which still lack\nuniversal access to electricity. We find that temporal resolution has a high\ninfluence on all assessed results parameters, and spatial resolution has a\nsignificant influence on the expansion of distribution lines to the\nunelectrified population. The larger overall influence of temporal resolution\nindicates that this should be prioritised compared to spatial resolution.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.10518v1"
    },
    {
        "title": "No-Arbitrage Deep Calibration for Volatility Smile and Skewness",
        "authors": [
            "Kentaro Hoshisashi",
            "Carolyn E. Phelan",
            "Paolo Barucca"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Volatility smile and skewness are two key properties of option prices that\nare represented by the implied volatility (IV) surface. However, IV surface\ncalibration through nonlinear interpolation is a complex problem due to several\nfactors, including limited input data, low liquidity, and noise. Additionally,\nthe calibrated surface must obey the fundamental financial principle of the\nabsence of arbitrage, which can be modeled by various differential inequalities\nover the partial derivatives of the option price with respect to the expiration\ntime and the strike price. To address these challenges, we have introduced a\nDerivative-Constrained Neural Network (DCNN), which is an enhancement of a\nmultilayer perceptron (MLP) that incorporates derivatives in the objective\nfunction. DCNN allows us to generate a smooth surface and incorporate the\nno-arbitrage condition thanks to the derivative terms in the loss function. In\nnumerical experiments, we train the model using prices generated with the SABR\nmodel to produce smile and skewness parameters. We carry out different settings\nto examine the stability of the calibrated model under different conditions.\nThe results show that DCNNs improve the interpolation of the implied volatility\nsurface with smile and skewness by integrating the computation of the\nderivatives, which are necessary and sufficient no-arbitrage conditions. The\ndeveloped algorithm also offers practitioners an effective tool for\nunderstanding expected market dynamics and managing risk associated with\nvolatility smile and skewness.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.16703v3"
    },
    {
        "title": "Deeper Hedging: A New Agent-based Model for Effective Deep Hedging",
        "authors": [
            "Kang Gao",
            "Stephen Weston",
            "Perukrishnen Vytelingum",
            "Namid R. Stillman",
            "Wayne Luk",
            "Ce Guo"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We propose the Chiarella-Heston model, a new agent-based model for improving\nthe effectiveness of deep hedging strategies. This model includes momentum\ntraders, fundamental traders, and volatility traders. The volatility traders\nparticipate in the market by innovatively following a Heston-style volatility\nsignal. The proposed model generalises both the extended Chiarella model and\nthe Heston stochastic volatility model, and is calibrated to reproduce as many\nempirical stylized facts as possible. According to the stylised facts distance\nmetric, the proposed model is able to reproduce more realistic financial time\nseries than three baseline models: the extended Chiarella model, the Heston\nmodel, and the Geometric Brownian Motion. The proposed model is further\nvalidated by the Generalized Subtracted L-divergence metric. With the proposed\nChiarella-Heston model, we generate a training dataset to train a deep hedging\nagent for optimal hedging strategies under various transaction cost levels. The\ndeep hedging agent employs the Deep Deterministic Policy Gradient algorithm and\nis trained to maximize profits and minimize risks. Our testing results reveal\nthat the deep hedging agent, trained with data generated by our proposed model,\noutperforms the baseline in most transaction cost levels. Furthermore, the\ntesting process, which is conducted using empirical data, demonstrates the\neffective performance of the trained deep hedging agent in a realistic trading\nenvironment.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.18755v1"
    },
    {
        "title": "Maximizing Portfolio Predictability with Machine Learning",
        "authors": [
            "Michael Pinelis",
            "David Ruppert"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We construct the maximally predictable portfolio (MPP) of stocks using\nmachine learning. Solving for the optimal constrained weights in the\nmulti-asset MPP gives portfolios with a high monthly coefficient of\ndetermination, given the sample covariance matrix of predicted return errors\nfrom a machine learning model. Various models for the covariance matrix are\ntested. The MPPs of S&P 500 index constituents with estimated returns from\nElastic Net, Random Forest, and Support Vector Regression models can outperform\nor underperform the index depending on the time period. Portfolios that take\nadvantage of the high predictability of the MPP's returns and employ a Kelly\ncriterion style strategy consistently outperform the benchmark.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.01985v1"
    },
    {
        "title": "Advancing Algorithmic Trading: A Multi-Technique Enhancement of Deep\n  Q-Network Models",
        "authors": [
            "Gang Hu"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This study enhances a Deep Q-Network (DQN) trading model by incorporating\nadvanced techniques like Prioritized Experience Replay, Regularized Q-Learning,\nNoisy Networks, Dueling, and Double DQN. Extensive tests on assets like BTC/USD\nand AAPL demonstrate superior performance compared to the original model, with\nmarked increases in returns and Sharpe Ratio, indicating improved risk-adjusted\nrewards. Notably, convolutional neural network (CNN) architectures, both 1D and\n2D, significantly boost returns, suggesting their effectiveness in market trend\nanalysis. Across instruments, these enhancements have yielded stable and high\ngains, eclipsing the baseline and highlighting the potential of CNNs in trading\nsystems. The study suggests that applying sophisticated deep learning within\nreinforcement learning can greatly enhance automated trading, urging further\nexploration into advanced methods for broader financial applicability. The\nfindings advocate for the continued evolution of AI in finance.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.05743v1"
    },
    {
        "title": "A Gaussian Process Based Method with Deep Kernel Learning for Pricing\n  High-dimensional American Options",
        "authors": [
            "Jirong Zhuang",
            "Deng Ding",
            "Weiguo Lu",
            "Xuan Wu",
            "Gangnan Yuan"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this work, we present a novel machine learning approach for pricing\nhigh-dimensional American options based on the modified Gaussian process\nregression (GPR). We incorporate deep kernel learning and sparse variational\nGaussian processes to address the challenges traditionally associated with GPR.\nThese challenges include its diminished reliability in high-dimensional\nscenarios and the excessive computational costs associated with processing\nextensive numbers of simulated paths Our findings indicate that the proposed\nmethod surpasses the performance of the least squares Monte Carlo method in\nhigh-dimensional scenarios, particularly when the underlying assets are modeled\nby Merton's jump diffusion model. Moreover, our approach does not exhibit a\nsignificant increase in computational time as the number of dimensions grows.\nConsequently, this method emerges as a potential tool for alleviating the\nchallenges posed by the curse of dimensionality.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.07211v4"
    },
    {
        "title": "Fast calculation of Counterparty Credit exposures and associated\n  sensitivities using fourier series expansion",
        "authors": [
            "Gijs Mast",
            "Xiaoyu Shen",
            "Fang Fang"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper introduces a novel approach for computing netting--set level and\ncounterparty level exposures, such as Potential Future Exposure (PFE) and\nExpected Exposure (EE), along with associated sensitivities. The method is\nessentially an extension of the Fourier-cosine series expansion (COS) method,\noriginally proposed for option pricing. This method can accommodate a broad\nrange of models where the joint distribution of involved risk factors is\nanalytically or semi-analytically tractable. This inclusivity encompasses\nnearly all CCR models commonly employed in practice. A notable advantage of the\nCOS method is its sustained efficiency, particularly when handling large\nportfolios. A theoretical error analysis is also provided to justify the\nmethod's theoretical stability and accuracy. Various numerical tests are\nconducted using real-sized portfolios, and the results underscore its potential\nas a significantly more efficient alternative to the Monte Carlo method for\npractical usage, particularly applicable to portfolios involving a relatively\nmodest number of risk factors. Furthermore, the observed error convergence\nrates align closely with the theoretical error analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12575v1"
    },
    {
        "title": "Market Misconduct in Decentralized Finance (DeFi): Analysis, Regulatory\n  Challenges and Policy Implications",
        "authors": [
            "Xihan Xiong",
            "Zhipeng Wang",
            "Tianxiang Cui",
            "William Knottenbelt",
            "Michael Huth"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Technological advancement drives financial innovation, reshaping the\ntraditional finance landscape and redefining user-market interactions. The rise\nof blockchain and Decentralized Finance (DeFi) underscores this intertwined\nevolution of technology and finance. While DeFi has introduced exciting\nopportunities, it has also exposed the ecosystem to new forms of market\nmisconduct. This paper aims to bridge the academic and regulatory gaps by\naddressing key research questions about market misconduct in DeFi. We begin by\ndiscussing how blockchain technology can potentially enable the emergence of\nnovel forms of market misconduct. We then offer a comprehensive definition and\ntaxonomy for understanding DeFi market misconduct. Through comparative analysis\nand empirical measurements, we examine the novel forms of misconduct in DeFi,\nshedding light on their characteristics and social impact. Subsequently, we\ninvestigate the challenges of building a tailored regulatory framework for\nDeFi. We identify key areas where existing regulatory frameworks may need\nenhancement. Finally, we discuss potential approaches that bring DeFi into the\nregulatory perimeter.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17715v3"
    },
    {
        "title": "Deep Learning for Dynamic NFT Valuation",
        "authors": [
            "Mingxuan He"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  I study the price dynamics of non-fungible tokens (NFTs) and propose a deep\nlearning framework for dynamic valuation of NFTs. I use data from the Ethereum\nblockchain and OpenSea to train a deep learning model on historical trades,\nmarket trends, and traits/rarity features of Bored Ape Yacht Club NFTs. After\nhyperparameter tuning, the model is able to predict the price of NFTs with high\naccuracy. I propose an application framework for this model using\nzero-knowledge machine learning (zkML) and discuss its potential use cases in\nthe context of decentralized finance (DeFi) applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.05346v1"
    },
    {
        "title": "Leveraging Sample Entropy for Enhanced Volatility Measurement and\n  Prediction in International Oil Price Returns",
        "authors": [
            "Radhika Prosad Datta"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper explores the application of Sample Entropy (SampEn) as a\nsophisticated tool for quantifying and predicting volatility in international\noil price returns. SampEn, known for its ability to capture underlying patterns\nand predict periods of heightened volatility, is compared with traditional\nmeasures like standard deviation. The study utilizes a comprehensive dataset\nspanning 27 years (1986-2023) and employs both time series regression and\nmachine learning methods. Results indicate SampEn's efficacy in predicting\ntraditional volatility measures, with machine learning algorithms outperforming\nstandard regression techniques during financial crises. The findings underscore\nSampEn's potential as a valuable tool for risk assessment and decision-making\nin the realm of oil price investments.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.12788v1"
    },
    {
        "title": "Implied volatility (also) is path-dependent",
        "authors": [
            "Hervé Andrès",
            "Alexandre Boumezoued",
            "Benjamin Jourdain"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We propose a new model for the coherent forecasting of both the implied\nvolatility surfaces and the underlying asset returns.In the spirit of Guyon and\nLekeufack (2023) who are interested in the dependence of volatility indices\n(e.g. the VIX) on the paths of the associated equity indices (e.g. the S&P\n500), we first study how implied volatility can be predicted using the past\ntrajectory of the underlying asset price. Our empirical study reveals that a\nlarge part of the movements of the at-the-money-forward implied volatility for\nup to two years maturities can be explained using the past returns and their\nsquares. Moreover, we show that up to four years of the past evolution of the\nunderlying price should be used for the prediction and that this feedback\neffect gets weaker when the maturity increases. Building on this new stylized\nfact, we fit to historical data a parsimonious version of the SSVI\nparameterization (Gatheral and Jacquier, 2014) of the implied volatility\nsurface relying on only four parameters and show that the two parameters ruling\nthe at-the-money-forward implied volatility as a function of the maturity\nexhibit a path-dependent behavior with respect to the underlying asset price.\nFinally, we propose a model for the joint dynamics of the implied volatility\nsurface and the underlying asset price. The latter is modelled using a variant\nof the path-dependent volatility model of Guyon and Lekeufack and the former is\nobtained by adding a feedback effect of the underlying asset price onto the two\nparameters ruling the at-the-money-forward implied volatility in the\nparsimonious SSVI parameterization and by specifying a hidden semi-Markov\ndiffusion model for the residuals of these two parameters and the two other\nparameters. Thanks to this model, we are able to simulate highly realistic\npaths of implied volatility surfaces that are arbitrage-free.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.15950v2"
    },
    {
        "title": "Intraday Trading Algorithm for Predicting Cryptocurrency Price Movements\n  Using Twitter Big Data Analysis",
        "authors": [
            "Vahidin Jeleskovic",
            "Stephen Mackay"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Cryptocurrencies have emerged as a novel financial asset garnering\nsignificant attention in recent years. A defining characteristic of these\ndigital currencies is their pronounced short-term market volatility, primarily\ninfluenced by widespread sentiment polarization, particularly on social media\nplatforms such as Twitter. Recent research has underscored the correlation\nbetween sentiment expressed in various networks and the price dynamics of\ncryptocurrencies. This study delves into the 15-minute impact of informative\ntweets disseminated through foundation channels on trader behavior, with a\nfocus on potential outcomes related to sentiment polarization. The primary\nobjective is to identify factors that can predict positive price movements and\npotentially be leveraged through a trading algorithm. To accomplish this\nobjective, we conduct a conditional examination of return and excess return\nrates within the 15 minutes following tweet publication. The empirical findings\nreveal statistically significant increases in return rates, particularly within\nthe initial three minutes following tweet publication. Notably, adverse effects\nresulting from the messages were not observed. Surprisingly, sentiments were\nfound to have no discerni-ble impact on cryptocurrency price movements. Our\nanalysis further identifies that inves-tors are primarily influenced by the\nquality of tweet content, as reflected in the choice of words and tweet volume.\nWhile the basic trading algorithm presented in this study does yield some\nbenefits within the 15-minute timeframe, these benefits are not statistically\nsignificant. Nevertheless, it serves as a foundational framework for potential\nenhance-ments and further investigations.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00603v1"
    },
    {
        "title": "Graph database while computationally efficient filters out quickly the\n  ESG integrated equities in investment management",
        "authors": [
            "Partha Sen",
            "Sumana Sen"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Design/methodology/approach This research evaluated the databases of SQL,\nNo-SQL and graph databases to compare and contrast efficiency and performance.\nTo perform this experiment the data were collected from multiple sources\nincluding stock price and financial news. Python is used as an interface to\nconnect and query databases (to create database structures according to the\nfeed file structure, to load data into tables, objects, to read data , to\nconnect PostgreSQL, ElasticSearch, Neo4j. Purpose Modern applications of LLM\n(Large language model) including RAG (Retrieval Augmented Generation) with\nMachine Learning, deep learning, NLP (natural language processing) or Decision\nAnalytics are computationally expensive. Finding a better option to consume\nless resources and time to get the result. Findings The Graph database of ESG\n(Environmental, Social and Governance) is comparatively better and can be\nconsidered for extended analytics to integrate ESG in business and investment.\nPractical implications A graph ML with a RAG architecture model can be\nintroduced as a new framework with less computationally expensive LLM\napplication in the equity filtering process for portfolio management.\nOriginality/value Filtering out selective stocks out of two thousand or more\nlisted companies in any stock exchange for active investment, consuming less\nresource consumption especially memory and energy to integrate artificial\nintelligence and ESG in business and investment.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07483v1"
    },
    {
        "title": "Fitting random cash management models to data",
        "authors": [
            "Francisco Salas-Molina"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Organizations use cash management models to control balances to both avoid\noverdrafts and obtain a profit from short-term investments. Most management\nmodels are based on control bounds which are derived from the assumption of a\nparticular cash flow probability distribution. In this paper, we relax this\nstrong assumption to fit cash management models to data by means of stochastic\nand linear programming. We also introduce ensembles of random cash management\nmodels which are built by randomly selecting a subsequence of the original cash\nflow data set. We illustrate our approach by means of a real case study showing\nthat a small random sample of data is enough to fit sufficiently good\nbound-based models.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08548v1"
    },
    {
        "title": "Reinforcement Learning and Deep Stochastic Optimal Control for Final\n  Quadratic Hedging",
        "authors": [
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We consider two data driven approaches, Reinforcement Learning (RL) and Deep\nTrajectory-based Stochastic Optimal Control (DTSOC) for hedging a European call\noption without and with transaction cost according to a quadratic hedging P&L\nobjective at maturity (\"variance-optimal hedging\" or \"final quadratic\nhedging\"). We study the performance of the two approaches under various market\nenvironments (modeled via the Black-Scholes and/or the log-normal SABR model)\nto understand their advantages and limitations. Without transaction costs and\nin the Black-Scholes model, both approaches match the performance of the\nvariance-optimal Delta hedge. In the log-normal SABR model without transaction\ncosts, they match the performance of the variance-optimal Barlett's Delta\nhedge. Agents trained on Black-Scholes trajectories with matching initial\nvolatility but used on SABR trajectories match the performance of Bartlett's\nDelta hedge in average cost, but show substantially wider variance. To apply RL\napproaches to these problems, P&L at maturity is written as sum of step-wise\ncontributions and variants of RL algorithms are implemented and used that\nminimize expectation of second moments of such sums.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08600v1"
    },
    {
        "title": "Optimizing Transition Strategies for Small to Medium Sized Portfolios",
        "authors": [
            "Nakul Upadhya",
            "Alexandre Granzer-Guay"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This work discusses the benefits of constrained portfolio turnover strategies\nfor small to medium-sized portfolios. We propose a dynamic multi-period model\nthat aims to minimize transaction costs and maximize terminal wealth levels\nwhilst adhering to strict portfolio turnover constraints. Our results\ndemonstrate that using our framework in combination with a reasonable forecast,\ncan lead to higher portfolio values and lower transaction costs on average when\ncompared to a naive, single-period model. Such results were maintained given\ndifferent problem cases, such as, trading horizon, assets under management,\nwealth levels, etc. In addition, the proposed model lends itself to a\nreformulation that makes use of the column generation algorithm which can be\nstrategically leveraged to reduce complexity and solving times.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.13126v2"
    },
    {
        "title": "Higher order approximation of option prices in Barndorff-Nielsen and\n  Shephard models",
        "authors": [
            "Álvaro Guinea Juliá",
            "Alet Roux"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We present an approximation method based on the mixing formula (Hull & White\n1987, Romano & Touzi 1997) for pricing European options in Barndorff-Nielsen\nand Shephard models. This approximation is based on a Taylor expansion of the\noption price. It is implemented using a recursive algorithm that allows us to\nobtain closed form approximations of the option price of any order (subject to\ntechnical conditions on the background driving L\\'evy process). This method can\nbe used for any type of Barndorff-Nielsen and Shephard stochastic volatility\nmodel. Explicit results are presented in the case where the stationary\ndistribution of the background driving L\\'evy process is inverse Gaussian or\ngamma. In both of these cases, the approximation compares favorably to option\nprices produced by the characteristic function. In particular, we also perform\nan error analysis of the approximation, which is partially based on the results\nof Das & Langren\\'e (2022). We obtain asymptotic results for the error of the\n$N^{\\text{th}}$ order approximation and error bounds when the variance process\nsatisfies an inverse Gaussian Ornstein-Uhlenbeck process or a gamma\nOrnstein-Uhlenbeck process.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14390v2"
    },
    {
        "title": "Estimation of domain truncation error for a system of PDEs arising in\n  option pricing",
        "authors": [
            "Anindya Goswami",
            "Kuldip Singh Patel"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this paper, a multidimensional system of parabolic partial differential\nequations arising in European option pricing under a regime-switching market\nmodel is studied in details. For solving that numerically, one must truncate\nthe domain and impose an artificial boundary data. By deriving an estimate of\nthe domain truncation error at all the points in the truncated domain, we\nextend some results in the literature those deal with option pricing equation\nunder constant regime case only. We differ from the existing approach to obtain\nthe error estimate that is sharper in certain region of the domain. Hence, the\nminimum of proposed and existing gives a strictly sharper estimate. A\ncomprehensive comparison with the existing literature is carried out by\nconsidering some numerical examples. Those examples confirm that the\nimprovement in the error estimates is significant.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.15570v1"
    },
    {
        "title": "Option pricing for Barndorff-Nielsen and Shephard model by supervised\n  deep learning",
        "authors": [
            "Takuji Arai",
            "Yuto Imai"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper aims to develop a supervised deep-learning scheme to compute call\noption prices for the Barndorff-Nielsen and Shephard model with a\nnon-martingale asset price process having infinite active jumps. In our deep\nlearning scheme, teaching data is generated through the Monte Carlo method\ndeveloped by Arai and Imai (2024). Moreover, the BNS model includes many\nvariables, which makes the deep learning accuracy worse. Therefore, we will\ncreate another input variable using the Black-Scholes formula. As a result, the\naccuracy is improved dramatically.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.00445v1"
    },
    {
        "title": "Neural option pricing for rough Bergomi model",
        "authors": [
            "Changqing Teng",
            "Guanglian Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The rough Bergomi (rBergomi) model can accurately describe the historical and\nimplied volatilities, and has gained much attention in the past few years.\nHowever, there are many hidden unknown parameters or even functions in the\nmodel. In this work, we investigate the potential of learning the forward\nvariance curve in the rBergomi model using a neural SDE. To construct an\nefficient solver for the neural SDE, we propose a novel numerical scheme for\nsimulating the volatility process using the modified summation of exponentials.\nUsing the Wasserstein 1-distance to define the loss function, we show that the\nlearned forward variance curve is capable of calibrating the price process of\nthe underlying asset and the price of the European-style options\nsimultaneously. Several numerical tests are provided to demonstrate its\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.02714v1"
    },
    {
        "title": "A monotone piecewise constant control integration approach for the\n  two-factor uncertain volatility model",
        "authors": [
            "Duy-Minh Dang",
            "Hao Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Prices of option contracts on two assets within uncertain volatility models\nfor worst and best-case scenarios satisfy a two-dimensional\nHamilton-Jacobi-Bellman (HJB) partial differential equation (PDE) with cross\nderivatives terms. Traditional methods mainly involve finite differences and\npolicy iteration. This \"discretize, then optimize\" paradigm requires complex\nrotations of computational stencils for monotonicity.\n  This paper presents a novel and more streamlined \"decompose and integrate,\nthen optimize\" approach to tackle the aforementioned HJB PDE. Within each\ntimestep, our strategy employs a piecewise constant control, breaking down the\nHJB PDE into independent linear two-dimensional PDEs. Using known closed-form\nexpressions for the Fourier transforms of the Green's functions associated with\nthese PDEs, we determine an explicit formula for these functions. Since the\nGreen's functions are non-negative, the solutions to the PDEs, cast as\ntwo-dimensional convolution integrals, can be conveniently approximated using a\nmonotone integration method. Such integration methods, including a composite\nquadrature rule, are generally available in popular programming languages. To\nfurther enhance efficiency, we propose an implementation of this monotone\nintegration scheme via Fast Fourier Transforms, exploiting the Toeplitz matrix\nstructure. Optimal control is subsequently obtained by efficiently synthesizing\nthe solutions of the individual PDEs.\n  The proposed monotone piecewise constant control method is demonstrated to be\nboth $\\ell_{\\infty} $-stable and consistent in the viscosity sense, ensuring\nits convergence to the viscosity solution of the HJB equation. Numerical\nresults show remarkable agreement with benchmark solutions obtained by\nunconditionally monotone finite differences, tree methods, and Monte Carlo\nsimulation, underscoring the robustness and effectiveness of our method.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.06840v2"
    },
    {
        "title": "RiskMiner: Discovering Formulaic Alphas via Risk Seeking Monte Carlo\n  Tree Search",
        "authors": [
            "Tao Ren",
            "Ruihan Zhou",
            "Jinyang Jiang",
            "Jiafeng Liang",
            "Qinghao Wang",
            "Yijie Peng"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The formulaic alphas are mathematical formulas that transform raw stock data\ninto indicated signals. In the industry, a collection of formulaic alphas is\ncombined to enhance modeling accuracy. Existing alpha mining only employs the\nneural network agent, unable to utilize the structural information of the\nsolution space. Moreover, they didn't consider the correlation between alphas\nin the collection, which limits the synergistic performance. To address these\nproblems, we propose a novel alpha mining framework, which formulates the alpha\nmining problems as a reward-dense Markov Decision Process (MDP) and solves the\nMDP by the risk-seeking Monte Carlo Tree Search (MCTS). The MCTS-based agent\nfully exploits the structural information of discrete solution space and the\nrisk-seeking policy explicitly optimizes the best-case performance rather than\naverage outcomes. Comprehensive experiments are conducted to demonstrate the\nefficiency of our framework. Our method outperforms all state-of-the-art\nbenchmarks on two real-world stock sets under various metrics. Backtest\nexperiments show that our alphas achieve the most profitable results under a\nrealistic trading setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07080v2"
    },
    {
        "title": "The Life Care Annuity: enhancing product features and refining pricing\n  methods",
        "authors": [
            "G. Apicella",
            "A. Molent",
            "M. Gaudenzi"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The state-of-the-art proposes Life Care Annuities, that have been recently\ndesigned as variable annuity contracts with Long-Term Care payouts and\nGuaranteed Lifelong Withdrawal Benefits. In this paper, we propose more general\nfeatures for these insurance products and refine their pricing methods. We name\nour proposed product ``GLWB-LTC''. In particular, as to the product features,\nwe allow dynamic withdrawal strategies, including the surrender option.\nFurthermore, we consider stochastic interest rates, described by a\nCox-Ingersoll-Ross process. As to the numerical methods, we solve the\nstochastic control problem involved by the selection of the optimal withdrawal\nstrategy through a robust tree method, which outperforms the Monte Carlo\napproach. We name this method ``Tree-LTC'', and we use it to estimate the fair\nprice of the product, as some relevant parameters vary, such as, for instance,\nthe entry age of the policyholder. Furthermore, our numerical results show how\nthe optimal withdrawal strategy varies over time with the health status of the\npolicyholder. Our findings stress the important advantage of flexible\nwithdrawal strategies in relation to insurance policies offering protection\nfrom health risks. Indeed, the policyholder is given more choice about how much\nto save for protection from the possible disability states at future times.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02858v2"
    },
    {
        "title": "Hedonic Models Incorporating ESG Factors for Time Series of Average\n  Annual Home Prices",
        "authors": [
            "Jason R. Bailey",
            "W. Brent Lindquist",
            "Svetlozar T. Rachev"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Using data from 2000 through 2022, we analyze the predictive capability of\nthe annual numbers of new home constructions and four available environmental,\nsocial, and governance factors on the average annual price of homes sold in\neight major U.S. cities. We contrast the predictive capability of a P-spline\ngeneralized additive model (GAM) against a strictly linear version of the\ncommonly used generalized linear model (GLM). As the data for the annual price\nand predictor variables constitute non-stationary time series, to avoid\nspurious correlations in the analysis we transform each time series\nappropriately to produce stationary series for use in the GAM and GLM models.\nWhile arithmetic returns or first differences are adequate transformations for\nthe predictor variables, for the average price response variable we utilize the\nseries of innovations obtained from AR(q)-ARCH(1) fits. Based on the GAM\nresults, we find that the influence of ESG factors varies markedly by city,\nreflecting geographic diversity. Notably, the presence of air conditioning\nemerges as a strong factor. Despite limitations on the length of available time\nseries, this study represents a pivotal step toward integrating ESG\nconsiderations into predictive real estate models.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.07132v1"
    },
    {
        "title": "Subset second-order stochastic dominance for enhanced indexation with\n  diversification enforced by sector constraints",
        "authors": [
            "Cristiano Arbex Valle",
            "John E Beasley",
            "Nigel Meade"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this paper we apply second-order stochastic dominance (SSD) to the problem\nof enhanced indexation with asset subset (sector) constraints. The problem we\nconsider is how to construct a portfolio that is designed to outperform a given\nmarket index whilst having regard to the proportion of the portfolio invested\nin distinct market sectors.\n  In our approach, subset SSD, the portfolio associated with each sector is\ntreated in a SSD manner. In other words in subset SSD we actively try to find\nsector portfolios that SSD dominate their respective sector indices. However\nthe proportion of the overall portfolio invested in each sector is not\npre-specified, rather it is decided via optimisation. Our subset SSD approach\ninvolves the numeric solution of a multivariate second-order stochastic\ndominance problem.\n  Computational results are given for our approach as applied to the S&P500\nover the period 3rd October 2018 to 29th December 2023. This period, over 5\nyears, includes the Covid pandemic, which had a significant effect on stock\nprices. The S&P500 data that we have used is made publicly available for the\nbenefit of future researchers. Our computational results indicate that the\nscaled version of our subset SSD approach outperforms the S&P500. Our approach\nalso outperforms the standard SSD based approach to the problem. Our results\nshow, that for the S&P500 data considered, including sector constraints\nimproves out-of-sample performance, irrespective of the SSD approach adopted.\nResults are also given for Fama-French data involving 49 industry portfolios\nand these confirm the effectiveness of our subset SSD approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.16777v2"
    },
    {
        "title": "The Effect of Data Types' on the Performance of Machine Learning\n  Algorithms for Financial Prediction",
        "authors": [
            "Hulusi Mehmet Tanrikulu",
            "Hakan Pabuccu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Forecasting cryptocurrencies as a financial issue is crucial as it provides\ninvestors with possible financial benefits. A small improvement in forecasting\nperformance can lead to increased profitability; therefore, obtaining a\nrealistic forecast is very important for investors. Successful forecasting\nprovides traders with effective buy-or-hold strategies, allowing them to make\nmore profits. The most important thing in this process is to produce accurate\nforecasts suitable for real-life applications. Bitcoin, frequently mentioned\nrecently due to its volatility and chaotic behavior, has begun to pay great\nattention and has become an investment tool, especially during and after the\nCOVID-19 pandemic. This study provided a comprehensive methodology, including\nconstructing continuous and trend data using one and seven years periods of\ndata as inputs and applying machine learning (ML) algorithms to forecast\nBitcoin price movement. A binarization procedure was applied using continuous\ndata to construct the trend data representing each input feature trend.\nFollowing the related literature, the input features are determined as\ntechnical indicators, google trends, and the number of tweets. Random forest\n(RF), K-Nearest neighbor (KNN), Extreme Gradient Boosting (XGBoost-XGB),\nSupport vector machine (SVM) Naive Bayes (NB), Artificial Neural Networks\n(ANN), and Long-Short-Term Memory (LSTM) networks were applied on the selected\nfeatures for prediction purposes. This work investigates two main research\nquestions: i. How does the sample size affect the prediction performance of ML\nalgorithms? ii. How does the data type affect the prediction performance of ML\nalgorithms? Accuracy and area under the ROC curve (AUC) values were used to\ncompare the model performance. A t-test was performed to test the statistical\nsignificance of the prediction results.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.19324v1"
    },
    {
        "title": "A weighted multilevel Monte Carlo method",
        "authors": [
            "Yu Li",
            "Antony Ware"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The Multilevel Monte Carlo (MLMC) method has been applied successfully in a\nwide range of settings since its first introduction by Giles (2008). When using\nonly two levels, the method can be viewed as a kind of control-variate approach\nto reduce variance, as earlier proposed by Kebaier (2005). We introduce a\ngeneralization of the MLMC formulation by extending this control variate\napproach to any number of levels and deriving a recursive formula for computing\nthe weights associated with the control variates and the optimal numbers of\nsamples at the various levels.\n  We also show how the generalisation can also be applied to the\n\\emph{multi-index} MLMC method of Haji-Ali, Nobile, Tempone (2015), at the cost\nof solving a $(2^d-1)$-dimensional minimisation problem at each node when $d$\nindex dimensions are used.\n  The comparative performance of the weighted MLMC method is illustrated in a\nrange of numerical settings. While the addition of weights does not change the\n\\emph{asymptotic} complexity of the method, the results show that significant\nefficiency improvements over the standard MLMC formulation are possible,\nparticularly when the coarse level approximations are poorly correlated.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.03453v1"
    },
    {
        "title": "Cost-Benefit Analysis using Modular Dynamic Fault Tree Analysis and\n  Monte Carlo Simulations for Condition-based Maintenance of Unmanned Systems",
        "authors": [
            "Joseph M. Southgate",
            "Katrina Groth",
            "Peter Sandborn",
            "Shapour Azarm"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Recent developments in condition-based maintenance (CBM) have helped make it\na promising approach to maintenance cost avoidance in engineering systems. By\nperforming maintenance based on conditions of the component with regards to\nfailure or time, there is potential to avoid the large costs of system shutdown\nand maintenance delays. However, CBM requires a large investment cost compared\nto other available maintenance strategies. The investment cost is required for\nresearch, development, and implementation. Despite the potential to avoid\nsignificant maintenance costs, the large investment cost of CBM makes decision\nmakers hesitant to implement. This study is the first in the literature that\nattempts to address the problem of conducting a cost-benefit analysis (CBA) for\nimplementing CBM concepts for unmanned systems. This paper proposes a method\nfor conducting a CBA to determine the return on investment (ROI) of potential\nCBM strategies. The CBA seeks to compare different CBM strategies based on the\ndifferences in the various maintenance requirements associated with maintaining\na multi-component, unmanned system. The proposed method uses modular dynamic\nfault tree analysis (MDFTA) with Monte Carlo simulations (MCS) to assess the\nvarious maintenance requirements. The proposed method is demonstrated on an\nunmanned surface vessel (USV) example taken from the literature that consists\nof 5 subsystems and 71 components. Following this USV example, it is found that\nselecting different combinations of components for a CBM strategy can have a\nsignificant impact on maintenance requirements and ROI by impacting cost\navoidances and investment costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.09519v1"
    },
    {
        "title": "Gaussian Recombining Split Tree",
        "authors": [
            "Yury Lebedev",
            "Arunava Banerjee"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Binomial trees are widely used in the financial sector for valuing securities\nwith early exercise characteristics, such as American stock options. However,\nwhile effective in many scenarios, pricing options with CRR binomial trees are\nlimited. Major limitations are volatility estimation, constant volatility\nassumption, subjectivity in parameter choices, and impracticality of\ninstantaneous delta hedging. This paper presents a novel tree: Gaussian\nRecombining Split Tree (GRST), which is recombining and does not need\nlog-normality or normality market assumption. GRST generates a discrete\nprobability mass function of market data distribution, which approximates a\nGaussian distribution with known parameters at any chosen time interval. GRST\nMixture builds upon the GRST concept while being flexible to fit a large class\nof market distributions and when given a 1-D time series data and moments of\ndistributions at each time interval, fits a Gaussian mixture with the same\nmixture component probabilities applied at each time interval. Gaussian\nRecombining Split Tre Mixture comprises several GRST tied using Gaussian\nmixture component probabilities at the first node. Our extensive empirical\nanalysis shows that the option prices from the GRST align closely with the\nmarket.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.16333v1"
    },
    {
        "title": "DeepUnifiedMom: Unified Time-series Momentum Portfolio Construction via\n  Multi-Task Learning with Multi-Gate Mixture of Experts",
        "authors": [
            "Joel Ong",
            "Dorien Herremans"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper introduces DeepUnifiedMom, a deep learning framework that enhances\nportfolio management through a multi-task learning approach and a multi-gate\nmixture of experts. The essence of DeepUnifiedMom lies in its ability to create\nunified momentum portfolios that incorporate the dynamics of time series\nmomentum across a spectrum of time frames, a feature often missing in\ntraditional momentum strategies. Our comprehensive backtesting, encompassing\ndiverse asset classes such as equity indexes, fixed income, foreign exchange,\nand commodities, demonstrates that DeepUnifiedMom consistently outperforms\nbenchmark models, even after factoring in transaction costs. This superior\nperformance underscores DeepUnifiedMom's capability to capture the full\nspectrum of momentum opportunities within financial markets. The findings\nhighlight DeepUnifiedMom as an effective tool for practitioners looking to\nexploit the entire range of momentum opportunities. It offers a compelling\nsolution for improving risk-adjusted returns and is a valuable strategy for\nnavigating the complexities of portfolio management.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.08742v1"
    },
    {
        "title": "Operator Deep Smoothing for Implied Volatility",
        "authors": [
            "Lukas Gonon",
            "Antoine Jacquier",
            "Ruben Wiedemann"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We devise a novel method for nowcasting implied volatility based on neural\noperators. Better known as implied volatility smoothing in the financial\nindustry, nowcasting of implied volatility means constructing a smooth surface\nthat is consistent with the prices presently observed on a given option market.\nOption price data arises highly dynamically in ever-changing spatial\nconfigurations, which poses a major limitation to foundational machine learning\napproaches using classical neural networks. While large models in language and\nimage processing deliver breakthrough results on vast corpora of raw data, in\nfinancial engineering the generalization from big historical datasets has been\nhindered by the need for considerable data pre-processing. In particular,\nimplied volatility smoothing has remained an instance-by-instance, hands-on\nprocess both for neural network-based and traditional parametric strategies.\nOur general operator deep smoothing approach, instead, directly maps observed\ndata to smoothed surfaces. We adapt the graph neural operator architecture to\ndo so with high accuracy on ten years of raw intraday S&P 500 options data,\nusing a single model instance. The trained operator adheres to critical\nno-arbitrage constraints and is robust with respect to subsampling of inputs\n(occurring in practice in the context of outlier removal). We provide extensive\nhistorical benchmarks and showcase the generalization capability of our\napproach in a comparison with classical neural networks and SVI, an industry\nstandard parametrization for implied volatility. The operator deep smoothing\napproach thus opens up the use of neural networks on large historical datasets\nin financial engineering.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11520v2"
    },
    {
        "title": "An Improved Algorithm to Identify More Arbitrage Opportunities on\n  Decentralized Exchanges",
        "authors": [
            "Yu Zhang",
            "Tao Yan",
            "Jianhong Lin",
            "Benjamin Kraner",
            "Claudio Tessone"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In decentralized exchanges (DEXs), the arbitrage paths exist abundantly in\nthe form of both arbitrage loops (e.g. the arbitrage path starts from token A\nand back to token A again in the end, A, B,..., A) and non-loops (e.g. the\narbitrage path starts from token A and stops at a different token N, A, B,...,\nN). The Moore-Bellman-Ford algorithm, often coupled with the ``walk to the\nroot\" technique, is commonly employed for detecting arbitrage loops in the\ntoken graph of decentralized exchanges (DEXs) such as Uniswap. However, a\nlimitation of this algorithm is its ability to recognize only a limited number\nof arbitrage loops in each run. Additionally, it cannot specify the starting\ntoken of the detected arbitrage loops, further constraining its effectiveness\nin certain scenarios. Another limitation of this algorithm is its incapacity to\ndetect non-loop arbitrage paths between any specified pairs of tokens. In this\npaper, we develop a new method to solve these problems by combining the line\ngraph and a modified Moore-Bellman-Ford algorithm (MMBF). This method can help\nto find more arbitrage loops by detecting at least one arbitrage loop starting\nfrom any specified tokens in the DEXs and can detect the non-loop arbitrage\npaths between any pair of tokens. Then, we applied our algorithm to Uniswap V2\nand found more arbitrage loops and non-loops indeed compared with applying the\nMoore-Bellman-Ford (MBF) combined algorithm. The found arbitrage profit by our\nmethod in some arbitrage paths can be even as high as one million dollars, far\nlarger than that found by the MBF combined algorithm. Finally, we statistically\ncompare the distribution of arbitrage path lengths and the arbitrage profit\ndetected by both our method and the MBF combined algorithm, and depict how\npotential arbitrage opportunities change with time by our method.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.16573v1"
    },
    {
        "title": "Profit Maximization In Arbitrage Loops",
        "authors": [
            "Yu Zhang",
            "Zichen Li",
            "Tao Yan",
            "Qianyu Liu",
            "Nicolo Vallarano",
            "Claudio Tessone"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Cyclic arbitrage chances exist abundantly among decentralized exchanges\n(DEXs), like Uniswap V2. For an arbitrage cycle (loop), researchers or\npractitioners usually choose a specific token, such as Ether as input, and\noptimize their input amount to get the net maximal amount of the specific token\nas arbitrage profit. By considering the tokens' prices from CEXs in this paper,\nthe new arbitrage profit, called monetized arbitrage profit, will be quantified\nas the product of the net number of a specific token we got from the arbitrage\nloop and its corresponding price in CEXs. Based on this concept, we put forward\nthree different strategies to maximize the monetized arbitrage profit for each\narbitrage loop. The first strategy is called the MaxPrice strategy. Under this\nstrategy, arbitrageurs start arbitrage only from the token with the highest CEX\nprice. The second strategy is called the MaxMax strategy. Under this strategy,\nwe calculate the monetized arbitrage profit for each token as input in turn in\nthe arbitrage loop. Then, we pick up the most maximal monetized arbitrage\nprofit among them as the monetized arbitrage profit of the MaxMax strategy. The\nthird one is called the Convex Optimization strategy. By mapping the MaxMax\nstrategy to a convex optimization problem, we proved that the Convex\nOptimization strategy could get more profit in theory than the MaxMax strategy,\nwhich is proved again in a given example. We also proved that if no arbitrage\nprofit exists according to the MaxMax strategy, then the Convex Optimization\nstrategy can not detect any arbitrage profit, either. However, the empirical\ndata analysis denotes that the profitability of the Convex Optimization\nstrategy is almost equal to that of the MaxMax strategy, and the MaxPrice\nstrategy is not reliable in getting the maximal monetized arbitrage profit\ncompared to the MaxMax strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.16600v1"
    },
    {
        "title": "New intelligent empowerment for digital transformation",
        "authors": [
            "Peng Yifeng",
            "Gao Chen"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study proposes an innovative evaluation method based on large language\nmodels (LLMs) specifically designed to measure the digital transformation (DT)\nprocess of enterprises. By analyzing the annual reports of 4407 companies\nlisted on the New York Stock Exchange and Nasdaq from 2005 to 2022, a\ncomprehensive set of DT indicators was constructed. The findings revealed that\nDT significantly improves a company's financial performance, however, different\ndigital technologies exhibit varying effects on financial performance.\nSpecifically, blockchain technology has a relatively limited positive impact on\nfinancial performance. In addition, this study further discovered that DT can\npromote the growth of financial performance by enhancing operational efficiency\nand reducing costs. This study provides a novel DT evaluation tool for the\nacademic community, while also expanding the application scope of generative\nartificial intelligence technology in economic research.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18440v1"
    },
    {
        "title": "Predicting public market behavior from private equity deals",
        "authors": [
            "Paolo Barucca",
            "Flaviano Morone"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We process private equity transactions to predict public market behavior with\na logit model. Specifically, we estimate our model to predict quarterly returns\nfor both the broad market and for individual sectors. Our hypothesis is that\nprivate equity investments (in aggregate) carry predictive signal about\npublicly traded securities. The key source of such predictive signal is the\nfact that, during their diligence process, private equity fund managers are\nprivy to valuable company information that may not yet be reflected in the\npublic markets at the time of their investment. Thus, we posit that we can\ndiscover investors' collective near-term insight via detailed analysis of the\ntiming and nature of the deals they execute. We evaluate the accuracy of the\nestimated model by applying it to test data where we know the correct output\nvalue. Remarkably, our model performs consistently better than a null model\nsimply based on return statistics, while showing a predictive accuracy of up to\n70% in sectors such as Consumer Services, Communications, and Non Energy\nMinerals.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01818v1"
    },
    {
        "title": "Machine learning in weekly movement prediction",
        "authors": [
            "Han Gui"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  To predict the future movements of stock markets, numerous studies\nconcentrate on daily data and employ various machine learning (ML) models as\nbenchmarks that often vary and lack standardization across different research\nworks. This paper tries to solve the problem from a fresh standpoint by aiming\nto predict the weekly movements, and introducing a novel benchmark of random\ntraders. This benchmark is independent of any ML model, thus making it more\nobjective and potentially serving as a commonly recognized standard. During\ntraining process, apart from the basic features such as technical indicators,\nscaling laws and directional changes are introduced as additional features,\nfurthermore, the training datasets are also adjusted by assigning varying\nweights to different samples, the weighting approach allows the models to\nemphasize specific samples. On back-testing, several trained models show good\nperformance, with the multi-layer perception (MLP) demonstrating stability and\nrobustness across extensive and comprehensive data that include upward,\ndownward and cyclic trends. The unique perspective of this work that focuses on\nweekly movements, incorporates new features and creates an objective benchmark,\ncontributes to the existing literature on stock market prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.09831v1"
    },
    {
        "title": "FinDKG: Dynamic Knowledge Graphs with Large Language Models for\n  Detecting Global Trends in Financial Markets",
        "authors": [
            "Xiaohui Victor Li",
            "Francesco Sanna Passino"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Dynamic knowledge graphs (DKGs) are popular structures to express different\ntypes of connections between objects over time. They can also serve as an\nefficient mathematical tool to represent information extracted from complex\nunstructured data sources, such as text or images. Within financial\napplications, DKGs could be used to detect trends for strategic thematic\ninvesting, based on information obtained from financial news articles. In this\nwork, we explore the properties of large language models (LLMs) as dynamic\nknowledge graph generators, proposing a novel open-source fine-tuned LLM for\nthis purpose, called the Integrated Contextual Knowledge Graph Generator\n(ICKG). We use ICKG to produce a novel open-source DKG from a corpus of\nfinancial news articles, called FinDKG, and we propose an attention-based GNN\narchitecture for analysing it, called KGTransformer. We test the performance of\nthe proposed model on benchmark datasets and FinDKG, demonstrating superior\nperformance on link prediction tasks. Additionally, we evaluate the performance\nof the KGTransformer on FinDKG for thematic investing, showing it can\noutperform existing thematic ETFs.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.10909v2"
    },
    {
        "title": "Leveraging Machine Learning for High-Dimensional Option Pricing within\n  the Uncertain Volatility Model",
        "authors": [
            "Ludovic Goudenege",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper explores the application of Machine Learning techniques for\npricing high-dimensional options within the framework of the Uncertain\nVolatility Model (UVM). The UVM is a robust framework that accounts for the\ninherent unpredictability of market volatility by setting upper and lower\nbounds on volatility and the correlation among underlying assets. By leveraging\nhistorical data and extreme values of estimated volatilities and correlations,\nthe model establishes a confidence interval for future volatility and\ncorrelations, thus providing a more realistic approach to option pricing. By\nintegrating advanced Machine Learning algorithms, we aim to enhance the\naccuracy and efficiency of option pricing under the UVM, especially when the\noption price depends on a large number of variables, such as in basket or\npath-dependent options. Our approach evolves backward in time, dynamically\nselecting at each time step the most expensive volatility and correlation for\neach market state. Specifically, it identifies the particular values of\nvolatility and correlation that maximize the expected option value at the next\ntime step. This is achieved through the use of Gaussian Process regression, the\ncomputation of expectations via a single step of a multidimensional tree and\nthe Sequential Quadratic Programming optimization algorithm. The numerical\nresults demonstrate that the proposed approach can significantly improve the\nprecision of option pricing and risk management strategies compared with\nmethods already in the literature, particularly in high-dimensional contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.13213v1"
    },
    {
        "title": "Explainable AI in Request-for-Quote",
        "authors": [
            "Qiqin Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In the contemporary financial landscape, accurately predicting the\nprobability of filling a Request-For-Quote (RFQ) is crucial for improving\nmarket efficiency for less liquid asset classes. This paper explores the\napplication of explainable AI (XAI) models to forecast the likelihood of RFQ\nfulfillment. By leveraging advanced algorithms including Logistic Regression,\nRandom Forest, XGBoost and Bayesian Neural Tree, we are able to improve the\naccuracy of RFQ fill rate predictions and generate the most efficient quote\nprice for market makers. XAI serves as a robust and transparent tool for market\nparticipants to navigate the complexities of RFQs with greater precision.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.15038v1"
    },
    {
        "title": "Calibrating the Heston Model with Deep Differential Networks",
        "authors": [
            "Chen Zhang",
            "Giovanni Amici",
            "Marco Morandotti"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We propose a gradient-based deep learning framework to calibrate the Heston\noption pricing model (Heston, 1993). Our neural network, henceforth deep\ndifferential network (DDN), learns both the Heston pricing formula for\nplain-vanilla options and the partial derivatives with respect to the model\nparameters. The price sensitivities estimated by the DDN are not subject to the\nnumerical issues that can be encountered in computing the gradient of the\nHeston pricing function. Thus, our network is an excellent pricing engine for\nfast gradient-based calibrations. Extensive tests on selected equity markets\nshow that the DDN significantly outperforms non-differential feedforward neural\nnetworks in terms of calibration accuracy. In addition, it dramatically reduces\nthe computational time with respect to global optimizers that do not use\ngradient information.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.15536v1"
    },
    {
        "title": "Alleviating Non-identifiability: a High-fidelity Calibration Objective\n  for Financial Market Simulation with Multivariate Time Series Data",
        "authors": [
            "Chenkai Wang",
            "Junji Ren",
            "Peng Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The non-identifiability issue has been frequently reported in social\nsimulation works, where different parameters of an agent-based simulation model\nyield indistinguishable simulated time series data under certain discrepancy\nmetrics. This issue largely undermines the simulation fidelity yet lacks\ndedicated investigations. This paper theoretically demonstrates that\nincorporating multiple time series data features during the model calibration\nphase can exponentially alleviate non-identifiability as the number of features\nincreases. To implement this theoretical finding, a maximization-based\naggregation function is proposed based on existing discrepancy metrics to form\na new calibration objective function. For verification, the task of calibrating\nthe Financial Market Simulation (FMS), a typical yet complex social simulation,\nis considered. Empirical studies confirm the significant improvements in\nalleviating the non-identifiability of calibration tasks. Furthermore, as a\nmodel-agnostic method, it achieves much higher simulation fidelity of the\nchosen FMS model on both synthetic and real market data. Hence, this work is\nexpected to provide not only a rigorous understanding of non-identifiability in\nsocial simulation but also an off-the-shelf high-fidelity calibration objective\nfunction for FMS.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16566v4"
    },
    {
        "title": "CVA Sensitivities, Hedging and Risk",
        "authors": [
            "Stéphane Crépey",
            "Botao Li",
            "Hoang Nguyen",
            "Bouazza Saadeddine"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We present a unified framework for computing CVA sensitivities, hedging the\nCVA, and assessing CVA risk, using probabilistic machine learning meant as\nrefined regression tools on simulated data, validatable by low-cost companion\nMonte Carlo procedures. Various notions of sensitivities are introduced and\nbenchmarked numerically. We identify the sensitivities representing the best\npractical trade-offs in downstream tasks including CVA hedging and risk\nassessment.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.18583v1"
    },
    {
        "title": "Evaluating Microscopic and Macroscopic Models for Derivative Contracts\n  on Commodity Indices",
        "authors": [
            "Alberto Manzano",
            "Emanuele Nastasi",
            "Andrea Pallavicini",
            "Carlos Vázquez"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this article, we analyze two modeling approaches for the pricing of\nderivative contracts on a commodity index. The first one is a microscopic\napproach, where the components of the index are modeled individually, and the\nindex price is derived from their combination. The second one is a macroscopic\napproach, where the index is modeled directly. While the microscopic approach\noffers greater flexibility, its calibration results to be more challenging,\nthus leading practitioners to favor the macroscopic approach. However, in the\nmacroscopic model, the lack of explicit futures curve dynamics raises questions\nabout its ability to accurately capture the behavior of the index and its\nsensitivities. In order to investigate this, we calibrate both models using\nderivatives of the S\\&P GSCI Crude Oil excess-return index and compare their\npricing and sensitivities on path-dependent options, such as autocallable\ncontracts. This research provides insights into the suitability of macroscopic\nmodels for pricing and hedging purposes in real scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.00784v1"
    },
    {
        "title": "Existence, uniqueness and positivity of solutions to the Guyon-Lekeufack\n  path-dependent volatility model with general kernels",
        "authors": [
            "Hervé Andrès",
            "Benjamin Jourdain"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We show the existence and uniqueness of a continuous solution to a\npath-dependent volatility model introduced by Guyon and Lekeufack (2023) to\nmodel the price of an equity index and its spot volatility. The considered\nmodel for the trend and activity features can be written as a Stochastic\nVolterra Equation (SVE) with non-convolutional and non-bounded kernels as well\nas non-Lipschitz coefficients. We first prove the existence and uniqueness of a\nsolution to the SVE under integrability and regularity assumptions on the two\nkernels and under a condition on the second kernel weighting the past squared\nreturns which ensures that the activity feature is bounded from below by a\npositive constant. Then, assuming in addition that the kernel weighting the\npast returns is of exponential type and that an inequality relating the\nlogarithmic derivatives of the two kernels with respect to their second\nvariables is satisfied, we show the positivity of the volatility process which\nis obtained as a non-linear function of the SVE's solution. We show numerically\nthat the choice of an exponential kernel for the kernel weighting the past\nreturns has little impact on the quality of model calibration compared to other\nchoices and the inequality involving the logarithmic derivatives is satisfied\nby the calibrated kernels. These results extend those of Nutz and Valdevenito\n(2023).\n",
        "pdf_link": "http://arxiv.org/pdf/2408.02477v1"
    },
    {
        "title": "Why Groups Matter: Necessity of Group Structures in Attributions",
        "authors": [
            "Dangxing Chen",
            "Jingfeng Chen",
            "Weicheng Ye"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Explainable machine learning methods have been accompanied by substantial\ndevelopment. Despite their success, the existing approaches focus more on the\ngeneral framework with no prior domain expertise. High-stakes financial sectors\nhave extensive domain knowledge of the features. Hence, it is expected that\nexplanations of models will be consistent with domain knowledge to ensure\nconceptual soundness.\n  In this work, we study the group structures of features that are naturally\nformed in the financial dataset. Our study shows the importance of considering\ngroup structures that conform to the regulations. When group structures are\npresent, direct applications of explainable machine learning methods, such as\nShapley values and Integrated Gradients, may not provide consistent\nexplanations; alternatively, group versions of the Shapley value can provide\nconsistent explanations. We contain detailed examples to concentrate on the\npractical perspective of our framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.05701v1"
    },
    {
        "title": "Causality-Inspired Models for Financial Time Series Forecasting",
        "authors": [
            "Daniel Cunha Oliveira",
            "Yutong Lu",
            "Xi Lin",
            "Mihai Cucuringu",
            "Andre Fujita"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We introduce a novel framework to financial time series forecasting that\nleverages causality-inspired models to balance the trade-off between invariance\nto distributional changes and minimization of prediction errors. To the best of\nour knowledge, this is the first study to conduct a comprehensive comparative\nanalysis among state-of-the-art causal discovery algorithms, benchmarked\nagainst non-causal feature selection techniques, in the application of\nforecasting asset returns. Empirical evaluations demonstrate the efficacy of\nour approach in yielding stable and accurate predictions, outperforming\nbaseline models, particularly in tumultuous market conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09960v1"
    },
    {
        "title": "Trading with Time Series Causal Discovery: An Empirical Study",
        "authors": [
            "Ruijie Tang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study investigates the application of causal discovery algorithms in\nequity markets, with a focus on their potential to build investment strategies.\nAn investment strategy was developed based on the causal structures identified\nby these algorithms. The performance of the strategy is evaluated based on the\nprofitability and effectiveness in stock markets. The results indicate that\ncausal discovery algorithms can successfully uncover actionable causal\nrelationships in large markets, leading to profitable investment outcomes.\nHowever, the research also identifies a critical challenge: the computational\ncomplexity and scalability of these algorithms when dealing with large\ndatasets. This challenge presents practical limitations for their application\nin real-world market analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.15846v2"
    },
    {
        "title": "Advancing Financial Forecasting: A Comparative Analysis of Neural\n  Forecasting Models N-HiTS and N-BEATS",
        "authors": [
            "Mohit Apte",
            "Yashodhara Haribhakta"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In the rapidly evolving field of financial forecasting, the application of\nneural networks presents a compelling advancement over traditional statistical\nmodels. This research paper explores the effectiveness of two specific neural\nforecasting models, N-HiTS and N-BEATS, in predicting financial market trends.\nThrough a systematic comparison with conventional models, this study\ndemonstrates the superior predictive capabilities of neural approaches,\nparticularly in handling the non-linear dynamics and complex patterns inherent\nin financial time series data. The results indicate that N-HiTS and N-BEATS not\nonly enhance the accuracy of forecasts but also boost the robustness and\nadaptability of financial predictions, offering substantial advantages in\nenvironments that require real-time decision-making. The paper concludes with\ninsights into the practical implications of neural forecasting in financial\nmarkets and recommendations for future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00480v2"
    },
    {
        "title": "Attention-Based Reading, Highlighting, and Forecasting of the Limit\n  Order Book",
        "authors": [
            "Jiwon Jung",
            "Kiseop Lee"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Managing high-frequency data in a limit order book (LOB) is a complex task\nthat often exceeds the capabilities of conventional time-series forecasting\nmodels. Accurately predicting the entire multi-level LOB, beyond just the\nmid-price, is essential for understanding high-frequency market dynamics.\nHowever, this task is challenging due to the complex interdependencies among\ncompound attributes within each dimension, such as order types, features, and\nlevels. In this study, we explore advanced multidimensional\nsequence-to-sequence models to forecast the entire multi-level LOB, including\norder prices and volumes. Our main contribution is the development of a\ncompound multivariate embedding method designed to capture the complex\nrelationships between spatiotemporal features. Empirical results show that our\nmethod outperforms other multivariate forecasting methods, achieving the lowest\nforecasting error while preserving the ordinal structure of the LOB.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.02277v2"
    },
    {
        "title": "Robust financial calibration: a Bayesian approach for neural SDEs",
        "authors": [
            "Christa Cuchiero",
            "Eva Flonner",
            "Kevin Kurt"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The paper presents a Bayesian framework for the calibration of financial\nmodels using neural stochastic differential equations (neural SDEs). The method\nis based on the specification of a prior distribution on the neural network\nweights and an adequately chosen likelihood function. The resulting posterior\ndistribution can be seen as a mixture of different classical neural SDE models\nyielding robust bounds on the implied volatility surface. Both, historical\nfinancial time series data and option price data are taken into consideration,\nwhich necessitates a methodology to learn the change of measure between the\nrisk-neutral and the historical measure. The key ingredient for a robust\nnumerical optimization of the neural networks is to apply a Langevin-type\nalgorithm, commonly used in the Bayesian approaches to draw posterior samples.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06551v3"
    },
    {
        "title": "MoA is All You Need: Building LLM Research Team using Mixture of Agents",
        "authors": [
            "Sandy Chen",
            "Leqi Zeng",
            "Abhinav Raghunathan",
            "Flora Huang",
            "Terrence C. Kim"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Large Language Models (LLMs) research in the financial domain is particularly\ncomplex due to the sheer number of approaches proposed in literature.\nRetrieval-Augmented Generation (RAG) has emerged as one of the leading methods\nin the sector due to its inherent groundedness and data source variability. In\nthis work, we introduce a RAG framework called Mixture of Agents (MoA) and\ndemonstrate its viability as a practical, customizable, and highly effective\napproach for scaling RAG applications. MoA is essentially a layered network of\nindividually customized small language models (Hoffmann et al., 2022)\ncollaborating to answer questions and extract information. While there are many\ntheoretical propositions for such an architecture and even a few libraries for\ngenerally applying the structure in practice, there are limited documented\nstudies evaluating the potential of this framework considering real business\nconstraints such as cost and speed. We find that the MoA framework, consisting\nof small language models (Hoffmann et al., 2022), produces higher quality and\nmore grounded responses across various financial domains that are core to\nVanguard's business while simultaneously maintaining low costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.07487v2"
    },
    {
        "title": "Market Simulation under Adverse Selection",
        "authors": [
            "Luca Lalor",
            "Anatoliy Swishchuk"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this paper, we study the effects of fill probabilities and adverse fills\non the trading strategy simulation process. We specifically focus on a\nstochastic optimal control market-making problem and test the strategy on ES\n(E-mini S&P 500), NQ (E-mini Nasdaq 100), CL (Crude Oil) and ZN (10-Year\nTreasury Note), which are some of the most liquid futures contract listed on\nthe CME (Chicago Mercantile Exchange). We provide empirical evidence which\nshows how fill probabilities and adverse fills can significantly effect\nperformance, and propose a more prudent simulation framework for dealing with\nthis. Many previous works aim to measure different types of adverse selection\nin the limit order book, however, they often simulate price processes and\nmarket orders independently. This has the ability to largely inflate the\nperformance of a short-term style trading strategy. Our studies show that using\nmore realistic fill probabilities, and tracking adverse fills, in the strategy\nsimulation process, more accurately portrays how these types of trading\nstrategies would perform in reality.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12721v1"
    },
    {
        "title": "Deep Gamma Hedging",
        "authors": [
            "John Armstrong",
            "George Tatlow"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We train neural networks to learn optimal replication strategies for an\noption when two replicating instruments are available, namely the underlying\nand a hedging option. If the price of the hedging option matches that of the\nBlack--Scholes model then we find the network will successfully learn the\nBlack-Scholes gamma hedging strategy, even if the dynamics of the underlying do\nnot match the Black--Scholes model, so long as we choose a loss function that\nrewards coping with model uncertainty. Our results suggest that the reason\ngamma hedging is used in practice is to account for model uncertainty rather\nthan to reduce the impact of transaction costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.13567v1"
    },
    {
        "title": "Economic effects on households of an augmentation of the cash back\n  duration of real estate loan",
        "authors": [
            "Hugo Spring-Ragain"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This article examines the economic effects of an increase in the duration of\nhome loans on households, focusing on the French real estate market. It\nhighlights trends in the property market, existing loan systems in other\ncountries (such as bullet loans in Sweden and Japanese home loans), the current\nstate of the property market in France, the potential effects of an increase in\nthe amortization period of home loans, and the financial implications for\nhouseholds.The article points out that increasing the repayment period on home\nloans could reduce the amount of monthly instalments to be repaid, thereby\nfacilitating access to credit for the most modest households. However, this\nmeasure also raises concerns about overall credit costs, financial stability\nand the impact on property prices. In addition, it highlights the differences\nbetween existing lending systems in other countries, such as the bullet loan in\nSweden and Japanese home loans, and the current characteristics of home loans\nin France, notably interest rates and house price trends. The article proposes\na model of the potential effects of an increase in the amortization period of\nhome loans on housing demand, housing supply, property prices and the\nassociated financial risks.In conclusion, the article highlights the crucial\nimportance of household debt for individual and economic financial stability.\nIt highlights the distortion between supply and demand for home loans as\namortization periods increase, and the significant rise in overall loan costs\nfor households. It also underlines the need to address structural issues such\nas the sustainable reduction in interest rates, the stabilization of banks'\nequity capital and the development of a regulatory framework for\nintergenerational lending to ensure a properly functioning market.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.14748v1"
    },
    {
        "title": "ChatGPT and Corporate Policies",
        "authors": [
            "Manish Jha",
            "Jialin Qian",
            "Michael Weber",
            "Baozhong Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We create a firm-level ChatGPT investment score, based on conference calls,\nthat measures managers' anticipated changes in capital expenditures. We\nvalidate the score with interpretable textual content and its strong\ncorrelation with CFO survey responses. The investment score predicts future\ncapital expenditure for up to nine quarters, controlling for Tobin's $q$ and\nother determinants, implying the investment score provides incremental\ninformation about firms' future investment opportunities. The investment score\nalso separately forecasts future total, intangible, and R\\&D investments.\nConsistent with theoretical predictions, high-investment-score firms experience\nsignificant positive short-term returns upon disclosure, and negative long-run\nfuture abnormal returns. We demonstrate ChatGPT's applicability to measure\nother policies, such as dividends and employment.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.17933v1"
    },
    {
        "title": "American Call Options Pricing With Modular Neural Networks",
        "authors": [
            "Ananya Unnikrishnan"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  An accurate valuation of American call options is critical in most financial\ndecision making environments. However, traditional models like the Barone-Adesi\nWhaley (B-AW) and Binomial Option Pricing (BOP) methods fall short in handling\nthe complexities of early exercise and market dynamics present in American\noptions. This paper proposes a Modular Neural Network (MNN) model which aims to\ncapture the key aspects of American options pricing. By dividing the prediction\nprocess into specialized modules, the MNN effectively models the non-linear\ninteractions that drive American call options pricing. Experimental results\nindicate that the MNN model outperform both traditional models as well as a\nsimpler Feed-forward Neural Network (FNN) across multiple stocks (AAPL, NVDA,\nQQQ), with significantly lower RMSE and nRMSE (by mean). These findings\nhighlight the potential of MNNs as a powerful tool to improve the accuracy of\npredicting option prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.19706v1"
    },
    {
        "title": "Interpool: a liquidity pool designed for interoperability that mints,\n  exchanges, and burns",
        "authors": [
            "Henrique de Carvalho Videira"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The lack of proper interoperability poses a significant challenge in\nleveraging use cases within the blockchain industry. Unlike typical solutions\nthat rely on third parties such as oracles and witnesses, the interpool design\noperates as a standalone solution that mints, exchanges, and burns (MEB) within\nthe same liquidity pool. This MEB approach ensures that minting is backed by\nthe locked capital supplied by liquidity providers. During the exchange\nprocess, the order of transactions in the mempool is optimized to maximize\nreturns, effectively transforming the front-running issue into a solution that\nforges an external blockchain hash. This forged hash enables a novel protocol,\nListrack (Listen and Track), which ensures that ultimate liquidity is always\nenforced through a solid burning procedure, strengthening a trustless design.\nSupported by Listrack, atomic swaps become feasible even outside the interpool,\nthereby enhancing the current design into a comprehensive interoperability\nsolution\n",
        "pdf_link": "http://arxiv.org/pdf/2410.00011v1"
    },
    {
        "title": "Numerical analysis of American option pricing in a two-asset\n  jump-diffusion model",
        "authors": [
            "Hao Zhou",
            "Duy-Minh Dang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper addresses a significant gap in rigorous numerical treatments for\npricing American options under correlated two-asset jump-diffusion models using\nthe viscosity solution approach, with a particular focus on the Merton model.\nThe pricing of these options is governed by complex two-dimensional (2-D)\nvariational inequalities that incorporate cross-derivative terms and nonlocal\nintegro-differential terms due to the presence of jumps. Existing numerical\nmethods, primarily based on finite differences, often struggle with preserving\nmonotonicity in the approximation of cross-derivatives-a key requirement for\nensuring convergence to the viscosity solution. In addition, these methods face\nchallenges in accurately discretizing 2-D jump integrals.\n  We introduce a novel approach to effectively tackle the aforementioned\nvariational inequalities, seamlessly managing cross-derivative terms and\nnonlocal integro-differential terms through an efficient and\nstraightforward-to-implement monotone integration scheme. Within each timestep,\nour approach explicitly tackles the variational inequality constraint,\nresulting in a 2-D Partial Integro-Differential Equation (PIDE) to solve. Its\nsolution is then expressed as a 2-D convolution integral involving the Green's\nfunction of the PIDE. We derive an infinite series representation of this\nGreen's function, where each term is strictly positive and computable. This\nseries facilitates the numerical approximation of the PIDE solution through a\nmonotone integration method, such as the composite quadrature rule.\n  The proposed method is demonstrated to be both $\\ell_{\\infty} $-stable and\nconsistent in the viscosity sense, ensuring its convergence to the viscosity\nsolution of the variational inequality. Extensive numerical results validate\nthe effectiveness and robustness of our approach, highlighting its practical\napplicability and theoretical soundness.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.04745v2"
    },
    {
        "title": "Can GANs Learn the Stylized Facts of Financial Time Series?",
        "authors": [
            "Sohyeon Kwon",
            "Yongjae Lee"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In the financial sector, a sophisticated financial time series simulator is\nessential for evaluating financial products and investment strategies.\nTraditional back-testing methods have mainly relied on historical data-driven\napproaches or mathematical model-driven approaches, such as various stochastic\nprocesses. However, in the current era of AI, data-driven approaches, where\nmodels learn the intrinsic characteristics of data directly, have emerged as\npromising techniques. Generative Adversarial Networks (GANs) have surfaced as\npromising generative models, capturing data distributions through adversarial\nlearning. Financial time series, characterized 'stylized facts' such as random\nwalks, mean-reverting patterns, unexpected jumps, and time-varying volatility,\npresent significant challenges for deep neural networks to learn their\nintrinsic characteristics. This study examines the ability of GANs to learn\ndiverse and complex temporal patterns (i.e., stylized facts) of both univariate\nand multivariate financial time series. Our extensive experiments revealed that\nGANs can capture various stylized facts of financial time series, but their\nperformance varies significantly depending on the choice of generator\narchitecture. This suggests that naively applying GANs might not effectively\ncapture the intricate characteristics inherent in financial time series,\nhighlighting the importance of carefully considering and validating the\nmodeling choices.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.09850v1"
    },
    {
        "title": "European Option Pricing in Regime Switching Framework via\n  Physics-Informed Residual Learning",
        "authors": [
            "Naman Krishna Pande",
            "Puneet Pasricha",
            "Arun Kumar",
            "Arvind Kumar Gupta"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this article, we employ physics-informed residual learning (PIRL) and\npropose a pricing method for European options under a regime-switching\nframework, where closed-form solutions are not available. We demonstrate that\nthe proposed approach serves an efficient alternative to competing pricing\ntechniques for regime-switching models in the literature. Specifically, we\ndemonstrate that PIRLs eliminate the need for retraining and become nearly\ninstantaneous once trained, thus, offering an efficient and flexible tool for\npricing options across a broad range of specifications and parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.10474v1"
    },
    {
        "title": "Inferring Option Movements Through Residual Transactions: A Quantitative\n  Model",
        "authors": [
            "Carl von Havighorst",
            "Vincil Bishop III"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This research presents a novel approach to predicting option movements by\nanalyzing residual transactions, which are trades that deviate from standard\nhedging activities. Unlike traditional methods that primarily focus on open\ninterest and trading volume, this study argues that residuals can reveal\nnuanced insights into institutional sentiment and strategic positioning. By\nexamining these deviations, the model identifies early indicators of market\ntrends, providing a refined framework for forecasting option prices. The\nproposed model integrates classical machine learning and regression techniques\nto analyze patterns in high frequency trading data, capturing complex, non\nlinear relationships. This predictive framework allows traders to anticipate\nshifts in option values, enhancing strategies for better market timing, risk\nmanagement, and portfolio optimization. The model's adaptability, driven by\nreal time data processing, makes it particularly effective in fast paced\ntrading environments, where early detection of institutional behavior is\ncrucial for gaining a competitive edge. Overall, this research contributes to\nthe field of options trading by offering a strategic tool that detects early\nmarket signals, optimizing trading decisions based on predictive insights\nderived from residual trading patterns. This approach bridges the gap between\nconventional metrics and the subtle behaviors of institutional players, marking\na significant advancement in options market analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.16563v1"
    },
    {
        "title": "Modeling and Replication of the Prepayment Option of Mortgages including\n  Behavioral Uncertainty",
        "authors": [
            "Leonardo Perotti",
            "Lech A. Grzelak",
            "Cornelis W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Prepayment risk embedded in fixed-rate mortgages forms a significant fraction\nof a financial institution's exposure, and it receives particular attention\nbecause of the magnitude of the underlying market. The embedded prepayment\noption (EPO) bears the same interest rate risk as an exotic interest rate swap\n(IRS) with a suitable stochastic notional. We investigate the effect of\nrelaxing the assumption of a deterministic relationship between the market\ninterest rate incentive and the prepayment rate. A non-hedgeable risk factor is\nmodeled to capture the uncertainty in mortgage owners' behavior, leading to an\nincomplete market. We prove under natural assumptions that including behavioral\nuncertainty reduces the exposure's value. We statically replicate the exposure\nresulting from the EPO with IRSs and swaptions, and we show that a replication\nbased on swaps solely cannot easily control the right tail of the exposure\ndistribution, while including swaptions enables that. The replication framework\nis flexible and focuses on different regions in the exposure distribution.\nSince a non-hedgeable risk factor entails the existence of multiple equivalent\nmartingale measures, pricing and optimal replication are not unique. We\ninvestigate the effect of a market price of risk misspecification and we\nprovide a methodology to generate robust hedging strategies. Such strategies,\nobtained as solutions to a saddle-point problem, allow us to bound the exposure\nagainst a misspecification of the pricing measure.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21110v1"
    },
    {
        "title": "Emerging countries' counter-currency cycles in the face of crises and\n  dominant currencies",
        "authors": [
            "Hugo Spring-Ragain"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This article examines how emerging economies use countercyclical monetary\npolicies to manage economic crises and fluctuations in dominant currencies,\nsuch as the US dollar and the euro. Global economic cycles are marked by phases\nof expansion and recession, often exacerbated by major financial crises. These\ncrises, such as those of 1997, 2008 and the disruption caused by the COVID-19\npandemic, have a particular impact on emerging economies due to their\nheightened vulnerability to foreign capital flows and exports.Counter-cyclical\nmonetary policies, including interest rate adjustments, foreign exchange\ninterventions and capital controls, are essential to stabilize these economies.\nThese measures aim to mitigate the effects of economic shocks, maintain price\nstability and promote sustainable growth. This article presents a theoretical\nanalysis of economic cycles and financial crises, highlighting the role of\ndominant currencies in global economic stability. Currencies such as the dollar\nand the euro strongly influence emerging economies, notably through exchange\nrate variations and international capital movements. Analysis of the monetary\nstrategies of emerging economies, through case studies of Brazil, India and\nNigeria, reveals how these countries use tools such as interest rates, foreign\nexchange interventions and capital controls to manage the impacts of crises and\nfluctuations in dominant currencies. The article also highlights the challenges\nand limitations faced by these countries, including structural and\ninstitutional constraints and the reactions of international financial\nmarkets.Finally, an econometric analysis using a Vector AutoRegression (VAR)\nmodel illustrates the impact of monetary policies on key economic variables,\nsuch as GDP, interest rates, inflation and exchange rates. The results show\nthat emerging economies, although sensitive to external shocks, can adjust\ntheir policies to stabilize economic growth in the medium and long term.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.23002v1"
    },
    {
        "title": "Continuous Risk Factor Models: Analyzing Asset Correlations through\n  Energy Distance",
        "authors": [
            "Marcus Gawronsky",
            "Chun-Sung Huang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper introduces a novel approach to financial risk analysis that does\nnot rely on traditional price and market data, instead using market news to\nmodel assets as distributions over a metric space of risk factors. By\nrepresenting asset returns as integrals over the scalar field of these risk\nfactors, we derive the covariance structure between asset returns. Utilizing\nencoder-only language models to embed this news data, we explore the\nrelationships between asset return distributions through the concept of Energy\nDistance, establishing connections between distributional differences and\nexcess returns co-movements. This data-agnostic approach provides new insights\ninto portfolio diversification, risk management, and the construction of\nhedging strategies. Our findings have significant implications for both\ntheoretical finance and practical risk management, offering a more robust\nframework for modelling complex financial systems without depending on\nconventional market data.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.23447v1"
    },
    {
        "title": "Evaluating Company-specific Biases in Financial Sentiment Analysis using\n  Large Language Models",
        "authors": [
            "Kei Nakagawa",
            "Masanori Hirano",
            "Yugo Fujimoto"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study aims to evaluate the sentiment of financial texts using large\nlanguage models~(LLMs) and to empirically determine whether LLMs exhibit\ncompany-specific biases in sentiment analysis. Specifically, we examine the\nimpact of general knowledge about firms on the sentiment measurement of texts\nby LLMs. Firstly, we compare the sentiment scores of financial texts by LLMs\nwhen the company name is explicitly included in the prompt versus when it is\nnot. We define and quantify company-specific bias as the difference between\nthese scores. Next, we construct an economic model to theoretically evaluate\nthe impact of sentiment bias on investor behavior. This model helps us\nunderstand how biased LLM investments, when widespread, can distort stock\nprices. This implies the potential impact on stock prices if investments driven\nby biased LLMs become dominant in the future. Finally, we conduct an empirical\nanalysis using Japanese financial text data to examine the relationship between\nfirm-specific sentiment bias, corporate characteristics, and stock performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00420v1"
    },
    {
        "title": "Whack-a-mole Online Learning: Physics-Informed Neural Network for\n  Intraday Implied Volatility Surface",
        "authors": [
            "Kentaro Hoshisashi",
            "Carolyn E. Phelan",
            "Paolo Barucca"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Calibrating the time-dependent Implied Volatility Surface (IVS) using sparse\nmarket data is an essential challenge in computational finance, particularly\nfor real-time applications. This task requires not only fitting market data but\nalso satisfying a specified partial differential equation (PDE) and\nno-arbitrage conditions modelled by differential inequalities. This paper\nproposes a novel Physics-Informed Neural Networks (PINNs) approach called\nWhack-a-mole Online Learning (WamOL) to address this multi-objective\noptimisation problem. WamOL integrates self-adaptive and auto-balancing\nprocesses for each loss term, efficiently reweighting objective functions to\nensure smooth surface fitting while adhering to PDE and no-arbitrage\nconstraints and updating for intraday predictions. In our experiments, WamOL\ndemonstrates superior performance in calibrating intraday IVS from uneven and\nsparse market data, effectively capturing the dynamic evolution of option\nprices and associated risk profiles. This approach offers an efficient solution\nfor intraday IVS calibration, extending PINNs applications and providing a\nmethod for real-time financial modelling.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.02375v1"
    },
    {
        "title": "Robust and Fast Bass local volatility",
        "authors": [
            "Hao Qin",
            "Charlie Che",
            "Ruozhong Yang",
            "Liming Feng"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The Bass Local Volatility Model (Bass-LV), as studied in\n\\citep{henry2021bass}, stands out for its ability to eliminate the need for\ninterpolation between maturities. This offers a significant advantage over\ntraditional LV models. However, its performance highly depends on accurate\nconstruction of state price densities and the corresponding marginal\ndistributions and efficient numerical convolutions which are necessary when\nsolving the associated fixed point problems. In this paper, we propose a new\napproach combining local quadratic estimation and lognormal mixture tails for\nthe construction of state price densities. We investigate computational\nefficiency of trapezoidal rule based schemes for numerical convolutions and\nshow that they outperform commonly used Gauss-Hermite quadrature. We\ndemonstrate the performance of the proposed method, both in standard option\npricing models, as well as through a detailed market case study.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.04321v1"
    },
    {
        "title": "Financial News-Driven LLM Reinforcement Learning for Portfolio\n  Management",
        "authors": [
            "Ananya Unnikrishnan"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Reinforcement learning (RL) has emerged as a transformative approach for\nfinancial trading, enabling dynamic strategy optimization in complex markets.\nThis study explores the integration of sentiment analysis, derived from large\nlanguage models (LLMs), into RL frameworks to enhance trading performance.\nExperiments were conducted on single-stock trading with Apple Inc. (AAPL) and\nportfolio trading with the ING Corporate Leaders Trust Series B (LEXCX). The\nsentiment-enhanced RL models demonstrated superior net worth and cumulative\nprofit compared to RL models without sentiment and, in the portfolio\nexperiment, outperformed the actual LEXCX portfolio's buy-and-hold strategy.\nThese results highlight the potential of incorporating qualitative market\nsignals to improve decision-making, bridging the gap between quantitative and\nqualitative approaches in financial trading.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11059v1"
    },
    {
        "title": "Markov-Functional Models with Local Drift",
        "authors": [
            "ShengQuan Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We introduce a Markov-functional approach to construct local volatility\nmodels that are calibrated to a discrete set of marginal distributions. The\nmethod is inspired by and extends the volatility interpolation of Bass (1983)\nand Conze and Henry-Labord\\`ere (2022). The method is illustrated with\nefficient numerical algorithms in the cases where the constructed local\nvolatility functions are: (1) time-homogeneous between or (2) continuous\nacross, the successive maturities. The step-wise time-homogeneous construction\nproduces a parsimonious representation of the local volatility term structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.15053v1"
    },
    {
        "title": "Pretrained LLM Adapted with LoRA as a Decision Transformer for Offline\n  RL in Quantitative Trading",
        "authors": [
            "Suyeol Yun"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Developing effective quantitative trading strategies using reinforcement\nlearning (RL) is challenging due to the high risks associated with online\ninteraction with live financial markets. Consequently, offline RL, which\nleverages historical market data without additional exploration, becomes\nessential. However, existing offline RL methods often struggle to capture the\ncomplex temporal dependencies inherent in financial time series and may overfit\nto historical patterns. To address these challenges, we introduce a Decision\nTransformer (DT) initialized with pre-trained GPT-2 weights and fine-tuned\nusing Low-Rank Adaptation (LoRA). This architecture leverages the\ngeneralization capabilities of pre-trained language models and the efficiency\nof LoRA to learn effective trading policies from expert trajectories solely\nfrom historical data. Our model performs competitively with established offline\nRL algorithms, including Conservative Q-Learning (CQL), Implicit Q-Learning\n(IQL), and Behavior Cloning (BC), as well as a baseline Decision Transformer\nwith randomly initialized GPT-2 weights and LoRA. Empirical results demonstrate\nthat our approach effectively learns from expert trajectories and secures\nsuperior rewards in certain trading scenarios, highlighting the effectiveness\nof integrating pre-trained language models and parameter-efficient fine-tuning\nin offline RL for quantitative trading. Replication code for our experiments is\npublicly available at https://github.com/syyunn/finrl-dt\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17900v1"
    },
    {
        "title": "Deep learning interpretability for rough volatility",
        "authors": [
            "Bo Yuan",
            "Damiano Brigo",
            "Antoine Jacquier",
            "Nicola Pede"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Deep learning methods have become a widespread toolbox for pricing and\ncalibration of financial models. While they often provide new directions and\nresearch results, their `black box' nature also results in a lack of\ninterpretability. We provide a detailed interpretability analysis of these\nmethods in the context of rough volatility - a new class of volatility models\nfor Equity and FX markets. Our work sheds light on the neural network learned\ninverse map between the rough volatility model parameters, seen as mathematical\nmodel inputs and network outputs, and the resulting implied volatility across\nstrikes and maturities, seen as mathematical model outputs and network inputs.\nThis contributes to building a solid framework for a safer use of neural\nnetworks in this context and in quantitative finance more generally.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.19317v1"
    },
    {
        "title": "On the relative performance of some parametric and nonparametric\n  estimators of option prices",
        "authors": [
            "Carlo Marinelli",
            "Stefano D'Addona"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We examine the empirical performance of some parametric and nonparametric\nestimators of prices of options with a fixed time to maturity, focusing on\nvariance-gamma and Heston models on one side, and on expansions in Hermite\nfunctions on the other side. The latter class of estimators can be seen as\nperturbations of the classical Black-Scholes model. The comparison between\nparametric and Hermite-based models having the same \"degrees of freedom\" is\nemphasized. The main criterion is the out-of-sample relative pricing error on a\ndataset of historical option prices on the S&P500 index. Prior to the main\nempirical study, the approximation of variance-gamma and Heston densities by\nseries of Hermite functions is studied, providing explicit expressions for the\ncoefficients of the expansion in the former case, and integral expressions\ninvolving the explicit characteristic function in the latter case. Moreover,\nthese approximations are investigated numerically on a few test cases,\nindicating that expansions in Hermite functions with few terms achieve\ncompetitive accuracy in the estimation of Heston densities and the pricing of\n(European) options, but they perform less effectively with variance-gamma\ndensities. On the other hand, the main large-scale empirical study show that\nparsimonious Hermite estimators can even outperform the Heston model in terms\nof pricing errors. These results underscore the trade-offs inherent in model\nselection and calibration, and their empirical fit in practical applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.00135v1"
    },
    {
        "title": "Unsupervised learning-based calibration scheme for Rough Bergomi model",
        "authors": [
            "Changqing Teng",
            "Guanglian Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Current deep learning-based calibration schemes for rough volatility models\nare based on the supervised learning framework, which can be costly due to a\nlarge amount of training data being generated. In this work, we propose a novel\nunsupervised learning-based scheme for the rough Bergomi (rBergomi) model which\ndoes not require accessing training data. The main idea is to use the backward\nstochastic differential equation (BSDE) derived in [Bayer, Qiu and Yao, {SIAM\nJ. Financial Math.}, 2022] and simultaneously learn the BSDE solutions with the\nmodel parameters. We establish that the mean squares error between the option\nprices under the learned model parameters and the historical data is bounded by\nthe loss function. Moreover, the loss can be made arbitrarily small under\nsuitable conditions on the fitting ability of the rBergomi model to the market\nand the universal approximation capability of neural networks. Numerical\nexperiments for both simulated and historical data confirm the efficiency of\nscheme.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.02135v2"
    },
    {
        "title": "S&P 500 Trend Prediction",
        "authors": [
            "Shasha Yu",
            "Qinchen Zhang",
            "Yuwei Zhao"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This project aims to predict short-term and long-term upward trends in the\nS&P 500 index using machine learning models and feature engineering based on\nthe \"101 Formulaic Alphas\" methodology. The study employed multiple models,\nincluding Logistic Regression, Decision Trees, Random Forests, Neural Networks,\nK-Nearest Neighbors (KNN), and XGBoost, to identify market trends from\nhistorical stock data collected from Yahoo! Finance. Data preprocessing\ninvolved handling missing values, standardization, and iterative feature\nselection to ensure relevance and variability.\n  For short-term predictions, KNN emerged as the most effective model,\ndelivering robust performance with high recall for upward trends, while for\nlong-term forecasts, XGBoost demonstrated the highest accuracy and AUC scores\nafter hyperparameter tuning and class imbalance adjustments using SMOTE.\nFeature importance analysis highlighted the dominance of momentum-based and\nvolume-related indicators in driving predictions. However, models exhibited\nlimitations such as overfitting and low recall for positive market movements,\nparticularly in imbalanced datasets.\n  The study concludes that KNN is ideal for short-term alerts, whereas XGBoost\nis better suited for long-term trend forecasting. Future enhancements could\ninclude advanced architectures like Long Short-Term Memory (LSTM) networks and\nfurther feature refinement to improve precision and generalizability. These\nfindings contribute to developing reliable machine learning tools for market\ntrend prediction and investment decision-making.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.11462v1"
    },
    {
        "title": "Volatility-Volume Order Slicing via Statistical Analysis",
        "authors": [
            "Ritwika Chattopadhyay",
            "Abhishek Malichkar",
            "Zhixuan Ren",
            "Xinyue Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper addresses the challenges faced in large-volume trading, where\nexecuting substantial orders can result in significant market impact and\nslippage. To mitigate these effects, this study proposes a\nvolatility-volume-based order slicing strategy that leverages Exponential\nWeighted Moving Average and Markov Chain Monte Carlo simulations. These methods\nare used to dynamically estimate future trading volumes and price ranges,\nenabling traders to adapt their strategies by segmenting order execution sizes\nbased on these predictions. Results show that the proposed approach improves\ntrade execution efficiency, reduces market impact, and offers a more adaptive\nsolution for volatile market conditions. The findings have practical\nimplications for large-volume trading, providing a foundation for further\nresearch into adaptive execution strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12482v1"
    },
    {
        "title": "Risk forecasting using Long Short-Term Memory Mixture Density Networks",
        "authors": [
            "Nico Herrig"
        ],
        "category": "q-fin.CP",
        "published_year": "2025",
        "summary": "  This work aims to implement Long Short-Term Memory mixture density networks\n(LSTM-MDNs) for Value-at-Risk forecasting and compare their performance with\nestablished models (historical simulation, CMM, and GARCH) using a defined\nbacktesting procedure. The focus was on the neural network's ability to capture\nvolatility clustering and its real-world applicability. Three architectures\nwere tested: a 2-component mixture density network, a regularized 2-component\nmodel (Arimond et al., 2020), and a 3-component mixture model, the latter being\ntested for the first time in Value-at-Risk forecasting.\n  Backtesting was performed on three stock indices (FTSE 100, S&P 500, EURO\nSTOXX 50) over two distinct two-year periods (2017-2018 as a calm period,\n2021-2022 as turbulent). Model performance was assessed through unconditional\ncoverage and independence assumption tests. The neural network's ability to\nhandle volatility clustering was validated via correlation analysis and\ngraphical evaluation.\n  Results show limited success for the neural network approach. LSTM-MDNs\nperformed poorly for 2017/2018 but outperformed benchmark models in 2021/2022.\nThe LSTM mechanism allowed the neural network to capture volatility clustering\nsimilarly to GARCH models. However, several issues were identified: the need\nfor proper model initialization and reliance on large datasets for effective\nlearning. The findings suggest that while LSTM-MDNs provide adequate risk\nforecasts, further research and adjustments are necessary for stable\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.01278v1"
    },
    {
        "title": "Finite Element Method for HJB in Option Pricing with Stock Borrowing\n  Fees",
        "authors": [
            "Rakhymzhan Kazbek",
            "Aidana Abdukarimova"
        ],
        "category": "q-fin.CP",
        "published_year": "2025",
        "summary": "  In mathematical finance, many derivatives from markets with frictions can be\nformulated as optimal control problems in the HJB framework. Analytical optimal\ncontrol can result in highly nonlinear PDEs, which might yield unstable\nnumerical results. Accurate and convergent numerical schemes are essential to\nleverage the benefits of the hedging process. In this study, we apply a finite\nelement approach with a non-uniform mesh for the task of option pricing with\nstock borrowing fees, leading to an HJB equation that bypasses analytical\noptimal control in favor of direct PDE discretization. The time integration\nemploys the theta-scheme, with initial modifications following Rannacher`s\nprocedure. A Newton-type algorithm is applied to address the penalty-like term\nat each time step. Numerical experiments are conducted, demonstrating\nconsistency with a benchmark problem and showing a strong match. The CPU time\nneeded to reach the desired results favors P2-FEM over FDM and linear P1-FEM,\nwith P2-FEM displaying superior convergence. This paper presents an efficient\nalternative framework for the HJB problem and contributes to the literature by\nintroducing a finite element method (FEM)-based solution for HJB applications\nin mathematical finance.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02327v1"
    },
    {
        "title": "Weak and Strong Taylor methods for numerical solutions of stochastic\n  differential equations",
        "authors": [
            "Maria Siopacha",
            "Josef Teichmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2007",
        "summary": "  We apply results of Malliavin-Thalmaier-Watanabe for strong and weak Taylor\nexpansions of solutions of perturbed stochastic differential equations (SDEs).\nIn particular, we work out weight expressions for the Taylor coefficients of\nthe expansion. The results are applied to LIBOR market models in order to deal\nwith the typical stochastic drift and with stochastic volatility. In contrast\nto other accurate methods like numerical schemes for the full SDE, we obtain\neasily tractable expressions for accurate pricing. In particular, we present an\neasily tractable alternative to ``freezing the drift'' in LIBOR market models,\nwhich has an accuracy similar to the full numerical scheme. Numerical examples\nunderline the results.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.0745v1"
    },
    {
        "title": "Exact retrospective Monte Carlo computation of arithmetic average Asian\n  options",
        "authors": [
            "Benjamin Jourdain",
            "Mohamed Sbai"
        ],
        "category": "q-fin.CP",
        "published_year": "2007",
        "summary": "  Taking advantage of the recent litterature on exact simulation algorithms\n(Beskos, Papaspiliopoulos and Roberts) and unbiased estimation of the\nexpectation of certain fonctional integrals (Wagner, Beskos et al. and\nFearnhead et al.), we apply an exact simulation based technique for pricing\ncontinuous arithmetic average Asian options in the Black and Scholes framework.\nUnlike existing Monte Carlo methods, we are no longer prone to the\ndiscretization bias resulting from the approximation of continuous time\nprocesses through discrete sampling. Numerical results of simulation studies\nare presented and variance reduction problems are considered.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.1433v3"
    },
    {
        "title": "An iterative algorithm for evaluating approximations to the optimal\n  exercise boundary for a nonlinear Black-Scholes equation",
        "authors": [
            "Daniel Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2007",
        "summary": "  The purpose of this paper is to analyze and compute the early exercise\nboundary for a class of nonlinear Black--Scholes equations with a nonlinear\nvolatility which can be a function of the second derivative of the option price\nitself. A motivation for studying the nonlinear Black--Scholes equation with a\nnonlinear volatility arises from option pricing models taking into account e.g.\nnontrivial transaction costs, investor's preferences, feedback and illiquid\nmarkets effects and risk from a volatile (unprotected) portfolio. We present a\nnew method how to transform the free boundary problem for the early exercise\nboundary position into a solution of a time depending nonlinear parabolic\nequation defined on a fixed domain. We furthermore propose an iterative\nnumerical scheme that can be used to find an approximation of the free\nboundary. We present results of numerical approximation of the early exercise\nboundary for various types of nonlinear Black--Scholes equations and we discuss\ndependence of the free boundary on various model parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.5301v1"
    },
    {
        "title": "An Hilbert space approach for a class of arbitrage free implied\n  volatilities models",
        "authors": [
            "A. Brace",
            "G. Fabbri",
            "B. Goldys"
        ],
        "category": "q-fin.CP",
        "published_year": "2007",
        "summary": "  We present an Hilbert space formulation for a set of implied volatility\nmodels introduced in \\cite{BraceGoldys01} in which the authors studied\nconditions for a family of European call options, varying the maturing time and\nthe strike price $T$ an $K$, to be arbitrage free. The arbitrage free\nconditions give a system of stochastic PDEs for the evolution of the implied\nvolatility surface ${\\hat\\sigma}_t(T,K)$. We will focus on the family obtained\nfixing a strike $K$ and varying $T$. In order to give conditions to prove an\nexistence-and-uniqueness result for the solution of the system it is here\nexpressed in terms of the square root of the forward implied volatility and\nrewritten in an Hilbert space setting. The existence and the uniqueness for the\n(arbitrage free) evolution of the forward implied volatility, and then of the\nthe implied volatility, among a class of models, are proved. Specific examples\nare also given.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.1343v2"
    },
    {
        "title": "Explicit Computations for a Filtering Problem with Point Process\n  Observations with Applications to Credit Risk",
        "authors": [
            "Vincent Leijdekker",
            "Peter Spreij"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  We consider the intensity-based approach for the modeling of default times of\none or more companies. In this approach the default times are defined as the\njump times of a Cox process, which is a Poisson process conditional on the\nrealization of its intensity. We assume that the intensity follows the\nCox-Ingersoll-Ross model. This model allows one to calculate survival\nprobabilities and prices of defaultable bonds explicitly. In this paper we\nassume that the Brownian motion, that drives the intensity, is not observed.\nUsing filtering theory for point process observations, we are able to derive\ndynamics for the intensity and its moment generating function, given the\nobservations of the Cox process. A transformation of the dynamics of the\nconditional moment generating function allows us to solve the filtering\nproblem, between the jumps of the Cox process, as well as at the jumps.\nAssuming that the initial distribution of the intensity is of the Gamma type,\nwe obtain an explicit solution to the filtering problem for all t>0. We\nconclude the paper with the observation that the resulting conditional moment\ngenerating function at time t corresponds to a mixture of Gamma distributions.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.1407v1"
    },
    {
        "title": "From Black-Scholes and Dupire formulae to last passage times of local\n  martingales. Part A : The infinite time horizon",
        "authors": [
            "Amel Bentata",
            "Marc Yor"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  These notes are the first half of the contents of the course given by the\nsecond author at the Bachelier Seminar (February 8-15-22 2008) at IHP. They\nalso correspond to topics studied by the first author for her Ph.D.thesis.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.0239v1"
    },
    {
        "title": "Geometric extension of put-call symmetry in the multiasset setting",
        "authors": [
            "Ilya Molchanov",
            "Michael Schmutz"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In this paper we show how to relate European call and put options on multiple\nassets to certain convex bodies called lift zonoids. Based on this, geometric\nproperties can be translated into economic statements and vice versa. For\ninstance, the European call-put parity corresponds to the central symmetry\nproperty, while the concept of dual markets can be explained by reflection with\nrespect to a plane. It is known that the classical univariate log-normal model\nbelongs to a large class of distributions with an extra property, analytically\nknown as put-call symmetry. The geometric interpretation of this symmetry\nproperty motivates a natural multivariate extension. The financial meaning of\nthis extension is explained, the asset price distributions that have this\nproperty are characterised and their further properties explored. It is also\nshown how to relate some multivariate asymmetric distributions to symmetric\nones by a power transformation that is useful to adjust for carrying costs. A\nparticular attention is devoted to the case of asset prices driven by L\\'evy\nprocesses. Based on this, semi-static hedging techniques for multiasset barrier\noptions are suggested.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.4506v2"
    },
    {
        "title": "On honest times in financial modeling",
        "authors": [
            "Ashkan Nikeghbali",
            "Eckhard Platen"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  This paper demonstrates the usefulness and importance of the concept of\nhonest times to financial modeling. It studies a financial market with asset\nprices that follow jump-diffusions with negative jumps. The central building\nblock of the market model is its growth optimal portfolio (GOP), which\nmaximizes the growth rate of strictly positive portfolios. Primary security\naccount prices, when expressed in units of the GOP, turn out to be nonnegative\nlocal martingales. In the proposed framework an equivalent risk neutral\nprobability measure need not exist. Derivative prices are obtained as\nconditional expectations of corresponding future payoffs, with the GOP as\nnumeraire and the real world probability as pricing measure. The time when the\nglobal maximum of a portfolio with no positive jumps, when expressed in units\nof the GOP, is reached, is shown to be a generic representation of an honest\ntime. We provide a general formula for the law of such honest times and compute\nthe conditional distributions of the global maximum of a portfolio in this\nframework. Moreover, we provide a stochastic integral representation for\nuniformly integrable martingales whose terminal values are functions of the\nglobal maximum of a portfolio. These formulae are model independent and\nuniversal. We also specialize our results to some examples where we hedge a\npayoff that arrives at an honest time.\n",
        "pdf_link": "http://arxiv.org/pdf/0808.2892v1"
    },
    {
        "title": "On incompleteness of bond markets with infinite number of random factors",
        "authors": [
            "Michał Barski",
            "Jacek Jakubowski",
            "Jerzy Zabczyk"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  The completeness of a bond market model with infinite number of sources of\nrandomness on a finite time interval in the Heath-Jarrow-Morton framework is\nstudied. It is proved that the market is not complete. A construction of a\nbounded contingent claim, which can not be replicated, is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.2270v2"
    },
    {
        "title": "Comparisons for backward stochastic differential equations on Markov\n  chains and related no-arbitrage conditions",
        "authors": [
            "Samuel N. Cohen",
            "Robert J. Elliott"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  Most previous contributions to BSDEs, and the related theories of nonlinear\nexpectation and dynamic risk measures, have been in the framework of continuous\ntime diffusions or jump diffusions. Using solutions of BSDEs on spaces related\nto finite state, continuous time Markov chains, we develop a theory of\nnonlinear expectations in the spirit of [Dynamically consistent nonlinear\nevaluations and expectations (2005) Shandong Univ.]. We prove basic properties\nof these expectations and show their applications to dynamic risk measures on\nsuch spaces. In particular, we prove comparison theorems for scalar and vector\nvalued solutions to BSDEs, and discuss arbitrage and risk measures in the\nscalar case.\n",
        "pdf_link": "http://arxiv.org/pdf/0810.0055v2"
    },
    {
        "title": "On the singular limit of solutions to the CIR interest rate model with\n  stochastic volatility",
        "authors": [
            "B. Stehlikova",
            "D. Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In this paper we are interested in term structure models for pricing zero\ncoupon bonds under rapidly oscillating stochastic volatility. We analyze\nsolutions to the generalized Cox-Ingersoll-Ross two factors model describing\nclustering of interest rate volatilities. The main goal is to derive an\nasymptotic expansion of the bond price with respect to a singular parameter\nrepresenting the fast scale for the stochastic volatility process. We derive\nthe second order asymptotic expansion of a solution to the two factors\ngeneralized CIR model and we show that the first two terms in the expansion are\nindependent of the variable representing stochastic volatility.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0591v1"
    },
    {
        "title": "Viscosity Solutions and American Option Pricing in a Stochastic\n  Volatility Model of the Ornstein-Uhlenbeck Type",
        "authors": [
            "Alexandre F. Roch"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In this paper, we study the valuation of American type derivatives in the\nstochastic volatility model of Barndorff-Nielsen and Shephard (2001). We\ncharacterize the value of such derivatives as the unique viscosity solution of\nan integral-partial differential equation when the payoff function satisfies a\nLipschitz condition.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.2444v1"
    },
    {
        "title": "A Finite Element Framework for Option Pricing with the Bates Model",
        "authors": [
            "Edie Miglio",
            "Carlo Sgarra"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In the present paper we present a finite element approach for option pricing\nin the framework of a well-known stochastic volatility model with jumps, the\nBates model. In this model the asset log-returns are assumed to follow a\njump-diffusion model where the jump component consists of a Levy process of\ncompound Poisson type, while the volatility behavior is described by a\nstochastic differential equation of CIR type, with a mean-reverting drift term\nand a diffusion component correlated with that of the log-returns. Like in all\nthe Levy models, the option pricing problem can be formulated in terms of an\nintegro-differential equation: for the Bates model the unknown F(S, V, t) (the\noption price) of the pricing equation depends on three independent variables\nand the differential operator part turns out to be of parabolic kind, while the\nnonlocal integral operator is calculated with respect to the Levy measure of\nthe jumps. In this paper we will present a variational formulation of the\nproblem suitable for a finite element approach. The numerical results obtained\nfor european options will be compared with those obtained with different\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.3083v1"
    },
    {
        "title": "The general mixture-diffusion SDE and its relationship with an\n  uncertain-volatility option model with volatility-asset decorrelation",
        "authors": [
            "Damiano Brigo"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In the present paper, given an evolving mixture of probability densities, we\ndefine a candidate diffusion process whose marginal law follows the same\nevolution. We derive as a particular case a stochastic differential equation\n(SDE) admitting a unique strong solution and whose density evolves as a mixture\nof Gaussian densities. We present an interesting result on the comparison\nbetween the instantaneous and the terminal correlation between the obtained\nprocess and its squared diffusion coefficient. As an application to\nmathematical finance, we construct diffusion processes whose marginal densities\nare mixtures of lognormal densities. We explain how such processes can be used\nto model the market smile phenomenon. We show that the lognormal mixture\ndynamics is the one-dimensional diffusion version of a suitable uncertain\nvolatility model, and suitably reinterpret the earlier correlation result. We\nexplore numerically the relationship between the future smile structures of\nboth the diffusion and the uncertain volatility versions.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.4052v1"
    },
    {
        "title": "Arbitrage-free Pricing of Credit Index Options: The no-armageddon\n  pricing measure and the role of correlation after the subprime crisis",
        "authors": [
            "Massimo Morini",
            "Damiano Brigo"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In this work we consider three problems of the standard market approach to\npricing of credit index options: the definition of the index spread is not\nvalid in general, the usually considered payoff leads to a pricing which is not\nalways defined, and the candidate numeraire one would use to define a pricing\nmeasure is not strictly positive, which would lead to a non-equivalent pricing\nmeasure.\n  We give a general mathematical solution to the three problems, based on a\nnovel way of modeling the flow of information through the definition of a new\nsubfiltration. Using this subfiltration, we take into account consistently the\npossibility of default of all names in the portfolio, that is neglected in the\nstandard market approach. We show that, while the related mispricing can be\nnegligible for standard options in normal market conditions, it can become\nhighly relevant for different options or in stressed market conditions.\n  In particular, we show on 2007 market data that after the subprime credit\ncrisis the mispricing of the market formula compared to the no arbitrage\nformula we propose has become financially relevant even for the liquid\nCrossover Index Options.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.4156v1"
    },
    {
        "title": "Efficient Pricing of CPPI using Markov Operators",
        "authors": [
            "Louis Paulot",
            "Xavier Lacroze"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  Constant Proportion Portfolio Insurance (CPPI) is a strategy designed to give\nparticipation in a risky asset while protecting the invested capital. Some gap\nrisk due to extreme events is often kept by the issuer of the product: a put\noption on the CPPI strategy is included in the product. In this paper we\npresent a new method for the pricing of CPPIs and options on CPPIs, which is\nmuch faster and more accurate than the usual Monte-Carlo method. Provided the\nunderlying follows a homogeneous process, the path-dependent CPPI strategy is\nreformulated into a Markov process in one variable, which allows to use\nefficient linear algebra techniques. Tail events, which are crucial in the\npricing are handled smoothly. We incorporate in this framework linear\nthresholds, profit lock-in, performance coupons... The American exercise of\nopen-ended CPPIs is handled naturally through backward propagation. Finally we\nuse our pricing scheme to study the influence of various features on the gap\nrisk of CPPI strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.1218v1"
    },
    {
        "title": "A Fourier transform method for spread option pricing",
        "authors": [
            "T. R. Hurd",
            "Zhuowei Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  Spread options are a fundamental class of derivative contract written on\nmultiple assets, and are widely used in a range of financial markets. There is\na long history of approximation methods for computing such products, but as yet\nthere is no preferred approach that is accurate, efficient and flexible enough\nto apply in general models. The present paper introduces a new formula for\ngeneral spread option pricing based on Fourier analysis of the spread option\npayoff function. Our detailed investigation proves the effectiveness of a fast\nFourier transform implementation of this formula for the computation of prices.\nIt is found to be easy to implement, stable, efficient and applicable in a wide\nvariety of asset pricing models.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.3643v1"
    },
    {
        "title": "T-Systems and the lower Snell envelope",
        "authors": [
            "Erick Trevino Aguilar"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  The dynamical analysis of American options has motivated the development of\nrobust versions of the classical Snell envelopes. The cost of superhedging an\nAmerican option is characterized by the upper Snell envelope. The infimum of\nthe arbitrage free prices is characterized by the lower Snell envelope. In this\npaper we focus on the lower Snell envelope. We construct a regular version of\nthis stochastic process. To this end, we apply results due to Dellacherie and\nLenglart on regularization of stochastic processes and T -Systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.4245v1"
    },
    {
        "title": "Monte Carlo sampling given a Characteristic Function: Quantile Mechanics\n  in Momentum Space",
        "authors": [
            "William T. Shaw",
            "Jonathan McCabe"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  In mathematical finance and other applications of stochastic processes, it is\nfrequently the case that the characteristic function may be known but explicit\nforms for density functions are not available. The simulation of any\ndistribution is greatly facilitated by a knowledge of the quantile function, by\nwhich uniformly distributed samples may be converted to samples of the given\ndistribution. This article analyzes the calculation of a quantile function\ndirect from the characteristic function of a probability distribution, without\nexplicit knowledge of the density. We form a non-linear integro-differential\nequation that despite its complexity admits an iterative solution for the power\nseries of the quantile about the median. We give some examples including tail\nmodels and show how to generate C-code for examples.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.1592v1"
    },
    {
        "title": "Computing Tails of Compound Distributions Using Direct Numerical\n  Integration",
        "authors": [
            "Xiaolin Luo",
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  An efficient adaptive direct numerical integration (DNI) algorithm is\ndeveloped for computing high quantiles and conditional Value at Risk (CVaR) of\ncompound distributions using characteristic functions. A key innovation of the\nnumerical scheme is an effective tail integration approximation that reduces\nthe truncation errors significantly with little extra effort. High precision\nresults of the 0.999 quantile and CVaR were obtained for compound losses with\nheavy tails and a very wide range of loss frequencies using the DNI, Fast\nFourier Transform (FFT) and Monte Carlo (MC) methods. These results,\nparticularly relevant to operational risk modelling, can serve as benchmarks\nfor comparing different numerical methods. We found that the adaptive DNI can\nachieve high accuracy with relatively coarse grids. It is much faster than MC\nand competitive with FFT in computing high quantiles and CVaR of compound\ndistributions in the case of moderate to high frequencies and heavy tails.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.0830v3"
    },
    {
        "title": "Addressing the bias in Monte Carlo pricing of multi-asset options with\n  multiple barriers through discrete sampling",
        "authors": [
            "P. V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  An efficient conditioning technique, the so-called Brownian Bridge\nsimulation, has previously been applied to eliminate pricing bias that arises\nin applications of the standard discrete-time Monte Carlo method to evaluate\noptions written on the continuous-time extrema of an underlying asset. It is\nbased on the simple and easy to implement analytic formulas for the\ndistribution of one-dimensional Brownian Bridge extremes. This paper extends\nthe technique to the valuation of multi-asset options with knock-out barriers\nimposed for all or some of the underlying assets. We derive formula for the\nunbiased option price estimator based on the joint distribution of the\nmulti-dimensional Brownian Bridge dependent extrema. As analytic formulas are\nnot available for the joint distribution in general, we develop upper and lower\nbiased option price estimators based on the distribution of independent extrema\nand the Fr\\'echet lower and upper bounds for the unknown distribution. All\nestimators are simple and easy to implement. They can always be used to bind\nthe true value by a confidence interval. Numerical tests indicate that our\nbiased estimators converge rapidly to the true option value as the number of\ntime steps for the asset path simulation increases in comparison to the\nestimator based on the standard discrete-time method. The convergence rate\ndepends on the correlation and barrier structures of the underlying assets.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.1157v1"
    },
    {
        "title": "Shaping tail dependencies by nesting box copulas",
        "authors": [
            "Christoph Hummel"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We introduce a family of copulas which are locally piecewise uniform in the\ninterior of the unit cube of any given dimension. Within that family, the\nsimultaneous control of tail dependencies of all projections to faces of the\ncube is possible and we give an efficient sampling algorithm. The combination\nof these two properties may be appealing to risk modellers.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.4853v2"
    },
    {
        "title": "Double Kernel estimation of sensitivities",
        "authors": [
            "Romuald Elie"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  This paper adresses the general issue of estimating the sensitivity of the\nexpectation of a random variable with respect to a parameter characterizing its\nevolution. In finance for example, the sensitivities of the price of a\ncontingent claim are called the Greeks. A new way of estimating the Greeks has\nbeen recently introduced by Elie, Fermanian and Touzi through a randomization\nof the parameter of interest combined with non parametric estimation\ntechniques. This paper studies another type of those estimators whose interest\nis to be closely related to the score function, which is well known to be the\noptimal Greek weight. This estimator relies on the use of two distinct kernel\nfunctions and the main interest of this paper is to provide its asymptotic\nproperties. Under a little more stringent condition, its rate of convergence\nequals the one of those introduced by Elie, Fermanian and Touzi and outperforms\nthe finite differences estimator. In addition to the technical interest of the\nproofs, this result is very encouraging in the dynamic of creating new type of\nestimators for sensitivities.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.2624v1"
    },
    {
        "title": "Study of the risk-adjusted pricing methodology model with methods of\n  Geometrical Analysis",
        "authors": [
            "Ljudmila A. Bordag"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  Families of exact solutions are found to a nonlinear modification of the\nBlack-Scholes equation. This risk-adjusted pricing methodology model (RAPM)\nincorporates both transaction costs and the risk from a volatile portfolio.\nUsing the Lie group analysis we obtain the Lie algebra admitted by the RAPM\nequation. It gives us the possibility to describe an optimal system of\nsubalgebras and correspondingly the set of invariant solutions to the model. In\nthis way we can describe the complete set of possible reductions of the\nnonlinear RAPM model. Reductions are given in the form of different second\norder ordinary differential equations. In all cases we provide solutions to\nthese equations in an exact or parametric form. We discuss the properties of\nthese reductions and the corresponding invariant solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0113v2"
    },
    {
        "title": "A framework for adaptive Monte-Carlo procedures",
        "authors": [
            "Bernard Lapeyre",
            "Jérôme Lelong"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Adaptive Monte Carlo methods are recent variance reduction techniques. In\nthis work, we propose a mathematical setting which greatly relaxes the\nassumptions needed by for the adaptive importance sampling techniques presented\nby Vazquez-Abad and Dufresne, Fu and Su, and Arouna. We establish the\nconvergence and asymptotic normality of the adaptive Monte Carlo estimator\nunder local assumptions which are easily verifiable in practice. We present one\nway of approximating the optimal importance sampling parameter using a randomly\ntruncated stochastic algorithm. Finally, we apply this technique to some\nexamples of valuation of financial derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.3551v2"
    },
    {
        "title": "Comparison of numerical and analytical approximations of the early\n  exercise boundary of the American put option",
        "authors": [
            "Martin Lauko",
            "Daniel Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In this paper we present qualitative and quantitative comparison of various\nanalytical and numerical approximation methods for calculating a position of\nthe early exercise boundary of the American put option paying zero dividends.\nFirst we analyze their asymptotic behavior close to expiration. In the second\npart of the paper, we introduce a new numerical scheme for computing the entire\nearly exercise boundary. The local iterative numerical scheme is based on a\nsolution to a nonlinear integral equation. We compare numerical results\nobtained by the new method to those of the projected successive over relaxation\nmethod and the analytical approximation formula recently derived by Zhu.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0979v2"
    },
    {
        "title": "Using pseudo-parabolic and fractional equations for option pricing in\n  jump diffusion models",
        "authors": [
            "Andrey Itkin",
            "Peter Carr"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In mathematical finance a popular approach for pricing options under some\nLevy model is to consider underlying that follows a Poisson jump diffusion\nprocess. As it is well known this results in a partial integro-differential\nequation (PIDE) that usually does not allow an analytical solution while\nnumerical solution brings some problems. In this paper we elaborate a new\napproach on how to transform the PIDE to some class of so-called\npseudo-parabolic equations which are known in mathematics but are relatively\nnew for mathematical finance. As an example we discuss several jump-diffusion\nmodels which Levy measure allows such a transformation.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.1995v1"
    },
    {
        "title": "Asymptotic analysis for stochastic volatility: Edgeworth expansion",
        "authors": [
            "Masaaki Fukasawa"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The validity of an approximation formula for European option prices under a\ngeneral stochastic volatility model is proved in the light of the Edgeworth\nexpansion for ergodic diffusions. The asymptotic expansion is around the\nBlack-Scholes price and is uniform in bounded payoff func- tions. The result\nprovides a validation of an existing singular perturbation expansion formula\nfor the fast mean reverting stochastic volatility model.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2106v1"
    },
    {
        "title": "Results on numerics for FBSDE with drivers of quadratic growth",
        "authors": [
            "Peter Imkeller",
            "Gonçalo dos Reis",
            "Jianing Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We consider the problem of numerical approximation for forward-backward\nstochastic differential equations with drivers of quadratic growth (qgFBSDE).\nTo illustrate the significance of qgFBSDE, we discuss a problem of cross\nhedging of an insurance related financial derivative using correlated assets.\nFor the convergence of numerical approximation schemes for such systems of\nstochastic equations, path regularity of the solution processes is\ninstrumental. We present a method based on the truncation of the driver, and\nexplicitly exhibit error estimates as functions of the truncation height. We\ndiscuss a reduction method to FBSDE with globally Lipschitz continuous drivers,\nby using the Cole-Hopf exponential transformation. We finally illustrate our\nnumerical approximation methods by giving simulations for prices and optimal\nhedges of simple insurance derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2248v1"
    },
    {
        "title": "Convenient Multiple Directions of Stratification",
        "authors": [
            "Benjamin Jourdain",
            "Bernard Lapeyre",
            "Piergiacomo Sabino"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  This paper investigates the use of multiple directions of stratification as a\nvariance reduction technique for Monte Carlo simulations of path-dependent\noptions driven by Gaussian vectors. The precision of the method depends on the\nchoice of the directions of stratification and the allocation rule within each\nstrata. Several choices have been proposed but, even if they provide variance\nreduction, their implementation is computationally intensive and not applicable\nto realistic payoffs, in particular not to Asian options with barrier.\nMoreover, all these previously published methods employ orthogonal directions\nfor multiple stratification. In this work we investigate the use of algorithms\nproducing convenient directions, generally non-orthogonal, combining a lower\ncomputational cost with a comparable variance reduction. In addition, we study\nthe accuracy of optimal allocation in terms of variance reduction compared to\nthe Latin Hypercube Sampling. We consider the directions obtained by the Linear\nTransformation and the Principal Component Analysis. We introduce a new\nprocedure based on the Linear Approximation of the explained variance of the\npayoff using the law of total variance. In addition, we exhibit a novel\nalgorithm that permits to correctly generate normal vectors stratified along\nnon-orthogonal directions. Finally, we illustrate the efficiency of these\nalgorithms in the computation of the price of different path-dependent options\nwith and without barriers in the Black-Scholes and in the Cox-Ingersoll-Ross\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.5037v1"
    },
    {
        "title": "Stochastic Utilities With a Given Optimal Portfolio : Approach by\n  Stochastic Flows",
        "authors": [
            "N. El Karoui",
            "Mohamed M'Rad"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The paper generalizes the construction by stochastic flows of consistent\nutility processes introduced by M. Mrad and N. El Karoui in (2010). The\nutilities random fields are defined from a general class of processes denoted\nby $\\GX$. Making minimal assumptions and convex constraints on test-processes,\nwe construct by composing two stochastic flows of homeomorphisms, all the\nconsistent stochastic utilities whose the optimal-benchmark process is given,\nstrictly increasing in its initial condition. Proofs are essentially based on\nstochastic change of variables techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.5192v2"
    },
    {
        "title": "Certifiably Pseudorandom Financial Derivatives",
        "authors": [
            "David Zuckerman"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Arora, Barak, Brunnermeier, and Ge showed that taking computational\ncomplexity into account, a dishonest seller could strategically place lemons in\nfinancial derivatives to make them substantially less valuable to buyers. We\nshow that if the seller is required to construct derivatives of a certain form,\nthen this phenomenon disappears. In particular, we define and construct\npseudorandom derivative families, for which lemon placement only slightly\naffects the values of the derivatives. Our constructions use expander graphs.\nWe study our derivatives in a more general setting than Arora et al. In\nparticular, we analyze arbitrary tranches of the common collateralized debt\nobligations (CDOs) when the underlying assets can have significant\ndependencies.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0469v9"
    },
    {
        "title": "Numerical methods for an optimal order execution problem",
        "authors": [
            "Fabien Guilbaud",
            "Mohamed Mnif",
            "Huyên Pham"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  This paper deals with numerical solutions to an impulse control problem\narising from optimal portfolio liquidation with bid-ask spread and market price\nimpact penalizing speedy execution trades. The corresponding dynamic\nprogramming (DP) equation is a quasi-variational inequality (QVI) with solvency\nconstraint satisfied by the value function in the sense of constrained\nviscosity solutions. By taking advantage of the lag variable tracking the time\ninterval between trades, we can provide an explicit backward numerical scheme\nfor the time discretization of the DPQVI. The convergence of this discrete-time\nscheme is shown by viscosity solutions arguments. An optimal quantization\nmethod is used for computing the (conditional) expectations arising in this\nscheme. Numerical results are presented by examining the behaviour of optimal\nliquidation strategies, and comparative performance analysis with respect to\nsome benchmark execution strategies. We also illustrate our optimal liquidation\nalgorithm on real data, and observe various interesting patterns of order\nexecution strategies. Finally, we provide some numerical tests of sensitivity\nwith respect to the bid/ask spread and market impact parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0768v1"
    },
    {
        "title": "Absolute ruin in the Ornstein-Uhlenbeck type risk model",
        "authors": [
            "Ronnie L. Loeffen",
            "Pierre Patie"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We start by showing that the finite-time absolute ruin probability in the\nclassical risk model with constant interest force can be expressed in terms of\nthe transition probability of a positive Ornstein-Uhlenbeck type process, say\nX. Our methodology applies to the case when the dynamics of the aggregate\nclaims process is a subordinator. From this expression, we easily deduce\nnecessary and sufficient conditions for the infinite-time absolute ruin to\noccur. We proceed by showing that, under some technical conditions, the\ntransition density of X admits a spectral type representation involving merely\nthe limiting distribution of the process. As a by-product, we obtain a series\nexpansions for the finite-time absolute ruin probability. On the way, we also\nderive, for the aforementioned risk process, the Laplace transform of the\nfirst-exit time from an interval from above. Finally, we illustrate our results\nby detailing some examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.2712v1"
    },
    {
        "title": "Numerical methods for the Lévy LIBOR model",
        "authors": [
            "Antonis Papapantoleon",
            "David Skovmand"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The aim of this work is to provide fast and accurate approximation schemes\nfor the Monte-Carlo pricing of derivatives in the L\\'evy LIBOR model of\nEberlein and \\\"Ozkan (2005). Standard methods can be applied to solve the\nstochastic differential equations of the successive LIBOR rates but the methods\nare generally slow. We propose an alternative approximation scheme based on\nPicard iterations. Our approach is similar in accuracy to the full numerical\nsolution, but with the feature that each rate is, unlike the standard method,\nevolved independently of the other rates in the term structure. This enables\nsimultaneous calculation of derivative prices of different maturities using\nparallel computing. We include numerical illustrations of the accuracy and\nspeed of our method pricing caplets.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.3340v1"
    },
    {
        "title": "Convex duality in stochastic programming and mathematical finance",
        "authors": [
            "Teemu Pennanen"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  This paper proposes a general duality framework for the problem of minimizing\na convex integral functional over a space of stochastic processes adapted to a\ngiven filtration. The framework unifies many well-known duality frameworks from\noperations research and mathematical finance. The unification allows the\nextension of some useful techniques from these two fields to a much wider class\nof problems. In particular, combining certain finite-dimensional techniques\nfrom convex analysis with measure theoretic techniques from mathematical\nfinance, we are able to close the duality gap in some situations where\ntraditional topological arguments fail.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4083v1"
    },
    {
        "title": "A Penalty Method for the Numerical Solution of Hamilton-Jacobi-Bellman\n  (HJB) Equations in Finance",
        "authors": [
            "Jan Hendrik Witte",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We present a simple and easy to implement method for the numerical solution\nof a rather general class of Hamilton-Jacobi-Bellman (HJB) equations. In many\ncases, the considered problems have only a viscosity solution, to which,\nfortunately, many intuitive (e.g. finite difference based) discretisations can\nbe shown to converge. However, especially when using fully implicit time\nstepping schemes with their desirable stability properties, one is still faced\nwith the considerable task of solving the resulting nonlinear discrete system.\nIn this paper, we introduce a penalty method which approximates the nonlinear\ndiscrete system to first order in the penalty parameter, and we show that an\niterative scheme can be used to solve the penalised discrete problem in\nfinitely many steps. We include a number of examples from mathematical finance\nfor which the described approach yields a rigorous numerical scheme and present\nnumerical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.0401v2"
    },
    {
        "title": "The Effect of Non-Smooth Payoffs on the Penalty Approximation of\n  American Options",
        "authors": [
            "Sam Howison",
            "Christoph Reisinger",
            "Jan Hendrik Witte"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  This article combines various methods of analysis to draw a comprehensive\npicture of penalty approximations to the value, hedge ratio, and optimal\nexercise strategy of American options. While convergence of the penalised\nsolution for sufficiently smooth obstacles is well established in the\nliterature, sharp rates of convergence and particularly the effect of gradient\ndiscontinuities (i.e., the omni-present `kinks' in option payoffs) on this rate\nhave not been fully analysed so far. This effect becomes important not least\nwhen using penalisation as a numerical technique. We use matched asymptotic\nexpansions to characterise the boundary layers between exercise and hold\nregions, and to compute first order corrections for representative payoffs on a\nsingle asset following a diffusion or jump-diffusion model. Furthermore, we\ndemonstrate how the viscosity theory framework in [Jakobsen, 2006] can be\napplied to this setting to derive upper and lower bounds on the value. In a\nsmall extension to [Bensoussan & Lions, 1982], we derive weak convergence rates\nalso for option sensitivities for convex payoffs under jump-diffusion models.\nFinally, we outline applications of the results, including accuracy\nimprovements by extrapolation.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.0836v3"
    },
    {
        "title": "Semi-Closed Form Cubature and Applications to Financial Diffusion Models",
        "authors": [
            "Christian Bayer",
            "Peter Friz",
            "Ronnie Loeffen"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Cubature methods, a powerful alternative to Monte Carlo due to\nKusuoka~[Adv.~Math.~Econ.~6, 69--83, 2004] and\nLyons--Victoir~[Proc.~R.~Soc.\\\\Lond.~Ser.~A 460, 169--198, 2004], involve the\nsolution to numerous auxiliary ordinary differential equations. With focus on\nthe Ninomiya-Victoir algorithm~[Appl.~Math.~Fin.~15, 107--121, 2008], which\ncorresponds to a concrete level $5$ cubature method, we study some parametric\ndiffusion models motivated from financial applications, and exhibit structural\nconditions under which all involved ODEs can be solved explicitly and\nefficiently. We then enlarge the class of models for which this technique\napplies, by introducing a (model-dependent) variation of the Ninomiya-Victoir\nmethod. Our method remains easy to implement; numerical examples illustrate the\nsavings in computation time.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.4818v1"
    },
    {
        "title": "Error bounds for small jumps of Lévy processes",
        "authors": [
            "El Hadj Aly Dia"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The pricing of options in exponential Levy models amounts to the computation\nof expectations of functionals of Levy processes. In many situations,\nMonte-Carlo methods are used. However, the simulation of a Levy process with\ninfinite Levy measure generally requires either to truncate small jumps or to\nreplace them by a Brownian motion with the same variance. We will derive bounds\nfor the errors generated by these two types of approximation.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.4886v5"
    },
    {
        "title": "Density quantization method in the optimal portfolio choice with partial\n  observation of stochastic volatility",
        "authors": [
            "Grzegorz Hałaj"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Computational aspects of the optimal consumption and investment with the\npartially observed stochastic volatility of the asset prices are considered.\nThe new quantization approach to filtering - density quantization - is\nintroduced which reduces the original infinite dimensional state space of the\nproblem to the finite quantization set. The density quantization is embedded\ninto the numerical algorithm to solve the dynamic programming equation related\nto the portfolio optimization.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.5806v1"
    },
    {
        "title": "On a numerical approximation scheme for construction of the early\n  exercise boundary for a class of nonlinear Black-Scholes equations",
        "authors": [
            "Daniel Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The purpose of this paper is to construct the early exercise boundary for a\nclass of nonlinear Black--Scholes equations with a nonlinear volatility\ndepending on the option price. We review a method how to transform the problem\ninto a solution of a time depending nonlinear parabolic equation defined on a\nfixed domain. Results of numerical computation of the early exercise boundary\nfor various nonlinear Black--Scholes equations are also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.5973v2"
    },
    {
        "title": "FX Smile in the Heston Model",
        "authors": [
            "Agnieszka Janek",
            "Tino Kluge",
            "Rafal Weron",
            "Uwe Wystup"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The Heston model stands out from the class of stochastic volatility (SV)\nmodels mainly for two reasons. Firstly, the process for the volatility is\nnon-negative and mean-reverting, which is what we observe in the markets.\nSecondly, there exists a fast and easily implemented semi-analytical solution\nfor European options. In this article we adapt the original work of Heston\n(1993) to a foreign exchange (FX) setting. We discuss the computational aspects\nof using the semi-analytical formulas, performing Monte Carlo simulations,\nchecking the Feller condition, and option pricing with FFT. In an empirical\nstudy we show that the smile of vanilla options can be reproduced by suitably\ncalibrating three out of five model parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.1617v1"
    },
    {
        "title": "Replicating financial market dynamics with a simple self-organized\n  critical lattice model",
        "authors": [
            "B. Dupoyet",
            "H. R. Fiebig",
            "D. P. Musgrove"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We explore a simple lattice field model intended to describe statistical\nproperties of high frequency financial markets. The model is relevant in the\ncross-disciplinary area of econophysics. Its signature feature is the emergence\nof a self-organized critical state. This implies scale invariance of the model,\nwithout tuning parameters. Prominent results of our simulation are time series\nof gains, prices, volatility, and gains frequency distributions, which all\ncompare favorably to features of historical market data. Applying a standard\nGARCH(1,1) fit to the lattice model gives results that are almost\nindistinguishable from historical NASDAQ data.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.4831v1"
    },
    {
        "title": "A simple discretization scheme for nonnegative diffusion processes, with\n  applications to option pricing",
        "authors": [
            "Chantal Labbé",
            "Bruno Rémillard",
            "Jean-François Renaud"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  A discretization scheme for nonnegative diffusion processes is proposed and\nthe convergence of the corresponding sequence of approximate processes is\nproved using the martingale problem framework. Motivations for this scheme come\ntypically from finance, especially for path-dependent option pricing. The\nscheme is simple: one only needs to find a nonnegative distribution whose mean\nand variance satisfy a simple condition to apply it. Then, for virtually any\n(path-dependent) payoff, Monte Carlo option prices obtained from this scheme\nwill converge to the theoretical price. Examples of models and diffusion\nprocesses for which the scheme applies are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.3247v1"
    },
    {
        "title": "Solving Optimal Dividend Problems via Phase-type Fitting Approximation\n  of Scale Functions",
        "authors": [
            "Masahiko Egami",
            "Kazutoshi Yamazaki"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The optimal dividend problem by De Finetti (1957) has been recently\ngeneralized to the spectrally negative L\\'evy model where the implementation of\noptimal strategies draws upon the computation of scale functions and their\nderivatives. This paper proposes a phase-type fitting approximation of the\noptimal strategy. We consider spectrally negative L\\'evy processes with\nphase-type jumps as well as meromorphic L\\'evy processes (Kuznetsov et al.,\n2010a), and use their scale functions to approximate the scale function for a\ngeneral spectrally negative L\\'evy process. We obtain analytically the\nconvergence results and illustrate numerically the effectiveness of the\napproximation methods using examples with the spectrally negative L\\'evy\nprocess with i.i.d. Weibull-distributed jumps, the \\beta-family and CGMY\nprocess.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.4732v1"
    },
    {
        "title": "Heat Kernel Interest Rate Models with Time-Inhomogeneous Markov\n  Processes",
        "authors": [
            "Jiro Akahori",
            "Andrea Macrina"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We consider a heat kernel approach for the development of stochastic pricing\nkernels. The kernels are constructed by positive propagators, which are driven\nby time-inhomogeneous Markov processes. We multiply such a propagator with a\npositive, time-dependent and decreasing weight function, and integrate the\nproduct over time. The result is a so-called weighted heat kernel that by\nconstruction is a supermartingale with respect to the filtration generated by\nthe time-inhomogeneous Markov processes. As an application, we show how this\nframework naturally fits the information-based asset pricing framework where\ntime-inhomogeneous Markov processes are utilized to model partial information\nabout random economic factors. We present examples of pricing kernel models\nwhich lead to analytical formulae for bond prices along with explicit\nexpressions for the associated interest rate and market price of risk.\nFurthermore, we also address the pricing of fixed-income derivatives within\nthis framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.1878v1"
    },
    {
        "title": "On the Use of Policy Iteration as an Easy Way of Pricing American\n  Options",
        "authors": [
            "Christoph Reisinger",
            "Jan Hendrik Witte"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In this paper, we demonstrate that policy iteration, introduced in the\ncontext of HJB equations in [Forsyth & Labahn, 2007], is an extremely simple\ngeneric algorithm for solving linear complementarity problems resulting from\nthe finite difference and finite element approximation of American options. We\nshow that, in general, O(N) is an upper and lower bound on the number of\niterations needed to solve a discrete LCP of size N. If embedded in a class of\nstandard discretisations with M time steps, the overall complexity of American\noption pricing is indeed only O(N(M+N)), and, therefore, for M N, identical to\nthe pricing of European options, which is O(MN). We also discuss the numerical\nproperties and robustness with respect to model parameters in relation to\npenalty and projected relaxation methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.4976v4"
    },
    {
        "title": "Sensitivity analysis of the early exercise boundary for American style\n  of Asian options",
        "authors": [
            "Daniel Sevcovic",
            "Martin Takac"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper we analyze American style of floating strike Asian call options\nbelonging to the class of financial derivatives whose payoff diagram depends\nnot only on the underlying asset price but also on the path average of\nunderlying asset prices over some predetermined time interval. The mathematical\nmodel for the option price leads to a free boundary problem for a parabolic\npartial differential equation. Applying fixed domain transformation and\ntransformation of variables we develop an efficient numerical algorithm based\non a solution to a non-local parabolic partial differential equation for the\ntransformed variable representing the synthesized portfolio. For various types\nof averaging methods we investigate the dependence of the early exercise\nboundary on model parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.3071v1"
    },
    {
        "title": "Multivariate GARCH estimation via a Bregman-proximal trust-region method",
        "authors": [
            "Stéphane Chrétien",
            "Juan-Pablo Ortega"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  The estimation of multivariate GARCH time series models is a difficult task\nmainly due to the significant overparameterization exhibited by the problem and\nusually referred to as the \"curse of dimensionality\". For example, in the case\nof the VEC family, the number of parameters involved in the model grows as a\npolynomial of order four on the dimensionality of the problem. Moreover, these\nparameters are subjected to convoluted nonlinear constraints necessary to\nensure, for instance, the existence of stationary solutions and the positive\nsemidefinite character of the conditional covariance matrices used in the model\ndesign. So far, this problem has been addressed in the literature only in low\ndimensional cases with strong parsimony constraints. In this paper we propose a\ngeneral formulation of the estimation problem in any dimension and develop a\nBregman-proximal trust-region method for its solution. The Bregman-proximal\napproach allows us to handle the constraints in a very efficient and natural\nway by staying in the primal space and the Trust-Region mechanism stabilizes\nand speeds up the scheme. Preliminary computational experiments are presented\nand confirm the very good performances of the proposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.5475v1"
    },
    {
        "title": "On the Stability the Least Squares Monte Carlo",
        "authors": [
            "Oleksii Mostovyi"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Consider Least Squares Monte Carlo (LSM) algorithm, which is proposed by\nLongstaff and Schwartz (2001) for pricing American style securities. This\nalgorithm is based on the projection of the value of continuation onto a\ncertain set of basis functions via the least squares problem. We analyze the\nstability of the algorithm when the number of exercise dates increases and\nprove that, if the underlying process for the stock price is continuous, then\nthe regression problem is ill-conditioned for small values of the time\nparameter.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.3218v2"
    },
    {
        "title": "Weighted Monte Carlo: Calibrating the Smile and Preserving Martingale\n  Condition",
        "authors": [
            "Alberto Elices",
            "Eduard Giménez"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Weighted Monte Carlo prices exotic options calibrating the probabilities of\npreviously generated paths by a regular Monte Carlo to fit a set of option\npremiums. When only vanilla call and put options and forward prices are\nconsidered, the Martingale condition might not be preserved. This paper shows\nthat this is indeed the case and overcomes the problem by adding additional\nsynthetic options. A robust, fast and easy-to-implement calibration algorithm\nis presented. The results are illustrated with a geometric cliquet option which\nshows how the price impact can be significant.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.3541v1"
    },
    {
        "title": "Hedging Effectiveness under Conditions of Asymmetry",
        "authors": [
            "John Cotter",
            "Jim Hanly"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We examine whether hedging effectiveness is affected by asymmetry in the\nreturn distribution by applying tail specific metrics to compare the hedging\neffectiveness of short and long hedgers using crude oil futures contracts. The\nmetrics used include Lower Partial Moments (LPM), Value at Risk (VaR) and\nConditional Value at Risk (CVAR). Comparisons are applied to a number of\nhedging strategies including OLS and both Symmetric and Asymmetric GARCH\nmodels. Our findings show that asymmetry reduces in-sample hedging performance\nand that there are significant differences in hedging performance between short\nand long hedgers. Thus, tail specific performance metrics should be applied in\nevaluating hedging effectiveness. We also find that the Ordinary Least Squares\n(OLS) model provides consistently good performance across different measures of\nhedging effectiveness and estimation methods irrespective of the\ncharacteristics of the underlying distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.5411v1"
    },
    {
        "title": "Multidimensional Quasi-Monte Carlo Malliavin Greeks",
        "authors": [
            "Nicola Cufaro Petroni",
            "Piergiacomo Sabino"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We investigate the use of Malliavin calculus in order to calculate the Greeks\nof multidimensional complex path-dependent options by simulation. For this\npurpose, we extend the formulas employed by Montero and Kohatsu-Higa to the\nmultidimensional case. The multidimensional setting shows the convenience of\nthe Malliavin Calculus approach over different techniques that have been\npreviously proposed. Indeed, these techniques may be computationally expensive\nand do not provide flexibility for variance reduction. In contrast, the\nMalliavin approach exhibits a higher flexibility by providing a class of\nfunctions that return the same expected value (the Greek) with different\naccuracies. This versatility for variance reduction is not possible without the\nuse of the generalized integral by part formula of Malliavin Calculus. In the\nmultidimensional context, we find convenient formulas that permit to improve\nthe localization technique, introduced in Fourni\\'e et al and reduce both the\ncomputational cost and the variance. Moreover, we show that the parameters\nemployed for variance reduction can be obtained \\textit{on the flight} in the\nsimulation. We illustrate the efficiency of the proposed procedures, coupled\nwith the enhanced version of Quasi-Monte Carlo simulations as discussed in\nSabino, for the numerical estimation of the Deltas of call, digital Asian-style\nand Exotic basket options with a fixed and a floating strike price in a\nmultidimensional Black-Scholes market.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.5722v1"
    },
    {
        "title": "Asymptotic Expansion for the Normal Implied Volatility in Local\n  Volatility Models",
        "authors": [
            "Viorel Costeanu",
            "Dan Pirjol"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We study the dynamics of the normal implied volatility in a local volatility\nmodel, using a small-time expansion in powers of maturity T. At leading order\nin this expansion, the asymptotics of the normal implied volatility is similar,\nup to a different definition of the moneyness, to that of the log-normal\nvolatility. This relation is preserved also to order O(T) in the small-time\nexpansion, and differences with the log-normal case appear first at O(T^2). The\nresults are illustrated on a few examples of local volatility models with\nanalytical local volatility, finding generally good agreement with exact or\nnumerical solutions. We point out that the asymptotic expansion can fail if\napplied naively for models with nonanalytical local volatility, for example\nwhich have discontinuous derivatives. Using perturbation theory methods, we\nshow that the ATM normal implied volatility for such a model contains a term ~\n\\sqrt{T}, with a coefficient which is proportional with the jump of the\nderivative.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.3359v1"
    },
    {
        "title": "Fourier Transform Methods for Regime-Switching Jump-Diffusions and the\n  Pricing of Forward Starting Options",
        "authors": [
            "Alessandro Ramponi"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper we consider a jump-diffusion dynamic whose parameters are\ndriven by a continuous time and stationary Markov Chain on a finite state space\nas a model for the underlying of European contingent claims. For this class of\nprocesses we firstly outline the Fourier transform method both in log-price and\nlog-strike to efficiently calculate the value of various types of options and\nas a concrete example of application, we present some numerical results within\na two-state regime switching version of the Merton jump-diffusion model. Then\nwe develop a closed-form solution to the problem of pricing a Forward Starting\nOption and use this result to approximate the value of such a derivative in a\ngeneral stochastic volatility framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.4567v1"
    },
    {
        "title": "Penalty Methods for the Solution of Discrete HJB Equations -- Continuous\n  Control and Obstacle Problems",
        "authors": [
            "Jan Hendrik Witte",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper, we present a novel penalty approach for the numerical solution\nof continuously controlled HJB equations and HJB obstacle problems. Our results\ninclude estimates of the penalisation error for a class of penalty terms, and\nwe show that variations of Newton's method can be used to obtain globally\nconvergent iterative solvers for the penalised equations. Furthermore, we\ndiscuss under what conditions local quadratic convergence of the iterative\nsolvers can be expected. We include numerical results demonstrating the\ncompetitiveness of our methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.5954v2"
    },
    {
        "title": "Analytical Approximation for Non-linear FBSDEs with Perturbation Scheme",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this work, we have presented a simple analytical approximation scheme for\ngeneric non-linear FBSDEs. By treating the interested system as the linear\ndecoupled FBSDE perturbed with non-linear generator and feedback terms, we have\nshown that it is possible to carry out a recursive approximation to an\narbitrarily higher order, where the required calculations in each order are\nequivalent to those for standard European contingent claims. We have also\napplied the perturbative method to the PDE framework following the so-called\nFour Step Scheme. The method is found to render the original non-linear PDE\ninto a series of standard parabolic linear PDEs. Due to the equivalence of the\ntwo approaches, it is also possible to derive approximate analytic solution for\nthe non-linear PDE by applying the asymptotic expansion to the corresponding\nprobabilistic model. Two simple examples are provided to demonstrate how the\nperturbation works and show its accuracy relative to known numerical\ntechniques. The method presented in this paper may be useful for various\nimportant problems which have eluded analytical treatment so far.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.0123v3"
    },
    {
        "title": "Utility based pricing and hedging of jump diffusion processes with a\n  view to applications",
        "authors": [
            "Jochen Zahn"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We discuss utility based pricing and hedging of jump diffusion processes with\nemphasis on the practical applicability of the framework. We point out two\ndifficulties that seem to limit this applicability, namely drift dependence and\nessential risk aversion independence. We suggest to solve these by a\nre-interpretation of the framework. This leads to the notion of an implied\ndrift. We also present a heuristic derivation of the marginal indifference\nprice and the marginal optimal hedge that might be useful in numerical\ncomputations.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.1395v2"
    },
    {
        "title": "Implied Volatility Surface: Construction Methodologies and\n  Characteristics",
        "authors": [
            "Cristian Homescu"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  The implied volatility surface (IVS) is a fundamental building block in\ncomputational finance. We provide a survey of methodologies for constructing\nsuch surfaces. We also discuss various topics which can influence the\nsuccessful construction of IVS in practice: arbitrage-free conditions in both\nstrike and time, how to perform extrapolation outside the core region, choice\nof calibrating functional and selection of numerical optimization algorithms,\nvolatility surface dynamics and asymptotics.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.1834v1"
    },
    {
        "title": "Computing Economic Equilibria by a Homotopy Method",
        "authors": [
            "Zoltan Pap"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper the possibility of computing equilibrium in pure exchange and\nproduction economies by a homotopy method is investigated. The performance of\nthe algorithm is tested on examples with known equilibria taken from the\nliterature on general equilibrium models and numerical results are presented.\nIn computing equilibria, economy will be specified by excess demand function.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.5144v1"
    },
    {
        "title": "ADI finite difference schemes for the Heston-Hull-White PDE",
        "authors": [
            "Tinne Haentjens",
            "Karel J. in 't Hout"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper we investigate the effectiveness of Alternating Direction\nImplicit (ADI) time discretization schemes in the numerical solution of the\nthree-dimensional Heston-Hull-White partial differential equation, which is\nsemidiscretized by applying finite difference schemes on nonuniform spatial\ngrids. We consider the Heston-Hull-White model with arbitrary correlation\nfactors, with time-dependent mean-reversion levels, with short and long\nmaturities, for cases where the Feller condition is satisfied and for cases\nwhere it is not. In addition, both European-style call options and up-and-out\ncall options are considered. It is shown through extensive tests that ADI\nschemes, with a proper choice of their parameters, perform very well in all\nsituations - in terms of stability, accuracy and efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.4087v1"
    },
    {
        "title": "Conditional sampling for barrier option pricing under the LT method",
        "authors": [
            "Nico Achtsis",
            "Ronald Cools",
            "Dirk Nuyens"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We develop a conditional sampling scheme for pricing knock-out barrier\noptions under the Linear Transformations (LT) algorithm from Imai and Tan\n(2006). We compare our new method to an existing conditional Monte Carlo scheme\nfrom Glasserman and Staum (2001), and show that a substantial variance\nreduction is achieved. We extend the method to allow pricing knock-in barrier\noptions and introduce a root-finding method to obtain a further variance\nreduction. The effectiveness of the new method is supported by numerical\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.4808v2"
    },
    {
        "title": "High-order short-time expansions for ATM option prices under the CGMY\n  model",
        "authors": [
            "José E. Figueroa-López",
            "Ruoting Gong",
            "Christian Houdré"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  The short-time asymptotic behavior of option prices for a variety of models\nwith jumps has received much attention in recent years. In the present work, a\nnovel second-order approximation for ATM option prices under the CGMY L\\'evy\nmodel is derived, and then extended to a model with an additional independent\nBrownian component. Our results shed light on the connection between both the\nvolatility of the continuous component and the jump parameters and the behavior\nof ATM option prices near expiration. In case of an additional Brownian\ncomponent, the second-order term, in time-t, is of the form $ d_{2}\nt^{(3-Y)/2}$, with the coefficient $d_{2}$ depending only on the overall jump\nintensity parameter C and the tail-heaviness parameter Y. This extends the\nknown result that the leading term is $(\\sigma/\\sqrt{2\\pi})t^{1/2}$, where\n$\\sigma$ is the volatility of the continuous component. In contrast, under a\npure-jump CGMY model, the dependence on the two parameters C and Y is already\nreflected in the leading term, which is of the form $d_{1} t^{1/Y}$.\nInformation on the relative frequency of negative and positive jumps appears\nonly in the second-order term, which is shown to be of the form $d_{2} t$ and\nwhose order of decay turns out to be independent of Y. The third-order\nasymptotic behavior of the option prices as well as the asymptotic behavior of\nthe corresponding Black-Scholes implied volatilities are also addressed. Our\nnumerical results show that in most cases the second-order term significantly\noutperform the first-order approximation.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.3111v2"
    },
    {
        "title": "Heavy-tails in economic data: fundamental assumptions, modelling and\n  analysis",
        "authors": [
            "João P. da Cruz",
            "Pedro G. Lind"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  The study of heavy-tailed distributions in economic and financial systems has\nbeen widely addressed since financial time series has become a research\nsubject.After the eighties, several \"highly improbable\" market drops were\nobserved (e.g. the 1987 stock market drop known as \"Black Monday\" and on even\nmore recent ones, already in the 21st century) that produce heavy losses that\nwere unexplainable in a GN environment. The losses incurred in these large\nmarket drop events did not change significantly the market practices or the way\nregulation is done but drove some attention back to the study of heavy-tails\nand their underlying mechanisms. Some recent findings in these context is the\nscope of this manuscript.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.0142v1"
    },
    {
        "title": "Perturbative Expansion of FBSDE in an Incomplete Market with Stochastic\n  Volatility",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In this work, we apply our newly proposed perturbative expansion technique to\na quadratic growth FBSDE appearing in an incomplete market with stochastic\nvolatility that is not perfectly hedgeable. By combining standard asymptotic\nexpansion technique for the underlying volatility process, we derive explicit\nexpression for the solution of the FBSDE up to the third order of\nvolatility-of-volatility, which can be directly translated into the optimal\ninvestment strategy. We compare our approximation with the exact solution,\nwhich is known to be derived by the Cole-Hopf transformation in this popular\nsetup. The result is very encouraging and shows good accuracy of the\napproximation up to quite long maturities. Since our new methodology can be\nextended straightforwardly to multi-dimensional setups, we expect it will open\nreal possibilities to obtain explicit optimal portfolios or hedging strategies\nunder realistic assumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.0608v3"
    },
    {
        "title": "Antithetic multilevel Monte Carlo estimation for multi-dimensional SDEs\n  without Lévy area simulation",
        "authors": [
            "Michael B. Giles",
            "Lukasz Szpruch"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In this paper we introduce a new multilevel Monte Carlo (MLMC) estimator for\nmulti-dimensional SDEs driven by Brownian motions. Giles has previously shown\nthat if we combine a numerical approximation with strong order of convergence\n$O(\\Delta t)$ with MLMC we can reduce the computational complexity to estimate\nexpected values of functionals of SDE solutions with a root-mean-square error\nof $\\epsilon$ from $O(\\epsilon^{-3})$ to $O(\\epsilon^{-2})$. However, in\ngeneral, to obtain a rate of strong convergence higher than $O(\\Delta t^{1/2})$\nrequires simulation, or approximation, of L\\'{e}vy areas. In this paper,\nthrough the construction of a suitable antithetic multilevel correction\nestimator, we are able to avoid the simulation of L\\'{e}vy areas and still\nachieve an $O(\\Delta t^2)$ multilevel correction variance for smooth payoffs,\nand almost an $O(\\Delta t^{3/2})$ variance for piecewise smooth payoffs, even\nthough there is only $O(\\Delta t^{1/2})$ strong convergence. This results in an\n$O(\\epsilon^{-2})$ complexity for estimating the value of European and Asian\nput and call options.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.6283v4"
    },
    {
        "title": "Quantile Mechanics 3: Series Representations and Approximation of some\n  Quantile Functions appearing in Finance",
        "authors": [
            "Asad Munir",
            "William Shaw"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  It has long been agreed by academics that the inversion method is the method\nof choice for generating random variates, given the availability of the\nquantile function. However for several probability distributions arising in\npractice a satisfactory method of approximating these functions is not\navailable. The main focus of this paper will be to develop Taylor and\nasymptotic series expansions for the quantile functions belonging to the\nfollowing probability distributions; Variance Gamma, Generalized Inverse\nGaussian, Hyperbolic and alpha-Stable. As a secondary matter, based on these\nanalytic expressions we briefly investigate the problem of approximating the\nquantile function.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.5729v2"
    },
    {
        "title": "Approximating stochastic volatility by recombinant trees",
        "authors": [
            "Erdinç Akyıldırım",
            "Yan Dolinsky",
            "H. Mete Soner"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  A general method to construct recombinant tree approximations for stochastic\nvolatility models is developed and applied to the Heston model for stock price\ndynamics. In this application, the resulting approximation is a four tuple\nMarkov process. The first two components are related to the stock and\nvolatility processes and take values in a two-dimensional binomial tree. The\nother two components of the Markov process are the increments of random walks\nwith simple values in $\\{-1,+1\\}$. The resulting efficient option pricing\nequations are numerically implemented for general American and European options\nincluding the standard put and calls, barrier, lookback and Asian-type\npay-offs. The weak and extended weak convergences are also proved.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.3555v2"
    },
    {
        "title": "Error estimates for binomial approximations of game put options",
        "authors": [
            "Y. Iron",
            "Y. Kifer"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We construct algorithms via binomial approximations for computation of prices\nof game put options and obtain estimates of approximation errors.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0153v2"
    },
    {
        "title": "A Numerical Scheme Based on Semi-Static Hedging Strategy",
        "authors": [
            "Yuri Imamura",
            "Yuta Ishigaki",
            "Takuya Kawagoe",
            "Toshiki Okumura"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In the present paper, we introduce a numerical scheme for the price of a\nbarrier option when the price of the underlying follows a diffusion process.\nThe numerical scheme is based on an extension of a static hedging formula of\nbarrier options. For getting the static hedging formula, the underlying process\nneeds to have a symmetry. We introduce a way to \"symmetrize\" a given diffusion\nprocess. Then the pricing of a barrier option is reduced to that of plain\noptions under the symmetrized process. To show how our symmetrization scheme\nworks, we will present some numerical results applying (path-independent)\nEuler-Maruyama approximation to our scheme, comparing them with the\npath-dependent Euler-Maruyama scheme when the model is of the Black-Scholes,\nCEV, Heston, and $ (\\lambda) $-SABR, respectively. The results show the\neffectiveness of our scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.2934v2"
    },
    {
        "title": "Hedging of game options in discrete markets with transaction costs",
        "authors": [
            "Yuri Kifer"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We construct algorithms for computation of prices and superhedging strategies\nfor game options in general discrete markets both from the seller and the buyer\npoints of view.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.4506v1"
    },
    {
        "title": "On a Symmetrization of Diffusion Processes",
        "authors": [
            "Jiro Akahori",
            "Yuri Imamura"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  The latter author, together with collaborators, proposed a numerical scheme\nto calculate the price of barrier options. The scheme is based on a\nsymmetrization of diffusion process. The present paper aims to give a\nmathematical credit to the use of the numerical scheme for Heston or SABR type\nstochastic volatility models. This will be done by showing a fairly general\nresult on the symmetrization (in multi-dimension/multi-reflections). Further\napplications (to time-inhomogeneous diffusions/ to time dependent boundaries/to\ncurved boundaries) are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.5983v1"
    },
    {
        "title": "A new approach to unbiased estimation for SDE's",
        "authors": [
            "Chang-han Rhee",
            "Peter W. Glynn"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In this paper, we introduce a new approach to constructing unbiased\nestimators when computing expectations of path functionals associated with\nstochastic differential equations (SDEs). Our randomization idea is closely\nrelated to multi-level Monte Carlo and provides a simple mechanism for\nconstructing a finite variance unbiased estimator with \"square root convergence\nrate\" whenever one has available a scheme that produces strong error of order\ngreater than 1/2 for the path functional under consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.2452v1"
    },
    {
        "title": "Conditional sampling for barrier option pricing under the Heston model",
        "authors": [
            "Nico Achtsis",
            "Ronald Cools",
            "Dirk Nuyens"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We propose a quasi-Monte Carlo algorithm for pricing knock-out and knock-in\nbarrier options under the Heston (1993) stochastic volatility model. This is\ndone by modifying the LT method from Imai and Tan (2006) for the Heston model\nsuch that the first uniform variable does not influence the stochastic\nvolatility path and then conditionally modifying its marginals to fulfill the\nbarrier condition(s). We show this method is unbiased and never does worse than\nthe unconditional algorithm. Additionally the conditioning is combined with a\nroot finding method to also force positive payouts. The effectiveness of this\nmethod is shown by extensive numerical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.6566v2"
    },
    {
        "title": "A New Trinomial Recombination Tree Algorithm and Its Applications",
        "authors": [
            "Peter C. L. Lin"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  A New Trinomial Recombination Tree Algorithm and Its Applications\n",
        "pdf_link": "http://arxiv.org/pdf/1210.0968v1"
    },
    {
        "title": "The solution of discretionary stopping problems with applications to the\n  optimal timing of investment decisions",
        "authors": [
            "Timothy C. Johnson"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We present a methodology for obtaining explicit solutions to infinite time\nhorizon optimal stopping problems involving general, one-dimensional, It\\^o\ndiffusions, payoff functions that need not be smooth and state-dependent\ndiscounting. This is done within a framework based on dynamic programming\ntechniques employing variational inequalities and links to the probabilistic\napproaches employing $r$-excessive functions and martingale theory. The aim of\nthis paper is to facilitate the the solution of a wide variety of problems,\nparticularly in finance or economics.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2617v1"
    },
    {
        "title": "Estimation of the shape parameter of a generalized Pareto distribution\n  based on a transformation to Pareto distributed variables",
        "authors": [
            "J. Martin van Zyl"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Random variables of the generalized Pareto distribution, can be transformed\nto that of the Pareto distribution. Explicit expressions exist for the maximum\nlikelihood estimators of the parameters of the Pareto distribution. The\nperformance of the estimation of the shape parameter of generalized Pareto\ndistributed using transformed observations, based on the probability weighted\nmethod is tested. It was found to improve the performance of the probability\nweighted estimator and performs good with respect to bias and MSE.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7642v4"
    },
    {
        "title": "An FBSDE Approach to American Option Pricing with an Interacting\n  Particle Method",
        "authors": [
            "Masaaki Fujii",
            "Seisho Sato",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In the paper, we propose a new calculation scheme for American options in the\nframework of a forward backward stochastic differential equation (FBSDE). The\nwell-known decomposition of an American option price with that of a European\noption of the same maturity and the remaining early exercise premium can be\ncast into the form of a decoupled non-linear FBSDE. We numerically solve the\nFBSDE by applying an interacting particle method recently proposed by Fujii and\nTakahashi (2012d), which allows one to perform a Monte Carlo simulation in a\nfully forward-looking manner. We perform the fourth-order analysis for the\nBlack-Scholes (BS) model and the third-order analysis for the Heston model. The\ncomparison to those obtained from existing tree algorithms shows the\neffectiveness of the particle method.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.5867v1"
    },
    {
        "title": "On Reduced Form Intensity-based Model with Trigger Events",
        "authors": [
            "Jia-Wen Gu",
            "Wai-Ki Ching",
            "Tak-Kuen Siu",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Corporate defaults may be triggered by some major market news or events such\nas financial crises or collapses of major banks or financial institutions. With\na view to develop a more realistic model for credit risk analysis, we introduce\na new type of reduced-form intensity-based model that can incorporate the\nimpacts of both observable \"trigger\" events and economic environment on\ncorporate defaults. The key idea of the model is to augment a Cox process with\ntrigger events. Both single-default and multiple-default cases are considered\nin this paper. In the former case, a simple expression for the distribution of\nthe default time is obtained. Applications of the proposed model to price\ndefaultable bonds and multi-name Credit Default Swaps (CDSs) are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.0109v1"
    },
    {
        "title": "Technical report : Risk-neutral density recovery via spectral analysis",
        "authors": [
            "Jean-Baptiste Monnier"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In this paper, we propose a new method for estimating the conditional\nrisk-neutral density (RND) directly from a cross-section of put option bid-ask\nquotes. More precisely, we propose to view the RND recovery problem as an\ninverse problem. We first show that it is possible to define restricted put and\ncall operators that admit a singular value decomposition (SVD), which we\ncompute explicitly. We subsequently show that this new framework allows us to\ndevise a simple and fast quadratic programming method to recover the smoothest\nRND whose corresponding put prices lie inside the bid-ask quotes. This method\nis termed the spectral recovery method (SRM). Interestingly, the SVD of the\nrestricted put and call operators sheds some new light on the RND recovery\nproblem. The SRM improves on other RND recovery methods in the sense that:\n  - it is fast and simple to implement since it requires solution of a single\nquadratic program, while being fully nonparametric; - it takes the bid ask\nquotes as sole input and does not require any sort of calibration, smoothing or\npreprocessing of the data; - it is robust to the paucity of price quotes; - it\nreturns the smoothest density giving rise to prices that lie inside the bid ask\nquotes. The estimated RND is therefore as well-behaved as can be; - it returns\na closed form estimate of the RND on the interval [0,B] of the positive real\nline, where B is a positive constant that can be chosen arbitrarily. We thus\nobtain both the middle part of the RND together with its full left tail and\npart of its right tail.\n  We confront this method to both real and simulated data and observe that it\nfares well in practice. The SRM is thus found to be a promising alternative to\nother RND recovery methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.2567v1"
    },
    {
        "title": "An Explicit Martingale Version of Brenier's Theorem",
        "authors": [
            "Pierre Henry-Labordere",
            "Nizar Touzi"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  By investigating model-independent bounds for exotic options in financial\nmathematics, a martingale version of the Monge-Kantorovich mass transport\nproblem was introduced in \\cite{BeiglbockHenry\nLaborderePenkner,GalichonHenry-LabordereTouzi}. In this paper, we extend the\none-dimensional Brenier's theorem to the present martingale version. We provide\nthe explicit martingale optimal transference plans for a remarkable class of\ncoupling functions corresponding to the lower and upper bounds. These explicit\nextremal probability measures coincide with the unique left and right monotone\nmartingale transference plans, which were introduced in \\cite{BeiglbockJuillet}\nby suitable adaptation of the notion of cyclic monotonicity. Instead, our\napproach relies heavily on the (weak) duality result stated in\n\\cite{BeiglbockHenry-LaborderePenkner}, and provides, as a by-product, an\nexplicit expression for the corresponding optimal semi-static hedging\nstrategies. We finally provide an extension to the multiple marginals case.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.4854v3"
    },
    {
        "title": "Efficient Solution of Backward Jump-Diffusion PIDEs with Splitting and\n  Matrix Exponentials",
        "authors": [
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We propose a new, unified approach to solving jump-diffusion partial\nintegro-differential equations (PIDEs) that often appear in mathematical\nfinance. Our method consists of the following steps. First, a second-order\noperator splitting on financial processes (diffusion and jumps) is applied to\nthese PIDEs. To solve the diffusion equation, we use standard finite-difference\nmethods, which for multi-dimensional problems could also include splitting on\nvarious dimensions. For the jump part, we transform the jump integral into a\npseudo-differential operator. Then for various jump models we show how to\nconstruct an appropriate first and second order approximation on a grid which\nsupersets the grid that we used for the diffusion part. These approximations\nmake the scheme to be unconditionally stable in time and preserve positivity of\nthe solution which is computed either via a matrix exponential, or via P{\\'a}de\napproximation of the matrix exponent. Various numerical experiments are\nprovided to justify these results.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.3159v3"
    },
    {
        "title": "The Convexity of the Free Boundary for the American put option",
        "authors": [
            "Hsuan-Ku Liu"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This paper studies the parabolic free boundary problem arising from pricing\nAmerican-style put options on an asset whose index follows a geometric Brownian\nmotion process. The contribution is to propose a condition for that the early\nexercise boundary is a convex function.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5337v7"
    },
    {
        "title": "B-spline techniques for volatility modeling",
        "authors": [
            "Sylvain Corlay"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This paper is devoted to the application of B-splines to volatility modeling,\nspecifically the calibration of the leverage function in stochastic local\nvolatility models and the parameterization of an arbitrage-free implied\nvolatility surface calibrated to sparse option data. We use an extension of\nclassical B-splines obtained by including basis functions with infinite\nsupport. We first come back to the application of shape-constrained B-splines\nto the estimation of conditional expectations, not merely from a scatter plot\nbut also from the given marginal distributions. An application is the Monte\nCarlo calibration of stochastic local volatility models by Markov projection.\nThen we present a new technique for the calibration of an implied volatility\nsurface to sparse option data. We use a B-spline parameterization of the\nRadon-Nikodym derivative of the underlying's risk-neutral probability density\nwith respect to a roughly calibrated base model. We show that this method\nprovides smooth arbitrage-free implied volatility surfaces. Finally, we sketch\na Galerkin method with B-spline finite elements to the solution of the partial\ndifferential equation satisfied by the Radon-Nikodym derivative.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.0995v4"
    },
    {
        "title": "Making Mean-Variance Hedging Implementable in a Partially Observable\n  Market",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  The mean-variance hedging (MVH) problem is studied in a partially observable\nmarket where the drift processes can only be inferred through the observation\nof asset or index processes. Although most of the literatures treat the MVH\nproblem by the duality method, here we study a system consisting of three BSDEs\nderived by Mania and Tevzadze (2003) and Mania et.al.(2008) and try to provide\nmore explicit expressions directly implementable by practitioners. Under the\nBayesian and Kalman-Bucy frameworks, we find that a relevant BSDE yields a\nsemi-closed solution via a simple set of ODEs which allow a quick numerical\nevaluation. This renders remaining problems equivalent to solving European\ncontingent claims under a new forward measure, and it is straightforward to\nobtain a forward looking non-sequential Monte Carlo simulation scheme. We also\ngive a special example where the hedging position is available in a semi-closed\nform. For more generic setups, we provide explicit expressions of approximate\nhedging portfolio by an asymptotic expansion. These analytic expressions not\nonly allow the hedgers to update the hedging positions in real time but also\nmake a direct analysis of the terminal distribution of the hedged portfolio\nfeasible by standard Monte Carlo simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3359v4"
    },
    {
        "title": "Efficient valuation method for the SABR model",
        "authors": [
            "Hyukjae Park"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In this article, we show how the scaling symmetry of the SABR model can be\nutilized to efficiently price European options. For special kinds of payoffs,\nthe complexity of the problem is reduced by one dimension. For more generic\npayoffs, instead of solving the 1+2 dimensional SABR PDE, it is sufficient to\nsolve $N_V$ uncoupled 1+1 dimensional PDE's, where $N_V$ is the number of\npoints used to discretize one dimension. Furthermore, the symmetry argument\nenables us to obtain prices of multiple options, whose payoffs are related to\neach other by convolutions, by valuing one of them. The results of the method\nare compared with the Monte Carlo simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.0665v4"
    },
    {
        "title": "ADI schemes for pricing American options under the Heston model",
        "authors": [
            "Tinne Haentjens",
            "Karel in 't Hout"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In this paper a simple, effective adaptation of Alternating Direction\nImplicit (ADI) time discretization schemes is proposed for the numerical\npricing of American-style options under the Heston model via a partial\ndifferential complementarity problem. The stability and convergence of the new\nmethods are extensively investigated in actual, challenging applications. In\naddition a relevant theoretical result is proved.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.0110v1"
    },
    {
        "title": "Hedging in Lévy Models and the Time Step Equivalent of Jumps",
        "authors": [
            "Aleš Černý",
            "Stephan Denkl",
            "Jan Kallsen"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We consider option hedging in a model where the underlying follows an\nexponential L\\'evy process. We derive approximations to the variance-optimal\nand to some suboptimal strategies as well as to their mean squared hedging\nerrors. The results are obtained by considering the L\\'evy model as a\nperturbation of the Black-Scholes model. The approximations depend on the first\nfour moments of logarithmic stock returns in the L\\'evy model and option price\nsensitivities (greeks) in the limiting Black-Scholes model. We illustrate\nnumerically that our formulas work well for a variety of L\\'evy models\nsuggested in the literature. From a theoretical point of view, it turns out\nthat jumps have a similar effect on hedging errors as discrete-time hedging in\nthe Black-Scholes model.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.7833v3"
    },
    {
        "title": "Order Estimates for the Exact Lugannani-Rice Expansion",
        "authors": [
            "Takashi Kato",
            "Jun Sekine",
            "Kenichi Yoshikawa"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  The Lugannani-Rice formula is a saddlepoint approximation method for\nestimating the tail probability distribution function, which was originally\nstudied for the sum of independent identically distributed random variables.\nBecause of its tractability, the formula is now widely used in practical\nfinancial engineering as an approximation formula for the distribution of a\n(single) random variable. In this paper, the Lugannani-Rice approximation\nformula is derived for a general, parametrized sequence of random variables and\nthe order estimates of the approximation are given.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3347v3"
    },
    {
        "title": "Multivariate stochastic volatility modelling using Wishart\n  autoregressive processes",
        "authors": [
            "K. Triantafyllopoulos"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  A new multivariate stochastic volatility estimation procedure for financial\ntime series is proposed. A Wishart autoregressive process is considered for the\nvolatility precision covariance matrix, for the estimation of which a two step\nprocedure is adopted. The first step is the conditional inference on the\nautoregressive parameters and the second step is the unconditional inference,\nbased on a Newton-Raphson iterative algorithm. The proposed methodology, which\nis mostly Bayesian, is suitable for medium dimensional data and it bridges the\ngap between closed-form estimation and simulation-based estimation algorithms.\nAn example, consisting of foreign exchange rates data, illustrates the proposed\nmethodology.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.0530v1"
    },
    {
        "title": "Functional Ito Calculus, Path-dependence and the Computation of Greeks",
        "authors": [
            "Samy Jazaerli",
            "Yuri F. Saporito"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Dupire's functional It\\^o calculus provides an alternative approach to the\nclassical Malliavin calculus for the computation of sensitivities, also called\nGreeks, of path-dependent derivatives prices. In this paper, we introduce a\nmeasure of path-dependence of functionals within the functional It\\^o calculus\nframework. Namely, we consider the Lie bracket of the space and time functional\nderivatives, which we use to classify functionals accordingly to their degree\nof path-dependence. We then revisit the problem of efficient numerical\ncomputation of Greeks for path-dependent derivatives using integration by parts\ntechniques. Special attention is paid to path-dependent functionals with zero\nLie bracket, called locally weakly path-dependent functionals in our\nclassification. Hence, we derive the weighted-expectation formulas for their\nGreeks. In the more general case of fully path-dependent functionals, we show\nthat, equipped with the functional It\\^o calculus, we are able to analyze the\neffect of the Lie bracket on the computation of Greeks. Moreover, we are also\nable to consider the more general dynamics of path-dependent volatility. These\nwere not achieved using Malliavin calculus.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3881v5"
    },
    {
        "title": "Multiscale Stochastic Volatility Model for Derivatives on Futures",
        "authors": [
            "Jean-Pierre Fouque",
            "Yuri F. Saporito",
            "Jorge P. Zubelli"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In this paper we present a new method to compute the first-order\napproximation of the price of derivatives on futures in the context of\nmultiscale stochastic volatility of Fouque \\textit{et al.} (2011, CUP). It\nprovides an alternative method to the singular perturbation technique presented\nin Hikspoors and Jaimungal (2008). The main features of our method are twofold:\nfirstly, it does not rely on any additional hypothesis on the regularity of the\npayoff function, and secondly, it allows an effective and straightforward\ncalibration procedure of the model to implied volatilities. These features were\nnot achieved in previous works. Moreover, the central argument of our method\ncould be applied to interest rate derivatives and compound derivatives. The\nonly pre-requisite of our approach is the first-order approximation of the\nunderlying derivative. Furthermore, the model proposed here is well-suited for\ncommodities since it incorporates mean reversion of the spot price and\nmultiscale stochastic volatility. Indeed, the model was validated by\ncalibrating it to options on crude-oil futures, and it displays a very good fit\nof the implied volatility.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.4249v1"
    },
    {
        "title": "Empirical Study of the GARCH model with Rational Errors",
        "authors": [
            "Ting Ting Chen",
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We use the GARCH model with a fat-tailed error distribution described by a\nrational function and apply it for the stock price data on the Tokyo Stock\nExchange. To determine the model parameters we perform the Bayesian inference\nto the model. The Bayesian inference is implemented by the Metropolis-Hastings\nalgorithm with an adaptive multi-dimensional Student's t-proposal density. In\norder to compare the model with the GARCH model with the standard normal errors\nwe calculate information criterions: AIC and DIC, and find that both criterions\nfavor the GARCH model with a rational error distribution. We also calculate the\naccuracy of the volatility by using the realized volatility and find that a\ngood accuracy is obtained for the GARCH model with a rational error\ndistribution. Thus we conclude that the GARCH model with a rational error\ndistribution is superior to the GARCH model with the normal errors and it can\nbe used as an alternative GARCH model to those with other fat-tailed\ndistributions.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7057v1"
    },
    {
        "title": "Faster Comparison of Stopping Times by Nested Conditional Monte Carlo",
        "authors": [
            "Fabian Dickmann",
            "Nikolaus Schweizer"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We show that deliberately introducing a nested simulation stage can lead to\nsignificant variance reductions when comparing two stopping times by Monte\nCarlo. We derive the optimal number of nested simulations and prove that the\nalgorithm is remarkably robust to misspecifications of this number. The method\nis applied to several problems related to Bermudan/American options. In these\napplications, our method allows to substantially increase the efficiency of\nother variance reduction techniques, namely, Quasi-Control Variates and\nMultilevel Monte Carlo.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.0243v1"
    },
    {
        "title": "Pricing Currency Derivatives with Markov-modulated Levy Dynamics",
        "authors": [
            "Anatoliy Swishchuk",
            "Maksym Tertychnyi",
            "Robert Elliott"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  Using a Levy process we generalize formulas in Bo et al.(2010) for the\nEsscher transform parameters for the log-normal distribution which ensure the\nmartingale condition holds for the discounted foreign exchange rate. Using\nthese values of the parameters we find a risk-neural measure and provide new\nformulas for the distribution of jumps, the mean jump size, and the Poisson\nprocess intensity with respect to to this measure. The formulas for a European\ncall foreign exchange option are also derived. We apply these formulas to the\ncase of the log-double exponential distribution of jumps. We provide numerical\nsimulations for the European call foreign exchange option prices with different\nparameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1953v1"
    },
    {
        "title": "Currency Derivatives Pricing for Markov-modulated Merton Jump-diffusion\n  Spot Forex Rate",
        "authors": [
            "Anatoliy Swishchuk",
            "Maksym Tertychnyi",
            "Winsor Hoang"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We derived similar to Bo et al. (2010) results but in the case when the\ndynamics of the FX rate is driven by a general Merton jump-diffusion process.\nThe main results of our paper are as follows: 1) formulas for the Esscher\ntransform parameters which ensure that the martingale condition for the\ndiscounted foreign exchange rate is a martingale for a general Merton\njump--diffusion process are derived; using the values of these parameters we\nproceeded to a risk-neural measure and provide new formulas for the\ndistribution of jumps, the mean jump size, and the Poisson process intensity\nwith respect to the measure; pricing formulas for European call foreign\nexchange options have been given as well; 2) obtained formulas are applied to\nthe case of the exponential processes; 3) numerical simulations of European\ncall foreign exchange option prices for different parameters are also provided;\n4) codes for Matlab functions used in numerical simulations of option prices\nare given.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.2273v1"
    },
    {
        "title": "A re-examination of real interest parity in CEECs using old and new\n  generations of panel unit root tests",
        "authors": [
            "Claudiu Tiberiu Albulescu",
            "Dominique Pepin",
            "Aviral Kumar Tiwari"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  This study applies old and new generations of panel unit root tests to test\nthe validity of long-run real interest rate parity (RIP) hypothesis for ten\nCentral and Eastern European Countries (CEECs) with respect to the Euro area\nand an average of the CEECs' real interest rates, respectively. When the panel\nunit root tests are carried out with respect to the Euro area rate, we confirm\nthe results of previous studies which support the RIP hypothesis. Nevertheless,\nwhen the test is performed using the average of the CEECs' rate, our results\nare mitigated, revealing that the hypothesis of CEECs' interest rates\nconvergence cannot be taken for granted. From a robustness analysis\nperspective, our findings indicate that the RIP hypothesis for CEECs should be\nconsidered with cautions, being sensitive to the benchmark.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.3627v1"
    },
    {
        "title": "A Method of Reducing Dimension of Space Variables in Multi-dimensional\n  Black-Scholes Equations",
        "authors": [
            "Hyong-chol O",
            "Yong-hwa Ro",
            "Ning Wan"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We study a method of reducing space dimension in multi-dimensional\nBlack-Scholes partial differential equations as well as in multi-dimensional\nparabolic equations. We prove that a multiplicative transformation of space\nvariables in the Black-Scholes partial differential equation reserves the form\nof Black-Scholes partial differential equation and reduces the space dimension.\nWe show that this transformation can reduce the number of sources of risks by\ntwo or more in some cases by giving remarks and several examples of financial\npricing problems. We also present that the invariance of the form of\nBlack-Scholes equations is based on the invariance of the form of parabolic\nequation under a change of variables with the linear combination of variables.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.2053v1"
    },
    {
        "title": "A robust algorithm and convergence analysis for static replications of\n  nonlinear payoffs",
        "authors": [
            "Jingtang Ma",
            "Dongya Deng",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In this paper we propose a new robust algorithm to find the optimal static\nreplicating portfolios for general nonlinear payoff functions and give the\nestimate of the rate of convergence that is absent in the literature. We choose\nthe static replication by minimizing the error bound between the nonlinear\npayoff function and the linear spline approximation and derive the\nequidistribution equation for selecting the optimal strike prices. The\nnumerical tests for variance swaps and swaptions and also for the static\nquadratic replication and the model with counterparty risk show that the\nproposed algorithm is simple, fast and accurate. The paper has generalized and\nimproved the results of the static replication and approximation in the\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.5430v1"
    },
    {
        "title": "Semiclassical approximation in stochastic optimal control I. Portfolio\n  construction problem",
        "authors": [
            "Sakda Chaiworawitkul",
            "Patrick S. Hagan",
            "Andrew Lesniewski"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  This is the first in a series of papers in which we study an efficient\napproximation scheme for solving the Hamilton-Jacobi-Bellman equation for\nmulti-dimensional problems in stochastic control theory. The method is a\ncombination of a WKB style asymptotic expansion of the value function, which\nreduces the second order HJB partial differential equation to a hierarchy of\nfirst order PDEs, followed by a numerical algorithm to solve the first few of\nthe resulting first order PDEs. This method is applicable to stochastic systems\nwith a relatively large number of degrees of freedom, and does not seem to\nsuffer from the curse of dimensionality. Computer code implementation of the\nmethod using modest computational resources runs essentially in real time. We\napply the method to solve a general portfolio construction problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.6090v1"
    },
    {
        "title": "Bank Networks from Text: Interrelations, Centrality and Determinants",
        "authors": [
            "Samuel Rönnqvist",
            "Peter Sarlin"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In the wake of the still ongoing global financial crisis, bank\ninterdependencies have come into focus in trying to assess linkages among banks\nand systemic risk. To date, such analysis has largely been based on numerical\ndata. By contrast, this study attempts to gain further insight into bank\ninterconnections by tapping into financial discourse. We present a\ntext-to-network process, which has its basis in co-occurrences of bank names\nand can be analyzed quantitatively and visualized. To quantify bank importance,\nwe propose an information centrality measure to rank and assess trends of bank\ncentrality in discussion. For qualitative assessment of bank networks, we put\nforward a visual, interactive interface for better illustrating network\nstructures. We illustrate the text-based approach on European Large and Complex\nBanking Groups (LCBGs) during the ongoing financial crisis by quantifying bank\ninterrelations and centrality from discussion in 3M news articles, spanning\n2007Q1 to 2014Q3.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.7752v2"
    },
    {
        "title": "Bayesian estimation of realized stochastic volatility model by Hybrid\n  Monte Carlo algorithm",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The hybrid Monte Carlo algorithm (HMCA) is applied for Bayesian parameter\nestimation of the realized stochastic volatility (RSV) model. Using the 2nd\norder minimum norm integrator (2MNI) for the molecular dynamics (MD) simulation\nin the HMCA, we find that the 2MNI is more efficient than the conventional\nleapfrog integrator. We also find that the autocorrelation time of the\nvolatility variables sampled by the HMCA is very short. Thus it is concluded\nthat the HMCA with the 2MNI is an efficient algorithm for parameter estimations\nof the RSV model.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.0981v1"
    },
    {
        "title": "Monte Carlo Calculation of Exposure Profiles and Greeks for Bermudan and\n  Barrier Options under the Heston Hull-White Model",
        "authors": [
            "Q. Feng",
            "C. W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  Valuation of Credit Valuation Adjustment (CVA) has become an important field\nas its calculation is required in Basel III, issued in 2010, in the wake of the\ncredit crisis. Exposure, which is defined as the potential future loss of a\ndefault event without any recovery, is one of the key elementsfor pricing CVA.\nThis paper provides a backward dynamics framework for assessing exposure\nprofiles of European, Bermudan and barrier options under the Heston and Heston\nHull-White asset dynamics. We discuss the potential of an efficient and\nadaptive Monte Carlo approach, the Stochastic Grid Bundling Method}(SGBM),\nwhich employs the techniques of simulation, regression and bundling. Greeks of\nthe exposure profiles can be calculated in the same backward iteration with\nlittle extra effort. Assuming independence between default event and exposure\nprofiles, we give examples of calculating exposure, CVA and Greeks for Bermudan\nand barrier options.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.3623v1"
    },
    {
        "title": "Variance reduced multilevel path simulation: going beyond the complexity\n  $\\varepsilon^{-2}$",
        "authors": [
            "Denis Belomestny",
            "Tigran Nagapetyan"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In this paper a novel modification of the multilevel Monte Carlo approach,\nallowing for further significant complexity reduction, is proposed. The idea of\nthe modification is to use the method of control variates to reduce variance at\nlevel zero. We show that, under a proper choice of control variates, one can\nreduce the complexity order of the modified MLMC algorithm down to\n$\\varepsilon^{-2+\\delta}$ for any $\\delta\\in [0,1)$ with $\\varepsilon$ being\nthe precision to be achieved. These theoretical results are illustrated by\nseveral numerical examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.4045v2"
    },
    {
        "title": "Equilibrium Pricing in an Order Book Environment: Case Study for a Spin\n  Model",
        "authors": [
            "Frederik Meudt",
            "Thilo A. Schmitt",
            "Rudi Schäfer",
            "Thomas Guhr"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  When modelling stock market dynamics, the price formation is often based on\nan equilbrium mechanism. In real stock exchanges, however, the price formation\nis goverend by the order book. It is thus interesting to check if the resulting\nstylized facts of a model with equilibrium pricing change, remain the same or,\nmore generally, are compatible with the order book environment. We tackle this\nissue in the framework of a case study by embedding the\nBornholdt-Kaizoji-Fujiwara spin model into the order book dynamics. To this\nend, we use a recently developed agent based model that realistically\nincorporates the order book. We find realistic stylized facts. We conclude for\nthe studied case that equilibrium pricing is not needed and that the\ncorresponding assumption of a \"fundamental\" price may be abandoned.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.01125v1"
    },
    {
        "title": "Feynman-Kac formula for Lévy processes with discontinuous killing rate",
        "authors": [
            "Kathrin Glau"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  The challenge to fruitfully merge state-of-the-art techniques from\nmathematical finance and numerical analysis has inspired researchers to develop\nfast deterministic option pricing methods. As a result, highly efficient\nalgorithms to compute option prices in L\\'evy models by solving partial integro\ndifferential equations have been developed. In order to provide a solid\nmathematical foundation for these methods, we derive a Feynman-Kac\nrepresentation of variational solutions to partial integro differential\nequations that characterize conditional expectations of functionals of killed\ntime-inhomogeneous L\\'evy processes. We allow for a wide range of underlying\nstochastic processes, comprising processes with Brownian part, and a broad\nclass of pure jump processes such as generalized hyperbolic, multivariate\nnormal inverse Gaussian, tempered stable, and $\\alpha$-semi stable L\\'evy\nprocesses. By virtue of our mild regularity assumptions as to the killing rate\nand the initial condition of the partial differential equation, our results\nprovide a rigorous basis for numerous applications, not only in financial\nmathematics but also in probability theory and relativistic quantum mechanics.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07531v3"
    },
    {
        "title": "Sensitivity and Computational Complexity in Financial Networks",
        "authors": [
            "Brett Hemenway",
            "Sanjeev Khanna"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Modern financial networks exhibit a high degree of interconnectedness and\ndetermining the causes of instability and contagion in financial networks is\nnecessary to inform policy and avoid future financial collapse. In the American\nEconomic Review, Elliott, Golub and Jackson proposed a simple model for\ncapturing the dynamics of complex financial networks. In Elliott, Golub and\nJackson's model, each institution in the network can buy underlying assets or\npercentage shares in other institutions (cross-holdings) and if any\ninstitution's value drops below a critical threshold value, its value suffers\nan additional failure cost.\n  This work shows that even in simple model put forward by Elliott, Golub and\nJackson there are fundamental barriers to understanding the risks that are\ninherent in a network. First, if institutions are not required to maintain a\nminimum amount of self-holdings, an $\\epsilon$ change in investments by a\nsingle institution can have an arbitrarily magnified influence on the net worth\nof the institutions in the system. This sensitivity result shows that if\ninstitutions have small self-holdings, then estimating the market value of an\ninstitution requires almost perfect information about every cross-holding in\nthe system. Second, we show that even if a regulator has complete information\nabout all cross-holdings in the system, it may be computationally intractable\nto even estimate the number of failures that could be caused by an arbitrarily\nsmall shock to the system. Together, these results show that any uncertainty in\nthe cross-holdings or values of the underlying assets can be amplified by the\nnetwork to arbitrarily large uncertainty in the valuations of institutions in\nthe network.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.07676v2"
    },
    {
        "title": "Intertemporal Substitutability, Risk Aversion and Asset Prices",
        "authors": [
            "Dominique Pepin"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Is the elasticity of intertemporal substitution (EIS) more or less than one?\nThis question can be answered by confronting theoretical results of asset\npricing models with investor behaviour during episodes of stock market panic.\nIf we consider these episodes as periods of high risk aversion, then lower\nasset prices are in fact associated with higher risk aversion. However,\naccording to theoretical models, risky asset price is an increasing function of\nthe coefficient of risk aversion only if the EIS exceeds unity. It may\ntherefore be concluded that the EIS must be more than one to reconcile theory\nwith the observed stock price decline during periods of panic.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07210v2"
    },
    {
        "title": "High-order compact schemes for Black-Scholes basket options",
        "authors": [
            "Bertram Düring",
            "Christof Heuer"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We present a new high-order compact scheme for the multi-dimensional\nBlack-Scholes model with application to European Put options on a basket of two\nunderlying assets. The scheme is second-order accurate in time and fourth-order\naccurate in space. Numerical examples confirm that a standard second-order\nfinite difference scheme is significantly outperformed.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07613v1"
    },
    {
        "title": "Switching to non-affine stochastic volatility: A closed-form expansion\n  for the Inverse Gamma model",
        "authors": [
            "Nicolas Langrené",
            "Geoffrey Lee",
            "Zili Zhu"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This paper introduces the Inverse Gamma (IGa) stochastic volatility model\nwith time-dependent parameters, defined by the volatility dynamics\n$dV_{t}=\\kappa_{t}\\left(\\theta_{t}-V_{t}\\right)dt+\\lambda_{t}V_{t}dB_{t}$. This\nnon-affine model is much more realistic than classical affine models like the\nHeston stochastic volatility model, even though both are as parsimonious (only\nfour stochastic parameters). Indeed, it provides more realistic volatility\ndistribution and volatility paths, which translate in practice into more robust\ncalibration and better hedging accuracy, explaining its popularity among\npractitioners. In order to price vanilla options with IGa volatility, we\npropose a closed-form volatility-of-volatility expansion. Specifically, the\nprice of a European put option with IGa volatility is approximated by a\nBlack-Scholes price plus a weighted combination of Black-Scholes greeks, where\nthe weights depend only on the four time-dependent parameters of the model.\nThis closed-form pricing method allows for very fast pricing and calibration to\nmarket data. The overall quality of the approximation is very good, as shown by\nseveral calibration tests on real-world market data where expansion prices are\ncompared favorably with Monte Carlo simulation results. This paper shows that\nthe IGa model is as simple, more realistic, easier to implement and faster to\ncalibrate than classical transform-based affine models. We therefore hope that\nthe present work will foster further research on non-affine models like the\nInverse Gamma stochastic volatility model, all the more so as this robust model\nis of great interest to the industry.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.02847v2"
    },
    {
        "title": "Forecasting Leading Death Causes in Australia using Extended\n  CreditRisk$+$",
        "authors": [
            "Pavel V. Shevchenko",
            "Jonas Hirz",
            "Uwe Schmock"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Recently we developed a new framework in Hirz et al (2015) to model\nstochastic mortality using extended CreditRisk$^+$ methodology which is very\ndifferent from traditional time series methods used for mortality modelling\npreviously. In this framework, deaths are driven by common latent stochastic\nrisk factors which may be interpreted as death causes like neoplasms,\ncirculatory diseases or idiosyncratic components. These common factors\nintroduce dependence between policyholders in annuity portfolios or between\ndeath events in population. This framework can be used to construct life tables\nbased on mortality rate forecast. Moreover this framework allows stress testing\nand, therefore, offers insight into how certain health scenarios influence\nannuity payments of an insurer. Such scenarios may include improvement in\nhealth treatments or better medication. In this paper, using publicly available\ndata for Australia, we estimate the model using Markov chain Monte Carlo method\nto identify leading death causes across all age groups including long term\nforecast for 2031 and 2051. On top of general reduced mortality, the proportion\nof deaths for certain certain causes has changed massively over the period 1987\nto 2011. Our model forecasts suggest that if these trends persist, then the\nfuture gives a whole new picture of mortality for people aged above 40 years.\nNeoplasms will become the overall number-one death cause. Moreover, deaths due\nto mental and behavioural disorders are very likely to surge whilst deaths due\nto circulatory diseases will tend to decrease. This potential increase in\ndeaths due to mental and behavioural disorders for older ages will have a\nmassive impact on social systems as, typically, such patients need long-term\ngeriatric care.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.07162v1"
    },
    {
        "title": "Managing Systematic Mortality Risk in Life Annuities: An Application of\n  Longevity Derivatives",
        "authors": [
            "Man Chung Fung",
            "Katja Ignatieva",
            "Michael Sherris"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This paper assesses the hedge effectiveness of an index-based longevity swap\nand a longevity cap. Although swaps are a natural instrument for hedging\nlongevity risk, derivatives with non-linear pay-offs, such as longevity caps,\nalso provide downside protection. A tractable stochastic mortality model with\nage dependent drift and volatility is developed and analytical formulae for\nprices of these longevity derivatives are derived. Hedge effectiveness is\nconsidered for a hypothetical life annuity portfolio. The hedging of the life\nannuity portfolio is comprehensively assessed for a range of assumptions for\nthe market price of longevity risk, the term to maturity of the hedging\ninstruments, as well as the size of the underlying annuity portfolio. The model\nis calibrated using Australian mortality data. The results provide a\ncomprehensive analysis of longevity hedging, highlighting the risk management\nbenefits and costs of linear and nonlinear payoff structures.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.00090v1"
    },
    {
        "title": "A computational spectral approach to interest rate models",
        "authors": [
            "Luca Di Persio",
            "Michele Bonollo",
            "Gregorio Pellegrini"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  The Polynomial Chaos Expansion (PCE) technique recovers a finite second order\nrandom variable exploiting suitable linear combinations of orthogonal\npolynomials which are functions of a given stochas- tic quantity {\\xi}, hence\nacting as a kind of random basis. The PCE methodology has been developed as a\nmathematically rigorous Uncertainty Quantification (UQ) method which aims at\nproviding reliable numerical estimates for some uncertain physical quantities\ndefining the dynamic of certain engineering models and their related\nsimulations. In the present paper we exploit the PCE approach to analyze some\nequity and interest rate models considering, without loss of generality, the\none dimensional case. In particular we will take into account those models\nwhich are based on the Geometric Brownian Motion (gBm), e.g. the Vasicek model,\nthe CIR model, etc. We also provide several numerical applications and results\nwhich are discussed for a set of volatility values. The latter allows us to\ntest the PCE technique on a quite large set of different scenarios, hence\nproviding a rather complete and detailed investigation on PCE-approximation's\nfeatures and properties, such as the convergence of statistics, distribution\nand quantiles. Moreover we give results concerning both an efficiency and an\naccuracy study of our approach by comparing our outputs with the ones obtained\nadopting the Monte Carlo approach in its standard form as well as in its\nenhanced version.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.06236v1"
    },
    {
        "title": "Ninomiya-Victoir scheme: strong convergence, antithetic version and\n  application to multilevel estimators",
        "authors": [
            "Anis Al Gerbi",
            "Benjamin Jourdain",
            "Emmanuelle Clément"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  In this paper, we are interested in the strong convergence properties of the\nNinomiya-Victoir scheme which is known to exhibit weak convergence with order\n2. We prove strong convergence with order $1/2$. This study is aimed at\nanalysing the use of this scheme either at each level or only at the finest\nlevel of a multilevel Monte Carlo estimator: indeed, the variance of a\nmultilevel Monte Carlo estimator is related to the strong error between the two\nschemes used on the coarse and fine grids at each level. Recently, Giles and\nSzpruch proposed a scheme permitting to construct a multilevel Monte Carlo\nestimator achieving the optimal complexity $O\\left(\\epsilon^{-2}\\right)$ for\nthe precision $\\epsilon$. In the same spirit, we propose a modified\nNinomiya-Victoir scheme, which may be strongly coupled with order $1$ to the\nGiles-Szpruch scheme at the finest level of a multilevel Monte Carlo estimator.\nNumerical experiments show that this choice improves the efficiency, since the\norder $2$ of weak convergence of the Ninomiya-Victoir scheme permits to reduce\nthe number of discretization levels.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.06492v2"
    },
    {
        "title": "Kriging Metamodels and Experimental Design for Bermudan Option Pricing",
        "authors": [
            "Michael Ludkovski"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We investigate two new strategies for the numerical solution of optimal\nstopping problems within the Regression Monte Carlo (RMC) framework of\nLongstaff and Schwartz. First, we propose the use of stochastic kriging\n(Gaussian process) meta-models for fitting the continuation value. Kriging\noffers a flexible, nonparametric regression approach that quantifies\napproximation quality. Second, we connect the choice of stochastic grids used\nin RMC to the Design of Experiments paradigm. We examine space-filling and\nadaptive experimental designs; we also investigate the use of batching with\nreplicated simulations at design sites to improve the signal-to-noise ratio.\nNumerical case studies for valuing Bermudan Puts and Max-Calls under a variety\nof asset dynamics illustrate that our methods offer significant reduction in\nsimulation budgets over existing approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.02179v3"
    },
    {
        "title": "Estimating Tipping Points in Feedback-Driven Financial Networks",
        "authors": [
            "Zvonko Kostanjcar",
            "Stjepan Begusic",
            "H. E. Stanley",
            "Boris Podobnik"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Much research has been conducted arguing that tipping points at which complex\nsystems experience phase transitions are difficult to identify. To test the\nexistence of tipping points in financial markets, based on the alternating\noffer strategic model we propose a network of bargaining agents who mutually\neither cooperate or where the feedback mechanism between trading and price\ndynamics is driven by an external \"hidden\" variable R that quantifies the\ndegree of market overpricing. Due to the feedback mechanism, R fluctuates and\noscillates over time, and thus periods when the market is underpriced and\noverpriced occur repeatedly. As the market becomes overpriced, bubbles are\ncreated that ultimately burst in a market crash. The probability that the index\nwill drop in the next year exhibits a strong hysteresis behavior from which we\ncalculate the tipping point. The probability distribution function of R has a\nbimodal shape characteristic of small systems near the tipping point. By\nexamining the S&P500 index we illustrate the applicability of the model and\ndemonstate that the financial data exhibits a hysteresis and a tipping point\nthat agree with the model predictions. We report a cointegration between the\nreturns of the S&P 500 index and its intrinsic value.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.04952v1"
    },
    {
        "title": "Asymptotic Expansion for Forward-Backward SDEs with Jumps",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This work provides a semi-analytic approximation method for decoupled\nforwardbackward SDEs (FBSDEs) with jumps. In particular, we construct an\nasymptotic expansion method for FBSDEs driven by the random Poisson measures\nwith {\\sigma}-finite compensators as well as the standard Brownian motions\naround the small-variance limit of the forward SDE. We provide a semi-analytic\nsolution technique as well as its error estimate for which we only need to\nsolve essentially a system of linear ODEs. In the case of a finite jump measure\nwith a bounded intensity, the method can also handle state-dependent and hence\nnon-Poissonian jumps, which are quite relevant for many practical applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.03220v4"
    },
    {
        "title": "Studies on Regional Wealth Inequalities: the case of Italy",
        "authors": [
            "Marcel Ausloos",
            "Roy Cerqueti"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  The paper contains a short review of techniques examining regional wealth\ninequalities based on recently published research work but is also presenting\nunpublished features.\n  The data pertains to Italy (IT), over the period 2007-2011: the number of\ncities in regions, the number of inhabitants in cities and in regions, as well\nas the aggregated tax income of the cities and of regions. Frequency-size plots\nand cumulative distribution function plots, scatter plots and rank-size plots\nare displayed. The rank-size rule of a few cases is discussed. Yearly data of\nthe aggregated tax income is transformed into a few indicators: the Gini,\nTheil, and Herfindahl-Hirschman indices. Numerical results confirm that IT is\ndivided into very different regional realities. One region is selected for a\nshort discussion: Molise.\n  A note on the \"first digit Benford law\" for testing data validity is\npresented.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.05356v1"
    },
    {
        "title": "Alpha-CIR Model with Branching Processes in Sovereign Interest Rate\n  Modelling",
        "authors": [
            "Ying Jiao",
            "Chunhua Ma",
            "Simone Scotti"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We introduce a class of interest rate models, called the $\\alpha$-CIR model,\nwhich gives a natural extension of the standard CIR model by adopting the\n$\\alpha$-stable L{\\'e}vy process and preserving the branching property. This\nmodel allows to describe in a unified and parsimonious way several recent\nobservations on the sovereign bond market such as the persistency of low\ninterest rate together with the presence of large jumps at local extent. We\nemphasize on a general integral representation of the model by using random\nfields, with which we establish the link to the CBI processes and the affine\nmodels. Finally we analyze the jump behaviors and in particular the large\njumps, and we provide numerical illustrations.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.05541v2"
    },
    {
        "title": "Kriging of financial term-structures",
        "authors": [
            "Areski Cousin",
            "Hassan Maatouk",
            "Didier Rullière"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  Due to the lack of reliable market information, building financial\nterm-structures may be associated with a significant degree of uncertainty. In\nthis paper, we propose a new term-structure interpolation method that extends\nclassical spline techniques by additionally allowing for quantification of\nuncertainty. The proposed method is based on a generalization of kriging models\nwith linear equality constraints (market-fit conditions) and shape-preserving\nconditions such as monotonicity or positivity (no-arbitrage conditions). We\ndefine the most likely curve and show how to build confidence bands. The\nGaussian process covariance hyper-parameters under the construction constraints\nare estimated using cross-validation techniques. Based on observed market\nquotes at different dates, we demonstrate the efficiency of the method by\nbuilding curves together with confidence intervals for term-structures of OIS\ndiscount rates, of zero-coupon swaps rates and of CDS implied default\nprobabilities. We also show how to construct interest-rate surfaces or default\nprobability surfaces by considering time (quotation dates) as an additional\ndimension.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02237v1"
    },
    {
        "title": "The subjective discount factor and the coefficient of relative risk\n  aversion under time-additive isoelastic expected utility model",
        "authors": [
            "Dominique Pepin"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  By analysing the restrictions that ensure the existence of capital market\nequilibrium, we show that the coefficient of relative risk aversion and the\nsubjective discount factor cannot be high simultaneously as they are supposed\nto be to make the standard asset pricing consistent with financial stylised\nfacts.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.03337v2"
    },
    {
        "title": "High order finite difference schemes on non-uniform meshes for the\n  time-fractional Black-Scholes equation",
        "authors": [
            "Yuri M. Dimitrov",
            "Lubin G. Vulkov"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We construct a three-point compact finite difference scheme on a non-uniform\nmesh for the time-fractional Black-Scholes equation. We show that for special\ngraded meshes used in finance, the Tavella-Randall and the quadratic meshes the\nnumerical solution has a fourth-order accuracy in space. Numerical experiments\nare discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.05178v1"
    },
    {
        "title": "Optimal trading with online parameters revisions",
        "authors": [
            "N Baradel",
            "B Bouchard",
            "Ngoc Minh Dang"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  The aim of this paper is to explain how parameters adjustments can be\nintegrated in the design or the control of automates of trading. Typically, we\nare interested by the online estimation of the market impacts generated by\nrobots or single orders, and how they/the controller should react in an optimal\nway to the informations generated by the observation of the realized impacts.\nThis can be formulated as an optimal impulse control problem with unknown\nparameters, on which a prior is given. We explain how a mix of the classical\nBayesian updating rule and of optimal control techniques allows one to derive\nthe dynamic programming equation satisfied by the corresponding value function,\nfrom which the optimal policy can be inferred. We provide an example of\nconvergent finite difference scheme and consider typical examples of\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.06342v1"
    },
    {
        "title": "The Problem of Calibrating an Agent-Based Model of High-Frequency\n  Trading",
        "authors": [
            "Donovan Platt",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  Agent-based models, particularly those applied to financial markets,\ndemonstrate the ability to produce realistic, simulated system dynamics,\ncomparable to those observed in empirical investigations. Despite this, they\nremain fairly difficult to calibrate due to their tendency to be\ncomputationally expensive, even with recent advances in technology. For this\nreason, financial agent-based models are frequently validated by demonstrating\nan ability to reproduce well-known log return time series and central limit\norder book stylized facts, as opposed to being rigorously calibrated to\ntransaction data. We thus apply an established financial agent-based model\ncalibration framework to a simple model of high- and low-frequency trader\ninteraction and demonstrate possible inadequacies of a stylized fact-centric\napproach to model validation. We further argue for the centrality of\ncalibration to the validation of financial agent-based models and possible\npitfalls of current approaches to financial agent-based modeling.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.01495v4"
    },
    {
        "title": "Solving Backward Stochastic Differential Equations with quadratic-growth\n  drivers by Connecting the Short-term Expansions",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  This article proposes a new approximation scheme for quadratic-growth BSDEs\nin a Markovian setting by connecting a series of semi-analytic asymptotic\nexpansions applied to short-time intervals. Although there remains a condition\nwhich needs to be checked a posteriori, one can avoid altogether time-consuming\nMonte Carlo simulation and other numerical integrations for estimating\nconditional expectations at each space-time node. Numerical examples of\nquadratic-growth as well as Lipschitz BSDEs suggest that the scheme works well\neven for large quadratic coefficients, and a fortiori for large Lipschitz\nconstants.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.04285v5"
    },
    {
        "title": "Vibrato and automatic differentiation for high order derivatives and\n  sensitivities of financial options",
        "authors": [
            "Gilles Pagès",
            "Olivier Pironneau",
            "Guillaume Sall"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  This paper deals with the computation of second or higher order greeks of\nfinancial securities. It combines two methods, Vibrato and automatic\ndifferentiation and compares with other methods. We show that this combined\ntechnique is faster than standard finite difference, more stable than automatic\ndifferentiation of second order derivatives and more general than Malliavin\nCalculus. We present a generic framework to compute any greeks and present\nseveral applications on different types of financial contracts: European and\nAmerican options, multidimensional Basket Call and stochastic volatility models\nsuch as Heston's model. We give also an algorithm to compute derivatives for\nthe Longstaff-Schwartz Monte Carlo method for American options. We also extend\nautomatic differentiation for second order derivatives of options with\nnon-twice differentiable payoff. 1. Introduction. Due to BASEL III regulations,\nbanks are requested to evaluate the sensitivities of their portfolios every day\n(risk assessment). Some of these portfolios are huge and sensitivities are time\nconsuming to compute accurately. Faced with the problem of building a software\nfor this task and distrusting automatic differentiation for non-differentiable\nfunctions, we turned to an idea developed by Mike Giles called Vibrato. Vibrato\nat core is a differentiation of a combination of likelihood ratio method and\npathwise evaluation. In Giles [12], [13], it is shown that the computing time,\nstability and precision are enhanced compared with numerical differentiation of\nthe full Monte Carlo path. In many cases, double sensitivities, i.e. second\nderivatives with respect to parameters, are needed (e.g. gamma hedging). Finite\ndifference approximation of sensitivities is a very simple method but its\nprecision is hard to control because it relies on the appropriate choice of the\nincrement. Automatic differentiation of computer programs bypass the difficulty\nand its computing cost is similar to finite difference, if not cheaper. But in\nfinance the payoff is never twice differentiable and so generalized derivatives\nhave to be used requiring approximations of Dirac functions of which the\nprecision is also doubtful. The purpose of this paper is to investigate the\nfeasibility of Vibrato for second and higher derivatives. We will first compare\nVibrato applied twice with the analytic differentiation of Vibrato and show\nthat it is equivalent, as the second is easier we propose the best compromise\nfor second derivatives: Automatic Differentiation of Vibrato. In [8], Capriotti\nhas recently investigated the coupling of different mathematical methods --\nnamely pathwise and likelihood ratio methods -- with an Automatic differ\n",
        "pdf_link": "http://arxiv.org/pdf/1606.06143v1"
    },
    {
        "title": "Smoothing the payoff for efficient computation of Basket option prices",
        "authors": [
            "Christian Bayer",
            "Markus Siebenmorgen",
            "Raul Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We consider the problem of pricing basket options in a multivariate Black\nScholes or Variance Gamma model. From a numerical point of view, pricing such\noptions corresponds to moderate and high dimensional numerical integration\nproblems with non-smooth integrands. Due to this lack of regularity, higher\norder numerical integration techniques may not be directly available, requiring\nthe use of methods like Monte Carlo specifically designed to work for\nnon-regular problems. We propose to use the inherent smoothing property of the\ndensity of the underlying in the above models to mollify the payoff function by\nmeans of an exact conditional expectation. The resulting conditional\nexpectation is unbiased and yields a smooth integrand, which is amenable to the\nefficient use of adaptive sparse grid cubature. Numerical examples indicate\nthat the high-order method may perform orders of magnitude faster compared to\nMonte Carlo or Quasi Monte Carlo in dimensions up to 35.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.05572v2"
    },
    {
        "title": "Causality and Correlations between BSE and NYSE indexes: A Janus Faced\n  Relationship",
        "authors": [
            " Neeraj",
            "Prasanta K. Panigrahi"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We study the multi-scale temporal correlations and causality connections\nbetween the New York Stock Exchange (NYSE) and Bombay Stock Exchange (BSE)\nmonthly average closing price indexes for a period of 300 months, encompassing\nthe time period of the liberalisation of the Indian economy and its gradual\nglobal exposure. In multi-scale analysis; clearly identifiable 1, 2 and 3 year\nnon-stationary periodic modulations in NYSE and BSE have been observed, with\nNYSE commensurating changes in BSE at 3 years scale. Interestingly, at one year\ntime scale, the two exchanges are phase locked only during the turbulent times,\nwhile at the scale of three year, in-phase nature is observed for a much longer\ntime frame. The two year time period, having characteristics of both one and\nthree year variations, acts as the transition regime. The normalised NYSE's\nstock value is found to Granger cause those of BSE, with a time lag of 9\nmonths. Surprisingly, observed Granger causality of high frequency variations\nreveals BSE behaviour getting reflected in the NYSE index fluctuations, after a\nsmaller time lag. This Janus faced relationship, shows that smaller stock\nexchanges may provide a natural setting for simulating market fluctuations of\nmuch bigger exchanges. This possibly arises due to the fact that high frequency\nfluctuations form an universal part of the financial time series, and are\nexpected to exhibit similar characteristics in open market economies.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.07796v1"
    },
    {
        "title": "Biased Roulette Wheel: A Quantitative Trading Strategy Approach",
        "authors": [
            "Giancarlo Salirrosas Martínez"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  The purpose of this research paper it is to present a new approach in the\nframework of a biased roulette wheel. It is used the approach of a quantitative\ntrading strategy, commonly used in quantitative finance, in order to assess the\nprofitability of the strategy in the short term. The tools of backtesting and\nwalk-forward optimization were used to achieve such task. The data has been\ngenerated from a real European roulette wheel from an on-line casino based in\nRiga, Latvia. It has been recorded 10,980 spins and sent to the computer\nthrough a voice-to-text software for further numerical analysis in R. It has\nbeen observed that the probabilities of occurrence of the numbers at the\nroulette wheel follows an Ornstein-Uhlenbeck process. Moreover, it is shown\nthat a flat betting system against Kelly Criterion was more profitable in the\nshort term.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.09601v1"
    },
    {
        "title": "An Agent-based Model of Contagion in Financial Networks",
        "authors": [
            "Leonardo dos Santos Pinheiro",
            "Flavio Codeco COelho"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This work develops an agent-based model for the study of how the leverage\nthrough the use of repurchase agreements can function as a mechanism for the\npropagation and amplification of financial shocks in a financial system. Based\non the analysis of financial intermediaries in the repo and interbank lending\nmarkets during the 2007-08 financial crisis we develop a model that can be used\nto simulate the dynamics of financial contagion.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.07513v1"
    },
    {
        "title": "A Numerical Method for Pricing Discrete Double Barrier Option by\n  Legendre Multiwavelet",
        "authors": [
            "Amirhossein Sobhani",
            "Mariyan Milev"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this Article, a fast numerical numerical algorithm for pricing discrete\ndouble barrier option is presented. According to Black-Scholes model, the price\nof option in each monitoring date can be evaluated by a recursive formula upon\nthe heat equation solution. These recursive solutions are approximated by using\nLegendre multiwavelets as orthonormal basis functions and expressed in\noperational matrix form. The most important feature of this method is that its\nCPU time is nearly invariant when monitoring dates increase. Besides, the rate\nof convergence of presented algorithm was obtained. The numerical results\nverify the validity and efficiency of the numerical method.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.09129v2"
    },
    {
        "title": "FIEMS: Fast Italian Energy Market Simulator",
        "authors": [
            "Matteo Gardini",
            "Marco Diana"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The article describes the algorithm used to define the electricity price in\nday-ahead and itraday energy markets in Italy. Details of Matlab implementation\nof one of its simplified versions, capable of producing good results in a\nextremely short time, are then provided and numerical results are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.09782v1"
    },
    {
        "title": "On a pricing problem for a multi-asset option with general transaction\n  costs",
        "authors": [
            "Pablo Amster",
            "Andres P. Mogni"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We consider a Black-Scholes type equation arising on a pricing model for a\nmulti-asset option with general transaction costs. The pioneering work of\nLeland is thus extended in two different ways: on the one hand, the problem is\nmulti-dimensional since it involves different underlying assets; on the other\nhand, the transaction costs are not assumed to be constant (i.e. a fixed\nproportion of the traded quantity). In this work, we generalize Leland's\ncondition and prove the existence of a viscosity solution for the corresponding\nfully nonlinear initial value problem using Perron method. Moreover, we develop\na numerical ADI scheme to find an approximated solution. We apply this method\non a specific multi-asset derivative and we obtain the option price under\ndifferent pricing scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.02036v2"
    },
    {
        "title": "An empirical behavioural order-driven model with price limit rules",
        "authors": [
            "Gao-Feng Gu",
            "Xiong Xiong",
            "Hai-Chuan Xu",
            "Wei Zhang",
            "Yong-Jie Zhang",
            "Wei Chen",
            "Wei-Xing Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We develop an empirical behavioural order-driven (EBOD) model, which consists\nof an order placement process and an order cancellation process. Price limit\nrules are introduced in the definition of relative price. The order placement\nprocess is determined by several empirical regularities: the long memory in\norder directions, the long memory in relative prices, the asymmetric\ndistribution of relative prices, and the nonlinear dependence of the average\norder size and its standard deviation on the relative price. Order cancellation\nfollows a Poisson process with the arrival rate determined from real data and\nthe cancelled order is determined according to the empirical distributions of\nrelative price level and relative position at the same price level. All these\ningredients of the model are derived based on the empirical microscopic\nregularities in the order flows of stocks on the Shenzhen Stock Exchange. The\nmodel is able to produce the main stylized facts in real markets. Computational\nexperiments uncover that asymmetric setting of price limits will cause the\nstock price diverging exponentially when the up price limit is higher than the\ndown price limit and vanishing vice versus. We also find that asymmetric price\nlimits have influences on stylized facts. Our EBOD model provides a suitable\ncomputational experiment platform for academics, market participants and policy\nmakers.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.04354v1"
    },
    {
        "title": "High-order compact finite difference scheme for option pricing in\n  stochastic volatility jump models",
        "authors": [
            "Bertram Düring",
            "Alexander Pitkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We derive a new high-order compact finite difference scheme for option\npricing in stochastic volatility jump models, e.g. in Bates model. In such\nmodels the option price is determined as the solution of a partial\nintegro-differential equation. The scheme is fourth order accurate in space and\nsecond order accurate in time. Numerical experiments for the European option\npricing problem are presented. We validate the stability of the scheme\nnumerically and compare its performance to standard finite difference and\nfinite element methods. The new scheme outperforms a standard discretisation\nbased on a second-order central finite difference approximation in all our\nexperiments. At the same time, it is very efficient, requiring only one initial\n$LU$-factorisation of a sparse matrix to perform the option price valuation.\nCompared to finite element approaches, it is very parsimonious in terms of\nmemory requirements and computational effort, since it achieves high-order\nconvergence without requiring additional unknowns, unlike finite element\nmethods with higher polynomial order basis functions. The new high-order\ncompact scheme can also be useful to upgrade existing implementations based on\nstandard finite differences in a straightforward manner to obtain a highly\nefficient option pricing code.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.05308v2"
    },
    {
        "title": "Towards the Exact Simulation Using Hyperbolic Brownian Motion",
        "authors": [
            "Yuuki Ida",
            "Yuri Imamura"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In the present paper, an expansion of the transition density of Hyperbolic\nBrownian motion with drift is given, which is potentially useful for pricing\nand hedging of options under stochastic volatility models. We work on a\ncondition on the drift which dramatically simplifies the proof.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00864v1"
    },
    {
        "title": "Turbocharging Monte Carlo pricing for the rough Bergomi model",
        "authors": [
            "Ryan McCrickerd",
            "Mikko S. Pakkanen"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The rough Bergomi model, introduced by Bayer, Friz and Gatheral [Quant.\nFinance 16(6), 887-904, 2016], is one of the recent rough volatility models\nthat are consistent with the stylised fact of implied volatility surfaces being\nessentially time-invariant, and are able to capture the term structure of skew\nobserved in equity markets. In the absence of analytical European option\npricing methods for the model, we focus on reducing the runtime-adjusted\nvariance of Monte Carlo implied volatilities, thereby contributing to the\nmodel's calibration by simulation. We employ a novel composition of variance\nreduction methods, immediately applicable to any conditionally log-normal\nstochastic volatility model. Assuming one targets implied volatility estimates\nwith a given degree of confidence, thus calibration RMSE, the results we\ndemonstrate equate to significant runtime reductions - roughly 20 times on\naverage, across different correlation regimes.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.02563v3"
    },
    {
        "title": "Random walks and market efficiency in Chinese and Indian equity markets",
        "authors": [
            "Oleg Malafeyev",
            "Achal Awasthi",
            "Kaustubh S. Kambekar"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Hypothesis of Market Efficiency is an important concept for the investors\nacross the globe holding diversified portfolios. With the world economy getting\nmore integrated day by day, more people are investing in global emerging\nmarkets. This means that it is pertinent to understand the efficiency of these\nmarkets. This paper tests for market efficiency by studying the impact of\nglobal financial crisis of 2008 and the recent Chinese crisis of 2015 on stock\nmarket efficiency in emerging stock markets of China and India. The data for\nlast 20 years was collected from both Bombay Stock Exchange (BSE200) and the\nShanghai Stock Exchange Composite Index and divided into four sub-periods, i.e.\nbefore financial crisis period (period-I), during recession (period-II), after\nrecession and before Chinese Crisis (periodIII) and from the start of Chinese\ncrisis till date (period- IV). Daily returns for the SSE and BSE were examined\nand tested for randomness using a combination of auto correlation tests, runs\ntests and unit root tests (Augmented Dickey-Fuller) for the entire sample\nperiod and the four sub-periods. The evidence from all these tests supports\nthat both the Indian and Chinese stock markets do not exhibit weak form of\nmarket efficiency. They do not follow random walk overall and in the first\nthree periods (1996 till the 2015) implying that recession did not impact the\nmarkets to a great extent, although the efficiency in percentage terms seems to\nbe increasing after the global financial crisis of 2008.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.04059v1"
    },
    {
        "title": "The Calibration of Stochastic-Local Volatility Models - An Inverse\n  Problem Perspective",
        "authors": [
            "Yuri F. Saporito",
            "Xu Yang",
            "Jorge P. Zubelli"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We tackle the calibration of the so-called Stochastic-Local Volatility (SLV)\nmodel. This is the class of financial models that combines the local and\nstochastic volatility features and has been subject of the attention by many\nresearchers recently. More precisely, given a local volatility surface and a\nchoice of stochastic volatility parameters, we calibrate the corresponding\nleverage function. Our approach makes use of regularization techniques from the\ninverse-problem theory, respecting the integrity of the data and thus avoiding\ndata interpolation. The result is a stable and robust algorithm which is\nresilient to instabilities in the regions of low probability density of the\nspot price and of the instantaneous variance. We substantiate our claims with\nnumerical experiments using simulated as well as real data.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.03023v1"
    },
    {
        "title": "Efficient Exponential Tilting for Portfolio Credit Risk",
        "authors": [
            "Cheng-Der Fuh",
            "Chuan-Ju Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This paper considers the problem of measuring the credit risk in portfolios\nof loans, bonds, and other instruments subject to possible default under\nmulti-factor models. Due to the amount of the portfolio, the heterogeneous\neffect of obligors, and the phenomena that default events are rare and mutually\ndependent, it is difficult to calculate portfolio credit risk either by means\nof direct analysis or crude Monte Carlo under such models. To capture the\nextreme dependence among obligors, we provide an efficient simulation method\nfor multi-factor models with a normal mixture copula that allows the\nmultivariate defaults to have an asymmetric distribution, while most of the\nliterature focuses on simulating one-dimensional cases. To this end, we first\npropose a general account of an importance sampling algorithm based on an\nunconventional exponential embedding, which is related to the classical\nsufficient statistic. Note that this innovative tilting device is more suitable\nfor the multivariate normal mixture model than traditional one-parameter\ntilting methods and is of independent interest. Next, by utilizing a fast\ncomputational method for how the rare event occurs and the proposed importance\nsampling method, we provide an efficient simulation algorithm to estimate the\nprobability that the portfolio incurs large losses under the normal mixture\ncopula. Here the proposed simulation device is based on importance sampling for\na joint probability other than the conditional probability used in previous\nstudies. Theoretical investigations and simulation studies, which include an\nempirical example, are given to illustrate the method.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.03744v6"
    },
    {
        "title": "A particle model for the herding phenomena induced by dynamic market\n  signals",
        "authors": [
            "Hyeong-Ohk Bae",
            "Seung-yeon Cho",
            "Sang-hyeok Lee",
            "Seok-Bae Yun"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this paper, we study the herding phenomena in financial markets arising\nfrom the combined effect of (1) non-coordinated collective interactions between\nthe market players and (2) concurrent reactions of market players to dynamic\nmarket signals. By interpreting the expected rate of return of an asset and the\nfavorability on that asset as position and velocity in phase space, we\nconstruct an agent-based particle model for herding behavior in finance. We\nthen define two types of herding functionals using this model, and show that\nthey satisfy a Gronwall type estimate and a LaSalle type invariance property\nrespectively, leading to the herding behavior of the market players. Various\nnumerical tests are presented to numerically verify these results.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.01085v1"
    },
    {
        "title": "QLBS: Q-Learner in the Black-Scholes(-Merton) Worlds",
        "authors": [
            "Igor Halperin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This paper presents a discrete-time option pricing model that is rooted in\nReinforcement Learning (RL), and more specifically in the famous Q-Learning\nmethod of RL. We construct a risk-adjusted Markov Decision Process for a\ndiscrete-time version of the classical Black-Scholes-Merton (BSM) model, where\nthe option price is an optimal Q-function, while the optimal hedge is a second\nargument of this optimal Q-function, so that both the price and hedge are parts\nof the same formula. Pricing is done by learning to dynamically optimize\nrisk-adjusted returns for an option replicating portfolio, as in the Markowitz\nportfolio theory. Using Q-Learning and related methods, once created in a\nparametric setting, the model is able to go model-free and learn to price and\nhedge an option directly from data, and without an explicit model of the world.\nThis suggests that RL may provide efficient data-driven and model-free methods\nfor optimal pricing and hedging of options, once we depart from the academic\ncontinuous-time limit, and vice versa, option pricing methods developed in\nMathematical Finance may be viewed as special cases of model-based\nReinforcement Learning. Further, due to simplicity and tractability of our\nmodel which only needs basic linear algebra (plus Monte Carlo simulation, if we\nwork with synthetic data), and its close relation to the original BSM model, we\nsuggest that our model could be used for benchmarking of different RL\nalgorithms for financial trading applications\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04609v3"
    },
    {
        "title": "Optimal Stochastic Decensoring and Applications to Calibration of Market\n  Models",
        "authors": [
            "Anastasis Kratsios"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Typically flat filling, linear or polynomial interpolation methods to\ngenerate missing historical data. We introduce a novel optimal method for\nrecreating data generated by a diffusion process. The results are then applied\nto recreate historical data for stocks.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04844v2"
    },
    {
        "title": "Pricing double barrier options on homogeneous diffusions: a Neumann\n  series of Bessel functions representation",
        "authors": [
            "Igor V. Kravchenko",
            "Vladislav V. Kravchenko",
            "Sergii M. Torba",
            "José Carlos Dias"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  This paper develops a novel analytically tractable Neumann series of Bessel\nfunctions representation for pricing (and hedging) European-style double\nbarrier knock-out options, which can be applied to the whole class of\none-dimensional time-homogeneous diffusions even for the cases where the\ncorresponding transition density is not known. The proposed numerical method is\nshown to be efficient and simple to implement. To illustrate the flexibility\nand computational power of the algorithm, we develop an extended jump to\ndefault model that is able to capture several empirical regularities commonly\nobserved in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.08247v1"
    },
    {
        "title": "Part 1: Training Sets & ASG Transforms",
        "authors": [
            "Rilwan Adewoyin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this paper, I discuss a method to tackle the issues arising from the small\ndata-sets available to data-scientists when building price predictive\nalgorithms that use monthly/quarterly macro-financial indicators. I approach\nthis by training separate classifiers on the equivalent dataset from a range of\ncountries. Using these classifiers, a three level meta learning algorithm (MLA)\nis developed. I develop a transform, ASG, to create a country agnostic proxy\nfor the macro-financial indicators. Using these proposed methods, I investigate\nthe degree to which a predictive algorithm for the US 5Y bond price,\npredominantly using macro-financial indicators, can outperform an identical\nalgorithm which only uses statistics deriving from previous price.\n  This was an undergraduate project, subsequently the research was not\nexhaustive.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05752v2"
    },
    {
        "title": "The QLBS Q-Learner Goes NuQLear: Fitted Q Iteration, Inverse RL, and\n  Option Portfolios",
        "authors": [
            "Igor Halperin"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The QLBS model is a discrete-time option hedging and pricing model that is\nbased on Dynamic Programming (DP) and Reinforcement Learning (RL). It combines\nthe famous Q-Learning method for RL with the Black-Scholes (-Merton) model's\nidea of reducing the problem of option pricing and hedging to the problem of\noptimal rebalancing of a dynamic replicating portfolio for the option, which is\nmade of a stock and cash. Here we expand on several NuQLear (Numerical\nQ-Learning) topics with the QLBS model. First, we investigate the performance\nof Fitted Q Iteration for a RL (data-driven) solution to the model, and\nbenchmark it versus a DP (model-based) solution, as well as versus the BSM\nmodel. Second, we develop an Inverse Reinforcement Learning (IRL) setting for\nthe model, where we only observe prices and actions (re-hedges) taken by a\ntrader, but not rewards. Third, we outline how the QLBS model can be used for\npricing portfolios of options, rather than a single option in isolation, thus\nproviding its own, data-driven and model independent solution to the (in)famous\nvolatility smile problem of the Black-Scholes model.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.06077v1"
    },
    {
        "title": "Target volatility option pricing in lognormal fractional SABR model",
        "authors": [
            "Elisa Alos",
            "Rupak Chatterjee",
            "Sebastian Tudor",
            "Tai-Ho Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We examine in this article the pricing of target volatility options in the\nlognormal fractional SABR model. A decomposition formula by Ito's calculus\nyields a theoretical replicating strategy for the target volatility option,\nassuming the accessibilities of all variance swaps and swaptions. The same\nformula also suggests an approximation formula for the price of target\nvolatility option in small time by the technique of freezing the coefficient.\nAlternatively, we also derive closed formed expressions for a small volatility\nof volatility expansion of the price of target volatility option. Numerical\nexperiments show accuracy of the approximations in a reasonably wide range of\nparameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08215v1"
    },
    {
        "title": "A bright future for financial agent-based models",
        "authors": [
            "J. Lussange",
            "A. Belianin",
            "S. Bourgeois-Gironde",
            "B. Gutkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The history of research in finance and economics has been widely impacted by\nthe field of Agent-based Computational Economics (ACE). While at the same time\nbeing popular among natural science researchers for its proximity to the\nsuccessful methods of physics and chemistry for example, the field of ACE has\nalso received critics by a part of the social science community for its lack of\nempiricism. Yet recent trends have shifted the weights of these general\narguments and potentially given ACE a whole new range of realism. At the base\nof these trends are found two present-day major scientific breakthroughs: the\nsteady shift of psychology towards a hard science due to the advances of\nneuropsychology, and the progress of artificial intelligence and more\nspecifically machine learning due to increasing computational power and big\ndata. These two have also found common fields of study in the form of\ncomputational neuroscience, and human-computer interaction, among others. We\noutline here the main lines of a computational research study of collective\neconomic behavior via Agent-Based Models (ABM) or Multi-Agent System (MAS),\nwhere each agent would be endowed with specific cognitive and behavioral biases\nknown to the field of neuroeconomics, and at the same time autonomously\nimplement rational quantitative financial strategies updated by machine\nlearning. We postulate that such ABMs would offer a whole new range of realism.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08222v1"
    },
    {
        "title": "Short-term at-the-money asymptotics under stochastic volatility models",
        "authors": [
            "Omar El Euch",
            "Masaaki Fukasawa",
            "Jim Gatheral",
            "Mathieu Rosenbaum"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  A small-time Edgeworth expansion of the density of an asset price is given\nunder a general stochastic volatility model, from which asymptotic expansions\nof put option prices and at-the-money implied volatilities follow. A limit\ntheorem for at-the-money implied volatility skew and curvature is also given as\na corollary. The rough Bergomi model is treated as an example.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08675v3"
    },
    {
        "title": "The Power of Trading Polarity: Evidence from China Stock Market Crash",
        "authors": [
            "Shan Lu",
            "Jichang Zhao",
            "Huiwen Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The imbalance of buying and selling functions profoundly in the formation of\nmarket trends, however, a fine-granularity investigation of the imbalance is\nstill missing. This paper investigates a unique transaction dataset that\nenables us to inspect the imbalance of buying and selling on the man-times\nlevel at high frequency, what we call 'trading polarity', for a large\ncross-section of stocks from Shenzhen Stock Exchange. The trading polarity\nmeasures the market sentiment toward stocks from a view of very essence of\ntrading desire. When using the polarity to examine market crash, we find that\ntrading polarity successfully reflects the changing of market-level behavior in\nterms of its flipping times, depth, and length. We further investigate the\nrelationship between polarity and return. At market-level, trading polarity is\nnegatively correlated with returns, while at stock-level, this correlation\nchanges according to market conditions, which becomes a good signal of market\npsychology transition. Also, the significant correlation disclosed by the\nmarket polarity and market emotion implies that our presented polarity, which\nessentially calculated in the context of high-frequency trading data, can\nreal-timely reflect the sentiment of the market. The trading polarity indeed\nprovides a new way to understand and foresee the market behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01143v1"
    },
    {
        "title": "Multilevel nested simulation for efficient risk estimation",
        "authors": [
            "Michael B. Giles",
            "Abdul-Lateef Haji-Ali"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We investigate the problem of computing a nested expectation of the form\n$\\mathbb{P}[\\mathbb{E}[X|Y]\n\\!\\geq\\!0]\\!=\\!\\mathbb{E}[\\textrm{H}(\\mathbb{E}[X|Y])]$ where $\\textrm{H}$ is\nthe Heaviside function. This nested expectation appears, for example, when\nestimating the probability of a large loss from a financial portfolio. We\npresent a method that combines the idea of using Multilevel Monte Carlo (MLMC)\nfor nested expectations with the idea of adaptively selecting the number of\nsamples in the approximation of the inner expectation, as proposed by (Broadie\net al., 2011). We propose and analyse an algorithm that adaptively selects the\nnumber of inner samples on each MLMC level and prove that the resulting MLMC\nmethod with adaptive sampling has an $\\mathcal{O}\\left(\n\\varepsilon^{-2}|\\log\\varepsilon|^2 \\right)$ complexity to achieve a root\nmean-squared error $\\varepsilon$. The theoretical analysis is verified by\nnumerical experiments on a simple model problem. We also present a stochastic\nroot-finding algorithm that, combined with our adaptive methods, can be used to\ncompute other risk measures such as Value-at-Risk (VaR) and Conditional\nValue-at-Risk (CVaR), with the latter being achieved with\n$\\mathcal{O}\\left(\\varepsilon^{-2}\\right)$ complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.05016v2"
    },
    {
        "title": "Discovering Bayesian Market Views for Intelligent Asset Allocation",
        "authors": [
            "Frank Z. Xing",
            "Erik Cambria",
            "Lorenzo Malandri",
            "Carlo Vercellis"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Along with the advance of opinion mining techniques, public mood has been\nfound to be a key element for stock market prediction. However, how market\nparticipants' behavior is affected by public mood has been rarely discussed.\nConsequently, there has been little progress in leveraging public mood for the\nasset allocation problem, which is preferred in a trusted and interpretable\nway. In order to address the issue of incorporating public mood analyzed from\nsocial media, we propose to formalize public mood into market views, because\nmarket views can be integrated into the modern portfolio theory. In our\nframework, the optimal market views will maximize returns in each period with a\nBayesian asset allocation model. We train two neural models to generate the\nmarket views, and benchmark the model performance on other popular asset\nallocation strategies. Our experimental results suggest that the formalization\nof market views significantly increases the profitability (5% to 10% annually)\nof the simulated portfolio at a given risk level.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.09911v2"
    },
    {
        "title": "Monte Carlo pathwise sensitivities for barrier options",
        "authors": [
            "Thomas Gerstner",
            "Bastian Harrach",
            "Daniel Roth"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The Monte Carlo pathwise sensitivities approach is well established for\nsmooth payoff functions. In this work, we present a new Monte Carlo algorithm\nthat is able to calculate the pathwise sensitivities for discontinuous payoff\nfunctions. Our main tool is to combine the one-step survival idea of Glasserman\nand Staum with the stable differentiation approach of Alm, Harrach, Harrach and\nKeller. As an application we use the derived results for a two-dimensional\ncalibration of a CoCo-Bond, which we model with different types of discretely\nmonitored barrier options.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.03975v4"
    },
    {
        "title": "On the First Hitting Time Density of an Ornstein-Uhlenbeck Process",
        "authors": [
            "Alexander Lipton",
            "Vadim Kaushansky"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we study the classical problem of the first passage hitting\ndensity of an Ornstein--Uhlenbeck process. We give two complementary (forward\nand backward) formulations of this problem and provide semi-analytical\nsolutions for both. The corresponding problems are comparable in complexity. By\nusing the method of heat potentials, we show how to reduce these problems to\nlinear Volterra integral equations of the second kind. For small values of $t$,\nwe solve these equations analytically by using Abel equation approximation; for\nlarger $t$ we solve them numerically. We also provide a comparison with other\nknown methods for finding the hitting density of interest, and argue that our\nmethod has considerable advantages and provides additional valuable insights.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02390v2"
    },
    {
        "title": "Fast Super-Paramagnetic Clustering",
        "authors": [
            "Lionel Yelibi",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We map stock market interactions to spin models to recover their hierarchical\nstructure using a simulated annealing based Super-Paramagnetic Clustering (SPC)\nalgorithm. This is directly compared to a modified implementation of a maximum\nlikelihood approach we call Fast Super-Paramagnetic Clustering (f-SPC). The\nmethods are first applied standard toy test-case problems, and then to a\ndata-set of 447 stocks traded on the New York Stock Exchange (NYSE) over 1249\ndays. The signal to noise ratio of stock market correlation matrices is briefly\nconsidered. Our result recover approximately clusters representative of\nstandard economic sectors and mixed ones whose dynamics shine light on the\nadaptive nature of financial markets and raise concerns relating to the\neffectiveness of industry based static financial market classification in the\nworld of real-time data analytics. A key result is that we show that f-SPC\nmaximum likelihood solutions converge to ones found within the\nSuper-Paramagnetic Phase where the entropy is maximum, and those solutions are\nqualitatively better for high dimensionality data-sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02529v2"
    },
    {
        "title": "Lifting the Heston model",
        "authors": [
            "Eduardo Abi Jaber"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  How to reconcile the classical Heston model with its rough counterpart? We\nintroduce a lifted version of the Heston model with n multi-factors, sharing\nthe same Brownian motion but mean reverting at different speeds. Our model\nnests as extreme cases the classical Heston model (when n = 1), and the rough\nHeston model (when n goes to infinity). We show that the lifted model enjoys\nthe best of both worlds: Markovianity and satisfactory fits of implied\nvolatility smiles for short maturities with very few parameters. Further, our\napproach speeds up the calibration time and opens the door to time-efficient\nsimulation schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.04868v2"
    },
    {
        "title": "Scaling Features of Price-Volume Cross-Correlation",
        "authors": [
            "Jamshid Ardalankia",
            "Mohammad Osoolian",
            "Emmanuel Haven",
            "G. Reza Jafari"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Price without transaction makes no sense. Trading volume authenticates its\ncorresponding price, so there exist mutual information and correlation between\nprice and trading volume. We are curious about fractal features of this\ncorrelation and need to know how structures in different scales translate\ninformation. To explore the influence of investment size (trading volume),\nprice-wise (gain/loss), and time-scale effects, we analyzed the price and\ntrading volume and their coupling by applying the MF-DXA method. Our results\nimply that price, trading volume, and price-volume coupling exhibit a power law\nand are also multifractal. Meanwhile, considering developed markets, the\nprice-volume couplings are significantly negatively correlated. However, in\nemerging markets, the price has less of a contribution to price-volume\ncoupling. In emerging markets in comparison with the developed markets, trading\nvolume and price are more independent.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.01744v2"
    },
    {
        "title": "Multimodal Deep Learning for Finance: Integrating and Forecasting\n  International Stock Markets",
        "authors": [
            "Sang Il Lee",
            "Seong Joon Yoo"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In today's increasingly international economy, return and volatility\nspillover effects across international equity markets are major macroeconomic\ndrivers of stock dynamics. Thus, information regarding foreign markets is one\nof the most important factors in forecasting domestic stock prices. However,\nthe cross-correlation between domestic and foreign markets is highly complex.\nHence, it is extremely difficult to explicitly express this cross-correlation\nwith a dynamical equation. In this study, we develop stock return prediction\nmodels that can jointly consider international markets, using multimodal deep\nlearning. Our contributions are three-fold: (1) we visualize the transfer\ninformation between South Korea and US stock markets by using scatter plots;\n(2) we incorporate the information into the stock prediction models with the\nhelp of multimodal deep learning; (3) we conclusively demonstrate that the\nearly and intermediate fusion models achieve a significant performance boost in\ncomparison with the late fusion and single modality models. Our study indicates\nthat jointly considering international stock markets can improve the prediction\naccuracy and deep neural networks are highly effective for such tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.06478v2"
    },
    {
        "title": "A fast method for pricing American options under the variance gamma\n  model",
        "authors": [
            "Weilong Fu",
            "Ali Hirsa"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We investigate methods for pricing American options under the variance gamma\nmodel. The variance gamma process is a pure jump process which is constructed\nby replacing the calendar time by the gamma time in a Brownian motion with\ndrift, which makes it a time-changed Brownian motion. In general, the finite\ndifference method and the simulation method can be used for pricing under this\nmodel, but their speed is not satisfactory. So there is a need for fast but\naccurate approximation methods. In the case of Black-Merton-Scholes model,\nthere are fast approximation methods, but they cannot be utilized for the\nvariance gamma model. We develop a new fast method inspired by the quadratic\napproximation method, while reducing the error by making use of a machine\nlearning technique on pre-calculated quantities. We compare the performance of\nour proposed method with those of the existing methods and show that this\nmethod is efficient and accurate for practical use.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.07519v1"
    },
    {
        "title": "Stacked Monte Carlo for option pricing",
        "authors": [
            "Antoine Jacquier",
            "Emma R. Malone",
            "Mugad Oumgari"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We introduce a stacking version of the Monte Carlo algorithm in the context\nof option pricing. Introduced recently for aeronautic computations, this simple\ntechnique, in the spirit of current machine learning ideas, learns control\nvariates by approximating Monte Carlo draws with some specified function. We\ndescribe the method from first principles and suggest appropriate fits, and\nshow its efficiency to evaluate European and Asian Call options in constant and\nstochastic volatility models.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.10795v1"
    },
    {
        "title": "A Stochastic Control Approach to Defined Contribution Plan Decumulation:\n  \"The Nastiest, Hardest Problem in Finance\"",
        "authors": [
            "Peter A. Forsyth"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We pose the decumulation strategy for a Defined Contribution (DC) pension\nplan as a problem in optimal stochastic control. The controls are the\nwithdrawal amounts and the asset allocation strategy. We impose maximum and\nminimum constraints on the withdrawal amounts, and impose no-shorting\nno-leverage constraints on the asset allocation strategy. Our objective\nfunction measures reward as the expected total withdrawals over the\ndecumulation horizon, and risk is measured by Expected Shortfall (ES) at the\nend of the decumulation period. We solve the stochastic control problem\nnumerically, based on a parametric model of market stochastic processes. We\nfind that, compared to a fixed constant withdrawal strategy, with minimum\nwithdrawal set to the constant withdrawal amount, the optimal strategy has a\nsignificantly higher expected average withdrawal, at the cost of a very small\nincrease in ES risk. Tests on bootstrapped resampled historical market data\nindicate that this strategy is robust to parametric model misspecification.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.06598v1"
    },
    {
        "title": "A short introduction to quasi-Monte Carlo option pricing",
        "authors": [
            "Gunther Leobacher"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  One of the main practical applications of quasi-Monte Carlo (QMC) methods is\nthe valuation of financial derivatives. We aim to give a short introduction\ninto option pricing and show how it is facilitated using QMC. We give some\npractical examples for illustration.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.04293v2"
    },
    {
        "title": "Discrete-type approximations for non-Markovian optimal stopping\n  problems: Part II",
        "authors": [
            "Sérgio C. Bezerra",
            "Alberto Ohashi",
            "Francesco Russo",
            "Francys de Souza"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this paper, we present a Longstaff-Schwartz-type algorithm for optimal\nstopping time problems based on the Brownian motion filtration. The algorithm\nis based on Le\\~ao, Ohashi and Russo and, in contrast to previous works, our\nmethodology applies to optimal stopping problems for fully non-Markovian and\nnon-semimartingale state processes such as functionals of path-dependent\nstochastic differential equations and fractional Brownian motions. Based on\nstatistical learning theory techniques, we provide overall error estimates in\nterms of concrete approximation architecture spaces with finite\nVapnik-Chervonenkis dimension. Analytical properties of continuation values for\npath-dependent SDEs and concrete linear architecture approximating spaces are\nalso discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.05250v4"
    },
    {
        "title": "On the range of admissible term-structures",
        "authors": [
            "Areski Cousin",
            "Ibrahima Niang"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In this paper, we analyze the diversity of term structure functions (e.g.,\nyield curves, swap curves, credit curves) constructed in a process which\ncomplies with some admissible properties: arbitrage-freeness, ability to fit\nmarket quotes and a certain degree of smooth- ness. When present values of\nbuilding instruments are expressed as linear combinations of some primary\nquantities such as zero-coupon bonds, discount factor, or survival probabilit-\nies, arbitrage-free bounds can be derived for those quantities at the most\nliquid maturities. As a matter of example, we present an iterative procedure\nthat allows to compute model-free bounds for OIS-implied discount rates and\nCDS-implied default probabilities. We then show how mean-reverting term\nstructure models can be used as generators of admissible curves. This framework\nis based on a particular specification of the mean-reverting level which al-\nlows to perfectly reproduce market quotes of standard vanilla interest-rate and\ndefault-risky securities while preserving a certain degree of smoothness. The\nnumerical results suggest that, for both OIS discounting curves and CDS credit\ncurves, the operational task of term- structure construction may be associated\nwith a significant degree of uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.0340v1"
    },
    {
        "title": "Parallel American Monte Carlo",
        "authors": [
            "Calypso Herrera",
            "Louis Paulot"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  In this paper we introduce a new algorithm for American Monte Carlo that can\nbe used either for American-style options, callable structured products or for\ncomputing counterparty credit risk (e.g. CVA or PFE computation). Leveraging\nleast squares regressions, the main novel feature of our algorithm is that it\ncan be fully parallelized. Moreover, there is no need to store the paths and\nthe payoff computation can be done forwards: this allows to price structured\nproducts with complex path and exercise dependencies. The key idea of our\nalgorithm is to split the set of paths in several subsets which are used\niteratively. We give the convergence rate of the algorithm. We illustrate our\nmethod on an American put option and compare the results with the\nLongstaff-Schwartz algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1180v1"
    },
    {
        "title": "Ramsey Rule with Progressive Utility in Long Term Yield Curves Modeling",
        "authors": [
            "Nicole El Karoui",
            "Caroline Hillairet",
            "Mohamed Mrad"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The purpose of this paper relies on the study of long term yield curves\nmodeling. Inspired by the economic litterature, it provides a financial\ninterpretation of the Ramsey rule that links discount rate and marginal utility\nof aggregate optimal consumption. For such a long maturity modelization, the\npossibility of adjusting preferences to new economic information is crucial.\nThus, after recalling some important properties on progressive utility, this\npaper first provides an extension of the notion of a consistent progressive\nutility to a consistent pair of progressive utilities of investment and\nconsumption. An optimality condition is that the utility from the wealth\nsatisfies a second order SPDE of HJB type involving the Fenchel-Legendre\ntransform of the utility from consumption. This SPDE is solved in order to give\na full characterization of this class of consistent progressive pair of\nutilities. An application of this results is to revisit the classical backward\noptimization problem in the light of progressive utility theory, emphasizing\nintertemporal-consistency issue. Then we study the dynamics of the marginal\nutility yield curve, and give example with backward and progressive power\nutilities.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1895v1"
    },
    {
        "title": "Ramsey Rule with Progressive utility and Long Term Affine Yields Curves",
        "authors": [
            "Nicole El Karoui",
            "Mohamed Mrad",
            "Caroline Hillairet"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The purpose of this paper relies on the study of long term affine yield\ncurves modeling. It is inspired by the Ramsey rule of the economic literature,\nthat links discount rate and marginal utility of aggregate optimal consumption.\nFor such a long maturity modelization, the possibility of adjusting preferences\nto new economic information is crucial, justifying the use of progressive\nutility. This paper studies, in a framework with affine factors, the yield\ncurve given from the Ramsey rule. It first characterizes consistent progressive\nutility of investment and consumption, given the optimal wealth and consumption\nprocesses. A special attention is paid to utilities associated with linear\noptimal processes with respect to their initial conditions, which is for\nexample the case of power progressive utilities. Those utilities are the basis\npoint to construct other progressive utilities generating non linear optimal\nprocesses but leading yet to still tractable computations. This is of\nparticular interest to study the impact of initial wealth on yield curves.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1913v1"
    },
    {
        "title": "High-order compact finite difference schemes for option pricing in\n  stochastic volatility models on non-uniform grids",
        "authors": [
            "Bertram Düring",
            "Michel Fournié",
            "Christof Heuer"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We derive high-order compact finite difference schemes for option pricing in\nstochastic volatility models on non-uniform grids. The schemes are fourth-order\naccurate in space and second-order accurate in time for vanishing correlation.\nIn our numerical study we obtain high-order numerical convergence also for\nnon-zero correlation and non-smooth payoffs which are typical in option\npricing. In all numerical experiments a comparative standard second-order\ndiscretisation is significantly outperformed. We conduct a numerical stability\nstudy which indicates unconditional stability of the scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.5138v1"
    },
    {
        "title": "High-order compact finite difference scheme for option pricing in\n  stochastic volatility models",
        "authors": [
            "Bertram Düring",
            "Michel Fournié"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We derive a new high-order compact finite difference scheme for option\npricing in stochastic volatility models. The scheme is fourth-order accurate in\nspace and second-order accurate in time. Under some restrictions, theoretical\nresults like unconditional stability in the sense of von Neumann are presented.\nWhere the analysis becomes too involved we validate our findings by a numerical\nstudy. Numerical experiments for the European option pricing problem are\npresented. We observe fourth-order convergence for non-smooth payoff.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.5140v1"
    },
    {
        "title": "High-order ADI scheme for option pricing in stochastic volatility models",
        "authors": [
            "Bertram Düring",
            "James Miles"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We propose a new high-order alternating direction implicit (ADI) finite\ndifference scheme for the solution of initial-boundary value problems of\nconvection-diffusion type with mixed derivatives and non-constant coefficients,\nas they arise from stochastic volatility models in option pricing. Our approach\ncombines different high-order spatial discretisations with Hundsdorfer and\nVerwer's ADI time-stepping method, to obtain an efficient method which is\nfourth-order accurate in space and second-order accurate in time. Numerical\nexperiments for the European put option pricing problem using Heston's\nstochastic volatility model confirm the high-order convergence.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.02529v1"
    },
    {
        "title": "Quadratic-exponential growth BSDEs with Jumps and their Malliavin's\n  Differentiability",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We investigate a class of quadratic-exponential growth BSDEs with jumps. The\nquadratic structure introduced by Barrieu & El Karoui (2013) yields the\nuniversal bounds on the possible solutions. With local Lipschitz continuity and\nthe so-called A_gamma-condition for the comparison principle to hold, we prove\nthe existence of a unique solution under the general quadratic-exponential\nstructure. We have also shown that the strong convergence occurs under more\ngeneral (not necessarily monotone) sequence of drivers, which is then applied\nto give the sufficient conditions for the Malliavin's differentiability.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.05924v6"
    },
    {
        "title": "Pricing European Options by Stable Fourier-Cosine Series Expansions",
        "authors": [
            "Chunfa Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The COS method proposed in Fang and Oosterlee (2008), although highly\nefficient, may lack robustness for a number of cases. In this paper, we present\na Stable pricing of call options based on Fourier cosine series expansion. The\nStability of the pricing methods is demonstrated by error analysis, as well as\nby a series of numerical examples, including the Heston stochastic volatility\nmodel, Kou jump-diffusion model, and CGMY model.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.00886v2"
    },
    {
        "title": "Recursive Marginal Quantization of Higher-Order Schemes",
        "authors": [
            "T. A. McWalter",
            "R. Rudd",
            "J. Kienitz",
            "E. Platen"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Quantization techniques have been applied in many challenging finance\napplications, including pricing claims with path dependence and early exercise\nfeatures, stochastic optimal control, filtering problems and efficient\ncalibration of large derivative books. Recursive Marginal Quantization of the\nEuler scheme has recently been proposed as an efficient numerical method for\nevaluating functionals of solutions of stochastic differential equations. This\nmethod involves recursively quantizing the conditional marginals of the\ndiscrete-time Euler approximation of the underlying process. By generalizing\nthis approach, we show that it is possible to perform recursive marginal\nquantization for two higher-order schemes: the Milstein scheme and a simplified\nweak order 2.0 scheme. As part of this generalization a simple matrix\nformulation is presented, allowing efficient implementation. We further extend\nthe applicability of recursive marginal quantization by showing how absorption\nand reflection at the zero boundary may be incorporated, when this is\nnecessary. To illustrate the improved accuracy of the higher order schemes,\nvarious computations are performed using geometric Brownian motion and its\ngeneralization, the constant elasticity of variance model. For both processes,\nwe show numerical evidence of improved weak order convergence and we compare\nthe marginal distributions implied by the three schemes to the known analytical\ndistributions. By pricing European, Bermudan and Barrier options, further\nevidence of improved accuracy of the higher order schemes is demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.02681v1"
    },
    {
        "title": "Phase-type Approximation of the Gerber-Shiu Function",
        "authors": [
            "Kazutoshi Yamazaki"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The Gerber-Shiu function provides a way of measuring the risk of an insurance\ncompany. It is given by the expected value of a function that depends on the\nruin time, the deficit at ruin, and the surplus prior to ruin. Its computation\nrequires the evaluation of the overshoot/undershoot distributions of the\nsurplus process at ruin. In this paper, we use the recent developments of the\nfluctuation theory and approximate it in a closed form by fitting the\nunderlying process by phase-type Levy processes. A sequence of numerical\nresults are given.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.02798v1"
    },
    {
        "title": "Multichannel Contagion vs Stabilisation in Multiple Interconnected\n  Financial Markets",
        "authors": [
            "Antoaneta Serguieva"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The theory of multilayer networks is in its early stages, and its development\nprovides vital methods for understanding complex systems. Multilayer networks,\nin their multiplex form, have been introduced within the last three years to\nanalysing the structure of financial systems, and existing studies have\nmodelled and evaluated interdependencies of different type among financial\ninstitutions. These studies, however, have considered the structure as a\nnon-interconnected multiplex - an ensemble of single layer networks comprising\nthe same nodes - rather than as an interconnected multiplex network. No\nmechanism of multichannel contagion has been modelled and empirically\nevaluated, and no multichannel stabilisation strategies for pre-emptive\ncontagion containment have been designed. This paper formulates an\ninterconnected multiplex structure, and a contagion mechanism among financial\ninstitutions due to bilateral exposures arising from institutions activity\nwithin different interconnected markets that compose the overall financial\nmarket. We introduce structural measures of absolute systemic risk and\nresilience, and relative systemic-risk indexes. Based on the contagion\nmechanism and systemic-risk quantification, this study designs minimum-cost\nstabilisation strategies that act simultaneously on different markets and their\ninterconnections, in order to effectively contain potential contagion\nprogressing through the overall structure. The stabilisation strategies subtly\naffect the emergence process of structure to adaptively build in structural\nresilience and achieve pre-emptive stabilisation at a minimum cost for each\ninstitution and at no cost for the system as a whole. We empirically evaluate\nthe new approach using large granular databases, maintained by the Prudential\nRegulatory Authority of the Bank of England. The capabilities of multichannel\nstabilisation are confirmed empirically.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.06975v5"
    },
    {
        "title": "Invariance times",
        "authors": [
            "Stéphane Crépey",
            "Shiqi Song"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  On a probability space $(\\Omega,\\mathcal{A},\\mathbb{Q})$ we consider two\nfiltrations $\\mathbb{F}\\subset \\mathbb{G}$ and a $\\mathbb{G}$ stopping time\n$\\theta$ such that the $\\mathbb{G}$ predictable processes coincide with\n$\\mathbb{F}$ predictable processes on $(0,\\theta]$. In this setup it is\nwell-known that, for any $\\mathbb{F}$ semimartingale $X$, the process\n$X^{\\theta-}$ ($X$ stopped \"right before $\\theta$\") is a $\\mathbb{G}$\nsemimartingale.Given a positive constant $T$, we call $\\theta$ an invariance\ntime if there exists a probability measure $\\mathbb{P}$ equivalent to\n$\\mathbb{Q}$ on $\\mathcal{F}\\_T$ such that, for any $(\\mathbb{F},\\mathbb{P})$\nlocal martingale $X$, $X^{\\theta-}$ is a $(\\mathbb{G},\\mathbb{Q})$ local\nmartingale. We characterize invariance times in terms of the\n$(\\mathbb{F},\\mathbb{Q})$ Az\\'ema supermartingale of $\\theta$ and we derive a\nmild and tractable invariance time sufficiency condition. We discuss invariance\ntimes in mathematical finance and BSDE applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.01045v1"
    },
    {
        "title": "Asymptotic Expansion as Prior Knowledge in Deep Learning Method for high\n  dimensional BSDEs",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi",
            "Masayuki Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We demonstrate that the use of asymptotic expansion as prior knowledge in the\n\"deep BSDE solver\", which is a deep learning method for high dimensional BSDEs\nproposed by Weinan E, Han & Jentzen (2017), drastically reduces the loss\nfunction and accelerates the speed of convergence. We illustrate the technique\nand its implications by using Bergman's model with different lending and\nborrowing rates as a typical model for FVA as well as a class of solvable BSDEs\nwith quadratic growth drivers. We also present an extension of the deep BSDE\nsolver for reflected BSDEs representing American option prices.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.07030v3"
    },
    {
        "title": "Deep learning calibration of option pricing models: some pitfalls and\n  solutions",
        "authors": [
            "A Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Recent progress in the field of artificial intelligence, machine learning and\nalso in computer industry resulted in the ongoing boom of using these\ntechniques as applied to solving complex tasks in both science and industry.\nSame is, of course, true for the financial industry and mathematical finance.\nIn this paper we consider a classical problem of mathematical finance -\ncalibration of option pricing models to market data, as it was recently drawn\nsome attention of the financial society in the context of deep learning and\nartificial neural networks. We highlight some pitfalls in the existing\napproaches and propose resolutions that improve both performance and accuracy\nof calibration. We also address a problem of no-arbitrage pricing when using a\ntrained neural net, that is currently ignored in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.03507v1"
    },
    {
        "title": "Using Machine Learning and Alternative Data to Predict Movements in\n  Market Risk",
        "authors": [
            "Thomas Dierckx",
            "Jesse Davis",
            "Wim Schoutens"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Using machine learning and alternative data for the prediction of financial\nmarkets has been a popular topic in recent years. Many financial variables such\nas stock price, historical volatility and trade volume have already been\nthrough extensive investigation. Remarkably, we found no existing research on\nthe prediction of an asset's market implied volatility within this context.\nThis forward-looking measure gauges the sentiment on the future volatility of\nan asset, and is deemed one of the most important parameters in the world of\nderivatives. The ability to predict this statistic may therefore provide a\ncompetitive edge to practitioners of market making and asset management alike.\nConsequently, in this paper we investigate Google News statistics and Wikipedia\nsite traffic as alternative data sources to quantitative market data and\nconsider Logistic Regression, Support Vector Machines and AdaBoost as machine\nlearning models. We show that movements in market implied volatility can indeed\nbe predicted through the help of machine learning techniques. Although the\nemployed alternative data appears to not enhance predictive accuracy, we reveal\npreliminary evidence of non-linear relationships between features obtained from\nWikipedia page traffic and movements in market implied volatility.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.07947v1"
    },
    {
        "title": "Fast Estimation of True Bounds on Bermudan Option Prices under\n  Jump-diffusion Processes",
        "authors": [
            "Helin Zhu",
            "Fan Ye",
            "Enlu Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Fast pricing of American-style options has been a difficult problem since it\nwas first introduced to financial markets in 1970s, especially when the\nunderlying stocks' prices follow some jump-diffusion processes. In this paper,\nwe propose a new algorithm to generate tight upper bounds on the Bermudan\noption price without nested simulation, under the jump-diffusion setting. By\nexploiting the martingale representation theorem for jump processes on the dual\nmartingale, we are able to explore the unique structure of the optimal dual\nmartingale and construct an approximation that preserves the martingale\nproperty. The resulting upper bound estimator avoids the nested Monte Carlo\nsimulation suffered by the original primal-dual algorithm, therefore\nsignificantly improves the computational efficiency. Theoretical analysis is\nprovided to guarantee the quality of the martingale approximation. Numerical\nexperiments are conducted to verify the efficiency of our proposed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.4321v1"
    },
    {
        "title": "Essentially high-order compact schemes with application to stochastic\n  volatility models on non-uniform grids",
        "authors": [
            "Bertram Düring",
            "Christof Heuer"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We present high-order compact schemes for a linear second-order parabolic\npartial differential equation (PDE) with mixed second-order derivative terms in\ntwo spatial dimensions. The schemes are applied to option pricing PDE for a\nfamily of stochastic volatility models. We use a non-uniform grid with more\ngrid-points around the strike price. The schemes are fourth-order accurate in\nspace and second-order accurate in time for vanishing correlation. In our\nnumerical convergence study we achieve fourth-order accuracy also for non-zero\ncorrelation. A combination of Crank-Nicolson and BDF-4 discretisation is\napplied in time. Numerical examples confirm that a standard, second-order\nfinite difference scheme is significantly outperformed.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.00316v1"
    },
    {
        "title": "Pricing Bounds for VIX Derivatives via Least Squares Monte Carlo",
        "authors": [
            "Ivan Guo",
            "Gregoire Loeper"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  Derivatives on the Chicago Board Options Exchange volatility index (VIX) have\ngained significant popularity over the last decade. The pricing of VIX\nderivatives involves evaluating the square root of the expected realised\nvariance which cannot be computed by direct Monte Carlo methods. Least squares\nMonte Carlo methods can be used but the sign of the error is difficult to\ndetermine. In this paper, we propose new model independent upper and lower\npricing bounds for VIX derivatives. In particular, we first present a general\nstochastic duality result on payoffs involving concave functions. This is then\napplied to VIX derivatives along with minor adjustments to handle issues caused\nby the square root function. The upper bound involves the evaluation of a\nvariance swap, while the lower bound involves estimating a martingale increment\ncorresponding to its hedging portfolio. Both can be achieved simultaneously\nusing a single linear least square regression. Numerical results show that the\nmethod works very well for VIX futures, calls and puts under a wide range of\nparameter choices.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.00464v1"
    },
    {
        "title": "Sparse grid high-order ADI scheme for option pricing in stochastic\n  volatility models",
        "authors": [
            "Bertram Düring",
            "Christian Hendricks",
            "James Miles"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We present a sparse grid high-order alternating direction implicit (ADI)\nscheme for option pricing in stochastic volatility models. The scheme is\nsecond-order in time and fourth-order in space. Numerical experiments confirm\nthe computational efficiency gains achieved by the sparse grid combination\ntechnique.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.01379v1"
    },
    {
        "title": "Can Agent-Based Models Probe Market Microstructure?",
        "authors": [
            "Donovan Platt",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We extend prior evidence that naively using intraday agent-based models that\ninvolve realistic order-matching processes for modeling continuous-time double\nauction markets seems to fail to be able to provide a robust link between data\nand many model parameters, even when these models are able to reproduce a\nnumber of well-known stylized facts of return time series. We demonstrate that\nwhile the parameters of intraday agent-based models rooted in market\nmicrostructure can be meaningfully calibrated, those exclusively related to\nagent behaviors and incentives remain problematic. This could simply be a\nfailure of the calibration techniques used but we argue that the observed\nparameter degeneracies are most likely a consequence of the realistic matching\nprocesses employed in these models. This suggests that alternative approaches\nto linking data, phenomenology and market structure may be necessary and that\nit is conceivable that one could construct a useful model that does not\ndirectly depend on the nuances of agent behaviors, even when it is known that\nthe real agents engage in complex behaviors.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.08510v3"
    },
    {
        "title": "Exploring the Interconnectedness of Cryptocurrencies using Correlation\n  Networks",
        "authors": [
            "Andrew Burnie"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Correlation networks were used to detect characteristics which, although\nfixed over time, have an important influence on the evolution of prices over\ntime. Potentially important features were identified using the websites and\nwhitepapers of cryptocurrencies with the largest userbases. These were assessed\nusing two datasets to enhance robustness: one with fourteen cryptocurrencies\nbeginning from 9 November 2017, and a subset with nine cryptocurrencies\nstarting 9 September 2016, both ending 6 March 2018. Separately analysing the\nsubset of cryptocurrencies raised the number of data points from 115 to 537,\nand improved robustness to changes in relationships over time. Excluding USD\nTether, the results showed a positive association between different\ncryptocurrencies that was statistically significant. Robust, strong positive\nassociations were observed for six cryptocurrencies where one was a fork of the\nother; Bitcoin / Bitcoin Cash was an exception. There was evidence for the\nexistence of a group of cryptocurrencies particularly associated with Cardano,\nand a separate group correlated with Ethereum. The data was not consistent with\na token's functionality or creation mechanism being the dominant determinants\nof the evolution of prices over time but did suggest that factors other than\nspeculation contributed to the price.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.06632v1"
    },
    {
        "title": "A copula based Markov Reward approach to the credit spread in European\n  Union",
        "authors": [
            "Guglielmo D'Amico",
            "Filippo Petroni",
            "Philippe Regnault",
            "Stefania Scocchera",
            "Loriano Storchi"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper, we propose a methodology based on piece-wise homogeneous\nMarkov chain for credit ratings and a multivariate model of the credit spreads\nto evaluate the financial risk in European Union (EU). Two main aspects are\nconsidered: how the financial risk is distributed among the European countries\nand how large is the value of the total risk. The first aspect is evaluated by\nmeans of the expected value of a dynamic entropy measure. The second one is\nsolved by computing the evolution of the total credit spread over time.\nMoreover, the covariance between countries' total spread allows understand any\ncontagions in EU. The methodology is applied to real data of 24 countries for\nthe three major agencies: Moody's, Standard and Poor's, and Fitch. Obtained\nresults suggest that both the financial risk inequality and the value of the\ntotal risk increase over time at a different rate depending on the rating\nagency and that the dependence structure is characterized by a strong\ncorrelation between most of European countries.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.00691v1"
    },
    {
        "title": "Deep Adaptive Input Normalization for Time Series Forecasting",
        "authors": [
            "Nikolaos Passalis",
            "Anastasios Tefas",
            "Juho Kanniainen",
            "Moncef Gabbouj",
            "Alexandros Iosifidis"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Deep Learning (DL) models can be used to tackle time series analysis tasks\nwith great success. However, the performance of DL models can degenerate\nrapidly if the data are not appropriately normalized. This issue is even more\napparent when DL is used for financial time series forecasting tasks, where the\nnon-stationary and multimodal nature of the data pose significant challenges\nand severely affect the performance of DL models. In this work, a simple, yet\neffective, neural layer, that is capable of adaptively normalizing the input\ntime series, while taking into account the distribution of the data, is\nproposed. The proposed layer is trained in an end-to-end fashion using\nback-propagation and leads to significant performance improvements compared to\nother evaluated normalization schemes. The proposed method differs from\ntraditional normalization methods since it learns how to perform normalization\nfor a given task instead of using a fixed normalization scheme. At the same\ntime, it can be directly applied to any new time series without requiring\nre-training. The effectiveness of the proposed method is demonstrated using a\nlarge-scale limit order book dataset, as well as a load forecasting dataset.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.07892v2"
    },
    {
        "title": "Working Paper: Improved Stock Price Forecasting Algorithm based on\n  Feature-weighed Support Vector Regression by using Grey Correlation Degree",
        "authors": [
            "Quanxi Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  With the widespread engineering applications ranging from artificial\nintelligence and big data decision-making, originally a lot of tedious\nfinancial data processing, processing and analysis have become more and more\nconvenient and effective. This paper aims to improve the accuracy of stock\nprice forecasting. It improves the support vector machine regression algorithm\nby using grey correlation analysis (GCA) and improves the accuracy of stock\nprediction. This article first divides the factors affecting the stock price\nmovement into behavioral factors and technical factors. The behavioral factors\nmainly include weather indicators and emotional indicators. The technical\nfactors mainly include the daily closing data and the HS 300 Index, and then\nmeasure relation through the method of grey correlation analysis. The\nrelationship between the stock price and its impact factors during the trading\nday, and this relationship is transformed into the characteristic weight of\neach impact factor. The weight of the impact factors of all trading days is\nweighted by the feature weight, and finally the support vector regression (SVR)\nis used. The forecast of the revised stock trading data was compared based on\nthe forecast results of technical indicators (MSE, MAE, SCC, and DS) and\nunmodified transaction data, and it was found that the forecast results were\nsignificantly improved.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.08938v1"
    },
    {
        "title": "Fast Calculation of Credit Exposures for Barrier and Bermudan options\n  using Chebyshev interpolation",
        "authors": [
            "Kathrin Glau",
            "Ricardo Pachon",
            "Christian Pötz"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We introduce a new method to calculate the credit exposure of Bermudan,\ndiscretely monitored barrier and European options. Core of the approach is the\napplication of the dynamic Chebyshev method of Glau et al. (2019). The dynamic\nChebyshev method delivers a closed form approximation of the option prices\nalong the paths together with the options' delta and gamma. Key advantage is\nthe polynomial structure of the approximation, which allows us a highly\nefficient evaluation of the credit exposures, even for a large number of\nsimulated paths. The approach is highly flexible in the model choice, payoff\nprofiles and asset classes. We compute the exposure profiles for Bermudan and\nbarrier options in three different equity models and compare them to the\nprofiles of European options. The analysis reveals potential shortcomings of\ncommon simplifications in the exposure calculation. The proposed method is\nsufficiently simple and efficient to avoid such risk-bearing simplifications.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.00238v1"
    },
    {
        "title": "Optimal execution with rough path signatures",
        "authors": [
            "Jasdeep Kalsi",
            "Terry Lyons",
            "Imanol Perez Arribas"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We present a method for obtaining approximate solutions to the problem of\noptimal execution, based on a signature method. The framework is general, only\nrequiring that the price process is a geometric rough path and the price impact\nfunction is a continuous function of the trading speed. Following an\napproximation of the optimisation problem, we are able to calculate an optimal\nsolution for the trading speed in the space of linear functions on a truncation\nof the signature of the price process. We provide strong numerical evidence\nillustrating the accuracy and flexibility of the approach. Our numerical\ninvestigation both examines cases where exact solutions are known,\ndemonstrating that the method accurately approximates these solutions, and\nmodels where exact solutions are not known. In the latter case, we obtain\nfavourable comparisons with standard execution strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.00728v1"
    },
    {
        "title": "What is the Minimal Systemic Risk in Financial Exposure Networks?",
        "authors": [
            "Christian Diem",
            "Anton Pichler",
            "Stefan Thurner"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Management of systemic risk in financial markets is traditionally associated\nwith setting (higher) capital requirements for market participants. There are\nindications that while equity ratios have been increased massively since the\nfinancial crisis, systemic risk levels might not have lowered, but even\nincreased. It has been shown that systemic risk is to a large extent related to\nthe underlying network topology of financial exposures. A natural question\narising is how much systemic risk can be eliminated by optimally rearranging\nthese networks and without increasing capital requirements. Overlapping\nportfolios with minimized systemic risk which provide the same market\nfunctionality as empirical ones have been studied by [pichler2018]. Here we\npropose a similar method for direct exposure networks, and apply it to\ncross-sectional interbank loan networks, consisting of 10 quarterly\nobservations of the Austrian interbank market. We show that the suggested\nframework rearranges the network topology, such that systemic risk is reduced\nby a factor of approximately 3.5, and leaves the relevant economic features of\nthe optimized network and its agents unchanged. The presented optimization\nprocedure is not intended to actually re-configure interbank markets, but to\ndemonstrate the huge potential for systemic risk management through rearranging\nexposure networks, in contrast to increasing capital requirements that were\nshown to have only marginal effects on systemic risk [poledna2017]. Ways to\nactually incentivize a self-organized formation toward optimal network\nconfigurations were introduced in [thurner2013] and [poledna2016]. For\nregulatory policies concerning financial market stability the knowledge of\nminimal systemic risk for a given economic environment can serve as a benchmark\nfor monitoring actual systemic risk in markets.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.05931v1"
    },
    {
        "title": "Machine Learning for Pricing American Options in High-Dimensional\n  Markovian and non-Markovian models",
        "authors": [
            "Ludovic Goudenège",
            "Andrea Molent",
            "Antonino Zanette"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper we propose two efficient techniques which allow one to compute\nthe price of American basket options. In particular, we consider a basket of\nassets that follow a multi-dimensional Black-Scholes dynamics. The proposed\ntechniques, called GPR Tree (GRP-Tree) and GPR Exact Integration (GPR-EI), are\nboth based on Machine Learning, exploited together with binomial trees or with\na closed formula for integration. Moreover, these two methods solve the\nbackward dynamic programming problem considering a Bermudan approximation of\nthe American option. On the exercise dates, the value of the option is first\ncomputed as the maximum between the exercise value and the continuation value\nand then approximated by means of Gaussian Process Regression. The two methods\nmainly differ in the approach used to compute the continuation value: a single\nstep of binomial tree or integration according to the probability density of\nthe process. Numerical results show that these two methods are accurate and\nreliable in handling American options on very large baskets of assets. Moreover\nwe also consider the rough Bergomi model, which provides stochastic volatility\nwith memory. Despite this model is only bidimensional, the whole history of the\nprocess impacts on the price, and handling all this information is not obvious\nat all. To this aim, we present how to adapt the GPR-Tree and GPR-EI methods\nand we focus on pricing American options in this non-Markovian framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.09474v3"
    },
    {
        "title": "Financial Market Directional Forecasting With Stacked Denoising\n  Autoencoder",
        "authors": [
            "Shaogao Lv",
            "Yongchao Hou",
            "Hongwei Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Forecasting stock market direction is always an amazing but challenging\nproblem in finance. Although many popular shallow computational methods (such\nas Backpropagation Network and Support Vector Machine) have extensively been\nproposed, most algorithms have not yet attained a desirable level of\napplicability. In this paper, we present a deep learning model with strong\nability to generate high level feature representations for accurate financial\nprediction. Precisely, a stacked denoising autoencoder (SDAE) from deep\nlearning is applied to predict the daily CSI 300 index, from Shanghai and\nShenzhen Stock Exchanges in China. We use six evaluation criteria to evaluate\nits performance compared with the back propagation network, support vector\nmachine. The experiment shows that the underlying financial model with deep\nmachine technology has a significant advantage for the prediction of the CSI\n300 index.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.00712v1"
    },
    {
        "title": "Speed-up credit exposure calculations for pricing and risk management",
        "authors": [
            "Kathrin Glau",
            "Ricardo Pachon",
            "Christian Pötz"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We introduce a new method to calculate the credit exposure of European and\npath-dependent options. The proposed method is able to calculate accurate\nexpected exposure and potential future exposure profiles under the risk-neutral\nand the real-world measure. Key advantage of is that it delivers an accuracy\ncomparable to a full re-evaluation and at the same time it is faster than a\nregression-based method. Core of the approach is solving a dynamic programming\nproblem by function approximation. This yields a closed form approximation\nalong the paths together with the option's delta and gamma. The simple\nstructure allows for highly efficient evaluation of the exposures, even for a\nlarge number of simulated paths. The approach is flexible in the model choice,\npayoff profiles and asset classes. We validate the accuracy of the method\nnumerically for three different equity products and a Bermudan interest rate\nswaption. Benchmarking against the popular least-squares Monte Carlo approach\nshows that our method is able to deliver a higher accuracy in a faster runtime.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01280v1"
    },
    {
        "title": "Extensions of the Deep Galerkin Method",
        "authors": [
            "Ali Al-Aradi",
            "Adolfo Correia",
            "Danilo de Frietas Naiff",
            "Gabriel Jardim",
            "Yuri Saporito"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We extend the Deep Galerkin Method (DGM) introduced in Sirignano and\nSpiliopoulos (2018)} to solve a number of partial differential equations (PDEs)\nthat arise in the context of optimal stochastic control and mean field games.\nFirst, we consider PDEs where the function is constrained to be positive and\nintegrate to unity, as is the case with Fokker-Planck equations. Our approach\ninvolves reparameterizing the solution as the exponential of a neural network\nappropriately normalized to ensure both requirements are satisfied. This then\ngives rise to nonlinear a partial integro-differential equation (PIDE) where\nthe integral appearing in the equation is handled by a novel application of\nimportance sampling. Secondly, we tackle a number of Hamilton-Jacobi-Bellman\n(HJB) equations that appear in stochastic optimal control problems. The key\ncontribution is that these equations are approached in their unsimplified\nprimal form which includes an optimization problem as part of the equation. We\nextend the DGM algorithm to solve for the value function and the optimal\ncontrol \\simultaneously by characterizing both as deep neural networks.\nTraining the networks is performed by taking alternating stochastic gradient\ndescent steps for the two functions, a technique inspired by the policy\nimprovement algorithms (PIA).\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01455v3"
    },
    {
        "title": "Gauge transformations in the dual space, and pricing and estimation in\n  the long run in affine jump-diffusion models",
        "authors": [
            "Svetlana Boyarchenko",
            "Sergei Levendorskiĭ"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We suggest a simple reduction of pricing European options in affine\njump-diffusion models to pricing options with modified payoffs in diffusion\nmodels. The procedure is based on the conjugation of the infinitesimal\ngenerator of the model with an operator of the form $e^{i\\Phi(-i\\dd_x)}$ (gauge\ntransformation in the dual space). A general procedure for the calculation of\nthe function $\\Phi$ is given, with examples. As applications, we consider\npricing in jump-diffusion models and their subordinated versions using the\neigenfunction expansion technique, and estimation of the extremely rare jumps\ncomponent. The beliefs of the market about yet unobserved extreme jumps and\npricing kernel can be recovered: the market prices allow one to see \"the shape\nof things to come\".\n",
        "pdf_link": "http://arxiv.org/pdf/1912.06948v2"
    },
    {
        "title": "Deep combinatorial optimisation for optimal stopping time problems :\n  application to swing options pricing",
        "authors": [
            "Thomas Deschatre",
            "Joseph Mikael"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  A new method for stochastic control based on neural networks and using\nrandomisation of discrete random variables is proposed and applied to optimal\nstopping time problems. The method models directly the policy and does not need\nthe derivation of a dynamic programming principle nor a backward stochastic\ndifferential equation. Unlike continuous optimization where automatic\ndifferentiation is used directly, we propose a likelihood ratio method for\ngradient computation. Numerical tests are done on the pricing of American and\nswing options. The proposed algorithm succeeds in pricing high dimensional\nAmerican and swing options in a reasonable computation time, which is not\npossible with classical algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11247v2"
    },
    {
        "title": "A neural network model for solvency calculations in life insurance",
        "authors": [
            "Lucio Fernandez-Arjona"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Insurance companies make extensive use of Monte Carlo simulations in their\ncapital and solvency models. To overcome the computational problems associated\nwith Monte Carlo simulations, most large life insurance companies use proxy\nmodels such as replicating portfolios.\n  In this paper, we present an example based on a variable annuity guarantee,\nshowing the main challenges faced by practitioners in the construction of\nreplicating portfolios: the feature engineering step and subsequent basis\nfunction selection problem.\n  We describe how neural networks can be used as a proxy model and how to apply\nrisk-neutral pricing on a neural network to integrate such a model into a\nmarket risk framework. The proposed model naturally solves the feature\nengineering and feature selection problems of replicating portfolios.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02318v1"
    },
    {
        "title": "Differential Machine Learning",
        "authors": [
            "Brian Huge",
            "Antoine Savine"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Differential machine learning combines automatic adjoint differentiation\n(AAD) with modern machine learning (ML) in the context of risk management of\nfinancial Derivatives. We introduce novel algorithms for training fast,\naccurate pricing and risk approximations, online, in real-time, with\nconvergence guarantees. Our machinery is applicable to arbitrary Derivatives\ninstruments or trading books, under arbitrary stochastic models of the\nunderlying market variables. It effectively resolves computational bottlenecks\nof Derivatives risk reports and capital calculations.\n  Differential ML is a general extension of supervised learning, where ML\nmodels are trained on examples of not only inputs and labels but also\ndifferentials of labels wrt inputs. It is also applicable in many situations\noutside finance, where high quality first-order derivatives wrt training inputs\nare available. Applications in Physics, for example, may leverage differentials\nknown from first principles to learn function approximations more effectively.\n  In finance, AAD computes pathwise differentials with remarkable efficacy so\ndifferential ML algorithms provide extremely effective pricing and risk\napproximations. We can produce fast analytics in models too complex for closed\nform solutions, extract the risk factors of complex transactions and trading\nbooks, and effectively compute risk management metrics like reports across a\nlarge number of scenarios, backtesting and simulation of hedge strategies, or\nregulations like XVA, CCR, FRTB or SIMM-MVA.\n  TensorFlow implementation is available on\nhttps://github.com/differential-machine-learning\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02347v4"
    },
    {
        "title": "Pricing Path-Dependent Derivatives under Multiscale Stochastic\n  Volatility Models: a Malliavin Representation",
        "authors": [
            "Yuri F. Saporito"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper we derive a efficient Monte Carlo approximation for the price\nof path-dependent derivatives under the multiscale stochastic volatility models\nof Fouque \\textit{et al}. Using the formulation of this pricing problem under\nthe functional It\\^o calculus framework and making use of Greek formulas from\nMalliavin calculus, we derive a representation for the first-order\napproximation of the price of path-dependent derivatives in the form\n$\\mathbb{E}[\\mbox{payoff} \\times \\mbox{weight}]$. The weight is known in closed\nform and depends only on the group market parameters arising from the\ncalibration of the multiscale stochastic volatility to the market's implied\nvolatility. Moreover, only simulations of the Black-Scholes model is required.\nWe exemplify the method for a couple path-dependent derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.04297v1"
    },
    {
        "title": "Rational Finance Approach to Behavioral Option Pricing",
        "authors": [
            "Jiexin Dai",
            "Abootaleb Shirvani",
            "Frank J. Fabozzi"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  When pricing options, there may be different views on the instantaneous mean\nreturn of the underlying price process. According to Black (1972), where there\nexist heterogeneous views on the instantaneous mean return, this will result in\narbitrage opportunities. Behavioral finance proponents argue that such\nheterogenous views are likely to occur and this will not impact option pricing\nmodels proposed by rational dynamic asset pricing theory and will not give rise\nto volatility smiles. To rectify this, a leading advocate of behavioral finance\nhas proposed a behavioral option pricing model. As there may be unexplored\nlinks between the behavioral and rational approaches to option pricing, in this\npaper we revisit Shefrin (2008) option pricing model as an example and suggest\none approach to modify this behavioral finance option pricing formula to be\nconsistent with rational dynamic asset pricing theory by introducing arbitrage\ntransaction costs which offset the gains from arbitrage trades.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05310v1"
    },
    {
        "title": "Multi-Period Liability Clearing via Convex Optimal Control",
        "authors": [
            "Shane Barratt",
            "Stephen Boyd"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We consider the problem of determining a sequence of payments among a set of\nentities that clear (if possible) the liabilities among them. We formulate this\nas an optimal control problem, which is convex when the objective function is,\nand therefore readily solved. For this optimal control problem, we give a\nnumber of useful and interesting convex costs and constraints that can be\ncombined in any way for different applications. We describe a number of\nextensions, for example to handle unknown changes in cash and liabilities, to\nallow bailouts, to find the minimum time to clear the liabilities, or to\nminimize the number of non-cleared liabilities, when fully clearing the\nliabilities is impossible.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.09066v1"
    },
    {
        "title": "A Computational Approach to Hedging Credit Valuation Adjustment in a\n  Jump-Diffusion Setting",
        "authors": [
            "T. van der Zwaard",
            "L. A. Grzelak",
            "C. W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This study contributes to understanding Valuation Adjustments (xVA) by\nfocussing on the dynamic hedging of Credit Valuation Adjustment (CVA),\ncorresponding Profit & Loss (P&L) and the P&L explain. This is done in a Monte\nCarlo simulation setting, based on a theoretical hedging framework discussed in\nexisting literature. We look at hedging CVA market risk for a portfolio with\nEuropean options on a stock, first in a Black-Scholes setting, then in a Merton\njump-diffusion setting. Furthermore, we analyze the trading business at a bank\nafter including xVAs in pricing. We provide insights into the hedging of\nderivatives and their xVAs by analyzing and visualizing the cash-flows of a\nportfolio from a desk structure perspective. The case study shows that not\ncharging CVA at trade inception results in an expected loss. Furthermore,\nhedging CVA market risk is crucial to end up with a stable trading strategy. In\nthe Black-Scholes setting this can be done using the underlying stock, whereas\nin the Merton jump-diffusion setting we need to add extra options to the hedge\nportfolio to properly hedge the jump risk. In addition to the simulation, we\nderive analytical results that explain our observations from the numerical\nexperiments. Understanding the hedging of CVA helps to deal with xVAs in a\npractical setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.10504v3"
    },
    {
        "title": "Computation of Expected Shortfall by fast detection of worst scenarios",
        "authors": [
            "Bruno Bouchard",
            "Adil Reghai",
            "Benjamin Virrion"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We consider a multi-step algorithm for the computation of the historical\nexpected shortfall such as defined by the Basel Minimum Capital Requirements\nfor Market Risk. At each step of the algorithm, we use Monte Carlo simulations\nto reduce the number of historical scenarios that potentially belong to the set\nof worst scenarios. The number of simulations increases as the number of\ncandidate scenarios is reduced and the distance between them diminishes. For\nthe most naive scheme, we show that the L p-error of the estimator of the\nExpected Shortfall is bounded by a linear combination of the probabilities of\ninversion of favorable and unfavorable scenarios at each step, and of the last\nstep Monte Carlo error associated to each scenario. By using concentration\ninequalities, we then show that, for sub-gamma pricing errors, the\nprobabilities of inversion converge at an exponential rate in the number of\nsimulated paths. We then propose an adaptative version in which the algorithm\nimproves step by step its knowledge on the unknown parameters of interest: mean\nand variance of the Monte Carlo estimators of the different scenarios. Both\nschemes can be optimized by using dynamic programming algorithms that can be\nsolved off-line. To our knowledge, these are the first non-asymptotic bounds\nfor such estimators. Our hypotheses are weak enough to allow for the use of\nestimators for the different scenarios and steps based on the same random\nvariables, which, in practice, reduces considerably the computational effort.\nFirst numerical tests are performed.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.12593v1"
    },
    {
        "title": "Notes on the SWIFT method based on Shannon Wavelets for Option Pricing",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This note shows that the cosine expansion based on the Vieta formula is\nequivalent to a discretization of the Parseval identity. We then evaluate the\nuse of simple direct algorithms to compute the Shannon coefficients for the\npayoff. Finally, we explore the efficiency of a Filon quadrature instead of the\nVieta formula for the coefficients related to the probability density function.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.13252v1"
    },
    {
        "title": "First order strong approximations of scalar SDEs with values in a domain",
        "authors": [
            "Andreas Neuenkirch",
            "Lukasz Szpruch"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We are interested in strong approximations of one-dimensional SDEs which have\nnon-Lipschitz coefficients and which take values in a domain. Under a set of\ngeneral assumptions we derive an implicit scheme that preserves the domain of\nthe SDEs and is strongly convergent with rate one. Moreover, we show that this\ngeneral result can be applied to many SDEs we encounter in mathematical finance\nand bio-mathematics. We will demonstrate flexibility of our approach by\nanalysing classical examples of SDEs with sublinear coefficients (CIR, CEV\nmodels and Wright-Fisher diffusion) and also with superlinear coefficients\n(3/2-volatility, Ait-Sahalia model).\n  Our goal is to justify an efficient Multi-Level Monte Carlo (MLMC) method for\na rich family of SDEs, which relies on good strong convergence properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.0390v1"
    },
    {
        "title": "Momentum-Space Approach to Asymptotic Expansion for Stochastic Filtering",
        "authors": [
            "Masaaki Fujii"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  This paper develops an asymptotic expansion technique in momentum space for\nstochastic filtering. It is shown that Fourier transformation combined with a\npolynomial-function approximation of the nonlinear terms gives a closed\nrecursive system of ordinary differential equations (ODEs) for the relevant\nconditional distribution. Thanks to the simplicity of the ODE system, higher\norder calculation can be performed easily. Furthermore, solving ODEs\nsequentially with small sub-periods with updated initial conditions makes it\npossible to implement a substepping method for asymptotic expansion in a\nnumerically efficient way. This is found to improve the performance\nsignificantly where otherwise the approximation fails badly. The method is\nexpected to provide a useful tool for more realistic financial modeling with\nunobserved parameters, and also for problems involving nonlinear measure-valued\nprocesses.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.1893v3"
    },
    {
        "title": "Numerical Valuation of Derivatives in High-Dimensional Settings via PDE\n  Expansions",
        "authors": [
            "Christoph Reisinger",
            "Rasmus Wissmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In this article, we propose a new numerical approach to high-dimensional\npartial differential equations (PDEs) arising in the valuation of exotic\nderivative securities. The proposed method is extended from Reisinger and\nWittum (2007) and uses principal component analysis (PCA) of the underlying\nprocess in combination with a Taylor expansion of the value function into\nsolutions to low-dimensional PDEs. The approximation is related to anchored\nanalysis of variance (ANOVA) decompositions and is expected to be accurate\nwhenever the covariance matrix has one or few dominating eigenvalues. A main\npurpose of the present article is to give a careful analysis of the numerical\naccuracy and computational complexity compared to state-of-the-art Monte Carlo\nmethods on the example of Bermudan swaptions and Ratchet floors, which are\nconsidered difficult benchmark problems. We are able to demonstrate that for\nproblems with medium to high dimensionality and moderate time horizons the\npresented PDE method delivers results comparable in accuracy to the MC methods\nconsidered here in similar or (often significantly) faster runtime.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.1909v2"
    },
    {
        "title": "LSV models with stochastic interest rates and correlated jumps",
        "authors": [
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Pricing and hedging exotic options using local stochastic volatility models\ndrew a serious attention within the last decade, and nowadays became almost a\nstandard approach to this problem. In this paper we show how this framework\ncould be extended by adding to the model stochastic interest rates and\ncorrelated jumps in all three components. We also propose a new fully implicit\nmodification of the popular Hundsdorfer and Verwer and Modified Craig-Sneyd\nfinite-difference schemes which provides second order approximation in space\nand time, is unconditionally stable and preserves positivity of the solution,\nwhile still has a linear complexity in the number of grid nodes.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.01460v3"
    },
    {
        "title": "Pricing Two-asset Options under Exponential Lévy Model Using a Finite\n  Element Method",
        "authors": [
            "Xun Li",
            "Ping Lin",
            "Xue-Cheng Tai",
            "Jinghui Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This article presents a finite element method (FEM) for a partial\nintegro-differential equation (PIDE) to price two-asset options with underlying\nprice processes modeled by an exponential Levy process. We provide a\nvariational formulation in a weighted Sobolev space, and establish existence\nand uniqueness of the FEM-based solution. Then we discuss the localization of\nthe infinite domain problem to a finite domain and analyze its error. We tackle\nthe localized problem by an explicit-implicit time-discretization of the PIDE,\nwhere the space-discretization is done through a standard continuous finite\nelement method. Error estimates are given for the fully discretized localized\nproblem where two assets are assumed to have uncorrelated jumps. Numerical\nexperiments for the polynomial option and a few other two-asset options shed\nlight on good performance of our proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.04950v1"
    },
    {
        "title": "Modelling stock correlations with expected returns from investors",
        "authors": [
            "Ming-Yuan Yang",
            "Sai-Ping Li",
            "Li-Xin Zhong",
            "Fei Ren"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Stock correlations is crucial to asset pricing, investor decision-making, and\nfinancial risk regulations. However, microscopic explanation based on\nagent-based modeling is still lacking. We here propose a model derived from\nminority game for modeling stock correlations, in which an agent's expected\nreturn for one stock is influenced by the historical return of the other stock.\nEach agent makes a decision based on his expected return with reference to\ninformation dissemination and the historical return of the stock. We find that\nthe returns of the stocks are positively (negatively) correlated when agents'\nexpected returns for one stock are positively (negatively) correlated with the\nhistorical return of the other. We provide both numerical simulations and\nanalytical studies and give explanations to stock correlations for cases with\nagents having either homogeneous or heterogeneous expected returns. The result\nstill holds when other factors such as holding decisions and external events\nare included which broadens the practicability of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.02019v2"
    },
    {
        "title": "Simulation Methods for Stochastic Storage Problems: A Statistical\n  Learning Perspective",
        "authors": [
            "Michael Ludkovski",
            "Aditya Maheshwari"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We consider solution of stochastic storage problems through regression Monte\nCarlo (RMC) methods. Taking a statistical learning perspective, we develop the\ndynamic emulation algorithm (DEA) that unifies the different existing\napproaches in a single modular template. We then investigate the two central\naspects of regression architecture and experimental design that constitute DEA.\nFor the regression piece, we discuss various non-parametric approaches, in\nparticular introducing the use of Gaussian process regression in the context of\nstochastic storage. For simulation design, we compare the performance of\ntraditional design (grid discretization), against space-filling, and several\nadaptive alternatives. The overall DEA template is illustrated with multiple\nexamples drawing from natural gas storage valuation and optimal control of\nback-up generator in a microgrid.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.11309v1"
    },
    {
        "title": "Deep Learning-Based BSDE Solver for Libor Market Model with Application\n  to Bermudan Swaption Pricing and Hedging",
        "authors": [
            "Haojie Wang",
            "Han Chen",
            "Agus Sudjianto",
            "Richard Liu",
            "Qi Shen"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The Libor market model is a mainstay term structure model of interest rates\nfor derivatives pricing, especially for Bermudan swaptions, and other exotic\nLibor callable derivatives. For numerical implementation the pricing of\nderivatives with Libor market models is mainly carried out with Monte Carlo\nsimulation. The PDE grid approach is not particularly feasible due to Curse of\nDimensionality. The standard Monte Carlo method for American/Bermudan swaption\npricing more or less uses regression to estimate expected value as a linear\ncombination of basis functions (Longstaff and Schwartz). However, Monte Carlo\nmethod only provides the lower bound for American option price. Another\ncomplexity is the computation of the sensitivities of the option, the so-called\nGreeks, which are fundamental for a trader's hedging activity. Recently, an\nalternative numerical method based on deep learning and backward stochastic\ndifferential equations appeared in quite a few researches. For European style\noptions the feedforward deep neural networks (DNN) show not only feasibility\nbut also efficiency to obtain both prices and numerical Greeks. In this paper,\na new backward DNN solver is proposed for Bermudan swaptions. Our approach is\nrepresenting financial pricing problems in the form of high dimensional\nstochastic optimal control problems, FBSDEs, or equivalent PDEs. We demonstrate\nthat using backward DNN the high-dimension Bermudan swaption pricing and\nhedging can be solved effectively and efficiently. A comparison between Monte\nCarlo simulation and the new method for pricing vanilla interest rate options\nmanifests the superior performance of the new method. We then use this method\nto calculate prices and Greeks of Bermudan swaptions as a prelude for other\nLibor callable derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.06622v2"
    },
    {
        "title": "From (Martingale) Schrodinger bridges to a new class of Stochastic\n  Volatility Models",
        "authors": [
            "Pierre Henry-Labordere"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Following closely the construction of the Schrodinger bridge, we build a new\nclass of Stochastic Volatility Models exactly calibrated to market instruments\nsuch as for example Vanillas, options on realized variance or VIX options.\nThese models differ strongly from the well-known local stochastic volatility\nmodels, in particular the instantaneous volatility-of-volatility of the\nassociated naked SVMs is not modified, once calibrated to market instruments.\nThey can be interpreted as a martingale version of the Schrodinger bridge. The\nnumerical calibration is performed using a dynamic-like version of the Sinkhorn\nalgorithm. We finally highlight a striking relation with Dyson non-colliding\nBrownian motions.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.04554v1"
    },
    {
        "title": "A Dynamic Bayesian Model for Interpretable Decompositions of Market\n  Behaviour",
        "authors": [
            "Théophile Griveau-Billion",
            "Ben Calderhead"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We propose a heterogeneous simultaneous graphical dynamic linear model\n(H-SGDLM), which extends the standard SGDLM framework to incorporate a\nheterogeneous autoregressive realised volatility (HAR-RV) model. This novel\napproach creates a GPU-scalable multivariate volatility estimator, which\ndecomposes multiple time series into economically-meaningful variables to\nexplain the endogenous and exogenous factors driving the underlying\nvariability. This unique decomposition goes beyond the classic one step ahead\nprediction; indeed, we investigate inferences up to one month into the future\nusing stocks, FX futures and ETF futures, demonstrating its superior\nperformance according to accuracy of large moves, longer-term prediction and\nconsistency over time.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.08153v3"
    },
    {
        "title": "Inefficiency of the Brazilian Stock Market: the IBOVESPA Future\n  Contracts",
        "authors": [
            "Tarcisio M. Rocha Filho",
            "Paulo M. M. Rocha"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We present some indications of inefficiency of the Brazilian stock market\nbased on the existence of strong long-time cross-correlations with foreign\nmarkets and indices. Our results show a strong dependence on foreign markets\nindices as the S\\&P 500 and CAC 40, but not to the Shanghai SSE 180, indicating\nan intricate interdependence. We also show that the distribution of log-returns\nof the Brazilian BOVESPA index has a discrete fat tail in the time scale of a\nday, which is also a deviation of what is expected of an efficient equilibrated\nmarket. As a final argument of the inefficiency of the Brazilian stock market,\nwe use a neural network approach to forecast the direction of movement of the\nvalue of the IBOVESPA future contracts, with an accuracy allowing financial\nreturns over passive strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.09214v1"
    },
    {
        "title": "Fast Pricing of Energy Derivatives with Mean-reverting Jump-diffusion\n  Processes",
        "authors": [
            "Nicola Cufaro Petroni",
            "Piergiacomo Sabino"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Most energy and commodity markets exhibit mean-reversion and occasional\ndistinctive price spikes, which results in demand for derivative products which\nprotect the holder against high prices. To this end, in this paper we present\nexact and fast methodologies for the simulation of the spot price dynamics\nmodeled as the exponential of the sum of an Ornstein-Uhlenbeck and an\nindependent pure jump process, where the latter one is driven by a compound\nPoisson process with (bilateral) exponentially distributed jumps. These\nmethodologies are finally applied to the pricing of Asian options, gas storages\nand swings under different combinations of jump-diffusion market models, and\nthe apparent computational advantages of the proposed procedures are\nemphasized.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.03137v2"
    },
    {
        "title": "Expansion method for pricing foreign exchange options under stochastic\n  volatility and interest rates",
        "authors": [
            "Kenji Nagami"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Some expansion methods have been proposed for approximately pricing options\nwhich has no exact closed formula. Benhamou et al. (2010) presents the smart\nexpansion method that directly expands the expectation value of payoff function\nwith respect to the volatility of volatility, then uses it to price options in\nthe stochastic volatility model. In this paper, we apply their method to the\nstochastic volatility model with stochastic interest rates, and present the\nexpansion formula for pricing options up to the second order. Then the\nnumerical studies are performed to compare our approximation formula with the\nMonte-Carlo simulation. It is found that our formula shows the numerically\ncomparable results with the method proposed by Grzelak et al. (2012) which uses\nthe approximation of characteristic function.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.09640v1"
    },
    {
        "title": "PAGAN: Portfolio Analysis with Generative Adversarial Networks",
        "authors": [
            "Giovanni Mariani",
            "Yada Zhu",
            "Jianbo Li",
            "Florian Scheidegger",
            "Roxana Istrate",
            "Costas Bekas",
            "A. Cristiano I. Malossi"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Since decades, the data science community tries to propose prediction models\nof financial time series. Yet, driven by the rapid development of information\ntechnology and machine intelligence, the velocity of today's information leads\nto high market efficiency. Sound financial theories demonstrate that in an\nefficient marketplace all information available today, including expectations\non future events, are represented in today prices whereas future price trend is\ndriven by the uncertainty. This jeopardizes the efforts put in designing\nprediction models. To deal with the unpredictability of financial systems,\ntoday's portfolio management is largely based on the Markowitz framework which\nputs more emphasis in the analysis of the market uncertainty and less in the\nprice prediction. The limitation of the Markowitz framework stands in taking\nvery strong ideal assumptions about future returns probability distribution.\n  To address this situation we propose PAGAN, a pioneering methodology based on\ndeep generative models. The goal is modeling the market uncertainty that\nultimately is the main factor driving future trends. The generative model\nlearns the joint probability distribution of price trends for a set of\nfinancial assets to match the probability distribution of the real market. Once\nthe model is trained, a portfolio is optimized by deciding the best\ndiversification to minimize the risk and maximize the expected returns observed\nover the execution of several simulations. Applying the model for analyzing\npossible futures, is as simple as executing a Monte Carlo simulation, a\ntechnique very familiar to finance experts. The experimental results on\ndifferent portfolios representing different geopolitical areas and industrial\nsegments constructed using real-world public data sets demonstrate promising\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.10578v1"
    },
    {
        "title": "Deep Learning for Stock Selection Based on High Frequency Price-Volume\n  Data",
        "authors": [
            "Junming Yang",
            "Yaoqi Li",
            "Xuanyu Chen",
            "Jiahang Cao",
            "Kangkang Jiang"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Training a practical and effective model for stock selection has been a\ngreatly concerned problem in the field of artificial intelligence. Even though\nsome of the models from previous works have achieved good performance in the\nU.S. market by using low-frequency data and features, training a suitable model\nwith high-frequency stock data is still a problem worth exploring. Based on the\nhigh-frequency price data of the past several days, we construct two separate\nmodels-Convolution Neural Network and Long Short-Term Memory-which can predict\nthe expected return rate of stocks on the current day, and select the stocks\nwith the highest expected yield at the opening to maximize the total return. In\nour CNN model, we propose improvements on the CNNpred model presented by E.\nHoseinzade and S. Haratizadeh in their paper which deals with low-frequency\nfeatures. Such improvements enable our CNN model to exploit the convolution\nlayer's ability to extract high-level factors and avoid excessive loss of\noriginal information at the same time. Our LSTM model utilizes Recurrent Neural\nNetwork'advantages in handling time series data. Despite considerable\ntransaction fees due to the daily changes of our stock position, annualized net\nrate of return is 62.27% for our CNN model, and 50.31% for our LSTM model.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.02502v1"
    },
    {
        "title": "Quantization-based Bermudan option pricing in the $FX$ world",
        "authors": [
            "Jean-Michel Fayolle",
            "Vincent Lemaire",
            "Thibaut Montes",
            "Gilles Pagès"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  This paper proposes two numerical solution based on Product Optimal\nQuantization for the pricing of Foreign Echange (FX) linked long term Bermudan\noptions e.g. Bermudan Power Reverse Dual Currency options, where we take into\naccount stochastic domestic and foreign interest rates on top of stochastic FX\nrate, hence we consider a 3-factor model. For these two numerical methods, we\ngive an estimation of the $L^2$-error induced by such approximations and we\nillustrate them with market-based examples that highlight the speed of such\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05462v2"
    },
    {
        "title": "Bounds on Multi-asset Derivatives via Neural Networks",
        "authors": [
            "Luca De Gennaro Aquino",
            "Carole Bernard"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Using neural networks, we compute bounds on the prices of multi-asset\nderivatives given information on prices of related payoffs. As a main example,\nwe focus on European basket options and include information on the prices of\nother similar options, such as spread options and/or basket options on\nsubindices. We show that, in most cases, adding further constraints gives rise\nto bounds that are considerably tighter and discuss the maximizing/minimizing\ncopulas achieving such bounds. Our approach follows the literature on\nconstrained optimal transport and, in particular, builds on a recent paper by\nEckstein and Kupper (2019, Appl. Math. Optim.).\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05523v6"
    },
    {
        "title": "On the Importance of Opponent Modeling in Auction Markets",
        "authors": [
            "Mahmoud Mahfouz",
            "Angelos Filos",
            "Cyrine Chtourou",
            "Joshua Lockhart",
            "Samuel Assefa",
            "Manuela Veloso",
            "Danilo Mandic",
            "Tucker Balch"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  The dynamics of financial markets are driven by the interactions between\nparticipants, as well as the trading mechanisms and regulatory frameworks that\ngovern these interactions. Decision-makers would rather not ignore the impact\nof other participants on these dynamics and should employ tools and models that\ntake this into account. To this end, we demonstrate the efficacy of applying\nopponent-modeling in a number of simulated market settings. While our\nsimulations are simplified representations of actual market dynamics, they\nprovide an idealized \"playground\" in which our techniques can be demonstrated\nand tested. We present this work with the aim that our techniques could be\nrefined and, with some effort, scaled up to the full complexity of real-world\nmarket scenarios. We hope that the results presented encourage practitioners to\nadopt opponent-modeling methods and apply them online systems, in order to\nenable not only reactive but also proactive decisions to be made.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12816v1"
    },
    {
        "title": "Consistent Recalibration Models and Deep Calibration",
        "authors": [
            "Matteo Gambara",
            "Josef Teichmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Consistent Recalibration models (CRC) have been introduced to capture in\nnecessary generality the dynamic features of term structures of derivatives'\nprices. Several approaches have been suggested to tackle this problem, but all\nof them, including CRC models, suffered from numerical intractabilities mainly\ndue to the presence of complicated drift terms or consistency conditions. We\novercome this problem by machine learning techniques, which allow to store the\ncrucial drift term's information in neural network type functions. This yields\nfirst time dynamic term structure models which can be efficiently simulated.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.09455v3"
    },
    {
        "title": "Deep Investing in Kyle's Single Period Model",
        "authors": [
            "Paul Friedrich",
            "Josef Teichmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The Kyle model describes how an equilibrium of order sizes and security\nprices naturally arises between a trader with insider information and the price\nproviding market maker as they interact through a series of auctions. Ever\nsince being introduced by Albert S. Kyle in 1985, the model has become\nimportant in the study of market microstructure models with asymmetric\ninformation. As it is well understood, it serves as an excellent opportunity to\nstudy how modern deep learning technology can be used to replicate and better\nunderstand equilibria that occur in certain market learning problems.\n  We model the agents in Kyle's single period setting using deep neural\nnetworks. The networks are trained by interacting following the rules and\nobjectives as defined by Kyle. We show how the right network architectures and\ntraining methods lead to the agents' behaviour converging to the theoretical\nequilibrium that is predicted by Kyle's model.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13889v1"
    },
    {
        "title": "An unsupervised deep learning approach in solving partial\n  integro-differential equations",
        "authors": [
            "Ali Hirsa",
            "Weilong Fu"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We investigate solving partial integro-differential equations (PIDEs) using\nunsupervised deep learning in this paper. To price options, assuming underlying\nprocesses follow Levy processes, we require to solve PIDEs. In supervised deep\nlearning, pre-calculated labels are used to train neural networks to fit the\nsolution of the PIDE. In an unsupervised deep learning, neural networks are\nemployed as the solution, and the derivatives and the integrals in the PIDE are\ncalculated based on the neural network. By matching the PIDE and its boundary\nconditions, the neural network gives an accurate solution of the PIDE. Once\ntrained, it would be fast for calculating options values as well as option\nGreeks.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15012v3"
    },
    {
        "title": "Dynamic Hedging using Generated Genetic Programming Implied Volatility\n  Models",
        "authors": [
            "Fathi Abid",
            "Wafa Abdelmalek",
            "Sana Ben Hamida"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The purpose of this paper is to improve the accuracy of dynamic hedging using\nimplied volatilities generated by genetic programming. Using real data from\nS&P500 index options, the genetic programming's ability to forecast Black and\nScholes implied volatility is compared between static and dynamic\ntraining-subset selection methods. The performance of the best generated GP\nimplied volatilities is tested in dynamic hedging and compared with\nBlack-Scholes model. Based on MSE total, the dynamic training of GP yields\nbetter results than those obtained from static training with fixed samples.\nAccording to hedging errors, the GP model is more accurate almost in all\nhedging strategies than the BS model, particularly for in-the-money call\noptions and at-the-money put options.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.16407v1"
    },
    {
        "title": "mlOSP: Towards a Unified Implementation of Regression Monte Carlo\n  Algorithms",
        "authors": [
            "Mike Ludkovski"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We introduce mlOSP, a computational template for Machine Learning for Optimal\nStopping Problems. The template is implemented in the R statistical environment\nand publicly available via a GitHub repository. mlOSP presents a unified\nnumerical implementation of Regression Monte Carlo (RMC) approaches to optimal\nstopping, providing a state-of-the-art, open-source, reproducible and\ntransparent platform. Highlighting its modular nature, we present multiple\nnovel variants of RMC algorithms, especially in terms of constructing\nsimulation designs for training the regressors, as well as in terms of machine\nlearning regression modules. Furthermore, mlOSP nests most of the existing RMC\nschemes, allowing for a consistent and verifiable benchmarking of extant\nalgorithms. The article contains extensive R code snippets and figures, and\nserves as a vignette to the underlying software package.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.00729v2"
    },
    {
        "title": "Flashot: A Snapshot of Flash Loan Attack on DeFi Ecosystem",
        "authors": [
            "Yixin Cao",
            "Chuanwei Zou",
            "Xianfeng Cheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Flash Loan attack can grab millions of dollars from decentralized vaults in\none single transaction, drawing increasing attention from the Decentralized\nFinance (DeFi) players. It has also demonstrated an exciting opportunity that a\nhuge wealth could be created by composing DeFi's building blocks and exploring\nthe arbitrage change. However, a fundamental framework to study the field of\nDeFi has not yet reached a consensus and there's a lack of standard tools or\nlanguages to help better describe, design and improve the running processes of\nthe infant DeFi systems, which naturally makes it harder to understand the\nbasic principles behind the complexity of Flash Loan attacks.\n  In this paper, we are the first to propose Flashot, a prototype that is able\nto transparently illustrate the precise asset flows intertwined with smart\ncontracts in a standardized diagram for each Flash Loan event. Some use cases\nare shown and specifically, based on Flashot, we study a typical Pump and\nArbitrage case and present in-depth economic explanations to the attacker's\nbehaviors. Finally, we conclude the development trends of Flash Loan attacks\nand discuss the great impact on DeFi ecosystem brought by Flash Loan. We\nenvision a brand new quantitative financial industry powered by highly\nefficient automatic risk and profit detection systems based on the blockchain.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00626v1"
    },
    {
        "title": "A Stochastic Time Series Model for Predicting Financial Trends using NLP",
        "authors": [
            "Pratyush Muthukumar",
            "Jie Zhong"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Stock price forecasting is a highly complex and vitally important field of\nresearch. Recent advancements in deep neural network technology allow\nresearchers to develop highly accurate models to predict financial trends. We\npropose a novel deep learning model called ST-GAN, or Stochastic Time-series\nGenerative Adversarial Network, that analyzes both financial news texts and\nfinancial numerical data to predict stock trends. We utilize cutting-edge\ntechnology like the Generative Adversarial Network (GAN) to learn the\ncorrelations among textual and numerical data over time. We develop a new\nmethod of training a time-series GAN directly using the learned representations\nof Naive Bayes' sentiment analysis on financial text data alongside technical\nindicators from numerical data. Our experimental results show significant\nimprovement over various existing models and prior research on deep neural\nnetworks for stock price forecasting.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01290v1"
    },
    {
        "title": "Deep Hedging under Rough Volatility",
        "authors": [
            "Blanka Horvath",
            "Josef Teichmann",
            "Zan Zuric"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We investigate the performance of the Deep Hedging framework under training\npaths beyond the (finite dimensional) Markovian setup. In particular we analyse\nthe hedging performance of the original architecture under rough volatility\nmodels with view to existing theoretical results for those. Furthermore, we\nsuggest parsimonious but suitable network architectures capable of capturing\nthe non-Markoviantity of time-series. Secondly, we analyse the hedging\nbehaviour in these models in terms of P\\&L distributions and draw comparisons\nto jump diffusion models if the the rebalancing frequency is realistically\nsmall.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01962v1"
    },
    {
        "title": "Variational Autoencoders: A Hands-Off Approach to Volatility",
        "authors": [
            "Maxime Bergeron",
            "Nicholas Fung",
            "John Hull",
            "Zissis Poulos"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  A volatility surface is an important tool for pricing and hedging\nderivatives. The surface shows the volatility that is implied by the market\nprice of an option on an asset as a function of the option's strike price and\nmaturity. Often, market data is incomplete and it is necessary to estimate\nmissing points on partially observed surfaces. In this paper, we show how\nvariational autoencoders can be used for this task. The first step is to derive\nlatent variables that can be used to construct synthetic volatility surfaces\nthat are indistinguishable from those observed historically. The second step is\nto determine the synthetic surface generated by our latent variables that fits\navailable data as closely as possible. As a dividend of our first step, the\nsynthetic surfaces produced can also be used in stress testing, in market\nsimulators for developing quantitative investment strategies, and for the\nvaluation of exotic options. We illustrate our procedure and demonstrate its\npower using foreign exchange market data.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03945v1"
    },
    {
        "title": "Surrogate Monte Carlo",
        "authors": [
            "A. Christian Silva",
            "Fernando F. Ferreira"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  This article proposes an artificial data generating algorithm that is simple\nand easy to customize. The fundamental concept is to perform random permutation\nof Monte Carlo generated random numbers which conform to the unconditional\nprobability distribution of the original real time series. Similar to\nconstraint surrogate methods, random permutations are only accepted if a given\nobjective function is minimized. The objective function is selected in order to\ndescribe the most important features of the stochastic process. The algorithm\nis demonstrated by producing simulated log-returns of the S\\&P 500 stock index.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08186v1"
    },
    {
        "title": "Deep Learning for Exotic Option Valuation",
        "authors": [
            "Jay Cao",
            "Jacky Chen",
            "John Hull",
            "Zissis Poulos"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  A common approach to valuing exotic options involves choosing a model and\nthen determining its parameters to fit the volatility surface as closely as\npossible. We refer to this as the model calibration approach (MCA). A\ndisadvantage of MCA is that some information in the volatility surface is lost\nduring the calibration process and the prices of exotic options will not in\ngeneral be consistent with those of plain vanilla options. We consider an\nalternative approach where the structure of the user's preferred model is\npreserved but points on the volatility are features input to a neural network.\nWe refer to this as the volatility feature approach (VFA) model. We conduct\nexperiments showing that VFA can be expected to outperform MCA for the\nvolatility surfaces encountered in practice. Once the upfront computational\ntime has been invested in developing the neural network, the valuation of\nexotic options using VFA is very fast.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.12551v2"
    },
    {
        "title": "Fast Barrier Option Pricing by the COS BEM Method in Heston Model",
        "authors": [
            "A. Aimi",
            "C. Guardasoni",
            "L. Ortiz-Gracia",
            "S. Sanfelici"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this work, the Fourier-cosine series (COS) method has been combined with\nthe Boundary Element Method (BEM) for a fast evaluation of barrier option\nprices. After a description of its use in the Black and Scholes (BS) model, the\nfocus of the paper is on the application of the proposed methodology to the\nbarrier option evaluation in the Heston model, where its contribution is\nfundamental to improve computational efficiency and to make BEM appealing among\nFinance practitioners as a valid alternative to Monte Carlo (MC) or other more\ntraditional approaches. An error analysis is provided on the number of terms\nused in the Fourier-cosine series expansion, where the error bound estimation\nis based on the characteristic function of the log-asset price process.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00648v2"
    },
    {
        "title": "Quant 4.0: Engineering Quantitative Investment with Automated,\n  Explainable and Knowledge-driven Artificial Intelligence",
        "authors": [
            "Jian Guo",
            "Saizhuo Wang",
            "Lionel M. Ni",
            "Heung-Yeung Shum"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Quantitative investment (``quant'') is an interdisciplinary field combining\nfinancial engineering, computer science, mathematics, statistics, etc. Quant\nhas become one of the mainstream investment methodologies over the past\ndecades, and has experienced three generations: Quant 1.0, trading by\nmathematical modeling to discover mis-priced assets in markets; Quant 2.0,\nshifting quant research pipeline from small ``strategy workshops'' to large\n``alpha factories''; Quant 3.0, applying deep learning techniques to discover\ncomplex nonlinear pricing rules. Despite its advantage in prediction, deep\nlearning relies on extremely large data volume and labor-intensive tuning of\n``black-box'' neural network models. To address these limitations, in this\npaper, we introduce Quant 4.0 and provide an engineering perspective for\nnext-generation quant. Quant 4.0 has three key differentiating components.\nFirst, automated AI changes quant pipeline from traditional hand-craft modeling\nto the state-of-the-art automated modeling, practicing the philosophy of\n``algorithm produces algorithm, model builds model, and eventually AI creates\nAI''. Second, explainable AI develops new techniques to better understand and\ninterpret investment decisions made by machine learning black-boxes, and\nexplains complicated and hidden risk exposures. Third, knowledge-driven AI is a\nsupplement to data-driven AI such as deep learning and it incorporates prior\nknowledge into modeling to improve investment decision, in particular for\nquantitative value investing. Moreover, we discuss how to build a system that\npractices the Quant 4.0 concept. Finally, we propose ten challenging research\nproblems for quant technology, and discuss potential solutions, research\ndirections, and future trends.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.04020v1"
    },
    {
        "title": "Macroeconomic forecasting and sovereign risk assessment using deep\n  learning techniques",
        "authors": [
            "Anastasios Petropoulos",
            "Vassilis Siakoulis",
            "Konstantinos P. Panousis",
            "Loukas Papadoulas",
            "Sotirios Chatzis"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this study, we propose a novel approach of nowcasting and forecasting the\nmacroeconomic status of a country using deep learning techniques. We focus\nparticularly on the US economy but the methodology can be applied also to other\neconomies. Specifically US economy has suffered a severe recession from 2008 to\n2010 which practically breaks out conventional econometrics model attempts.\nDeep learning has the advantage that it models all macro variables\nsimultaneously taking into account all interdependencies among them and\ndetecting non-linear patterns which cannot be easily addressed under a\nunivariate modelling framework. Our empirical results indicate that the deep\nlearning methods have a superior out-of-sample performance when compared to\ntraditional econometric techniques such as Bayesian Model Averaging (BMA).\nTherefore our results provide a concise view of a more robust method for\nassessing sovereign risk which is a crucial component in investment and\nmonetary decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09856v1"
    },
    {
        "title": "Select and Trade: Towards Unified Pair Trading with Hierarchical\n  Reinforcement Learning",
        "authors": [
            "Weiguang Han",
            "Boyi Zhang",
            "Qianqian Xie",
            "Min Peng",
            "Yanzhao Lai",
            "Jimin Huang"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Pair trading is one of the most effective statistical arbitrage strategies\nwhich seeks a neutral profit by hedging a pair of selected assets. Existing\nmethods generally decompose the task into two separate steps: pair selection\nand trading. However, the decoupling of two closely related subtasks can block\ninformation propagation and lead to limited overall performance. For pair\nselection, ignoring the trading performance results in the wrong assets being\nselected with irrelevant price movements, while the agent trained for trading\ncan overfit to the selected assets without any historical information of other\nassets. To address it, in this paper, we propose a paradigm for automatic pair\ntrading as a unified task rather than a two-step pipeline. We design a\nhierarchical reinforcement learning framework to jointly learn and optimize two\nsubtasks. A high-level policy would select two assets from all possible\ncombinations and a low-level policy would then perform a series of trading\nactions. Experimental results on real-world stock data demonstrate the\neffectiveness of our method on pair trading compared with both existing pair\nselection and trading methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10724v2"
    },
    {
        "title": "Long-Term Modeling of Financial Machine Learning for Active Portfolio\n  Management",
        "authors": [
            "Kazuki Amagai",
            "Tomoya Suzuki"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In the practical business of asset management by investment trusts and the\nlike, the general practice is to manage over the medium to long term owing to\nthe burden of operations and increase in transaction costs with the increase in\nturnover ratio. However, when machine learning is used to construct a\nmanagement model, the number of learning data decreases with the increase in\nthe long-term time scale; this causes a decline in the learning precision.\nAccordingly, in this study, data augmentation was applied by the combined use\nof not only the time scales of the target tasks but also the learning data of\nshorter term time scales, demonstrating that degradation of the generalization\nperformance can be inhibited even if the target tasks of machine learning have\nlong-term time scales. Moreover, as an illustration of how this data\naugmentation can be applied, we conducted portfolio management in which machine\nlearning of a multifactor model was done by an autoencoder and mispricing was\nused from the estimated theoretical values. The effectiveness could be\nconfirmed in not only the stock market but also the FX market, and a\ngeneral-purpose management model could be constructed in various financial\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.12346v1"
    },
    {
        "title": "Forex Trading Strategy That Might Be Executed Due to the Popularity of\n  Gotobi Anomaly",
        "authors": [
            "Hiroki Bessho",
            "Takanari Sugimoto",
            "Tomoya Suzuki"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Our previous research has confirmed that the USD/JPY rate tends to rise\ntoward 9:55 every morning in the Gotobi days, which are divisible by five. This\nis called the Gotobi anomaly. In the present study, we verify the possible\ntrading strategy and its validity under the condition that investors recognize\nthe existence of the anomaly. Moreover, we illustrate the possibility that the\nwealth of Japanese companies might leak to FX traders due to the arbitrage\nopportunity if Japanese companies blindly keep making payments in the Gotobi\ndays as a business custom.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13204v1"
    },
    {
        "title": "Monte Carlo-based tail exponent estimator",
        "authors": [
            "Jozef Barunik",
            "Lukas Vacha"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In this paper we propose a new approach to estimation of the tail exponent in\nfinancial stock markets. We begin the study with the finite sample behavior of\nthe Hill estimator under {\\alpha}-stable distributions. Using large Monte Carlo\nsimulations, we show that the Hill estimator overestimates the true tail\nexponent and can hardly be used on samples with small length. Utilizing our\nresults, we introduce a Monte Carlo-based method of estimation for the tail\nexponent. Our proposed method is not sensitive to the choice of tail size and\nworks well also on small data samples. The new estimator also gives unbiased\nresults with symmetrical confidence intervals. Finally, we demonstrate the\npower of our estimator on the international world stock market indices. On the\ntwo separate periods of 2002-2005 and 2006-2009, we estimate the tail exponent.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.4781v1"
    },
    {
        "title": "Measures of Causality in Complex Datasets with application to financial\n  data",
        "authors": [
            "Anna Zaremba",
            "Tomaso Aste"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  This article investigates the causality structure of financial time series.\nWe concentrate on three main approaches to measuring causality: linear Granger\ncausality, kernel generalisations of Granger causality (based on ridge\nregression and the Hilbert--Schmidt norm of the cross-covariance operator) and\ntransfer entropy, examining each method and comparing their theoretical\nproperties, with special attention given to the ability to capture nonlinear\ncausality. We also present the theoretical benefits of applying non-symmetrical\nmeasures rather than symmetrical measures of dependence. We apply the measures\nto a range of simulated and real data. The simulated data sets were generated\nwith linear and several types of nonlinear dependence, using bivariate, as well\nas multivariate settings. An application to real-world financial data\nhighlights the practical difficulties, as well as the potential of the methods.\nWe use two real data sets: (1) U.S. inflation and one-month Libor; (2) S$\\&$P\ndata and exchange rates for the following currencies: AUDJPY, CADJPY, NZDJPY,\nAUDCHF, CADCHF, NZDCHF. Overall, we reach the conclusion that no single method\ncan be recognised as the best in all circumstances, and each of the methods has\nits domain of best applicability. We also highlight areas for improvement and\nfuture research.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1457v2"
    },
    {
        "title": "An efficient algorithm for the calculation of reserves for non-unit\n  linked life policies",
        "authors": [
            "Mark Tucker",
            "J. Mark Bull"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The underlying stochastic nature of the requirements for the Solvency II\nregulations has introduced significant challenges if the required calculations\nare to be performed correctly, without resorting to excessive approximations,\nwithin practical timescales. It is generally acknowledged by practising\nactuaries within UK life offices that it is currently impossible to correctly\nfulfil the requirements imposed by Solvency II using existing computational\ntechniques based on commercially available valuation packages. Our work has\nalready shown that it is possible to perform profitability calculations at a\nfar higher rate than is achievable using commercial packages. One of the key\nfactors in achieving these gains is to calculate reserves using recurrence\nrelations that scale linearly with the number of time steps. Here, we present a\ngeneral vector recurrence relation which can be used for a wide range of\nnon-unit linked policies that are covered by Solvency II; such contracts\ninclude annuities, term assurances, and endowments. Our results suggest that by\nusing an optimised parallel implementation of this algorithm, on an affordable\nhardware platform, it is possible to perform the `brute force' approach to\ndemonstrating solvency in a realistic timescale (of the order of a few hours).\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1757v2"
    },
    {
        "title": "A Polynomial Scheme of Asymptotic Expansion for Backward SDEs and Option\n  pricing",
        "authors": [
            "Masaaki Fujii"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  A new asymptotic expansion scheme for backward SDEs (BSDEs) is proposed.The\nperturbation parameter is introduced just to scale the forward stochastic\nvariables within a BSDE. In contrast to the standard small-diffusion asymptotic\nexpansion method, the dynamics of variables given by the forward SDEs is\ntreated exactly. Although it requires a special form of the quadratic\ncovariation terms of the continuous part, it allows rather generic drift as\nwell as jump components to exist. The resultant approximation is given by a\npolynomial function in terms of the unperturbed forward variables whose\ncoefficients are uniquely specified by the solution of the recursive system of\nlinear ODEs. Applications to a jump-extended Heston and lambda-SABR models for\nEuropean contingent claims, as well as the utility-optimization problem in the\npresence of a terminal liability are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.0378v4"
    },
    {
        "title": "An explicit Euler scheme with strong rate of convergence for financial\n  SDEs with non-Lipschitz coefficients",
        "authors": [
            "Jean-Francois Chassagneux",
            "Antoine Jacquier",
            "Ivo Mihaylov"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We consider the approximation of stochastic differential equations (SDEs)\nwith non-Lipschitz drift or diffusion coefficients. We present a modified\nexplicit Euler-Maruyama discretisation scheme that allows us to prove strong\nconvergence, with a rate. Under some regularity and integrability conditions,\nwe obtain the optimal strong error rate. We apply this scheme to SDEs widely\nused in the mathematical finance literature, including the\nCox-Ingersoll-Ross~(CIR), the 3/2 and the Ait-Sahalia models, as well as a\nfamily of mean-reverting processes with locally smooth coefficients. We\nnumerically illustrate the strong convergence of the scheme and demonstrate its\nefficiency in a multilevel Monte Carlo setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.3561v4"
    },
    {
        "title": "Recombining binomial tree for constant elasticity of variance process",
        "authors": [
            "Hi Jun Choe",
            "Jeong Ho Chu",
            "So Jeong Shin"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The theme in this paper is the recombining binomial tree to price American\nput option when the underlying stock follows constant elasticity of\nvariance(CEV) process. Recombining nodes of binomial tree are decided from\nfinite difference scheme to emulate CEV process and the tree has a linear\ncomplexity. Also it is derived from the differential equation the asymptotic\nenvelope of the boundary of tree. Conducting numerical experiments, we confirm\nthe convergence and accuracy of the pricing by our recombining binomial tree\nmethod. As a result, we can compute the price of American put option under CEV\nmodel, effectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.5955v1"
    },
    {
        "title": "A Fourier interpolation method for numerical solution of FBSDEs: Global\n  convergence, stability, and higher order discretizations",
        "authors": [
            "Polynice Oyono Ngou",
            "Cody Hyndman"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The convolution method for the numerical solution of forward-backward\nstochastic differential equations (FBSDEs), introduced in [21], uses a uniform\nspace grid. In this paper we utilize a tree-like spatial discretization that\napproximates the BSDE on the tree, so that no spatial interpolation procedure\nis necessary. In addition to suppressing extrapolation error, leading to a\nglobally convergent numerical solution for the FBSDE, we provide explicit\nconvergence rates. On this alternative grid the conditional expectations\ninvolved in the time discretization of the BSDE are computed using Fourier\nanalysis and the fast Fourier transform (FFT) algorithm. The method is then\nextended to higher-order time discretizations of FBSDEs. Numerical results\ndemonstrating convergence are presented using a commodity price model,\nincorporating seasonality, and forward prices.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.8595v3"
    },
    {
        "title": "A detailed heterogeneous agent model for a single asset financial market\n  with trading via an order book",
        "authors": [
            "Roberto Mota Navarro",
            "Hernán Larralde Ridaura"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We present an agent based model of a single asset financial market that is\ncapable of replicating several non-trivial statistical properties observed in\nreal financial markets, generically referred to as stylized facts. While\nprevious models reported in the literature are also capable of replicating some\nof these statistical properties, in general, they tend to oversimplify either\nthe trading mechanisms or the behavior of the agents. In our model, we strived\nto capture the most important characteristics of both aspects to create agents\nthat employ strategies inspired on those used in real markets, and, at the same\ntime, a more realistic trade mechanism based on a double auction order book. We\nstudy the role of the distinct types of trader on the return statistics:\nspecifically, correlation properties (or lack thereof), volatilty clustering,\nheavy tails, and the degree to which the distribution can be described by a\nlog-normal. Further, by introducing the practice of profit taking, our model is\nalso capable of replicating the stylized fact related to an asymmetry in the\ndistribution of losses and gains.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.00229v2"
    },
    {
        "title": "Stock prices, inflation and inflation uncertainty in the U.S.: Testing\n  the long-run relationship considering Dow Jones sector indexes",
        "authors": [
            "Claudiu Albulescu",
            "Christian Aubin",
            "Daniel Goyeau"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We test for the long-run relationship between stock prices, inflation and its\nuncertainty for different U.S. sector stock indexes, over the period 2002M7 to\n2015M10. For this purpose we use a cointegration analysis with one structural\nbreak to capture the crisis effect, and we assess the inflation uncertainty\nbased on a time-varying unobserved component model. In line with recent\nempirical studies we discover that in the long-run, the inflation and its\nuncertainty negatively impact the stock prices, opposed to the well-known\nFisher effect. In addition we show that for several sector stock indexes the\nnegative effect of inflation and its uncertainty vanishes after the crisis\nsetup. However, in the short-run the results provide evidence in the favor of a\nnegative impact of uncertainty, while the inflation has no significant\ninfluence on stock prices, except for the consumption indexes. The\nconsideration of business cycle effects confirms our findings, which proves\nthat the results are robust, both for the long-and the short-run relationships.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.01231v1"
    },
    {
        "title": "Contagion and Stability in Financial Networks",
        "authors": [
            "Seyyed Mostafa Mousavi",
            "Robert Mackay",
            "Alistair Tucker"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  This paper investigates two mechanisms of financial contagion that are,\nfirstly, the correlated exposure of banks to the same source of risk, and\nsecondly the direct exposure of banks in the interbank market. It will consider\na random network of banks which are connected through the inter-bank market and\nwill discuss the desirable level of banks exposure to the same sources of risk,\nthat is investment in similar portfolios, for different levels of network\nconnectivity when peering through the lens of the systemic cost incurred to the\neconomy from the banks simultaneous failure. It demonstrates that for all\nlevels of network connectivity, certain levels of diversifying individual banks\ndiversifications are not optimum under any condition. So, given an acceptable\nlevel of systemic cost, the regulator could let banks decrease their capital\nbuffers by moving away from the non-optimum area.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.04099v1"
    },
    {
        "title": "Some Mathematical Aspects of Price Optimisation",
        "authors": [
            "Y. Bai",
            "E. Hashorva",
            "G. Ratovomirija",
            "M. Tamraz"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  Calculation of an optimal tariff is a principal challenge for pricing\nactuaries. In this contribution we are concerned with the renewal insurance\nbusiness discussing various mathematical aspects of calculation of an optimal\nrenewal tariff. Our motivation comes from two important actuarial tasks, namely\na) construction of an optimal renewal tariff subject to business and technical\nconstraints, and b) determination of an optimal allocation of certain premium\nloadings. We consider both continuous and discrete optimisation and then\npresent several algorithmic sub-optimal solutions. Additionally, we explore\nsome simulation techniques. Several illustrative examples show both the\ncomplexity and the importance of the optimisation approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.05814v1"
    },
    {
        "title": "Realized volatility and parametric estimation of Heston SDEs",
        "authors": [
            "Robert Azencott",
            "Peng Ren",
            "Ilya Timofeyev"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We present a detailed analysis of \\emph{observable} moments based parameter\nestimators for the Heston SDEs jointly driving the rate of returns $R_t$ and\nthe squared volatilities $V_t$. Since volatilities are not directly observable,\nour parameter estimators are constructed from empirical moments of realized\nvolatilities $Y_t$, which are of course observable. Realized volatilities are\ncomputed over sliding windows of size $\\varepsilon$, partitioned into\n$J(\\varepsilon)$ intervals. We establish criteria for the joint selection of\n$J(\\varepsilon)$ and of the sub-sampling frequency of return rates data.\n  We obtain explicit bounds for the $L^q$ speed of convergence of realized\nvolatilities to true volatilities as $\\varepsilon \\to 0$. In turn, these bounds\nprovide also $L^q$ speeds of convergence of our observable estimators for the\nparameters of the Heston volatility SDE.\n  Our theoretical analysis is supplemented by extensive numerical simulations\nof joint Heston SDEs to investigate the actual performances of our moments\nbased parameter estimators. Our results provide practical guidelines for\nadequately fitting Heston SDEs parameters to observed stock prices series.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.04566v2"
    },
    {
        "title": "Dynamic programming for optimal stopping via pseudo-regression",
        "authors": [
            "Christian Bayer",
            "Martin Redmann",
            "John Schoenmakers"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We introduce new variants of classical regression-based algorithms for\noptimal stopping problems based on computation of regression coefficients by\nMonte Carlo approximation of the corresponding $L^2$ inner products instead of\nthe least-squares error functional. Coupled with new proposals for simulation\nof the underlying samples, we call the approach \"pseudo regression\". A detailed\nconvergence analysis is provided and it is shown that the approach\nasymptotically leads to less computational cost for a pre-specified error\ntolerance, hence to lower complexity. The method is justified by numerical\nexamples.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.04725v3"
    },
    {
        "title": "The Co-Terminal Swap Market Model with Bergomi Stochastic Volatility",
        "authors": [
            "Kenjiro Oya"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this article, we apply the forward variance modeling approach by L.Bergomi\nto the co-terminal swap market model. We build an interest rate model for which\nall the market price changes of hedging instruments, interest rate swaps and\nEuropean swaptions, are interpreted as the state variable variations, and no\ndiffusion parameter calibration procedure is required. The model provides quite\nsimple profit and loss (PnL) formula, with which we can easily understand where\na material PnL trend comes from when it appears, and consider how we should\nmodify the model parameters. The model has high flexibility to control the\nmodel dynamics because parameter calibration is unnecessary and the model\nparameters can be used solely for the purpose of the model dynamics control.\nWith the model, the position management of the exotic interest rate products,\ne.g. Bermudan swaptions, can be carried out in a more sophisticated and\nsystematic manner. A numerical experiment is performed to show the\neffectiveness of the approach for a Canary swaption, which is a special form of\na Bermudan swaption.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.08054v1"
    },
    {
        "title": "Deeply Learning Derivatives",
        "authors": [
            "Ryan Ferguson",
            "Andrew Green"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  This paper uses deep learning to value derivatives. The approach is broadly\napplicable, and we use a call option on a basket of stocks as an example. We\nshow that the deep learning model is accurate and very fast, capable of\nproducing valuations a million times faster than traditional models. We develop\na methodology to randomly generate appropriate training data and explore the\nimpact of several parameters including layer width and depth, training data\nquality and quantity on model speed and accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.02233v4"
    },
    {
        "title": "Measuring Systematic Risk with Neural Network Factor Model",
        "authors": [
            "Jeonggyu Huh"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we measure systematic risk with a new nonparametric factor\nmodel, the neural network factor model. The suitable factors for systematic\nrisk can be naturally found by inserting daily returns on a wide range of\nassets into the bottleneck network. The network-based model does not stick to a\nprobabilistic structure unlike parametric factor models, and it does not need\nfeature engineering because it selects notable features by itself. In addition,\nwe compare performance between our model and the existing models using 20-year\ndata of S&P 100 components. Although the new model can not outperform the best\nones among the parametric factor models due to limitations of the variational\ninference, the estimation method used for this study, it is still noteworthy in\nthat it achieves the performance as best the comparable models could without\nany prior knowledge.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.04925v1"
    },
    {
        "title": "Pricing American Options by Exercise Rate Optimization",
        "authors": [
            "Christian Bayer",
            "Raúl Tempone",
            "Sören Wolfers"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We present a novel method for the numerical pricing of American options based\non Monte Carlo simulation and the optimization of exercise strategies. Previous\nsolutions to this problem either explicitly or implicitly determine so-called\noptimal exercise regions, which consist of points in time and space at which a\ngiven option is exercised. In contrast, our method determines the exercise\nrates of randomized exercise strategies. We show that the supremum of the\ncorresponding stochastic optimization problem provides the correct option\nprice. By integrating analytically over the random exercise decision, we obtain\nan objective function that is differentiable with respect to perturbations of\nthe exercise rate even for finitely many sample paths. The global optimum of\nthis function can be approached gradually when starting from a constant\nexercise rate.\n  Numerical experiments on vanilla put options in the multivariate\nBlack-Scholes model and a preliminary theoretical analysis underline the\nefficiency of our method, both with respect to the number of\ntime-discretization steps and the required number of degrees of freedom in the\nparametrization of the exercise rates. Finally, we demonstrate the flexibility\nof our method through numerical experiments on max call options in the\nclassical Black-Scholes model, and vanilla put options in both the Heston model\nand the non-Markovian rough Bergomi model.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07300v2"
    },
    {
        "title": "Constructing Financial Sentimental Factors in Chinese Market Using\n  Natural Language Processing",
        "authors": [
            "Junfeng Jiang",
            "Jiahao Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we design an integrated algorithm to evaluate the sentiment of\nChinese market. Firstly, with the help of the web browser automation, we crawl\na lot of news and comments from several influential financial websites\nautomatically. Secondly, we use techniques of Natural Language Processing(NLP)\nunder Chinese context, including tokenization, Word2vec word embedding and\nsemantic database WordNet, to compute Senti-scores of these news and comments,\nand then construct the sentimental factor. Here, we build a finance-specific\nsentimental lexicon so that the sentimental factor can reflect the sentiment of\nfinancial market but not the general sentiments as happiness, sadness, etc.\nThirdly, we also implement an adjustment of the standard sentimental factor.\nOur experimental performance shows that there is a significant correlation\nbetween our standard sentimental factor and the Chinese market, and the\nadjusted factor is even more informative, having a stronger correlation with\nthe Chinese market. Therefore, our sentimental factors can be important\nreferences when making investment decisions. Especially during the Chinese\nmarket crash in 2015, the Pearson correlation coefficient of adjusted\nsentimental factor with SSE is 0.5844, which suggests that our model can\nprovide a solid guidance, especially in the special period when the market is\ninfluenced greatly by public sentiment.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.08390v1"
    },
    {
        "title": "Leveraging Financial News for Stock Trend Prediction with\n  Attention-Based Recurrent Neural Network",
        "authors": [
            "Huicheng Liu"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Stock market prediction is one of the most attractive research topic since\nthe successful prediction on the market's future movement leads to significant\nprofit. Traditional short term stock market predictions are usually based on\nthe analysis of historical market data, such as stock prices, moving averages\nor daily returns. However, financial news also contains useful information on\npublic companies and the market. Existing methods in finance literature exploit\nsentiment signal features, which are limited by not considering factors such as\nevents and the news context. We address this issue by leveraging deep neural\nmodels to extract rich semantic features from news text. In particular, a\nBidirectional-LSTM are used to encode the news text and capture the context\ninformation, self attention mechanism are applied to distribute attention on\nmost relative words, news and days. In terms of predicting directional changes\nin both Standard & Poor's 500 index and individual companies stock price, we\nshow that this technique is competitive with other state of the art approaches,\ndemonstrating the effectiveness of recent NLP technology advances for\ncomputational finance.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06173v1"
    },
    {
        "title": "Neural Network for CVA: Learning Future Values",
        "authors": [
            "Jian-Huang She",
            "Dan Grecu"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  A new challenge to quantitative finance after the recent financial crisis is\nthe study of credit valuation adjustment (CVA), which requires modeling of the\nfuture values of a portfolio. In this paper, following recent work in [Weinan\nE(2017), Han(2017)], we apply deep learning to attack this problem. The future\nvalues are parameterized by neural networks, and the parameters are then\ndetermined through optimization. Two concrete products are studied: Bermudan\nswaption and Mark-to-Market cross-currency swap. We obtain their expected\npositive/negative exposures, and further study the resulting functional form of\nfuture values. Such an approach represents a new framework for modeling XVA,\nand it also sheds new lights on other methods like American Monte Carlo.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08726v1"
    },
    {
        "title": "Hedging and Pricing European-type, Early-Exercise and Discrete Barrier\n  Options using Algorithm for the Convolution of Legendre Series",
        "authors": [
            "Tat Lung Chan",
            "Nicholas Hale"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  This paper applies an algorithm for the convolution of compactly supported\nLegendre series (the CONLeg method) (cf. Hale and Townsend 2014a), to\npricing/hedging European-type, early-exercise and discrete-monitored barrier\noptions under a Levy process. The paper employs Chebfun (cf. Trefethen et al.\n2014) in computational finance and provides a quadrature-free approach by\napplying the Chebyshev series in financial modelling. A significant advantage\nof using the CONLeg method is to formulate option pricing and option Greek\ncurves rather than individual prices/values. Moreover, the CONLeg method can\nyield high accuracy in option pricing and hedging when the risk-free smooth\nprobability density function (PDF) is smooth/non-smooth. Finally, we show that\nour method can accurately price/hedge options deep in/out of the money and with\nvery long/short maturities. Compared with existing techniques, the CONLeg\nmethod performs either favourably or comparably in numerical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.09257v3"
    },
    {
        "title": "Bull Bear Balance: A Cluster Analysis of Socially Informed Financial\n  Volatility",
        "authors": [
            "Jonathan Manfield",
            "Derek Lukacsko",
            "Thársis T. P. Souza"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Using a method rooted in information theory, we present results that have\nidentified a large set of stocks for which social media can be informative\nregarding financial volatility. By clustering stocks based on the joint feature\nsets of social and financial variables, our research provides an important\ncontribution by characterizing the conditions in which social media signals can\nlead financial volatility. The results indicate that social media is most\ninformative about financial market volatility when the ratio of bullish to\nbearish sentiment is high, even when the number of messages is low. The\nrobustness of these findings is verified across 500 stocks from both NYSE and\nNASDAQ exchanges. The reported results are reproducible via an open-source\nlibrary for social-financial analysis made freely available.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.10195v1"
    },
    {
        "title": "Timing the market: the economic value of price extremes",
        "authors": [
            "Haibin Xie",
            "Shouyang Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  By decomposing asset returns into potential maximum gain (PMG) and potential\nmaximum loss (PML) with price extremes, this study empirically investigated the\nrelationships between PMG and PML. We found significant asymmetry between PMG\nand PML. PML significantly contributed to forecasting PMG but not vice versa.\nWe further explored the power of this asymmetry for predicting asset returns\nand found it could significantly improve asset return predictability in both\nin-sample and out-of-sample forecasting. Investors who incorporate this\nasymmetry into their investment decisions can get substantial utility gains.\nThis asymmetry remains significant even when controlling for macroeconomic\nvariables, technical indicators, market sentiment, and skewness. Moreover, this\nasymmetry was found to be quite general across different countries.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.01832v1"
    },
    {
        "title": "Pricing path-dependent Bermudan options using Wiener chaos expansion: an\n  embarrassingly parallel approach",
        "authors": [
            "Jérôme Lelong"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this work, we propose a new policy iteration algorithm for pricing\nBermudan options when the payoff process cannot be written as a function of a\nlifted Markov process. Our approach is based on a modification of the\nwell-known Longstaff Schwartz algorithm, in which we basically replace the\nstandard least square regression by a Wiener chaos expansion. Not only does it\nallow us to deal with a non Markovian setting, but it also breaks the\nbottleneck induced by the least square regression as the coefficients of the\nchaos expansion are given by scalar products on the L^2 space and can therefore\nbe approximated by independent Monte Carlo computations. This key feature\nenables us to provide an embarrassingly parallel algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.05672v2"
    },
    {
        "title": "Capturing Financial markets to apply Deep Reinforcement Learning",
        "authors": [
            "Souradeep Chakraborty"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper we explore the usage of deep reinforcement learning algorithms\nto automatically generate consistently profitable, robust, uncorrelated trading\nsignals in any general financial market. In order to do this, we present a\nnovel Markov decision process (MDP) model to capture the financial trading\nmarkets. We review and propose various modifications to existing approaches and\nexplore different techniques like the usage of technical indicators, to\nsuccinctly capture the market dynamics to model the markets. We then go on to\nuse deep reinforcement learning to enable the agent (the algorithm) to learn\nhow to take profitable trades in any market on its own, while suggesting\nvarious methodology changes and leveraging the unique representation of the\nFMDP (financial MDP) to tackle the primary challenges faced in similar works.\nThrough our experimentation results, we go on to show that our model could be\neasily extended to two very different financial markets and generates a\npositively robust performance in all conducted experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04373v3"
    },
    {
        "title": "Accelerated Share Repurchase and other buyback programs: what neural\n  networks can bring",
        "authors": [
            "Olivier Guéant",
            "Iuliia Manziuk",
            "Jiang Pu"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  When firms want to buy back their own shares, they have a choice between\nseveral alternatives. If they often carry out open market repurchase, they also\nincreasingly rely on banks through complex buyback contracts involving option\ncomponents, e.g. accelerated share repurchase contracts, VWAP-minus\nprofit-sharing contracts, etc. The entanglement between the execution problem\nand the option hedging problem makes the management of these contracts a\ndifficult task that should not boil down to simple Greek-based risk hedging,\ncontrary to what happens with classical books of options. In this paper, we\npropose a machine learning method to optimally manage several types of buyback\ncontract. In particular, we recover strategies similar to those obtained in the\nliterature with partial differential equation and recombinant tree methods and\nshow that our new method, which does not suffer from the curse of\ndimensionality, enables to address types of contract that could not be\naddressed with grid or tree methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.09753v2"
    },
    {
        "title": "CVA and vulnerable options in stochastic volatility models",
        "authors": [
            "Elisa Alos",
            "Fabio Antonelli",
            "Alessandro Ramponi",
            "Sergio Scarlatti"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this work we want to provide a general principle to evaluate the CVA\n(Credit Value Adjustment) for a vulnerable option, that is an option subject to\nsome default event, concerning the solvability of the issuer. CVA is needed to\nevaluate correctly the contract and it is particularly important in presence of\nWWR (Wrong Way Risk), when a credit deterioration determines an increase of the\nclaim's price. In particular, we are interested in evaluating the CVA in\nstochastic volatility models for the underlying's price (which often fit quite\nwell the market's prices) when admitting correlation with the default event. By\ncunningly using Ito's calculus, we provide a general representation formula\napplicable to some popular models such as SABR, Hull \\& White and Heston, which\nexplicitly shows the correction in CVA due to the processes correlation. Later,\nwe specialize this formula and construct its approximation for the three\nselected models. Lastly, we run a numerical study to test the formula's\naccuracy, comparing our results with Monte Carlo simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12922v1"
    },
    {
        "title": "The option pricing model based on time values: an application of the\n  universal approximation theory on unbounded domains",
        "authors": [
            "Yang Qu",
            "Ming-Xi Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We propose a time value related decision function to treat a classical option\npricing problem raised by Hutchinson-Lo-Poggio. In numerical experiments, the\nnew decision function significantly improves the original model of\nHutchinson-Lo-Poggio with faster convergence and better generalization\nperformance. By proving a novel universal approximation theorem, we show that\nour decision function rather than Hutchinson-Lo-Poggio's can be approximated on\nthe entire domain of definition by neural networks. Thus the experimental\nresults are partially explained by the representation properties of networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.01490v3"
    },
    {
        "title": "Weighted Monte Carlo with least squares and randomized extended Kaczmarz\n  for option pricing",
        "authors": [
            "Damir Filipović",
            "Kathrin Glau",
            "Yuji Nakatsukasa",
            "Francesco Statti"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We propose a methodology for computing single and multi-asset European option\nprices, and more generally expectations of scalar functions of (multivariate)\nrandom variables. This new approach combines the ability of Monte Carlo\nsimulation to handle high-dimensional problems with the efficiency of function\napproximation. Specifically, we first generalize the recently developed method\nfor multivariate integration in [arXiv:1806.05492] to integration with respect\nto probability measures. The method is based on the principle \"approximate and\nintegrate\" in three steps i) sample the integrand at points in the integration\ndomain, ii) approximate the integrand by solving a least-squares problem, iii)\nintegrate the approximate function. In high-dimensional applications we face\nmemory limitations due to large storage requirements in step ii). Combining\nweighted sampling and the randomized extended Kaczmarz algorithm we obtain a\nnew efficient approach to solve large-scale least-squares problems. Our\nconvergence and cost analysis along with numerical experiments show the\neffectiveness of the method in both low and high dimensions, and under the\nassumption of a limited number of available simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.07241v1"
    },
    {
        "title": "Deep reinforcement learning for market making in corporate bonds:\n  beating the curse of dimensionality",
        "authors": [
            "Olivier Guéant",
            "Iuliia Manziuk"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In corporate bond markets, which are mainly OTC markets, market makers play a\ncentral role by providing bid and ask prices for a large number of bonds to\nasset managers from all around the globe. Determining the optimal bid and ask\nquotes that a market maker should set for a given universe of bonds is a\ncomplex task. Useful models exist, most of them inspired by that of Avellaneda\nand Stoikov. These models describe the complex optimization problem faced by\nmarket makers: proposing bid and ask prices in an optimal way for making money\nout of the difference between bid and ask prices while mitigating the market\nrisk associated with holding inventory. While most of the models only tackle\none-asset market making, they can often be generalized to a multi-asset\nframework. However, the problem of solving numerically the equations\ncharacterizing the optimal bid and ask quotes is seldom tackled in the\nliterature, especially in high dimension. In this paper, our goal is to propose\na numerical method for approximating the optimal bid and ask quotes over a\nlarge universe of bonds in a model \\`a la Avellaneda-Stoikov. Because we aim at\nconsidering a large universe of bonds, classical finite difference methods as\nthose discussed in the literature cannot be used and we present therefore a\ndiscrete-time method inspired by reinforcement learning techniques. More\nprecisely, the approach we propose is a model-based actor-critic-like algorithm\ninvolving deep neural networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13205v1"
    },
    {
        "title": "Transformers for Limit Order Books",
        "authors": [
            "James Wallbridge"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We introduce a new deep learning architecture for predicting price movements\nfrom limit order books. This architecture uses a causal convolutional network\nfor feature extraction in combination with masked self-attention to update\nfeatures based on relevant contextual information. This architecture is shown\nto significantly outperform existing architectures such as those using\nconvolutional networks (CNN) and Long-Short Term Memory (LSTM) establishing a\nnew state-of-the-art benchmark for the FI-2010 dataset.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.00130v1"
    },
    {
        "title": "PDGM: a Neural Network Approach to Solve Path-Dependent Partial\n  Differential Equations",
        "authors": [
            "Yuri F. Saporito",
            "Zhaoyu Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper, we propose a novel numerical method for Path-Dependent Partial\nDifferential Equations (PPDEs). These equations firstly appeared in the seminal\nwork of Dupire [2009], where the functional It\\^o calculus was developed to\ndeal with path-dependent financial derivatives contracts. More specificaly, we\ngeneralize the Deep Galerking Method (DGM) of Sirignano and Spiliopoulos [2018]\nto deal with these equations. The method, which we call Path-Dependent DGM\n(PDGM), consists of using a combination of feed-forward and Long Short-Term\nMemory architectures to model the solution of the PPDE. We then analyze several\nnumerical examples, many from the Financial Mathematics literature, that show\nthe capabilities of the method under very different situations.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.02035v2"
    },
    {
        "title": "Predicting Stock Returns with Batched AROW",
        "authors": [
            "Rachid Guennouni Hassani",
            "Alexis Gilles",
            "Emmanuel Lassalle",
            "Arthur Dénouveaux"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We extend the AROW regression algorithm developed by Vaits and Crammer in\n[VC11] to handle synchronous mini-batch updates and apply it to stock return\nprediction. By design, the model should be more robust to noise and adapt\nbetter to non-stationarity compared to a simple rolling regression. We\nempirically show that the new model outperforms more classical approaches by\nbacktesting a strategy on S\\&P500 stocks.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.03076v2"
    },
    {
        "title": "Coronavirus and financial volatility: 40 days of fasting and fear",
        "authors": [
            "Claudiu Albulescu"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  40 days after the start of the international monitoring of COVID-19, we\nsearch for the effect of official announcements regarding new cases of\ninfection and death ratio on the financial markets volatility index (VIX).\nWhereas the new cases reported in China and outside China have a mixed effect\non financial volatility, the death ratio positively influences VIX, that\noutside China triggering a more important impact. In addition, the higher the\nnumber of affected countries, the higher the financial volatility is.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.04005v1"
    },
    {
        "title": "Copula-based local dependence between energy, agriculture and metal\n  commodity markets",
        "authors": [
            "Claudiu Albulescu",
            "Aviral Tiwari",
            "Qiang Ji"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper studies the extreme dependencies between energy, agriculture and\nmetal commodity markets, with a focus on local co-movements, allowing the\nidentification of asymmetries and changing trend in the degree of co-movements.\nMore precisely, starting from a non-parametric mixture copula, we use a novel\ncopula-based local Kendall's tau approach to measure nonlinear local dependence\nin regions. In all pairs of commodity indexes, we find increased co-movements\nin extreme situations, a stronger dependence between energy and other commodity\nmarkets at lower tails, and a 'V-type' local dependence for the energy-metal\npairs. The three-dimensional Kendall's tau plot for upper tails in quantiles\nshows asymmetric co-movements in the energy-metal pairs, which tend to become\nnegative at peak returns. Therefore, we show that the energy market can offer\ndiversification solutions for risk management in the case of extreme bull\nmarket events.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.04007v1"
    },
    {
        "title": "Market states: A new understanding",
        "authors": [
            "Hirdesh K. Pharasi",
            "Eduard Seligman",
            "Thomas H. Seligman"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We present the clustering analysis of the financial markets of S&P 500 (USA)\nand Nikkei 225 (JPN) markets over a period of 2006-2019 as an example of a\ncomplex system. We investigate the statistical properties of correlation\nmatrices constructed from the sliding epochs. The correlation matrices can be\nclassified into different clusters, named as market states based on the\nsimilarity of correlation structures. We cluster the S&P 500 market into four\nand Nikkei 225 into six market states by optimizing the value of intracluster\ndistances. The market shows transitions between these market states and the\nstatistical properties of the transitions to critical market states can\nindicate likely precursors to the catastrophic events. We also analyze the same\nclustering technique on surrogate data constructed from average correlations of\nmarket states and the fluctuations arise due to the white noise of short time\nseries. We use the correlated Wishart orthogonal ensemble for the construction\nof surrogate data whose average correlation equals the average of the real\ndata.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07058v2"
    },
    {
        "title": "Do COVID-19 and crude oil prices drive the US economic policy\n  uncertainty?",
        "authors": [
            "Claudiu Albulescu"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper investigates the effect of the novel coronavirus and crude oil\nprices on the United States (US) economic policy uncertainty (EPU). Using daily\ndata for the period January 21-March 13, 2020, our Autoregressive Distributed\nLag (ARDL) model shows that the new infection cases reported at global level,\nand the death ratio, have no significant effect on the US EPU, whereas the oil\nprice negative dynamics leads to increased uncertainty. However, analyzing the\nsituation outside China, we discover that both new case announcements and the\nCOVID-19 associated death ratio have a positive influence on the US EPU.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07591v1"
    },
    {
        "title": "Streaming Approach to Quadratic Covariation Estimation Using Financial\n  Ultra-High-Frequency Data",
        "authors": [
            "Vladimír Holý",
            "Petra Tomanová"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We investigate the computational issues related to the memory size in the\nestimation of quadratic covariation, taking into account the specifics of\nfinancial ultra-high-frequency data. In multivariate price processes, we\nconsider both contamination by the market microstructure noise and the\nnon-synchronicity of the observations. We formulate a multi-scale, flat-top\nrealized kernel, non-flat-top realized kernel, pre-averaging and modulated\nrealized covariance estimators in quadratic form and fix their bandwidth\nparameter at a constant value. This allows us to operate with limited memory\nand formulate this estimation as a streaming algorithm. We compare the\nperformance of the estimators with fixed bandwidth parameter in a simulation\nstudy. We find that the estimators ensuring positive semidefiniteness require\nmuch higher bandwidth than the estimators without this constraint.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.13062v3"
    },
    {
        "title": "The illiquidity network of stocks in China's market crash",
        "authors": [
            "Xiaoling Tan",
            "Jichang Zhao"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The Chinese stock market experienced an abrupt crash in 2015, and over\none-third of its market value evaporated. Given its associations with fear and\nthe fine resolution with respect to frequency, the illiquidity of stocks may\noffer a promising perspective for understanding and even signaling a market\ncrash. In this study, by connecting stocks with illiquidity comovements, an\nilliquidity network is established to model the market. Compared to noncrash\ndays, on crash days, the market is more densely connected due to heavier but\nmore homogeneous illiquidity dependencies that facilitate abrupt collapses.\nCritical stocks in the illiquidity network, particularly those in the finance\nsector, are targeted for inspection because of their crucial roles in\naccumulating and passing on illiquidity losses. The cascading failures of\nstocks in market crashes are profiled as disseminating from small degrees to\nhigh degrees that are usually located in the core of the illiquidity network\nand then back to the periphery. By counting the days with random failures in\nthe previous five days, an early signal is implemented to successfully predict\nmore than half of the crash days, especially consecutive days in the early\nphase. Additional evidence from both the Granger causality network and the\nrandom network further testifies to the robustness of the signal. Our results\ncould help market practitioners such as regulators detect and prevent the risk\nof crashes in advance.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01917v3"
    },
    {
        "title": "Exact Simulation of Variance Gamma related OU processes: Application to\n  the Pricing of Energy Derivatives",
        "authors": [
            "Piergiacomo Sabino"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this study we define a three-step procedure to relate the\nself-decomposability of the stationary law of a generalized Ornstein-Uhlenbeck\nprocess to the law of the increments of such processes. Based on this procedure\nand the results of Qu et al. (2019), we derive the exact simulation, without\nnumerical inversion, of the skeleton of a Variance Gamma, and of a symmetric\nVariance Gamma driven Ornstein-Uhlenbeck process. Extensive numerical\nexperiments are reported to demonstrate the accuracy and efficiency of our\nalgorithms. These results are instrumental to simulate the spot price dynamics\nin energy markets and to price Asian options and gas storages by Monte Carlo\nsimulations in a framework similar to the one discussed in Cummins et al.\n(2017, 2018).\n",
        "pdf_link": "http://arxiv.org/pdf/2004.06786v1"
    },
    {
        "title": "A perspective on correlation-based financial networks and entropy\n  measures",
        "authors": [
            "Vishwas Kukreti",
            "Hirdesh K. Pharasi",
            "Priya Gupta",
            "Sunil Kumar"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this brief review, we critically examine the recent work done on\ncorrelation-based networks in financial systems. The structure of empirical\ncorrelation matrices constructed from the financial market data changes as the\nindividual stock prices fluctuate with time, showing interesting evolutionary\npatterns, especially during critical events such as market crashes, bubbles,\netc. We show that the study of correlation-based networks and their evolution\nwith time is useful for extracting important information of the underlying\nmarket dynamics. We, also, present our perspective on the use of recently\ndeveloped entropy measures such as structural entropy and eigen-entropy for\ncontinuous monitoring of correlation-based networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09448v1"
    },
    {
        "title": "Optimal execution with liquidity risk in a diffusive order book market",
        "authors": [
            "Hyoeun Lee",
            "Kiseop Lee"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We study the optimal order placement strategy with the presence of a\nliquidity cost. In this problem, a stock trader wishes to clear her large\ninventory by a predetermined time horizon $T$. A trader uses both limit and\nmarket orders, and a large market order faces an adverse price movement caused\nby the liquidity risk. First, we study a single period model where the trader\nplaces a limit order and/or a market order at the beginning. We show the\nbehavior of optimal amount of market order, $m^*$, and optimal placement of\nlimit order, $y^*$, under different market conditions. Next, we extend it to a\nmulti-period model, where the trader makes sequential decisions of limit and\nmarket orders at multiple time points.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.10951v1"
    },
    {
        "title": "Volatility model calibration with neural networks a comparison between\n  direct and indirect methods",
        "authors": [
            "Dirk Roeder",
            "Georgi Dimitroff"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In a recent paper \"Deep Learning Volatility\" a fast 2-step deep calibration\nalgorithm for rough volatility models was proposed: in the first step the time\nconsuming mapping from the model parameter to the implied volatilities is\nlearned by a neural network and in the second step standard solver techniques\nare used to find the best model parameter.\n  In our paper we compare these results with an alternative direct approach\nwhere the the mapping from market implied volatilities to model parameters is\napproximated by the neural network, without the need for an extra solver step.\nUsing a whitening procedure and a projection of the target parameter to [0,1],\nin order to be able to use a sigmoid type output function we found that the\ndirect approach outperforms the two-step one for the data sets and methods\npublished in \"Deep Learning Volatility\".\n  For our implementation we use the open source tensorflow 2 library. The paper\nshould be understood as a technical comparison of neural network techniques and\nnot as an methodically new Ansatz.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.03494v1"
    },
    {
        "title": "KrigHedge: Gaussian Process Surrogates for Delta Hedging",
        "authors": [
            "Mike Ludkovski",
            "Yuri Saporito"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We investigate a machine learning approach to option Greeks approximation\nbased on Gaussian process (GP) surrogates. The method takes in noisily observed\noption prices, fits a nonparametric input-output map and then analytically\ndifferentiates the latter to obtain the various price sensitivities. Our\nmotivation is to compute Greeks in cases where direct computation is expensive,\nsuch as in local volatility models, or can only ever be done approximately. We\nprovide a detailed analysis of numerous aspects of GP surrogates, including\nchoice of kernel family, simulation design, choice of trend function and impact\nof noise.\n  We further discuss the application to Delta hedging, including a new Lemma\nthat relates quality of the Delta approximation to discrete-time hedging loss.\nResults are illustrated with two extensive case studies that consider\nestimation of Delta, Theta and Gamma and benchmark approximation quality and\nuncertainty quantification using a variety of statistical metrics. Among our\nkey take-aways are the recommendation to use Matern kernels, the benefit of\nincluding virtual training points to capture boundary conditions, and the\nsignificant loss of fidelity when training on stock-path-based datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08407v4"
    },
    {
        "title": "Multilevel Monte-Carlo for computing the SCR with the standard formula\n  and other stress tests",
        "authors": [
            "Aurélien Alfonsi",
            "Adel Cherchali",
            "Jose Arturo Infante Acevedo"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper studies the multilevel Monte-Carlo estimator for the expectation\nof a maximum of conditional expectations. This problem arises naturally when\nconsidering many stress tests and appears in the calculation of the interest\nrate module of the standard formula for the SCR. We obtain theoretical\nconvergence results that complements the recent work of Giles and Goda and\ngives some additional tractability through a parameter that somehow describes\nregularity properties around the maximum. We then apply the MLMC estimator to\nthe calculation of the SCR at future dates with the standard formula for an ALM\nsavings business on life insurance. We compare it with estimators obtained with\nLeast Square Monte-Carlo or Neural Networks. We find that the MLMC estimator is\ncomputationally more efficient and has the main advantage to avoid regression\nissues, which is particularly significant in the context of projection of a\nbalance sheet by an insurer due to the path dependency. Last, we discuss the\npotentiality of this numerical method and analyze in particular the effect of\nthe portfolio allocation on the SCR at future~dates.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.12651v2"
    },
    {
        "title": "Stock Price Prediction Using CNN and LSTM-Based Deep Learning Models",
        "authors": [
            "Sidra Mehtab",
            "Jaydip Sen"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Designing robust and accurate predictive models for stock price prediction\nhas been an active area of research for a long time. While on one side, the\nsupporters of the efficient market hypothesis claim that it is impossible to\nforecast stock prices accurately, many researchers believe otherwise. There\nexist propositions in the literature that have demonstrated that if properly\ndesigned and optimized, predictive models can very accurately and reliably\npredict future values of stock prices. This paper presents a suite of deep\nlearning based models for stock price prediction. We use the historical records\nof the NIFTY 50 index listed in the National Stock Exchange of India, during\nthe period from December 29, 2008 to July 31, 2020, for training and testing\nthe models. Our proposition includes two regression models built on\nconvolutional neural networks and three long and short term memory network\nbased predictive models. To forecast the open values of the NIFTY 50 index\nrecords, we adopted a multi step prediction technique with walk forward\nvalidation. In this approach, the open values of the NIFTY 50 index are\npredicted on a time horizon of one week, and once a week is over, the actual\nindex values are included in the training set before the model is trained\nagain, and the forecasts for the next week are made. We present detailed\nresults on the forecasting accuracies for all our proposed models. The results\nshow that while all the models are very accurate in forecasting the NIFTY 50\nopen values, the univariate encoder decoder convolutional LSTM with the\nprevious two weeks data as the input is the most accurate model. On the other\nhand, a univariate CNN model with previous one week data as the input is found\nto be the fastest model in terms of its execution speed.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.13891v1"
    },
    {
        "title": "SuperDeConFuse: A Supervised Deep Convolutional Transform based Fusion\n  Framework for Financial Trading Systems",
        "authors": [
            "Pooja Gupta",
            "Angshul Majumdar",
            "Emilie Chouzenoux",
            "Giovanni Chierchia"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This work proposes a supervised multi-channel time-series learning framework\nfor financial stock trading. Although many deep learning models have recently\nbeen proposed in this domain, most of them treat the stock trading time-series\ndata as 2-D image data, whereas its true nature is 1-D time-series data. Since\nthe stock trading systems are multi-channel data, many existing techniques\ntreating them as 1-D time-series data are not suggestive of any technique to\neffectively fusion the information carried by the multiple channels. To\ncontribute towards both of these shortcomings, we propose an end-to-end\nsupervised learning framework inspired by the previously established\n(unsupervised) convolution transform learning framework. Our approach consists\nof processing the data channels through separate 1-D convolution layers, then\nfusing the outputs with a series of fully-connected layers, and finally\napplying a softmax classification layer. The peculiarity of our framework -\nSuperDeConFuse (SDCF), is that we remove the nonlinear activation located\nbetween the multi-channel convolution layers and the fully-connected layers, as\nwell as the one located between the latter and the output layer. We compensate\nfor this removal by introducing a suitable regularization on the aforementioned\nlayer outputs and filters during the training phase. Specifically, we apply a\nlogarithm determinant regularization on the layer filters to break symmetry and\nforce diversity in the learnt transforms, whereas we enforce the non-negativity\nconstraint on the layer outputs to mitigate the issue of dead neurons. This\nresults in the effective learning of a richer set of features and filters with\nrespect to a standard convolutional neural network. Numerical experiments\nconfirm that the proposed model yields considerably better results than\nstate-of-the-art deep learning techniques for real-world problem of stock\ntrading.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.04364v1"
    },
    {
        "title": "Prospects and challenges of quantum finance",
        "authors": [
            "Adam Bouland",
            "Wim van Dam",
            "Hamed Joorati",
            "Iordanis Kerenidis",
            "Anupam Prakash"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Quantum computers are expected to have substantial impact on the finance\nindustry, as they will be able to solve certain problems considerably faster\nthan the best known classical algorithms. In this article we describe such\npotential applications of quantum computing to finance, starting with the\nstate-of-the-art and focusing in particular on recent works by the QC Ware\nteam. We consider quantum speedups for Monte Carlo methods, portfolio\noptimization, and machine learning. For each application we describe the extent\nof quantum speedup possible and estimate the quantum resources required to\nachieve a practical speedup. The near-term relevance of these quantum finance\nalgorithms varies widely across applications - some of them are heuristic\nalgorithms designed to be amenable to near-term prototype quantum computers,\nwhile others are proven speedups which require larger-scale quantum computers\nto implement. We also describe powerful ways to bring these speedups closer to\nexperimental feasibility - in particular describing lower depth algorithms for\nMonte Carlo methods and quantum machine learning, as well as quantum annealing\nheuristics for portfolio optimization. This article is targeted at financial\nprofessionals and no particular background in quantum computation is assumed.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.06492v1"
    },
    {
        "title": "Sample path generation of the stochastic volatility CGMY process and its\n  application to path-dependent option pricing",
        "authors": [
            "Young Shin Kim"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  This paper proposes the sample path generation method for the stochastic\nvolatility version of CGMY process. We present the Monte-Carlo method for\nEuropean and American option pricing with the sample path generation and\ncalibrate model parameters to the American style S\\&P 100 index options market,\nusing the least square regression method. Moreover, we discuss path-dependent\noptions such as Asian and Barrier options.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.11001v1"
    },
    {
        "title": "Calibrating an adaptive Farmer-Joshi agent-based model for financial\n  markets",
        "authors": [
            "Ivan Jericevich",
            "Murray McKechnie",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We replicate the contested calibration of the Farmer and Joshi agent based\nmodel of financial markets using a genetic algorithm and a Nelder-Mead with\nthreshold accepting algorithm following Fabretti. The novelty of the\nFarmer-Joshi model is that the dynamics are driven by trade entry and exit\nthresholds alone. We recover the known claim that some important stylized facts\nobserved in financial markets cannot be easily found under calibration -- in\nparticular those relating to the auto-correlations in the absolute values of\nthe price fluctuations, and sufficient kurtosis. However, rather than concerns\nrelating to the calibration method, what is novel here is that we extended the\nFarmer-Joshi model to include agent adaptation using an Brock and Hommes\napproach to strategy fitness based on trading strategy profitability. We call\nthis an adaptive Farmer-Joshi model: the model allows trading agents to switch\nbetween strategies by favouring strategies that have been more profitable over\nsome period of time determined by a free-parameter fixing the profit monitoring\ntime-horizon. In the adaptive model we are able to calibrate and recover\nadditional stylized facts, despite apparent degeneracy's. This is achieved by\ncombining the interactions of trade entry levels with trade strategy switching.\nWe use this to argue that for low-frequency trading across days, as calibrated\nto daily sampled data, feed-backs can be accounted for by strategy die-out\nbased on intermediate term profitability; we find that the average trade\nmonitoring horizon is approximately two to three months (or 40 to 60 days) of\ntrading.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.09863v1"
    },
    {
        "title": "Sparse Grid Method for Highly Efficient Computation of Exposures for xVA",
        "authors": [
            "Lech A. Grzelak"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Every \"x\"-adjustment in the so-called xVA financial risk management framework\nrelies on the computation of exposures. Considering thousands of Monte Carlo\npaths and tens of simulation steps, a financial portfolio needs to be evaluated\nnumerous times during the lifetime of the underlying assets. This is the\nbottleneck of every simulation of xVA. In this article, we explore numerical\ntechniques for improving the simulation of exposures. We aim to decimate the\nnumber of portfolio evaluations, particularly for large portfolios involving\nmultiple, correlated risk factors. The usage of the Stochastic Collocation (SC)\nmethod, together with Smolyak's sparse grid extension, allows for a significant\nreduction in the number of portfolio evaluations, even when dealing with many\nrisk factors. The proposed model can be easily applied to any portfolio and\nsize. We report that for a realistic portfolio comprising linear and non-linear\nderivatives, the expected reduction in the portfolio evaluations may exceed\n6000 times, depending on the dimensionality and the required accuracy. We give\nillustrative examples and examine the method with realistic multi-currency\nportfolios consisting of interest rate swaps and swaptions.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.14319v2"
    },
    {
        "title": "Normal Tempered Stable Processes and the Pricing of Energy Derivatives",
        "authors": [
            "Piergiacomo Sabino"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this study we consider the pricing of energy derivatives when the\nevolution of spot prices is modeled with a normal tempered stable driven\nOrnstein-Uhlenbeck process. Such processes are the generalization of normal\ninverse Gaussian processes that are widely used in energy finance applications.\nWe first specify their statistical properties calculating their characteristic\nfunction in closed form. This result is instrumental for the derivation of\nnon-arbitrage conditions such that the spot dynamics is consistent with the\nforward curve without relying on numerical approximations or on numerical\nintegration. Moreover, we conceive an efficient algorithm for the exact\ngeneration of the trajectories which gives the possibility to implement Monte\nCarlo simulations without approximations or bias. We illustrate the\napplicability of the theoretical findings and the simulation algorithms in the\ncontext of the pricing of different contracts, namely, strips of daily call\noptions, Asian options with European style and swing options. Finally, we\npresent an extension to future markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03071v1"
    },
    {
        "title": "Multilevel Monte Carlo simulation for VIX options in the rough Bergomi\n  model",
        "authors": [
            "Florian Bourgey",
            "Stefano De Marco"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We consider the pricing of VIX options in the rough Bergomi model. In this\nsetting, the VIX random variable is defined by the one-dimensional integral of\nthe exponential of a Gaussian process with correlated increments, hence\napproximate samples of the VIX can be constructed via discretization of the\nintegral and simulation of a correlated Gaussian vector. A Monte-Carlo\nestimator of VIX options based on a rectangle discretization scheme and exact\nGaussian sampling via the Cholesky method has a computational complexity of\norder $\\mathcal{O}(\\varepsilon^{-4})$ when the mean-squared error is set to\n$\\varepsilon^2$. We demonstrate that this cost can be reduced to\n$\\mathcal{O}(\\varepsilon^{-2} \\log^2(\\varepsilon))$ combining the scheme above\nwith the multilevel method, and further reduced to the asymptotically optimal\ncost $\\mathcal{O}(\\varepsilon^{-2})$ when using a trapezoidal discretization.\nWe provide numerical experiments highlighting the efficiency of the multilevel\napproach in the pricing of VIX options in such a rough forward variance\nsetting.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.05356v2"
    },
    {
        "title": "Efficient approximations for utility-based pricing",
        "authors": [
            "Laurence Carassus",
            "Massinissa Ferhoune"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In a context of illiquidity, the reservation price is a well-accepted\nalternative to the usual martingale approach which does not apply. However,\nthis price is not available in closed form and requires numerical methods such\nas Monte Carlo or polynomial approximations to evaluate it. We show that these\nmethods can be inaccurate and propose a deterministic decomposition of the\nreservation price using the Lambert function. This decomposition allows us to\nperform an improved Monte Carlo method, which we name Lambert Monte Carlo (LMC)\nand to give deterministic approximations of the reservation price and of the\noptimal strategies based on the Lambert function. We also give an answer to the\nproblem of selecting a hedging asset that minimizes the reservation price and\nalso the cash invested. Our theoretical results are illustrated by numerical\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08804v3"
    },
    {
        "title": "Financial Time Series Analysis and Forecasting with HHT Feature\n  Generation and Machine Learning",
        "authors": [
            "Tim Leung",
            "Theodore Zhao"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We present the method of complementary ensemble empirical mode decomposition\n(CEEMD) and Hilbert-Huang transform (HHT) for analyzing nonstationary financial\ntime series. This noise-assisted approach decomposes any time series into a\nnumber of intrinsic mode functions, along with the corresponding instantaneous\namplitudes and instantaneous frequencies. Different combinations of modes allow\nus to reconstruct the time series using components of different timescales. We\nthen apply Hilbert spectral analysis to define and compute the associated\ninstantaneous energy-frequency spectrum to illustrate the properties of various\ntimescales embedded in the original time series. Using HHT, we generate a\ncollection of new features and integrate them into machine learning models,\nsuch as regression tree ensemble, support vector machine (SVM), and long\nshort-term memory (LSTM) neural network. Using empirical financial data, we\ncompare several HHT-enhanced machine learning models in terms of forecasting\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10871v1"
    },
    {
        "title": "Sample Recycling Method -- A New Approach to Efficient Nested Monte\n  Carlo Simulations",
        "authors": [
            "Runhuan Feng",
            "Peng Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Nested stochastic modeling has been on the rise in many fields of the\nfinancial industry. Such modeling arises whenever certain components of a\nstochastic model are stochastically determined by other models. There are at\nleast two main areas of applications, including (1) portfolio risk management\nin the banking sector and (2) principle-based reserving and capital\nrequirements in the insurance sector. As financial instrument values often\nchange with economic fundamentals, the risk management of a portfolio (outer\nloop) often requires the assessment of financial positions subject to changes\nin risk factors in the immediate future. The valuation of financial position\n(inner loop) is based on projections of cashflows and risk factors into the\ndistant future. The nesting of such stochastic modeling can be computationally\nchallenging.\n  Most of existing techniques to speed up nested simulations are based on curve\nfitting. The main idea is to establish a functional relationship between inner\nloop estimator and risk factors by running a limited set of economic scenarios,\nand, instead of running inner loop simulations, inner loop estimations are made\nby feeding other scenarios into the fitted curve. This paper presents a\nnon-conventional approach based on the concept of sample recycling. Its essence\nis to run inner loop estimation for a small set of outer loop scenarios and to\nfind inner loop estimates under other outer loop scenarios by recycling those\nknown inner loop paths. This new approach can be much more efficient when\ntraditional techniques are difficult to implement in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06028v1"
    },
    {
        "title": "Pricing methods for $α$-quantile and perpetual early exercise\n  options based on Spitzer identities",
        "authors": [
            "Carolyn E. Phelan",
            "Daniele Marazzina",
            "Guido Germano"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We present new numerical schemes for pricing perpetual Bermudan and American\noptions as well as $\\alpha$-quantile options. This includes a new direct\ncalculation of the optimal exercise barrier for early-exercise options. Our\napproach is based on the Spitzer identities for general L\\'evy processes and on\nthe Wiener-Hopf method. Our direct calculation of the price of\n$\\alpha$-quantile options combines for the first time the Dassios-Port-Wendel\nidentity and the Spitzer identities for the extrema of processes. Our results\nshow that the new pricing methods provide excellent error convergence with\nrespect to computational time when implemented with a range of L\\'evy\nprocesses.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06030v1"
    },
    {
        "title": "Generative Adversarial Networks in finance: an overview",
        "authors": [
            "Florian Eckerli",
            "Joerg Osterrieder"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Modelling in finance is a challenging task: the data often has complex\nstatistical properties and its inner workings are largely unknown. Deep\nlearning algorithms are making progress in the field of data-driven modelling,\nbut the lack of sufficient data to train these models is currently holding back\nseveral new applications. Generative Adversarial Networks (GANs) are a neural\nnetwork architecture family that has achieved good results in image generation\nand is being successfully applied to generate time series and other types of\nfinancial data. The purpose of this study is to present an overview of how\nthese GANs work, their capabilities and limitations in the current state of\nresearch with financial data, and present some practical applications in the\nindustry. As a proof of concept, three known GAN architectures were tested on\nfinancial time series, and the generated data was evaluated on its statistical\nproperties, yielding solid results. Finally, it was shown that GANs have made\nconsiderable progress in their finance applications and can be a solid\nadditional tool for data scientists in this field.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06364v2"
    },
    {
        "title": "A Numerical Approach to Pricing Exchange Options under Stochastic\n  Volatility and Jump-Diffusion Dynamics",
        "authors": [
            "Len Patrick Dominic M. Garces",
            "Gerald H. L. Cheang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We consider a method of lines (MOL) approach to determine prices of European\nand American exchange options when underlying asset prices are modelled with\nstochastic volatility and jump-diffusion dynamics. As the MOL, as with any\nother numerical scheme for PDEs, becomes increasingly complex when higher\ndimensions are involved, we first simplify the problem by transforming the\nexchange option into a call option written on the ratio of the yield processes\nof the two assets. This is achieved by taking the second asset yield process as\nthe numeraire. We also characterize the near-maturity behavior of the early\nexercise boundary of the American exchange option and analyze how model\nparameters affect this behavior. Using the MOL scheme, we conduct a numerical\ncomparative static analysis of exchange option prices with respect to the model\nparameters and investigate the impact of stochastic volatility and jumps to\noption prices. We also consider the effect of boundary conditions at\nfar-but-finite limits of the computational domain on the overall efficiency of\nthe MOL scheme. Toward these objectives, a brief exposition of the MOL and how\nit can be implemented on computing software are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.07362v1"
    },
    {
        "title": "Pricing American options with the Runge-Kutta-Legendre finite difference\n  scheme",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  This paper presents the Runge-Kutta-Legendre finite difference scheme,\nallowing for an additional shift in its polynomial representation. A short\npresentation of the stability region, comparatively to the\nRunge-Kutta-Chebyshev scheme follows. We then explore the problem of pricing\nAmerican options with the Runge-Kutta-Legendre scheme under the one factor\nBlack-Scholes and the two factor Heston stochastic volatility models, as well\nas the pricing of butterfly spread and digital options under the uncertain\nvolatility model, where a Hamilton-Jacobi-Bellman partial differential equation\nneeds to be solved. We explore the order of convergence in these problems, as\nwell as the option greeks stability, compared to the literature and popular\nschemes such as Crank-Nicolson, with Rannacher time-stepping.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.12049v1"
    },
    {
        "title": "A General Approach for Parisian Stopping Times under Markov Processes",
        "authors": [
            "Gongqiu Zhang",
            "Lingfei Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We propose a method based on continuous time Markov chain approximation to\ncompute the distribution of Parisian stopping times and price Parisian options\nunder general one-dimensional Markov processes. We prove the convergence of the\nmethod under a general setting and obtain sharp estimate of the convergence\nrate for diffusion models. Our theoretical analysis reveals how to design the\ngrid of the CTMC to achieve faster convergence. Numerical experiments are\nconducted to demonstrate the accuracy and efficiency of our method for both\ndiffusion and jump models. To show the versality of our approach, we develop\nextensions for multi-sided Parisian stopping times, the joint distribution of\nParisian stopping times and first passage times, Parisian bonds and for more\nsophisticated models like regime-switching and stochastic volatility models.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.06605v1"
    },
    {
        "title": "On simulation of rough Volterra stochastic volatility models",
        "authors": [
            "Jan Matas",
            "Jan Pospíšil"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Rough Volterra volatility models are a progressive and promising field of\nresearch in derivative pricing. Although rough fractional stochastic volatility\nmodels already proved to be superior in real market data fitting, techniques\nused in simulation of these models are still inefficient in terms of speed and\naccuracy. This paper aims to present accurate and efficient tools and\ntechniques for Monte-Carlo simulations for a wide range of rough volatility\nmodels. In particular, we compare three commonly used simulation methods: the\nCholesky method, the Hybrid scheme, and the rDonsker scheme. We also comment on\nthe implementation of variance reduction techniques. In particular, we show the\nobstacles of the so-called turbocharging technique whose performance is\nsometimes counter-productive. To overcome these obstacles, we suggest several\nmodifications.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.01999v2"
    },
    {
        "title": "Markovian approximations of stochastic Volterra equations with the\n  fractional kernel",
        "authors": [
            "Christian Bayer",
            "Simon Breneis"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We consider rough stochastic volatility models where the variance process\nsatisfies a stochastic Volterra equation with the fractional kernel, as in the\nrough Bergomi and the rough Heston model. In particular, the variance process\nis therefore not a Markov process or semimartingale, and has quite low\nH\\\"older-regularity. In practice, simulating such rough processes thus often\nresults in high computational cost. To remedy this, we study approximations of\nstochastic Volterra equations using an $N$-dimensional diffusion process\ndefined as solution to a system of ordinary stochastic differential equation.\nIf the coefficients of the stochastic Volterra equation are Lipschitz\ncontinuous, we show that these approximations converge strongly with\nsuperpolynomial rate in $N$. Finally, we apply this approximation to compute\nthe implied volatility smile of a European call option under the rough Bergomi\nand the rough Heston model.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.05048v2"
    },
    {
        "title": "Learning to Classify and Imitate Trading Agents in Continuous Double\n  Auction Markets",
        "authors": [
            "Mahmoud Mahfouz",
            "Tucker Balch",
            "Manuela Veloso",
            "Danilo Mandic"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Continuous double auctions such as the limit order book employed by exchanges\nare widely used in practice to match buyers and sellers of a variety of\nfinancial instruments. In this work, we develop an agent-based model for\ntrading in a limit order book and show (1) how opponent modelling techniques\ncan be applied to classify trading agent archetypes and (2) how behavioural\ncloning can be used to imitate these agents in a simulated setting. We\nexperimentally compare a number of techniques for both tasks and evaluate their\napplicability and use in real-world scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.01325v2"
    },
    {
        "title": "Sector Volatility Prediction Performance Using GARCH Models and\n  Artificial Neural Networks",
        "authors": [
            "Curtis Nybo"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Recently artificial neural networks (ANNs) have seen success in volatility\nprediction, but the literature is divided on where an ANN should be used rather\nthan the common GARCH model. The purpose of this study is to compare the\nvolatility prediction performance of ANN and GARCH models when applied to\nstocks with low, medium, and high volatility profiles. This approach intends to\nidentify which model should be used for each case. The volatility profiles\ncomprise of five sectors that cover all stocks in the U.S stock market from\n2005 to 2020. Three GARCH specifications and three ANN architectures are\nexamined for each sector, where the most adequate model is chosen to move on to\nforecasting. The results indicate that the ANN model should be used for\npredicting volatility of assets with low volatility profiles, and GARCH models\nshould be used when predicting volatility of medium and high volatility assets.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.09489v1"
    },
    {
        "title": "FinRL-Podracer: High Performance and Scalable Deep Reinforcement\n  Learning for Quantitative Finance",
        "authors": [
            "Zechu Li",
            "Xiao-Yang Liu",
            "Jiahao Zheng",
            "Zhaoran Wang",
            "Anwar Walid",
            "Jian Guo"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Machine learning techniques are playing more and more important roles in\nfinance market investment. However, finance quantitative modeling with\nconventional supervised learning approaches has a number of limitations. The\ndevelopment of deep reinforcement learning techniques is partially addressing\nthese issues. Unfortunately, the steep learning curve and the difficulty in\nquick modeling and agile development are impeding finance researchers from\nusing deep reinforcement learning in quantitative trading. In this paper, we\npropose an RLOps in finance paradigm and present a FinRL-Podracer framework to\naccelerate the development pipeline of deep reinforcement learning (DRL)-driven\ntrading strategy and to improve both trading performance and training\nefficiency. FinRL-Podracer is a cloud solution that features high performance\nand high scalability and promises continuous training, continuous integration,\nand continuous delivery of DRL-driven trading strategies, facilitating a rapid\ntransformation from algorithmic innovations into a profitable trading strategy.\nFirst, we propose a generational evolution mechanism with an ensemble strategy\nto improve the trading performance of a DRL agent, and schedule the training of\na DRL algorithm onto a GPU cloud via multi-level mapping. Then, we carry out\nthe training of DRL components with high-performance optimizations on GPUs.\nFinally, we evaluate the FinRL-Podracer framework for a stock trend prediction\ntask on an NVIDIA DGX SuperPOD cloud. FinRL-Podracer outperforms three popular\nDRL libraries Ray RLlib, Stable Baseline 3 and FinRL, i.e., 12% \\sim 35%\nimprovements in annual return, 0.1 \\sim 0.6 improvements in Sharpe ratio and 3\ntimes \\sim 7 times speed-up in training time. We show the high scalability by\ntraining a trading agent in 10 minutes with $80$ A100 GPUs, on NASDAQ-100\nconstituent stocks with minute-level data over 10 years.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.05188v1"
    },
    {
        "title": "Correlation Estimation in Hybrid Systems",
        "authors": [
            "Baron Law"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  A simple method is proposed to estimate the instantaneous correlations\nbetween state variables in a hybrid system from the empirical correlations\nbetween observable market quantities such as spot rate, stock price and implied\nvolatility. The new algorithm is extremely fast since only low-dimension linear\nsystems are involved. If the resulting matrix from the linear systems is not\npositive semidefinite, the shrinking method, which requires only\nbisection-style iterations, is recommended to convert the matrix to positive\nsemidefinite. The square of short-term at-the-money implied volatility is\nsuggested as the proxy for the unobservable stochastic variance. When the\nimplied volatility is not available, a simple trick is provided to fill in the\nmissing correlations. Numerical study shows that the estimates are reasonably\naccurate, when using more than 1,000 data points. In addition, the algorithm is\nrobust to misspecified interest rate model parameters and the\nshort-sampling-period assumption. G2++ and Heston are used for illustration but\nthe method can be extended to other affine term structure, local volatility and\njump diffusion models, with or without stochastic interest rate.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.06042v6"
    },
    {
        "title": "Deep Hedging: Learning to Remove the Drift under Trading Frictions with\n  Minimal Equivalent Near-Martingale Measures",
        "authors": [
            "Hans Buehler",
            "Phillip Murray",
            "Mikko S. Pakkanen",
            "Ben Wood"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We present a machine learning approach for finding minimal equivalent\nmartingale measures for markets simulators of tradable instruments, e.g. for a\nspot price and options written on the same underlying. We extend our results to\nmarkets with frictions, in which case we find \"near-martingale measures\" under\nwhich the prices of hedging instruments are martingales within their bid/ask\nspread.\n  By removing the drift, we are then able to learn using Deep Hedging a \"clean\"\nhedge for an exotic payoff which is not polluted by the trading strategy trying\nto make money from statistical arbitrage opportunities. We correspondingly\nhighlight the robustness of this hedge vs estimation error of the original\nmarket simulator. We discuss applications to two market simulators.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.07844v3"
    },
    {
        "title": "Pricing Bermudan options using regression trees/random forests",
        "authors": [
            "Zineb El Filali Ech-Chafiq",
            "Pierre Henry-Labordere",
            "Jérôme Lelong"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The value of an American option is the maximized value of the discounted cash\nflows from the option. At each time step, one needs to compare the immediate\nexercise value with the continuation value and decide to exercise as soon as\nthe exercise value is strictly greater than the continuation value. We can\nformulate this problem as a dynamic programming equation, where the main\ndifficulty comes from the computation of the conditional expectations\nrepresenting the continuation values at each time step. In (Longstaff and\nSchwartz, 2001), these conditional expectations were estimated using\nregressions on a finite-dimensional vector space (typically a polynomial\nbasis). In this paper, we follow the same algorithm; only the conditional\nexpectations are estimated using Regression trees or Random forests. We discuss\nthe convergence of the LS algorithm when the standard least squares regression\nis replaced with regression trees. Finally, we expose some numerical results\nwith regression trees and random forests. The random forest algorithm gives\nexcellent results in high dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02587v2"
    },
    {
        "title": "Deep self-consistent learning of local volatility",
        "authors": [
            "Zhe Wang",
            "Nicolas Privault",
            "Claude Guet"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We present an algorithm for the calibration of local volatility from market\noption prices through deep self-consistent learning, by approximating both\nmarket option prices and local volatility using deep neural networks,\nrespectively. Our method uses the initial-boundary value problem of the\nunderlying Dupire's partial differential equation solved by the parameterized\noption prices to bring corrections to the parameterization in a self-consistent\nway. By exploiting the differentiability of the neural networks, we can\nevaluate Dupire's equation locally at each strike-maturity pair; while by\nexploiting their continuity, we sample strike-maturity pairs uniformly from a\ngiven domain, going beyond the discrete points where the options are quoted.\nMoreover, the absence of arbitrage opportunities are imposed by penalizing an\nassociated loss function as a soft constraint. For comparison with existing\napproaches, the proposed method is tested on both synthetic and market option\nprices, which shows an improved performance in terms of reduced interpolation\nand reprice errors, as well as the smoothness of the calibrated local\nvolatility. An ablation study has been performed, asserting the robustness and\nsignificance of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.07880v2"
    },
    {
        "title": "Regime recovery using implied volatility in Markov modulated market\n  model",
        "authors": [
            "Anindya Goswami",
            "Kedar Nath Mukherjee",
            "Irvine Homi Patalwala",
            "Sanjay N. S"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In the regime switching extension of Black-Scholes-Merton model of asset\nprice dynamics, one assumes that the volatility coefficient evolves as a hidden\npure jump process. Under the assumption of Markov regime switching, we have\nconsidered the locally risk minimizing price of European vanilla options. By\npretending these prices or their noisy versions as traded prices, we have first\ncomputed the implied volatility (IV) of the underlying asset. Then by\nperforming several numerical experiments we have investigated the dependence of\nIV on the time to maturity (TTM) and strike price of the vanilla options. We\nhave observed a clear dependence that is at par with the empirically observed\nstylized facts. Furthermore, we have experimentally validated that IV time\nseries, obtained from contracts with moneyness and TTM varying in particular\nnarrow ranges, can recover the transition instances of the hidden Markov chain.\nSuch regime recovery has also been proved in a theoretical setting. Moreover,\nthe novel scheme for computing option price is shown to be stable.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.10304v2"
    },
    {
        "title": "Option Pricing and CVA Calculations using the Monte Carlo-Tree (MC-Tree)\n  Method",
        "authors": [
            "Yen Thuan Trinh",
            "Bernard Hanzon"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The binomial tree method and the Monte Carlo (MC) method are popular methods\nfor solving option pricing problems. However in both methods there is a\ntrade-off between accuracy and speed of computation, both of which are\nimportant in applications. We introduce a new method, the MC-Tree method, that\ncombines the MC method with the binomial tree method. It employs a mixing\ndistribution on the tree parameters, which are restricted to give prescribed\nmean and variance. For the family of mixing densities proposed here, the\ncorresponding compound densities of the tree outcomes at final time are\nobtained. Ideally the compound density would be (after a logarithmic\ntransformation of the asset prices) Gaussian. Using the fact that in general,\nwhen mean and variance are prescribed, the maximum entropy distribution is\nGaussian, we look for mixing densities for which the corresponding compound\ndensity has high entropy level. The compound densities that we obtain are not\nexactly Gaussian, but have entropy values close to the maximum possible\nGaussian entropy. Furthermore we introduce techniques to correct for the\ndeviation from the ideal Gaussian pricing measure. One of these (distribution\ncorrection technique) ensures that expectations calculated with the method are\ntaken with respect to the desired Gaussian measure. The other one\n(bias-correction technique) ensures that the probability distributions used are\nrisk-neutral in each of the trees. Apart from option pricing, we apply our\ntechniques to develop an algorithm for calculation of the Credit Valuation\nAdjustment (CVA) to the price of an American option. Numerical examples of the\nworkings of the MC-Tree approach are provided, which show good performance in\nterms of accuracy and computational speed.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.00785v1"
    },
    {
        "title": "Universal approximation of credit portfolio losses using Restricted\n  Boltzmann Machines",
        "authors": [
            "Giuseppe Genovese",
            "Ashkan Nikeghbali",
            "Nicola Serra",
            "Gabriele Visentin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We introduce a new portfolio credit risk model based on Restricted Boltzmann\nMachines (RBMs), which are stochastic neural networks capable of universal\napproximation of loss distributions. We test the model on an empirical dataset\nof default probabilities of 1'012 US companies and we show that it outperforms\ncommonly used parametric factor copula models -- such as the Gaussian or the t\nfactor copula models -- across several credit risk management tasks. In\nparticular, the model leads to better fits for the empirical loss distribution\nand more accurate risk measure estimations. We introduce an importance sampling\nprocedure which allows risk measures to be estimated at high confidence levels\nin a computationally efficient way and which is a substantial improvement over\nthe Monte Carlo techniques currently available for copula models. Furthermore,\nthe statistical factors extracted by the model admit an interpretation in terms\nof the underlying portfolio sector structure and provide practitioners with\nquantitative tools for the management of concentration risk. Finally, we show\nhow to use the model for stress testing by estimating stressed risk measures\n(e.g. stressed VaR) under various macroeconomic stress test scenarios, such as\nthose specified by the FRB's Dodd-Frank Act stress test.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.11060v3"
    },
    {
        "title": "A Reproducing Kernel Hilbert Space approach to singular local stochastic\n  volatility McKean-Vlasov models",
        "authors": [
            "Christian Bayer",
            "Denis Belomestny",
            "Oleg Butkovsky",
            "John Schoenmakers"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Motivated by the challenges related to the calibration of financial models,\nwe consider the problem of numerically solving a singular McKean-Vlasov\nequation $$ d X_t= \\sigma(t,X_t) X_t \\frac{\\sqrt v_t}{\\sqrt {E[v_t|X_t]}}dW_t,\n$$ where $W$ is a Brownian motion and $v$ is an adapted diffusion process. This\nequation can be considered as a singular local stochastic volatility model.\nWhilst such models are quite popular among practitioners, unfortunately, its\nwell-posedness has not been fully understood yet and, in general, is possibly\nnot guaranteed at all. We develop a novel regularization approach based on the\nreproducing kernel Hilbert space (RKHS) technique and show that the regularized\nmodel is well-posed. Furthermore, we prove propagation of chaos. We demonstrate\nnumerically that a thus regularized model is able to perfectly replicate option\nprices due to typical local volatility models. Our results are also applicable\nto more general McKean--Vlasov equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.01160v2"
    },
    {
        "title": "Double sweep LU decomposition for American options under negative rates",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The classic Brennan-Schwartz algorithm to solve the linear complementary\nproblem, which arises from the finite difference discretization of the partial\ndifferential equation related to American option pricing does not lead to the\nexact solution under negative interest rates. This is due to the two exercise\nboundaries which may appear under negative interest rate, while the algorithm\nwas proven to lead to the exact solution in the case of a single exercise\nboundary only. This paper explains that two sweeps of the Brennan-Schwartz\nalgorithm in two directions is enough to recover the exact solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.08794v1"
    },
    {
        "title": "Weak error rates of numerical schemes for rough volatility",
        "authors": [
            "Paul Gassiat"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Simulation of rough volatility models involves discretization of stochastic\nintegrals where the integrand is a function of a (correlated) fractional\nBrownian motion of Hurst index $H \\in (0,1/2)$. We obtain results on the rate\nof convergence for the weak error of such approximations, in the special cases\nwhen either the integrand is the fBm itself, or the test function is cubic. Our\nresult states that the convergence is of order $(3H+ \\frac{1}{2}) \\wedge 1$ for\nexact left-point discretization, and of order $H+\\frac{1}{2}$ for the hybrid\nscheme with well-chosen weights.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.09298v2"
    },
    {
        "title": "Relevance of Wrong-Way Risk in Funding Valuation Adjustments",
        "authors": [
            "T. van der Zwaard",
            "L. A. Grzelak",
            "C. W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In March 2020, the world was thrown into financial distress. This manifested\nitself in increased uncertainty in the financial markets. Many interest rates\ncollapsed, and funding spreads surged significantly, which increased due to the\nmarket turmoil. In light of these events, it is essential to understand and\nmodel Wrong-Way Risk (WWR) in a Funding Valuation Adjustment (FVA) context. WWR\nmay currently be absent from FVA calculations in banks' Valuation Adjustment\n(xVA) engines. However, in this letter, we demonstrate that WWR effects are\nnon-negligible in FVA modelling from a risk-management perspective. We look at\nthe impact of various modelling choices, such as including the default times of\nthe relevant parties, as well as stochastic and deterministic funding spreads.\nA case study is presented for interest rate derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.02680v4"
    },
    {
        "title": "Supervised machine learning classification for short straddles on the\n  S&P500",
        "authors": [
            "Alexander Brunhuemer",
            "Lukas Larcher",
            "Philipp Seidl",
            "Sascha Desmettre",
            "Johannes Kofler",
            "Gerhard Larcher"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this working paper we present our current progress in the training of\nmachine learning models to execute short option strategies on the S&P500. As a\nfirst step, this paper is breaking this problem down to a supervised\nclassification task to decide if a short straddle on the S&P500 should be\nexecuted or not on a daily basis. We describe our used framework and present an\noverview over our evaluation metrics on different classification models. In\nthis preliminary work, using standard machine learning techniques and without\nhyperparameter search, we find no statistically significant outperformance to a\nsimple \"trade always\" strategy, but gain additional insights on how we could\nproceed in further experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.13587v1"
    },
    {
        "title": "Dynamic and Context-Dependent Stock Price Prediction Using Attention\n  Modules and News Sentiment",
        "authors": [
            "Nicole Koenigstein"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The growth of machine-readable data in finance, such as alternative data,\nrequires new modeling techniques that can handle non-stationary and\nnon-parametric data. Due to the underlying causal dependence and the size and\ncomplexity of the data, we propose a new modeling approach for financial time\nseries data, the $\\alpha_{t}$-RIM (recurrent independent mechanism). This\narchitecture makes use of key-value attention to integrate top-down and\nbottom-up information in a context-dependent and dynamic way. To model the data\nin such a dynamic manner, the $\\alpha_{t}$-RIM utilizes an exponentially\nsmoothed recurrent neural network, which can model non-stationary times series\ndata, combined with a modular and independent recurrent structure. We apply our\napproach to the closing prices of three selected stocks of the S\\&P 500\nuniverse as well as their news sentiment score. The results suggest that the\n$\\alpha_{t}$-RIM is capable of reflecting the causal structure between stock\nprices and news sentiment, as well as the seasonality and trends. Consequently,\nthis modeling approach markedly improves the generalization performance, that\nis, the prediction of unseen data, and outperforms state-of-the-art networks\nsuch as long short-term memory models.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.01639v1"
    },
    {
        "title": "Deep learning based Chinese text sentiment mining and stock market\n  correlation research",
        "authors": [
            "Chenrui Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We explore how to crawl financial forum data such as stock bars and combine\nthem with deep learning models for sentiment analysis. In this paper, we will\nuse the BERT model to train against the financial corpus and predict the SZSE\nComponent Index, and find that applying the BERT model to the financial corpus\nthrough the maximum information coefficient comparison study. The obtained\nsentiment features will be able to reflect the fluctuations in the stock market\nand help to improve the prediction accuracy effectively. Meanwhile, this paper\ncombines deep learning with financial text, in further exploring the mechanism\nof investor sentiment on stock market through deep learning method, which will\nbe beneficial for national regulators and policy departments to develop more\nreasonable policy guidelines for maintaining the stability of stock market.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04743v1"
    },
    {
        "title": "Gamma and Vega Hedging Using Deep Distributional Reinforcement Learning",
        "authors": [
            "Jay Cao",
            "Jacky Chen",
            "Soroush Farghadani",
            "John Hull",
            "Zissis Poulos",
            "Zeyu Wang",
            "Jun Yuan"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We show how D4PG can be used in conjunction with quantile regression to\ndevelop a hedging strategy for a trader responsible for derivatives that arrive\nstochastically and depend on a single underlying asset. We assume that the\ntrader makes the portfolio delta neutral at the end of each day by taking a\nposition in the underlying asset. We focus on how trades in the options can be\nused to manage gamma and vega. The option trades are subject to transaction\ncosts. We consider three different objective functions. We reach conclusions on\nhow the optimal hedging strategy depends on the trader's objective function,\nthe level of transaction costs, and the maturity of the options used for\nhedging. We also investigate the robustness of the hedging strategy to the\nprocess assumed for the underlying asset.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05614v4"
    },
    {
        "title": "A time-varying study of Chinese investor sentiment, stock market\n  liquidity and volatility: Based on deep learning BERT model and TVP-VAR model",
        "authors": [
            "Chenrui Zhang",
            "Xinyi Wu",
            "Hailu Deng",
            "Huiwei Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Based on the commentary data of the Shenzhen Stock Index bar on the EastMoney\nwebsite from January 1, 2018 to December 31, 2019. This paper extracts the\nembedded investor sentiment by using a deep learning BERT model and\ninvestigates the time-varying linkage between investment sentiment, stock\nmarket liquidity and volatility using a TVP-VAR model. The results show that\nthe impact of investor sentiment on stock market liquidity and volatility is\nstronger. Although the inverse effect is relatively small, it is more\npronounced with the state of the stock market. In all cases, the response is\nmore pronounced in the short term than in the medium to long term, and the\nimpact is asymmetric, with shocks stronger when the market is in a downward\nspiral.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05719v2"
    },
    {
        "title": "Replicating Portfolios: Constructing Permissionless Derivatives",
        "authors": [
            "Estelle Sterrett",
            "Waylon Jepsen",
            "Evan Kim"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The current design space of derivatives in Decentralized Finance (DeFi)\nrelies heavily on oracle systems. Replicating market makers (RMMs) provide a\nmechanism for converting specific payoff functions to an associated Constant\nFunction Market Makers (CFMMs). We leverage RMMs to replicate the approximate\npayoff of a Black-Scholes covered call option. RMM-01 is the first\nimplementation of an on-chain expiring option mechanism that relies on\narbitrage rather than an external oracle for price. We provide frameworks for\nderivative instruments and structured products achievable on-chain without\nrelying on oracles. We construct long and binary options and briefly discuss\nperpetual covered call strategies commonly referred to as \"theta vaults.\"\nMoreover, we introduce a procedure to eliminate liquidation risk in lending\nmarkets. The results suggest that CFMMs are essential for structured product\ndesign with minimized trust dependencies.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.09890v2"
    },
    {
        "title": "Applying separative non-negative matrix factorization to extra-financial\n  data",
        "authors": [
            "P Fogel",
            "C Geissler",
            "P Cotte",
            "G Luta"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We present here an original application of the non-negative matrix\nfactorization (NMF) method, for the case of extra-financial data. These data\nare subject to high correlations between co-variables, as well as between\nobservations. NMF provides a much more relevant clustering of co-variables and\nobservations than a simple principal component analysis (PCA). In addition, we\nshow that an initial data separation step before applying NMF further improves\nthe quality of the clustering.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.04350v1"
    },
    {
        "title": "AlphaMLDigger: A Novel Machine Learning Solution to Explore Excess\n  Return on Investment",
        "authors": [
            "Jimei Shen",
            "Zhehu Yuan",
            "Yifan Jin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  How to quickly and automatically mine effective information and serve\ninvestment decisions has attracted more and more attention from academia and\nindustry. And new challenges have arisen with the global pandemic. This paper\nproposes a two-phase AlphaMLDigger that effectively finds excessive returns in\na highly fluctuated market. In phase 1, a deep sequential natural language\nprocessing (NLP) model is proposed to transfer Sina Microblog blogs to market\nsentiment. In phase 2, the predicted market sentiment is combined with social\nnetwork indicator features and stock market history features to predict the\nstock movements with different Machine Learning models and optimizers. The\nresults show that the ensemble models achieve an accuracy of 0.984 and\nsignificantly outperform the baseline model. In addition, we find that COVID-19\nbrings data shift to China's stock market.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.11072v2"
    },
    {
        "title": "Exchange option pricing under variance gamma-like models",
        "authors": [
            "Matteo Gardini",
            "Piergiacomo Sabino"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this article we focus on the pricing of exchange options when the dynamic\nof logprices follows either the well-known variance gamma or the recent\nvariance gamma++ process introduced in Gardini et al [19]. In particular, for\nthe former model we can derive a Margrabe's type formula whereas, for the\nlatter one we can write an \"integral free\" formula. Furthermore, we show how to\nconstruct a general multidimensional versions of the variance gamma++ processes\npreserving both the mathematical and numerical tractability. Finally we apply\nthe derived models to German and French energy power markets: we calibrate\ntheir parameters using real market data and we accordingly evaluate exchange\noptions with the derived closed formulas, Fourier based methods and Monte Carlo\ntechniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00453v1"
    },
    {
        "title": "Solving barrier options under stochastic volatility using deep learning",
        "authors": [
            "Weilong Fu",
            "Ali Hirsa"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We develop an unsupervised deep learning method to solve the barrier options\nunder the Bergomi model. The neural networks serve as the approximate option\nsurfaces and are trained to satisfy the PDE as well as the boundary conditions.\nTwo singular terms are added to the neural networks to deal with the non-smooth\nand discontinuous payoff at the strike and barrier levels so that the neural\nnetworks can replicate the asymptotic behaviors of barrier options at short\nmaturities. After that, vanilla options and barrier options are priced in a\nsingle framework. Also, neural networks are employed to deal with the high\ndimensionality of the function input in the Bergomi model. Once trained, the\nneural network solution yields fast and accurate option values.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00524v1"
    },
    {
        "title": "Deep Bellman Hedging",
        "authors": [
            "Hans Buehler",
            "Phillip Murray",
            "Ben Wood"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We present an actor-critic-type reinforcement learning algorithm for solving\nthe problem of hedging a portfolio of financial instruments such as securities\nand over-the-counter derivatives using purely historic data. The key\ncharacteristics of our approach are: the ability to hedge with derivatives such\nas forwards, swaps, futures, options; incorporation of trading frictions such\nas trading cost and liquidity constraints; applicability for any reasonable\nportfolio of financial instruments; realistic, continuous state and action\nspaces; and formal risk-adjusted return objectives. Most importantly, the\ntrained model provides an optimal hedge for arbitrary initial portfolios and\nmarket states without the need for re-training. We also prove existence of\nfinite solutions to our Bellman equation, and show the relation to our vanilla\nDeep Hedging approach\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00932v4"
    },
    {
        "title": "ETF Portfolio Construction via Neural Network trained on Financial\n  Statement Data",
        "authors": [
            "Jinho Lee",
            "Sungwoo Park",
            "Jungyu Ahn",
            "Jonghun Kwak"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Recently, the application of advanced machine learning methods for asset\nmanagement has become one of the most intriguing topics. Unfortunately, the\napplication of these methods, such as deep neural networks, is difficult due to\nthe data shortage problem. To address this issue, we propose a novel approach\nusing neural networks to construct a portfolio of exchange traded funds (ETFs)\nbased on the financial statement data of their components. Although a number of\nETFs and ETF-managed portfolios have emerged in the past few decades, the\nability to apply neural networks to manage ETF portfolios is limited since the\nnumber and historical existence of ETFs are relatively smaller and shorter,\nrespectively, than those of individual stocks. Therefore, we use the data of\nindividual stocks to train our neural networks to predict the future\nperformance of individual stocks and use these predictions and the portfolio\ndeposit file (PDF) to construct a portfolio of ETFs. Multiple experiments have\nbeen performed, and we have found that our proposed method outperforms the\nbaselines. We believe that our approach can be more beneficial when managing\nrecently listed ETFs, such as thematic ETFs, of which there is relatively\nlimited historical data for training advanced machine learning methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01187v1"
    },
    {
        "title": "Analysis of VIX-linked fee incentives in variable annuities via\n  continuous-time Markov chain approximation",
        "authors": [
            "Zhenyu Cui",
            "Anne MacKay",
            "Marie-Claude Vachon"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We consider the pricing of variable annuities (VAs) with general fee\nstructures under popular stochastic volatility models such as Heston,\nHull-White, Scott, $\\alpha$-Hypergeometric, $3/2$, and $4/2$ models. In\nparticular, we analyze the impact of different VIX-linked fee structures on the\noptimal surrender strategy of a VA contract with guaranteed minimum maturity\nbenefit (GMMB). Under the assumption that the VA contract can be surrendered\nbefore maturity, the pricing of a VA contract corresponds to an optimal\nstopping problem with an unbounded, time-dependent, and discontinuous payoff\nfunction. We develop efficient algorithms for the pricing of VA contracts using\na two-layer continuous-time Markov chain approximation for the fund value\nprocess. When the contract is kept until maturity and under a general fee\nstructure, we show that the value of the contract can be approximated by a\nclosed-form matrix expression. We also provide a quick and simple way to\ndetermine the value of early surrenders via a recursive algorithm and give an\neasy procedure to approximate the optimal surrender surface. We show\nnumerically that the optimal surrender strategy is more robust to changes in\nthe volatility of the account value when the fee is linked to the VIX index.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.14793v1"
    },
    {
        "title": "Solving the optimal stopping problem with reinforcement learning: an\n  application in financial option exercise",
        "authors": [
            "Leonardo Kanashiro Felizardo",
            "Elia Matsumoto",
            "Emilio Del-Moral-Hernandez"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The optimal stopping problem is a category of decision problems with a\nspecific constrained configuration. It is relevant to various real-world\napplications such as finance and management. To solve the optimal stopping\nproblem, state-of-the-art algorithms in dynamic programming, such as the\nleast-squares Monte Carlo (LSMC), are employed. This type of algorithm relies\non path simulations using only the last price of the underlying asset as a\nstate representation. Also, the LSMC was thinking for option valuation where\nrisk-neutral probabilities can be employed to account for uncertainty. However,\nthe general optimal stopping problem goals may not fit the requirements of the\nLSMC showing auto-correlated prices. We employ a data-driven method that uses\nMonte Carlo simulation to train and test artificial neural networks (ANN) to\nsolve the optimal stopping problem. Using ANN to solve decision problems is not\nentirely new. We propose a different architecture that uses convolutional\nneural networks (CNN) to deal with the dimensionality problem that arises when\nwe transform the whole history of prices into a Markovian state. We present\nexperiments that indicate that our proposed architecture improves results over\nthe previous implementations under specific simulated time series function\nsets. Lastly, we employ our proposed method to compare the optimal exercise of\nthe financial options problem with the LSMC algorithm. Our experiments show\nthat our method can capture more accurate exercise opportunities when compared\nto the LSMC. We have outstandingly higher (above 974\\% improvement) expected\npayoff from these exercise policies under the many Monte Carlo simulations that\nused the real-world return database on the out-of-sample (test) data.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.00765v1"
    },
    {
        "title": "Regime-based Implied Stochastic Volatility Model for Crypto Option\n  Pricing",
        "authors": [
            "Danial Saef",
            "Yuanrong Wang",
            "Tomaso Aste"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The increasing adoption of Digital Assets (DAs), such as Bitcoin (BTC), rises\nthe need for accurate option pricing models. Yet, existing methodologies fail\nto cope with the volatile nature of the emerging DAs. Many models have been\nproposed to address the unorthodox market dynamics and frequent disruptions in\nthe microstructure caused by the non-stationarity, and peculiar statistics, in\nDA markets. However, they are either prone to the curse of dimensionality, as\nadditional complexity is required to employ traditional theories, or they\noverfit historical patterns that may never repeat. Instead, we leverage recent\nadvances in market regime (MR) clustering with the Implied Stochastic\nVolatility Model (ISVM). Time-regime clustering is a temporal clustering\nmethod, that clusters the historic evolution of a market into different\nvolatility periods accounting for non-stationarity. ISVM can incorporate\ninvestor expectations in each of the sentiment-driven periods by using implied\nvolatility (IV) data. In this paper, we applied this integrated time-regime\nclustering and ISVM method (termed MR-ISVM) to high-frequency data on BTC\noptions at the popular trading platform Deribit. We demonstrate that MR-ISVM\ncontributes to overcome the burden of complex adaption to jumps in higher order\ncharacteristics of option pricing models. This allows us to price the market\nbased on the expectations of its participants in an adaptive fashion.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12614v2"
    },
    {
        "title": "Understanding intra-day price formation process by agent-based financial\n  market simulation: calibrating the extended chiarella model",
        "authors": [
            "Kang Gao",
            "Perukrishnen Vytelingum",
            "Stephen Weston",
            "Wayne Luk",
            "Ce Guo"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This article presents XGB-Chiarella, a powerful new approach for deploying\nagent-based models to generate realistic intra-day artificial financial price\ndata. This approach is based on agent-based models, calibrated by XGBoost\nmachine learning surrogate. Following the Extended Chiarella model, three types\nof trading agents are introduced in this agent-based model: fundamental\ntraders, momentum traders, and noise traders. In particular, XGB-Chiarella\nfocuses on configuring the simulation to accurately reflect real market\nbehaviours. Instead of using the original Expectation-Maximisation algorithm\nfor parameter estimation, the agent-based Extended Chiarella model is\ncalibrated using XGBoost machine learning surrogate. It is shown that the\nmachine learning surrogate learned in the proposed method is an accurate proxy\nof the true agent-based market simulation. The proposed calibration method is\nsuperior to the original Expectation-Maximisation parameter estimation in terms\nof the distance between historical and simulated stylised facts. With the same\nunderlying model, the proposed methodology is capable of generating realistic\nprice time series in various stocks listed at three different exchanges, which\nindicates the universality of intra-day price formation process. For the time\nscale (minutes) chosen in this paper, one agent per category is shown to be\nsufficient to capture the intra-day price formation process. The proposed\nXGB-Chiarella approach provides insights that the price formation process is\ncomprised of the interactions between momentum traders, fundamental traders,\nand noise traders. It can also be used to enhance risk management by\npractitioners.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.14207v1"
    },
    {
        "title": "Generative Adversarial Networks Applied to Synthetic Financial Scenarios\n  Generation",
        "authors": [
            "Matteo Rizzato",
            "Julien Wallart",
            "Christophe Geissler",
            "Nicolas Morizet",
            "Noureddine Boumlaik"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The finance industry is producing an increasing amount of datasets that\ninvestment professionals can consider to be influential on the price of\nfinancial assets. These datasets were initially mainly limited to exchange\ndata, namely price, capitalization and volume. Their coverage has now\nconsiderably expanded to include, for example, macroeconomic data, supply and\ndemand of commodities, balance sheet data and more recently extra-financial\ndata such as ESG scores. This broadening of the factors retained as influential\nconstitutes a serious challenge for statistical modeling. Indeed, the\ninstability of the correlations between these factors makes it practically\nimpossible to identify the joint laws needed to construct scenarios.\nFortunately, spectacular advances in Deep Learning field in recent years have\ngiven rise to GANs. GANs are a type of generative machine learning models that\nproduce new data samples with the same characteristics as a training data\ndistribution in an unsupervised way, avoiding data assumptions and human\ninduced biases. In this work, we are exploring the use of GANs for synthetic\nfinancial scenarios generation. This pilot study is the result of a\ncollaboration between Fujitsu and Advestis and it will be followed by a\nthorough exploration of the use cases that can benefit from the proposed\nsolution. We propose a GANs-based algorithm that allows the replication of\nmultivariate data representing several properties (including, but not limited\nto, price, market capitalization, ESG score, controversy score,. . .) of a set\nof stocks. This approach differs from examples in the financial literature,\nwhich are mainly focused on the reproduction of temporal asset price scenarios.\nWe also propose several metrics to evaluate the quality of the data generated\nby the GANs. This approach is well fit for the generation of scenarios, the\ntime direction simply arising as a subsequent (eventually conditioned)\ngeneration of data points drawn from the learned distribution. Our method will\nallow to simulate high dimensional scenarios (compared to $\\lesssim10$ features\ncurrently employed in most recent use cases) where network complexity is\nreduced thanks to a wisely performed feature engineering and selection.\nComplete results will be presented in a forthcoming study.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.03935v2"
    },
    {
        "title": "Statistical Learning of Value-at-Risk and Expected Shortfall",
        "authors": [
            "D Barrera",
            "S Crépey",
            "E Gobet",
            "Hoang-Dung Nguyen",
            "B Saadeddine"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We propose a non-asymptotic convergence analysis of a two-step approach to\nlearn a conditional value-at-risk (VaR) and a conditional expected shortfall\n(ES) using Rademacher bounds, in a non-parametric setup allowing for\nheavy-tails on the financial loss. Our approach for the VaR is extended to the\nproblem of learning at once multiple VaRs corresponding to different quantile\nlevels. This results in efficient learning schemes based on neural network\nquantile and least-squares regressions. An a posteriori Monte Carlo procedure\nis introduced to estimate distances to the ground-truth VaR and ES. This is\nillustrated by numerical experiments in a Student-$t$ toy model and a financial\ncase study where the objective is to learn a dynamic initial margin.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.06476v2"
    },
    {
        "title": "Interpretable Selective Learning in Credit Risk",
        "authors": [
            "Dangxing Chen",
            "Weicheng Ye",
            "Jiahui Ye"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The forecasting of the credit default risk has been an important research\nfield for several decades. Traditionally, logistic regression has been widely\nrecognized as a solution due to its accuracy and interpretability. As a recent\ntrend, researchers tend to use more complex and advanced machine learning\nmethods to improve the accuracy of the prediction. Although certain non-linear\nmachine learning methods have better predictive power, they are often\nconsidered to lack interpretability by financial regulators. Thus, they have\nnot been widely applied in credit risk assessment. We introduce a neural\nnetwork with the selective option to increase interpretability by\ndistinguishing whether the datasets can be explained by the linear models or\nnot. We find that, for most of the datasets, logistic regression will be\nsufficient, with reasonable accuracy; meanwhile, for some specific data\nportions, a shallow neural network model leads to much better accuracy without\nsignificantly sacrificing the interpretability.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.10127v1"
    },
    {
        "title": "Sentiment Analysis of ESG disclosures on Stock Market",
        "authors": [
            "Sudeep R. Bapat",
            "Saumya Kothari",
            "Rushil Bansal"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this paper, we look at the impact of Environment, Social and Governance\nrelated news articles and social media data on the stock market performance. We\npick four stocks of companies which are widely known in their domain to\nunderstand the complete effect of ESG as the newly opted investment style\nremains restricted to only the stocks with widespread information. We summarise\nlive data of both twitter tweets and newspaper articles and create a sentiment\nindex using a dictionary technique based on online information for the month of\nJuly, 2022. We look at the stock price data for all the four companies and\ncalculate the percentage change in each of them. We also compare the overall\nsentiment of the company to its percentage change over a specific historical\nperiod.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00731v1"
    },
    {
        "title": "MetaTrader: An Reinforcement Learning Approach Integrating Diverse\n  Policies for Portfolio Optimization",
        "authors": [
            "Hui Niu",
            "Siyuan Li",
            "Jian Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Portfolio management is a fundamental problem in finance. It involves\nperiodic reallocations of assets to maximize the expected returns within an\nappropriate level of risk exposure. Deep reinforcement learning (RL) has been\nconsidered a promising approach to solving this problem owing to its strong\ncapability in sequential decision making. However, due to the non-stationary\nnature of financial markets, applying RL techniques to portfolio optimization\nremains a challenging problem. Extracting trading knowledge from various expert\nstrategies could be helpful for agents to accommodate the changing markets. In\nthis paper, we propose MetaTrader, a novel two-stage RL-based approach for\nportfolio management, which learns to integrate diverse trading policies to\nadapt to various market conditions. In the first stage, MetaTrader incorporates\nan imitation learning objective into the reinforcement learning framework.\nThrough imitating different expert demonstrations, MetaTrader acquires a set of\ntrading policies with great diversity. In the second stage, MetaTrader learns a\nmeta-policy to recognize the market conditions and decide on the most proper\nlearned policy to follow. We evaluate the proposed approach on three real-world\nindex datasets and compare it to state-of-the-art baselines. The empirical\nresults demonstrate that MetaTrader significantly outperforms those baselines\nin balancing profits and risks. Furthermore, thorough ablation studies validate\nthe effectiveness of the components in the proposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.01774v1"
    },
    {
        "title": "Stock Volatility Prediction using Time Series and Deep Learning Approach",
        "authors": [
            "Ananda Chatterjee",
            "Hrisav Bhowmick",
            "Jaydip Sen"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Volatility clustering is a crucial property that has a substantial impact on\nstock market patterns. Nonetheless, developing robust models for accurately\npredicting future stock price volatility is a difficult research topic. For\npredicting the volatility of three equities listed on India's national stock\nmarket (NSE), we propose multiple volatility models depending on the\ngeneralized autoregressive conditional heteroscedasticity (GARCH),\nGlosten-Jagannathan-GARCH (GJR-GARCH), Exponential general autoregressive\nconditional heteroskedastic (EGARCH), and LSTM framework. Sector-wise stocks\nhave been chosen in our study. The sectors which have been considered are\nbanking, information technology (IT), and pharma. yahoo finance has been used\nto obtain stock price data from Jan 2017 to Dec 2021. Among the pulled-out\nrecords, the data from Jan 2017 to Dec 2020 have been taken for training, and\ndata from 2021 have been chosen for testing our models. The performance of\npredicting the volatility of stocks of three sectors has been evaluated by\nimplementing three different types of GARCH models as well as by the LSTM model\nare compared. It has been observed the LSTM performed better in predicting\nvolatility in pharma over banking and IT sectors. In tandem, it was also\nobserved that E-GARCH performed better in the case of the banking sector and\nfor IT and pharma, GJR-GARCH performed better.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.02126v1"
    },
    {
        "title": "Factor Investing with a Deep Multi-Factor Model",
        "authors": [
            "Zikai Wei",
            "Bo Dai",
            "Dahua Lin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Modeling and characterizing multiple factors is perhaps the most important\nstep in achieving excess returns over market benchmarks. Both academia and\nindustry are striving to find new factors that have good explanatory power for\nfuture stock returns and good stability of their predictive power. In practice,\nfactor investing is still largely based on linear multi-factor models, although\nmany deep learning methods show promising results compared to traditional\nmethods in stock trend prediction and portfolio risk management. However, the\nexisting non-linear methods have two drawbacks: 1) there is a lack of\ninterpretation of the newly discovered factors, 2) the financial insights\nbehind the mining process are unclear, making practitioners reluctant to apply\nthe existing methods to factor investing. To address these two shortcomings, we\ndevelop a novel deep multi-factor model that adopts industry neutralization and\nmarket neutralization modules with clear financial insights, which help us\neasily build a dynamic and multi-relational stock graph in a hierarchical\nstructure to learn the graph representation of stock relationships at different\nlevels, e.g., industry level and universal level. Subsequently, graph attention\nmodules are adopted to estimate a series of deep factors that maximize the\ncumulative factor returns. And a factor-attention module is developed to\napproximately compose the estimated deep factors from the input factors, as a\nway to interpret the deep factors explicitly. Extensive experiments on\nreal-world stock market data demonstrate the effectiveness of our deep\nmulti-factor model in the task of factor investing.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.12462v1"
    },
    {
        "title": "Using Deep Learning to Find the Next Unicorn: A Practical Synthesis",
        "authors": [
            "Lele Cao",
            "Vilhelm von Ehrenheim",
            "Sebastian Krakowski",
            "Xiaoxue Li",
            "Alexandra Lutz"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Startups often represent newly established business models associated with\ndisruptive innovation and high scalability. They are commonly regarded as\npowerful engines for economic and social development. Meanwhile, startups are\nheavily constrained by many factors such as limited financial funding and human\nresources. Therefore, the chance for a startup to eventually succeed is as rare\nas \"spotting a unicorn in the wild\". Venture Capital (VC) strives to identify\nand invest in unicorn startups during their early stages, hoping to gain a high\nreturn. To avoid entirely relying on human domain expertise and intuition,\ninvestors usually employ data-driven approaches to forecast the success\nprobability of startups. Over the past two decades, the industry has gone\nthrough a paradigm shift moving from conventional statistical approaches\ntowards becoming machine-learning (ML) based. Notably, the rapid growth of data\nvolume and variety is quickly ushering in deep learning (DL), a subset of ML,\nas a potentially superior approach in terms of capacity and expressivity. In\nthis work, we carry out a literature review and synthesis on DL-based\napproaches, covering the entire DL life cycle. The objective is a) to obtain a\nthorough and in-depth understanding of the methodologies for startup evaluation\nusing DL, and b) to distil valuable and actionable learning for practitioners.\nTo the best of our knowledge, our work is the first of this kind.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.14195v2"
    },
    {
        "title": "Projecting Non-Fungible Token (NFT) Collections: A Contextual Generative\n  Approach",
        "authors": [
            "Wesley Joon-Wie Tann",
            "Akhil Vuputuri",
            "Ee-Chien Chang"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Non-fungible tokens (NFTs) are digital assets stored on a blockchain\nrepresenting real-world objects such as art or collectibles. An NFT collection\ncomprises numerous tokens; each token can be transacted multiple times. It is a\nmultibillion-dollar market where the number of collections has more than\ndoubled in 2022. In this paper, we want to obtain a generative model that,\ngiven the early transactions history (first quarter Q1) of a newly minted\ncollection, generates subsequent transactions (quarters Q2, Q3, Q4), where the\ngenerative model is trained using the transaction history of a few mature\ncollections. The goal is to use the generated transactions to project the\npotential market value of this newly minted collection over the next few\nquarters. A technical challenge exists in that different collections have\ndiverse characteristics, and the generative model should generate based on the\nappropriate \"contexts\" of the collection. Our method takes a two-step approach.\nFirst, it employs unsupervised learning on the early transactions to extract\ncharacteristics (which we call contexts) of NFT collections. Next, it generates\nfuture transactions of each token based on these contexts and the early\ntransactions, projecting the target collection's potential market value.\nComprehensive experiments demonstrate our contextual generative approach's NFT\nprojection capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.15493v2"
    },
    {
        "title": "Uncertainty Aware Trader-Company Method: Interpretable Stock Price\n  Prediction Capturing Uncertainty",
        "authors": [
            "Yugo Fujimoto",
            "Kei Nakagawa",
            "Kentaro Imajo",
            "Kentaro Minami"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Machine learning is an increasingly popular tool with some success in\npredicting stock prices. One promising method is the Trader-Company~(TC)\nmethod, which takes into account the dynamism of the stock market and has both\nhigh predictive power and interpretability. Machine learning-based stock\nprediction methods including the TC method have been concentrating on point\nprediction. However, point prediction in the absence of uncertainty estimates\nlacks credibility quantification and raises concerns about safety. The\nchallenge in this paper is to make an investment strategy that combines high\npredictive power and the ability to quantify uncertainty. We propose a novel\napproach called Uncertainty Aware Trader-Company Method~(UTC) method. The core\nidea of this approach is to combine the strengths of both frameworks by merging\nthe TC method with the probabilistic modeling, which provides probabilistic\npredictions and uncertainty estimations. We expect this to retain the\npredictive power and interpretability of the TC method while capturing the\nuncertainty. We theoretically prove that the proposed method estimates the\nposterior variance and does not introduce additional biases from the original\nTC method. We conduct a comprehensive evaluation of our approach based on the\nsynthetic and real market datasets. We confirm with synthetic data that the UTC\nmethod can detect situations where the uncertainty increases and the prediction\nis difficult. We also confirmed that the UTC method can detect abrupt changes\nin data generating distributions. We demonstrate with real market data that the\nUTC method can achieve higher returns and lower risks than baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.17030v2"
    },
    {
        "title": "A novel approach to quantify volatility prediction",
        "authors": [
            "Suchetana Sadhukhan",
            "Shiv Manjaree Gopaliya",
            "Pushpdant Jain"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Volatility prediction in the financial market helps to understand the profit\nand involved risks in investment. However, due to irregularities, high\nfluctuations, and noise in the time series, predicting volatility poses a\nchallenging task. In the recent Covid-19 pandemic situation, volatility\nprediction using complex intelligence techniques has attracted enormous\nattention from researchers worldwide. In this paper, a novel and simple\napproach based on the robust least squares method in two approaches a) with\nleast absolute residuals (LAR) and b) without LAR, have been applied to the\nChicago Board Options Exchange (CBOE) Volatility Index (VIX) for a period of\nten years. For a deeper analysis, the volatility time series has been\ndecomposed into long-term trends, and seasonal, and random fluctuations. The\ndata sets have been divided into parts viz. training data set and testing data\nset. The validation results have been achieved using root mean square error\n(RMSE) values. It has been found that robust least squares method with LAR\napproach gives better results for volatility (RMSE = 0.01366) and its\ncomponents viz. long term trend (RMSE = 0.10087), seasonal (RMSE = 0.010343)\nand remainder fluctuations (RMSE = 0.014783), respectively. For the first time,\ngeneralized prediction equations for volatility and its three components have\nbeen presented. Young researchers working in this domain can directly use the\npresented prediction equations to understand their data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.00528v1"
    },
    {
        "title": "A weak MLMC scheme for Lévy-copula-driven SDEs with applications to\n  the pricing of credit, equity and interest rate derivatives",
        "authors": [
            "Aleksandar Mijatović",
            "Romain Palfray"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper develops a novel weak multilevel Monte-Carlo (MLMC) approximation\nscheme for L\\'evy-driven Stochastic Differential Equations (SDEs). The scheme\nis based on the state space discretization (via a continuous-time Markov chain\napproximation) of the pure-jump component of the driving L\\'evy process and is\nparticularly suited if the multidimensional driver is given by a L\\'evy copula.\nThe multilevel version of the algorithm requires a new coupling of the\napproximate L\\'evy drivers in the consecutive levels of the scheme, which is\ndefined via a coupling of the corresponding Poisson point processes. The\nmultilevel scheme is weak in the sense that the bound on the level variances is\nbased on the coupling alone without requiring strong convergence. Moreover, the\ncoupling is natural for the proposed discretization of jumps and is easy to\nsimulate. The approximation scheme and its multilevel analogous are applied to\nexamples taken from mathematical finance, including the pricing of credit,\nequity and interest rate derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02528v1"
    },
    {
        "title": "Graph-Regularized Tensor Regression: A Domain-Aware Framework for\n  Interpretable Multi-Way Financial Modelling",
        "authors": [
            "Yao Lei Xu",
            "Kriton Konstantinidis",
            "Danilo P. Mandic"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Analytics of financial data is inherently a Big Data paradigm, as such data\nare collected over many assets, asset classes, countries, and time periods.\nThis represents a challenge for modern machine learning models, as the number\nof model parameters needed to process such data grows exponentially with the\ndata dimensions; an effect known as the Curse-of-Dimensionality. Recently,\nTensor Decomposition (TD) techniques have shown promising results in reducing\nthe computational costs associated with large-dimensional financial models\nwhile achieving comparable performance. However, tensor models are often unable\nto incorporate the underlying economic domain knowledge. To this end, we\ndevelop a novel Graph-Regularized Tensor Regression (GRTR) framework, whereby\nknowledge about cross-asset relations is incorporated into the model in the\nform of a graph Laplacian matrix. This is then used as a regularization tool to\npromote an economically meaningful structure within the model parameters. By\nvirtue of tensor algebra, the proposed framework is shown to be fully\ninterpretable, both coefficient-wise and dimension-wise. The GRTR model is\nvalidated in a multi-way financial forecasting setting and compared against\ncompeting models, and is shown to achieve improved performance at reduced\ncomputational costs. Detailed visualizations are provided to help the reader\ngain an intuitive understanding of the employed tensor operations.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.05581v1"
    },
    {
        "title": "The Short-Term Predictability of Returns in Order Book Markets: a Deep\n  Learning Perspective",
        "authors": [
            "Lorenzo Lucchese",
            "Mikko Pakkanen",
            "Almut Veraart"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this paper, we conduct a systematic large-scale analysis of order\nbook-driven predictability in high-frequency returns by leveraging deep\nlearning techniques. First, we introduce a new and robust representation of the\norder book, the volume representation. Next, we carry out an extensive\nempirical experiment to address various questions regarding predictability. We\ninvestigate if and how far ahead there is predictability, the importance of a\nrobust data representation, the advantages of multi-horizon modeling, and the\npresence of universal trading patterns. We use model confidence sets, which\nprovide a formalized statistical inference framework particularly well suited\nto answer these questions. Our findings show that at high frequencies\npredictability in mid-price returns is not just present, but ubiquitous. The\nperformance of the deep learning models is strongly dependent on the choice of\norder book representation, and in this respect, the volume representation\nappears to have multiple practical advantages.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.13777v3"
    },
    {
        "title": "Optimizing Stock Option Forecasting with the Assembly of Machine\n  Learning Models and Improved Trading Strategies",
        "authors": [
            "Zheng Cao",
            "Raymond Guo",
            "Wenyu Du",
            "Jiayi Gao",
            "Kirill V. Golubnichiy"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper introduced key aspects of applying Machine Learning (ML) models,\nimproved trading strategies, and the Quasi-Reversibility Method (QRM) to\noptimize stock option forecasting and trading results. It presented the\nfindings of the follow-up project of the research \"Application of Convolutional\nNeural Networks with Quasi-Reversibility Method Results for Option\nForecasting\". First, the project included an application of Recurrent Neural\nNetworks (RNN) and Long Short-Term Memory (LSTM) networks to provide a novel\nway of predicting stock option trends. Additionally, it examined the dependence\nof the ML models by evaluating the experimental method of combining multiple ML\nmodels to improve prediction results and decision-making. Lastly, two improved\ntrading strategies and simulated investing results were presented. The Binomial\nAsset Pricing Model with discrete time stochastic process analysis and\nportfolio hedging was applied and suggested an optimized investment\nexpectation. These results can be utilized in real-life trading strategies to\noptimize stock option investment results based on historical data.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.15912v1"
    },
    {
        "title": "Weak error estimates for rough volatility models",
        "authors": [
            "Peter K. Friz",
            "William Salkeld",
            "Thomas Wagenhofer"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We consider a class of stochastic processes with rough stochastic volatility,\nexamples of which include the rough Bergomi and rough Stein-Stein model, that\nhave gained considerable importance in quantitative finance.\n  A basic question for such (non-Markovian) models concerns efficient numerical\nschemes. While strong rates are well understood (order $H$), we tackle here the\nintricate question of weak rates. Our main result asserts that the weak rate,\nfor a reasonably large class of test function, is essentially of order $\\min \\{\n3H+\\tfrac12, 1 \\}$ where $H \\in (0,1/2]$ is the Hurst parameter of the\nfractional Brownian motion that underlies the rough volatility process.\n  Interestingly, the phase transition at $H=1/6$ is related to the correlation\nbetween the two driving factors, and thus gives additional meaning to a\nquantity already of central importance in stochastic volatility modelling.Our\nresults are complemented by a lower bound which show that the obtained weak\nrate is indeed optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01591v2"
    },
    {
        "title": "Multi-Agent Dynamic Pricing in a Blockchain Protocol Using Gaussian\n  Bandits",
        "authors": [
            "Alexis Asseman",
            "Tomasz Kornuta",
            "Anirudh Patel",
            "Matt Deible",
            "Sam Green"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The Graph Protocol indexes historical blockchain transaction data and makes\nit available for querying. As the protocol is decentralized, there are many\nindependent Indexers that index and compete with each other for serving queries\nto the Consumers. One dimension along which Indexers compete is pricing. In\nthis paper, we propose a bandit-based algorithm for maximization of Indexers'\nrevenue via Consumer budget discovery. We present the design and the\nconsiderations we had to make for a dynamic pricing algorithm being used by\nmultiple agents simultaneously. We discuss the results achieved by our dynamic\npricing bandits both in simulation and deployed into production on one of the\nIndexers operating on Ethereum. We have open-sourced both the simulation\nframework and tools we created, which other Indexers have since started to\nadapt into their own workflows.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07942v2"
    },
    {
        "title": "Benchmarking Machine Learning Models to Predict Corporate Bankruptcy",
        "authors": [
            "Emmanuel Alanis",
            "Sudheer Chava",
            "Agam Shah"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Using a comprehensive sample of 2,585 bankruptcies from 1990 to 2019, we\nbenchmark the performance of various machine learning models in predicting\nfinancial distress of publicly traded U.S. firms. We find that gradient boosted\ntrees outperform other models in one-year-ahead forecasts. Variable permutation\ntests show that excess stock returns, idiosyncratic risk, and relative size are\nthe more important variables for predictions. Textual features derived from\ncorporate filings do not improve performance materially. In a credit\ncompetition model that accounts for the asymmetric cost of default\nmisclassification, the survival random forest is able to capture large dollar\nprofits.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.12051v1"
    },
    {
        "title": "Data-driven Approach for Static Hedging of Exchange Traded Options",
        "authors": [
            "Vikranth Lokeshwar Dhandapani",
            "Shashi Jain"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper presents a data-driven interpretable machine learning algorithm\nfor semi-static hedging of Exchange Traded options, considering transaction\ncosts with efficient run-time. Further, we provide empirical evidence on the\nperformance of hedging longer-term National Stock Exchange (NSE) Index options\nusing a self-replicating portfolio of shorter-term options and cash position,\nachieved by the automated algorithm, under different modeling assumptions and\nmarket conditions, including Covid period. We also systematically assess the\nmodel's performance using the Superior Predictive Ability (SPA) test by\nbenchmarking against the static hedge proposed by Peter Carr and Liuren Wu and\nindustry-standard dynamic hedging. We finally perform a thorough Profit and\nLoss (PnL) attribution analysis on the target option and hedge portfolios\n(dynamic and static) to discern the factors explaining the superior performance\nof static hedging.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00728v2"
    },
    {
        "title": "Policy gradient learning methods for stochastic control with exit time\n  and applications to share repurchase pricing",
        "authors": [
            "Mohamed Hamdouche",
            "Pierre Henry-Labordere",
            "Huyen Pham"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We develop policy gradients methods for stochastic control with exit time in\na model-free setting. We propose two types of algorithms for learning either\ndirectly the optimal policy or by learning alternately the value function\n(critic) and the optimal control (actor). The use of randomized policies is\ncrucial for overcoming notably the issue related to the exit time in the\ngradient computation. We demonstrate the effectiveness of our approach by\nimplementing our numerical schemes in the application to the problem of share\nrepurchase pricing. Our results show that the proposed policy gradient methods\noutperform PDE or other neural networks techniques in a model-based setting.\nFurthermore, our algorithms are flexible enough to incorporate realistic market\nconditions like e.g. price impact or transaction costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.07320v1"
    },
    {
        "title": "A Deep Reinforcement Learning Trader without Offline Training",
        "authors": [
            "Boian Lazov"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper we pursue the question of a fully online trading algorithm\n(i.e. one that does not need offline training on previously gathered data). For\nthis task we use Double Deep $Q$-learning in the episodic setting with Fast\nLearning Networks approximating the expected reward $Q$. Additionally, we\ndefine the possible terminal states of an episode in such a way as to introduce\na mechanism to conserve some of the money in the trading pool when market\nconditions are seen as unfavourable. Some of these money are taken as profit\nand some are reused at a later time according to certain criteria. After\ndescribing the algorithm, we test it using the 1-minute-tick data for Cardano's\nprice on Binance. We see that the agent performs better than trading with\nrandomly chosen actions on each timestep. And it does so when tested on the\nwhole dataset as well as on different subsets, capturing different market\ntrends.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00356v1"
    },
    {
        "title": "Forecasting the movements of Bitcoin prices: an application of machine\n  learning algorithms",
        "authors": [
            "Hakan Pabuccu",
            "Serdar Ongan",
            "Ayse Ongan"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Cryptocurrencies, such as Bitcoin, are one of the most controversial and\ncomplex technological innovations in today's financial system. This study aims\nto forecast the movements of Bitcoin prices at a high degree of accuracy. To\nthis aim, four different Machine Learning (ML) algorithms are applied, namely,\nthe Support Vector Machines (SVM), the Artificial Neural Network (ANN), the\nNaive Bayes (NB) and the Random Forest (RF) besides the logistic regression\n(LR) as a benchmark model. In order to test these algorithms, besides existing\ncontinuous dataset, discrete dataset was also created and used. For the\nevaluations of algorithm performances, the F statistic, accuracy statistic, the\nMean Absolute Error (MAE), the Root Mean Square Error (RMSE) and the Root\nAbsolute Error (RAE) metrics were used. The t test was used to compare the\nperformances of the SVM, ANN, NB and RF with the performance of the LR.\nEmpirical findings reveal that, while the RF has the highest forecasting\nperformance in the continuous dataset, the NB has the lowest. On the other\nhand, while the ANN has the highest and the NB the lowest performance in the\ndiscrete dataset. Furthermore, the discrete dataset improves the overall\nforecasting performance in all algorithms (models) estimated.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.04642v1"
    },
    {
        "title": "Mastering Pair Trading with Risk-Aware Recurrent Reinforcement Learning",
        "authors": [
            "Weiguang Han",
            "Jimin Huang",
            "Qianqian Xie",
            "Boyi Zhang",
            "Yanzhao Lai",
            "Min Peng"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Although pair trading is the simplest hedging strategy for an investor to\neliminate market risk, it is still a great challenge for reinforcement learning\n(RL) methods to perform pair trading as human expertise. It requires RL methods\nto make thousands of correct actions that nevertheless have no obvious\nrelations to the overall trading profit, and to reason over infinite states of\nthe time-varying market most of which have never appeared in history. However,\nexisting RL methods ignore the temporal connections between asset price\nmovements and the risk of the performed trading. These lead to frequent\ntradings with high transaction costs and potential losses, which barely reach\nthe human expertise level of trading. Therefore, we introduce CREDIT, a\nrisk-aware agent capable of learning to exploit long-term trading opportunities\nin pair trading similar to a human expert. CREDIT is the first to apply\nbidirectional GRU along with the temporal attention mechanism to fully consider\nthe temporal correlations embedded in the states, which allows CREDIT to\ncapture long-term patterns of the price movements of two assets to earn higher\nprofit. We also design the risk-aware reward inspired by the economic theory,\nthat models both the profit and risk of the tradings during the trading period.\nIt helps our agent to master pair trading with a robust trading preference that\navoids risky trading with possible high returns and losses. Experiments show\nthat it outperforms existing reinforcement learning methods in pair trading and\nachieves a significant profit over five years of U.S. stock data.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.00364v1"
    },
    {
        "title": "Non-parametric cumulants approach for outlier detection of multivariate\n  financial data",
        "authors": [
            "Francesco Cesarone",
            "Rosella Giacometti",
            "Jacopo Maria Ricci"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we propose an outlier detection algorithm for multivariate\ndata based on their projections on the directions that maximize the Cumulant\nGenerating Function (CGF). We prove that CGF is a convex function, and we\ncharacterize the CGF maximization problem on the unit n-circle as a concave\nminimization problem. Then, we show that the CGF maximization approach can be\ninterpreted as an extension of the standard principal component technique.\nTherefore, for validation and testing, we provide a thorough comparison of our\nmethodology with two other projection-based approaches both on artificial and\nreal-world financial data. Finally, we apply our method as an early detector\nfor financial crises.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10911v1"
    },
    {
        "title": "Trustless Price Feeds of Cryptocurrencies: Pathfinder",
        "authors": [
            "Orhan Koc"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Price feeds of securities is a critical component for many financial\nservices, allowing for collateral liquidation, margin trading, derivative\npricing and more. With the advent of blockchain technology, value in reporting\naccurate prices without a third party has become apparent. There have been many\nattempts at trying to calculate prices without a third party, in which each of\nthese attempts have resulted in being exploited by an exploiter artificially\ninflating the price. The industry has then shifted to a more centralized\ndesign, fetching price data from multiple centralized sources and then applying\nstatistical methods to reach a consensus price. Even though this strategy is\nsecure compared to reading from a single source, enough number of sources need\nto report to be able to apply statistical methods. As more sources participate\nin reporting the price, the feed gets more secure with the slowest feed\nbecoming the bottleneck for query response time, introducing a tradeoff between\nsecurity and speed. This paper provides the design and implementation details\nof a novel method to algorithmically compute security prices in a way that\nartificially inflating targeted pools has no effect on the reported price of\nthe queried asset. We hypothesize that the proposed algorithm can report\naccurate prices given a set of possibly dishonest sources.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13227v1"
    },
    {
        "title": "Market Making with Deep Reinforcement Learning from Limit Order Books",
        "authors": [
            "Hong Guo",
            "Jianwu Lin",
            "Fanlin Huang"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Market making (MM) is an important research topic in quantitative finance,\nthe agent needs to continuously optimize ask and bid quotes to provide\nliquidity and make profits. The limit order book (LOB) contains information on\nall active limit orders, which is an essential basis for decision-making. The\nmodeling of evolving, high-dimensional and low signal-to-noise ratio LOB data\nis a critical challenge. Traditional MM strategy relied on strong assumptions\nsuch as price process, order arrival process, etc. Previous reinforcement\nlearning (RL) works handcrafted market features, which is insufficient to\nrepresent the market. This paper proposes a RL agent for market making with LOB\ndata. We leverage a neural network with convolutional filters and attention\nmechanism (Attn-LOB) for feature extraction from LOB. We design a new\ncontinuous action space and a hybrid reward function for the MM task. Finally,\nwe conduct comprehensive experiments on latency and interpretability, showing\nthat our agent has good applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.15821v1"
    },
    {
        "title": "Robust Hedging GANs",
        "authors": [
            "Yannick Limmer",
            "Blanka Horvath"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The availability of deep hedging has opened new horizons for solving hedging\nproblems under a large variety of realistic market conditions. At the same\ntime, any model - be it a traditional stochastic model or a market generator -\nis at best an approximation of market reality, prone to model-misspecification\nand estimation errors. This raises the question, how to furnish a modelling\nsetup with tools that can address the risk of discrepancy between anticipated\ndistribution and market reality, in an automated way. Automated robustification\nis currently attracting increased attention in numerous investment problems,\nbut it is a delicate task due to its imminent implications on risk management.\nHence, it is beyond doubt that more activity can be anticipated on this topic\nto converge towards a consensus on best practices.\n  This paper presents a natural extension of the original deep hedging\nframework to address uncertainty in the data generating process via an\nadversarial approach inspired by GANs to automate robustification in our\nhedging objective. This is achieved through an interplay of three modular\ncomponents: (i) a (deep) hedging engine, (ii) a data-generating process (that\nis model agnostic permitting a large variety of classical models as well as\nmachine learning-based market generators), and (iii) a notion of distance on\nmodel space to measure deviations between our market prognosis and reality. We\ndo not restrict the ambiguity set to a region around a reference model, but\ninstead penalize deviations from the anticipated distribution. Our suggested\nchoice for each component is motivated by model agnosticism, allowing a\nseamless transition between settings. Since all individual components are\nalready used in practice, we believe that our framework is easily adaptable to\nexisting functional settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.02310v1"
    },
    {
        "title": "Machine learning for option pricing: an empirical investigation of\n  network architectures",
        "authors": [
            "Laurens Van Mieghem",
            "Antonis Papapantoleon",
            "Jonas Papazoglou-Hennig"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We consider the supervised learning problem of learning the price of an\noption or the implied volatility given appropriate input data (model\nparameters) and corresponding output data (option prices or implied\nvolatilities). The majority of articles in this literature considers a (plain)\nfeed forward neural network architecture in order to connect the neurons used\nfor learning the function mapping inputs to outputs. In this article, motivated\nby methods in image classification and recent advances in machine learning\nmethods for PDEs, we investigate empirically whether and how the choice of\nnetwork architecture affects the accuracy and training time of a machine\nlearning algorithm. We find that for option pricing problems, where we focus on\nthe Black--Scholes and the Heston model, the generalized highway network\narchitecture outperforms all other variants, when considering the mean squared\nerror and the training time as criteria. Moreover, for the computation of the\nimplied volatility, after a necessary transformation, a variant of the DGM\narchitecture outperforms all other variants, when considering again the mean\nsquared error and the training time as criteria.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07657v1"
    },
    {
        "title": "An Adaptive Dual-level Reinforcement Learning Approach for Optimal Trade\n  Execution",
        "authors": [
            "Soohan Kim",
            "Jimyeong Kim",
            "Hong Kee Sul",
            "Youngjoon Hong"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The purpose of this research is to devise a tactic that can closely track the\ndaily cumulative volume-weighted average price (VWAP) using reinforcement\nlearning. Previous studies often choose a relatively short trading horizon to\nimplement their models, making it difficult to accurately track the daily\ncumulative VWAP since the variations of financial data are often insignificant\nwithin the short trading horizon. In this paper, we aim to develop a strategy\nthat can accurately track the daily cumulative VWAP while minimizing the\ndeviation from the VWAP. We propose a method that leverages the U-shaped\npattern of intraday stock trade volumes and use Proximal Policy Optimization\n(PPO) as the learning algorithm. Our method follows a dual-level approach: a\nTransformer model that captures the overall(global) distribution of daily\nvolumes in a U-shape, and a LSTM model that handles the distribution of orders\nwithin smaller(local) time intervals. The results from our experiments suggest\nthat this dual-level architecture improves the accuracy of approximating the\ncumulative VWAP, when compared to previous reinforcement learning-based models.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.10649v1"
    },
    {
        "title": "Adversarial Deep Hedging: Learning to Hedge without Price Process\n  Modeling",
        "authors": [
            "Masanori Hirano",
            "Kentaro Minami",
            "Kentaro Imajo"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Deep hedging is a deep-learning-based framework for derivative hedging in\nincomplete markets. The advantage of deep hedging lies in its ability to handle\nvarious realistic market conditions, such as market frictions, which are\nchallenging to address within the traditional mathematical finance framework.\nSince deep hedging relies on market simulation, the underlying asset price\nprocess model is crucial. However, existing literature on deep hedging often\nrelies on traditional mathematical finance models, e.g., Brownian motion and\nstochastic volatility models, and discovering effective underlying asset models\nfor deep hedging learning has been a challenge. In this study, we propose a new\nframework called adversarial deep hedging, inspired by adversarial learning. In\nthis framework, a hedger and a generator, which respectively model the\nunderlying asset process and the underlying asset process, are trained in an\nadversarial manner. The proposed method enables to learn a robust hedger\nwithout explicitly modeling the underlying asset process. Through numerical\nexperiments, we demonstrate that our proposed method achieves competitive\nperformance to models that assume explicit underlying asset processes across\nvarious real market data.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.13217v1"
    },
    {
        "title": "Grover Search for Portfolio Selection",
        "authors": [
            "A. Ege Yilmaz",
            "Stefan Stettler",
            "Thomas Ankenbrand",
            "Urs Rhyner"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We present explicit oracles designed to be used in Grover's algorithm to\nmatch investor preferences. Specifically, the oracles select portfolios with\nreturns and standard deviations exceeding and falling below certain thresholds,\nrespectively. One potential use case for the oracles is selecting portfolios\nwith the best Sharpe ratios. We have implemented these algorithms using quantum\nsimulators.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.13063v1"
    },
    {
        "title": "Sizing Strategies for Algorithmic Trading in Volatile Markets: A Study\n  of Backtesting and Risk Mitigation Analysis",
        "authors": [
            "S. M. Masrur Ahmed"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Backtest is a way of financial risk evaluation which helps to analyze how our\ntrading algorithm would work in markets with past time frame. The high\nvolatility situation has always been a critical situation which creates\nchallenges for algorithmic traders. The paper investigates different models of\nsizing in financial trading and backtest to high volatility situations to\nunderstand how sizing models can lower the models of VaR during crisis events.\nHence it tries to show that how crisis events with high volatility can be\ncontrolled using short and long positional size. The paper also investigates\nstocks with AR, ARIMA, LSTM, GARCH with ETF data.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.09094v2"
    },
    {
        "title": "Comparing effects of price limit and circuit breaker in stock exchanges\n  by an agent-based model",
        "authors": [
            "Takanobu Mizuta",
            "Isao Yagi"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The prevention of rapidly and steeply falling market prices is vital to avoid\nfinancial crisis. To this end, some stock exchanges implement a price limit or\na circuit breaker, and there has been intensive investigation into which\nregulation best prevents rapid and large variations in price. In this study, we\nexamine this question using an artificial market model that is an agent-based\nmodel for a financial market. Our findings show that the price limit and the\ncircuit breaker basically have the same effect when the parameters, limit price\nrange and limit time range, are the same. However, the price limit is less\neffective when limit the time range is smaller than the cancel time range. With\nthe price limit, many sell orders are accumulated around the lower limit price,\nand when the lower limit price is changed before the accumulated sell orders\nare cancelled, it leads to the accumulation of sell orders of various prices.\nThese accumulated sell orders essentially act as a wall against buy orders,\nthereby preventing price from rising. Caution should be taken in the sense that\nthese results pertain to a limited situation. Specifically, our finding that\nthe circuit breaker is better than the price limit should be adapted only in\ncases where the reason for falling prices is erroneous orders and when\nindividual stocks are regulated.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10220v1"
    },
    {
        "title": "Derivatives Sensitivities Computation under Heston Model on GPU",
        "authors": [
            "Pierre-Antoine Arsaguet",
            "Paul Bilokon"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This report investigates the computation of option Greeks for European and\nAsian options under the Heston stochastic volatility model on GPU. We first\nimplemented the exact simulation method proposed by Broadie and Kaya and used\nit as a baseline for precision and speed. We then proposed a novel method for\ncomputing Greeks using the Milstein discretisation method on GPU. Our results\nshow that the proposed method provides a speed-up up to 200x compared to the\nexact simulation implementation and that it can be used for both European and\nAsian options. However, the accuracy of the GPU method for estimating Rho is\ninferior to the CPU method. Overall, our study demonstrates the potential of\nGPU for computing derivatives sensitivies with numerical methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10477v1"
    },
    {
        "title": "A Portfolio Rebalancing Approach for the Indian Stock Market",
        "authors": [
            "Jaydip Sen",
            "Arup Dasgupta",
            "Subhasis Dasgupta",
            "Sayantani Roychoudhury"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This chapter presents a calendar rebalancing approach to portfolios of stocks\nin the Indian stock market. Ten important sectors of the Indian economy are\nfirst selected. For each of these sectors, the top ten stocks are identified\nbased on their free-float market capitalization values. Using the ten stocks in\neach sector, a sector-specific portfolio is designed. In this study, the\nhistorical stock prices are used from January 4, 2021, to September 20, 2023\n(NSE Website). The portfolios are designed based on the training data from\nJanuary 4, 2021 to June 30, 2022. The performances of the portfolios are tested\nover the period from July 1, 2022, to September 20, 2023. The calendar\nrebalancing approach presented in the chapter is based on a yearly rebalancing\nmethod. However, the method presented is perfectly flexible and can be adapted\nfor weekly or monthly rebalancing. The rebalanced portfolios for the ten\nsectors are analyzed in detail for their performances. The performance results\nare not only indicative of the relative performances of the sectors over the\ntraining (i.e., in-sample) data and test (out-of-sample) data, but they also\nreflect the overall effectiveness of the proposed portfolio rebalancing\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09770v1"
    },
    {
        "title": "The Measure Preserving Martingale Sinkhorn Algorithm",
        "authors": [
            "Benjamin Joseph",
            "Gregoire Loeper",
            "Jan Obloj"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We contribute to the recent studies of the so-called Bass martingale.\nBackhoff-Veraguas et al. (2020) showed it is the solution to the martingale\nBenamou-Brenier (mBB) problem, i.e., among all martingales with prescribed\ninitial and terminal distributions it is the one closest to the Brownian\nmotion. We link it with semimartingale optimal transport and deduce an\nalternative way to derive the dual formulation recently obtained in\nBackhoff-Veraguas et al. (2023). We then consider computational methods to\ncompute the Bass martingale. The dual formulation of the transport problem\nleads to an iterative scheme that mirrors to the celebrated Sinkhorn algorithm\nfor entropic optimal transport. We call it the measure preserving martingale\nSinkhorn (MPMS) algorithm. We prove that in any dimension, each step of the\nalgorithm improves the value of the dual problem, which implies its\nconvergence. Our MPMS algorithm is equivalent to the fixed-point method of\nConze and Henry-Labordere (2021), studied in Acciaio et al. (2023), and\nperforms very well on a range of examples, including real market data.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.13797v3"
    },
    {
        "title": "Predicting risk/reward ratio in financial markets for asset management\n  using machine learning",
        "authors": [
            "Reza Yarbakhsh",
            "Mahdieh Soleymani Baghshah",
            "Hamidreza Karimaghaie"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Financial market forecasting remains a formidable challenge despite the surge\nin computational capabilities and machine learning advancements. While numerous\nstudies have underscored the precision of computer-generated market\npredictions, many of these forecasts fail to yield profitable trading outcomes.\nThis discrepancy often arises from the unpredictable nature of profit and loss\nratios in the event of successful and unsuccessful predictions. In this study,\nwe introduce a novel algorithm specifically designed for forecasting the profit\nand loss outcomes of trading activities. This is further augmented by an\ninnovative approach for integrating these forecasts with previous predictions\nof market trends. This approach is designed for algorithmic trading, enabling\ntraders to assess the profitability of each trade and calibrate the optimal\ntrade size. Our findings indicate that this method significantly improves the\nperformance of traditional trading strategies as well as algorithmic trading\nsystems, offering a promising avenue for enhancing trading decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09148v1"
    },
    {
        "title": "Alternative models for FX, arbitrage opportunities and efficient pricing\n  of double barrier options in Lévy models",
        "authors": [
            "Svetlana Boyarchenko",
            "Sergei Levendorskii"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We analyze the qualitative differences between prices of double barrier\nno-touch options in the Heston model and pure jump KoBoL model calibrated to\nthe same set of the empirical data, and discuss the potential for arbitrage\nopportunities if the correct model is a pure jump model. We explain and\ndemonstrate with numerical examples that accurate and fast calculations of\nprices of double barrier options in jump models are extremely difficult using\nthe numerical methods available in the literature. We develop a new efficient\nmethod (GWR-SINH method) based of the Gaver-Wynn-Rho acceleration applied to\nthe Bromwich integral; the SINH-acceleration and simplified trapezoid rule are\nused to evaluate perpetual double barrier options for each value of the\nspectral parameter in GWR-algorithm. The program in Matlab running on a Mac\nwith moderate characteristics achieves the precision of the order of E-5 and\nbetter in several several dozen of milliseconds; the precision E-07 is\nachievable in about 0.1 sec. We outline the extension of GWR-SINH method to\nregime-switching models and models with stochastic parameters and stochastic\ninterest rates.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.03915v1"
    },
    {
        "title": "Simulation of a Lévy process, its extremum, and hitting time of the\n  extremum via characteristic functions",
        "authors": [
            "Svetlana Boyarchenko",
            "Sergei Levendorskii"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We suggest a general framework for simulation of the triplet $(X_T,\\bar X_\nT,\\tau_T)$ (L\\'evy process, its extremum, and hitting time of the extremum),\nand, separately, $X_T,\\bar X_ T$ and pairs $(X_T,\\bar X_ T)$, $(\\bar X_\nT,\\tau_T)$,\n  $(\\bar X_ T-X_T,\\tau_T)$, via characteristic functions and conditional\ncharacteristic functions. The conformal deformations technique allows one to\nevaluate probability distributions, joint probability distributions and\nconditional probability distributions accurately and fast. For simulations in\nthe far tails of the distribution, we precalculate and store the values of the\n(conditional) characteristic functions on multi-grids on appropriate surfaces\nin $C^n$, and use these values to calculate the quantiles in the tails. For\nsimulation in the central part of a distribution, we precalculate the values of\nthe cumulative distribution at points of a non-uniform (multi-)grid, and use\ninterpolation to calculate quantiles.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.03929v1"
    },
    {
        "title": "A Two-Step Longstaff Schwartz Monte Carlo Approach to Game Option\n  Pricing",
        "authors": [
            "Ce Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We proposed a two-step Longstaff Schwartz Monte Carlo (LSMC) method with two\nregression models fitted at each time step to price game options. Although the\noriginal LSMC can be used to price game options with an enlarged range of path\nin regression and a modified cashflow updating rule, we identified a drawback\nof such approach, which motivated us to propose our approach. We implemented\nnumerical examples with benchmarks using binomial tree and numerical PDE, and\nit showed that our method produces more reliable results comparing to the\noriginal LSMC.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08093v1"
    },
    {
        "title": "CNN-DRL with Shuffled Features in Finance",
        "authors": [
            "Sina Montazeri",
            "Akram Mirzaeinia",
            "Amir Mirzaeinia"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In prior methods, it was observed that the application of Convolutional\nNeural Networks agent in Deep Reinforcement Learning to financial data resulted\nin an enhanced reward. In this study, a specific permutation was applied to the\nfeature vector, thereby generating a CNN matrix that strategically positions\nmore pertinent features in close proximity. Our comprehensive experimental\nevaluations unequivocally demonstrate a substantial enhancement in reward\nattainment.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.03338v1"
    },
    {
        "title": "Alpha-GPT 2.0: Human-in-the-Loop AI for Quantitative Investment",
        "authors": [
            "Hang Yuan",
            "Saizhuo Wang",
            "Jian Guo"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Recently, we introduced a new paradigm for alpha mining in the realm of\nquantitative investment, developing a new interactive alpha mining system\nframework, Alpha-GPT. This system is centered on iterative Human-AI interaction\nbased on large language models, introducing a Human-in-the-Loop approach to\nalpha discovery. In this paper, we present the next-generation Alpha-GPT 2.0\n\\footnote{Draft. Work in progress}, a quantitative investment framework that\nfurther encompasses crucial modeling and analysis phases in quantitative\ninvestment. This framework emphasizes the iterative, interactive research\nbetween humans and AI, embodying a Human-in-the-Loop strategy throughout the\nentire quantitative investment pipeline. By assimilating the insights of human\nresearchers into the systematic alpha research process, we effectively leverage\nthe Human-in-the-Loop approach, enhancing the efficiency and precision of\nquantitative investment research.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09746v1"
    },
    {
        "title": "Deep Hedging with Market Impact",
        "authors": [
            "Andrei Neagu",
            "Frédéric Godin",
            "Clarence Simard",
            "Leila Kosseim"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Dynamic hedging is the practice of periodically transacting financial\ninstruments to offset the risk caused by an investment or a liability. Dynamic\nhedging optimization can be framed as a sequential decision problem; thus,\nReinforcement Learning (RL) models were recently proposed to tackle this task.\nHowever, existing RL works for hedging do not consider market impact caused by\nthe finite liquidity of traded instruments. Integrating such feature can be\ncrucial to achieve optimal performance when hedging options on stocks with\nlimited liquidity. In this paper, we propose a novel general market impact\ndynamic hedging model based on Deep Reinforcement Learning (DRL) that considers\nseveral realistic features such as convex market impacts, and impact\npersistence through time. The optimal policy obtained from the DRL model is\nanalysed using several option hedging simulations and compared to commonly used\nprocedures such as delta hedging. Results show our DRL model behaves better in\ncontexts of low liquidity by, among others: 1) learning the extent to which\nportfolio rebalancing actions should be dampened or delayed to avoid high\ncosts, 2) factoring in the impact of features not considered by conventional\napproaches, such as previous hedging errors through the portfolio value, and\nthe underlying asset's drift (i.e. the magnitude of its expected return).\n",
        "pdf_link": "http://arxiv.org/pdf/2402.13326v2"
    },
    {
        "title": "A Note on Optimal Liquidation with Linear Price Impact",
        "authors": [
            "Yan Dolinsky",
            "Doron Greenstein"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this note we consider the maximization of the expected terminal wealth for\nthe setup of quadratic transaction costs. First, we provide a very simple\nprobabilistic solution to the problem. Although the problem was largely\nstudied, as far as we know up to date this simple and probabilistic form of the\nsolution has not appeared in the literature.\n  Next, we apply the general result for the numerical study of the case where\nthe risky asset is given by a fractional Brownian Motion and the information\nflow of the investor can be diversified.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.14100v2"
    },
    {
        "title": "On the Hull-White model with volatility smile for Valuation Adjustments",
        "authors": [
            "T. van der Zwaard",
            "L. A. Grzelak",
            "C. W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Affine Diffusion dynamics are frequently used for Valuation Adjustments (xVA)\ncalculations due to their analytic tractability. However, these models cannot\ncapture the market-implied skew and smile, which are relevant when computing\nxVA metrics. Hence, additional degrees of freedom are required to capture these\nmarket features. In this paper, we address this through an SDE with\nstate-dependent coefficients. The SDE is consistent with the convex combination\nof a finite number of different AD dynamics. We combine Hull-White one-factor\nmodels where one model parameter is varied. We use the Randomized AD (RAnD)\ntechnique to parameterize the combination of dynamics. We refer to our SDE with\nstate-dependent coefficients and the RAnD parametrization of the original\nmodels as the rHW model. The rHW model allows for efficient semi-analytic\ncalibration to European swaptions through the analytic tractability of the\nHull-White dynamics. We use a regression-based Monte-Carlo simulation to\ncalculate exposures. In this setting, we demonstrate the significant effect of\nskew and smile on exposures and xVAs of linear and early-exercise interest rate\nderivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.14841v1"
    },
    {
        "title": "Construction of a Japanese Financial Benchmark for Large Language Models",
        "authors": [
            "Masanori Hirano"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  With the recent development of large language models (LLMs), models that\nfocus on certain domains and languages have been discussed for their necessity.\nThere is also a growing need for benchmarks to evaluate the performance of\ncurrent LLMs in each domain. Therefore, in this study, we constructed a\nbenchmark comprising multiple tasks specific to the Japanese and financial\ndomains and performed benchmark measurements on some models. Consequently, we\nconfirmed that GPT-4 is currently outstanding, and that the constructed\nbenchmarks function effectively. According to our analysis, our benchmark can\ndifferentiate benchmark scores among models in all performance ranges by\ncombining tasks with different difficulties.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.15062v1"
    },
    {
        "title": "Enhancing path-integral approximation for non-linear diffusion with\n  neural network",
        "authors": [
            "Anna Knezevic"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Enhancing the existing solution for pricing of fixed income instruments\nwithin Black-Karasinski model structure, with neural network at various\nparameterisation points to demonstrate that the method is able to achieve\nsuperior outcomes for multiple calibrations across extended projection\nhorizons.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.08903v1"
    },
    {
        "title": "Experimental Analysis of Deep Hedging Using Artificial Market\n  Simulations for Underlying Asset Simulators",
        "authors": [
            "Masanori Hirano"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Derivative hedging and pricing are important and continuously studied topics\nin financial markets. Recently, deep hedging has been proposed as a promising\napproach that uses deep learning to approximate the optimal hedging strategy\nand can handle incomplete markets. However, deep hedging usually requires\nunderlying asset simulations, and it is challenging to select the best model\nfor such simulations. This study proposes a new approach using artificial\nmarket simulations for underlying asset simulations in deep hedging. Artificial\nmarket simulations can replicate the stylized facts of financial markets, and\nthey seem to be a promising approach for deep hedging. We investigate the\neffectiveness of the proposed approach by comparing its results with those of\nthe traditional approach, which uses mathematical finance models such as\nBrownian motion and Heston models for underlying asset simulations. The results\nshow that the proposed approach can achieve almost the same level of\nperformance as the traditional approach without mathematical finance models.\nFinally, we also reveal that the proposed approach has some limitations in\nterms of performance under certain conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09462v1"
    },
    {
        "title": "A Comparison of Traditional and Deep Learning Methods for Parameter\n  Estimation of the Ornstein-Uhlenbeck Process",
        "authors": [
            "Jacob Fein-Ashley"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We consider the Ornstein-Uhlenbeck (OU) process, a stochastic process widely\nused in finance, physics, and biology. Parameter estimation of the OU process\nis a challenging problem. Thus, we review traditional tracking methods and\ncompare them with novel applications of deep learning to estimate the\nparameters of the OU process. We use a multi-layer perceptron to estimate the\nparameters of the OU process and compare its performance with traditional\nparameter estimation methods, such as the Kalman filter and maximum likelihood\nestimation. We find that the multi-layer perceptron can accurately estimate the\nparameters of the OU process given a large dataset of observed trajectories\nand, on average, outperforms traditional parameter estimation methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.11526v3"
    },
    {
        "title": "Internet sentiment exacerbates intraday overtrading, evidence from\n  A-Share market",
        "authors": [
            "Peng Yifeng"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Market fluctuations caused by overtrading are important components of\nsystemic market risk. This study examines the effect of investor sentiment on\nintraday overtrading activities in the Chinese A-share market. Employing\nhigh-frequency sentiment indices inferred from social media posts on the\nEastmoney forum Guba, the research focuses on constituents of the CSI 300 and\nCSI 500 indices over a period from 01/01/2018, to 12/30/2022. The empirical\nanalysis indicates that investor sentiment exerts a significantly positive\nimpact on intraday overtrading, with the influence being more pronounced among\ninstitutional investors relative to individual traders. Moreover,\nsentiment-driven overtrading is found to be more prevalent during bull markets\nas opposed to bear markets. Additionally, the effect of sentiment on\novertrading is observed to be more pronounced among individual investors in\nlarge-cap stocks compared to small- and mid-cap stocks.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.12001v3"
    },
    {
        "title": "Analysis of market efficiency in main stock markets: using Karman-Filter\n  as an approach",
        "authors": [
            "Beier Liu",
            "Haiyun Zhu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this study, we utilize the Kalman-Filter analysis to assess market\nefficiency in major stock markets. The Kalman-Filter operates in two stages,\nassuming that the data contains a consistent trendline representing the true\nmarket value prior to being affected by noise. Unlike traditional methods, it\ncan forecast stock price movements effectively. Our findings reveal significant\nportfolio returns in emerging markets such as Korea, Vietnam, and Malaysia, as\nwell as positive returns in developed markets like the UK, Europe, Japan, and\nHong Kong. This suggests that the Kalman-Filter-based price reversal indicator\nyields promising results across various market types.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.16449v1"
    },
    {
        "title": "Assessing the Potential of AI for Spatially Sensitive Nature-Related\n  Financial Risks",
        "authors": [
            "Steven Reece",
            "Emma O'Donnell",
            "Felicia Liu",
            "Joanna Wolstenholme",
            "Frida Arriaga",
            "Giacomo Ascenzi",
            "Richard Pywell"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  There is growing recognition among financial institutions, financial\nregulators and policy makers of the importance of addressing nature-related\nrisks and opportunities. Evaluating and assessing nature-related risks for\nfinancial institutions is challenging due to the large volume of heterogeneous\ndata available on nature and the complexity of investment value chains and the\nvarious components' relationship to nature. The dual problem of scaling data\nanalytics and analysing complex systems can be addressed using Artificial\nIntelligence (AI). We address issues such as plugging existing data gaps with\ndiscovered data, data estimation under uncertainty, time series analysis and\n(near) real-time updates. This report presents potential AI solutions for\nmodels of two distinct use cases, the Brazil Beef Supply Use Case and the Water\nUtility Use Case. Our two use cases cover a broad perspective within\nsustainable finance. The Brazilian cattle farming use case is an example of\ngreening finance - integrating nature-related considerations into mainstream\nfinancial decision-making to transition investments away from sectors with poor\nhistorical track records and unsustainable operations. The deployment of\nnature-based solutions in the UK water utility use case is an example of\nfinancing green - driving investment to nature-positive outcomes. The two use\ncases also cover different sectors, geographies, financial assets and AI\nmodelling techniques, providing an overview on how AI could be applied to\ndifferent challenges relating to nature's integration into finance. This report\nis primarily aimed at financial institutions but is also of interest to ESG\ndata providers, TNFD, systems modellers, and, of course, AI practitioners.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17369v1"
    },
    {
        "title": "Learning parameter dependence for Fourier-based option pricing with\n  tensor trains",
        "authors": [
            "Rihito Sakurai",
            "Haruto Takahashi",
            "Koichi Miyamoto"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  A long-standing issue in mathematical finance is the speed-up of option\npricing, especially for multi-asset options. A recent study has proposed to use\ntensor train learning algorithms to speed up Fourier transform (FT)-based\noption pricing, utilizing the ability of tensor trains to compress\nhigh-dimensional tensors. Another usage of the tensor train is to compress\nfunctions, including their parameter dependence. Here, we propose a pricing\nmethod, where, by a tensor train learning algorithm, we build tensor trains\nthat approximate functions appearing in FT-based option pricing with their\nparameter dependence and efficiently calculate the option price for the varying\ninput parameters. As a benchmark test, we run the proposed method to price a\nmulti-asset option for the various values of volatilities and present asset\nprices. We show that, in the tested cases involving up to 11 assets, the\nproposed method outperforms Monte Carlo-based option pricing with $10^6$ paths\nin terms of computational complexity while keeping better accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.00701v7"
    },
    {
        "title": "Markowitz Meets Bellman: Knowledge-distilled Reinforcement Learning for\n  Portfolio Management",
        "authors": [
            "Gang Hu",
            "Ming Gu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Investment portfolios, central to finance, balance potential returns and\nrisks. This paper introduces a hybrid approach combining Markowitz's portfolio\ntheory with reinforcement learning, utilizing knowledge distillation for\ntraining agents. In particular, our proposed method, called KDD (Knowledge\nDistillation DDPG), consist of two training stages: supervised and\nreinforcement learning stages. The trained agents optimize portfolio assembly.\nA comparative analysis against standard financial models and AI frameworks,\nusing metrics like returns, the Sharpe ratio, and nine evaluation indices,\nreveals our model's superiority. It notably achieves the highest yield and\nSharpe ratio of 2.03, ensuring top profitability with the lowest risk in\ncomparable return scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.05449v1"
    },
    {
        "title": "Can machine learning unlock new insights into high-frequency trading?",
        "authors": [
            "G. Ibikunle",
            "B. Moews",
            "K. Rzayev"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We design and train machine learning models to capture the nonlinear\ninteractions between financial market dynamics and high-frequency trading (HFT)\nactivity. In doing so, we introduce new metrics to identify liquidity-demanding\nand -supplying HFT strategies. Both types of HFT strategies increase activity\nin response to information events and decrease it when trading speed is\nrestricted, with liquidity-supplying strategies demonstrating greater\nresponsiveness. Liquidity-demanding HFT is positively linked with latency\narbitrage opportunities, whereas liquidity-supplying HFT is negatively related,\naligning with theoretical expectations. Our metrics have implications for\nunderstanding the information production process in financial markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.08101v1"
    },
    {
        "title": "NIFTY Financial News Headlines Dataset",
        "authors": [
            "Raeid Saqur",
            "Ken Kato",
            "Nicholas Vinden",
            "Frank Rudzicz"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We introduce and make publicly available the NIFTY Financial News Headlines\ndataset, designed to facilitate and advance research in financial market\nforecasting using large language models (LLMs). This dataset comprises two\ndistinct versions tailored for different modeling approaches: (i) NIFTY-LM,\nwhich targets supervised fine-tuning (SFT) of LLMs with an auto-regressive,\ncausal language-modeling objective, and (ii) NIFTY-RL, formatted specifically\nfor alignment methods (like reinforcement learning from human feedback (RLHF))\nto align LLMs via rejection sampling and reward modeling. Each dataset version\nprovides curated, high-quality data incorporating comprehensive metadata,\nmarket indices, and deduplicated financial news headlines systematically\nfiltered and ranked to suit modern LLM frameworks. We also include experiments\ndemonstrating some applications of the dataset in tasks like stock price\nmovement and the role of LLM embeddings in information acquisition/richness.\nThe NIFTY dataset along with utilities (like truncating prompt's context length\nsystematically) are available on Hugging Face at\nhttps://huggingface.co/datasets/raeidsaqur/NIFTY.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.09747v1"
    },
    {
        "title": "Application of Black-Litterman Bayesian in Statistical Arbitrage",
        "authors": [
            "Qiqin Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  \\begin{abstract} In this paper, we integrated the statistical arbitrage\nstrategy, pairs trading, into the Black-Litterman model and constructed\nefficient mean-variance portfolios. Typically, pairs trading underperforms\nunder volatile or distressed market condition because the selected asset pairs\nfail to revert to equilibrium within the investment horizon. By enhancing this\nstrategy with the Black-Litterman portfolio optimization, we achieved superior\nperformance compared to the S\\&P 500 market index under both normal and extreme\nmarket conditions. Furthermore, this research presents an innovative idea of\nincorporating traditional pairs trading strategies into the portfolio\noptimization framework in a scalable and systematic manner.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.06706v1"
    },
    {
        "title": "$\\text{Alpha}^2$: Discovering Logical Formulaic Alphas using Deep\n  Reinforcement Learning",
        "authors": [
            "Feng Xu",
            "Yan Yin",
            "Xinyu Zhang",
            "Tianyuan Liu",
            "Shengyi Jiang",
            "Zongzhang Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Alphas are pivotal in providing signals for quantitative trading. The\nindustry highly values the discovery of formulaic alphas for their\ninterpretability and ease of analysis, compared with the expressive yet\noverfitting-prone black-box alphas. In this work, we focus on discovering\nformulaic alphas. Prior studies on automatically generating a collection of\nformulaic alphas were mostly based on genetic programming (GP), which is known\nto suffer from the problems of being sensitive to the initial population,\nconverting to local optima, and slow computation speed. Recent efforts\nemploying deep reinforcement learning (DRL) for alpha discovery have not fully\naddressed key practical considerations such as alpha correlations and validity,\nwhich are crucial for their effectiveness. In this work, we propose a novel\nframework for alpha discovery using DRL by formulating the alpha discovery\nprocess as program construction. Our agent, $\\text{Alpha}^2$, assembles an\nalpha program optimized for an evaluation metric. A search algorithm guided by\nDRL navigates through the search space based on value estimates for potential\nalpha outcomes. The evaluation metric encourages both the performance and the\ndiversity of alphas for a better final trading strategy. Our formulation of\nsearching alphas also brings the advantage of pre-calculation dimensional\nanalysis, ensuring the logical soundness of alphas, and pruning the vast search\nspace to a large extent. Empirical experiments on real-world stock markets\ndemonstrates $\\text{Alpha}^2$'s capability to identify a diverse set of logical\nand effective alphas, which significantly improves the performance of the final\ntrading strategy. The code of our method is available at\nhttps://github.com/x35f/alpha2.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.16505v2"
    },
    {
        "title": "AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha\n  Factors",
        "authors": [
            "Hao Shi",
            "Weili Song",
            "Xinting Zhang",
            "Jiahe Shi",
            "Cuicui Luo",
            "Xiang Ao",
            "Hamid Arian",
            "Luis Seco"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The complexity of financial data, characterized by its variability and low\nsignal-to-noise ratio, necessitates advanced methods in quantitative investment\nthat prioritize both performance and interpretability.Transitioning from early\nmanual extraction to genetic programming, the most advanced approach in the\nalpha factor mining domain currently employs reinforcement learning to mine a\nset of combination factors with fixed weights. However, the performance of\nresultant alpha factors exhibits inconsistency, and the inflexibility of fixed\nfactor weights proves insufficient in adapting to the dynamic nature of\nfinancial markets. To address this issue, this paper proposes a two-stage\nformulaic alpha generating framework AlphaForge, for alpha factor mining and\nfactor combination. This framework employs a generative-predictive neural\nnetwork to generate factors, leveraging the robust spatial exploration\ncapabilities inherent in deep learning while concurrently preserving diversity.\nThe combination model within the framework incorporates the temporal\nperformance of factors for selection and dynamically adjusts the weights\nassigned to each component alpha factor. Experiments conducted on real-world\ndatasets demonstrate that our proposed model outperforms contemporary\nbenchmarks in formulaic alpha factor mining. Furthermore, our model exhibits a\nnotable enhancement in portfolio returns within the realm of quantitative\ninvestment and real money investment.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18394v5"
    },
    {
        "title": "Basket Options with Volatility Skew: Calibrating a Local Volatility\n  Model by Sample Rearrangement",
        "authors": [
            "Nicola F. Zaugg",
            "Lech A. Grzelak"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The pricing of derivatives tied to baskets of assets demands a sophisticated\nframework that aligns with the available market information to capture the\nintricate non-linear dependency structure among the assets. We describe the\ndynamics of the multivariate process of constituents with a copula model and\npropose an efficient method to extract the dependency structure from the\nmarket. The proposed method generates coherent sets of samples of the\nconstituents process through systematic sampling rearrangement. These samples\nare then utilized to calibrate a local volatility model (LVM) of the basket\nprocess, which is used to price basket derivatives. We show that the method is\ncapable of efficiently pricing basket options based on a large number of basket\nconstituents, accomplishing the calibration process within a matter of seconds,\nand achieving near-perfect calibration to the index options of the market.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.02901v1"
    },
    {
        "title": "GraphCNNpred: A stock market indices prediction using a Graph based deep\n  learning system",
        "authors": [
            "Yuhui Jin"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The application of deep learning techniques for predicting stock market\nprices is a prominent and widely researched topic in the field of data science.\nTo effectively predict market trends, it is essential to utilize a diversified\ndataset. In this paper, we give a graph neural network based convolutional\nneural network (CNN) model, that can be applied on diverse source of data, in\nthe attempt to extract features to predict the trends of indices of\n\\text{S}\\&\\text{P} 500, NASDAQ, DJI, NYSE, and RUSSEL. The experiments show\nthat the associated models improve the performance of prediction in all indices\nover the baseline algorithms by about $4\\% \\text{ to } 15\\%$, in terms of\nF-measure. A trading simulation is generated from predictions and gained a\nSharpe ratio of over 3.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.03760v2"
    },
    {
        "title": "Attribution Methods in Asset Pricing: Do They Account for Risk?",
        "authors": [
            "Dangxing Chen",
            "Yuan Gao"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Over the past few decades, machine learning models have been extremely\nsuccessful. As a result of axiomatic attribution methods, feature contributions\nhave been explained more clearly and rigorously. There are, however, few\nstudies that have examined domain knowledge in conjunction with the axioms. In\nthis study, we examine asset pricing in finance, a field closely related to\nrisk management. Consequently, when applying machine learning models, we must\nensure that the attribution methods reflect the underlying risks accurately. In\nthis work, we present and study several axioms derived from asset pricing\ndomain knowledge. It is shown that while Shapley value and Integrated Gradients\npreserve most axioms, neither can satisfy all axioms. Using extensive\nanalytical and empirical examples, we demonstrate how attribution methods can\nreflect risks and when they should not be used.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.08953v1"
    },
    {
        "title": "Temporal Representation Learning for Stock Similarities and Its\n  Applications in Investment Management",
        "authors": [
            "Yoontae Hwang",
            "Stefan Zohren",
            "Yongjae Lee"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In the era of rapid globalization and digitalization, accurate identification\nof similar stocks has become increasingly challenging due to the non-stationary\nnature of financial markets and the ambiguity in conventional regional and\nsector classifications. To address these challenges, we examine SimStock, a\nnovel temporal self-supervised learning framework that combines techniques from\nself-supervised learning (SSL) and temporal domain generalization to learn\nrobust and informative representations of financial time series data. The\nprimary focus of our study is to understand the similarities between stocks\nfrom a broader perspective, considering the complex dynamics of the global\nfinancial landscape. We conduct extensive experiments on four real-world\ndatasets with thousands of stocks and demonstrate the effectiveness of SimStock\nin finding similar stocks, outperforming existing methods. The practical\nutility of SimStock is showcased through its application to various investment\nstrategies, such as pairs trading, index tracking, and portfolio optimization,\nwhere it leads to superior performance compared to conventional methods. Our\nfindings empirically examine the potential of data-driven approach to enhance\ninvestment decision-making and risk management practices by leveraging the\npower of temporal self-supervised learning in the face of the ever-changing\nglobal financial landscape.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.13751v1"
    },
    {
        "title": "Is the difference between deep hedging and delta hedging a statistical\n  arbitrage?",
        "authors": [
            "Pascal François",
            "Geneviève Gauthier",
            "Frédéric Godin",
            "Carlos Octavio Pérez Mendoza"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The recent work of Horikawa and Nakagawa (2024) claims that under a complete\nmarket admitting statistical arbitrage, the difference between the hedging\nposition provided by deep hedging and that of the replicating portfolio is a\nstatistical arbitrage. This raises concerns as it entails that deep hedging can\ninclude a speculative component aimed simply at exploiting the structure of the\nrisk measure guiding the hedging optimisation problem. We test whether such\nfinding remains true in a GARCH-based market model, which is an illustrative\ncase departing from complete market dynamics. We observe that the difference\nbetween deep hedging and delta hedging is a speculative overlay if the risk\nmeasure considered does not put sufficient relative weight on adverse outcomes.\nNevertheless, a suitable choice of risk measure can prevent the deep hedging\nagent from engaging in speculation.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14736v3"
    },
    {
        "title": "On Deep Learning for computing the Dynamic Initial Margin and Margin\n  Value Adjustment",
        "authors": [
            "Joel P. Villarino",
            "Álvaro Leitao"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The present work addresses the challenge of training neural networks for\nDynamic Initial Margin (DIM) computation in counterparty credit risk, a task\ntraditionally burdened by the high costs associated with generating training\ndatasets through nested Monte Carlo (MC) simulations. By condensing the initial\nmarket state variables into an input vector, determined through an interest\nrate model and a parsimonious parameterization of the current interest rate\nterm structure, we construct a training dataset where labels are noisy but\nunbiased DIM samples derived from single MC paths. A multi-output neural\nnetwork structure is employed to handle DIM as a time-dependent function,\nfacilitating training across a mesh of monitoring times. The methodology offers\nsignificant advantages: it reduces the dataset generation cost to a single MC\nexecution and parameterizes the neural network by initial market state\nvariables, obviating the need for repeated training. Experimental results\ndemonstrate the approach's convergence properties and robustness across\ndifferent interest rate models (Vasicek and Hull-White) and portfolio\ncomplexities, validating its general applicability and efficiency in more\nrealistic scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16435v1"
    },
    {
        "title": "Multilevel Monte Carlo in Sample Average Approximation: Convergence,\n  Complexity and Application",
        "authors": [
            "Devang Sinha",
            "Siddhartha P. Chakrabarty"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this paper, we examine the Sample Average Approximation (SAA) procedure\nwithin a framework where the Monte Carlo estimator of the expectation is\nbiased. We also introduce Multilevel Monte Carlo (MLMC) in the SAA setup to\nenhance the computational efficiency of solving optimization problems. In this\ncontext, we conduct a thorough analysis, exploiting Cram\\'er's large deviation\ntheory, to establish uniform convergence, quantify the convergence rate, and\ndetermine the sample complexity for both standard Monte Carlo and MLMC\nparadigms. Additionally, we perform a root-mean-squared error analysis\nutilizing tools from empirical process theory to derive sample complexity\nwithout relying on the finite moment condition typically required for uniform\nconvergence results. Finally, we validate our findings and demonstrate the\nadvantages of the MLMC estimator through numerical examples, estimating\nConditional Value-at-Risk (CVaR) in the Geometric Brownian Motion and nested\nexpectation framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.18504v1"
    },
    {
        "title": "Efficient simulation of the SABR model",
        "authors": [
            "Jaehyuk Choi",
            "Lilian Hu",
            "Yue Kuen Kwok"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We propose an efficient and reliable simulation scheme for the\nstochastic-alpha-beta-rho (SABR) model. The two challenges of the SABR\nsimulation lie in sampling (i) the integrated variance conditional on terminal\nvolatility and (ii) the terminal price conditional on terminal volatility and\nintegrated variance. For the first sampling procedure, we analytically derive\nthe first four moments of the conditional average variance, and sample it from\nthe moment-matched shifted lognormal approximation. For the second sampling\nprocedure, we approximate the conditional terminal price as a\nconstant-elasticity-of-variance (CEV) distribution. Our CEV approximation\npreserves the martingale condition and precludes arbitrage, which is a key\nadvantage over Islah's approximation used in most SABR simulation schemes in\nthe literature. Then, we adopt the exact sampling method of the CEV\ndistribution based on the shifted-Poisson-mixture Gamma random variable. Our\nenhanced procedures avoid the tedious Laplace inversion algorithm for sampling\nintegrated variance and non-efficient inverse transform sampling of the forward\nprice in some of the earlier simulation schemes. Numerical results demonstrate\nour simulation scheme to be highly efficient, accurate, and reliable.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01898v1"
    },
    {
        "title": "Stochastic Calculus for Option Pricing with Convex Duality, Logistic\n  Model, and Numerical Examination",
        "authors": [
            "Zheng Cao"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This thesis explores the historical progression and theoretical constructs of\nfinancial mathematics, with an in-depth exploration of Stochastic Calculus as\nshowcased in the Binomial Asset Pricing Model and the Continuous-Time Models. A\ncomprehensive survey of stochastic calculus principles applied to option\npricing is offered, highlighting insights from Peter Carr and Lorenzo\nTorricelli's ``Convex Duality in Continuous Option Pricing Models\". This\nmanuscript adopts techniques such as Monte-Carlo Simulation and machine\nlearning algorithms to examine the propositions of Carr and Torricelli, drawing\ncomparisons between the Logistic and Bachelier models. Additionally, it\nsuggests directions for potential future research on option pricing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.05672v1"
    },
    {
        "title": "Gradient Reduction Convolutional Neural Network Policy for Financial\n  Deep Reinforcement Learning",
        "authors": [
            "Sina Montazeri",
            "Haseebullah Jumakhan",
            "Sonia Abrasiabian",
            "Amir Mirzaeinia"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Building on our prior explorations of convolutional neural networks (CNNs)\nfor financial data processing, this paper introduces two significant\nenhancements to refine our CNN model's predictive performance and robustness\nfor financial tabular data. Firstly, we integrate a normalization layer at the\ninput stage to ensure consistent feature scaling, addressing the issue of\ndisparate feature magnitudes that can skew the learning process. This\nmodification is hypothesized to aid in stabilizing the training dynamics and\nimproving the model's generalization across diverse financial datasets.\nSecondly, we employ a Gradient Reduction Architecture, where earlier layers are\nwider and subsequent layers are progressively narrower. This enhancement is\ndesigned to enable the model to capture more complex and subtle patterns within\nthe data, a crucial factor in accurately predicting financial outcomes. These\nadvancements directly respond to the limitations identified in previous\nstudies, where simpler models struggled with the complexity and variability\ninherent in financial applications. Initial tests confirm that these changes\nimprove accuracy and model stability, suggesting that deeper and more nuanced\nnetwork architectures can significantly benefit financial predictive tasks.\nThis paper details the implementation of these enhancements and evaluates their\nimpact on the model's performance in a controlled experimental setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.11859v1"
    },
    {
        "title": "A deep primal-dual BSDE method for optimal stopping problems",
        "authors": [
            "Jiefei Yang",
            "Guanglian Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We present a new deep primal-dual backward stochastic differential equation\nframework based on stopping time iteration to solve optimal stopping problems.\nA novel loss function is proposed to learn the conditional expectation, which\nconsists of subnetwork parameterization of a continuation value and spatial\ngradients from present up to the stopping time. Notable features of the method\ninclude: (i) The martingale part in the loss function reduces the variance of\nstochastic gradients, which facilitates the training of the neural networks as\nwell as alleviates the error propagation of value function approximation; (ii)\nthis martingale approximates the martingale in the Doob-Meyer decomposition,\nand thus leads to a true upper bound for the optimal value in a non-nested\nMonte Carlo way. We test the proposed method in American option pricing\nproblems, where the spatial gradient network yields the hedging ratio directly.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06937v1"
    },
    {
        "title": "Theoretical and Empirical Validation of Heston Model",
        "authors": [
            "Zheng Cao",
            "Xinhao Lin"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study focuses on the application of the Heston model to option pricing,\nemploying both theoretical derivations and empirical validations. The Heston\nmodel, known for its ability to incorporate stochastic volatility, is derived\nand analyzed to evaluate its effectiveness in pricing options. For practical\napplication, we utilize Monte Carlo simulations alongside market data from the\nCrude Oil WTI market to test the model's accuracy. Machine learning based\noptimization methods are also applied for the estimation of the five Heston\nparameters. By calibrating the model with real-world data, we assess its\nrobustness and relevance in current financial markets, aiming to bridge the gap\nbetween theoretical finance models and their practical implementations.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12453v2"
    },
    {
        "title": "Portfolio Stress Testing and Value at Risk (VaR) Incorporating Current\n  Market Conditions",
        "authors": [
            "Krishan Mohan Nagpal"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Value at Risk (VaR) and stress testing are two of the most widely used\napproaches in portfolio risk management to estimate potential market value\nlosses under adverse market moves. VaR quantifies potential loss in value over\na specified horizon (such as one day or ten days) at a desired confidence level\n(such as 95'th percentile). In scenario design and stress testing, the goal is\nto construct extreme market scenarios such as those involving severe recession\nor a specific event of concern (such as a rapid increase in rates or a\ngeopolitical event), and quantify potential impact of such scenarios on the\nportfolio. The goal of this paper is to propose an approach for incorporating\nprevailing market conditions in stress scenario design and estimation of VaR so\nthat they provide more accurate and realistic insights about portfolio risk\nover the near term. The proposed approach is based on historical data where\nhistorical observations of market changes are given more weight if a certain\nperiod in history is \"more similar\" to the prevailing market conditions.\nClusters of market conditions are identified using a Machine Learning approach\ncalled Variational Inference (VI) where for each cluster future changes in\nportfolio value are similar. VI based algorithm uses optimization techniques to\nobtain analytical approximations of the posterior probability density of\ncluster assignments (market regimes) and probabilities of different outcomes\nfor changes in portfolio value. Covid related volatile period around the year\n2020 is used to illustrate the performance of the proposed approach and in\nparticular show how VaR and stress scenarios adapt quickly to changing market\nconditions. Another advantage of the proposed approach is that classification\nof market conditions into clusters can provide useful insights about portfolio\nperformance under different market conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.18970v1"
    },
    {
        "title": "GARCH-Informed Neural Networks for Volatility Prediction in Financial\n  Markets",
        "authors": [
            "Zeda Xu",
            "John Liechty",
            "Sebastian Benthall",
            "Nicholas Skar-Gislinge",
            "Christopher McComb"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Volatility, which indicates the dispersion of returns, is a crucial measure\nof risk and is hence used extensively for pricing and discriminating between\ndifferent financial investments. As a result, accurate volatility prediction\nreceives extensive attention. The Generalized Autoregressive Conditional\nHeteroscedasticity (GARCH) model and its succeeding variants are well\nestablished models for stock volatility forecasting. More recently, deep\nlearning models have gained popularity in volatility prediction as they\ndemonstrated promising accuracy in certain time series prediction tasks.\nInspired by Physics-Informed Neural Networks (PINN), we constructed a new,\nhybrid Deep Learning model that combines the strengths of GARCH with the\nflexibility of a Long Short-Term Memory (LSTM) Deep Neural Network (DNN), thus\ncapturing and forecasting market volatility more accurately than either class\nof models are capable of on their own. We refer to this novel model as a\nGARCH-Informed Neural Network (GINN). When compared to other time series\nmodels, GINN showed superior out-of-sample prediction performance in terms of\nthe Coefficient of Determination ($R^2$), Mean Squared Error (MSE), and Mean\nAbsolute Error (MAE).\n",
        "pdf_link": "http://arxiv.org/pdf/2410.00288v1"
    },
    {
        "title": "Mamba Meets Financial Markets: A Graph-Mamba Approach for Stock Price\n  Prediction",
        "authors": [
            "Ali Mehrabian",
            "Ehsan Hoseinzade",
            "Mahdi Mazloum",
            "Xiaohong Chen"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Stock markets play an important role in the global economy, where accurate\nstock price predictions can lead to significant financial returns. While\nexisting transformer-based models have outperformed long short-term memory\nnetworks and convolutional neural networks in financial time series prediction,\ntheir high computational complexity and memory requirements limit their\npracticality for real-time trading and long-sequence data processing. To\naddress these challenges, we propose SAMBA, an innovative framework for stock\nreturn prediction that builds on the Mamba architecture and integrates graph\nneural networks. SAMBA achieves near-linear computational complexity by\nutilizing a bidirectional Mamba block to capture long-term dependencies in\nhistorical price data and employing adaptive graph convolution to model\ndependencies between daily stock features. Our experimental results demonstrate\nthat SAMBA significantly outperforms state-of-the-art baseline models in\nprediction accuracy, maintaining low computational complexity. The code and\ndatasets are available at github.com/Ali-Meh619/SAMBA.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.03707v2"
    },
    {
        "title": "Reinforcement Learning in Non-Markov Market-Making",
        "authors": [
            "Luca Lalor",
            "Anatoliy Swishchuk"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We develop a deep reinforcement learning (RL) framework for an optimal\nmarket-making (MM) trading problem, specifically focusing on price processes\nwith semi-Markov and Hawkes Jump-Diffusion dynamics. We begin by discussing the\nbasics of RL and the deep RL framework used, where we deployed the\nstate-of-the-art Soft Actor-Critic (SAC) algorithm for the deep learning part.\nThe SAC algorithm is an off-policy entropy maximization algorithm more suitable\nfor tackling complex, high-dimensional problems with continuous state and\naction spaces like in optimal market-making (MM). We introduce the optimal MM\nproblem considered, where we detail all the deterministic and stochastic\nprocesses that go into setting up an environment for simulating this strategy.\nHere we also give an in-depth overview of the jump-diffusion pricing dynamics\nused, our method for dealing with adverse selection within the limit order\nbook, and we highlight the working parts of our optimization problem. Next, we\ndiscuss training and testing results, where we give visuals of how important\ndeterministic and stochastic processes such as the bid/ask, trade executions,\ninventory, and the reward function evolved. We include a discussion on the\nlimitations of these results, which are important points to note for most\ndiffusion models in this setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.14504v2"
    },
    {
        "title": "Generation of synthetic financial time series by diffusion models",
        "authors": [
            "Tomonori Takahashi",
            "Takayuki Mizuno"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Despite its practical significance, generating realistic synthetic financial\ntime series is challenging due to statistical properties known as stylized\nfacts, such as fat tails, volatility clustering, and seasonality patterns.\nVarious generative models, including generative adversarial networks (GANs) and\nvariational autoencoders (VAEs), have been employed to address this challenge,\nalthough no model yet satisfies all the stylized facts. We alternatively\npropose utilizing diffusion models, specifically denoising diffusion\nprobabilistic models (DDPMs), to generate synthetic financial time series. This\napproach employs wavelet transformation to convert multiple time series (into\nimages), such as stock prices, trading volumes, and spreads. Given these\nconverted images, the model gains the ability to generate images that can be\ntransformed back into realistic time series by inverse wavelet transformation.\nWe demonstrate that our proposed approach satisfies stylized facts.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.18897v1"
    },
    {
        "title": "Extracting Alpha from Financial Analyst Networks",
        "authors": [
            "Dragos Gorduza",
            "Yaxuan Kong",
            "Xiaowen Dong",
            "Stefan Zohren"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We investigate the effectiveness of a momentum trading signal based on the\ncoverage network of financial analysts. This signal builds on the key\ninformation-brokerage role financial sell-side analysts play in modern stock\nmarkets. The baskets of stocks covered by each analyst can be used to construct\na network between firms whose edge weights represent the number of analysts\njointly covering both firms. Although the link between financial analysts\ncoverage and co-movement of firms' stock prices has been investigated in the\nliterature, little effort has been made to systematically learn the most\neffective combination of signals from firms covered jointly by analysts in\norder to benefit from any spillover effect. To fill this gap, we build a\ntrading strategy which leverages the analyst coverage network using a graph\nattention network. More specifically, our model learns to aggregate information\nfrom individual firm features and signals from neighbouring firms in a\nnode-level forecasting task. We develop a portfolio based on those predictions\nwhich we demonstrate to exhibit an annualized returns of 29.44% and a Sharpe\nratio of 4.06 substantially outperforming market baselines and existing graph\nmachine learning based frameworks. We further investigate the performance and\nrobustness of this strategy through extensive empirical analysis. Our paper\nrepresents one of the first attempts in using graph machine learning to extract\nactionable knowledge from the analyst coverage network for practical financial\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.20597v1"
    },
    {
        "title": "Evaluating utility in synthetic banking microdata applications",
        "authors": [
            "Hugo E. Caceres",
            "Ben Moews"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Financial regulators such as central banks collect vast amounts of data, but\naccess to the resulting fine-grained banking microdata is severely restricted\nby banking secrecy laws. Recent developments have resulted in mechanisms that\ngenerate faithful synthetic data, but current evaluation frameworks lack a\nfocus on the specific challenges of banking institutions and microdata. We\ndevelop a framework that considers the utility and privacy requirements of\nregulators, and apply this to financial usage indices, term deposit yield\ncurves, and credit card transition matrices. Using the Central Bank of\nParaguay's data, we provide the first implementation of synthetic banking\nmicrodata using a central bank's collected information, with the resulting\nsynthetic datasets for all three domain applications being publicly available\nand featuring information not yet released in statistical disclosure. We find\nthat applications less susceptible to post-processing information loss, which\nare based on frequency tables, are particularly suited for this approach, and\nthat marginal-based inference mechanisms to outperform generative adversarial\nnetwork models for these applications. Our results demonstrate that synthetic\ndata generation is a promising privacy-enhancing technology for financial\nregulators seeking to complement their statistical disclosure, while\nhighlighting the crucial role of evaluating such endeavors in terms of utility\nand privacy requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.22519v1"
    },
    {
        "title": "Multi-asset and generalised Local Volatility. An efficient\n  implementation",
        "authors": [
            "Olivier Deloire",
            "Louis Roth"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This article presents a generic hybrid numerical method to price a wide range\nof options on one or several assets, as well as assets with stochastic drift or\nvolatility. In particular for equity and interest rate hybrid with local\nvolatility.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05425v1"
    },
    {
        "title": "Quantifying Qualitative Insights: Leveraging LLMs to Market Predict",
        "authors": [
            "Hoyoung Lee",
            "Youngsoo Choi",
            "Yuhee Kwon"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Recent advancements in Large Language Models (LLMs) have the potential to\ntransform financial analytics by integrating numerical and textual data.\nHowever, challenges such as insufficient context when fusing multimodal\ninformation and the difficulty in measuring the utility of qualitative outputs,\nwhich LLMs generate as text, have limited their effectiveness in tasks such as\nfinancial forecasting. This study addresses these challenges by leveraging\ndaily reports from securities firms to create high-quality contextual\ninformation. The reports are segmented into text-based key factors and combined\nwith numerical data, such as price information, to form context sets. By\ndynamically updating few-shot examples based on the query time, the sets\nincorporate the latest information, forming a highly relevant set closely\naligned with the query point. Additionally, a crafted prompt is designed to\nassign scores to the key factors, converting qualitative insights into\nquantitative results. The derived scores undergo a scaling process,\ntransforming them into real-world values that are used for prediction. Our\nexperiments demonstrate that LLMs outperform time-series models in market\nforecasting, though challenges such as imperfect reproducibility and limited\nexplainability remain.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08404v1"
    },
    {
        "title": "Deep Hedging Bermudan Swaptions",
        "authors": [
            "Kenjiro Oya"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Abstract This paper proposes a novel approach to Bermudan swaption hedging by\napplying the deep hedging framework to address limitations of traditional\narbitrage-free methods. Conventional methods assume ideal conditions, such as\nzero transaction costs, perfect liquidity, and continuous-time hedging, which\noften differ from real market environments. This discrepancy can lead to\nresidual profit and loss (P&L), resulting in two primary issues. First,\nresidual P&L may prevent achieving the initial model price, especially with\nimproper parameter settings, potentially causing a negative P&L trend and\nsignificant financial impacts. Second, controlling the distribution of residual\nP&L to mitigate downside risk is challenging, as hedged positions may become\ncurve gamma-short, making them vulnerable to large interest rate movements. The\ndeep hedging approach enables flexible selection of convex risk measures and\nhedge strategies, allowing for improved residual P&L management. This study\nalso addresses challenges in applying the deep hedging approach to Bermudan\nswaptions, such as efficient arbitrage-free market scenario generation and\nmanaging early exercise conditions. Additionally, we introduce a unique \"Option\nSpread Hedge\" strategy, which allows for robust hedging and provides intuitive\ninterpretability. Numerical analysis results demonstrate the effectiveness of\nour approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.10079v1"
    },
    {
        "title": "IVE: Enhanced Probabilistic Forecasting of Intraday Volume Ratio with\n  Transformers",
        "authors": [
            "Hanwool Lee",
            "Heehwan Park"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper presents a new approach to volume ratio prediction in financial\nmarkets, specifically targeting the execution of Volume-Weighted Average Price\n(VWAP) strategies. Recognizing the importance of accurate volume profile\nforecasting, our research leverages the Transformer architecture to predict\nintraday volume ratio at a one-minute scale. We diverge from prior models that\nuse log-transformed volume or turnover rates, instead opting for a prediction\nmodel that accounts for the intraday volume ratio's high variability,\nstabilized via log-normal transformation. Our input data incorporates not only\nthe statistical properties of volume but also external volume-related features,\nabsolute time information, and stock-specific characteristics to enhance\nprediction accuracy. The model structure includes an encoder-decoder\nTransformer architecture with a distribution head for greedy sampling,\noptimizing performance on high-liquidity stocks across both Korean and American\nmarkets. We extend the capabilities of our model beyond point prediction by\nintroducing probabilistic forecasting that captures the mean and standard\ndeviation of volume ratios, enabling the anticipation of significant intraday\nvolume spikes. Furthermore, an agent with a simple trading logic demonstrates\nthe practical application of our model through live trading tests in the Korean\nmarket, outperforming VWAP benchmarks over a period of two and a half months.\nOur findings underscore the potential of Transformer-based probabilistic models\nfor volume ratio prediction and pave the way for future research advancements\nin this domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.10956v1"
    },
    {
        "title": "Do Activists Align with Larger Mutual Funds?",
        "authors": [
            "Manish Jha"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper demonstrates that hedge funds tend to design their activist\ncampaigns to align with the preferences and ideologies of institutions holding\nlarge stakes in the target company. I estimate these preferences by analyzing\nthe institutions' previous proxy voting behavior. The results reveal that\nactivists benefit from this approach. Campaigns with a stronger positive\ncorrelation between the preferences of larger institutions and activist\ncommunications attract more shareholder attention, receive more votes, and are\nmore likely to succeed.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.16553v1"
    },
    {
        "title": "GRU-PFG: Extract Inter-Stock Correlation from Stock Factors with Graph\n  Neural Network",
        "authors": [
            "Yonggai Zhuang",
            "Haoran Chen",
            "Kequan Wang",
            "Teng Fei"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The complexity of stocks and industries presents challenges for stock\nprediction. Currently, stock prediction models can be divided into two\ncategories. One category, represented by GRU and ALSTM, relies solely on stock\nfactors for prediction, with limited effectiveness. The other category,\nrepresented by HIST and TRA, incorporates not only stock factors but also\nindustry information, industry financial reports, public sentiment, and other\ninputs for prediction. The second category of models can capture correlations\nbetween stocks by introducing additional information, but the extra data is\ndifficult to standardize and generalize. Considering the current state and\nlimitations of these two types of models, this paper proposes the GRU-PFG\n(Project Factors into Graph) model. This model only takes stock factors as\ninput and extracts inter-stock correlations using graph neural networks. It\nachieves prediction results that not only outperform the others models relies\nsolely on stock factors, but also achieve comparable performance to the second\ncategory models. The experimental results show that on the CSI300 dataset, the\nIC of GRU-PFG is 0.134, outperforming HIST's 0.131 and significantly surpassing\nGRU and Transformer, achieving results better than the second category models.\nMoreover as a model that relies solely on stock factors, it has greater\npotential for generalization.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.18997v1"
    },
    {
        "title": "Smart leverage? Rethinking the role of Leveraged Exchange Traded Funds\n  in constructing portfolios to beat a benchmark",
        "authors": [
            "Pieter van Staden",
            "Peter Forsyth",
            "Yuying Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Leveraged Exchange Traded Funds (LETFs), while extremely controversial in the\nliterature, remain stubbornly popular with both institutional and retail\ninvestors in practice. While the criticisms of LETFs are certainly valid, we\nargue that their potential has been underestimated in the literature due to the\nuse of very simple investment strategies involving LETFs. In this paper, we\nsystematically investigate the potential of including a broad stock market\nindex LETF in long-term, dynamically-optimal investment strategies designed to\nmaximize the outperformance over standard investment benchmarks in the sense of\nthe information ratio (IR). Our results exploit the observation that positions\nin a LETF deliver call-like payoffs, so that the addition of a LETF to a\nportfolio can be a convenient way to add inexpensive leverage while providing\ndownside protection. Under stylized assumptions, we present and analyze\nclosed-form IR-optimal investment strategies using either a LETF or\nstandard/vanilla ETF (VETF) on the same equity index, which provides the\nnecessary intuition for the potential and benefits of LETFs. In more realistic\nsettings, we use a neural network-based approach to determine the IR-optimal\nstrategies, trained on bootstrapped historical data. We find that IR-optimal\nstrategies with a broad stock market LETF are not only more likely to\noutperform the benchmark than IR-optimal strategies derived using the\ncorresponding VETF, but are able to achieve partial stochastic dominance over\nthe benchmark and VETF-based strategies in terms of terminal wealth.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.05431v1"
    },
    {
        "title": "Hype-Adjusted Probability Measure for NLP Stock Return Forecasting",
        "authors": [
            "Zheng Cao",
            "Helyette Geman"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This manuscript introduces the Hype-Adjusted Probability Measure developed in\nthe context of a new Natural Language Processing (NLP) approach for stock\nreturn and volatility forecasting. A novel sentiment score equation is\npresented to capture component and memory effects and assign dynamic\nparameters, enhancing the impact of intraday news data on forecasting\nnext-period volatility for selected U.S. semiconductor tickers. This approach\nintegrates machine learning techniques to analyze and improve the predictive\nvalue of news. Building on the research of Geman et al [6], this work improves\nforecast accuracy by addressing news bias, memory, and weight, and\nincorporating shifts in senti-ment direction. Finally, we propose the\nHype-Adjusted Probability Measure, proving its existence and uniqueness, and\ndiscuss its theoretical applications in finance for NLP-based stock return\nforecasting, outlining future research pathways inspired by its concepts.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.07587v2"
    },
    {
        "title": "High-dimensional covariance matrix estimators on simulated portfolios\n  with complex structures",
        "authors": [
            "Andrés García-Medina"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We study the allocation of synthetic portfolios under hierarchical nested,\none-factor, and diagonal structures of the population covariance matrix in a\nhigh-dimensional scenario. The noise reduction approaches for the sample\nrealizations are based on random matrices, free probability, deterministic\nequivalents, and their combination with a data science hierarchical method\nknown as two-step covariance estimators. The financial performance metrics from\nthe simulations are compared with empirical data from companies comprising the\nS&P 500 index using a moving window and walk-forward analysis. The portfolio\nallocation strategies analyzed include the minimum variance portfolio (both\nwith and without short-selling constraints) and the hierarchical risk parity\napproach. Our proposed hierarchical nested covariance model shows signatures of\ncomplex system interactions. The empirical financial data reproduces stylized\nportfolio facts observed in the complex and one-factor covariance models. The\ntwo-step estimators proposed here improve several financial metrics under the\nanalyzed investment strategies. The results pave the way for new risk\nmanagement and diversification approaches when the number of assets is of the\nsame order as the number of transaction days in the investment portfolio.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.08756v1"
    },
    {
        "title": "Financial Fine-tuning a Large Time Series Model",
        "authors": [
            "Xinghong Fu",
            "Masanori Hirano",
            "Kentaro Imajo"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Large models have shown unprecedented capabilities in natural language\nprocessing, image generation, and most recently, time series forecasting. This\nleads us to ask the question: treating market prices as a time series, can\nlarge models be used to predict the market? In this paper, we answer this by\nevaluating the performance of the latest time series foundation model TimesFM\non price prediction. We find that due to the irregular nature of price data,\ndirectly applying TimesFM gives unsatisfactory results and propose to fine-tune\nTimeFM on financial data for the task of price prediction. This is done by\ncontinual pre-training of the latest time series foundation model TimesFM on\nprice data containing 100 million time points, spanning a range of financial\ninstruments spanning hourly and daily granularities. The fine-tuned model\ndemonstrates higher price prediction accuracy than the baseline model. We\nconduct mock trading for our model in various financial markets and show that\nit outperforms various benchmarks in terms of returns, sharpe ratio, max\ndrawdown and trading cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.09880v1"
    },
    {
        "title": "From Votes to Volatility Predicting the Stock Market on Election Day",
        "authors": [
            "Igor L. R. Azevedo",
            "Toyotaro Suzumura"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Stock market forecasting has been a topic of extensive research, aiming to\nprovide investors with optimal stock recommendations for higher returns. In\nrecent years, this field has gained even more attention due to the widespread\nadoption of deep learning models. While these models have achieved impressive\naccuracy in predicting stock behavior, tailoring them to specific scenarios has\nbecome increasingly important. Election Day represents one such critical\nscenario, characterized by intensified market volatility, as the winning\ncandidate's policies significantly impact various economic sectors and\ncompanies. To address this challenge, we propose the Election Day Stock Market\nForecasting (EDSMF) Model. Our approach leverages the contextual capabilities\nof large language models alongside specialized agents designed to analyze the\npolitical and economic consequences of elections. By building on a\nstate-of-the-art architecture, we demonstrate that EDSMF improves the\npredictive performance of the S&P 500 during this uniquely volatile day.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.11192v1"
    },
    {
        "title": "Enhanced Momentum with Momentum Transformers",
        "authors": [
            "Max Mason",
            "Waasi A Jagirdar",
            "David Huang",
            "Rahul Murugan"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The primary objective of this research is to build a Momentum Transformer\nthat is expected to outperform benchmark time-series momentum and\nmean-reversion trading strategies. We extend the ideas introduced in the paper\nTrading with the Momentum Transformer: An Intelligent and Interpretable\nArchitecture to equities as the original paper primarily only builds upon\nfutures and equity indices. Unlike conventional Long Short-Term Memory (LSTM)\nmodels, which operate sequentially and are optimized for processing local\npatterns, an attention mechanism equips our architecture with direct access to\nall prior time steps in the training window. This hybrid design, combining\nattention with an LSTM, enables the model to capture long-term dependencies,\nenhance performance in scenarios accounting for transaction costs, and\nseamlessly adapt to evolving market conditions, such as those witnessed during\nthe Covid Pandemic. We average 4.14% returns which is similar to the original\npapers results. Our Sharpe is lower at an average of 1.12 due to much higher\nvolatility which may be due to stocks being inherently more volatile than\nfutures and indices.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12516v1"
    },
    {
        "title": "Leveraging Generative Adversarial Networks for Addressing Data Imbalance\n  in Financial Market Supervision",
        "authors": [
            "Mohan Jiang",
            "Yaxin Liang",
            "Siyuan Han",
            "Kunyuan Ma",
            "Yuan Chen",
            "Zhen Xu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study explores the application of generative adversarial networks in\nfinancial market supervision, especially for solving the problem of data\nimbalance to improve the accuracy of risk prediction. Since financial market\ndata are often imbalanced, especially high-risk events such as market\nmanipulation and systemic risk occur less frequently, traditional models have\ndifficulty effectively identifying these minority events. This study proposes\nto generate synthetic data with similar characteristics to these minority\nevents through GAN to balance the dataset, thereby improving the prediction\nperformance of the model in financial supervision. Experimental results show\nthat compared with traditional oversampling and undersampling methods, the data\ngenerated by GAN has significant advantages in dealing with imbalance problems\nand improving the prediction accuracy of the model. This method has broad\napplication potential in financial regulatory agencies such as the U.S.\nSecurities and Exchange Commission (SEC), the Financial Industry Regulatory\nAuthority (FINRA), the Federal Deposit Insurance Corporation (FDIC), and the\nFederal Reserve.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15222v1"
    },
    {
        "title": "Assessing the Impact of Technical Indicators on Machine Learning Models\n  for Stock Price Prediction",
        "authors": [
            "Akash Deep",
            "Chris Monico",
            "Abootaleb Shirvani",
            "Svetlozar Rachev",
            "Frank J. Fabozzi"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study evaluates the performance of random forest regression models\nenhanced with technical indicators for high-frequency stock price prediction.\nUsing minute-level SPY data, we assessed 13 models that incorporate technical\nindicators such as Bollinger bands, exponential moving average, and Fibonacci\nretracement. While these models improved risk-adjusted performance metrics,\nthey struggled with out-of-sample generalization, highlighting significant\noverfitting challenges. Feature importance analysis revealed that primary\nprice-based features consistently outperformed technical indicators, suggesting\ntheir limited utility in high-frequency trading contexts. These findings\nchallenge the weak form of the efficient market hypothesis, identifying\nshort-lived inefficiencies during volatile periods but its limited persistence\nacross market regimes. The study emphasizes the need for selective feature\nengineering, adaptive modeling, and a stronger focus on risk-adjusted\nperformance metrics to navigate the complexities of high-frequency trading\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15448v1"
    },
    {
        "title": "Generalized Mean Absolute Directional Loss as a Solution to Overfitting\n  and High Transaction Costs in Machine Learning Models Used in High-Frequency\n  Algorithmic Investment Strategies",
        "authors": [
            "Jakub Michańków",
            "Paweł Sakowski",
            "Robert Ślepaczuk"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Regardless of the selected asset class and the level of model complexity\n(Transformer versus LSTM versus Perceptron/RNN), the GMADL loss function\nproduces superior results than standard MSE-type loss functions and has better\nnumerical properties in the context of optimization than MADL. Better results\nmean the possibility of achieving a higher risk-weighted return based on buy\nand sell signals built on forecasts generated by a given theoretical model\nestimated using the GMADL versus MSE or MADL function. In practice, GMADL\nsolves the problem of selecting the most preferable feature in both\nclassification and regression problems, improving the performance of each\nestimation. What is important is that, through additional parameterization,\nGMADL also solves the problem of optimizing investment systems on\nhigh-frequency data in such a way that they focus on strategy variants that\ncontain fewer transactions so that transaction costs do not reduce the\neffectiveness of a given strategy to zero. Moreover, the implementation\nleverages state-of-the-art machine learning tools, including frameworks for\nhyperparameter tuning, architecture testing, and walk-forward optimization,\nensuring robust and scalable solutions for real-world algorithmic trading.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18405v1"
    },
    {
        "title": "Improving DeFi Accessibility through Efficient Liquidity Provisioning\n  with Deep Reinforcement Learning",
        "authors": [
            "Haonan Xu",
            "Alessio Brini"
        ],
        "category": "q-fin.CP",
        "published_year": "2025",
        "summary": "  This paper applies deep reinforcement learning (DRL) to optimize liquidity\nprovisioning in Uniswap v3, a decentralized finance (DeFi) protocol\nimplementing an automated market maker (AMM) model with concentrated liquidity.\nWe model the liquidity provision task as a Markov Decision Process (MDP) and\ntrain an active liquidity provider (LP) agent using the Proximal Policy\nOptimization (PPO) algorithm. The agent dynamically adjusts liquidity positions\nby using information about price dynamics to balance fee maximization and\nimpermanent loss mitigation. We use a rolling window approach for training and\ntesting, reflecting realistic market conditions and regime shifts. This study\ncompares the data-driven performance of the DRL-based strategy against common\nheuristics adopted by small retail LP actors that do not systematically modify\ntheir liquidity positions. By promoting more efficient liquidity management,\nthis work aims to make DeFi markets more accessible and inclusive for a broader\nrange of participants. Through a data-driven approach to liquidity management,\nthis work seeks to contribute to the ongoing development of more efficient and\nuser-friendly DeFi markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.07508v1"
    },
    {
        "title": "Fine-tune your smile: Correction to Hagan et al",
        "authors": [
            "Jan Obloj"
        ],
        "category": "q-fin.CP",
        "published_year": "2007",
        "summary": "  In this small note we use results derived in Berestycki et al. to correct the\ncelebrated formulae of Hagan et al. We derive explicitly the correct zero order\nterm in the expansion of the implied volatility in time to maturity. The new\nterm is consistent as $\\beta\\to 1$. Furthermore, numerical simulations show\nthat it reduces or eliminates known pathologies of the earlier formula.\n",
        "pdf_link": "http://arxiv.org/pdf/0708.0998v3"
    },
    {
        "title": "Finite-time singularity in the evolution of hyperinflation episodes",
        "authors": [
            "Martin A. Szybisz",
            "Leszek Szybisz"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  A model proposed by Sornette, Takayasu, and Zhou for describing\nhyperinflation regimes based on adaptive expectations expressed in terms of a\npower law which leads to a finite-time singularity is revisited. It is\nsuggested to express the price index evolution explicitly in terms of the\nparameters introduced along the theoretical formulation avoiding any\ncombination of them used in the original work. This procedure allows to study\nunambiguously the uncertainties of such parameters when an error is assigned to\nthe measurement of the price index. In this way, it is possible to determine an\nuncertainty in the critical time at which the singularity occurs. For this\npurpose, Monte Carlo simulation techniques are applied. The hyperinflation\nepisodes of Peru (1969-90) and Weimar Germany (1920-3) are reexamined. The\nfirst analyses performed within this framework of the very extreme\nhyper-inflations occurred in Greece (1941-4) and Yugoslavia (1991-4) are\nreported. The study of the hyperinflation spiral experienced just nowadays in\nZimbabwe predicts a singularity, i.e., a complete economic crash within two\nyears.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3553v1"
    },
    {
        "title": "Nonlinear Fokker-Planck Equation in the Model of Asset Returns",
        "authors": [
            "Alexander Shapovalov",
            "Andrey Trifonov",
            "Elena Masalova"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  The Fokker-Planck equation with diffusion coefficient quadratic in space\nvariable, linear drift coefficient, and nonlocal nonlinearity term is\nconsidered in the framework of a model of analysis of asset returns at\nfinancial markets. For special cases of such a Fokker-Planck equation we\ndescribe a construction of exact solution of the Cauchy problem. In the general\ncase, we construct the leading term of the Cauchy problem solution asymptotic\nin a formal small parameter in semiclassical approximation following the\ncomplex WKB-Maslov method in the class of trajectory concentrated functions.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.0900v1"
    },
    {
        "title": "Probability distribution of returns in the exponential\n  Ornstein-Uhlenbeck model",
        "authors": [
            "Giacomo Bormetti",
            "Valentina Cazzola",
            "Guido Montagna",
            "Oreste Nicrosini"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  We analyze the problem of the analytical characterization of the probability\ndistribution of financial returns in the exponential Ornstein-Uhlenbeck model\nwith stochastic volatility. In this model the prices are driven by a Geometric\nBrownian motion, whose diffusion coefficient is expressed through an\nexponential function of an hidden variable Y governed by a mean-reverting\nprocess. We derive closed-form expressions for the probability distribution and\nits characteristic function in two limit cases. In the first one the\nfluctuations of Y are larger than the volatility normal level, while the second\none corresponds to the assumption of a small stationary value for the variance\nof Y. Theoretical results are tested numerically by intensive use of Monte\nCarlo simulations. The effectiveness of the analytical predictions is checked\nvia a careful analysis of the parameters involved in the numerical\nimplementation of the Euler-Maruyama scheme and is tested on a data set of\nfinancial indexes. In particular, we discuss results for the German DAX30 and\nDow Jones Euro Stoxx 50, finding a good agreement between the empirical data\nand the theoretical description.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0540v2"
    },
    {
        "title": "Transformation methods for evaluating approximations to the optimal\n  exercise boundary for linear and nonlinear Black-Scholes equations",
        "authors": [
            "Daniel Sevcovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  The purpose of this survey chapter is to present a transformation technique\nthat can be used in analysis and numerical computation of the early exercise\nboundary for an American style of vanilla options that can be modelled by class\nof generalized Black-Scholes equations. We analyze qualitatively and\nquantitatively the early exercise boundary for a linear as well as a class of\nnonlinear Black-Scholes equations with a volatility coefficient which can be a\nnonlinear function of the second derivative of the option price itself. A\nmotivation for studying the nonlinear Black-Scholes equation with a nonlinear\nvolatility arises from option pricing models taking into account e.g.\nnontrivial transaction costs, investor's preferences, feedback and illiquid\nmarkets effects and risk from a volatile (unprotected) portfolio. We present a\nmethod how to transform the free boundary problem for the early exercise\nboundary position into a solution of a time depending nonlinear nonlocal\nparabolic equation defined on a fixed domain. We furthermore propose an\niterative numerical scheme that can be used in order to find an approximation\nof the free boundary. In the case of a linear Black-Scholes equation we are\nable to derive a nonlinear integral equation for the position of the free\nboundary. We present results of numerical approximation of the early exercise\nboundary for various types of linear and nonlinear Black-Scholes equations and\nwe discuss dependence of the free boundary on model parameters. Finally, we\ndiscuss an application of the transformation method for the pricing equation\nfor American type of Asian options.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0611v1"
    },
    {
        "title": "Some Control Variates for exotic options",
        "authors": [
            "JC Ndogmo"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  There are no known exact formulas for the valuation of a number of exotic\noptions, and this is particularly true for options under discrete monitoring\nand for American style options. Therefore, one usually recourses to a Monte\nCarlo Simulation approach, amongst other numerical methods, to estimate the\nvalue of these options. The problem which then arises with this method is one\nof variance reduction. Control variates are often used, and we present some\nresults concerning these control variables, for the valuation of Asian and\nlookback options. An inequality on functions of correlations useful for\ncomparing estimators in variance reduction procedures is also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.4675v1"
    },
    {
        "title": "Monte Carlo Greeks for financial products via approximative transition\n  densities",
        "authors": [
            "Joerg Kampen",
            "Anastasia Kolodko",
            "John Schoenmakers"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In this paper we introduce efficient Monte Carlo estimators for the valuation\nof high-dimensional derivatives and their sensitivities (''Greeks''). These\nestimators are based on an analytical, usually approximative representation of\nthe underlying density. We study approximative densities obtained by the WKB\nmethod. The results are applied in the context of a Libor market model.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1213v1"
    },
    {
        "title": "On the Esscher transforms and other equivalent martingale measures for\n  Barndorff-Nielsen and Shephard stochastic volatility models with jumps",
        "authors": [
            "Friedrich Hubalek",
            "Carlo Sgarra"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  We compute and discuss the Esscher martingale transform for exponential\nprocesses, the Esscher martingale transform for linear processes, the minimal\nmartingale measure, the class of structure preserving martingale measures, and\nthe minimum entropy martingale measure for stochastic volatility models of\nOrnstein-Uhlenbeck type as introduced by Barndorff-Nielsen and Shephard. We\nshow, that in the model with leverage, with jumps both in the volatility and in\nthe returns, all those measures are different, whereas in the model without\nleverage, with jumps in the volatility only and a continuous return process,\nseveral measures coincide, some simplifications can be made and the results are\nmore explicit. We illustrate our results with parametric examples used in the\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1227v1"
    },
    {
        "title": "A dual characterization of self-generation and exponential forward\n  performances",
        "authors": [
            "Gordan Žitković"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  We propose a mathematical framework for the study of a family of random\nfields--called forward performances--which arise as numerical representation of\ncertain rational preference relations in mathematical finance. Their spatial\nstructure corresponds to that of utility functions, while the temporal one\nreflects a Nisio-type semigroup property, referred to as self-generation. In\nthe setting of semimartingale financial markets, we provide a dual formulation\nof self-generation in addition to the original one, and show equivalence\nbetween the two, thus giving a dual characterization of forward performances.\nThen we focus on random fields with an exponential structure and provide\nnecessary and sufficient conditions for self-generation in that case. Finally,\nwe illustrate our methods in financial markets driven by It\\^o-processes, where\nwe obtain an explicit parametrization of all exponential forward performances.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.0739v4"
    },
    {
        "title": "Graphical models for correlated defaults",
        "authors": [
            "I. Onur Filiz",
            "Xin Guo",
            "Jason Morton",
            "Bernd Sturmfels"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  A simple graphical model for correlated defaults is proposed, with explicit\nformulas for the loss distribution. Algebraic geometry techniques are employed\nto show that this model is well posed for default dependence: it represents any\ngiven marginal distribution for single firms and pairwise correlation matrix.\nThese techniques also provide a calibration algorithm based on maximum\nlikelihood estimation. Finally, the model is compared with standard normal\ncopula model in terms of tails of the loss distribution and implied correlation\nsmile.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.1393v1"
    },
    {
        "title": "On contingent claims pricing in incomplete markets: A risk sharing\n  approach",
        "authors": [
            "Michail Anthropelos",
            "Nikolaos E. Frangos",
            "Stylianos Z. Xanthopoulos",
            "Athanasios N. Yannacopoulos"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  In an incomplete market setting, we consider two financial agents, who wish\nto price and trade a non-replicable contingent claim. Assuming that the agents\nare utility maximizers, we propose a transaction price which is a result of the\nminimization of a convex combination of their utility differences. We call this\nprice the risk sharing price, we prove its existence for a large family of\nutility functions and we state some of its properties. As an example, we\nanalyze extensively the case where both agents report exponential utility.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.4781v3"
    },
    {
        "title": "Hedging of Defaultable Contingent Claims using BSDE with uncertain time\n  horizon",
        "authors": [
            "Christophette Blanchet-Scalliet",
            "Anne Eyraud-Loisel",
            "Manuela Royer-Carenzi"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  This article focuses on the mathematical problem of existence and uniqueness\nof BSDE with a random terminal time which is a general random variable but not\na stopping time, as it has been usually the case in the previous literature of\nBSDE with random terminal time. The main motivation of this work is a financial\nor actuarial problem of hedging of defaultable contingent claims or life\ninsurance contracts, for which the terminal time is a default time or a death\ntime, which are not stopping times. We have to use progressive enlargement of\nthe Brownian filtration, and to solve the obtained BSDE under this enlarged\nfiltration. This work gives a solution to the mathematical problem and proves\nthe existence and uniqueness of solutions of such BSDE under certain general\nconditions. This approach is applied to the financial problem of hedging of\ndefaultable contingent claims, and an expression of the hedging strategy is\ngiven for a defaultable contingent claim or a life insurance contract.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.4039v2"
    },
    {
        "title": "Utility maximization in incomplete markets with default",
        "authors": [
            "Thomas Lim",
            "Marie-Claire Quenez"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  We adress the maximization problem of expected utility from terminal wealth.\nThe special feature of this paper is that we consider a financial market where\nthe price process of risky assets can have a default time. Using dynamic\nprogramming, we characterize the value function with a backward stochastic\ndifferential equation and the optimal portfolio policies. We separately treat\nthe cases of exponential, power and logarithmic utility.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.4715v3"
    },
    {
        "title": "Computation of VaR and CVaR using stochastic approximations and\n  unconstrained importance sampling",
        "authors": [
            "Olivier Aj Bardou",
            "Noufel Frikha",
            "G. Pagès"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR) are two risk\nmeasures which are widely used in the practice of risk management. This paper\ndeals with the problem of computing both VaR and CVaR using stochastic\napproximation (with decreasing steps): we propose a first Robbins-Monro\nprocedure based on Rockaffelar-Uryasev's identity for the CVaR. The convergence\nrate of this algorithm to its target satisfies a Gaussian Central Limit\nTheorem. As a second step, in order to speed up the initial procedure, we\npropose a recursive importance sampling (I.S.) procedure which induces a\nsignificant variance reduction of both VaR and CVaR procedures. This idea,\nwhich goes back to the seminal paper of B. Arouna, follows a new approach\nintroduced by V. Lemaire and G. Pag\\`es. Finally, we consider a deterministic\nmoving risk level to speed up the initialization phase of the algorithm. We\nprove that the convergence rate of the resulting procedure is ruled by a\nCentral Limit Theorem with minimal variance and its efficiency is illustrated\nby considering several typical energy portfolios.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.3381v5"
    },
    {
        "title": "An Adaptive Markov Chain Monte Carlo Method for GARCH Model",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We propose a method to construct a proposal density for the\nMetropolis-Hastings algorithm in Markov Chain Monte Carlo (MCMC) simulations of\nthe GARCH model. The proposal density is constructed adaptively by using the\ndata sampled by the MCMC metho d itself. It turns out that autocorrelations\nbetween the data generated with our adaptive proposal density are greatly\nreduced. Thus it is concluded that the adaptive construction method is very\nefficient and works well for the MCMC simulations of the GARCH model.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.0992v1"
    },
    {
        "title": "Laplace transformation method for the Black-Scholes equation",
        "authors": [
            "Hyoseop Lee",
            "Dongwoo Sheen"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  In this paper we apply the innovative Laplace transformation method\nintroduced by Sheen, Sloan, and Thom\\'ee (IMA J. Numer. Anal., 2003) to solve\nthe Black-Scholes equation. The algorithm is of arbitrary high convergence rate\nand naturally parallelizable. It is shown that the method is very efficient for\ncalculating various options. Existence and uniqueness properties of the Laplace\ntransformed Black-Scholes equation are analyzed. Also a transparent boundary\ncondition associated with the Laplace transformation method is proposed.\nSeveral numerical results for various options under various situations confirm\nthe efficiency, convergence and parallelization property of the proposed\nscheme.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.4604v2"
    },
    {
        "title": "Existence & Regularity of Weak Solutions of Degenerate Parabolic PDE\n  Models for the Pricing of Security Derivatives",
        "authors": [
            "Rasoul Behboudi",
            "You-Lan Zhu"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  This work is focused on the solvability of initial-boundary value problems\nfor degenerate parabolic partial differential equations that arise in the\npricing of Asian options, and on the investigation of differential and certain\nqualitative properties of solutions of such equations. The generalized\nsolvability for such models with degeneracy at the boundaries is proven by\nemploying solutions obtained from finite difference numerical schemes.\nFurthermore, the regularity of such solutions is studied.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.1721v2"
    },
    {
        "title": "Quantum Neural Computation for Option Price Modelling",
        "authors": [
            "Vladimir G. Ivancevic"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We propose a new cognitive framework for option price modelling, using\nquantum neural computation formalism. Briefly, when we apply a classical\nnonlinear neural-network learning to a linear quantum Schr\\\"odinger equation,\nas a result we get a nonlinear Schr\\\"odinger equation (NLS), performing as a\nquantum stochastic filter. In this paper, we present a bidirectional quantum\nassociative memory model for the Black--Scholes--like option price evolution,\nconsisting of a pair of coupled NLS equations, one governing the stochastic\nvolatility and the other governing the option price, both self-organizing in an\nadaptive `market heat potential', trained by continuous Hebbian learning. This\nstiff pair of NLS equations is numerically solved using the method of lines\nwith adaptive step-size integrator.\n  Keywords: Option price modelling, Quantum neural computation, nonlinear\nSchr\\\"odinger equations, leverage effect, bidirectional associative memory\n",
        "pdf_link": "http://arxiv.org/pdf/0903.0680v3"
    },
    {
        "title": "Optimisation of Stochastic Programming by Hidden Markov Modelling based\n  Scenario Generation",
        "authors": [
            "Sovan Mitra"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  This paper formed part of a preliminary research report for a risk\nconsultancy and academic research. Stochastic Programming models provide a\npowerful paradigm for decision making under uncertainty. In these models the\nuncertainties are represented by a discrete scenario tree and the quality of\nthe solutions obtained is governed by the quality of the scenarios generated.\nWe propose a new technique to generate scenarios based on Gaussian Mixture\nHidden Markov Modelling. We show that our approach explicitly captures\nimportant time varying dynamics of stochastic processes (such as autoregression\nand jumps) as well as non-Gaussian distribution characteristics (such as\nskewness and kurtosis). Our scenario generation method enables richer\nrobustness and scenario analysis through exploiting the tractable properties of\nMarkov models and Gaussian mixture distributions. We demonstrate the benefits\nof our scenario generation method by conducting numerical experiments on\nFTSE-100 data.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.1131v1"
    },
    {
        "title": "An application to credit risk of a hybrid Monte Carlo-Optimal\n  quantization method",
        "authors": [
            "Giorgia Callegaro",
            "Abass Sagna"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  In this paper we use a hybrid Monte Carlo-Optimal quantization method to\napproximate the conditional survival probabilities of a firm, given a\nstructural model for its credit defaul, under partial information. We consider\nthe case when the firm's value is a non-observable stochastic process $(V_t)_{t\n\\geq 0}$ and inverstors in the market have access to a process $(S_t)_{t \\geq\n0}$, whose value at each time t is related to $(V_s, s \\leq t)$. We are\ninterested in the computation of the conditional survival probabilities of the\nfirm given the \"investor information\". As a application, we analyse the shape\nof the credit spread curve for zero coupon bonds in two examples.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.0645v1"
    },
    {
        "title": "Bayesian Inference on QGARCH Model Using the Adaptive Construction\n  Scheme",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We study the performance of the adaptive construction scheme for a Bayesian\ninference on the Quadratic GARCH model which introduces the asymmetry in time\nseries dynamics. In the adaptive construction scheme a proposal density in the\nMetropolis-Hastings algorithm is constructed adaptively by changing the\nparameters of the density to fit the posterior density. Using artificial QGARCH\ndata we infer the QGARCH parameters by applying the adaptive construction\nscheme to the Bayesian inference of QGARCH model. We find that the adaptive\nconstruction scheme samples QGARCH parameters effectively, i.e. correlations\nbetween the sampled data are very small. We conclude that the adaptive\nconstruction scheme is an efficient method to the Bayesian estimation of the\nQGARCH model.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.5276v1"
    },
    {
        "title": "State price density estimation via nonparametric mixtures",
        "authors": [
            "Ming Yuan"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We consider nonparametric estimation of the state price density encapsulated\nin option prices. Unlike usual density estimation problems, we only observe\noption prices and their corresponding strike prices rather than samples from\nthe state price density. We propose to model the state price density directly\nwith a nonparametric mixture and estimate it using least squares. We show that\nalthough the minimization is taken over an infinitely dimensional function\nspace, the minimizer always admits a finite dimensional representation and can\nbe computed efficiently. We also prove that the proposed estimate of the state\nprice density function converges to the truth at a ``nearly parametric'' rate.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.1430v1"
    },
    {
        "title": "Geometric Arbitrage Theory and Market Dynamics Reloaded",
        "authors": [
            "Simone Farinelli"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We have embedded the classical theory of stochastic finance into a\ndifferential geometric framework called Geometric Arbitrage Theory and show\nthat it is possible to:\n  --Write arbitrage as curvature of a principal fibre bundle.\n  --Parameterize arbitrage strategies by its holonomy.\n  --Give the Fundamental Theorem of Asset Pricing a differential homotopic\ncharacterization.\n  --Characterize Geometric Arbitrage Theory by five principles and show they\nthey are consistent with the classical theory of stochastic finance.\n  --Derive for a closed market the equilibrium solution for market portfolio\nand dynamics in the cases where:\n  -->Arbitrage is allowed but minimized.\n  -->Arbitrage is not allowed.\n  --Prove that the no-free-lunch-with-vanishing-risk condition implies the zero\ncurvature condition.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.1671v10"
    },
    {
        "title": "BSDEs with random default time and their applications to default risk",
        "authors": [
            "Shige Peng",
            "Xiaoming Xu"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  In this paper we are concerned with backward stochastic differential\nequations with random default time and their applications to default risk. The\nequations are driven by Brownian motion as well as a mutually independent\nmartingale appearing in a defaultable setting. We show that these equations\nhave unique solutions and a comparison theorem for their solutions. As an\napplication, we get a saddle-point strategy for the related zero-sum stochastic\ndifferential game problem.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.2091v1"
    },
    {
        "title": "Admissible Strategies in Semimartingale Portfolio Selection",
        "authors": [
            "Sara Biagini",
            "Aleš Černý"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  The choice of admissible trading strategies in mathematical modelling of\nfinancial markets is a delicate issue, going back to Harrison and Kreps (1979).\nIn the context of optimal portfolio selection with expected utility preferences\nthis question has been a focus of considerable attention over the last twenty\nyears. We propose a novel notion of admissibility that has many pleasant\nfeatures - admissibility is characterized purely under the objective measure;\neach admissible strategy can be approximated by simple strategies using finite\nnumber of trading dates; the wealth of any admissible strategy is a\nsupermartingale under all pricing measures; local boundedness of the price\nprocess is not required; neither strict monotonicity, strict concavity nor\ndifferentiability of the utility function are necessary; the definition\nencompasses both the classical mean-variance preferences and the monotone\nexpected utility. For utility functions finite on the whole real line, our\nclass represents a minimal set containing simple strategies which also contains\nthe optimizer, under conditions that are milder than the celebrated reasonable\nasymptotic elasticity condition on the utility function.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.3936v5"
    },
    {
        "title": "Exact Simulation of Bessel Diffusions",
        "authors": [
            "Roman N. Makarov",
            "Devin Glew"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We consider the exact path sampling of the squared Bessel process and some\nother continuous-time Markov processes, such as the CIR model, constant\nelasticity of variance diffusion model, and hypergeometric diffusions, which\ncan all be obtained from a squared Bessel process by using a change of\nvariable, time and scale transformation, and/or change of measure. All these\ndiffusions are broadly used in mathematical finance for modelling asset prices,\nmarket indices, and interest rates. We show how the probability distributions\nof a squared Bessel bridge and a squared Bessel process with or without\nabsorption at zero are reduced to randomized gamma distributions. Moreover, for\nabsorbing stochastic processes, we develop a new bridge sampling technique\nbased on conditioning on the first hitting time at zero. Such an approach\nallows us to simplify simulation schemes. New methods are illustrated with\npricing path-dependent options.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.4177v1"
    },
    {
        "title": "Dual Quantization for random walks with application to credit\n  derivatives",
        "authors": [
            "Gilles Pagès",
            "Benedikt Wilbertz"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We propose a new Quantization algorithm for the approximation of\ninhomogeneous random walks, which are the key terms for the valuation of\nCDO-tranches in latent factor models. This approach is based on a dual\nquantization operator which posses an intrinsic stationarity and therefore\nautomatically leads to a second order error bound for the weak approximation.\nWe illustrate the numerical performance of our methods in case of the\napproximation of the conditional tranche function of synthetic CDO products and\ndraw comparisons to the approximations achieved by the saddlepoint method and\nStein's method.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.5655v1"
    },
    {
        "title": "Bonds with volatilities proportional to forward rates",
        "authors": [
            "Michal Baran",
            "Jerzy Zabczyk"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  The problem of existence of solution for the Heath-Jarrow-Morton equation\nwith linear volatility and purely jump random factor is studied. Sufficient\nconditions for existence and non-existence of the solution in the class of\nbounded fields are formulated. It is shown that if the first derivative of the\nLevy-Khinchin exponent grows slower then logarithmic function then the answer\nis positive and if it is bounded from below by a fractional power function of\nany positive order then the answer is negative. Numerous examples including\nmodels with Levy measures of stable type are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.1119v1"
    },
    {
        "title": "Regularity of the Exercise Boundary for American Put Options on Assets\n  with Discrete Dividends",
        "authors": [
            "Benjamin Jourdain",
            "Michel Vellekoop"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  We analyze the regularity of the optimal exercise boundary for the American\nPut option when the underlying asset pays a discrete dividend at a known time\n$t_d$ during the lifetime of the option. The ex-dividend asset price process is\nassumed to follow Black-Scholes dynamics and the dividend amount is a\ndeterministic function of the ex-dividend asset price just before the dividend\ndate. The solution to the associated optimal stopping problem can be\ncharacterised in terms of an optimal exercise boundary which, in contrast to\nthe case when there are no dividends, may no longer be monotone. In this paper\nwe prove that when the dividend function is positive and concave, then the\nboundary is non-increasing in a left-hand neighbourhood of $t_d$, and tends to\n$0$ as time tends to $t_d^-$ with a speed that we can characterize. When the\ndividend function is linear in a neighbourhood of zero, then we show continuity\nof the exercise boundary and a high contact principle in the left-hand\nneighbourhood of $t_d$. When it is globally linear, then right-continuity of\nthe boundary and the high contact principle are proved to hold globally.\nFinally, we show how all the previous results can be extended to multiple\ndividend payment dates in that case.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.5117v2"
    },
    {
        "title": "Variance Optimal Hedging for continuous time processes with independent\n  increments and applications",
        "authors": [
            "Stéphane Goutte",
            "Nadia Oudjane",
            "Francesco Russo"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  For a large class of vanilla contingent claims, we establish an explicit\nF\\\"ollmer-Schweizer decomposition when the underlying is a process with\nindependent increments (PII) and an exponential of a PII process. This allows\nto provide an efficient algorithm for solving the mean variance hedging\nproblem. Applications to models derived from the electricity market are\nperformed.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.0372v1"
    },
    {
        "title": "Bayesian Inference of Stochastic Volatility Model by Hybrid Monte Carlo",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  The hybrid Monte Carlo (HMC) algorithm is applied for the Bayesian inference\nof the stochastic volatility (SV) model. We use the HMC algorithm for the\nMarkov chain Monte Carlo updates of volatility variables of the SV model. First\nwe compute parameters of the SV model by using the artificial financial data\nand compare the results from the HMC algorithm with those from the Metropolis\nalgorithm. We find that the HMC algorithm decorrelates the volatility variables\nfaster than the Metropolis algorithm. Second we make an empirical study for the\ntime series of the Nikkei 225 stock index by the HMC algorithm. We find the\nsimilar correlation behavior for the sampled data to the results from the\nartificial financial data and obtain a $\\phi$ value close to one ($\\phi \\approx\n0.977$), which means that the time series has the strong persistency of the\nvolatility shock.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.0024v1"
    },
    {
        "title": "Is the minimum value of an option on variance generated by local\n  volatility?",
        "authors": [
            "Mathias Beiglboeck",
            "Peter Friz",
            "Stephan Sturm"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We discuss the possibility of obtaining model-free bounds on volatility\nderivatives, given present market data in the form of a calibrated local\nvolatility model. A counter-example to a wide-spread conjecture is given.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.4031v3"
    },
    {
        "title": "Shortfall Risk Approximations for American Options in the\n  multidimensional Black--Scholes Model",
        "authors": [
            "Yan Dolinsky"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We show that shortfall risks of American options in a sequence of multinomial\napproximations of the multidimensional Black--Scholes (BS) market converge to\nthe corresponding quantities for similar American options in the\nmultidimensional BS market with path dependent payoffs. In comparison to\nprevious papers we consider the multi assets case for which we use the weak\nconvergence approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1574v1"
    },
    {
        "title": "Error Estimates for Multinomial Approximations of American Options in\n  Merton's Model",
        "authors": [
            "Yan Dolinsky"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We derive error estimates for multinomial approximations of American options\nin a multidimensional jump--diffusion Merton's model. We assume that the\npayoffs are Markovian and satisfy Lipschitz type conditions. Error estimates\nfor such type of approximations were not obtained before. Our main tool is the\nstrong approximations theorems for i.i.d. random vectors which were obtained\n[14]. For the multidimensional Black--Scholes model our results can be extended\nalso to a general path dependent payoffs which satisfy Lipschitz type\nconditions. For the case of multinomial approximations of American options for\nthe Black--Scholes model our estimates are a significant improvement of those\nwhich were obtained in [8] (for game options in a more general setup)\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1575v1"
    },
    {
        "title": "Limit Theorems for Partial Hedging Under Transaction Costs",
        "authors": [
            "Yan Dolinsky"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We study shortfall risk minimization for American options with path dependent\npayoffs under proportional transaction costs in the Black--Scholes (BS) model.\nWe show that for this case the shortfall risk is a limit of similar terms in an\nappropriate sequence of binomial models. We also prove that in the continuous\ntime BS model for a given initial capital there exists a portfolio strategy\nwhich minimizes the shortfall risk. In the absence of transactions costs\n(complete markets) similar limit theorems were obtained in Dolinsky and Kifer\n(2008, 2010) for game options. In the presence of transaction costs the markets\nare no longer complete and additional machinery required. Shortfall risk\nminimization for American options under transaction costs was not studied\nbefore.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1576v1"
    },
    {
        "title": "Chain ladder method: Bayesian bootstrap versus classical bootstrap",
        "authors": [
            "Gareth W. Peters",
            "Mario V. Wüthrich",
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The intention of this paper is to estimate a Bayesian distribution-free chain\nladder (DFCL) model using approximate Bayesian computation (ABC) methodology.\nWe demonstrate how to estimate quantities of interest in claims reserving and\ncompare the estimates to those obtained from classical and credibility\napproaches. In this context, a novel numerical procedure utilising Markov chain\nMonte Carlo (MCMC), ABC and a Bayesian bootstrap procedure was developed in a\ntruly distribution-free setting. The ABC methodology arises because we work in\na distribution-free setting in which we make no parametric assumptions, meaning\nwe can not evaluate the likelihood point-wise or in this case simulate directly\nfrom the likelihood model. The use of a bootstrap procedure allows us to\ngenerate samples from the intractable likelihood without the requirement of\ndistributional assumptions, this is crucial to the ABC framework. The developed\nmethodology is used to obtain the empirical distribution of the DFCL model\nparameters and the predictive distribution of the outstanding loss liabilities\nconditional on the observed claims. We then estimate predictive Bayesian\ncapital estimates, the Value at Risk (VaR) and the mean square error of\nprediction (MSEP). The latter is compared with the classical bootstrap and\ncredibility methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2548v1"
    },
    {
        "title": "Optimal closing of a pair trade with a model containing jumps",
        "authors": [
            "Stig Larsson",
            "Carl Lindberg",
            "Marcus Warfheimer"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  A pair trade is a portfolio consisting of a long position in one asset and a\nshort position in another, and it is a widely applied investment strategy in\nthe financial industry. Recently, Ekstr\\\"om, Lindberg and Tysk studied the\nproblem of optimally closing a pair trading strategy when the difference of the\ntwo assets is modelled by an Ornstein-Uhlenbeck process. In this paper we study\nthe same problem, but the model is generalized to also include jumps. More\nprecisely we assume that the above difference is an Ornstein-Uhlenbeck type\nprocess, driven by a L\\'evy process of finite activity. We prove a verification\ntheorem and analyze a numerical method for the associated free boundary\nproblem. We prove rigorous error estimates, which are used to draw some\nconclusions from numerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2947v1"
    },
    {
        "title": "A general method for debiasing a Monte Carlo estimator",
        "authors": [
            "Don McLeish"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Consider a process, stochastic or deterministic, obtained by using a\nnumerical integration scheme, or from Monte-Carlo methods involving an\napproximation to an integral, or a Newton-Raphson iteration to approximate the\nroot of an equation. We will assume that we can sample from the distribution of\nthe process from time 0 to finite time n. We propose a scheme for unbiased\nestimation of the limiting value of the process, together with estimates of\nstandard error and apply this to examples including numerical integrals,\nroot-finding and option pricing in a Heston Stochastic Volatility model. This\nresults in unbiased estimators in place of biased ones i nmany potential\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.2228v2"
    },
    {
        "title": "Computation of vector sublattices and minimal lattice-subspaces of R^k.\n  Applications in finance",
        "authors": [
            "V. N. Katsikis",
            "I. A. Polyrakis"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In this article we perform a computational study of Polyrakis algorithms\npresented in [12,13]. These algorithms are used for the determination of the\nvector sublattice and the minimal lattice-subspace generated by a finite set of\npositive vectors of R^k. The study demonstrates that our findings can be very\nuseful in the field of Economics, especially in completion by options of\nsecurity markets and portfolio insurance.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4070v1"
    },
    {
        "title": "Phase transition in a log-normal Markov functional model",
        "authors": [
            "Dan Pirjol"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We derive the exact solution of a one-dimensional Markov functional model\nwith log-normally distributed interest rates in discrete time. The model is\nshown to have two distinct limiting states, corresponding to small and\nasymptotically large volatilities, respectively. These volatility regimes are\nseparated by a phase transition at some critical value of the volatility. We\ninvestigate the conditions under which this phase transition occurs, and show\nthat it is related to the position of the zeros of an appropriately defined\ngenerating function in the complex plane, in analogy with the Lee-Yang theory\nof the phase transitions in condensed matter physics.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.0691v3"
    },
    {
        "title": "Picard approximation of stochastic differential equations and\n  application to LIBOR models",
        "authors": [
            "Antonis Papapantoleon",
            "David Skovmand"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The aim of this work is to provide fast and accurate approximation schemes\nfor the Monte Carlo pricing of derivatives in LIBOR market models. Standard\nmethods can be applied to solve the stochastic differential equations of the\nsuccessive LIBOR rates but the methods are generally slow. Our contribution is\ntwofold. Firstly, we propose an alternative approximation scheme based on\nPicard iterations. This approach is similar in accuracy to the Euler\ndiscretization, but with the feature that each rate is evolved independently of\nthe other rates in the term structure. This enables simultaneous calculation of\nderivative prices of different maturities using parallel computing. Secondly,\nthe product terms occurring in the drift of a LIBOR market model driven by a\njump process grow exponentially as a function of the number of rates, quickly\nrendering the model intractable. We reduce this growth from exponential to\nquadratic using truncated expansions of the product terms. We include numerical\nillustrations of the accuracy and speed of our method pricing caplets,\nswaptions and forward rate agreements.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.3362v2"
    },
    {
        "title": "Non-existence of Markovian time dynamics for graphical models of\n  correlated default",
        "authors": [
            "Steven N. Evans",
            "Alexandru Hening"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Filiz et al. (2008) proposed a model for the pattern of defaults seen among a\ngroup of firms at the end of a given time period. The ingredients in the model\nare a graph, where the vertices correspond to the firms and the edges describe\nthe network of interdependencies between the firms, a parameter for each vertex\nthat captures the individual propensity of that firm to default, and a\nparameter for each edge that captures the joint propensity of the two connected\nfirms to default. The correlated default model can be re-rewritten as a\nstandard Ising model on the graph by identifying the set of defaulting firms in\nthe default model with the set of sites in the Ising model for which the spin\nis +1. We ask whether there is a suitable continuous time Markov chain taking\nvalues in the subsets of the vertex set such that the initial state of the\nchain is the empty set, each jump of the chain involves the inclusion of a\nsingle extra vertex, the distribution of the chain at some fixed time horizon\ntime is the one given by the default model, and the distribution of the chain\nfor other times is described by a probability distribution in the same family\nas the default model. We show for three simple but financially natural special\ncases that this is not possible outside of the trivial case where there is\ncomplete independence between the firms.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.2226v1"
    },
    {
        "title": "No-arbitrage of second kind in countable markets with proportional\n  transaction costs",
        "authors": [
            "Bruno Bouchard",
            "Erik Taflin"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Motivated by applications to bond markets, we propose a multivariate\nframework for discrete time financial markets with proportional transaction\ncosts and a countable infinite number of tradable assets. We show that the\nno-arbitrage of second kind property (NA2 in short), recently introduced by\nRasonyi for finite-dimensional markets, allows us to provide a closure property\nfor the set of attainable claims in a very natural way, under a suitable\nefficient friction condition. We also extend to this context the equivalence\nbetween NA2 and the existence of many (strictly) consistent price systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.3276v3"
    },
    {
        "title": "Connecting discrete and continuous lookback or hindsight options in\n  exponential Lévy models",
        "authors": [
            "El Hadj Aly Dia",
            "Damien Lamberton"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Motivated by the pricing of lookback options in exponential L\\'evy models, we\nstudy the difference between the continuous and discrete supremum of L\\'evy\nprocesses. In particular, we extend the results of Broadie et al. (1999) to\njump-diffusion models. We also derive bounds for general exponential L\\'evy\nmodels.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.4884v1"
    },
    {
        "title": "Sequential Monte Carlo pricing of American-style options under\n  stochastic volatility models",
        "authors": [
            "Bhojnarine R. Rambharat",
            "Anthony E. Brockwell"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  We introduce a new method to price American-style options on underlying\ninvestments governed by stochastic volatility (SV) models. The method does not\nrequire the volatility process to be observed. Instead, it exploits the fact\nthat the optimal decision functions in the corresponding dynamic programming\nproblem can be expressed as functions of conditional distributions of\nvolatility, given observed data. By constructing statistics summarizing\ninformation about these conditional distributions, one can obtain high quality\napproximate solutions. Although the required conditional distributions are in\ngeneral intractable, they can be arbitrarily precisely approximated using\nsequential Monte Carlo schemes. The drawback, as with many Monte Carlo schemes,\nis potentially heavy computational demand. We present two variants of the\nalgorithm, one closely related to the well-known least-squares Monte Carlo\nalgorithm of Longstaff and Schwartz [The Review of Financial Studies 14 (2001)\n113-147], and the other solving the same problem using a \"brute force\" gridding\napproach. We estimate an illustrative SV model using Markov chain Monte Carlo\n(MCMC) methods for three equities. We also demonstrate the use of our algorithm\nby estimating the posterior distribution of the market price of volatility risk\nfor each of the three equities.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.1372v2"
    },
    {
        "title": "An Efficient, Distributable, Risk Neutral Framework for CVA Calculation",
        "authors": [
            "Dongsheng Lu",
            "Frank Juan"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The importance of counterparty credit risk to the derivative contracts was\ndemonstrated consistently throughout the financial crisis of 2008. Accurate\nvaluation of Credit value adjustment (CVA) is essential to reflect the economic\nvalues of these risks. In the present article, we reviewed several different\napproaches for calculating CVA, and compared the advantage and disadvantage for\neach method. We also introduced an more efficient and scalable computational\nframework for this calculation.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.1689v1"
    },
    {
        "title": "On optimal arbitrage",
        "authors": [
            "Daniel Fernholz",
            "Ioannis Karatzas"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In a Markovian model for a financial market, we characterize the best\narbitrage with respect to the market portfolio that can be achieved using\nnonanticipative investment strategies, in terms of the smallest positive\nsolution to a parabolic partial differential inequality; this is determined\nentirely on the basis of the covariance structure of the model. The solution is\nintimately related to properties of strict local martingales and is used to\ngenerate the investment strategy which realizes the best possible arbitrage.\nSome extensions to non-Markovian situations are also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.4987v1"
    },
    {
        "title": "On using shadow prices in portfolio optimization with transaction costs",
        "authors": [
            "J. Kallsen",
            "J. Muhle-Karbe"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  In frictionless markets, utility maximization problems are typically solved\neither by stochastic control or by martingale methods. Beginning with the\nseminal paper of Davis and Norman [Math. Oper. Res. 15 (1990) 676--713],\nstochastic control theory has also been used to solve various problems of this\ntype in the presence of proportional transaction costs. Martingale methods, on\nthe other hand, have so far only been used to derive general structural\nresults. These apply the duality theory for frictionless markets typically to a\nfictitious shadow price process lying within the bid-ask bounds of the real\nprice process. In this paper, we show that this dual approach can actually be\nused for both deriving a candidate solution and verification in Merton's\nproblem with logarithmic utility and proportional transaction costs. In\nparticular, we determine the shadow price process.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.4989v1"
    },
    {
        "title": "Storage option an Analytic approach",
        "authors": [
            "Dmitry Lesnik"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The mathematical problem of the static storage optimisation is formulated and\nsolved by means of a variational analysis. The solution obtained in implicit\nform is shedding light on the most important features of the optimal exercise\nstrategy. We show how the solution depends on different constraint types\nincluding carry cost and cycling constraint. We investigate the relation\nbetween intrinsic and stochastic solutions. In particular we give another proof\nthat the stochastic problem has a \"bang-bang\" optimal exercise strategy. We\nalso show why the optimal stochastic exercise decision is always close to the\nintrinsic one. In the second half we develop a perturbation analysis to solve\nthe stochastic optimisation problem. The obtained approximate solution allows\nus to estimate the time value of the storage option. In particular we find an\nanswer to rather academic question of asymptotic time value for the mean\nreversion parameter approaching zero or infinity. We also investigate the\ndifferences between swing and storage problems. The analytical results are\ncompared with numerical valuations and found to be in a good agreement.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.1234v3"
    },
    {
        "title": "A Numerical Study of Radial Basis Function Based Methods for Options\n  Pricing under the One Dimension Jump-diffusion Model",
        "authors": [
            "Ron T. L. Chan",
            "Simon Hubbert"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  The aim of this chapter is to show how option prices in jump-diffusion models\ncan be computed using meshless methods based on Radial Basis Function (RBF)\ninterpolation. The RBF technique is demonstrated by solving the partial\nintegro-differential equation (PIDE) in one-dimension for the American put and\nthe European vanilla call/put options on dividend-paying stocks in the Merton\nand Kou jump-diffusion models. The radial basis function we select is the Cubic\nSpline. We also propose a simple numerical algorithm for finding a finite\ncomputational range of an improper integral term in the PIDE so that the\naccuracy of approximation of the integral can be improved. Moreover, the\nsolution functions of the PIDE are approximated explicitly by RBFs which have\nexact forms so we can easily compute the global integral by any kind of\nnumerical quadrature. Finally, we will not only show numerically that our\nscheme is second order accurate in both spatial and time variables in a\nEuropean case but also second order accurate in spatial variables and first\norder accurate in time variables in an American case.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.5650v4"
    },
    {
        "title": "Duality in Robust Utility Maximization with Unbounded Claim via a Robust\n  Extension of Rockafellar's Theorem",
        "authors": [
            "Keita Owari"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We study the convex duality method for robust utility maximization in the\npresence of a random endowment. When the underlying price process is a locally\nbounded semimartingale, we show that the fundamental duality relation holds\ntrue for a wide class of utility functions on the whole real line and unbounded\nrandom endowment. To obtain this duality, we prove a robust version of\nRockafellar's theorem on convex integral functionals and apply Fenchel's\ngeneral duality theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.2968v1"
    },
    {
        "title": "GPGPUs in computational finance: Massive parallel computing for American\n  style options",
        "authors": [
            "Gilles Pagès",
            "Benedikt Wilbertz"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  The pricing of American style and multiple exercise options is a very\nchallenging problem in mathematical finance. One usually employs a Least-Square\nMonte Carlo approach (Longstaff-Schwartz method) for the evaluation of\nconditional expectations which arise in the Backward Dynamic Programming\nprinciple for such optimal stopping or stochastic control problems in a\nMarkovian framework. Unfortunately, these Least-Square Monte Carlo approaches\nare rather slow and allow, due to the dependency structure in the Backward\nDynamic Programming principle, no parallel implementation; whether on the Monte\nCarlo levelnor on the time layer level of this problem. We therefore present in\nthis paper a quantization method for the computation of the conditional\nexpectations, that allows a straightforward parallelization on the Monte Carlo\nlevel. Moreover, we are able to develop for AR(1)-processes a further\nparallelization in the time domain, which makes use of faster memory structures\nand therefore maximizes parallel execution. Finally, we present numerical\nresults for a CUDA implementation of this methods. It will turn out that such\nan implementation leads to an impressive speed-up compared to a serial CPU\nimplementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.3228v1"
    },
    {
        "title": "Volatility made observable at last",
        "authors": [
            "Michel Fliess",
            "Cédric Join",
            "Frédéric Hatt"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  The Cartier-Perrin theorem, which was published in 1995 and is expressed in\nthe language of nonstandard analysis, permits, for the first time perhaps, a\nclear-cut mathematical definition of the volatility of a financial asset. It\nyields as a byproduct a new understanding of the means of returns, of the beta\ncoefficient, and of the Sharpe and Treynor ratios. New estimation techniques\nfrom automatic control and signal processing, which were already successfully\napplied in quantitative finance, lead to several computer experiments with some\nquite convincing forecasts.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.0683v1"
    },
    {
        "title": "A method for pricing American options using semi-infinite linear\n  programming",
        "authors": [
            "Sören Christensen"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We introduce a new approach for the numerical pricing of American options.\nThe main idea is to choose a finite number of suitable excessive functions\n(randomly) and to find the smallest majorant of the gain function in the span\nof these functions. The resulting problem is a linear semi-infinite programming\nproblem, that can be solved using standard algorithms. This leads to good upper\nbounds for the original problem. For our algorithms no discretization of space\nand time and no simulation is necessary. Furthermore it is applicable even for\nhigh-dimensional problems. The algorithm provides an approximation of the value\nnot only for one starting point, but for the complete value function on the\ncontinuation set, so that the optimal exercise region and e.g. the Greeks can\nbe calculated. We apply the algorithm to (one- and) multidimensional diffusions\nand to L\\'evy processes, and show it to be fast and accurate.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.4483v2"
    },
    {
        "title": "Explosive behavior in a log-normal interest rate model",
        "authors": [
            "Dan Pirjol"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We consider an interest rate model with log-normally distributed rates in the\nterminal measure in discrete time. Such models are used in financial practice\nas parametric versions of the Markov functional model, or as approximations to\nthe log-normal Libor market model. We show that the model has two distinct\nregimes, at high and low volatilities, with different qualitative behavior. The\ntwo regimes are separated by a sharp transition, which is similar to a phase\ntransition in condensed matter physics. We study the behavior of the model in\nthe large volatility phase, and discuss the implications of the phase\ntransition for the pricing of interest rate derivatives. In the large\nvolatility phase, certain expectation values and convexity adjustments have an\nexplosive behavior. For sufficiently low volatilities the caplet smile is\nlog-normal to a very good approximation, while in the large volatility phase\nthe model develops a non-trivial caplet skew. The phenomenon discussed here\nimposes thus an upper limit on the volatilities for which the model behaves as\nintended.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.0322v4"
    },
    {
        "title": "Is a probabilistic modeling really useful in financial engineering? -\n  A-t-on vraiment besoin d'un modèle probabiliste en ingénierie\n  financière ?",
        "authors": [
            "Michel Fliess",
            "Cédric Join",
            "Frédéric Hatt"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  A new standpoint on financial time series, without the use of any\nmathematical model and of probabilistic tools, yields not only a rigorous\napproach of trends and volatility, but also efficient calculations which were\nalready successfully applied in automatic control and in signal processing. It\nis based on a theorem due to P. Cartier and Y. Perrin, which was published in\n1995. The above results are employed for sketching a dynamical portfolio and\nstrategy management, without any global optimization technique. Numerous\ncomputer simulations are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.2124v2"
    },
    {
        "title": "Calibration and filtering for multi factor commodity models with\n  seasonality: incorporating panel data from futures contracts",
        "authors": [
            "Gareth W. Peters",
            "Mark Briers",
            "Pavel V. Shevchenko",
            "Arnaud Doucet"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We examine a general multi-factor model for commodity spot prices and futures\nvaluation. We extend the multi-factor long-short model in Schwartz and Smith\n(2000) and Yan (2002) in two important aspects: firstly we allow for both the\nlong and short term dynamic factors to be mean reverting incorporating\nstochastic volatility factors and secondly we develop an additive structural\nseasonality model. Then a Milstein discretized non-linear stochastic volatility\nstate space representation for the model is developed which allows for futures\nand options contracts in the observation equation. We then develop numerical\nmethodology based on an advanced Sequential Monte Carlo algorithm utilising\nParticle Markov chain Monte Carlo to perform calibration of the model jointly\nwith the filtering of the latent processes for the long-short dynamics and\nvolatility factors. In this regard we explore and develop a novel methodology\nbased on an adaptive Rao-Blackwellised version of the Particle Markov chain\nMonte Carlo methodology. In doing this we deal accurately with the\nnon-linearities in the state-space model which are therefore introduced into\nthe filtering framework. We perform analysis on synthetic and real data for oil\ncommodities.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.5850v1"
    },
    {
        "title": "Efficient and accurate log-Lévy approximations to Lévy driven LIBOR\n  models",
        "authors": [
            "Antonis Papapantoleon",
            "John Schoenmakers",
            "David Skovmand"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  The LIBOR market model is very popular for pricing interest rate derivatives,\nbut is known to have several pitfalls. In addition, if the model is driven by a\njump process, then the complexity of the drift term is growing exponentially\nfast (as a function of the tenor length). In this work, we consider a\nL\\'evy-driven LIBOR model and aim at developing accurate and efficient\nlog-L\\'evy approximations for the dynamics of the rates. The approximations are\nbased on truncation of the drift term and Picard approximation of suitable\nprocesses. Numerical experiments for FRAs, caps, swaptions and sticky ratchet\ncaps show that the approximations perform very well. In addition, we also\nconsider the log-L\\'evy approximation of annuities, which offers good\napproximations for high volatility regimes.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.0866v2"
    },
    {
        "title": "Default risk modeling beyond the first-passage approximation:\n  Position-dependent killing",
        "authors": [
            "Yuri A. Katz"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Diffusion in a linear potential in the presence of position-dependent killing\nis used to mimic a default process. Different assumptions regarding transport\ncoefficients, initial conditions, and elasticity of the killing measure lead to\ndiverse models of bankruptcy. One \"stylized fact\" is fundamental for our\nconsideration: empirically default is a rather rare event, especially in the\ninvestment grade categories of credit ratings. Hence, the action of killing may\nbe considered as a small parameter. In a number of special cases we derive\nclosed-form expressions for the entire term structure of the cumulative\nprobability of default, its hazard rate and intensity. Comparison with\nhistorical data on global corporate defaults confirms applicability of the\nmodel-independent perturbation method for companies in the investment grade\ncategories of credit ratings and allows for\n",
        "pdf_link": "http://arxiv.org/pdf/1108.5098v1"
    },
    {
        "title": "Pricing and Semimartingale Representations of Vulnerable Contingent\n  Claims in Regime-Switching Markets",
        "authors": [
            "Agostino Capponi",
            "Jose Figueroa-Lopez",
            "Jeffrey Nisen"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Using a suitable change of probability measure, we obtain a novel Poisson\nseries representation for the arbitrage- free price process of vulnerable\ncontingent claims in a regime-switching market driven by an underlying\ncontinuous- time Markov process. As a result of this representation, along with\na short-time asymptotic expansion of the claim's price process, we develop an\nefficient method for pricing claims whose payoffs may depend on the full path\nof the underlying Markov chain. The proposed approach is applied to price not\nonly simple European claims such as defaultable bonds, but also a new type of\npath-dependent claims that we term self-decomposable, as well as the important\nclass of vulnerable call and put options on a stock. We provide a detailed\nerror analysis and illustrate the accuracy and computational complexity of our\nmethod on several market traded instruments, such as defaultable bond prices,\nbarrier options, and vulnerable call options. Using again our Poisson series\nrepresentation, we show differentiability in time of the pre-default price\nfunction of European vulnerable claims, which enables us to rigorously deduce\nFeynman-Kac representations for the pre-default pricing function and new\nsemimartingale representations for the price process of the vulnerable claim\nunder both risk-neutral and objective probability measures.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.0403v2"
    },
    {
        "title": "Optimal decision under ambiguity for diffusion processes",
        "authors": [
            "Sören Christensen"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper we consider stochastic optimization problems for an ambiguity\naverse decision maker who is uncertain about the parameters of the underlying\nprocess. In a first part we consider problems of optimal stopping under drift\nambiguity for one-dimensional diffusion processes. Analogously to the case of\nordinary optimal stopping problems for one-dimensional Brownian motions we\nreduce the problem to the geometric problem of finding the smallest majorant of\nthe reward function in a two-parameter function space. In a second part we\nsolve optimal stopping problems when the underlying process may crash down.\nThese problems are reduced to one optimal stopping problem and one Dynkin game.\nExamples are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.3897v2"
    },
    {
        "title": "Exact and asymptotic results for insurance risk models with\n  surplus-dependent premiums",
        "authors": [
            "Hansjörg Albrecher",
            "Corina Constantinescu",
            "Zbigniew Palmowski",
            "Georg Regensburger",
            "Markus Rosenkranz"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper we develop a symbolic technique to obtain asymptotic\nexpressions for ruin probabilities and discounted penalty functions in renewal\ninsurance risk models when the premium income depends on the present surplus of\nthe insurance portfolio. The analysis is based on boundary problems for linear\nordinary differential equations with variable coefficients. The algebraic\nstructure of the Green's operators allows us to develop an intuitive way of\ntackling the asymptotic behavior of the solutions, leading to exponential-type\nexpansions and Cram\\'er-type asymptotics. Furthermore, we obtain closed-form\nsolutions for more specific cases of premium functions in the compound Poisson\nrisk model.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.5276v1"
    },
    {
        "title": "Optimizing expected utility of dividend payments for a Cramér-Lundberg\n  risk proces",
        "authors": [
            "Zbigniew Palmowski",
            "Sebastian Baran"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We consider the problem of maximizing the discounted utility of dividend\npayments of an insurance company whose reserves are modeled as a classical\nCram\\'er-Lundberg risk process. We investigate this optimization problem under\nthe constraint that dividend rate is bounded. We prove that the value function\nfulfills the Hamilton-Jacobi-Bellman equation and we identify the optimal\ndividend strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.5446v3"
    },
    {
        "title": "Symmetries of the Black-Scholes equation",
        "authors": [
            "Paul Lescot"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We determine the algebra of isovectors for the Black--Scholes equation. As a\nconsequence, we obtain some previously unknown families of transformations on\nthe solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.6170v2"
    },
    {
        "title": "Numerical Solutions of Optimal Risk Control and Dividend Optimization\n  Policies under A Generalized Singular Control Formulation",
        "authors": [
            "Zhuo Jin",
            "George Yin",
            "Chao Zhu"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  This paper develops numerical methods for finding optimal dividend pay-out\nand reinsurance policies. A generalized singular control formulation of surplus\nand discounted payoff function are introduced, where the surplus is modeled by\na regime-switching process subject to both regular and singular controls. To\napproximate the value function and optimal controls, Markov chain approximation\ntechniques are used to construct a discrete-time controlled Markov chain with\ntwo components. The proofs of the convergence of the approximation sequence to\nthe surplus process and the value function are given. Examples of proportional\nand excess-of-loss reinsurance are presented to illustrate the applicability of\nthe numerical methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.2584v1"
    },
    {
        "title": "Optimal dual martingales, their analysis and application to new\n  algorithms for Bermudan products",
        "authors": [
            "John Schoenmakers",
            "Junbo Huang",
            "Jianing Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper we introduce and study the concept of optimal and surely\noptimal dual martingales in the context of dual valuation of Bermudan options,\nand outline the development of new algorithms in this context. We provide a\ncharacterization theorem, a theorem which gives conditions for a martingale to\nbe surely optimal, and a stability theorem concerning martingales which are\nnear to be surely optimal in a sense. Guided by these results we develop a\nframework of backward algorithms for constructing such a martingale. In turn\nthis martingale may then be utilized for computing an upper bound of the\nBermudan product. The methodology is pure dual in the sense that it doesn't\nrequire certain input approximations to the Snell envelope. In an It\\^o-L\\'evy\nenvironment we outline a particular regression based backward algorithm which\nallows for computing dual upper bounds without nested Monte Carlo simulation.\nMoreover, as a by-product this algorithm also provides approximations to the\ncontinuation values of the product, which in turn determine a stopping policy.\nHence, we may obtain lower bounds at the same time. In a first numerical study\nwe demonstrate the backward dual regression algorithm in a Wiener environment\nat well known benchmark examples. It turns out that the method is at least\ncomparable to the one in Belomestny et. al. (2009) regarding accuracy, but\nregarding computational robustness there are even several advantages.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6038v2"
    },
    {
        "title": "Adaptive Simulation of the Heston Model",
        "authors": [
            "Ian Iscoe",
            "Asif Lakhany"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Recent years have seen an increased level of interest in pricing equity\noptions under a stochastic volatility model such as the Heston model. Often,\nsimulating a Heston model is difficult, as a standard finite difference scheme\nmay lead to significant bias in the simulation result. Reducing the bias to an\nacceptable level is not only challenging but computationally demanding. In this\npaper we address this issue by providing an alternative simulation strategy --\none that systematically decreases the bias in the simulation. Additionally, our\nmethodology is adaptive and achieves the reduction in bias with \"near\" minimum\ncomputational effort. We illustrate this feature with a numerical example.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6067v1"
    },
    {
        "title": "Dual representations for general multiple stopping problems",
        "authors": [
            "Christian Bender",
            "John Schoenmakers",
            "Jianing Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  In this paper, we study the dual representation for generalized multiple\nstopping problems, hence the pricing problem of general multiple exercise\noptions. We derive a dual representation which allows for cashflows which are\nsubject to volume constraints modeled by integer valued adapted processes and\nrefraction periods modeled by stopping times. As such, this extends the works\nby Schoenmakers (2010), Bender (2011a), Bender (2011b), Aleksandrov and Hambly\n(2010), and Meinshausen and Hambly (2004) on multiple exercise options, which\neither take into consideration a refraction period or volume constraints, but\nnot both simultaneously. We also allow more flexible cashflow structures than\nthe additive structure in the above references. For example some exponential\nutility problems are covered by our setting. We supplement the theoretical\nresults with an explicit Monte Carlo algorithm for constructing confidence\nintervals for the price of multiple exercise options and exemplify it by a\nnumerical study on the pricing of a swing option in an electricity market.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.2638v1"
    },
    {
        "title": "Minimax Option Pricing Meets Black-Scholes in the Limit",
        "authors": [
            "Jacob Abernethy",
            "Rafael M. Frongillo",
            "Andre Wibisono"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Option contracts are a type of financial derivative that allow investors to\nhedge risk and speculate on the variation of an asset's future market price. In\nshort, an option has a particular payout that is based on the market price for\nan asset on a given date in the future. In 1973, Black and Scholes proposed a\nvaluation model for options that essentially estimates the tail risk of the\nasset price under the assumption that the price will fluctuate according to\ngeometric Brownian motion. More recently, DeMarzo et al., among others, have\nproposed more robust valuation schemes, where we can even assume an adversary\nchooses the price fluctuations. This framework can be considered as a\nsequential two-player zero-sum game between the investor and Nature. We analyze\nthe value of this game in the limit, where the investor can trade at smaller\nand smaller time intervals. Under weak assumptions on the actions of Nature (an\nadversary), we show that the minimax option price asymptotically approaches\nexactly the Black-Scholes valuation. The key piece of our analysis is showing\nthat Nature's minimax optimal dual strategy converges to geometric Brownian\nmotion in the limit.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.2585v1"
    },
    {
        "title": "A Semi-group Expansion for Pricing Barrier Options",
        "authors": [
            "Takashi Kato",
            "Akihiko Takahashi",
            "Toshihiro Yamada"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  This paper presents a new asymptotic expansion method for pricing\ncontinuously monitoring barrier options. In particular, we develops a\nsemi-group expansion scheme for the Cauchy-Dirichlet problem in the\nsecond-order parabolic partial differential equations (PDEs) arising in barrier\noption pricing. As an application, we propose a concrete approximation formula\nunder a stochastic volatility model and demonstrate its validity by some\nnumerical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.3002v5"
    },
    {
        "title": "Equivalence of interest rate models and lattice gases",
        "authors": [
            "Dan Pirjol"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We consider the class of short rate interest rate models for which the short\nrate is proportional to the exponential of a Gaussian Markov process x(t) in\nthe terminal measure r(t) = a(t) exp(x(t)). These models include the Black,\nDerman, Toy and Black, Karasinski models in the terminal measure. We show that\nsuch interest rate models are equivalent with lattice gases with attractive\ntwo-body interaction V(t1,t2)= -Cov(x(t1),x(t2)). We consider in some detail\nthe Black, Karasinski model with x(t) an Ornstein, Uhlenbeck process, and show\nthat it is similar with a lattice gas model considered by Kac and Helfand, with\nattractive long-range two-body interactions V(x,y) = -\\alpha (e^{-\\gamma |x -\ny|} - e^{-\\gamma (x + y)}). An explicit solution for the model is given as a\nsum over the states of the lattice gas, which is used to show that the model\nhas a phase transition similar to that found previously in the Black, Derman,\nToy model in the terminal measure.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.0915v1"
    },
    {
        "title": "Perturbative Expansion Technique for Non-linear FBSDEs with Interacting\n  Particle Method",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  In this paper, we propose an efficient Monte Carlo implementation of\nnon-linear FBSDEs as a system of interacting particles inspired by the ideas of\nbranching diffusion method. It will be particularly useful to investigate large\nand complex systems, and hence it is a good complement of our previous work\npresenting an analytical perturbation procedure for generic non-linear FBSDEs.\nThere appear multiple species of particles, where the first one follows the\ndiffusion of the original underlying state, and the others the Malliavin\nderivatives with a grading structure. The number of branching points are capped\nby the order of perturbation, which is expected to make the scheme less\nnumerically intensive. The proposed method can be applied to semi-linear\nproblems, such as American and Bermudan options, Credit Value Adjustment (CVA),\nand even fully non-linear issues, such as the optimal portfolio problems in\nincomplete and/or constrained markets, feedbacks from large investors, and also\nthe analysis of various risk measures.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.2638v2"
    },
    {
        "title": "Maximum likelihood approach for several stochastic volatility models",
        "authors": [
            "Jordi Camprodon",
            "Josep Perelló"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Volatility measures the amplitude of price fluctuations. Despite it is one of\nthe most important quantities in finance, volatility is not directly\nobservable. Here we apply a maximum likelihood method which assumes that price\nand volatility follow a two-dimensional diffusion process where volatility is\nthe stochastic diffusion coefficient of the log-price dynamics. We apply this\nmethod to the simplest versions of the expOU, the OU and the Heston stochastic\nvolatility models and we study their performance in terms of the log-price\nprobability, the volatility probability, and its Mean First-Passage Time. The\napproach has some predictive power on the future returns amplitude by only\nknowing current volatility. The assumed models do not consider long-range\nvolatility auto-correlation and the asymmetric return-volatility\ncross-correlation but the method still arises very naturally these two\nimportant stylized facts. We apply the method to different market indexes and\nwith a good performance in all cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3556v2"
    },
    {
        "title": "Yield to maturity modelling and a Monte Carlo Technique for pricing\n  Derivatives on Constant Maturity Treasury (CMT) and Derivatives on forward\n  Bonds",
        "authors": [
            "Didier Kouokap Youmbi"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  This paper proposes a Monte Carlo technique for pricing the forward yield to\nmaturity, when the volatility of the zero-coupon bond is known. We make the\nassumption of deterministic default intensity (Hazard Rate Function). We make\nno assumption on the volatility of the yield. We actually calculate the initial\nvalue of the forward yield, we calculate the volatility of the yield, and we\nwrite the diffusion of the yield. As direct application we price options on\nConstant Maturity Treasury (CMT) in the Hull and White Model for the short\ninterest rate. Tests results with Caps and Floors on 10 years constant maturity\ntreasury (CMT10) are satisfactory. This work can also be used for pricing\noptions on bonds or forward bonds.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.4631v1"
    },
    {
        "title": "A No-Arbitrage Model of Liquidity in Financial Markets involving\n  Brownian Sheets",
        "authors": [
            "David German",
            "Henry Schellhorn"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We consider a dynamic market model where buyers and sellers submit limit\norders. If at a given moment in time, the buyer is unable to complete his\nentire order due to the shortage of sell orders at the required limit price,\nthe unmatched part of the order is recorded in the order book. Subsequently\nthese buy unmatched orders may be matched with new incoming sell orders. The\nresulting demand curve constitutes the sole input to our model. The clearing\nprice is then mechanically calculated using the market clearing condition. We\nuse a Brownian sheet to model the demand curve, and provide some theoretical\nassumptions under which such a model is justified.\n  Our main result is the proof that if there exists a unique equivalent\nmartingale measure for the clearing price, then under some mild assumptions\nthere is no arbitrage. We use the Ito- Wentzell formula to obtain that result,\nand also to characterize the dynamics of the demand curve and of the clearing\nprice in the equivalent measure. We find that the volatility of the clearing\nprice is (up to a stochastic factor) inversely proportional to the sum of buy\nand sell order flow density (evaluated at the clearing price), which confirms\nthe intuition that volatility is inversely proportional to volume. We also\ndemonstrate that our approach is implementable. We use real order book data and\nsimulate option prices under a particularly simple parameterization of our\nmodel.\n  The no-arbitrage conditions we obtain are applicable to a wide class of\nmodels, in the same way that the Heath-Jarrow-Morton conditions apply to a wide\nclass of interest rate models.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.4804v1"
    },
    {
        "title": "On free lunches in random walk markets with short-sale constraints and\n  small transaction costs, and weak convergence to Gaussian continuous-time\n  processes",
        "authors": [
            "Nils Chr. Framstad"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  This paper considers a sequence of discrete-time random walk markets with a\nsafe and a single risky investment opportunity, and gives conditions for the\nexistence of arbitrages or free lunches with vanishing risk, of the form of\nwaiting to buy and selling the next period, with no shorting, and furthermore\nfor weak convergence of the random walk to a Gaussian continuous-time\nstochastic process. The conditions are given in terms of the kernel\nrepresentation with respect to ordinary Brownian motion and the discretisation\nchosen. Arbitrage and free lunch with vanishing risk examples are established\nwhere the continuous-time analogue is arbitrage-free under small transaction\ncosts - including for the semimartingale modifications of fractional Brownian\nmotion suggested in the seminal Rogers (1997) article proving arbitrage in fBm\nmodels.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.5756v2"
    },
    {
        "title": "From characteristic functions to implied volatility expansions",
        "authors": [
            "Antoine Jacquier",
            "Matthew Lorig"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  For any strictly positive martingale $S = \\exp(X)$ for which $X$ has a\ncharacteristic function, we provide an expansion for the implied volatility.\nThis expansion is explicit in the sense that it involves no integrals, but only\npolynomials in the log strike. We illustrate the versatility of our expansion\nby computing the approximate implied volatility smile in three well-known\nmartingale models: one finite activity exponential L\\'evy model (Merton), one\ninfinite activity exponential L\\'evy model (Variance Gamma), and one stochastic\nvolatility model (Heston). Finally, we illustrate how our expansion can be used\nto perform a model-free calibration of the empirically observed implied\nvolatility surface.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.0233v5"
    },
    {
        "title": "The Exact Smile of some Local Volatility Models",
        "authors": [
            "Matthew Lorig"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We introduce a new class of local volatility models. Within this framework,\nwe obtain expressions for both (i) the price of any European option and (ii)\nthe induced implied volatility smile. As an illustration of our framework, we\nperform specific pricing and implied volatility computations for a CEV-like\nexample. Numerical examples are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.0750v4"
    },
    {
        "title": "The Smile of certain Lévy-type Models",
        "authors": [
            "Antoine Jacquier",
            "Matthew Lorig"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We consider a class of assets whose risk-neutral pricing dynamics are\ndescribed by an exponential L\\'evy-type process subject to default. The class\nof processes we consider features locally-dependent drift, diffusion and\ndefault-intensity as well as a locally-dependent L\\'evy measure. Using\ntechniques from regular perturbation theory and Fourier analysis, we derive a\nseries expansion for the price of a European-style option. We also provide\nprecise conditions under which this series expansion converges to the exact\nprice. Additionally, for a certain subclass of assets in our modeling\nframework, we derive an expansion for the implied volatility induced by our\noption pricing formula. The implied volatility expansion is exact within its\nradius of convergence. As an example of our framework, we propose a class of\nCEV-like L\\'evy-type models. Within this class, approximate option prices can\nbe computed by a single Fourier integral and approximate implied volatilities\nare explicit (i.e., no integration is required). Furthermore, the class of\nCEV-like L\\'evy-type models is shown to provide a tight fit to the implied\nvolatility surface of S{&}P500 index options.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.1630v5"
    },
    {
        "title": "Second Order Multiscale Stochastic Volatility Asymptotics: Stochastic\n  Terminal Layer Analysis & Calibration",
        "authors": [
            "Jean-Pierre Fouque",
            "Matthew Lorig",
            "Ronnie Sircar"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Multiscale stochastic volatility models have been developed as an efficient\nway to capture the principle effects on derivative pricing and portfolio\noptimization of randomly varying volatility. The recent book Fouque,\nPapanicolaou, Sircar and S{\\o}lna (2011, CUP) analyzes models in which the\nvolatility of the underlying is driven by two diffusions -- one fast\nmean-reverting and one slow-varying, and provides a first order approximation\nfor European option prices and for the implied volatility surface, which is\ncalibrated to market data. Here, we present the full second order asymptotics,\nwhich are considerably more complicated due to a terminal layer near the option\nexpiration time. We find that, to second order, the implied volatility\napproximation depends quadratically on log-moneyness, capturing the convexity\nof the implied volatility curve seen in data. We introduce a new probabilistic\napproach to the terminal layer analysis needed for the derivation of the second\norder singular perturbation term, and calibrate to S&P 500 options data.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.5802v6"
    },
    {
        "title": "Strong Convergence for Euler-Maruyama and Milstein Schemes with\n  Asymptotic Method",
        "authors": [
            "Hideyuki Tanaka",
            "Toshihiro Yamada"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Motivated by weak convergence results in the paper of Takahashi and Yoshida\n(2005), we show strong convergence for an accelerated Euler-Maruyama scheme\napplied to perturbed stochastic differential equations. The Milstein scheme\nwith the same acceleration is also discussed as an extended result. The\ntheoretical results can be applied to analyzing the multi-level Monte Carlo\nmethod originally developed by M.B. Giles. Several numerical experiments for\nthe SABR stochastic volatility model are presented in order to confirm the\nefficiency of the schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.0670v2"
    },
    {
        "title": "An introduction to particle integration methods: with applications to\n  risk and insurance",
        "authors": [
            "P. Del Moral",
            "G. W. Peters",
            "Ch. Vergé"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Interacting particle methods are increasingly used to sample from complex and\nhigh-dimensional distributions. These stochastic particle integration\ntechniques can be interpreted as an universal acceptance-rejection sequential\nparticle sampler equipped with adaptive and interacting recycling mechanisms.\nPractically, the particles evolve randomly around the space independently and\nto each particle is associated a positive potential function. Periodically,\nparticles with high potentials duplicate at the expense of low potential\nparticle which die. This natural genetic type selection scheme appears in\nnumerous applications in applied probability, physics, Bayesian statistics,\nsignal processing, biology, and information engineering. It is the intention of\nthis paper to introduce them to risk modeling. From a purely mathematical point\nof view, these stochastic samplers can be interpreted as Feynman-Kac particle\nintegration methods. These functional models are natural mathematical\nextensions of the traditional change of probability measures, commonly used to\ndesign an importance sampling strategy. In this article, we provide a brief\nintroduction to the stochastic modeling and the theoretical analysis of these\nparticle algorithms. Then we conclude with an illustration of a subset of such\nmethods to resolve important risk measure and capital estimation in risk and\ninsurance modelling.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.3851v2"
    },
    {
        "title": "Application of simplest random walk algorithms for pricing barrier\n  options",
        "authors": [
            "M. Krivko",
            "M. V. Tretyakov"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We demonstrate effectiveness of the first-order algorithm from [Milstein,\nTretyakov. Theory Prob. Appl. 47 (2002), 53-68] in application to barrier\noption pricing. The algorithm uses the weak Euler approximation far from\nbarriers and a special construction motivated by linear interpolation of the\nprice near barriers. It is easy to implement and is universal: it can be\napplied to various structures of the contracts including derivatives on\nmulti-asset correlated underlyings and can deal with various type of barriers.\nIn contrast to the Brownian bridge techniques currently commonly used for\npricing barrier options, the algorithm tested here does not require knowledge\nof trigger probabilities nor their estimates. We illustrate this algorithm via\npricing a barrier caplet, barrier trigger swap and barrier swaption.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.5726v1"
    },
    {
        "title": "Online Portfolio Selection: A Survey",
        "authors": [
            "Bin Li",
            "Steven C. H. Hoi"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  Online portfolio selection is a fundamental problem in computational finance,\nwhich has been extensively studied across several research communities,\nincluding finance, statistics, artificial intelligence, machine learning, and\ndata mining, etc. This article aims to provide a comprehensive survey and a\nstructural understanding of published online portfolio selection techniques.\nFrom an online machine learning perspective, we first formulate online\nportfolio selection as a sequential decision problem, and then survey a variety\nof state-of-the-art approaches, which are grouped into several major\ncategories, including benchmarks, \"Follow-the-Winner\" approaches,\n\"Follow-the-Loser\" approaches, \"Pattern-Matching\" based approaches, and\n\"Meta-Learning Algorithms\". In addition to the problem formulation and related\nalgorithms, we also discuss the relationship of these algorithms with the\nCapital Growth theory in order to better understand the similarities and\ndifferences of their underlying trading ideas. This article aims to provide a\ntimely and comprehensive survey for both machine learning and data mining\nresearchers in academia and quantitative portfolio managers in the financial\nindustry to help them understand the state-of-the-art and facilitate their\nresearch and practical applications. We also discuss some open issues and\nevaluate some emerging new trends for future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.2129v2"
    },
    {
        "title": "Sequential Design for Optimal Stopping Problems",
        "authors": [
            "Robert B. Gramacy",
            "Mike Ludkovski"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We propose a new approach to solve optimal stopping problems via simulation.\nWorking within the backward dynamic programming/Snell envelope framework, we\naugment the methodology of Longstaff-Schwartz that focuses on approximating the\nstopping strategy. Namely, we introduce adaptive generation of the stochastic\ngrids anchoring the simulated sample paths of the underlying state process.\nThis allows for active learning of the classifiers partitioning the state space\ninto the continuation and stopping regions. To this end, we examine sequential\ndesign schemes that adaptively place new design points close to the stopping\nboundaries. We then discuss dynamic regression algorithms that can implement\nsuch recursive estimation and local refinement of the classifiers. The new\nalgorithm is illustrated with a variety of numerical experiments, showing that\nan order of magnitude savings in terms of design size can be achieved. We also\ncompare with existing benchmarks in the context of pricing multi-dimensional\nBermudan options.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.3832v2"
    },
    {
        "title": "A primal-dual algorithm for BSDEs",
        "authors": [
            "Christian Bender",
            "Nikolaus Schweizer",
            "Jia Zhuo"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We generalize the primal-dual methodology, which is popular in the pricing of\nearly-exercise options, to a backward dynamic programming equation associated\nwith time discretization schemes of (reflected) backward stochastic\ndifferential equations (BSDEs). Taking as an input some approximate solution of\nthe backward dynamic program, which was pre-computed, e.g., by least-squares\nMonte Carlo, our methodology allows to construct a confidence interval for the\nunknown true solution of the time discretized (reflected) BSDE at time 0. We\nnumerically demonstrate the practical applicability of our method in two\nfive-dimensional nonlinear pricing problems where tight price bounds were\npreviously unavailable.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3694v2"
    },
    {
        "title": "Quantum harmonic oscillator in option pricing",
        "authors": [
            "Liviu-Adrian Cotfas",
            "Nicolae Cotfas"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  The Black-Scholes model anticipates rather well the observed prices for\noptions in the case of a strike price that is not too far from the current\nprice of the underlying asset. Some useful extensions can be obtained by an\nadequate modification of the coefficients in the Black-Scholes equation. We\ninvestigate from a mathematical point of view an extension directly related to\nthe quantum harmonic oscillator. In the considered case, the solution is the\nsum of a series involving the Hermite-Gauss functions. A finite-dimensional\nversion is obtained by using a finite oscillator and the Harper functions. This\nsimplified model keeps the essential characteristics of the continuous one and\nuses finite sums instead of series and integrals.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.4142v2"
    },
    {
        "title": "On strong binomial approximation for stochastic processes and\n  applications for financial modelling",
        "authors": [
            "Nikolai Dokuchaev"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  This paper considers binomial approximation of continuous time stochastic\nprocesses. It is shown that, under some mild integrability conditions, a\nprocess can be approximated in mean square sense and in other strong metrics by\nbinomial processes, i.e., by processes with fixed size binary increments at\nsampling points. Moreover, this approximation can be causal, i.e., at every\ntime it requires only past historical values of the underlying process. In\naddition, possibility of approximation of solutions of stochastic differential\nequations by solutions of ordinary equations with binary noise is established.\nSome consequences for the financial modelling and options pricing models are\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.0675v3"
    },
    {
        "title": "Filters and smoothers for self-exciting Markov modulated counting\n  processes",
        "authors": [
            "Samuel N. Cohen",
            "Robert J. Elliott"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  We consider a self-exciting counting process, the parameters of which depend\non a hidden finite-state Markov chain. We derive the optimal filter and\nsmoother for the hidden chain based on observation of the jump process. This\nfilter is in closed form and is finite dimensional. We demonstrate the\nperformance of this filter both with simulated data, and by analysing the\n`flash crash' of 6th May 2010 in this framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6257v1"
    },
    {
        "title": "Extrapolating the term structure of interest rates with parameter\n  uncertainty",
        "authors": [
            "Anne Balter",
            "Antoon Pelsser",
            "Peter Schotman"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  Pricing extremely long-dated liabilities market consistently deals with the\ndecline in liquidity of financial instruments on long maturities. The aim is to\nquantify the uncertainty of rates up to maturities of a century. We assume that\nthe interest rates follow the affine mean-reverting Vasicek model. We model\nparameter uncertainty by Bayesian distributions over the parameters. The\ncross-sectional and time series parameters are obtained via the restricted\nbivariate VAR(1) model. The empirical example shows extremely low confidence in\nlong term extrapolations due to the accumulated effect of the mean-reversion`s\nbehaviour close to the unit root.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.5073v1"
    },
    {
        "title": "Asset Prices and Risk Aversion",
        "authors": [
            "Dominique Pepin"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The standard asset pricing models (the CCAPM and the Epstein-Zin non-expected\nutility model) counterintuitively predict that equilibrium asset prices can\nrise if the representative agent's risk aversion increases. If the income\neffect, which implies enhanced saving as a result of an increase in risk\naversion, dominates the substitution effect, which causes the representative\nagent to reallocate his portfolio in favour of riskless assets, the demand for\nsecurities increases. Thus, asset prices are forced to rise when the\nrepresentative agent is more risk adverse. By disentangling risk aversion and\nintertemporal substituability, we demonstrate that the risky asset price is an\nincreasing function of the coefficient of risk aversion only if the elasticity\nof intertemporal substitution (EIS) exceeds unity. This result, which was first\nproved par Epstein (1988) in a stationary economy setting with a constant risk\naversion, is shown to hold true for non-stationary economies with a variable or\nconstant risk aversion coefficient. The conclusion is that the EIS probably\nexceeds unity.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.0851v1"
    },
    {
        "title": "High-speed detection of emergent market clustering via an unsupervised\n  parallel genetic algorithm",
        "authors": [
            "Dieter Hendricks",
            "Diane Wilcox",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  We implement a master-slave parallel genetic algorithm (PGA) with a bespoke\nlog-likelihood fitness function to identify emergent clusters within price\nevolutions. We use graphics processing units (GPUs) to implement a PGA and\nvisualise the results using disjoint minimal spanning trees (MSTs). We\ndemonstrate that our GPU PGA, implemented on a commercially available general\npurpose GPU, is able to recover stock clusters in sub-second speed, based on a\nsubset of stocks in the South African market. This represents a pragmatic\nchoice for low-cost, scalable parallel computing and is significantly faster\nthan a prototype serial implementation in an optimised C-based\nfourth-generation programming language, although the results are not directly\ncomparable due to compiler differences. Combined with fast online intraday\ncorrelation matrix estimation from high frequency data for cluster\nidentification, the proposed implementation offers cost-effective,\nnear-real-time risk assessment for financial practitioners.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.4099v4"
    },
    {
        "title": "What are the main drivers of the Bitcoin price? Evidence from wavelet\n  coherence analysis",
        "authors": [
            "Ladislav Kristoufek"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  Bitcoin has emerged as a fascinating phenomenon of the financial markets.\nWithout any central authority issuing the currency, it has been associated with\ncontroversy ever since its popularity and public interest reached high levels.\nHere, we contribute to the discussion by examining potential drivers of Bitcoin\nprices ranging from fundamental to speculative and technical sources as well as\na potential influence of the Chinese market. The evolution of the relationships\nis examined in both time and frequency domains utilizing the continuous\nwavelets framework so that we comment on development of the interconnections in\ntime but we can also distinguish between short-term and long-term connections.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0268v1"
    },
    {
        "title": "Integration of a Predictive, Continuous Time Neural Network into\n  Securities Market Trading Operations",
        "authors": [
            "Christopher S Kirk"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  This paper describes recent development and test implementation of a\ncontinuous time recurrent neural network that has been configured to predict\nrates of change in securities. It presents outcomes in the context of popular\ntechnical analysis indicators and highlights the potential impact of continuous\npredictive capability on securities market trading operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0968v1"
    },
    {
        "title": "Efficient solution of structural default models with correlated jumps\n  and mutual obligations",
        "authors": [
            "Andrey Itkin",
            "Alexander Lipton"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  The structural default model of Lipton and Sepp, 2009 is generalized for a\nset of banks with mutual interbank liabilities whose assets are driven by\ncorrelated Levy processes with idiosyncratic and common components. The\nmulti-dimensional problem is made tractable via a novel computational method,\nwhich generalizes the one-dimensional fractional partial differential equation\nmethod of Itkin, 2014 to the two- and three-dimensional cases. This method is\nunconditionally stable and of the second order of approximation in space and\ntime; in addition, for many popular Levy models it has linear complexity in\neach dimension. Marginal and joint survival probabilities for two and three\nbanks with mutual liabilities are computed. The effects of mutual liabilities\nare discussed, and numerical examples are given to illustrate these effects.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.6513v2"
    },
    {
        "title": "Efficient XVA Management: Pricing, Hedging, and Attribution using\n  Trade-Level Regression and Global Conditioning",
        "authors": [
            "Chris Kenyon",
            "Andrew Green"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  Banks must manage their trading books, not just value them. Pricing includes\nvaluation adjustments collectively known as XVA (at least credit, funding,\ncapital and tax), so management must also include XVA. In trading book\nmanagement we focus on pricing, hedging, and allocation of prices or hedging\ncosts to desks on an individual trade basis. We show how to combine three\ntechnical elements to radically simplify XVA management, both in terms of the\ncalculations, and the implementation of the calculations. The three technical\nelements are: trade-level regression; analytic computation of sensitivities;\nand global conditioning. All three are required to obtain the radical\nefficiency gains and implementation simplification. Moreover, many of the\ncalculations are inherently parallel and suitable for GPU implementation. The\nresulting methodology for XVA management is sufficiently general that we can\ncover pricing, first- and second-order sensitivities, and exact trade-level\nallocation of pricing and sensitivities within the same framework. Managing\nincremental changes to portfolios exactly is also radically simplified.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.5332v2"
    },
    {
        "title": "Explicit solution to dynamic portfolio choice problem : The\n  continuous-time detour",
        "authors": [
            "François Legendre",
            "Djibril Togola"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  This paper solves the dynamic portfolio choice problem. Using an explicit\nsolution with a power utility, we construct a bridge between a continuous and\ndiscrete VAR model to assess portfolio sensitivities. We find, from a well\nanalyzed example that the optimal allocation to stocks is particularly\nsensitive to Sharpe ratio. Our quantitative analysis highlights that this\nsensitivity increases when the risk aversion decreases and/or when the time\nhorizon increases. This finding explains the low accuracy of discrete numerical\nmethods especially along the tails of the unconditional distribution of the\nstate variable.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.03079v1"
    },
    {
        "title": "SMC-ABC methods for the estimation of stochastic simulation models of\n  the limit order book",
        "authors": [
            "Gareth W. Peters",
            "Efstathios Panayi",
            "Francois Septier"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  In this paper we consider classes of models that have been recently developed\nfor quantitative finance that involve modelling a highly complex multivariate,\nmulti-attribute stochastic process known as the Limit Order Book (LOB). The LOB\nis the primary data structure recorded each day intra-daily for all assets on\nevery electronic exchange in the world in which trading takes place. As such,\nit represents one of the most important fundamental structures to study from a\nstochastic process perspective if one wishes to characterize features of\nstochastic dynamics for price, volume, liquidity and other important attributes\nfor a traded asset. In this paper we aim to adopt the model structure which\ndevelops a stochastic model framework for the LOB of a given asset and to\nexplain how to perform calibration of this stochastic model to real observed\nLOB data for a range of different assets.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.05806v1"
    },
    {
        "title": "Financial Market Modeling with Quantum Neural Networks",
        "authors": [
            "Carlos Pedro Gonçalves"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  Econophysics has developed as a research field that applies the formalism of\nStatistical Mechanics and Quantum Mechanics to address Economics and Finance\nproblems. The branch of Econophysics that applies of Quantum Theory to\nEconomics and Finance is called Quantum Econophysics. In Finance, Quantum\nEconophysics' contributions have ranged from option pricing to market dynamics\nmodeling, behavioral finance and applications of Game Theory, integrating the\nempirical finding, from human decision analysis, that shows that nonlinear\nupdate rules in probabilities, leading to non-additive decision weights, can be\ncomputationally approached from quantum computation, with resulting quantum\ninterference terms explaining the non-additive probabilities. The current work\ndraws on these results to introduce new tools from Quantum Artificial\nIntelligence, namely Quantum Artificial Neural Networks as a way to build and\nsimulate financial market models with adaptive selection of trading rules,\nleading to turbulence and excess kurtosis in the returns distributions for a\nwide range of parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.06586v1"
    },
    {
        "title": "Nonlinear PDEs risen when solving some optimization problems in finance,\n  and their solutions",
        "authors": [
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We consider a specific type of nonlinear partial differential equations (PDE)\nthat appear in mathematical finance as the result of solving some optimization\nproblems. We review some existing in the literature examples of such problems,\nand discuss the properties of these PDEs. We also demonstrate how to solve them\nnumerically in a general case, and analytically in some particular case.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.04899v1"
    },
    {
        "title": "Pricing European and American Options under Heston Model using\n  Discontinuous Galerkin Finite Elements",
        "authors": [
            "Sinem Kozpınar",
            "Murat Uzunca",
            "Bülent Karasözen"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  This paper deals with pricing of European and American options, when the\nunderlying asset price follows Heston model, via the interior penalty\ndiscontinuous Galerkin finite element method (dGFEM). The advantages of dGFEM\nspace discretization with Rannacher smoothing as time integrator with nonsmooth\ninitial and boundary conditions are illustrated for European vanilla options,\ndigital call and American put options. The convection dominated Heston model\nfor vanishing volatility is efficiently solved utilizing the adaptive dGFEM.\nFor fast solution of the linear complementary problem of the American options,\na projected successive over relaxation (PSOR) method is developed with the norm\npreconditioned dGFEM. We show the efficiency and accuracy of dGFEM for option\npricing by conducting comparison analysis with other methods and numerical\nexperiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.08381v3"
    },
    {
        "title": "Filling the gaps smoothly",
        "authors": [
            "Andrey Itkin",
            "Alexander Lipton"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  The calibration of a local volatility models to a given set of option prices\nis a classical problem of mathematical finance. It was considered in multiple\npapers where various solutions were proposed. In this paper an extension of the\napproach proposed in LiptonSepp2011 is developed by i) replacing a piecewise\nconstant local variance construction with a piecewise linear one, and ii)\nallowing non-zero interest rates and dividend yields. Our approach remains\nanalytically tractable; it combines the Laplace transform in time with an\nanalytical solution of the resulting spatial equations in terms of Kummer's\ndegenerate hypergeometric functions.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.05145v1"
    },
    {
        "title": "RELARM: A rating model based on relative PCA attributes and k-means\n  clustering",
        "authors": [
            "Elnura Irmatova"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  Following widely used in visual recognition concept of relative attributes,\nthe article establishes definition of the relative PCA attributes for a class\nof objects defined by vectors of their parameters. A new rating model (RELARM)\nis built using relative PCA attribute ranking functions for rating object\ndescription and k-means clustering algorithm. Rating assignment of each rating\nobject to a rating category is derived as a result of cluster centers\nprojection on the specially selected rating vector. Empirical study has shown a\nhigh level of approximation to the existing S & P, Moody's and Fitch ratings.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.06416v1"
    },
    {
        "title": "Gated Neural Networks for Option Pricing: Rationality by Design",
        "authors": [
            "Yongxin Yang",
            "Yu Zheng",
            "Timothy M. Hospedales"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We propose a neural network approach to price EU call options that\nsignificantly outperforms some existing pricing models and comes with\nguarantees that its predictions are economically reasonable. To achieve this,\nwe introduce a class of gated neural networks that automatically learn to\ndivide-and-conquer the problem space for robust and accurate pricing. We then\nderive instantiations of these networks that are 'rational by design' in terms\nof naturally encoding a valid call option surface that enforces no arbitrage\nprinciples. This integration of human insight within data-driven learning\nprovides significantly better generalisation in pricing performance due to the\nencoded inductive bias in the learning, guarantees sanity in the model's\npredictions, and provides econometrically useful byproduct such as risk neutral\ndensity.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.07472v3"
    },
    {
        "title": "A dynamic approach merging network theory and credit risk techniques to\n  assess systemic risk in financial networks",
        "authors": [
            "Daniele Petrone",
            "Vito Latora"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  The interconnectedness of financial institutions affects instability and\ncredit crises. To quantify systemic risk we introduce here the PD model, a\ndynamic model that combines credit risk techniques with a contagion mechanism\non the network of exposures among banks. A potential loss distribution is\nobtained through a multi-period Monte Carlo simulation that considers the\nprobability of default (PD) of the banks and their tendency of defaulting in\nthe same time interval. A contagion process increases the PD of banks exposed\ntoward distressed counterparties. The systemic risk is measured by statistics\nof the loss distribution, while the contribution of each node is quantified by\nthe new measures PDRank and PDImpact. We illustrate how the model works on the\nnetwork of the European Global Systemically Important Banks. For a certain\nrange of the banks' capital and of their assets volatility, our results reveal\nthe emergence of a strong contagion regime where lower default correlation\nbetween banks corresponds to higher losses. This is the opposite of the\ndiversification benefits postulated by standard credit risk models used by\nbanks and regulators who could therefore underestimate the capital needed to\novercome a period of crisis, thereby contributing to the financial system\ninstability.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.00795v2"
    },
    {
        "title": "Mini-symposium on automatic differentiation and its applications in the\n  financial industry",
        "authors": [
            "Sébastien Geeraert",
            "Charles-Albert Lehalle",
            "Barak Pearlmutter",
            "Olivier Pironneau",
            "Adil Reghai"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Automatic differentiation is involved for long in applied mathematics as an\nalternative to finite difference to improve the accuracy of numerical\ncomputation of derivatives. Each time a numerical minimization is involved,\nautomatic differentiation can be used. In between formal derivation and\nstandard numerical schemes, this approach is based on software solutions\napplying mechanically the chain rule to obtain an exact value for the desired\nderivative. It has a cost in memory and cpu consumption. For participants of\nfinancial markets (banks, insurances, financial intermediaries, etc), computing\nderivatives is needed to obtain the sensitivity of its exposure to well-defined\npotential market moves. It is a way to understand variations of their balance\nsheets in specific cases. Since the 2008 crisis, regulation demand to compute\nthis kind of exposure to many different case, to be sure market participants\nare aware and ready to face a wide spectrum of configurations. This paper shows\nhow automatic differentiation provides a partial answer to this recent\nexplosion of computation to perform. One part of the answer is a\nstraightforward application of Adjoint Algorithmic Differentiation (AAD), but\nit is not enough. Since financial sensitivities involves specific functions and\nmix differentiation with Monte-Carlo simulations, dedicated tools and\nassociated theoretical results are needed. We give here short introductions to\ntypical cases arising when one use AAD on financial markets.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.02311v2"
    },
    {
        "title": "Bartlett's delta in the SABR model",
        "authors": [
            "Patrick S. Hagan",
            "Andrew Lesniewski"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We refine the analysis of hedging strategies for options under the SABR model\ncarried out in [2]. In particular, we provide a theoretical justification of\nthe empirical observation made in [2] that the modified delta (\"Bartlett's\ndelta\") introduced there provides a more accurate and robust hedging strategy\nthan the conventional SABR delta hedge.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.03110v2"
    },
    {
        "title": "Optimal client recommendation for market makers in illiquid financial\n  products",
        "authors": [
            "Dieter Hendricks",
            "Stephen J. Roberts"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The process of liquidity provision in financial markets can result in\nprolonged exposure to illiquid instruments for market makers. In this case,\nwhere a proprietary position is not desired, pro-actively targeting the right\nclient who is likely to be interested can be an effective means to offset this\nposition, rather than relying on commensurate interest arising through natural\ndemand. In this paper, we consider the inference of a client profile for the\npurpose of corporate bond recommendation, based on typical recorded information\navailable to the market maker. Given a historical record of corporate bond\ntransactions and bond meta-data, we use a topic-modelling analogy to develop a\nprobabilistic technique for compiling a curated list of client recommendations\nfor a particular bond that needs to be traded, ranked by probability of\ninterest. We show that a model based on Latent Dirichlet Allocation offers\npromising performance to deliver relevant recommendations for sales traders.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.08488v1"
    },
    {
        "title": "Influence of jump-at-default in IR and FX on Quanto CDS prices",
        "authors": [
            "A. Itkin",
            "V. Shcherbakov",
            "A. Veygman"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We propose a new model for pricing Quanto CDS and risky bonds. The model\noperates with four stochastic factors, namely: hazard rate, foreign exchange\nrate, domestic interest rate, and foreign interest rate, and also allows for\njumps-at-default in the FX and foreign interest rates. Corresponding systems of\nPDEs are derived similar to how this is done in Bielecki at al., 2005. A\nlocalized version of the RBF partition of unity method is used to solve these\n4D PDEs. The results of our numerical experiments presented in the paper\nqualitatively explain the discrepancies observed in the marked values of CDS\nspreads traded in domestic and foreign economies.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.07133v1"
    },
    {
        "title": "Pricing Derivatives under Multiple Stochastic Factors by Localized\n  Radial Basis Function Methods",
        "authors": [
            "Slobodan Milovanović",
            "Victor Shcherbakov"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We propose two localized Radial Basis Function (RBF) methods, the Radial\nBasis Function Partition of Unity method (RBF-PUM) and the Radial Basis\nFunction generated Finite Differences method (RBF-FD), for solving financial\nderivative pricing problems arising from market models with multiple stochastic\nfactors. We demonstrate the useful features of the proposed methods, such as\nhigh accuracy, sparsity of the differentiation matrices, mesh-free nature and\nmulti-dimensional extendability, and show how to apply these methods for\nsolving time-dependent higher-dimensional PDEs in finance. We test these\nmethods on several problems that incorporate stochastic asset, volatility, and\ninterest rate dynamics by conducting numerical experiments. The results\nillustrate the capability of both methods to solve the problems to a sufficient\naccuracy within reasonable time. Both methods exhibit similar orders of\nconvergence, which can be further improved by a more elaborate choice of the\nmethod parameters. Finally, we discuss the parallelization potentials of the\nproposed methods and report the speedup on the example of RBF-FD.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09852v2"
    },
    {
        "title": "Valuing Exchange Options Under an Ornstein-Uhlenbeck Covariance Model",
        "authors": [
            "Olivares Pablo",
            "Villamor Enrique"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this paper we study the pricing of exchange options under a dynamic\ndescribed by stochastic correlation with random jumps. In particular, we\nconsider a Ornstein-Uhlenbeck covariance model with Levy Background Noise\nProcess driven by Inverse Gaussian subordinators. We use expansion in terms of\nTaylor polynomials and cubic splines to approximately compute the price of the\nderivative contract. Our findings show that this approach provides an efficient\nway to compute the price when compared with a Monte Carlo method while\nmaintaining an equivalent degree of accuracy with the latter.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10013v1"
    },
    {
        "title": "A threshold model for local volatility: evidence of leverage and mean\n  reversion effects on historical data",
        "authors": [
            "Antoine Lejay",
            "Paolo Pigato"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In financial markets, low prices are generally associated with high\nvolatilities and vice-versa, this well known stylized fact usually being\nreferred to as leverage effect. We propose a local volatility model, given by a\nstochastic differential equation with piecewise constant coefficients, which\naccounts of leverage and mean-reversion effects in the dynamics of the prices.\nThis model exhibits a regime switch in the dynamics accordingly to a certain\nthreshold. It can be seen as a continuous-time version of the Self-Exciting\nThreshold Autoregressive (SETAR) model. We propose an estimation procedure for\nthe volatility and drift coefficients as well as for the threshold level.\nParameters estimated on the daily prices of 348 stocks of NYSE and S\\&P 500, on\ndifferent time windows, show consistent empirical evidence for leverageeffects.\nMean-reversion effects are also detected, most markedly in crisis periods.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.08329v4"
    },
    {
        "title": "SABCEMM-A Simulator for Agent-Based Computational Economic Market Models",
        "authors": [
            "Torsten Trimborn",
            "Philipp Otte",
            "Simon Cramer",
            "Max Beikirch",
            "Emma Pabich",
            "Martin Frank"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We introduce the simulation tool SABCEMM (Simulator for Agent-Based\nComputational Economic Market Models) for agent-based computational economic\nmarket (ABCEM) models. Our simulation tool is implemented in C++ and we can\neasily run ABCEM models with several million agents. The object-oriented\nsoftware design enables the isolated implementation of building blocks for\nABCEM models, such as agent types and market mechanisms. The user can design\nand compare ABCEM models in a unified environment by recombining existing\nbuilding blocks using the XML-based SABCEMM configuration file. We introduce an\nabstract ABCEM model class which our simulation tool is built upon.\nFurthermore, we present the software architecture as well as computational\naspects of SABCEMM. Here, we focus on the efficiency of SABCEMM with respect to\nthe run time of our simulations. We show the great impact of different random\nnumber generators on the run time of ABCEM models. The code and documentation\nis published on GitHub at https://github.com/SABCEMM/SABCEMM, such that all\nresults can be reproduced by the reader.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.01811v2"
    },
    {
        "title": "Stock returns forecast: an examination by means of Artificial Neural\n  Networks",
        "authors": [
            "Martin Iglesias Caride",
            "Aurelio F. Bariviera",
            "Laura Lanzarini"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The validity of the Efficient Market Hypothesis has been under severe\nscrutiny since several decades. However, the evidence against it is not\nconclusive. Artificial Neural Networks provide a model-free means to analize\nthe prediction power of past returns on current returns. This chapter analizes\nthe predictability in the intraday Brazilian stock market using a\nbackpropagation Artificial Neural Network. We selected 20 stocks from Bovespa\nindex, according to different market capitalization, as a proxy for stock size.\nWe find that predictability is related to capitalization. In particular, larger\nstocks are less predictable than smaller ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07960v1"
    },
    {
        "title": "Generating virtual scenarios of multivariate financial data for\n  quantitative trading applications",
        "authors": [
            "Javier Franco-Pedroso",
            "Joaquin Gonzalez-Rodriguez",
            "Jorge Cubero",
            "Maria Planas",
            "Rafael Cobo",
            "Fernando Pablos"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we present a novel approach to the generation of virtual\nscenarios of multivariate financial data of arbitrary length and composition of\nassets. With this approach, decades of realistic time-synchronized data can be\nsimulated for a large number of assets, producing diverse scenarios to test and\nimprove quantitative investment strategies. Our approach is based on the\nanalysis and synthesis of the time-dependent individual and joint\ncharacteristics of real financial time series, using stochastic sequences of\nmarket trends to draw multivariate returns from time-dependent probability\nfunctions preserving both distributional properties of asset returns and\ntime-dependent correlation among time series. Moreover, new time-synchronized\nassets can be arbitrarily generated through a PCA-based procedure to obtain any\nnumber of assets in the final virtual scenario. For the validation of such\nsimulated data, they are tested with an extensive set of measurements showing a\nsignificant degree of agreement with the reference performance of real\nfinancial series, better than that obtained with other classical and\nstate-of-the-art approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01861v1"
    },
    {
        "title": "An Expanded Local Variance Gamma model",
        "authors": [
            "Peter Carr",
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The paper proposes an expanded version of the Local Variance Gamma model of\nCarr and Nadtochiy by adding drift to the governing underlying process. Still\nin this new model it is possible to derive an ordinary differential equation\nfor the option price which plays a role of Dupire's equation for the standard\nlocal volatility model. It is shown how calibration of multiple smiles (the\nwhole local volatility surface) can be done in such a case. Further, assuming\nthe local variance to be a piecewise linear function of strike and piecewise\nconstant function of time this ODE is solved in closed form in terms of\nConfluent hypergeometric functions. Calibration of the model to market smiles\ndoes not require solving any optimization problem and, in contrast, can be done\nterm-by-term by solving a system of non-linear algebraic equations for each\nmaturity, which is fast.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.09611v2"
    },
    {
        "title": "Robust calibration and arbitrage-free interpolation of SSVI slices",
        "authors": [
            "Pierre Cohort",
            "Jacopo Corbetta",
            "Claude Martini",
            "Ismail Laachir"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We describe a robust calibration algorithm of a set of SSVI slices (i.e. a\nset of 3 SSVI parameters $\\theta, \\rho, \\varphi$ attached to each option\nmaturity available on the market), which grants that these slices are free of\nButterfly and Calendar-Spread arbitrage. Given such a set of consistent SSVI\nparameters, we show that the most natural interpolation/extrapolation of the\nparameters provides a full continuous volatility surface free of arbitrage. The\nnumerical implementation is straightforward, robust and quick, yielding an\neffective, parsimonious solution to the smile problem, which has the potential\nto become a benchmark one.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04924v2"
    },
    {
        "title": "Aggregating multiple types of complex data in stock market prediction: A\n  model-independent framework",
        "authors": [
            "Huiwen Wang",
            "Shan Lu",
            "Jichang Zhao"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The increasing richness in volume, and especially types of data in the\nfinancial domain provides unprecedented opportunities to understand the stock\nmarket more comprehensively and makes the price prediction more accurate than\nbefore. However, they also bring challenges to classic statistic approaches\nsince those models might be constrained to a certain type of data. Aiming at\naggregating differently sourced information and offering type-free capability\nto existing models, a framework for predicting stock market of scenarios with\nmixed data, including scalar data, compositional data (pie-like) and functional\ndata (curve-like), is established. The presented framework is\nmodel-independent, as it serves like an interface to multiple types of data and\ncan be combined with various prediction models. And it is proved to be\neffective through numerical simulations. Regarding to price prediction, we\nincorporate the trading volume (scalar data), intraday return series\n(functional data), and investors' emotions from social media (compositional\ndata) through the framework to competently forecast whether the market goes up\nor down at opening in the next day. The strong explanatory power of the\nframework is further demonstrated. Specifically, it is found that the intraday\nreturns impact the following opening prices differently between bearish market\nand bullish market. And it is not at the beginning of the bearish market but\nthe subsequent period in which the investors' \"fear\" comes to be indicative.\nThe framework would help extend existing prediction models easily to scenarios\nwith multiple types of data and shed light on a more systemic understanding of\nthe stock market.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.05617v1"
    },
    {
        "title": "Quantitative approach to multifractality induced by correlations and\n  broad distribution of data",
        "authors": [
            "Rafal Rak",
            "Dariusz Grech"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We analyze quantitatively the effect of spurious multifractality induced by\nthe presence of fat-tailed symmetric and asymmetric probability distributions\nof fluctuations in time series. In the presented approach different kinds of\nsymmetric and asymmetric broad probability distributions of synthetic data are\nexamined starting from Levy regime up to those with finite variance. We use\nnonextensive Tsallis statistics to construct all considered data in order to\nhave good analytical description of frequencies of fluctuations in the whole\nrange of their magnitude and simultaneously the full control over exponent of\npower-law decay for tails of probability distribution. The semi-analytical\ncompact formulas are then provided to express the level of spurious\nmultifractality generated by the presence of fat tails in terms of Tsallis\nparameter $\\tilde{q}$ and the scaling exponent $\\beta$ of the asymptotic decay\nof cumulated probability density function (CDF).The results are presented in\nHurst and H\\\"{o}lder languages - more often used in study of multifractal\nphenomena. According to the provided semi-analytical relations, it is argued\nhow one can make a clear quantitative distinction for any real data between\ntrue multifractality caused by the presence of nonlinear correlations, spurious\nmultifractality generated by fat-tailed shape of distributions - eventually\nwith their asymmetry, and the correction due to linear autocorrelations in\nanalyzed time series of finite length. In particular, the spurious multifractal\neffect of fat tails is found basic for proper quantitative estimation of all\nspurious multifractal effects. Examples from stock market data are presented to\nsupport these findings.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.11909v1"
    },
    {
        "title": "Leave-one-out least squares Monte Carlo algorithm for pricing Bermudan\n  options",
        "authors": [
            "Jeechul Woo",
            "Chenru Liu",
            "Jaehyuk Choi"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  The least squares Monte Carlo (LSM) algorithm proposed by Longstaff and\nSchwartz (2001) is widely used for pricing Bermudan options. The LSM estimator\ncontains undesirable look-ahead bias, and the conventional technique of\navoiding it requires additional simulation paths. We present the leave-one-out\nLSM (LOOLSM) algorithm to eliminate look-ahead bias without doubling\nsimulations. We also show that look-ahead bias is asymptotically proportional\nto the regressors-to-paths ratio. Our findings are demonstrated with several\noption examples in which the LSM algorithm overvalues the options. The LOOLSM\nmethod can be extended to other regression-based algorithms that improve the\nLSM method.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02071v4"
    },
    {
        "title": "Unbiased deep solvers for linear parametric PDEs",
        "authors": [
            "Marc Sabate Vidales",
            "David Siska",
            "Lukasz Szpruch"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We develop several deep learning algorithms for approximating families of\nparametric PDE solutions. The proposed algorithms approximate solutions\ntogether with their gradients, which in the context of mathematical finance\nmeans that the derivative prices and hedging strategies are computed\nsimulatenously. Having approximated the gradient of the solution one can\ncombine it with a Monte-Carlo simulation to remove the bias in the deep network\napproximation of the PDE solution (derivative price). This is achieved by\nleveraging the Martingale Representation Theorem and combining the Monte Carlo\nsimulation with the neural network. The resulting algorithm is robust with\nrespect to quality of the neural network approximation and consequently can be\nused as a black-box in case only limited a priori information about the\nunderlying problem is available. We believe this is important as neural network\nbased algorithms often require fair amount of tuning to produce satisfactory\nresults. The methods are empirically shown to work for high-dimensional\nproblems (e.g. 100 dimensions). We provide diagnostics that shed light on\nappropriate network architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.05094v4"
    },
    {
        "title": "A volatility-of-volatility expansion of the option prices in the SABR\n  stochastic volatility model",
        "authors": [
            "Olesya Grishchenko",
            "Xiao Han",
            "Victor Nistor"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We propose a general, very fast method to quickly approximate the solution of\na parabolic Partial Differential Equation (PDEs) with explicit formulas. Our\nmethod also provides equaly fast approximations of the derivatives of the\nsolution, which is a challenge for many other methods. Our approach is based on\na computable series expansion in terms of a \"small\" parameter. As an example,\nwe treat in detail the important case of the SABR PDE for $\\beta = 1$, namely\n$\\partial_{\\tau}u = \\sigma^2 \\big [ \\frac{1}{2} (\\partial^2_xu - \\partial_xu) +\n\\nu \\rho \\partial_x\\partial_\\sigma u + \\frac{1}{2} \\nu^2 \\partial^2_\\sigma u \\,\n\\big ] + \\kappa (\\theta - \\sigma) \\partial_\\sigma$, by choosing $\\nu$ as small\nparameter. This yields $u = u_0 + \\nu u_1 + \\nu^2 u_2 + \\ldots$, with $u_j$\nindependent of $\\nu$. The terms $u_j$ are explicitly computable, which is also\na challenge for many other, related methods. Truncating this expansion leads to\ncomputable approximations of $u$ that are in \"closed form,\" and hence can be\nevaluated very quickly. Most of the other related methods use the \"time\" $\\tau$\nas a small parameter. The advantage of our method is that it leads to shorter\nand hence easier to determine and to generalize formulas. We obtain also an\nexplicit expansion for the implied volatility in the SABR model in terms of\n$\\nu$, similar to Hagan's formula, but including also the {\\em mean reverting\nterm.} We provide several numerical tests that show the performance of our\nmethod. In particular, we compare our formula to the one due to Hagan. Our\nresults also behave well when used for actual market data and show the mean\nreverting property of the volatility.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.09904v1"
    },
    {
        "title": "Pricing foreign exchange options under stochastic volatility and\n  interest rates using an RBF--FD method",
        "authors": [
            "Fazlollah Soleymani",
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  This paper proposes a numerical method for pricing foreign exchange (FX)\noptions in a model which deals with stochastic interest rates and stochastic\nvolatility of the FX rate. The model considers four stochastic drivers, each\nrepresented by an It\\^{o}'s diffusion with time--dependent drift, and with a\nfull matrix of correlations. It is known that prices of FX options in this\nmodel can be found by solving an associated backward partial differential\nequation (PDE). However, it contains non--affine terms, which makes its\ndifficult to solve it analytically. Also, a standard approach of solving it\nnumerically by using traditional finite--difference (FD) or finite elements\n(FE) methods suffers from the high computational burden. Therefore, in this\npaper a flavor of a localized radial basis functions (RBFs) method, RBF--FD, is\ndeveloped which allows for a good accuracy at a relatively low computational\ncost. Results of numerical simulations are presented which demonstrate\nefficiency of such an approach in terms of both performance and accuracy for\npricing FX options and computation of the associated Greeks.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.00937v1"
    },
    {
        "title": "Learning the dynamics of technical trading strategies",
        "authors": [
            "Nicholas Murphy",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We use an adversarial expert based online learning algorithm to learn the\noptimal parameters required to maximise wealth trading zero-cost portfolio\nstrategies. The learning algorithm is used to determine the relative population\ndynamics of technical trading strategies that can survive historical\nback-testing as well as form an overall aggregated portfolio trading strategy\nfrom the set of underlying trading strategies implemented on daily and intraday\nJohannesburg Stock Exchange data. The resulting population time-series are\ninvestigated using unsupervised learning for dimensionality reduction and\nvisualisation. A key contribution is that the overall aggregated trading\nstrategies are tested for statistical arbitrage using a novel hypothesis test\nproposed by Jarrow et al. (2012) on both daily sampled and intraday\ntime-scales. The (low frequency) daily sampled strategies fail the arbitrage\ntests after costs, while the (high frequency) intraday sampled strategies are\nnot falsified as statistical arbitrages after costs. The estimates of trading\nstrategy success, cost of trading and slippage are considered along with an\nonline benchmark portfolio algorithm for performance comparison. In addition,\nthe algorithms generalisation error is analysed by recovering a probability of\nback-test overfitting estimate using a nonparametric procedure introduced by\nBailey et al. (2016). The work aims to explore and better understand the\ninterplay between different technical trading strategies from a data-informed\nperspective.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.02228v3"
    },
    {
        "title": "Multigrid Iterative Algorithm based on Compact Finite Difference Schemes\n  and Hermite interpolation for Solving Regime Switching American Options",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We present a multigrid iterative algorithm for solving a system of coupled\nfree boundary problems for pricing American put options with regime-switching.\nThe algorithm is based on our recently developed compact finite difference\nscheme coupled with Hermite interpolation for solving the coupled partial\ndifferential equations consisting of the asset option and the delta, gamma, and\nspeed sensitivities. In the algorithm, we first use the Gauss-Seidel method as\na smoother and then implement a multigrid strategy based on modified cycle\n(M-cycle) for solving our discretized equations. Hermite interpolation with\nNewton interpolatory divided difference (as the basis) is used in estimating\nthe coupled asset, delta, gamma, and speed options in the set of equations. A\nnumerical experiment is performed with the two- and four- regime examples and\ncompared with other existing methods to validate the optimal strategy. Results\nshow that this algorithm provides a fast and efficient tool for pricing\nAmerican put options with regime-switching.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.00925v5"
    },
    {
        "title": "Fast Agent-Based Simulation Framework with Applications to Reinforcement\n  Learning and the Study of Trading Latency Effects",
        "authors": [
            "Peter Belcak",
            "Jan-Peter Calliess",
            "Stefan Zohren"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We introduce a new software toolbox for agent-based simulation. Facilitating\nrapid prototyping by offering a user-friendly Python API, its core rests on an\nefficient C++ implementation to support simulation of large-scale multi-agent\nsystems. Our software environment benefits from a versatile message-driven\narchitecture. Originally developed to support research on financial markets, it\noffers the flexibility to simulate a wide-range of different (easily\ncustomisable) market rules and to study the effect of auxiliary factors, such\nas delays, on the market dynamics. As a simple illustration, we employ our\ntoolbox to investigate the role of the order processing delay in normal trading\nand for the scenario of a significant price change. Owing to its general\narchitecture, our toolbox can also be employed as a generic multi-agent system\nsimulator. We provide an example of such a non-financial application by\nsimulating a mechanism for the coordination of no-regret learning agents in a\nmulti-agent network routing scenario previously proposed in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.07871v3"
    },
    {
        "title": "Deep Learning for Constrained Utility Maximisation",
        "authors": [
            "Ashley Davey",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper proposes two algorithms for solving stochastic control problems\nwith deep learning, with a focus on the utility maximisation problem. The first\nalgorithm solves Markovian problems via the Hamilton Jacobi Bellman (HJB)\nequation. We solve this highly nonlinear partial differential equation (PDE)\nwith a second order backward stochastic differential equation (2BSDE)\nformulation. The convex structure of the problem allows us to describe a dual\nproblem that can either verify the original primal approach or bypass some of\nthe complexity. The second algorithm utilises the full power of the duality\nmethod to solve non-Markovian problems, which are often beyond the scope of\nstochastic control solvers in the existing literature. We solve an adjoint BSDE\nthat satisfies the dual optimality conditions. We apply these algorithms to\nproblems with power, log and non-HARA utilities in the Black-Scholes, the\nHeston stochastic volatility, and path dependent volatility models. Numerical\nexperiments show highly accurate results with low computational cost,\nsupporting our proposed algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.11757v2"
    },
    {
        "title": "Modeling the price of Bitcoin with geometric fractional Brownian motion:\n  a Monte Carlo approach",
        "authors": [
            "Mariusz Tarnopolski"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  The long-term dependence of Bitcoin (BTC), manifesting itself through a Hurst\nexponent $H>0.5$, is exploited in order to predict future BTC/USD price. A\nMonte Carlo simulation with $10^4$ geometric fractional Brownian motion\nrealisations is performed as extensions of historical data. The accuracy of\nstatistical inferences is 10\\%. The most probable Bitcoin price at the\nbeginning of 2018 is 6358 USD.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.03746v3"
    },
    {
        "title": "Automatic Backward Differentiation for American Monte-Carlo Algorithms\n  (Conditional Expectation)",
        "authors": [
            "Christian P. Fries"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  In this note we derive the backward (automatic) differentiation (adjoint\n[automatic] differentiation) for an algorithm containing a conditional\nexpectation operator. As an example we consider the backward algorithm as it is\nused in Bermudan product valuation, but the method is applicable in full\ngenerality.\n  The method relies on three simple properties: 1) a forward or backward\n(automatic) differentiation of an algorithm containing a conditional\nexpectation operator results in a linear combination of the conditional\nexpectation operators; 2) the differential of an expectation is the expectation\nof the differential $\\frac{d}{dx} E(Y) = E(\\frac{d}{dx}Y)$; 3) if we are only\ninterested in the expectation of the final result (as we are in all valuation\nproblems), we may use $E(A \\cdot E(B\\vert\\mathcal{F})) = E(E(A\\vert\\mathcal{F})\n\\cdot B)$, i.e., instead of applying the (conditional) expectation operator to\na function of the underlying random variable (continuation values), it may be\napplied to the adjoint differential. \\end{enumerate}\n  The methodology not only allows for a very clean and simple implementation,\nbut also offers the ability to use different conditional expectation estimators\nin the valuation and the differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.04942v1"
    },
    {
        "title": "Equal Risk Pricing of Derivatives with Deep Hedging",
        "authors": [
            "Alexandre Carbonneau",
            "Frédéric Godin"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This article presents a deep reinforcement learning approach to price and\nhedge financial derivatives. This approach extends the work of Guo and Zhu\n(2017) who recently introduced the equal risk pricing framework, where the\nprice of a contingent claim is determined by equating the optimally hedged\nresidual risk exposure associated respectively with the long and short\npositions in the derivative. Modifications to the latter scheme are considered\nto circumvent theoretical pitfalls associated with the original approach.\nDerivative prices obtained through this modified approach are shown to be\narbitrage-free. The current paper also presents a general and tractable\nimplementation for the equal risk pricing framework inspired by the deep\nhedging algorithm of Buehler et al. (2019). An $\\epsilon$-completeness measure\nallowing for the quantification of the residual hedging risk associated with a\nderivative is also proposed. The latter measure generalizes the one presented\nin Bertsimas et al. (2001) based on the quadratic penalty. Monte Carlo\nsimulations are performed under a large variety of market dynamics to\ndemonstrate the practicability of our approach, to perform benchmarking with\nrespect to traditional methods and to conduct sensitivity analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08492v2"
    },
    {
        "title": "The role of adaptivity in a numerical method for the Cox-Ingersoll-Ross\n  model",
        "authors": [
            "Cónall Kelly",
            "Gabriel Lord",
            "Heru Maulana"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We demonstrate the effectiveness of an adaptive explicit Euler method for the\napproximate solution of the Cox-Ingersoll-Ross model. This relies on a class of\npath-bounded timestepping strategies which work by reducing the stepsize as\nsolutions approach a neighbourhood of zero. The method is hybrid in the sense\nthat a convergent backstop method is invoked if the timestep becomes too small,\nor to prevent solutions from overshooting zero and becoming negative. Under\nparameter constraints that imply Feller's condition, we prove that such a\nscheme is strongly convergent, of order at least 1/2. Control of the strong\nerror is important for multi-level Monte Carlo techniques. Under Feller's\ncondition we also prove that the probability of ever needing the backstop\nmethod to prevent a negative value can be made arbitrarily small. Numerically,\nwe compare this adaptive method to fixed step implicit and explicit schemes,\nand a novel semi-implicit adaptive variant. We observe that the adaptive\napproach leads to methods that are competitive in a domain that extends beyond\nFeller's condition, indicating suitability for the modelling of stochastic\nvolatility in Heston-type asset models.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.10206v2"
    },
    {
        "title": "Predictive intraday correlations in stable and volatile market\n  environments: Evidence from deep learning",
        "authors": [
            "Ben Moews",
            "Gbenga Ibikunle"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Standard methods and theories in finance can be ill-equipped to capture\nhighly non-linear interactions in financial prediction problems based on\nlarge-scale datasets, with deep learning offering a way to gain insights into\ncorrelations in markets as complex systems. In this paper, we apply deep\nlearning to econometrically constructed gradients to learn and exploit lagged\ncorrelations among S&P 500 stocks to compare model behaviour in stable and\nvolatile market environments, and under the exclusion of target stock\ninformation for predictions. In order to measure the effect of time horizons,\nwe predict intraday and daily stock price movements in varying interval lengths\nand gauge the complexity of the problem at hand with a modification of our\nmodel architecture. Our findings show that accuracies, while remaining\nsignificant and demonstrating the exploitability of lagged correlations in\nstock markets, decrease with shorter prediction horizons. We discuss\nimplications for modern finance theory and our work's applicability as an\ninvestigative tool for portfolio managers. Lastly, we show that our model's\nperformance is consistent in volatile markets by exposing it to the environment\nof the recent financial crisis of 2007/2008.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.10385v1"
    },
    {
        "title": "Fast Lower and Upper Estimates for the Price of Constrained Multiple\n  Exercise American Options by Single Pass Lookahead Search and\n  Nearest-Neighbor Martingale",
        "authors": [
            "Nicolas Essis-Breton",
            "Patrice Gaillardetz"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This article presents fast lower and upper estimates for a large class of\noptions: the class of constrained multiple exercise American options. Typical\noptions in this class are swing options with volume and timing constraints, and\npassport options with multiple lookback rights. The lower estimate algorithm\nuses the artificial intelligence method of lookahead search. The upper estimate\nalgorithm uses the dual approach to option pricing on a nearest-neighbor basis\nfor the martingale space. Probabilistic convergence guarantees are provided.\nSeveral numerical examples illustrate the approaches including a swing option\nwith four constraints, and a passport option with 16 constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.11258v1"
    },
    {
        "title": "Model order reduction for parametric high dimensional models in the\n  analysis of financial risk",
        "authors": [
            "Andreas Binder",
            "Onkar Jadhav",
            "Volker Mehrmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper presents a model order reduction (MOR) approach for high\ndimensional problems in the analysis of financial risk. To understand the\nfinancial risks and possible outcomes, we have to perform several thousand\nsimulations of the underlying product. These simulations are expensive and\ncreate a need for efficient computational performance. Thus, to tackle this\nproblem, we establish a MOR approach based on a proper orthogonal decomposition\n(POD) method. The study involves the computations of high dimensional\nparametric convection-diffusion reaction partial differential equations (PDEs).\nPOD requires to solve the high dimensional model at some parameter values to\ngenerate a reduced-order basis. We propose an adaptive greedy sampling\ntechnique based on surrogate modeling for the selection of the sample parameter\nset that is analyzed, implemented, and tested on the industrial data. The\nresults obtained for the numerical example of a floater with cap and floor\nunder the Hull-White model indicate that the MOR approach works well for\nshort-rate models.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.11976v2"
    },
    {
        "title": "An identity of hitting times and its application to the valuation of\n  guaranteed minimum withdrawal benefit",
        "authors": [
            "Runhuan Feng",
            "Hans W. Volkmer"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  In this paper we explore an identity in distribution of hitting times of a\nfinite variation process (Yor's process) and a diffusion process (geometric\nBrownian motion with affine drift), which arise from various applications in\nfinancial mathematics. As a result, we provide analytical solutions to the fair\ncharge of variable annuity guaranteed minimum withdrawal benefit (GMWB) from a\npolicyholder's point of view, which was only previously obtained in the\nliterature by numerical methods. We also use complex inversion methods to\nderive analytical solutions to the fair charge of the GMWB from an insurer's\npoint of view, which is used in the market practice, however, based on Monte\nCarlo simulations. Despite of their seemingly different formulations, we can\nprove under certain assumptions the two pricing approaches are equivalent.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7070v1"
    },
    {
        "title": "The least squares method for option pricing revisited",
        "authors": [
            "Maciej Klimek",
            "Marcin Pitera"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  It is shown that the the popular least squares method of option pricing\nconverges even under very general assumptions. This substantially increases the\nfreedom of creating different implementations of the method, with varying\nlevels of computational complexity and flexible approach to regression. It is\nalso argued that in many practical applications even modest non-linear\nextensions of standard regression may produce satisfactory results. This claim\nis illustrated with examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.7438v3"
    },
    {
        "title": "Modeling stochastic skew of FX options using SLV models with stochastic\n  spot/vol correlation and correlated jumps",
        "authors": [
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  It is known that the implied volatility skew of FX options demonstrates a\nstochastic behavior which is called stochastic skew. In this paper we create\nstochastic skew by assuming the spot/instantaneous variance correlation to be\nstochastic. Accordingly, we consider a class of SLV models with stochastic\ncorrelation where all drivers - the spot, instantaneous variance and their\ncorrelation are modeled by Levy processes. We assume all diffusion components\nto be fully correlated as well as all jump components. A new fully implicit\nsplitting finite-difference scheme is proposed for solving forward PIDE which\nis used when calibrating the model to market prices of the FX options with\ndifferent strikes and maturities. The scheme is unconditionally stable, of\nsecond order of approximation in time and space, and achieves a linear\ncomplexity in each spatial direction. The results of simulation obtained by\nusing this model demonstrate capacity of the presented approach in modeling\nstochastic skew.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.02821v2"
    },
    {
        "title": "Keep It Real: Tail Probabilities of Compound Heavy-Tailed Distributions",
        "authors": [
            "Igor Halperin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  We propose an analytical approach to the computation of tail probabilities of\ncompound distributions whose individual components have heavy tails. Our\napproach is based on the contour integration method, and gives rise to a\nrepresentation of the tail probability of a compound distribution in the form\nof a rapidly convergent one-dimensional integral involving a discontinuity of\nthe imaginary part of its moment generating function across a branch cut. The\nlatter integral can be evaluated in quadratures, or alternatively represented\nas an asymptotic expansion. Our approach thus offers a viable (especially at\nhigh percentile levels) alternative to more standard methods such as Monte\nCarlo or the Fast Fourier Transform, traditionally used for such problems. As a\npractical application, we use our method to compute the operational Value at\nRisk (VAR) of a financial institution, where individual losses are modeled as\nspliced distributions whose large loss components are given by power-law or\nlognormal distributions. Finally, we briefly discuss extensions of the present\nformalism for calculation of tail probabilities of compound distributions made\nof compound distributions with heavy tails.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.01227v1"
    },
    {
        "title": "Semi-tractability of optimal stopping problems via a weighted stochastic\n  mesh algorithm",
        "authors": [
            "D. Belomestny",
            "M. Kaledin",
            "J. Schoenmakers"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this article we propose a Weighted Stochastic Mesh (WSM) Algorithm for\napproximating the value of a discrete and continuous time optimal stopping\nproblem. We prove that in the discrete case the WSM algorithm leads to\n  semi-tractability of the corresponding optimal problems in the sense that its\ncomplexity is bounded in order by $\\varepsilon^{-4}\\log^{d+2}(1/\\varepsilon)$\nwith $d$ being the dimension of the underlying Markov chain. Furthermore we\nstudy the WSM approach in the context of continuous time optimal stopping\nproblems and derive the corresponding complexity bounds. Although we can not\nprove semi-tractability in this case, our bounds turn out to be the tightest\nones among the bounds known for the existing algorithms in the literature. We\nillustrate our theoretical findings by a numerical example.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.09431v1"
    },
    {
        "title": "The impact of social influence in Australian real-estate: market\n  forecasting with a spatial agent-based model",
        "authors": [
            "Benjamin Patrick Evans",
            "Kirill Glavatskiy",
            "Michael S. Harré",
            "Mikhail Prokopenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Housing markets are inherently spatial, yet many existing models fail to\ncapture this spatial dimension. Here we introduce a new graph-based approach\nfor incorporating a spatial component in a large-scale urban housing\nagent-based model (ABM). The model explicitly captures several social and\neconomic factors that influence the agents' decision-making behaviour (such as\nfear of missing out, their trend following aptitude, and the strength of their\nsubmarket outreach), and interprets these factors in spatial terms. The\nproposed model is calibrated and validated with the housing market data for the\nGreater Sydney region. The ABM simulation results not only include predictions\nfor the overall market, but also produce area-specific forecasting at the level\nof local government areas within Sydney as arising from individual buy and sell\ndecisions. In addition, the simulation results elucidate agent preferences in\nsubmarkets, highlighting differences in agent behaviour, for example, between\nfirst-time home buyers and investors, and between both local and overseas\ninvestors.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.06914v2"
    },
    {
        "title": "Solving the Optimal Trading Trajectory Problem Using Simulated\n  Bifurcation",
        "authors": [
            "Kyle Steinhauer",
            "Takahisa Fukadai",
            "Sho Yoshida"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We use an optimization procedure based on simulated bifurcation (SB) to solve\nthe integer portfolio and trading trajectory problem with an unprecedented\ncomputational speed. The underlying algorithm is based on a classical\ndescription of quantum adiabatic evolutions of a network of non-linearly\ninteracting oscillators. This formulation has already proven to beat state of\nthe art computation times for other NP-hard problems and is expected to show\nsimilar performance for certain portfolio optimization problems. Inspired by\nsuch we apply the SB approach to the portfolio integer optimization problem\nwith quantity constraints and trading activities. We show first numerical\nresults for portfolios of up to 1000 assets, which already confirm the power of\nthe SB algorithm for its novel use-case as a portfolio and trading trajectory\noptimizer.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.08412v1"
    },
    {
        "title": "Semi-analytic pricing of double barrier options with time-dependent\n  barriers and rebates at hit",
        "authors": [
            "Andrey Itkin",
            "Dmitry Muravey"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We continue a series of papers devoted to construction of semi-analytic\nsolutions for barrier options. These options are written on underlying\nfollowing some simple one-factor diffusion model, but all the parameters of the\nmodel as well as the barriers are time-dependent. We managed to show that these\nsolutions are systematically more efficient for pricing and calibration than,\neg., the corresponding finite-difference solvers. In this paper we extend this\ntechnique to pricing double barrier options and present two approaches to\nsolving it: the General Integral transform method and the Heat Potential\nmethod. Our results confirm that for double barrier options these semi-analytic\ntechniques are also more efficient than the traditional numerical methods used\nto solve this type of problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.09342v3"
    },
    {
        "title": "A Deep Learning Approach for Dynamic Balance Sheet Stress Testing",
        "authors": [
            "Anastasios Petropoulos",
            "Vassilis Siakoulis",
            "Konstantinos P. Panousis",
            "Loukas Papadoulas",
            "Sotirios Chatzis"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In the aftermath of the financial crisis, supervisory authorities have\nconsiderably altered the mode of operation of financial stress testing. Despite\nthese efforts, significant concerns and extensive criticism have been raised by\nmarket participants regarding the considered unrealistic methodological\nassumptions and simplifications. Current stress testing methodologies attempt\nto simulate the risks underlying a financial institution's balance sheet by\nusing several satellite models. This renders their integration a really\nchallenging task, leading to significant estimation errors. Moreover, advanced\nstatistical techniques that could potentially capture the non-linear nature of\nadverse shocks are still ignored. This work aims to address these criticisms\nand shortcomings by proposing a novel approach based on recent advances in Deep\nLearning towards a principled method for Dynamic Balance Sheet Stress Testing.\nExperimental results on a newly collected financial/supervisory dataset,\nprovide strong empirical evidence that our paradigm significantly outperforms\ntraditional approaches; thus, it is capable of more accurately and efficiently\nsimulating real world scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.11075v2"
    },
    {
        "title": "Empirical Analysis of Stochastic Volatility Model by Hybrid Monte Carlo\n  Algorithm",
        "authors": [
            "Tetsuya Takaishi"
        ],
        "category": "q-fin.CP",
        "published_year": "2013",
        "summary": "  The stochastic volatility model is one of volatility models which infer\nlatent volatility of asset returns. The Bayesian inference of the stochastic\nvolatility (SV) model is performed by the hybrid Monte Carlo (HMC) algorithm\nwhich is superior to other Markov Chain Monte Carlo methods in sampling\nvolatility variables. We perform the HMC simulations of the SV model for two\nliquid stock returns traded on the Tokyo Stock Exchange and measure the\nvolatilities of those stock returns. Then we calculate the accuracy of the\nvolatility measurement using the realized volatility as a proxy of the true\nvolatility and compare the SV model with the GARCH model which is one of other\nvolatility models. Using the accuracy calculated with the realized volatility\nwe find that empirically the SV model performs better than the GARCH model.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.3184v1"
    },
    {
        "title": "A spectral method for an Optimal Investment problem with Transaction\n  Costs under Potential Utility",
        "authors": [
            "Javier de Frutos",
            "Victor Gaton"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  This paper concerns the numerical solution of the finite-horizon Optimal\nInvestment problem with transaction costs under Potential Utility. The problem\nis initially posed in terms of an evolutive HJB equation with gradient\nconstraints. In Finite-Horizon Optimal Investment with Transaction Costs: A\nParabolic Double Obstacle Problem, Day-Yi, the problem is reformulated as a\nnon-linear parabolic double obstacle problem posed in one spatial variable and\ndefined in an unbounded domain where several explicit properties and formulas\nare obtained. The restatement of the problem in polar coordinates allows to\npose the problem in one spatial variable in a finite domain, avoiding some of\nthe technical difficulties of the numerical solution of the previous statement\nof the problem. If high precision is required, the spectral numerical method\nproposed becomes more efficient than simpler methods as finite differences for\nexample.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.09469v1"
    },
    {
        "title": "A Comparison of Economic Agent-Based Model Calibration Methods",
        "authors": [
            "Donovan Platt"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Interest in agent-based models of financial markets and the wider economy has\nincreased consistently over the last few decades, in no small part due to their\nability to reproduce a number of empirically-observed stylised facts that are\nnot easily recovered by more traditional modelling approaches. Nevertheless,\nthe agent-based modelling paradigm faces mounting criticism, focused\nparticularly on the rigour of current validation and calibration practices,\nmost of which remain qualitative and stylised fact-driven. While the literature\non quantitative and data-driven approaches has seen significant expansion in\nrecent years, most studies have focused on the introduction of new calibration\nmethods that are neither benchmarked against existing alternatives nor\nrigorously tested in terms of the quality of the estimates they produce. We\ntherefore compare a number of prominent ABM calibration methods, both\nestablished and novel, through a series of computational experiments in an\nattempt to determine the respective strengths and weaknesses of each approach\nand the overall quality of the resultant parameter estimates. We find that\nBayesian estimation, though less popular in the literature, consistently\noutperforms frequentist, objective function-based approaches and results in\nreasonable parameter estimates in many contexts. Despite this, we also find\nthat agent-based model calibration techniques require further development in\norder to definitively calibrate large-scale models. We therefore make\nsuggestions for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.05938v1"
    },
    {
        "title": "A numerical scheme for the quantile hedging problem",
        "authors": [
            "Cyril Bénézet",
            "Jean-François Chassagneux",
            "Christoph Reisinger"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We consider the numerical approximation of the quantile hedging price in a\nnon-linear market. In a Markovian framework, we propose a numerical method\nbased on a Piecewise Constant Policy Timestepping (PCPT) scheme coupled with a\nmonotone finite difference approximation. We prove the convergence of our\nalgorithm combining BSDE arguments with the Barles & Jakobsen and Barles &\nSouganidis approaches for non-linear equations. In a numerical section, we\nillustrate the efficiency of our scheme by considering a financial example in a\nmarket with imperfections.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.11228v1"
    },
    {
        "title": "Revisiting the Epps effect using volume time averaging: An exercise in R",
        "authors": [
            "Patrick Chang",
            "Roger Bukuru",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We revisit and demonstrate the Epps effect using two well-known\nnon-parametric covariance estimators; the Malliavin and Mancino (MM), and\nHayashi and Yoshida (HY) estimators. We show the existence of the Epps effect\nin the top 10 stocks from the Johannesburg Stock Exchange (JSE) by various\nmethods of aggregating Trade and Quote (TAQ) data. Concretely, we compare\ncalendar time sampling with two volume time sampling methods: asset intrinsic\nvolume time averaging, and volume time averaging synchronised in volume time\nacross assets relative to the least and most liquid asset clocks. We reaffirm\nthe argument made in much of the literature that the MM estimator is more\nrepresentative of trade time reality because it does not over-estimate\nshort-term correlations in an asynchronous event driven world. We confirm well\nknown market phenomenology with the aim of providing some standardised R based\nsimulation tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.02416v2"
    },
    {
        "title": "A Quantum algorithm for linear PDEs arising in Finance",
        "authors": [
            "Filipe Fontanela",
            "Antoine Jacquier",
            "Mugad Oumgari"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We propose a hybrid quantum-classical algorithm, originated from quantum\nchemistry, to price European and Asian options in the Black-Scholes model. Our\napproach is based on the equivalence between the pricing partial differential\nequation and the Schrodinger equation in imaginary time. We devise a strategy\nto build a shallow quantum circuit approximation to this equation, only\nrequiring few qubits. This constitutes a promising candidate for the\napplication of Quantum Computing techniques (with large number of qubits\naffected by noise) in Quantitative Finance.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.02753v2"
    },
    {
        "title": "Four-factor model of Quanto CDS with jumps-at-default and stochastic\n  recovery",
        "authors": [
            "Andrey Itkin",
            "Fazlollah Soleymani"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper we modify the model of Itkin, Shcherbakov and Veygman, (2019)\n(ISV2019), proposed for pricing Quanto Credit Default Swaps (CDS) and risky\nbonds, in several ways. First, it is known since the Lehman Brothers bankruptcy\nthat the recovery rate could significantly vary right before or at default,\ntherefore, in this paper we consider it to be stochastic. Second, to reduce\ncomplexity of the model, we treat the domestic interest rate as deterministic,\nbecause, as shown in ISV2019, volatility of the domestic interest rate does not\ncontribute much to the value of the Quanto CDS spread. Finally, to solve the\ncorresponding systems of 4D partial differential equations we use a different\nflavor of the Radial Basis Function (RBF) method which is a combination of\nlocalized RBF and finite-difference methods, and is known in the literature as\nRBF-FD. Results of our numerical experiments presented in the paper demonstrate\nthat the influence of volatility of the recovery rate is significant if the\ncorrelation between the recovery rate and the log-intensity of the default is\nnon-zero. Also, the impact of the recovery mean-reversion rate on the Quanto\nCDS spread could be comparable with the impact due to jump-at-default in the FX\nrate.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.08713v1"
    },
    {
        "title": "On Calibration Neural Networks for extracting implied information from\n  American options",
        "authors": [
            "Shuaiqiang Liu",
            "Álvaro Leitao",
            "Anastasia Borovykh",
            "Cornelis W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Extracting implied information, like volatility and/or dividend, from\nobserved option prices is a challenging task when dealing with American\noptions, because of the computational costs needed to solve the corresponding\nmathematical problem many thousands of times. We will employ a data-driven\nmachine learning approach to estimate the Black-Scholes implied volatility and\nthe dividend yield for American options in a fast and robust way. To determine\nthe implied volatility, the inverse function is approximated by an artificial\nneural network on the computational domain of interest, which decouples the\noffline (training) and online (prediction) phases and thus eliminates the need\nfor an iterative process. For the implied dividend yield, we formulate the\ninverse problem as a calibration problem and determine simultaneously the\nimplied volatility and dividend yield. For this, a generic and robust\ncalibration framework, the Calibration Neural Network (CaNN), is introduced to\nestimate multiple parameters. It is shown that machine learning can be used as\nan efficient numerical technique to extract implied information from American\noptions.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11786v1"
    },
    {
        "title": "Long short-term memory networks and laglasso for bond yield forecasting:\n  Peeping inside the black box",
        "authors": [
            "Manuel Nunes",
            "Enrico Gerding",
            "Frank McGroarty",
            "Mahesan Niranjan"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Modern decision-making in fixed income asset management benefits from\nintelligent systems, which involve the use of state-of-the-art machine learning\nmodels and appropriate methodologies. We conduct the first study of bond yield\nforecasting using long short-term memory (LSTM) networks, validating its\npotential and identifying its memory advantage. Specifically, we model the\n10-year bond yield using univariate LSTMs with three input sequences and five\nforecasting horizons. We compare those with multilayer perceptrons (MLP),\nunivariate and with the most relevant features. To demystify the notion of\nblack box associated with LSTMs, we conduct the first internal study of the\nmodel. To this end, we calculate the LSTM signals through time, at selected\nlocations in the memory cell, using sequence-to-sequence architectures, uni and\nmultivariate. We then proceed to explain the states' signals using exogenous\ninformation, for what we develop the LSTM-LagLasso methodology. The results\nshow that the univariate LSTM model with additional memory is capable of\nachieving similar results as the multivariate MLP using macroeconomic and\nmarket information. Furthermore, shorter forecasting horizons require smaller\ninput sequences and vice-versa. The most remarkable property found consistently\nin the LSTM signals, is the activation/deactivation of units through time, and\nthe specialisation of units by yield range or feature. Those signals are\ncomplex but can be explained by exogenous variables. Additionally, some of the\nrelevant features identified via LSTM-LagLasso are not commonly used in\nforecasting models. In conclusion, our work validates the potential of LSTMs\nand methodologies for bonds, providing additional tools for financial\npractitioners.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02217v1"
    },
    {
        "title": "A generative adversarial network approach to calibration of local\n  stochastic volatility models",
        "authors": [
            "Christa Cuchiero",
            "Wahid Khosrawi",
            "Josef Teichmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We propose a fully data-driven approach to calibrate local stochastic\nvolatility (LSV) models, circumventing in particular the ad hoc interpolation\nof the volatility surface. To achieve this, we parametrize the leverage\nfunction by a family of feed-forward neural networks and learn their parameters\ndirectly from the available market option prices. This should be seen in the\ncontext of neural SDEs and (causal) generative adversarial networks: we\ngenerate volatility surfaces by specific neural SDEs, whose quality is assessed\nby quantifying, possibly in an adversarial manner, distances to market prices.\nThe minimization of the calibration functional relies strongly on a variance\nreduction technique based on hedging and deep hedging, which is interesting in\nits own right: it allows the calculation of model prices and model implied\nvolatilities in an accurate way using only small sets of sample paths. For\nnumerical illustration we implement a SABR-type LSV model and conduct a\nthorough statistical performance analysis on many samples of implied volatility\nsmiles, showing the accuracy and stability of the method.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02505v3"
    },
    {
        "title": "ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility\n  Prediction",
        "authors": [
            "Tian Guo",
            "Nicolas Jamet",
            "Valentin Betrix",
            "Louis-Alexandre Piquet",
            "Emmanuel Hauptmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Incorporating environmental, social, and governance (ESG) considerations into\nsystematic investments has drawn numerous attention recently. In this paper, we\nfocus on the ESG events in financial news flow and exploring the predictive\npower of ESG related financial news on stock volatility. In particular, we\ndevelop a pipeline of ESG news extraction, news representations, and Bayesian\ninference of deep learning models. Experimental evaluation on real data and\ndifferent markets demonstrates the superior predicting performance as well as\nthe relation of high volatility prediction to stocks with potential high risk\nand low return. It also shows the prospect of the proposed pipeline as a\nflexible predicting framework for various textual data and target variables.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02527v1"
    },
    {
        "title": "Semi-closed form prices of barrier options in the time-dependent CEV and\n  CIR models",
        "authors": [
            "Peter Carr",
            "Andrey Itkin",
            "Dmitry Muravey"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We continue a series of papers where prices of the barrier options written on\nthe underlying, which dynamics follows some one factor stochastic model with\ntime-dependent coefficients and the barrier, are obtained in semi-closed form,\nsee (Carr and Itkin, 2020, Itkin and Muravey, 2020). This paper extends this\nmethodology to the CIR model for zero-coupon bonds, and to the CEV model for\nstocks which are used as the corresponding underlying for the barrier options.\nWe describe two approaches. One is generalization of the method of heat\npotentials for the heat equation to the Bessel process, so we call it the\nmethod of Bessel potentials. We also propose a general scheme how to construct\nthe potential method for any linear differential operator with time-independent\ncoefficients. The second one is the method of generalized integral transform,\nwhich is also extended to the Bessel process. In all cases, a semi-closed\nsolution means that first, we need to solve numerically a linear Volterra\nequation of the second kind, and then the option price is represented as a\none-dimensional integral. We demonstrate that computationally our method is\nmore efficient than both the backward and forward finite difference methods\nwhile providing better accuracy and stability. Also, it is shown that both\nmethod don't duplicate but rather compliment each other, as one provides very\naccurate results at small maturities, and the other one - at high maturities.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05459v1"
    },
    {
        "title": "Pricing Barrier Options with DeepBSDEs",
        "authors": [
            "Narayan Ganesan",
            "Yajie Yu",
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper presents a novel and direct approach to price boundary and\nfinal-value problems, corresponding to barrier options, using forward deep\nlearning to solve forward-backward stochastic differential equations (FBSDEs).\nBarrier instruments are instruments that expire or transform into another\ninstrument if a barrier condition is satisfied before maturity; otherwise they\nperform like the instrument without the barrier condition. In the PDE\nformulation, this corresponds to adding boundary conditions to the final value\nproblem. The deep BSDE methods developed so far have not addressed\nbarrier/boundary conditions directly. We extend the forward deep BSDE to the\nbarrier condition case by adding nodes to the computational graph to explicitly\nmonitor the barrier conditions for each realization of the dynamics as well as\nnodes that preserve the time, state variables, and trading strategy value at\nbarrier breach or at maturity otherwise. Given these additional nodes in the\ncomputational graph, the forward loss function quantifies the replication of\nthe barrier or final payoff according to a chosen risk measure such as squared\nsum of differences. The proposed method can handle any barrier condition in the\nFBSDE set-up and any Dirichlet boundary conditions in the PDE set-up, both in\nlow and high dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.10966v2"
    },
    {
        "title": "Pricing Derivatives on Multiscale Diffusions: an Eigenfunction Expansion\n  Approach",
        "authors": [
            "Matthew Lorig"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Using tools from spectral analysis, singular and regular perturbation theory,\nwe develop a systematic method for analytically computing the approximate price\nof a derivative-asset. The payoff of the derivative-asset may be\npath-dependent. Additionally, the process underlying the derivative may exhibit\nkilling (i.e. jump to default) as well as combined local/nonlocal stochastic\nvolatility. The nonlocal component of volatility is multiscale, in the sense\nthat it is driven by one fast-varying and one slow-varying factor. The\nflexibility of our modeling framework is contrasted by the simplicity of our\nmethod. We reduce the derivative pricing problem to that of solving a single\neigenvalue equation. Once the eigenvalue equation is solved, the approximate\nprice of a derivative can be calculated formulaically. To illustrate our\nmethod, we calculate the approximate price of three derivative-assets: a\nvanilla option on a defaultable stock, a path-dependent option on a\nnon-defaultable stock, and a bond in a short-rate model.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0738v2"
    },
    {
        "title": "Numerical integration of Heath-Jarrow-Morton model of interest rates",
        "authors": [
            "M. Krivko",
            "M. V. Tretyakov"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  We propose and analyze numerical methods for the Heath-Jarrow-Morton (HJM)\nmodel. To construct the methods, we first discretize the infinite dimensional\nHJM equation in maturity time variable using quadrature rules for approximating\nthe arbitrage-free drift. This results in a finite dimensional system of\nstochastic differential equations (SDEs) which we approximate in the weak and\nmean-square sense using the general theory of numerical integration of SDEs.\nThe proposed numerical algorithms are computationally highly efficient due to\nthe use of high-order quadrature rules which allow us to take relatively large\ndiscretization steps in the maturity time without affecting overall accuracy of\nthe algorithms. Convergence theorems for the methods are proved. Results of\nsome numerical experiments with European-type interest rate derivatives are\npresented.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.2557v1"
    },
    {
        "title": "Sparsifying Defaults: Optimal Bailout Policies for Financial Networks in\n  Distress",
        "authors": [
            "Zhang Li",
            "Ilya Pollak"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  The events of the last few years revealed an acute need for tools to\nsystematically model and analyze large financial networks. Many applications of\nsuch tools include the forecasting of systemic failures and analyzing probable\neffects of economic policy decisions. We consider optimizing the amount and\nstructure of a bailout in a borrower-lender network: Given a fixed amount of\ncash to be injected into the system, how should it be distributed among the\nnodes in order to achieve the smallest overall amount of unpaid liabilities or\nthe smallest number of nodes in default? We develop an exact algorithm for the\nproblem of minimizing the amount of unpaid liabilities, by showing that it is\nequivalent to a linear program. For the problem of minimizing the number of\ndefaults, we develop an approximate algorithm using a reweighted l1\nminimization approach. We illustrate this algorithm using an example with\nsynthetic data for which the optimal solution can be calculated exactly, and\nshow through numerical simulation that the solutions calculated by our\nalgorithm are close to optimal.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.3982v1"
    },
    {
        "title": "Exploring the predictability of range-based volatility estimators using\n  RNNs",
        "authors": [
            "Gábor Petneházi",
            "József Gáll"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We investigate the predictability of several range-based stock volatility\nestimators, and compare them to the standard close-to-close estimator which is\nmost commonly acknowledged as the volatility. The patterns of volatility\nchanges are analyzed using LSTM recurrent neural networks, which are a state of\nthe art method of sequence learning. We implement the analysis on all current\nconstituents of the Dow Jones Industrial Average index, and report averaged\nevaluation results. We find that changes in the values of range-based\nestimators are more predictable than that of the estimator using daily closing\nvalues only.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.07152v1"
    },
    {
        "title": "Pricing Credit Default Swap Subject to Counterparty Risk and\n  Collateralization",
        "authors": [
            "Alan White"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  This article presents a new model for valuing a credit default swap (CDS)\ncontract that is affected by multiple credit risks of the buyer, seller and\nreference entity. We show that default dependency has a significant impact on\nasset pricing. In fact, correlated default risk is one of the most pervasive\nthreats in financial markets. We also show that a fully collateralized CDS is\nnot equivalent to a risk-free one. In other words, full collateralization\ncannot eliminate counterparty risk completely in the CDS market.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.07843v1"
    },
    {
        "title": "Stock Forecasting using M-Band Wavelet-Based SVR and RNN-LSTMs Models",
        "authors": [
            "Hieu Quang Nguyen",
            "Abdul Hasib Rahimyar",
            "Xiaodi Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  The task of predicting future stock values has always been one that is\nheavily desired albeit very difficult. This difficulty arises from stocks with\nnon-stationary behavior, and without any explicit form. Hence, predictions are\nbest made through analysis of financial stock data. To handle big data sets,\ncurrent convention involves the use of the Moving Average. However, by\nutilizing the Wavelet Transform in place of the Moving Average to denoise stock\nsignals, financial data can be smoothened and more accurately broken down. This\nnewly transformed, denoised, and more stable stock data can be followed up by\nnon-parametric statistical methods, such as Support Vector Regression (SVR) and\nRecurrent Neural Network (RNN) based Long Short-Term Memory (LSTM) networks to\npredict future stock prices. Through the implementation of these methods, one\nis left with a more accurate stock forecast, and in turn, increased profits.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.08459v1"
    },
    {
        "title": "A neural network-based framework for financial model calibration",
        "authors": [
            "Shuaiqiang Liu",
            "Anastasia Borovykh",
            "Lech A. Grzelak",
            "Cornelis W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  A data-driven approach called CaNN (Calibration Neural Network) is proposed\nto calibrate financial asset price models using an Artificial Neural Network\n(ANN). Determining optimal values of the model parameters is formulated as\ntraining hidden neurons within a machine learning framework, based on available\nfinancial option prices. The framework consists of two parts: a forward pass in\nwhich we train the weights of the ANN off-line, valuing options under many\ndifferent asset model parameter settings; and a backward pass, in which we\nevaluate the trained ANN-solver on-line, aiming to find the weights of the\nneurons in the input layer. The rapid on-line learning of implied volatility by\nANNs, in combination with the use of an adapted parallel global optimization\nmethod, tackles the computation bottleneck and provides a fast and reliable\ntechnique for calibrating model parameters while avoiding, as much as possible,\ngetting stuck in local minima. Numerical experiments confirm that this\nmachine-learning framework can be employed to calibrate parameters of\nhigh-dimensional stochastic volatility models efficiently and accurately.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.10523v1"
    },
    {
        "title": "Deep Generative Models for Reject Inference in Credit Scoring",
        "authors": [
            "Rogelio A. Mancisidor",
            "Michael Kampffmeyer",
            "Kjersti Aas",
            "Robert Jenssen"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Credit scoring models based on accepted applications may be biased and their\nconsequences can have a statistical and economic impact. Reject inference is\nthe process of attempting to infer the creditworthiness status of the rejected\napplications. In this research, we use deep generative models to develop two\nnew semi-supervised Bayesian models for reject inference in credit scoring, in\nwhich we model the data generating process to be dependent on a Gaussian\nmixture. The goal is to improve the classification accuracy in credit scoring\nmodels by adding reject applications. Our proposed models infer the unknown\ncreditworthiness of the rejected applications by exact enumeration of the two\npossible outcomes of the loan (default or non-default). The efficient\nstochastic gradient optimization technique used in deep generative models makes\nour models suitable for large data sets. Finally, the experiments in this\nresearch show that our proposed models perform better than classical and\nalternative machine learning models for reject inference in credit scoring.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11376v2"
    },
    {
        "title": "Incorporating prior financial domain knowledge into neural networks for\n  implied volatility surface prediction",
        "authors": [
            "Yu Zheng",
            "Yongxin Yang",
            "Bowei Chen"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this paper we develop a novel neural network model for predicting implied\nvolatility surface. Prior financial domain knowledge is taken into account. A\nnew activation function that incorporates volatility smile is proposed, which\nis used for the hidden nodes that process the underlying asset price. In\naddition, financial conditions, such as the absence of arbitrage, the\nboundaries and the asymptotic slope, are embedded into the loss function. This\nis one of the very first studies which discuss a methodological framework that\nincorporates prior financial domain knowledge into neural network architecture\ndesign and model training. The proposed model outperforms the benchmarked\nmodels with the option data on the S&P 500 index over 20 years. More\nimportantly, the domain knowledge is satisfied empirically, showing the model\nis consistent with the existing financial theories and conditions related to\nimplied volatility surface.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12834v5"
    },
    {
        "title": "Agglomerative Likelihood Clustering",
        "authors": [
            "Lionel Yelibi",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We consider the problem of fast time-series data clustering. Building on\nprevious work modeling the correlation-based Hamiltonian of spin variables we\npresent an updated fast non-expensive Agglomerative Likelihood Clustering\nalgorithm (ALC). The method replaces the optimized genetic algorithm based\napproach (f-SPC) with an agglomerative recursive merging framework inspired by\nprevious work in Econophysics and Community Detection. The method is tested on\nnoisy synthetic correlated time-series data-sets with built-in cluster\nstructure to demonstrate that the algorithm produces meaningful non-trivial\nresults. We apply it to time-series data-sets as large as 20,000 assets and we\nargue that ALC can reduce compute time costs and resource usage cost for large\nscale clustering for time-series applications while being serialized, and hence\nhas no obvious parallelization requirement. The algorithm can be an effective\nchoice for state-detection for online learning in a fast non-linear data\nenvironment because the algorithm requires no prior information about the\nnumber of clusters.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.00951v4"
    },
    {
        "title": "An SFP--FCC Method for Pricing and Hedging Early-exercise Options under\n  Lévy Processes",
        "authors": [
            "Tat Lung",
            " Chan"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  This paper extends the Singular Fourier--Pad\\'e (SFP) method proposed by Chan\n(2018) to pricing/hedging early-exercise options--Bermudan, American and\ndiscrete-monitored barrier options--under a L\\'evy process. The current SFP\nmethod is incorporated with the Filon--Clenshaw--Curtis (FCC) rules invented by\nDom\\'inguez et al. (2011), and we call the new method SFP--FCC. The main\npurpose of using the SFP--FCC method is to require a small number of terms to\nyield fast error convergence and to formulate option pricing and option Greek\ncurves rather than individual prices/Greek values. We also numerically show\nthat the SFP--FCC method can retain a global spectral convergence rate in\noption pricing and hedging when the risk-free probability density function is\npiecewise smooth. Moreover, the computational complexity of the method is\n$\\mathcal{O}((L-1)(N+1)(\\tilde{N} \\log \\tilde{N}) )$ with $N$ a (small) number\nof complex Fourier series terms, $\\tilde{N}$ a number of Chebyshev series terms\nand $L$, the number of early-exercise/monitoring dates. Finally, we show that\nour method is more favourable than existing techniques in numerical\nexperiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.07319v1"
    },
    {
        "title": "Deep Neural Network Framework Based on Backward Stochastic Differential\n  Equations for Pricing and Hedging American Options in High Dimensions",
        "authors": [
            "Yangang Chen",
            "Justin W. L. Wan"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We propose a deep neural network framework for computing prices and deltas of\nAmerican options in high dimensions. The architecture of the framework is a\nsequence of neural networks, where each network learns the difference of the\nprice functions between adjacent timesteps. We introduce the least squares\nresidual of the associated backward stochastic differential equation as the\nloss function. Our proposed framework yields prices and deltas on the entire\nspacetime, not only at a given point. The computational cost of the proposed\napproach is quadratic in dimension, which addresses the curse of dimensionality\nissue that state-of-the-art approaches suffer. Our numerical simulations\ndemonstrate these contributions, and show that the proposed neural network\nframework outperforms state-of-the-art approaches in high dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11532v1"
    },
    {
        "title": "Deep Reinforcement Learning for Trading",
        "authors": [
            "Zihao Zhang",
            "Stefan Zohren",
            "Stephen Roberts"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We adopt Deep Reinforcement Learning algorithms to design trading strategies\nfor continuous futures contracts. Both discrete and continuous action spaces\nare considered and volatility scaling is incorporated to create reward\nfunctions which scale trade positions based on market volatility. We test our\nalgorithms on the 50 most liquid futures contracts from 2011 to 2019, and\ninvestigate how performance varies across different asset classes including\ncommodities, equity indices, fixed income and FX markets. We compare our\nalgorithms against classical time series momentum strategies, and show that our\nmethod outperforms such baseline models, delivering positive profits despite\nheavy transaction costs. The experiments show that the proposed algorithms can\nfollow large market trends without changing positions and can also scale down,\nor hold, through consolidation periods.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.10107v1"
    },
    {
        "title": "Introduction to Solving Quant Finance Problems with Time-Stepped FBSDE\n  and Deep Learning",
        "authors": [
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this introductory paper, we discuss how quantitative finance problems\nunder some common risk factor dynamics for some common instruments and\napproaches can be formulated as time-continuous or time-discrete\nforward-backward stochastic differential equations (FBSDE) final-value or\ncontrol problems, how these final value problems can be turned into control\nproblems, how time-continuous problems can be turned into time-discrete\nproblems, and how the forward and backward stochastic differential equations\n(SDE) can be time-stepped. We obtain both forward and backward time-stepped\ntime-discrete stochastic control problems (where forward and backward indicate\nin which direction the Y SDE is time-stepped) that we will solve with\noptimization approaches using deep neural networks for the controls and\nstochastic gradient and other deep learning methods for the actual\noptimization/learning. We close with examples for the forward and backward\nmethods for an European option pricing problem. Several methods and approaches\nare new.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12231v1"
    },
    {
        "title": "Sig-SDEs model for quantitative finance",
        "authors": [
            "Imanol Perez Arribas",
            "Cristopher Salvi",
            "Lukasz Szpruch"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Mathematical models, calibrated to data, have become ubiquitous to make key\ndecision processes in modern quantitative finance. In this work, we propose a\nnovel framework for data-driven model selection by integrating a classical\nquantitative setup with a generative modelling approach. Leveraging the\nproperties of the signature, a well-known path-transform from stochastic\nanalysis that recently emerged as leading machine learning technology for\nlearning time-series data, we develop the Sig-SDE model. Sig-SDE provides a new\nperspective on neural SDEs and can be calibrated to exotic financial products\nthat depend, in a non-linear way, on the whole trajectory of asset prices.\nFurthermore, we our approach enables to consistently calibrate under the\npricing measure $\\mathbb Q$ and real-world measure $\\mathbb P$. Finally, we\ndemonstrate the ability of Sig-SDE to simulate future possible market scenarios\nneeded for computing risk profiles or hedging strategies. Importantly, this new\nmodel is underpinned by rigorous mathematical analysis, that under appropriate\nconditions provides theoretical guarantees for convergence of the presented\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.00218v2"
    },
    {
        "title": "Backward Deep BSDE Methods and Applications to Nonlinear Problems",
        "authors": [
            "Yajie Yu",
            "Bernhard Hientzsch",
            "Narayan Ganesan"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper, we present a backward deep BSDE method applied to Forward\nBackward Stochastic Differential Equations (FBSDE) with given terminal\ncondition at maturity that time-steps the BSDE backwards. We present an\napplication of this method to a nonlinear pricing problem - the differential\nrates problem. To time-step the BSDE backward, one needs to solve a nonlinear\nproblem. For the differential rates problem, we derive an exact solution of\nthis time-step problem and a Taylor-based approximation. Previously backward\ndeep BSDE methods only treated zero or linear generators. While a Taylor\napproach for nonlinear generators was previously mentioned, it had not been\nimplemented or applied, while we apply our method to nonlinear generators and\nderive details and present results. Likewise, previously backward deep BSDE\nmethods were presented for fixed initial risk factor values $X_0$ only, while\nwe present a version with random $X_0$ and a version that learns portfolio\nvalues at intermediate times as well. The method is able to solve nonlinear\nFBSDE problems in high dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.07635v1"
    },
    {
        "title": "From the Black-Karasinski to the Verhulst model to accommodate the\n  unconventional Fed's policy",
        "authors": [
            "A. Itkin",
            "A. Lipton",
            "D. Muravey"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper, we argue that some of the most popular short-term interest\nmodels have to be revisited and modified to reflect current market conditions\nbetter. In particular, we propose a modification of the popular\nBlack-Karasinski model, which is widely used by practitioners for modeling\ninterest rates, credit, and commodities. Our adjustment gives rise to the\nstochastic Verhulst model, which is well-known in the population dynamics and\nepidemiology as a logistic model. We demonstrate that the Verhulst model's\ndynamics are well suited to the current economic environment and the Fed's\nactions. Besides, we derive new integral equations for the zero-coupon bond\nprices for both the BK and Verhulst models. For the BK model for small\nmaturities up to 2 years, we solve the corresponding integral equation by using\nthe reduced differential transform method. For the Verhulst integral equation,\nunder some mild assumptions, we find the closed-form solution. Numerical\nexamples show that computationally our approach is significantly more efficient\nthan the standard finite difference method.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.11976v2"
    },
    {
        "title": "Deep reinforcement learning for portfolio management",
        "authors": [
            "Gang Huang",
            "Xiaohua Zhou",
            "Qingyang Song"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In our paper, we apply deep reinforcement learning approach to optimize\ninvestment decisions in portfolio management. We make several innovations, such\nas adding short mechanism and designing an arbitrage mechanism, and applied our\nmodel to make decision optimization for several randomly selected portfolios.\nThe experimental results show that our model is able to optimize investment\ndecisions and has the ability to obtain excess return in stock market, and the\noptimized agent maintains the asset weights at fixed value throughout the\ntrading periods and trades at a very low transaction cost rate. In addition, we\nredesigned the formula for calculating portfolio asset weights in continuous\ntrading process which can make leverage trading, that fills the theoretical gap\nin the calculation of portfolio weights when shorting.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.13773v7"
    },
    {
        "title": "Black-box model risk in finance",
        "authors": [
            "Samuel N. Cohen",
            "Derek Snow",
            "Lukasz Szpruch"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Machine learning models are increasingly used in a wide variety of financial\nsettings. The difficulty of understanding the inner workings of these systems,\ncombined with their wide applicability, has the potential to lead to\nsignificant new risks for users; these risks need to be understood and\nquantified. In this sub-chapter, we will focus on a well studied application of\nmachine learning techniques, to pricing and hedging of financial options. Our\naim will be to highlight the various sources of risk that the introduction of\nmachine learning emphasises or de-emphasises, and the possible risk mitigation\nand management strategies that are available.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04757v1"
    },
    {
        "title": "Multilayer heat equations: application to finance",
        "authors": [
            "A. Itkin",
            "A. Lipton",
            "D. Muravey"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this paper, we develop a Multilayer (ML) method for solving one-factor\nparabolic equations. Our approach provides a powerful alternative to the\nwell-known finite difference and Monte Carlo methods. We discuss various\nadvantages of this approach, which judiciously combines semi-analytical and\nnumerical techniques and provides a fast and accurate way of finding solutions\nto the corresponding equations. To introduce the core of the method, we\nconsider multilayer heat equations, known in physics for a relatively long time\nbut never used when solving financial problems. Thus, we expand the analytic\nmachinery of quantitative finance by augmenting it with the ML method. We\ndemonstrate how one can solve various problems of mathematical finance by using\nour approach. Specifically, we develop efficient algorithms for pricing barrier\noptions for time-dependent one-factor short-rate models, such as\nBlack-Karasinski and Verhulst. Besides, we show how to solve the well-known\nDupire equation quickly and accurately. Numerical examples confirm that our\napproach is considerably more efficient for solving the corresponding partial\ndifferential equations than the conventional finite difference method by being\nmuch faster and more accurate than the known alternatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08338v1"
    },
    {
        "title": "Deep Equal Risk Pricing of Financial Derivatives with Multiple Hedging\n  Instruments",
        "authors": [
            "Alexandre Carbonneau",
            "Frédéric Godin"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  This paper studies the equal risk pricing (ERP) framework for the valuation\nof European financial derivatives. This option pricing approach is consistent\nwith global trading strategies by setting the premium as the value such that\nthe residual hedging risk of the long and short positions in the option are\nequal under optimal hedging. The ERP setup of Marzban et al. (2020) is\nconsidered where residual hedging risk is quantified with convex risk measures.\nThe main objective of this paper is to assess through extensive numerical\nexperiments the impact of including options as hedging instruments within the\nERP framework. The reinforcement learning procedure developed in Carbonneau and\nGodin (2020), which relies on the deep hedging algorithm of Buehler et al.\n(2019b), is applied to numerically solve the global hedging problems by\nrepresenting trading policies with neural networks. Among other findings,\nnumerical results indicate that in the presence of jump risk, hedging long-term\nputs with shorter-term options entails a significant decrease of both equal\nrisk prices and market incompleteness as compared to trading only the stock.\nMonte Carlo experiments demonstrate the potential of ERP as a fair valuation\napproach providing prices consistent with observable market prices. Analyses\nexhibit the ability of ERP to span a large interval of prices through the\nchoice of convex risk measures which is close to encompass the variance-optimal\npremium.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.12694v1"
    },
    {
        "title": "No-Transaction Band Network: A Neural Network Architecture for Efficient\n  Deep Hedging",
        "authors": [
            "Shota Imaki",
            "Kentaro Imajo",
            "Katsuya Ito",
            "Kentaro Minami",
            "Kei Nakagawa"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Deep hedging (Buehler et al. 2019) is a versatile framework to compute the\noptimal hedging strategy of derivatives in incomplete markets. However, this\noptimal strategy is hard to train due to action dependence, that is, the\nappropriate hedging action at the next step depends on the current action. To\novercome this issue, we leverage the idea of a no-transaction band strategy,\nwhich is an existing technique that gives optimal hedging strategies for\nEuropean options and the exponential utility. We theoretically prove that this\nstrategy is also optimal for a wider class of utilities and derivatives\nincluding exotics. Based on this result, we propose a no-transaction band\nnetwork, a neural network architecture that facilitates fast training and\nprecise evaluation of the optimal hedging strategy. We experimentally\ndemonstrate that for European and lookback options, our architecture quickly\nattains a better hedging strategy in comparison to a standard feed-forward\nnetwork.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.01775v1"
    },
    {
        "title": "Pricing high-dimensional Bermudan options with hierarchical tensor\n  formats",
        "authors": [
            "Christian Bayer",
            "Martin Eigel",
            "Leon Sallandt",
            "Philipp Trunschke"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  An efficient compression technique based on hierarchical tensors for popular\noption pricing methods is presented. It is shown that the \"curse of\ndimensionality\" can be alleviated for the computation of Bermudan option prices\nwith the Monte Carlo least-squares approach as well as the dual martingale\nmethod, both using high-dimensional tensorized polynomial expansions. This\ndiscretization allows for a simple and computationally cheap evaluation of\nconditional expectations. Complexity estimates are provided as well as a\ndescription of the optimization procedures in the tensor train format.\nNumerical experiments illustrate the favourable accuracy of the proposed\nmethods. The dynamical programming method yields results comparable to recent\nNeural Network based methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.01934v2"
    },
    {
        "title": "Trading Signals In VIX Futures",
        "authors": [
            "M. Avellaneda",
            "T. N. Li",
            "A. Papanicolaou",
            "G. Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We propose a new approach for trading VIX futures. We assume that the term\nstructure of VIX futures follows a Markov model. Our trading strategy selects a\nposition in VIX futures by maximizing the expected utility for a day-ahead\nhorizon given the current shape and level of the term structure.\nComputationally, we model the functional dependence between the VIX futures\ncurve, the VIX futures positions, and the expected utility as a deep neural\nnetwork with five hidden layers. Out-of-sample backtests of the VIX futures\ntrading strategy suggest that this approach gives rise to reasonable portfolio\nperformance, and to positions in which the investor will be either long or\nshort VIX futures contracts depending on the market environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.02016v3"
    },
    {
        "title": "Deep Hedging, Generative Adversarial Networks, and Beyond",
        "authors": [
            "Hyunsu Kim"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  This paper introduces a potential application of deep learning and artificial\nintelligence in finance, particularly its application in hedging. The major\ngoal encompasses two objectives. First, we present a framework of a direct\npolicy search reinforcement agent replicating a simple vanilla European call\noption and use the agent for the model-free delta hedging. Through the first\npart of this paper, we demonstrate how the RNN-based direct policy search RL\nagents can perform delta hedging better than the classic Black-Scholes model in\nQ-world based on parametrically generated underlying scenarios, particularly\nminimizing tail exposures at higher values of the risk aversion parameter. In\nthe second part of this paper, with the non-parametric paths generated by\ntime-series GANs from multi-variate temporal space, we illustrate its delta\nhedging performance on various values of the risk aversion parameter via the\nbasic RNN-based RL agent introduced in the first part of the paper, showing\nthat we can potentially achieve higher average profits with a rather evident\nrisk-return trade-off. We believe that this RL-based hedging framework is a\nmore efficient way of performing hedging in practice, addressing some of the\ninherent issues with the classic models, providing promising/intuitive hedging\nresults, and rendering a flexible framework that can be easily paired with\nother AI-based models for many other purposes.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.03913v1"
    },
    {
        "title": "Portfolio risk allocation through Shapley value",
        "authors": [
            "Patrick S. Hagan",
            "Andrew Lesniewski",
            "Georgios E. Skoufis",
            "Diana E. Woodward"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We argue that using the Shapley value of cooperative game theory as the\nscheme for risk allocation among non-orthogonal risk factors is a natural way\nof interpreting the contribution made by each of such factors to overall\nportfolio risk. We discuss a Shapley value scheme for allocating risk to\nnon-orthogonal greeks in a portfolio of derivatives. Such a situation arises,\nfor example, when using a stochastic volatility model to capture option\nvolatility smile. We also show that Shapley value allows for a natural method\nof interpreting components of enterprise risk measures such as VaR and ES. For\nall applications discussed, we derive explicit formulas and / or numerical\nalgorithms to calculate the allocations.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.05453v1"
    },
    {
        "title": "A deep learning approach to data-driven model-free pricing and to\n  martingale optimal transport",
        "authors": [
            "Ariel Neufeld",
            "Julian Sester"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We introduce a novel and highly tractable supervised learning approach based\non neural networks that can be applied for the computation of model-free price\nbounds of, potentially high-dimensional, financial derivatives and for the\ndetermination of optimal hedging strategies attaining these bounds. In\nparticular, our methodology allows to train a single neural network offline and\nthen to use it online for the fast determination of model-free price bounds of\na whole class of financial derivatives with current market data. We show the\napplicability of this approach and highlight its accuracy in several examples\ninvolving real market data. Further, we show how a neural network can be\ntrained to solve martingale optimal transport problems involving fixed marginal\ndistributions instead of financial market data.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.11435v3"
    },
    {
        "title": "Deep Hedging: Learning Risk-Neutral Implied Volatility Dynamics",
        "authors": [
            "Hans Buehler",
            "Phillip Murray",
            "Mikko S. Pakkanen",
            "Ben Wood"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We present a numerically efficient approach for learning a risk-neutral\nmeasure for paths of simulated spot and option prices up to a finite horizon\nunder convex transaction costs and convex trading constraints. This approach\ncan then be used to implement a stochastic implied volatility model in the\nfollowing two steps: 1. Train a market simulator for option prices, as\ndiscussed for example in our recent; 2. Find a risk-neutral density,\nspecifically the minimal entropy martingale measure. The resulting model can be\nused for risk-neutral pricing, or for Deep Hedging in the case of transaction\ncosts or trading constraints. To motivate the proposed approach, we also show\nthat market dynamics are free from \"statistical arbitrage\" in the absence of\ntransaction costs if and only if they follow a risk-neutral measure. We\nadditionally provide a more general characterization in the presence of convex\ntransaction costs and trading constraints. These results can be seen as an\nanalogue of the fundamental theorem of asset pricing for statistical arbitrage\nunder trading frictions and are of independent interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.11948v3"
    },
    {
        "title": "Deep Hedging of Derivatives Using Reinforcement Learning",
        "authors": [
            "Jay Cao",
            "Jacky Chen",
            "John Hull",
            "Zissis Poulos"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  This paper shows how reinforcement learning can be used to derive optimal\nhedging strategies for derivatives when there are transaction costs. The paper\nillustrates the approach by showing the difference between using delta hedging\nand optimal hedging for a short position in a call option when the objective is\nto minimize a function equal to the mean hedging cost plus a constant times the\nstandard deviation of the hedging cost. Two situations are considered. In the\nfirst, the asset price follows a geometric Brownian motion. In the second, the\nasset price follows a stochastic volatility process. The paper extends the\nbasic reinforcement learning approach in a number of ways. First, it uses two\ndifferent Q-functions so that both the expected value of the cost and the\nexpected value of the square of the cost are tracked for different state/action\ncombinations. This approach increases the range of objective functions that can\nbe used. Second, it uses a learning algorithm that allows for continuous state\nand action space. Third, it compares the accounting P&L approach (where the\nhedged position is valued at each step) and the cash flow approach (where cash\ninflows and outflows are used). We find that a hybrid approach involving the\nuse of an accounting P&L approach that incorporates a relatively simple\nvaluation model works well. The valuation model does not have to correspond to\nthe process assumed for the underlying asset price.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.16409v1"
    },
    {
        "title": "Online learning techniques for prediction of temporal tabular datasets\n  with regime changes",
        "authors": [
            "Thomas Wong",
            "Mauricio Barahona"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The application of deep learning to non-stationary temporal datasets can lead\nto overfitted models that underperform under regime changes. In this work, we\npropose a modular machine learning pipeline for ranking predictions on temporal\npanel datasets which is robust under regime changes. The modularity of the\npipeline allows the use of different models, including Gradient Boosting\nDecision Trees (GBDTs) and Neural Networks, with and without feature\nengineering. We evaluate our framework on financial data for stock portfolio\nprediction, and find that GBDT models with dropout display high performance,\nrobustness and generalisability with reduced complexity and computational cost.\nWe then demonstrate how online learning techniques, which require no retraining\nof models, can be used post-prediction to enhance the results. First, we show\nthat dynamic feature projection improves robustness by reducing drawdown in\nregime changes. Second, we demonstrate that dynamical model ensembling based on\nselection of models with good recent performance leads to improved Sharpe and\nCalmar ratios of out-of-sample predictions. We also evaluate the robustness of\nour pipeline across different data splits and random seeds with good\nreproducibility.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00790v4"
    },
    {
        "title": "Deep Reinforcement Learning for Asset Allocation: Reward Clipping",
        "authors": [
            "Jiwon Kim",
            "Moon-Ju Kang",
            "KangHun Lee",
            "HyungJun Moon",
            "Bo-Kwan Jeon"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Recently, there are many trials to apply reinforcement learning in asset\nallocation for earning more stable profits. In this paper, we compare\nperformance between several reinforcement learning algorithms - actor-only,\nactor-critic and PPO models. Furthermore, we analyze each models' character and\nthen introduce the advanced algorithm, so called Reward clipping model. It\nseems that the Reward Clipping model is better than other existing models in\nfinance domain, especially portfolio optimization - it has strength both in\nbull and bear markets. Finally, we compare the performance for these models\nwith traditional investment strategies during decreasing and increasing\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.05300v1"
    },
    {
        "title": "Optimal Hedging for Fund & Insurance Managers with Partially Observable\n  Investment Flows",
        "authors": [
            "Masaaki Fujii",
            "Akihiko Takahashi"
        ],
        "category": "q-fin.CP",
        "published_year": "2014",
        "summary": "  All the financial practitioners are working in incomplete markets full of\nunhedgeable risk-factors. Making the situation worse, they are only equipped\nwith the imperfect information on the relevant processes. In addition to the\nmarket risk, fund and insurance managers have to be prepared for sudden and\npossibly contagious changes in the investment flows from their clients so that\nthey can avoid the over- as well as under-hedging. In this work, the prices of\nsecurities, the occurrences of insured events and (possibly a network of) the\ninvestment flows are used to infer their drifts and intensities by a stochastic\nfiltering technique. We utilize the inferred information to provide the optimal\nhedging strategy based on the mean-variance (or quadratic) risk criterion. A\nBSDE approach allows a systematic derivation of the optimal strategy, which is\nshown to be implementable by a set of simple ODEs and the standard Monte Carlo\nsimulation. The presented framework may also be useful for manufactures and\nenergy firms to install an efficient overlay of dynamic hedging by financial\nderivatives to minimize the costs.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.2314v2"
    },
    {
        "title": "Option pricing in the model with stochastic volatility driven by\n  Ornstein--Uhlenbeck process. Simulation",
        "authors": [
            "Sergii Kuchuk-Iatsenko",
            "Yuliya Mishura"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We consider a discrete-time approximation of paths of an Ornstein--Uhlenbeck\nprocess as a mean for estimation of a price of European call option in the\nmodel of financial market with stochastic volatility. The Euler--Maruyama\napproximation scheme is implemented. We determine the estimates for the option\nprice for predetermined sets of parameters. The rate of convergence of the\nprice and an average volatility when discretization intervals tighten are\ndetermined. Discretization precision is analyzed for the case where the exact\nvalue of the price can be derived.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.01128v1"
    },
    {
        "title": "Semi-analytic path integral solution of SABR and Heston equations:\n  pricing Vanilla and Asian options",
        "authors": [
            "Jan Kuklinski",
            "Kevin Tyloo"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We discuss a semi-analytical method for solving SABR-type equations based on\npath integrals. In this approach, one set of variables is integrated\nanalytically while the second set is integrated numerically via Monte-Carlo.\nThis method, known in the literature as Conditional Monte-Carlo, leads to\ncompact expressions functional on three correlated stochastic variables. The\nmethodology is practical and efficient when solving Vanilla pricing in the\nSABR, Heston and Bates models with time depending parameters. Further, it can\nalso be practically applied to pricing Asian options in the $\\beta=0$ SABR\nmodel and to other $\\beta=0$ type models.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00307v1"
    },
    {
        "title": "Learning zero-cost portfolio selection with pattern matching",
        "authors": [
            "Tim Gebbie",
            "Fayyaaz Loonat"
        ],
        "category": "q-fin.CP",
        "published_year": "2016",
        "summary": "  We consider and extend the adversarial agent-based learning approach of\nGy{\\\"o}rfi {\\it et al} to the situation of zero-cost portfolio selection\nimplemented with a quadratic approximation derived from the mutual fund\nseparation theorems. The algorithm is applied to daily sampled sequential\nOpen-High-Low-Close data and sequential intraday 5-minute bar-data from the\nJohannesburg Stock Exchange (JSE). Statistical tests of the algorithms are\nconsidered. The algorithms are directly compared to standard NYSE test cases\nfrom prior literature. The learning algorithm is used to select parameters for\nagents (or experts) generated by pattern matching past dynamics using a simple\nnearest-neighbour search algorithm. It is shown that there is a speed advantage\nassociated with using an analytic solution of the mutual fund separation\ntheorems. It is argued that the expected loss in performance does not undermine\nthe potential application to intraday quantitative trading and that when\ntransactions costs and slippage are considered the strategies can still remain\nprofitable when unleveraged. The paper demonstrates that patterns in financial\ntime-series on the JSE can be systematically exploited in collective but that\nthis does not imply predictability of the individual asset time-series\nthemselves.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.04600v1"
    },
    {
        "title": "A Deep Reinforcement Learning Framework for the Financial Portfolio\n  Management Problem",
        "authors": [
            "Zhengyao Jiang",
            "Dixing Xu",
            "Jinjun Liang"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Financial portfolio management is the process of constant redistribution of a\nfund into different financial products. This paper presents a\nfinancial-model-free Reinforcement Learning framework to provide a deep machine\nlearning solution to the portfolio management problem. The framework consists\nof the Ensemble of Identical Independent Evaluators (EIIE) topology, a\nPortfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL)\nscheme, and a fully exploiting and explicit reward function. This framework is\nrealized in three instants in this work with a Convolutional Neural Network\n(CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term Memory\n(LSTM). They are, along with a number of recently reviewed or published\nportfolio-selection strategies, examined in three back-test experiments with a\ntrading period of 30 minutes in a cryptocurrency market. Cryptocurrencies are\nelectronic and decentralized alternatives to government-issued money, with\nBitcoin as the best-known example of a cryptocurrency. All three instances of\nthe framework monopolize the top three positions in all experiments,\noutdistancing other compared trading algorithms. Although with a high\ncommission rate of 0.25% in the backtests, the framework is able to achieve at\nleast 4-fold returns in 50 days.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.10059v2"
    },
    {
        "title": "Pricing Financial Derivatives using Radial Basis Function generated\n  Finite Differences with Polyharmonic Splines on Smoothly Varying Node Layouts",
        "authors": [
            "Slobodan Milovanović"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we study the benefits of using polyharmonic splines and node\nlayouts with smoothly varying density for developing robust and efficient\nradial basis function generated finite difference (RBF-FD) methods for pricing\nof financial derivatives. We present a significantly improved RBF-FD scheme and\nsuccessfully apply it to two types of multidimensional partial differential\nequations in finance: a two-asset European call basket option under the\nBlack--Scholes--Merton model, and a European call option under the Heston\nmodel. We also show that the performance of the improved method is equally high\nwhen it comes to pricing American options. By studying convergence,\ncomputational performance, and conditioning of the discrete systems, we show\nthe superiority of the introduced approaches over previously used versions of\nthe RBF-FD method in financial applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.02365v2"
    },
    {
        "title": "SINH-acceleration: efficient evaluation of probability distributions,\n  option pricing, and Monte-Carlo simulations",
        "authors": [
            "Svetlana Boyarchenko",
            "Sergei Levendorskiĭ"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Characteristic functions of several popular classes of distributions and\nprocesses admit analytic continuation into unions of strips and open coni\naround $\\mathbb{R}\\subset \\mathbb{C}$. The Fourier transform techniques reduces\ncalculation of probability distributions and option prices to evaluation of\nintegrals whose integrands are analytic in domains enjoying these properties.\nIn the paper, we suggest to use changes of variables of the form\n$\\xi=\\sqrt{-1}\\omega_1+b\\sinh (\\sqrt{-1}\\omega+y)$ and the simplified trapezoid\nrule to evaluate the integrals accurately and fast. We formulate the general\nscheme, and apply the scheme for calculation probability distributions and\npricing European options in L\\'evy models, the Heston model, the CIR model, and\na L\\'evy model with the CIR-subordinator. We outline applications to fast and\naccurate calibration procedures and Monte Carlo simulations in L\\'evy models,\nregime switching L\\'evy models that can account for stochastic drift,\nvolatility and skewness, and the Heston model. For calculation of quantiles in\nthe tails using the Newton or bisection method, it suffices to precalculate\nseveral hundred of values of the characteristic exponent at points of an\nappropriate grid ({\\em conformal principal components}) and use these values in\nformulas for cpdf and pdf.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.05295v1"
    },
    {
        "title": "A High Order Method for Pricing of Financial Derivatives using Radial\n  Basis Function generated Finite Differences",
        "authors": [
            "Slobodan Milovanović",
            "Lina von Sydow"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we consider the numerical pricing of financial derivatives\nusing Radial Basis Function generated Finite Differences in space. Such\ndiscretization methods have the advantage of not requiring Cartesian grids.\nInstead, the nodes can be placed with higher density in areas where there is a\nneed for higher accuracy. Still, the discretization matrix is fairly sparse. As\na model problem, we consider the pricing of European options in 2D. Since such\noptions have a discontinuity in the first derivative of the payoff function\nwhich prohibits high order convergence, we smooth this function using an\nestablished technique for Cartesian grids. Numerical experiments show that we\nacquire a fourth order scheme in space, both for the uniform and the nonuniform\nnode layouts that we use. The high order method with the nonuniform node layout\nachieves very high accuracy with relatively few nodes. This renders the\npotential for solving pricing problems in higher spatial dimensions since the\ncomputational memory and time demand become much smaller with this method\ncompared to standard techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.05890v2"
    },
    {
        "title": "Kernel-based collocation methods for Heath-Jarrow-Morton models with\n  Musiela parametrization",
        "authors": [
            "Yuki Kinoshita",
            "Yumiharu Nakano"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We propose kernel-based collocation methods for numerical solutions to\nHeath-Jarrow-Morton models with Musiela parametrization. The methods can be\nseen as the Euler-Maruyama approximation of some finite dimensional stochastic\ndifferential equations, and allow us to compute the derivative prices by the\nusual Monte Carlo methods. We derive a bound on the rate of convergence under\nsome decay condition on the inverse of the interpolation matrix and some\nregularity conditions on the volatility functionals.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05643v4"
    },
    {
        "title": "An extension of Heston's SV model to Stochastic Interest Rates",
        "authors": [
            "Javier de Frutos",
            "Victor Gaton"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In 'A Closed-Form Solution for Options with Stochastic Volatility with\nApplications to Bond and Currency Options', Heston proposes a Stochastic\nVolatility (SV) model with constant interest rate and derives a semi-explicit\nvaluation formula. Heston also describes, in general terms, how the model could\nbe extended to incorporate Stochastic Interest Rates (SIR). This paper is\ndevoted to the construction of an extension of Heston's SV model with a\nparticular stochastic bond model which, just increasing in one the number of\nparameters, allows to incorporate SIR and to derive a semi-explicit formula for\noption pricing.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.09069v1"
    },
    {
        "title": "Derivatives pricing using signature payoffs",
        "authors": [
            "Imanol Perez Arribas"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We introduce signature payoffs, a family of path-dependent derivatives that\nare given in terms of the signature of the price path of the underlying asset.\nWe show that these derivatives are dense in the space of continuous payoffs, a\nresult that is exploited to quickly price arbitrary continuous payoffs. This\napproach to pricing derivatives is then tested with European options, American\noptions, Asian options, lookback options and variance swaps. As we show,\nsignature payoffs can be used to price these derivatives with very high\naccuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.09466v1"
    },
    {
        "title": "Stochastic Algorithmic Differentiation of (Expectations of)\n  Discontinuous Functions (Indicator Functions)",
        "authors": [
            "Christian P. Fries"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  In this paper, we present a method for the accurate estimation of the\nderivative (aka.~sensitivity) of expectations of functions involving an\nindicator function by combining a stochastic algorithmic differentiation and a\nregression.\n  The method is an improvement of the approach presented in [Risk Magazine\nApril 2018].\n  The finite difference approximation of a partial derivative of a Monte-Carlo\nintegral of a discontinuous function is known to exhibit a high Monte-Carlo\nerror. The issue is evident since the Monte-Carlo approximation of a\ndiscontinuous function is just a finite sum of discontinuous functions and as\nsuch, not even differentiable.\n  The algorithmic differentiation of a discontinuous function is problematic. A\nnatural approach is to replace the discontinuity by continuous functions. This\nis equivalent to replacing a path-wise automatic differentiation by a (local)\nfinite difference approximation.\n  We present an improvement (in terms of variance reduction) by decoupling the\nintegration of the Dirac delta and the remaining conditional expectation and\nestimating the two parts by separate regressions. For the algorithmic\ndifferentiation, we derive an operator that can be injected seamlessly - with\nminimal code changes - into the algorithm resulting in the exact result.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05741v5"
    },
    {
        "title": "Lagged correlation-based deep learning for directional trend change\n  prediction in financial time series",
        "authors": [
            "Ben Moews",
            "J. Michael Herrmann",
            "Gbenga Ibikunle"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Trend change prediction in complex systems with a large number of noisy time\nseries is a problem with many applications for real-world phenomena, with stock\nmarkets as a notoriously difficult to predict example of such systems. We\napproach predictions of directional trend changes via complex lagged\ncorrelations between them, excluding any information about the target series\nfrom the respective inputs to achieve predictions purely based on such\ncorrelations with other series. We propose the use of deep neural networks that\nemploy step-wise linear regressions with exponential smoothing in the\npreparatory feature engineering for this task, with regression slopes as trend\nstrength indicators for a given time interval. We apply this method to\nhistorical stock market data from 2011 to 2016 as a use case example of lagged\ncorrelations between large numbers of time series that are heavily influenced\nby externally arising new information as a random factor. The results\ndemonstrate the viability of the proposed approach, with state-of-the-art\naccuracies and accounting for the statistical significance of the results for\nadditional validation, as well as important implications for modern financial\neconomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.11287v2"
    },
    {
        "title": "Pricing options and computing implied volatilities using neural networks",
        "authors": [
            "Shuaiqiang Liu",
            "Cornelis W. Oosterlee",
            "Sander M. Bohte"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  This paper proposes a data-driven approach, by means of an Artificial Neural\nNetwork (ANN), to value financial options and to calculate implied volatilities\nwith the aim of accelerating the corresponding numerical methods. With ANNs\nbeing universal function approximators, this method trains an optimized ANN on\na data set generated by a sophisticated financial model, and runs the trained\nANN as an agent of the original solver in a fast and efficient way. We test\nthis approach on three different types of solvers, including the analytic\nsolution for the Black-Scholes equation, the COS method for the Heston\nstochastic volatility model and Brent's iterative root-finding method for the\ncalculation of implied volatilities. The numerical results show that the ANN\nsolver can reduce the computing time significantly.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.08943v2"
    },
    {
        "title": "A model-free backward and forward nonlinear PDEs for implied volatility",
        "authors": [
            "Peter Carr",
            "Andrey Itkin",
            "Sasha Stoikov"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We derive a backward and forward nonlinear PDEs that govern the implied\nvolatility of a contingent claim whenever the latter is well-defined. This\nwould include at least any contingent claim written on a positive stock price\nwhose payoff at a possibly random time is convex. We also discuss suitable\ninitial and boundary conditions for those PDEs. Finally, we demonstrate how to\nsolve them numerically by using an iterative finite-difference approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.07305v1"
    },
    {
        "title": "Deep Learning-Based Least Square Forward-Backward Stochastic\n  Differential Equation Solver for High-Dimensional Derivative Pricing",
        "authors": [
            "Jian Liang",
            "Zhe Xu",
            "Peter Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We propose a new forward-backward stochastic differential equation solver for\nhigh-dimensional derivatives pricing problems by combining deep learning solver\nwith least square regression technique widely used in the least square Monte\nCarlo method for the valuation of American options. Our numerical experiments\ndemonstrate the efficiency and accuracy of our least square backward deep\nneural network solver and its capability to provide accurate prices for complex\nearly exercise derivatives such as callable yield notes. Our method can serve\nas a generic numerical solver for pricing derivatives across various asset\ngroups, in particular, as an efficient means for pricing high-dimensional\nderivatives with early exercises features.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10578v2"
    },
    {
        "title": "Algorithmic market making for options",
        "authors": [
            "Bastien Baldacci",
            "Philippe Bergault",
            "Olivier Guéant"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  In this article, we tackle the problem of a market maker in charge of a book\nof options on a single liquid underlying asset. By using an approximation of\nthe portfolio in terms of its vega, we show that the seemingly high-dimensional\nstochastic optimal control problem of an option market maker is in fact\ntractable. More precisely, when volatility is modeled using a classical\nstochastic volatility model -- e.g. the Heston model -- the problem faced by an\noption market maker is characterized by a low-dimensional functional equation\nthat can be solved numerically using a Euler scheme along with interpolation\ntechniques, even for large portfolios. In order to illustrate our findings,\nnumerical examples are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12433v7"
    },
    {
        "title": "Isogeometric analysis in option pricing",
        "authors": [
            "Jan Pospíšil",
            "Vladimír Švígler"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Isogeometric analysis is a recently developed computational approach that\nintegrates finite element analysis directly into design described by\nnon-uniform rational B-splines (NURBS). In this paper we show that price\nsurfaces that occur in option pricing can be easily described by NURBS\nsurfaces. For a class of stochastic volatility models, we develop a methodology\nfor solving corresponding pricing partial integro-differential equations\nnumerically by isogeometric analysis tools and show that a very small number of\nspace discretization steps can be used to obtain sufficiently accurate results.\nPresented solution by finite element method is especially useful for\npractitioners dealing with derivatives where closed-form solution is not\navailable.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.00258v1"
    },
    {
        "title": "A deep learning approach for computations of exposure profiles for\n  high-dimensional Bermudan options",
        "authors": [
            "Kristoffer Andersson",
            "Cornelis Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper, we propose a neural network-based method for approximating\nexpected exposures and potential future exposures of Bermudan options. In a\nfirst phase, the method relies on the Deep Optimal Stopping algorithm, which\nlearns the optimal stopping rule from Monte-Carlo samples of the underlying\nrisk factors. Cashflow-paths are then created by applying the learned stopping\nstrategy on a new set of realizations of the risk factors. Furthermore, in a\nsecond phase the risk factors are regressed against the cashflow-paths to\nobtain approximations of pathwise option values. The regression step is carried\nout by ordinary least squares as well as neural networks, and it is shown that\nthe latter produces more accurate approximations.\n  The expected exposure is formulated, both in terms of the cashflow-paths and\nin terms of the pathwise option values and it is shown that a simple\nMonte-Carlo average yields accurate approximations in both cases. The potential\nfuture exposure is estimated by the empirical $\\alpha$-percentile.\n  Finally, it is shown that the expected exposures, as well as the potential\nfuture exposures can be computed under either, the risk neutral measure, or the\nreal world measure, without having to re-train the neural networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.01977v3"
    },
    {
        "title": "Time-varying neural network for stock return prediction",
        "authors": [
            "Steven Y. K. Wong",
            "Jennifer Chan",
            "Lamiae Azizi",
            "Richard Y. D. Xu"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We consider the problem of neural network training in a time-varying context.\nMachine learning algorithms have excelled in problems that do not change over\ntime. However, problems encountered in financial markets are often\ntime-varying. We propose the online early stopping algorithm and show that a\nneural network trained using this algorithm can track a function changing with\nunknown dynamics. We compare the proposed algorithm to current approaches on\npredicting monthly U.S. stock returns and show its superiority. We also show\nthat prominent factors (such as the size and momentum effects) and industry\nindicators, exhibit time varying stock return predictiveness. We find that\nduring market distress, industry indicators experience an increase in\nimportance at the expense of firm level features. This indicates that\nindustries play a role in explaining stock returns during periods of heightened\nrisk.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.02515v4"
    },
    {
        "title": "Malliavin-Mancino estimators implemented with non-uniform fast Fourier\n  transforms",
        "authors": [
            "Patrick Chang",
            "Etienne Pienaar",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We implement and test kernel averaging Non-Uniform Fast Fourier Transform\n(NUFFT) methods to enhance the performance of correlation and covariance\nestimation on asynchronously sampled event-data using the Malliavin-Mancino\nFourier estimator. The methods are benchmarked for Dirichlet and Fej\\'{e}r\nFourier basis kernels. We consider test cases formed from Geometric Brownian\nmotions to replicate synchronous and asynchronous data for benchmarking\npurposes. We consider three standard averaging kernels to convolve the\nevent-data for synchronisation via over-sampling for use with the Fast Fourier\nTransform (FFT): the Gaussian kernel, the Kaiser-Bessel kernel, and the\nexponential of semi-circle kernel. First, this allows us to demonstrate the\nperformance of the estimator with different combinations of basis kernels and\naveraging kernels. Second, we investigate and compare the impact of the\naveraging scales explicit in each averaging kernel and its relationship between\nthe time-scale averaging implicit in the Malliavin-Mancino estimator. Third, we\ndemonstrate the relationship between time-scale averaging based on the number\nof Fourier coefficients used in the estimator to a theoretical model of the\nEpps effect. We briefly demonstrate the methods on Trade-and-Quote (TAQ) data\nfrom the Johannesburg Stock Exchange to make an initial visualisation of the\ncorrelation dynamics for various time-scales under market microstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.02842v3"
    },
    {
        "title": "Convex Optimization Over Risk-Neutral Probabilities",
        "authors": [
            "Shane Barratt",
            "Jonathan Tuck",
            "Stephen Boyd"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We consider a collection of derivatives that depend on the price of an\nunderlying asset at expiration or maturity. The absence of arbitrage is\nequivalent to the existence of a risk-neutral probability distribution on the\nprice; in particular, any risk neutral distribution can be interpreted as a\ncertificate establishing that no arbitrage exists. We are interested in the\ncase when there are multiple risk-neutral probabilities. We describe a number\nof convex optimization problems over the convex set of risk neutral price\nprobabilities. These include computation of bounds on the cumulative\ndistribution, VaR, CVaR, and other quantities, over the set of risk-neutral\nprobabilities. After discretizing the underlying price, these problems become\nfinite dimensional convex or quasiconvex optimization problems, and therefore\nare tractable. We illustrate our approach using real options and futures\npricing data for the S&P 500 index and Bitcoin.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.02878v1"
    },
    {
        "title": "A computational weighted finite difference method for American and\n  barrier options in subdiffusive Black-Scholes model",
        "authors": [
            "Grzegorz Krzyżanowski",
            "Marcin Magdziarz"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Subdiffusion is a well established phenomenon in physics. In this paper we\napply the subdiffusive dynamics to analyze financial markets. We focus on the\nfinancial aspect of time fractional diffusion model with moving boundary i.e.\nAmerican and barrier option pricing in the subdiffusive Black-Scholes (B-S)\nmodel. Two computational methods for valuing American options in the considered\nmodel are proposed - the weighted finite difference (FD) and the\nLongstaff-Schwartz method. In the article it is also shown how to valuate\nnumerically wide range of barrier options using the FD approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.05358v4"
    },
    {
        "title": "Multilevel Monte Carlo with Numerical Smoothing for Robust and Efficient\n  Computation of Probabilities and Densities",
        "authors": [
            "Christian Bayer",
            "Chiheb Ben Hammouda",
            "Raul Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  The multilevel Monte Carlo (MLMC) method is highly efficient for estimating\nexpectations of a functional of a solution to a stochastic differential\nequation (SDE). However, MLMC estimators may be unstable and have a poor\n(noncanonical) complexity in the case of low regularity of the functional. To\novercome this issue, we extend our previously introduced idea of numerical\nsmoothing in (Quantitative Finance, 23(2), 209-227, 2023), in the context of\ndeterministic quadrature methods to the MLMC setting. The numerical smoothing\ntechnique is based on root-finding methods combined with one-dimensional\nnumerical integration with respect to a single well-chosen variable. This study\nis motivated by the computation of probabilities of events, pricing options\nwith a discontinuous payoff, and density estimation problems for dynamics where\nthe discretization of the underlying stochastic processes is necessary. The\nanalysis and numerical experiments reveal that the numerical smoothing\nsignificantly improves the strong convergence, and consequently, the complexity\nand robustness (by making the kurtosis at deep levels bounded) of the MLMC\nmethod. In particular, we show that numerical smoothing enables recovering the\nMLMC complexities obtained for Lipschitz functionals due to the optimal\nvariance decay rate when using the Euler--Maruyama scheme. For the Milstein\nscheme, numerical smoothing recovers the canonical MLMC complexity even for the\nnonsmooth integrand mentioned above. Finally, our approach efficiently\nestimates univariate and multivariate density functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.05708v4"
    },
    {
        "title": "Explaining herding and volatility in the cyclical price dynamics of\n  urban housing markets using a large scale agent-based model",
        "authors": [
            "Kirill S. Glavatskiy",
            "Mikhail Prokopenko",
            "Adrian Carro",
            "Paul Ormerod",
            "Michael Harre"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Urban housing markets, along with markets of other assets, universally\nexhibit periods of strong price increases followed by sharp corrections. The\nmechanisms generating such non-linearities are not yet well understood. We\ndevelop an agent-based model populated by a large number of heterogeneous\nhouseholds. The agents' behavior is compatible with economic rationality, with\nthe trend-following behavior found to be essential in replicating market\ndynamics. The model is calibrated using several large and distributed datasets\nof the Greater Sydney region (demographic, economic and financial) across three\nspecific and diverse periods since 2006. The model is not only capable of\nexplaining price dynamics during these periods, but also reproduces the novel\nbehavior actually observed immediately prior to the market peak in 2017, namely\na sharp increase in the variability of prices. This novel behavior is related\nto a combination of trend-following aptitude of the household agents (rational\nherding) and their propensity to borrow.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.07571v1"
    },
    {
        "title": "Empirical Study of Market Impact Conditional on Order-Flow Imbalance",
        "authors": [
            "Anastasia Bugaenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this research, we have empirically investigated the key drivers affecting\nliquidity in equity markets. We illustrated how theoretical models, such as\nKyle's model, of agents' interplay in the financial markets, are aligned with\nthe phenomena observed in publicly available trades and quotes data.\nSpecifically, we confirmed that for small signed order-flows, the price impact\ngrows linearly with increase in the order-flow imbalance. We have, further,\nimplemented a machine learning algorithm to forecast market impact given a\nsigned order-flow. Our findings suggest that machine learning models can be\nused in estimation of financial variables; and predictive accuracy of such\nlearning algorithms can surpass the performance of traditional statistical\napproaches.\n  Understanding the determinants of price impact is crucial for several\nreasons. From a theoretical stance, modelling the impact provides a statistical\nmeasure of liquidity. Practitioners adopt impact models as a pre-trade tool to\nestimate expected transaction costs and optimize the execution of their\nstrategies. This further serves as a post-trade valuation benchmark as\nsuboptimal execution can significantly deteriorate a portfolio performance.\n  More broadly, the price impact reflects the balance of liquidity across\nmarkets. This is of central importance to regulators as it provides an\nall-encompassing explanation of the correlation between market design and\nsystemic risk, enabling regulators to design more stable and efficient markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.08290v2"
    },
    {
        "title": "Semi-closed form prices of barrier options in the Hull-White model",
        "authors": [
            "Andrey Itkin",
            "Dmitry Muravey"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this paper we derive semi-closed form prices of barrier (perhaps,\ntime-dependent) options for the Hull-White model, ie., where the underlying\nfollows a time-dependent OU process with a mean-reverting drift. Our approach\nis similar to that in (Carr and Itkin, 2020) where the method of generalized\nintegral transform is applied to pricing barrier options in the time-dependent\nOU model, but extends it to an infinite domain (which is an unsolved problem\nyet). Alternatively, we use the method of heat potentials for solving the same\nproblems. By semi-closed solution we mean that first, we need to solve\nnumerically a linear Volterra equation of the first kind, and then the option\nprice is represented as a one-dimensional integral. Our analysis shows that\ncomputationally our method is more efficient than the backward and even forward\nfinite difference methods (if one uses them to solve those problems), while\nproviding better accuracy and stability.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09591v2"
    },
    {
        "title": "Avoiding zero probability events when computing Value at Risk\n  contributions",
        "authors": [
            "Takaaki Koike",
            "Yuri F. Saporito",
            "Rodrigo S. Targino"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper is concerned with the process of risk allocation for a generic\nmultivariate model when the risk measure is chosen as the Value-at-Risk (VaR).\nWe recast the traditional Euler contributions from an expectation conditional\non an event of zero probability to a ratio involving conditional expectations\nwhose conditioning events have strictly positive probability. We derive an\nanalytical form of the proposed representation of VaR contributions for various\nparametric models. Our numerical experiments show that the estimator using this\nnovel representation outperforms the standard Monte Carlo estimator in terms of\nbias and variance. Moreover, unlike the existing estimators, the proposed\nestimator is free from hyperparameters under a parametric setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.13235v3"
    },
    {
        "title": "Mapping Coupled Time-series Onto Complex Network",
        "authors": [
            "Jamshid Ardalankia",
            "Jafar Askari",
            "Somaye Sheykhali",
            "Emmanuel Haven",
            "G. Reza Jafari"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In order to extract hidden joint information from two possibly uncorrelated\ntime-series, we explored the measures of network science. Alongside common\nmethods in time-series analysis of the economic markets, mapping the joint\nstructure of two time-series onto a network provides insight into hidden\naspects embedded in the couplings. We discretize the amplitude of two\ntime-series and investigate relative simultaneous locations of those\namplitudes. Each segment of a discretized amplitude is considered as a node.\nThe simultaneity of the amplitudes of the two time-series is considered as the\nedges in the network. The frequency of occurrences forms the weighted edges. In\norder to extract information, we need to measure that to what extent the\ncoupling deviates from the coupling of two uncoupled series. Also, we need to\nmeasure that to what extent the couplings inherit their characteristics from a\nGaussian distribution or a non-Gaussian distribution. We mapped the network\nfrom two surrogate time-series. The results show that the couplings of markets\npossess some features which diverge from the same features of the network\nmapped from white noise, and from the network mapped from two surrogate\ntime-series. These deviations prove that there exist joint information and\ncross-correlation therein. By applying the network's topological and\nstatistical measures and the deformation ratio in the joint probability\ndistribution, we distinguished basic structures of cross-correlation and\ncoupling of cross-markets. It was discovered that even two possibly known\nuncorrelated markets may possess some joint patterns with each other. Thereby,\nthose markets should be examined as coupled and \\textit{weakly} coupled\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.13536v2"
    },
    {
        "title": "An Adaptive and Explicit Fourth Order Runge-Kutta-Fehlberg Method\n  Coupled with Compact Finite Differencing for Pricing American Put Options",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We propose an adaptive and explicit fourth-order Runge-Kutta-Fehlberg method\ncoupled with a fourth-order compact scheme to solve the American put options\nproblem. First, the free boundary problem is converted into a system of partial\ndifferential equations with a fixed domain by using logarithm transformation\nand taking additional derivatives. With the addition of an intermediate\nfunction with a fixed free boundary, a quadratic formula is derived to compute\nthe velocity of the optimal exercise boundary analytically. Furthermore, we\nimplement an extrapolation method to ensure that at least, a third-order\naccuracy in space is maintained at the boundary point when computing the\noptimal exercise boundary from its derivative. As such, it enables us to employ\nfourth-order spatial and temporal discretization with Dirichlet boundary\nconditions for obtaining the numerical solution of the asset option, option\nGreeks, and the optimal exercise boundary. The advantage of the\nRunge-Kutta-Fehlberg method is based on error control and the adjustment of the\ntime step to maintain the error at a certain threshold. By comparing with some\nexisting methods in the numerical experiment, it shows that the present method\nhas a better performance in terms of computational speed and provides a more\naccurate solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.04408v5"
    },
    {
        "title": "Information Coefficient as a Performance Measure of Stock Selection\n  Models",
        "authors": [
            "Feng Zhang",
            "Ruite Guo",
            "Honggao Cao"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Information coefficient (IC) is a widely used metric for measuring investment\nmanagers' skills in selecting stocks. However, its adequacy and effectiveness\nfor evaluating stock selection models has not been clearly understood, as IC\nfrom a realistic stock selection model can hardly be materially different from\nzero and is often accompanies with high volatility. In this paper, we\ninvestigate the behavior of IC as a performance measure of stick selection\nmodels. Through simulation and simple statistical modeling, we examine the IC\nbehavior both statically and dynamically. The examination helps us propose two\npractical procedures that one may use for IC-based ongoing performance\nmonitoring of stock selection models.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08601v1"
    },
    {
        "title": "Non-Equilibrium Skewness, Market Crises, and Option Pricing: Non-Linear\n  Langevin Model of Markets with Supersymmetry",
        "authors": [
            "Igor Halperin"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  This paper presents a tractable model of non-linear dynamics of market\nreturns using a Langevin approach. Due to non-linearity of an interaction\npotential, the model admits regimes of both small and large return\nfluctuations. Langevin dynamics are mapped onto an equivalent quantum\nmechanical (QM) system. Borrowing ideas from supersymmetric quantum mechanics\n(SUSY QM), a parameterized ground state wave function (WF) of this QM system is\nused as a direct input to the model, which also fixes a non-linear Langevin\npotential. Using a two-component Gaussian mixture as a ground state WF with an\nasymmetric double well potential produces a tractable low-parametric model with\ninterpretable parameters, referred to as the NES (Non-Equilibrium Skew) model.\nSupersymmetry (SUSY) is then used to find time-dependent solutions of the model\nin an analytically tractable way. Additional approximations give rise to a\nfinal practical version of the NES model, where real-measure and risk-neutral\nreturn distributions are given by three component Gaussian mixtures. This\nproduces a closed-form approximation for option pricing in the NES model by a\nmixture of three Black-Scholes prices, providing accurate calibration to option\nprices for either benign or distressed market environments, while using only a\nsingle volatility parameter. These results stand in stark contrast to the most\nof other option pricing models such as local, stochastic, or rough volatility\nmodels that need more complex specifications of noise to fit the market data.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.01417v3"
    },
    {
        "title": "A bivariate Normal Inverse Gaussian process with stochastic delay:\n  efficient simulations and applications to energy markets",
        "authors": [
            "Matteo Gardini",
            "Piergiacomo Sabino",
            "Emanuela Sasso"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  Using the concept of self-decomposable subordinators introduced in Gardini et\nal. [11], we build a new bivariate Normal Inverse Gaussian process that can\ncapture stochastic delays. In addition, we also develop a novel path simulation\nscheme that relies on the mathematical connection between self-decomposable\nInverse Gaussian laws and L\\'evy-driven Ornstein-Uhlenbeck processes with\nInverse Gaussian stationary distribution. We show that our approach provides an\nimprovement to the existing simulation scheme detailed in Zhang and Zhang [23]\nbecause it does not rely on an acceptance-rejection method. Eventually, these\nresults are applied to the modelling of energy markets and to the pricing of\nspread options using the proposed Monte Carlo scheme and Fourier techniques\n",
        "pdf_link": "http://arxiv.org/pdf/2011.04256v1"
    },
    {
        "title": "Optimal control of the decumulation of a retirement portfolio with\n  variable spending and dynamic asset allocation",
        "authors": [
            "Peter A. Forsyth",
            "Kenneth R. Vetzal",
            "Graham Westmacott"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We extend the Annually Recalculated Virtual Annuity (ARVA) spending rule for\nretirement savings decumulation to include a cap and a floor on withdrawals.\nWith a minimum withdrawal constraint, the ARVA strategy runs the risk of\ndepleting the investment portfolio. We determine the dynamic asset allocation\nstrategy which maximizes a weighted combination of expected total withdrawals\n(EW) and expected shortfall (ES), defined as the average of the worst five per\ncent of the outcomes of real terminal wealth. We compare the performance of our\ndynamic strategy to simpler alternatives which maintain constant asset\nallocation weights over time accompanied by either our same modified ARVA\nspending rule or withdrawals that are constant over time in real terms. Tests\nare carried out using both a parametric model of historical asset returns as\nwell as bootstrap resampling of historical data. Consistent with previous\nliterature that has used different measures of reward and risk than EW and ES,\nwe find that allowing some variability in withdrawals leads to large\nimprovements in efficiency. However, unlike the prior literature, we also\ndemonstrate that further significant enhancements are possible through\nincorporating a dynamic asset allocation strategy rather than simply keeping\nasset allocation weights constant throughout retirement.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.02760v1"
    },
    {
        "title": "Least Squares Monte Carlo applied to Dynamic Monetary Utility Functions",
        "authors": [
            "Hampus Engsner"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  In this paper we explore ways of numerically computing recursive dynamic\nmonetary risk measures and utility functions. Computationally, this problem\nsuffers from the curse of dimensionality and nested simulations are unfeasible\nif there are more than two time steps. The approach considered in this paper is\nto use a Least Squares Monte Carlo (LSM) algorithm to tackle this problem, a\nmethod which has been primarily considered for valuing American derivatives, or\nmore general stopping time problems, as these also give rise to backward\nrecursions with corresponding challenges in terms of numerical computation. We\ngive some overarching consistency results for the LSM algorithm in a general\nsetting as well as explore numerically its performance for recursive\nCost-of-Capital valuation, a special case of a dynamic monetary utility\nfunction.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.10947v2"
    },
    {
        "title": "Aiding Long-Term Investment Decisions with XGBoost Machine Learning\n  Model",
        "authors": [
            "Ekaterina Zolotareva"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The ability to identify stock market trends has obvious advantages for\ninvestors. Buying stock on an upward trend (as well as selling it in case of\ndownward movement) results in profit. Accordingly, the start and end-points of\nthe trend are the optimal points for entering and leaving the market. The\nresearch concentrates on recognizing stock market long-term upward and downward\ntrends. The key results are obtained with the use of gradient boosting\nalgorithms, XGBoost in particular. The raw data is represented by time series\nwith basic stock market quotes with periods labelled by experts as Trend or\nFlat. The features are then obtained via various data transformations, aiming\nto catch implicit factors resulting in a change of stock direction. Modelling\nis done in two stages: stage one aims to detect endpoints of tendencies (i.e.\nsliding windows), stage two recognizes the tendency itself inside the window.\nThe research addresses such issues as imbalanced datasets and contradicting\nlabels, as well as the need for specific quality metrics to keep up with\npractical applicability. The model can be used to design an investment strategy\nthough further research in feature engineering and fine calibration is\nrequired.This paper is the full text of the research, presented at the 20th\nInternational Conference on Artificial Intelligence and Soft Computing Web\nSystem (ICAISC 2021)\n",
        "pdf_link": "http://arxiv.org/pdf/2104.09341v1"
    },
    {
        "title": "Estimating Future VaR from Value Samples and Applications to Future\n  Initial Margin",
        "authors": [
            "Narayan Ganesan",
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Predicting future values at risk (fVaR) is an important problem in finance.\nThey arise in the modelling of future initial margin requirements for\ncounterparty credit risk and future market risk VaR. One is also interested in\nderived quantities such as: i) Dynamic Initial Margin (DIM) and Margin Value\nAdjustment (MVA) in the counterparty risk context; and ii) risk weighted assets\n(RWA) and Capital Value Adjustment (KVA) for market risk. This paper describes\nseveral methods that can be used to predict fVaRs. We begin with the Nested\nMC-empirical quantile method as benchmark, but it is too computationally\nintensive for routine use. We review several known methods and discuss their\nnovel applications to the problem at hand.\n  The techniques considered include computing percentiles from distributions\n(Normal and Johnson) that were matched to parametric moments or percentile\nestimates, quantile regressions methods, and others with more specific\nassumptions or requirements.\n  We also consider how limited inner simulations can be used to improve the\nperformance of these techniques. The paper also provides illustrations,\nresults, and visualizations of intermediate and final results for the various\napproaches and methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.11768v1"
    },
    {
        "title": "Deep Graph Convolutional Reinforcement Learning for Financial Portfolio\n  Management -- DeepPocket",
        "authors": [
            "Farzan Soleymani",
            "Eric Paquet"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Portfolio management aims at maximizing the return on investment while\nminimizing risk by continuously reallocating the assets forming the portfolio.\nThese assets are not independent but correlated during a short time period. A\ngraph convolutional reinforcement learning framework called DeepPocket is\nproposed whose objective is to exploit the time-varying interrelations between\nfinancial instruments. These interrelations are represented by a graph whose\nnodes correspond to the financial instruments while the edges correspond to a\npair-wise correlation function in between assets. DeepPocket consists of a\nrestricted, stacked autoencoder for feature extraction, a convolutional network\nto collect underlying local information shared among financial instruments, and\nan actor-critic reinforcement learning agent. The actor-critic structure\ncontains two convolutional networks in which the actor learns and enforces an\ninvestment policy which is, in turn, evaluated by the critic in order to\ndetermine the best course of action by constantly reallocating the various\nportfolio assets to optimize the expected return on investment. The agent is\ninitially trained offline with online stochastic batching on historical data.\nAs new data become available, it is trained online with a passive concept drift\napproach to handle unexpected changes in their distributions. DeepPocket is\nevaluated against five real-life datasets over three distinct investment\nperiods, including during the Covid-19 crisis, and clearly outperformed market\nindexes.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08664v1"
    },
    {
        "title": "Volatility Modeling of Stocks from Selected Sectors of the Indian\n  Economy Using GARCH",
        "authors": [
            "Jaydip Sen",
            "Sidra Mehtab",
            "Abhishek Dutta"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Volatility clustering is an important characteristic that has a significant\neffect on the behavior of stock markets. However, designing robust models for\naccurate prediction of future volatilities of stock prices is a very\nchallenging research problem. We present several volatility models based on\ngeneralized autoregressive conditional heteroscedasticity (GARCH) framework for\nmodeling the volatility of ten stocks listed in the national stock exchange\n(NSE) of India. The stocks are selected from the auto sector and the banking\nsector of the Indian economy, and they have a significant impact on the\nsectoral index of their respective sectors in the NSE. The historical stock\nprice records from Jan 1, 2010, to Apr 30, 2021, are scraped from the Yahoo\nFinance website using the DataReader API of the Pandas module in the Python\nprogramming language. The GARCH modules are built and fine-tuned on the\ntraining data and then tested on the out-of-sample data to evaluate the\nperformance of the models. The analysis of the results shows that asymmetric\nGARCH models yield more accurate forecasts on the future volatility of stocks.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.13898v1"
    },
    {
        "title": "Chebyshev Greeks: Smoothing Gamma without Bias",
        "authors": [
            "Andrea Maran",
            "Andrea Pallavicini",
            "Stefano Scoleri"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The computation of Greeks is a fundamental task for risk managing of\nfinancial instruments. The standard approach to their numerical evaluation is\nvia finite differences. Most exotic derivatives are priced via Monte Carlo\nsimulation: in these cases, it is hard to find a fast and accurate\napproximation of Greeks, mainly because of the need of a tradeoff between bias\nand variance. Recent improvements in Greeks computation, such as Adjoint\nAlgorithmic Differentiation, are unfortunately uneffective on second order\nGreeks (such as Gamma), which are plagued by the most significant\ninstabilities, so that a viable alternative to standard finite differences is\nstill lacking. We apply Chebyshev interpolation techniques to the computation\nof spot Greeks, showing how to improve the stability of finite difference\nGreeks of arbitrary order, in a simple and general way. The increased\nperformance of the proposed technique is analyzed for a number of real payoffs\ncommonly traded by financial institutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.12431v1"
    },
    {
        "title": "Deep calibration of the quadratic rough Heston model",
        "authors": [
            "Mathieu Rosenbaum",
            "Jianfei Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The quadratic rough Heston model provides a natural way to encode Zumbach\neffect in the rough volatility paradigm. We apply multi-factor approximation\nand use deep learning methods to build an efficient calibration procedure for\nthis model. We show that the model is able to reproduce very well both SPX and\nVIX implied volatilities. We typically obtain VIX option prices within the\nbid-ask spread and an excellent fit of the SPX at-the-money skew. Moreover, we\nalso explain how to use the trained neural networks for hedging with\ninstantaneous computation of hedging quantities.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01611v2"
    },
    {
        "title": "Predicting Risk-adjusted Returns using an Asset Independent\n  Regime-switching Model",
        "authors": [
            "Nicklas Werge"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Financial markets tend to switch between various market regimes over time,\nmaking stationarity-based models unsustainable. We construct a regime-switching\nmodel independent of asset classes for risk-adjusted return predictions based\non hidden Markov models. This framework can distinguish between market regimes\nin a wide range of financial markets such as the commodity, currency, stock,\nand fixed income market. The proposed method employs sticky features that\ndirectly affect the regime stickiness and thereby changing turnover levels. An\ninvestigation of our metric for risk-adjusted return predictions is conducted\nby analyzing daily financial market changes for almost twenty years. Empirical\ndemonstrations of out-of-sample observations obtain an accurate detection of\nbull, bear, and high volatility periods, improving risk-adjusted returns while\nkeeping a preferable turnover level.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.05535v1"
    },
    {
        "title": "AI in Finance: Challenges, Techniques and Opportunities",
        "authors": [
            "Longbing Cao"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  AI in finance broadly refers to the applications of AI techniques in\nfinancial businesses. This area has been lasting for decades with both classic\nand modern AI techniques applied to increasingly broader areas of finance,\neconomy and society. In contrast to either discussing the problems, aspects and\nopportunities of finance that have benefited from specific AI techniques and in\nparticular some new-generation AI and data science (AIDS) areas or reviewing\nthe progress of applying specific techniques to resolving certain financial\nproblems, this review offers a comprehensive and dense roadmap of the\noverwhelming challenges, techniques and opportunities of AI research in finance\nover the past decades. The landscapes and challenges of financial businesses\nand data are firstly outlined, followed by a comprehensive categorization and a\ndense overview of the decades of AI research in finance. We then structure and\nillustrate the data-driven analytics and learning of financial businesses and\ndata. The comparison, criticism and discussion of classic vs. modern AI\ntechniques for finance are followed. Lastly, open issues and opportunities\naddress future AI-empowered finance and finance-motivated AI research.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09051v1"
    },
    {
        "title": "Time-adaptive high-order compact finite difference schemes for option\n  pricing in a family of stochastic volatility models",
        "authors": [
            "Bertram Düring",
            "Christof Heuer"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We propose a time-adaptive, high-order compact finite difference scheme for\noption pricing in a family of stochastic volatility models. We employ a\nsemi-discrete high-order compact finite difference method for the spatial\ndiscretisation, and combine this with an adaptive time discretisation,\nextending ideas from [LSRHF02] to fourth-order multistep methods in time.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09094v1"
    },
    {
        "title": "Adaptive Multilevel Monte Carlo for Probabilities",
        "authors": [
            "Abdul-Lateef Haji-Ali",
            "Jonathan Spence",
            "Aretha Teckentrup"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We consider the numerical approximation of $\\mathbb{P}[G\\in \\Omega]$ where\nthe $d$-dimensional random variable $G$ cannot be sampled directly, but there\nis a hierarchy of increasingly accurate approximations\n$\\{G_\\ell\\}_{\\ell\\in\\mathbb{N}}$ which can be sampled. The cost of standard\nMonte Carlo estimation scales poorly with accuracy in this setup since it\ncompounds the approximation and sampling cost. A direct application of\nMultilevel Monte Carlo improves this cost scaling slightly, but returns\nsub-optimal computational complexities since estimation of the probability\ninvolves a discontinuous functional of $G_\\ell$. We propose a general adaptive\nframework which is able to return the MLMC complexities seen for smooth or\nLipschitz functionals of $G_\\ell$. Our assumptions and numerical analysis are\nkept general allowing the methods to be used for a wide class of problems. We\npresent numerical experiments on nested simulation for risk estimation, where\n$G = \\mathbb{E}[X|Y]$ is approximated by an inner Monte Carlo estimate. Further\nexperiments are given for digital option pricing, involving an approximation of\na $d$-dimensional SDE.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09148v1"
    },
    {
        "title": "Deep equal risk pricing of financial derivatives with non-translation\n  invariant risk measures",
        "authors": [
            "Alexandre Carbonneau",
            "Frédéric Godin"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The use of non-translation invariant risk measures within the equal risk\npricing (ERP) methodology for the valuation of financial derivatives is\ninvestigated. The ability to move beyond the class of convex risk measures\nconsidered in several prior studies provides more flexibility within the\npricing scheme. In particular, suitable choices for the risk measure embedded\nin the ERP framework such as the semi-mean-square-error (SMSE) are shown herein\nto alleviate the price inflation phenomenon observed under Tail Value-at-Risk\nbased ERP as documented for instance in Carbonneau and Godin (2021b). The\nnumerical implementation of non-translation invariant ERP is performed through\ndeep reinforcement learning, where a slight modification is applied to the\nconventional deep hedging training algorithm (see Buehler et al., 2019) so as\nto enable obtaining a price through a single training run for the two neural\nnetworks associated with the respective long and short hedging strategies. The\naccuracy of the neural network training procedure is shown in simulation\nexperiments not to be materially impacted by such modification of the training\nalgorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11340v1"
    },
    {
        "title": "Realised Volatility Forecasting: Machine Learning via Financial Word\n  Embedding",
        "authors": [
            "Eghbal Rahimikia",
            "Stefan Zohren",
            "Ser-Huang Poon"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  This study develops a financial word embedding using 15 years of business\nnews. Our results show that this specialised language model produces more\naccurate results than general word embeddings, based on a financial benchmark\nwe established. As an application, we incorporate this word embedding into a\nsimple machine learning model to enhance the HAR model for forecasting realised\nvolatility. This approach statistically and economically outperforms\nestablished econometric models. Using an explainable AI method, we also\nidentify key phrases in business news that contribute significantly to\nvolatility, offering insights into language patterns tied to market dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.00480v4"
    },
    {
        "title": "The Generalized Gamma distribution as a useful RND under Heston's\n  stochastic volatility model",
        "authors": [
            "Ben Boukai"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Following Boukai (2021) we present the Generalized Gamma (GG) distribution as\na possible RND for modeling European options prices under Heston's (1993)\nstochastic volatility (SV) model. This distribution is seen as especially\nuseful in situations in which the spot's price follows a negatively skewed\ndistribution and hence, Black-Scholes based (i.e. the log-normal distribution)\nmodeling is largely inapt. We apply the GG distribution as RND to modeling\ncurrent market option data on three large market-index ETFs, namely the SPY,\nIWM and QQQ as well as on the TLT (an ETF that tracks an index of long term US\nTreasury bonds). The current option chain of each of the three market-index\nETFs shows of a pronounced skew of their volatility `smile' which indicates a\nlikely distortion in the Black-Scholes modeling of such option data. Reflective\nof entirely different market expectations, this distortion appears not to exist\nin the TLT option data. We provide a thorough modeling of the available option\ndata we have on each ETF (with the October 15, 2021 expiration) based on the GG\ndistribution and compared it to the option pricing and RND modeling obtained\ndirectly from a well-calibrated Heston's (1993) SV model (both theoretically\nand empirically, using Monte-Carlo simulations of the spot's price). All three\nmarket-index ETFs exhibit negatively skewed distributions which are\nwell-matched with those derived under the GG distribution as RND. The\ninadequacy of the Black-Scholes modeling in such instances which involve\nnegatively skewed distribution is further illustrated by its impact on the\nhedging factor, delta, and the immediate implications to the retail trader. In\ncontrast, for the TLT ETF, which exhibits no such distortion to the volatility\n`smile', the three pricing models (i.e. Heston's, Black-Scholes and Generalized\nGamma) appear to yield similar results.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.07937v2"
    },
    {
        "title": "Discriminating modelling approaches for Point in Time Economic Scenario\n  Generation",
        "authors": [
            "Rui Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We introduce the notion of Point in Time Economic Scenario Generation (PiT\nESG) with a clear mathematical problem formulation to unify and compare\neconomic scenario generation approaches conditional on forward looking market\ndata. Such PiT ESGs should provide quicker and more flexible reactions to\nsudden economic changes than traditional ESGs calibrated solely to long periods\nof historical data. We specifically take as economic variable the S&P500 Index\nwith the VIX Index as forward looking market data to compare the nonparametric\nfiltered historical simulation, GARCH model with joint likelihood estimation\n(parametric), Restricted Boltzmann Machine and the conditional Variational\nAutoencoder (Generative Networks) for their suitability as PiT ESG. Our\nevaluation consists of statistical tests for model fit and benchmarking the out\nof sample forecasting quality with a strategy backtest using model output as\nstop loss criterion. We find that both Generative Networks outperform the\nnonparametric and classic parametric model in our tests, but that the CVAE\nseems to be particularly well suited for our purposes: yielding more robust\nperformance and being computationally lighter.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.08818v1"
    },
    {
        "title": "Multi Anchor Point Shrinkage for the Sample Covariance Matrix (Extended\n  Version)",
        "authors": [
            "Hubeyb Gurdogan",
            "Alec Kercheval"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Portfolio managers faced with limited sample sizes must use factor models to\nestimate the covariance matrix of a high-dimensional returns vector. For the\nsimplest one-factor market model, success rests on the quality of the estimated\nleading eigenvector \"beta\".\n  When only the returns themselves are observed, the practitioner has available\nthe \"PCA\" estimate equal to the leading eigenvector of the sample covariance\nmatrix. This estimator performs poorly in various ways. To address this problem\nin the high-dimension, limited sample size asymptotic regime and in the context\nof estimating the minimum variance portfolio, Goldberg, Papanicolau, and\nShkolnik developed a shrinkage method (the \"GPS estimator\") that improves the\nPCA estimator of beta by shrinking it toward a constant target unit vector.\n  In this paper we continue their work to develop a more general framework of\nshrinkage targets that allows the practitioner to make use of further\ninformation to improve the estimator. Examples include sector separation of\nstock betas, and recent information from prior estimates. We prove some precise\nstatements and illustrate the resulting improvements over the GPS estimator\nwith some numerical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.00148v2"
    },
    {
        "title": "Adjoint Differentiation for generic matrix functions",
        "authors": [
            "Andrei Goloubentsev",
            "Dmitri Goloubentsev",
            "Evgeny Lakshtanov"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We derive a formula for the adjoint $\\overline{A}$ of a square-matrix\noperation of the form $C=f(A)$, where $f$ is holomorphic in the neighborhood of\neach eigenvalue. We then apply the formula to derive closed-form expressions in\nparticular cases of interest such as the case when we have a spectral\ndecomposition $A=UDU^{-1}$, the spectrum cut-off $C=A_+$ and the Nearest\nCorrelation Matrix routine. Finally, we explain how to simplify the computation\nof adjoints for regularized linear regression coefficients.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.04913v1"
    },
    {
        "title": "SINH-acceleration for B-spline projection with Option Pricing\n  Applications",
        "authors": [
            "Svetlana Boyarchenko",
            "Sergei Levendorskiĭ",
            "J. Lars Kirkby",
            "Zhenyu Cui"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We clarify the relations among different Fourier-based approaches to option\npricing, and improve the B-spline probability density projection method using\nthe sinh-acceleration technique. This allows us to efficiently separate the\ncontrol of different sources of errors better than the FFT-based realization\nallows; in many cases, the CPU time decreases as well. We demonstrate the\nimprovement of the B-spline projection method through several numerical\nexperiments in option pricing, including European and barrier options, where\nthe SINH acceleration technique proves to be robust and accurate.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.08738v1"
    },
    {
        "title": "Multi-Transformer: A New Neural Network-Based Architecture for\n  Forecasting S&P Volatility",
        "authors": [
            "Eduardo Ramos-Pérez",
            "Pablo J. Alonso-González",
            "José Javier Núñez-Velázquez"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Events such as the Financial Crisis of 2007-2008 or the COVID-19 pandemic\ncaused significant losses to banks and insurance entities. They also\ndemonstrated the importance of using accurate equity risk models and having a\nrisk management function able to implement effective hedging strategies. Stock\nvolatility forecasts play a key role in the estimation of equity risk and,\nthus, in the management actions carried out by financial institutions.\nTherefore, this paper has the aim of proposing more accurate stock volatility\nmodels based on novel machine and deep learning techniques. This paper\nintroduces a neural network-based architecture, called Multi-Transformer.\nMulti-Transformer is a variant of Transformer models, which have already been\nsuccessfully applied in the field of natural language processing. Indeed, this\npaper also adapts traditional Transformer layers in order to be used in\nvolatility forecasting models. The empirical results obtained in this paper\nsuggest that the hybrid models based on Multi-Transformer and Transformer\nlayers are more accurate and, hence, they lead to more appropriate risk\nmeasures than other autoregressive algorithms or hybrid models based on feed\nforward layers or long short term memory cells.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.12621v1"
    },
    {
        "title": "Forecasting Financial Market Structure from Network Features using\n  Machine Learning",
        "authors": [
            "Douglas Castilho",
            "Tharsis T. P. Souza",
            "Soong Moon Kang",
            "João Gama",
            "André C. P. L. F. de Carvalho"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We propose a model that forecasts market correlation structure from link- and\nnode-based financial network features using machine learning. For such, market\nstructure is modeled as a dynamic asset network by quantifying time-dependent\nco-movement of asset price returns across company constituents of major global\nmarket indices. We provide empirical evidence using three different network\nfiltering methods to estimate market structure, namely Dynamic Asset Graph\n(DAG), Dynamic Minimal Spanning Tree (DMST) and Dynamic Threshold Networks\n(DTN). Experimental results show that the proposed model can forecast market\nstructure with high predictive performance with up to $40\\%$ improvement over a\ntime-invariant correlation-based benchmark. Non-pair-wise correlation features\nshowed to be important compared to traditionally used pair-wise correlation\nmeasures for all markets studied, particularly in the long-term forecasting of\nstock market structure. Evidence is provided for stock constituents of the\nDAX30, EUROSTOXX50, FTSE100, HANGSENG50, NASDAQ100 and NIFTY50 market indices.\nFindings can be useful to improve portfolio selection and risk management\nmethods, which commonly rely on a backward-looking covariance matrix to\nestimate portfolio risk.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.11751v1"
    },
    {
        "title": "Clustering Market Regimes using the Wasserstein Distance",
        "authors": [
            "Blanka Horvath",
            "Zacharia Issa",
            "Aitor Muguruza"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The problem of rapid and automated detection of distinct market regimes is a\ntopic of great interest to financial mathematicians and practitioners alike. In\nthis paper, we outline an unsupervised learning algorithm for clustering\nfinancial time-series into a suitable number of temporal segments (market\nregimes). As a special case of the above, we develop a robust algorithm that\nautomates the process of classifying market regimes. The method is robust in\nthe sense that it does not depend on modelling assumptions of the underlying\ntime series as our experiments with real datasets show. This method -- dubbed\nthe Wasserstein $k$-means algorithm -- frames such a problem as one on the\nspace of probability measures with finite $p^\\text{th}$ moment, in terms of the\n$p$-Wasserstein distance between (empirical) distributions. We compare our\nWK-means approach with a more traditional clustering algorithms by studying the\nso-called maximum mean discrepancy scores between, and within clusters. In both\ncases it is shown that the WK-means algorithm vastly outperforms all considered\ncompetitor approaches. We demonstrate the performance of all approaches both in\na controlled environment on synthetic data, and on real data.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.11848v1"
    },
    {
        "title": "Profit warnings and stock returns: Evidence from moroccan stock exchange",
        "authors": [
            "Ilyas El Ghordaf",
            "Abdelbari El Khamlichi"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  There is an important literature focused on profit warnings and its impact on\nstock returns. We provide evidence from Moroccan stock market which aims to\nbecome an African financial hub. Despite this practical improvement, academic\nresearches that focused on this market are scarce and our study is a first\ninvestigation in this context. Using the event study methodology and a sample\nof companies listed in Casablanca Stock Exchange for the period of 2009 to\n2016, we examined whether the effect of qualitative warning is more negative\ncompared to quantitative warnings in a short event window. Our empirical\nfindings show that the average abnormal return on the date of announcement is\nnegative and statistically significant. The magnitude of this negative abnormal\nreturn is greater for qualitative warnings than quantitative ones.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.06655v1"
    },
    {
        "title": "Posterior Cramer-Rao Lower Bound based Adaptive State Estimation for\n  Option Price Forecasting",
        "authors": [
            "Kumar Yashaswi"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The use of Bayesian filtering has been widely used in mathematical finance,\nprimarily in Stochastic Volatility models. They help in estimating unobserved\nlatent variables from observed market data. This field saw huge developments in\nrecent years, because of the increased computational power and increased\nresearch in the model parameter estimation and implied volatility theory. In\nthis paper, we design a novel method to estimate underlying states (volatility\nand risk) from option prices using Bayesian filtering theory and Posterior\nCramer-Rao Lower Bound (PCRLB), further using it for option price prediction.\nSeveral Bayesian filters like Extended Kalman Filter (EKF), Unscented Kalman\nFilter (UKF), Particle Filter (PF) are used for latent state estimation of\nBlack-Scholes model under a GARCH model dynamics. We employ an Average and Best\ncase switching strategy for adaptive state estimation of a non-linear,\ndiscrete-time state space model (SSM) like Black-Scholes, using PCRLB based\nperformance measure to judge the best filter at each time step [1]. Since\nestimating closed-form solution of PCRLB is non-trivial, we employ a particle\nfilter based approximation of PCRLB based on [2]. We test our proposed\nframework on option data from S$\\&$P 500, estimating the underlying state from\nthe real option price, and using it to estimate theoretical price of the option\nand forecasting future prices. Our proposed method performs much better than\nthe individual applied filter used for estimating the underlying state and\nsubstantially improve forecasting capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.03193v1"
    },
    {
        "title": "Adaptive calibration of Heston Model using PCRLB based switching Filter",
        "authors": [
            "Kumar Yashaswi"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Stochastic volatility models have existed in Option pricing theory ever since\nthe crash of 1987 which violated the Black-Scholes model assumption of constant\nvolatility. Heston model is one such stochastic volatility model that is widely\nused for volatility estimation and option pricing. In this paper, we design a\nnovel method to estimate parameters of Heston model under state-space\nrepresentation using Bayesian filtering theory and Posterior Cramer-Rao Lower\nBound (PCRLB), integrating it with Normal Maximum Likelihood Estimation (NMLE)\nproposed in [1]. Several Bayesian filters like Extended Kalman Filter (EKF),\nUnscented Kalman Filter (UKF), Particle Filter (PF) are used for latent state\nand parameter estimation. We employ a switching strategy proposed in [2] for\nadaptive state estimation of the non-linear, discrete-time state-space model\n(SSM) like Heston model. We use a particle filter approximated PCRLB [3] based\nperformance measure to judge the best filter at each time step. We test our\nproposed framework on pricing data from S&P 500 and NSE Index, estimating the\nunderlying volatility and parameters from the index. Our proposed method is\ncompared with the VIX measure and historical volatility for both the indexes.\nThe results indicate an effective framework for estimating volatility\nadaptively with changing market dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.04576v1"
    },
    {
        "title": "Multivariate Realized Volatility Forecasting with Graph Neural Network",
        "authors": [
            "Qinkai Chen",
            "Christian-Yann Robert"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The existing publications demonstrate that the limit order book data is\nuseful in predicting short-term volatility in stock markets. Since stocks are\nnot independent, changes on one stock can also impact other related stocks. In\nthis paper, we are interested in forecasting short-term realized volatility in\na multivariate approach based on limit order book data and relational data. To\nachieve this goal, we introduce Graph Transformer Network for Volatility\nForecasting. The model allows to combine limit order book features and an\nunlimited number of temporal and cross-sectional relations from different\nsources. Through experiments based on about 500 stocks from S&P 500 index, we\nfind a better performance for our model than for other benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.09015v2"
    },
    {
        "title": "Neural Networks for Delta Hedging",
        "authors": [
            "Guijin Son",
            "Joocheol Kim"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  The Black-Scholes model, defined under the assumption of a perfect financial\nmarket, theoretically creates a flawless hedging strategy allowing the trader\nto evade risks in a portfolio of options. However, the concept of a \"perfect\nfinancial market,\" which requires zero transaction and continuous trading, is\nchallenging to meet in the real world. Despite such widely known limitations,\nacademics have failed to develop alternative models successful enough to be\nlong-established. In this paper, we explore the landscape of Deep Neural\nNetworks(DNN) based hedging systems by testing the hedging capacity of the\nfollowing neural architectures: Recurrent Neural Networks, Temporal\nConvolutional Networks, Attention Networks, and Span Multi-Layer Perceptron\nNetworks. In addition, we attempt to achieve even more promising results by\ncombining traditional derivative hedging models with DNN based approaches.\nLastly, we construct \\textbf{NNHedge}, a deep learning framework that provides\nseamless pipelines for model development and assessment for the experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10084v1"
    },
    {
        "title": "Importance sampling for option pricing with feedforward neural networks",
        "authors": [
            "Aleksandar Arandjelović",
            "Thorsten Rheinländer",
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We study the problem of reducing the variance of Monte Carlo estimators\nthrough performing suitable changes of the sampling measure which are induced\nby feedforward neural networks. To this end, building on the concept of vector\nstochastic integration, we characterize the Cameron-Martin spaces of a large\nclass of Gaussian measures which are induced by vector-valued continuous local\nmartingales with deterministic covariation. We prove that feedforward neural\nnetworks enjoy, up to an isometry, the universal approximation property in\nthese topological spaces. We then prove that sampling measures which are\ngenerated by feedforward neural networks can approximate the optimal sampling\nmeasure arbitrarily well. We conclude with a comprehensive numerical study\npricing path-dependent European options for asset price models that incorporate\nfactors such as changing business activity, knock-out barriers, dynamic\ncorrelations, and high-dimensional baskets.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.14247v2"
    },
    {
        "title": "Applications of Signature Methods to Market Anomaly Detection",
        "authors": [
            "Erdinc Akyildirim",
            "Matteo Gambara",
            "Josef Teichmann",
            "Syang Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Anomaly detection is the process of identifying abnormal instances or events\nin data sets which deviate from the norm significantly. In this study, we\npropose a signatures based machine learning algorithm to detect rare or\nunexpected items in a given data set of time series type. We present\napplications of signature or randomized signature as feature extractors for\nanomaly detection algorithms; additionally we provide an easy, representation\ntheoretic justification for the construction of randomized signatures. Our\nfirst application is based on synthetic data and aims at distinguishing between\nreal and fake trajectories of stock prices, which are indistinguishable by\nvisual inspection. We also show a real life application by using transaction\ndata from the cryptocurrency market. In this case, we are able to identify pump\nand dump attempts organized on social networks with F1 scores up to 88% by\nmeans of our unsupervised learning algorithm, thus achieving results that are\nclose to the state-of-the-art in the field based on supervised learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02441v2"
    },
    {
        "title": "Instability of financial markets by optimizing investment strategies\n  investigated by an agent-based model",
        "authors": [
            "Takanobu Mizuta",
            "Isao Yagi",
            "Kosei Takashima"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Most finance studies are discussed on the basis of several hypotheses, for\nexample, investors rationally optimize their investment strategies. However,\nthe hypotheses themselves are sometimes criticized. Market impacts, where\ntrades of investors can impact and change market prices, making optimization\nimpossible. In this study, we built an artificial market model by adding\ntechnical analysis strategy agents searching one optimized parameter to a whole\nsimulation run to the prior model and investigated whether investors' inability\nto accurately estimate market impacts in their optimizations leads to\noptimization instability. In our results, the parameter of investment strategy\nnever converged to a specific value but continued to change. This means that\neven if all other traders are fixed, only one investor will use backtesting to\noptimize his/her strategy, which leads to the time evolution of market prices\nbecoming unstable. Optimization instability is one level higher than\n\"non-equilibrium of market prices.\" Therefore, the time evolution of market\nprices produced by investment strategies having such unstable parameters is\nhighly unlikely to be predicted and have stable laws written by equations. This\nnature makes us suspect that financial markets include the principle of natural\nuniformity and indicates the difficulty of building an equation model\nexplaining the time evolution of prices.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.00831v1"
    },
    {
        "title": "Do new investment strategies take existing strategies' returns -- An\n  investigation into agent-based models",
        "authors": [
            "Takanobu Mizuta"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Commodity trading advisors (CTAs), who mainly trade commodity futures, showed\ngood returns in the 2000s. However, since the 2010's, they have not performed\nvery well. One possible reason of this phenomenon is the emergence of\nshort-term reversal traders (STRTs) who prey on CTAs for profit. In this study,\nI built an artificial market model by adding a CTA agent (CTAA) and STRT agent\n(STRTA) to a prior model and investigated whether emerging STRTAs led to a\ndecrease in CTAA revenue to determine whether STRTs prey on CTAs for profit. To\nthe contrary, my results showed that a CTAA and STRTA are more likely to trade\nand earn more when both exist. Therefore, it is possible that they have a\nmutually beneficial relationship.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.01423v1"
    },
    {
        "title": "An SMP-Based Algorithm for Solving the Constrained Utility Maximization\n  Problem via Deep Learning",
        "authors": [
            "Kristof Wiedermann"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We consider the utility maximization problem under convex constraints with\nregard to theoretical results which allow the formulation of algorithmic\nsolvers which make use of deep learning techniques. In particular for the case\nof random coefficients, we prove a stochastic maximum principle (SMP), which\nalso holds for utility functions $U$ with $\\mathrm{id}_{\\mathbb{R}^{+}} \\cdot\nU'$ being not necessarily nonincreasing, like the power utility functions,\nthereby generalizing the SMP proved by Li and Zheng (2018). We use this SMP\ntogether with the strong duality property for defining a new algorithm, which\nwe call deep primal SMP algorithm. Numerical examples illustrate the\neffectiveness of the proposed algorithm - in particular for higher-dimensional\nproblems and problems with random coefficients, which are either path dependent\nor satisfy their own SDEs. Moreover, our numerical experiments for constrained\nproblems show that the novel deep primal SMP algorithm overcomes the deep SMP\nalgorithm's (see Davey and Zheng (2021)) weakness of erroneously producing the\nvalue of the corresponding unconstrained problem. Furthermore, in contrast to\nthe deep controlled 2BSDE algorithm from Davey and Zheng (2021), this algorithm\nis also applicable to problems with path dependent coefficients. As the deep\nprimal SMP algorithm even yields the most accurate results in many of our\nstudied problems, we can highly recommend its usage. Moreover, we propose a\nlearning procedure based on epochs which improved the results of our algorithm\neven further. Implementing a semi-recurrent network architecture for the\ncontrol process turned out to be also a valuable advancement.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07771v1"
    },
    {
        "title": "Solution of integrals with fractional Brownian motion for different\n  Hurst indices",
        "authors": [
            "Fei Gao",
            "Shuaiqiang Liu",
            "Cornelis W. Oosterlee",
            "Nico M. Temme"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this paper, we will evaluate integrals that define the conditional\nexpectation, variance and characteristic function of stochastic processes with\nrespect to fractional Brownian motion (fBm) for all relevant Hurst indices,\ni.e. $H \\in (0,1)$. The fractional Ornstein-Uhlenbeck (fOU) process, for\nexample, gives rise to highly nontrivial integration formulas that need careful\nanalysis when considering the whole range of Hurst indices. We will show that\nthe classical technique of analytic continuation, from complex analysis,\nprovides a way of extending the domain of validity of an integral, from\n$H\\in(1/2,1)$, to the larger domain, $H\\in(0,1)$. Numerical experiments for\ndifferent Hurst indices confirm the robustness and efficiency of the integral\nformulations presented here. Moreover, we provide accurate and highly efficient\nfinancial option pricing results for processes that are related to the fOU\nprocess, with the help of Fourier cosine expansions.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.02323v2"
    },
    {
        "title": "Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement\n  Learning Perspective",
        "authors": [
            "Nelson Vadori"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  One of the most fundamental questions in quantitative finance is the\nexistence of continuous-time diffusion models that fit market prices of a given\nset of options. Traditionally, one employs a mix of intuition, theoretical and\nempirical analysis to find models that achieve exact or approximate fits. Our\ncontribution is to show how a suitable game theoretical formulation of this\nproblem can help solve this question by leveraging existing developments in\nmodern deep multi-agent reinforcement learning to search in the space of\nstochastic processes. Our experiments show that we are able to learn local\nvolatility, as well as path-dependence required in the volatility process to\nminimize the price of a Bermudan option. Our algorithm can be seen as a\nparticle method \\textit{\\`{a} la} Guyon \\textit{et} Henry-Labordere where\nparticles, instead of being designed to ensure $\\sigma_{loc}(t,S_t)^2 =\n\\mathbb{E}[\\sigma_t^2|S_t]$, are learning RL-driven agents cooperating towards\nmore general calibration targets.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06865v4"
    },
    {
        "title": "Optimal Damping with Hierarchical Adaptive Quadrature for Efficient\n  Fourier Pricing of Multi-Asset Options in Lévy Models",
        "authors": [
            "Michael Samet",
            "Christian Bayer",
            "Chiheb Ben Hammouda",
            "Antonis Papapantoleon",
            "Raúl Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Efficiently pricing multi-asset options is a challenging problem in\nquantitative finance. When the characteristic function is available,\nFourier-based methods are competitive compared to alternative techniques\nbecause the integrand in the frequency space often has a higher regularity than\nthat in the physical space. However, when designing a numerical quadrature\nmethod for most Fourier pricing approaches, two key aspects affecting the\nnumerical complexity should be carefully considered: (i) the choice of damping\nparameters that ensure integrability and control the regularity class of the\nintegrand and (ii) the effective treatment of high dimensionality. We propose\nan efficient numerical method for pricing European multi-asset options based on\ntwo complementary ideas to address these challenges. First, we smooth the\nFourier integrand via an optimized choice of the damping parameters based on a\nproposed optimization rule. Second, we employ sparsification and\ndimension-adaptivity techniques to accelerate the convergence of the quadrature\nin high dimensions. The extensive numerical study on basket and rainbow options\nunder the multivariate geometric Brownian motion and some L\\'evy models\ndemonstrates the advantages of adaptivity and the damping rule on the numerical\ncomplexity of quadrature methods. Moreover, for the tested two-asset examples,\nthe proposed approach outperforms the COS method in terms of computational\ntime. Finally, we show significant speed-up compared to the Monte Carlo method\nfor up to six dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.08196v4"
    },
    {
        "title": "Modeling Randomly Walking Volatility with Chained Gamma Distributions",
        "authors": [
            "Di Zhang",
            "Qiang Niu",
            "Youzhou Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Volatility clustering is a common phenomenon in financial time series.\nTypically, linear models can be used to describe the temporal autocorrelation\nof the (logarithmic) variance of returns. Considering the difficulty in\nestimating this model, we construct a Dynamic Bayesian Network, which utilizes\nthe conjugate prior relation of normal-gamma and gamma-gamma, so that its\nposterior form locally remains unchanged at each node. This makes it possible\nto find approximate solutions using variational methods quickly. Furthermore,\nwe ensure that the volatility expressed by the model is an independent\nincremental process after inserting dummy gamma nodes between adjacent time\nsteps. We have found that this model has two advantages: 1) It can be proved\nthat it can express heavier tails than Gaussians, i.e., have positive excess\nkurtosis, compared to popular linear models. 2) If the variational\ninference(VI) is used for state estimation, it runs much faster than Monte\nCarlo(MC) methods since the calculation of the posterior uses only basic\narithmetic operations. And its convergence process is deterministic.\n  We tested the model, named Gam-Chain, using recent Crypto, Nasdaq, and Forex\nrecords of varying resolutions. The results show that: 1) In the same case of\nusing MC, this model can achieve comparable state estimation results with the\nregular lognormal chain. 2) In the case of only using VI, this model can obtain\naccuracy that are slightly worse than MC, but still acceptable in practice; 3)\nOnly using VI, the running time of Gam-Chain, in general case, can be reduced\nto below 5% of that based on the lognormal chain via MC.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01151v3"
    },
    {
        "title": "Supervised similarity learning for corporate bonds using Random Forest\n  proximities",
        "authors": [
            "Jerinsh Jeyapaulraj",
            "Dhruv Desai",
            "Peter Chu",
            "Dhagash Mehta",
            "Stefano Pasquali",
            "Philip Sommer"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Financial literature consists of ample research on similarity and comparison\nof financial assets and securities such as stocks, bonds, mutual funds, etc.\nHowever, going beyond correlations or aggregate statistics has been arduous\nsince financial datasets are noisy, lack useful features, have missing data and\noften lack ground truth or annotated labels. However, though similarity\nextrapolated from these traditional models heuristically may work well on an\naggregate level, such as risk management when looking at large portfolios, they\noften fail when used for portfolio construction and trading which require a\nlocal and dynamic measure of similarity on top of global measure. In this paper\nwe propose a supervised similarity framework for corporate bonds which allows\nfor inference based on both local and global measures. From a machine learning\nperspective, this paper emphasis that random forest (RF), which is usually\nviewed as a supervised learning algorithm, can also be used as a similarity\nlearning (more specifically, a distance metric learning) algorithm. In\naddition, this framework proposes a novel metric to evaluate similarities, and\nanalyses other metrics which further demonstrate that RF outperforms all other\nmethods experimented with, in this work.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.04368v2"
    },
    {
        "title": "Learning Mutual Fund Categorization using Natural Language Processing",
        "authors": [
            "Dimitrios Vamvourellis",
            "Mate Attila Toth",
            "Dhruv Desai",
            "Dhagash Mehta",
            "Stefano Pasquali"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Categorization of mutual funds or Exchange-Traded-funds (ETFs) have long\nserved the financial analysts to perform peer analysis for various purposes\nstarting from competitor analysis, to quantifying portfolio diversification.\nThe categorization methodology usually relies on fund composition data in the\nstructured format extracted from the Form N-1A. Here, we initiate a study to\nlearn the categorization system directly from the unstructured data as depicted\nin the forms using natural language processing (NLP). Positing as a multi-class\nclassification problem with the input data being only the investment strategy\ndescription as reported in the form and the target variable being the Lipper\nGlobal categories, and using various NLP models, we show that the\ncategorization system can indeed be learned with high accuracy. We discuss\nimplications and applications of our findings as well as limitations of\nexisting pre-trained architectures in applying them to learn fund\ncategorization.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.04959v1"
    },
    {
        "title": "Learning Embedded Representation of the Stock Correlation Matrix using\n  Graph Machine Learning",
        "authors": [
            "Bhaskarjit Sarmah",
            "Nayana Nair",
            "Dhagash Mehta",
            "Stefano Pasquali"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Understanding non-linear relationships among financial instruments has\nvarious applications in investment processes ranging from risk management,\nportfolio construction and trading strategies. Here, we focus on\ninterconnectedness among stocks based on their correlation matrix which we\nrepresent as a network with the nodes representing individual stocks and the\nweighted links between pairs of nodes representing the corresponding pair-wise\ncorrelation coefficients. The traditional network science techniques, which are\nextensively utilized in financial literature, require handcrafted features such\nas centrality measures to understand such correlation networks. However,\nmanually enlisting all such handcrafted features may quickly turn out to be a\ndaunting task. Instead, we propose a new approach for studying nuances and\nrelationships within the correlation network in an algorithmic way using a\ngraph machine learning algorithm called Node2Vec. In particular, the algorithm\ncompresses the network into a lower dimensional continuous space, called an\nembedding, where pairs of nodes that are identified as similar by the algorithm\nare placed closer to each other. By using log returns of S&P 500 stock data, we\nshow that our proposed algorithm can learn such an embedding from its\ncorrelation network. We define various domain specific quantitative (and\nobjective) and qualitative metrics that are inspired by metrics used in the\nfield of Natural Language Processing (NLP) to evaluate the embeddings in order\nto identify the optimal one. Further, we discuss various applications of the\nembeddings in investment management.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07183v1"
    },
    {
        "title": "Deep Hedging: Continuous Reinforcement Learning for Hedging of General\n  Portfolios across Multiple Risk Aversions",
        "authors": [
            "Phillip Murray",
            "Ben Wood",
            "Hans Buehler",
            "Magnus Wiese",
            "Mikko S. Pakkanen"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We present a method for finding optimal hedging policies for arbitrary\ninitial portfolios and market states. We develop a novel actor-critic algorithm\nfor solving general risk-averse stochastic control problems and use it to learn\nhedging strategies across multiple risk aversion levels simultaneously. We\ndemonstrate the effectiveness of the approach with a numerical example in a\nstochastic volatility environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07467v1"
    },
    {
        "title": "On Randomization of Affine Diffusion Processes with Application to\n  Pricing of Options on VIX and S&P 500",
        "authors": [
            "Lech A. Grzelak"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The class of Affine (Jump) Diffusion (AD) has, due to its closed form\ncharacteristic function (ChF), gained tremendous popularity among practitioners\nand researchers. However, there is clear evidence that a linearity constraint\nis insufficient for precise and consistent option pricing. Any non-affine model\nmust pass the strict requirement of quick calibration -- which is often\nchallenging. We focus here on Randomized AD (RAnD) models, i.e., we allow for\nexogenous stochasticity of the model parameters. Randomization of a pricing\nmodel occurs outside the affine model and, therefore, forms a generalization\nthat relaxes the affinity constraints. The method is generic and can apply to\nany model parameter. It relies on the existence of moments of the so-called\nrandomizer- a random variable for the stochastic parameter. The RAnD model\nallows flexibility while benefiting from fast calibration and well-established,\nlarge-step Monte Carlo simulation, often available for AD processes. The\narticle will discuss theoretical and practical aspects of the RAnD method, like\nderivations of the corresponding ChF, simulation, and computations of\nsensitivities. We will also illustrate the advantages of the randomized\nstochastic volatility models in the consistent pricing of options on the S&P\n500 and VIX.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12518v1"
    },
    {
        "title": "Two-stage Modeling for Prediction with Confidence",
        "authors": [
            "Dangxing Chen"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The use of neural networks has been very successful in a wide variety of\napplications. However, it has recently been observed that it is difficult to\ngeneralize the performance of neural networks under the condition of\ndistributional shift. Several efforts have been made to identify potential\nout-of-distribution inputs. Although existing literature has made significant\nprogress with regard to images and textual data, finance has been overlooked.\nThe aim of this paper is to investigate the distribution shift in the credit\nscoring problem, one of the most important applications of finance. For the\npotential distribution shift problem, we propose a novel two-stage model. Using\nthe out-of-distribution detection method, data is first separated into\nconfident and unconfident sets. As a second step, we utilize the domain\nknowledge with a mean-variance optimization in order to provide reliable bounds\nfor unconfident samples. Using empirical results, we demonstrate that our model\noffers reliable predictions for the vast majority of datasets. It is only a\nsmall portion of the dataset that is inherently difficult to judge, and we\nleave them to the judgment of human beings. Based on the two-stage model,\nhighly confident predictions have been made and potential risks associated with\nthe model have been significantly reduced.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.08848v1"
    },
    {
        "title": "Efficient Wrong-Way Risk Modelling for Funding Valuation Adjustments",
        "authors": [
            "T. van der Zwaard",
            "L. A. Grzelak",
            "C. W. Oosterlee"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Wrong-Way Risk (WWR) is an important component in Funding Valuation\nAdjustment (FVA) modelling. Yet, the standard assumption is independence\nbetween market risks and the counterparty defaults and funding costs. This\ntypical industrial setting is our point of departure, where we aim to assess\nthe impact of WWR without running a full Monte Carlo simulation with all credit\nand funding processes. We propose to split the exposure profile into two parts:\nan independent and a WWR-driven part. For the former, exposures can be re-used\nfrom the standard xVA calculation. We express the second part of the exposure\nprofile in terms of the stochastic drivers and approximate these by a common\nGaussian stochastic factor. Within the affine setting, the proposed\napproximation is generic, is an add-on to the existing xVA calculations and\nprovides an efficient and robust way to include WWR in FVA modelling. Case\nstudies for an interest rate swap and a representative multi-currency portfolio\nof swaps illustrate that the approximation method is applicable in a practical\nsetting. We analyze the approximation error and use the approximation to\ncompute WWR sensitivities, which are needed for risk management. The approach\nis equally applicable to other metrics such as Credit Valuation Adjustment.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12222v4"
    },
    {
        "title": "Automatic Identification and Classification of Share Buybacks and their\n  Effect on Short-, Mid- and Long-Term Returns",
        "authors": [
            "Thilo Reintjes"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This thesis investigates share buybacks, specifically share buyback\nannouncements. It addresses how to recognize such announcements, the excess\nreturn of share buybacks, and the prediction of returns after a share buyback\nannouncement. We illustrate two NLP approaches for the automated detection of\nshare buyback announcements. Even with very small amounts of training data, we\ncan achieve an accuracy of up to 90%. This thesis utilizes these NLP methods to\ngenerate a large dataset consisting of 57,155 share buyback announcements. By\nanalyzing this dataset, this thesis aims to show that most companies, which\nhave a share buyback announced are underperforming the MSCI World. A minority\nof companies, however, significantly outperform the MSCI World. This\nsignificant overperformance leads to a net gain when looking at the averages of\nall companies. If the benchmark index is adjusted for the respective size of\nthe companies, the average overperformance disappears, and the majority\nunderperforms even greater. However, it was found that companies that announce\na share buyback with a volume of at least 1% of their market cap, deliver, on\naverage, a significant overperformance, even when using an adjusted benchmark.\nIt was also found that companies that announce share buybacks in times of\ncrisis emerge better than the overall market. Additionally, the generated\ndataset was used to train 72 machine learning models. Through this, it was able\nto find many strategies that could achieve an accuracy of up to 77% and\ngenerate great excess returns. A variety of performance indicators could be\nimproved across six different time frames and a significant overperformance was\nidentified. This was achieved by training several models for different tasks\nand time frames as well as combining these different models, generating\nsignificant improvement by fusing weak learners, in order to create one strong\nlearner.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12863v1"
    },
    {
        "title": "Boundary-safe PINNs extension: Application to non-linear parabolic PDEs\n  in counterparty credit risk",
        "authors": [
            "Joel P. Villarino",
            "Álvaro Leitao",
            "José A. García-Rodríguez"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  The goal of this work is to develop deep learning numerical methods for\nsolving option XVA pricing problems given by non-linear PDE models. A novel\nstrategy for the treatment of the boundary conditions is proposed, which allows\nto get rid of the heuristic choice of the weights for the different addends\nthat appear in the loss function related to the training process. It is based\non defining the losses associated to the boundaries by means of the PDEs that\narise from substituting the related conditions into the model equation itself.\nFurther, automatic differentiation is employed to obtain accurate approximation\nof the partial derivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.02175v1"
    },
    {
        "title": "Market Directional Information Derived From (Time, Execution Price,\n  Shares Traded) Sequence of Transactions. On The Impact From The Future",
        "authors": [
            "Vladislav Gennadievich Malyshkin",
            "Mikhail Gennadievich Belov"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  An attempt to obtain market directional information from non-stationary\nsolution of the dynamic equation: \"future price tends to the value maximizing\nthe number of shares traded per unit time\" is presented. A remarkable feature\nof the approach is an automatic time scale selection. It is determined from the\nstate of maximal execution flow calculated on past transactions. Both lagging\nand advancing prices are calculated.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.04223v1"
    },
    {
        "title": "Multiresolution Signal Processing of Financial Market Objects",
        "authors": [
            "Ioana Boier"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Multiresolution analysis has applications across many disciplines in the\nstudy of complex systems and their dynamics. Financial markets are among the\nmost complex entities in our environment, yet mainstream quantitative models\noperate at predetermined scale, rely on linear correlation measures, and\nstruggle to recognize non-linear or causal structures. In this paper, we\ncombine neural networks known to capture non-linear associations with a\nmultiscale decomposition to facilitate a better understanding of financial\nmarket data substructures. Quantization keeps our decompositions calibrated to\nmarket at every scale. We illustrate our approach in the context of seven use\ncases.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.15934v2"
    },
    {
        "title": "Mod-Poisson approximation schemes: Applications to credit risk",
        "authors": [
            "Pierre-Loïc Méliot",
            "Ashkan Nikeghbali",
            "Gabriele Visentin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We introduce a new numerical approximation method for functionals of factor\ncredit portfolio models based on the theory of mod-$\\phi$ convergence and\nmod-$\\phi$ approximation schemes. The method can be understood as providing\ncorrection terms to the classic Poisson approximation, where higher order\ncorrections lead to asymptotically better approximations as the number of\nobligors increases. We test the model empirically on two tasks: the estimation\nof risk measures ($\\mathrm{VaR}$ and $\\mathrm{ES}$) and the computation of CDO\ntranche prices. We compare it to other commonly used methods -- such as the\nrecursive method, the large deviations approximation, the Chen--Stein method\nand the Monte Carlo simulation technique (with and without importance sampling)\n-- and we show that it leads to more accurate estimates while requiring less\ncomputational time.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.04436v1"
    },
    {
        "title": "Efficient evaluation of double-barrier options and joint cpdf of a\n  Lévy process and its two extrema",
        "authors": [
            "Svetlana Boyarchenko",
            "Sergei Levendorskiĭ"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In the paper, we develop a very fast and accurate method for pricing double\nbarrier options with continuous monitoring in wide classes of L\\'evy models;\nthe calculations are in the dual space, and the Wiener-Hopf factorization is\nused. For wide regions in the parameter space, the precision of the order of\n$10^{-15}$ is achievable in seconds, and of the order of $10^{-9}-10^{-8}$ - in\nfractions of a second. The Wiener-Hopf factors and repeated integrals in the\npricing formulas are calculated using sinh-deformations of the lines of\nintegration, the corresponding changes of variables and the simplified\ntrapezoid rule. If the Bromwich integral is calculated using the Gaver-Wynn Rho\nacceleration instead of the sinh-acceleration, the CPU time is typically\nsmaller but the precision is of the order of $10^{-9}-10^{-6}$, at best.\nExplicit pricing algorithms and numerical examples are for no-touch options,\ndigitals (equivalently, for the joint distribution function of a L\\'evy process\nand its supremum and infimum processes), and call options. Several graphs are\nproduced to explain fundamental difficulties for accurate pricing of barrier\noptions using time discretization and interpolation-based calculations in the\nstate space.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.07765v1"
    },
    {
        "title": "Deep Signature Algorithm for Multi-dimensional Path-Dependent Options",
        "authors": [
            "Erhan Bayraktar",
            "Qi Feng",
            "Zhaoyu Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this work, we study the deep signature algorithms for path-dependent\noptions. We extend the backward scheme in [Hur\\'e-Pham-Warin. Mathematics of\nComputation 89, no. 324 (2020)] for state-dependent FBSDEs with reflections to\npath-dependent FBSDEs with reflections, by adding the signature layer to the\nbackward scheme. Our algorithm applies to both European and American type\noption pricing problems while the payoff function depends on the whole paths of\nthe underlying forward stock process. We prove the convergence analysis of our\nnumerical algorithm with explicit dependence on the truncation order of the\nsignature and the neural network approximation errors. Numerical examples for\nthe algorithm are provided including: Amerasian option under the Black-Scholes\nmodel, American option with a path-dependent geometric mean payoff function,\nand the Shiryaev's optimal stopping problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.11691v3"
    },
    {
        "title": "On a Moving Average with Internal Degrees of Freedom",
        "authors": [
            "Linda Boudjemila",
            "Alexander Bobyl",
            "Vadim Davydov",
            "Vladislav Malyshkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  A new type of moving average is developed. Whereas a regular moving average\n(e.g. of price) has a built-in internal time scale (time-window, exponential\nweight, etc.), the moving average developed in this paper has the weight as the\nproduct of a polynomial by window factor. The polynomial is the square of a\nwavefunction obtained from an eigenproblem corresponding to other observable\n(e.g. execution flow I=dV/dt , the number of shares traded per unit time). This\nallows to obtain an immediate \"switch\" without lagging typical for regular\nmoving average.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.14075v1"
    },
    {
        "title": "A Novel Deep Reinforcement Learning Based Automated Stock Trading System\n  Using Cascaded LSTM Networks",
        "authors": [
            "Jie Zou",
            "Jiashu Lou",
            "Baohua Wang",
            "Sixue Liu"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  More and more stock trading strategies are constructed using deep\nreinforcement learning (DRL) algorithms, but DRL methods originally widely used\nin the gaming community are not directly adaptable to financial data with low\nsignal-to-noise ratios and unevenness, and thus suffer from performance\nshortcomings. In this paper, to capture the hidden information, we propose a\nDRL based stock trading system using cascaded LSTM, which first uses LSTM to\nextract the time-series features from stock daily data, and then the features\nextracted are fed to the agent for training, while the strategy functions in\nreinforcement learning also use another LSTM for training. Experiments in DJI\nin the US market and SSE50 in the Chinese stock market show that our model\noutperforms previous baseline models in terms of cumulative returns and Sharp\nratio, and this advantage is more significant in the Chinese stock market, a\nmerging market. It indicates that our proposed method is a promising way to\nbuild a automated stock trading system.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.02721v2"
    },
    {
        "title": "Bi-LSTM Price Prediction based on Attention Mechanism",
        "authors": [
            "Jiashu Lou",
            "Leyi Cui",
            "Ye Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  With the increasing enrichment and development of the financial derivatives\nmarket, the frequency of transactions is also faster and faster. Due to human\nlimitations, algorithms and automatic trading have recently become the focus of\ndiscussion. In this paper, we propose a bidirectional LSTM neural network based\non an attention mechanism, which is based on two popular assets, gold and\nbitcoin. In terms of Feature Engineering, on the one hand, we add traditional\ntechnical factors, and at the same time, we combine time series models to\ndevelop factors. In the selection of model parameters, we finally chose a\ntwo-layer deep learning network. According to AUC measurement, the accuracy of\nbitcoin and gold is 71.94% and 73.03% respectively. Using the forecast results,\nwe achieved a return of 1089.34% in two years. At the same time, we also\ncompare the attention Bi-LSTM model proposed in this paper with the traditional\nmodel, and the results show that our model has the best performance in this\ndata set. Finally, we discuss the significance of the model and the\nexperimental results, as well as the possible improvement direction in the\nfuture.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.03443v2"
    },
    {
        "title": "Moate Simulation of Stochastic Processes",
        "authors": [
            "Michael E. Mura"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  A novel approach called Moate Simulation is presented to provide an accurate\nnumerical evolution of probability distribution functions represented on grids\narising from stochastic differential processes where initial conditions are\nspecified. Where the variables of stochastic differential equations may be\ntransformed via It\\^o-Doeblin calculus into stochastic differentials with a\nconstant diffusion term, the probability distribution function for these\nvariables can be simulated in discrete time steps. The drift is applied\ndirectly to a volume element of the distribution while the stochastic diffusion\nterm is applied through the use of convolution techniques such as Fast or\nDiscrete Fourier Transforms. This allows for highly accurate distributions to\nbe efficiently simulated to a given time horizon and may be employed in one,\ntwo or higher dimensional expectation integrals, e.g. for pricing of financial\nderivatives. The Moate Simulation approach forms a more accurate and\nconsiderably faster alternative to Monte Carlo Simulation for many applications\nwhile retaining the opportunity to alter the distribution in mid-simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.08509v1"
    },
    {
        "title": "Langevin algorithms for Markovian Neural Networks and Deep Stochastic\n  control",
        "authors": [
            "Pierre Bras",
            "Gilles Pagès"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Stochastic Gradient Descent Langevin Dynamics (SGLD) algorithms, which add\nnoise to the classic gradient descent, are known to improve the training of\nneural networks in some cases where the neural network is very deep. In this\npaper we study the possibilities of training acceleration for the numerical\nresolution of stochastic control problems through gradient descent, where the\ncontrol is parametrized by a neural network. If the control is applied at many\ndiscretization times then solving the stochastic control problem reduces to\nminimizing the loss of a very deep neural network. We numerically show that\nLangevin algorithms improve the training on various stochastic control problems\nlike hedging and resource management, and for different choices of gradient\ndescent methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.12018v2"
    },
    {
        "title": "A Novel Experts Advice Aggregation Framework Using Deep Reinforcement\n  Learning for Portfolio Management",
        "authors": [
            "MohammadAmin Fazli",
            "Mahdi Lashkari",
            "Hamed Taherkhani",
            "Jafar Habibi"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  Solving portfolio management problems using deep reinforcement learning has\nbeen getting much attention in finance for a few years. We have proposed a new\nmethod using experts signals and historical price data to feed into our\nreinforcement learning framework. Although experts signals have been used in\nprevious works in the field of finance, as far as we know, it is the first time\nthis method, in tandem with deep RL, is used to solve the financial portfolio\nmanagement problem. Our proposed framework consists of a convolutional network\nfor aggregating signals, another convolutional network for historical price\ndata, and a vanilla network. We used the Proximal Policy Optimization algorithm\nas the agent to process the reward and take action in the environment. The\nresults suggested that, on average, our framework could gain 90 percent of the\nprofit earned by the best expert.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.14477v1"
    },
    {
        "title": "A time-dependent Markovian model of a limit order book",
        "authors": [
            "Jonathan A. Chávez-Casillas"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper considers a Markovian model of a limit order book where\ntime-dependent rates are allowed. With the objective of understanding the\nmechanisms through which a microscopic model of an orderbook can converge to\nmore general diffusion than a Brownian motion with constant coefficient, a\nsimple time-dependent model is proposed. The model considered here starts by\ndescribing the processes that govern the arrival of the different orders such\nas limit orders, market orders and cancellations. In this sense, this is a\nmicroscopic model rather than a ``mesoscopic'' model where the starting point\nis usually the point processes describing the times at which the price changes\noccur and aggregate in these all the information pertaining to the arrival of\nindividual orders. Furthermore, several empirical studies are performed to shed\nsome light into the validity of the modeling assumptions and to verify whether\ncertain stocks satisfy the conditions for their price process to converge to a\nmore complex diffusion.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00846v1"
    },
    {
        "title": "Parametric Differential Machine Learning for Pricing and Calibration",
        "authors": [
            "Arun Kumar Polala",
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Differential machine learning (DML) is a recently proposed technique that\nuses samplewise state derivatives to regularize least square fits to learn\nconditional expectations of functionals of stochastic processes as functions of\nstate variables. Exploiting the derivative information leads to fewer samples\nthan a vanilla ML approach for the same level of precision. This paper extends\nthe methodology to parametric problems where the processes and functionals also\ndepend on model and contract parameters, respectively. In addition, we propose\nadaptive parameter sampling to improve relative accuracy when the functionals\nhave different magnitudes for different parameter sets. For calibration, we\nconstruct pricing surrogates for calibration instruments and optimize over them\nglobally. We discuss strategies for robust calibration. We demonstrate the\nusefulness of our methodology on one-factor Cheyette models with benchmark rate\nvolatility specification with an extra stochastic volatility factor on\n(two-curve) caplet prices at different strikes and maturities, first for\nparametric pricing, and then by calibrating to a given caplet volatility\nsurface. To allow convenient and efficient simulation of processes and\nfunctionals and in particular the corresponding computation of samplewise\nderivatives, we propose to specify the processes and functionals in a low-code\nway close to mathematical notation which is then used to generate efficient\ncomputation of the functionals and derivatives in TensorFlow.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06682v2"
    },
    {
        "title": "Generative Ornstein-Uhlenbeck Markets via Geometric Deep Learning",
        "authors": [
            "Anastasis Kratsios",
            "Cody Hyndman"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We consider the problem of simultaneously approximating the conditional\ndistribution of market prices and their log returns with a single machine\nlearning model. We show that an instance of the GDN model of Kratsios and Papon\n(2022) solves this problem without having prior assumptions on the market's\n\"clipped\" log returns, other than that they follow a generalized\nOrnstein-Uhlenbeck process with a priori unknown dynamics. We provide universal\napproximation guarantees for these conditional distributions and contingent\nclaims with a Lipschitz payoff function.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09176v1"
    },
    {
        "title": "Simultaneous upper and lower bounds of American-style option prices with\n  hedging via neural networks",
        "authors": [
            "Ivan Guo",
            "Nicolas Langrené",
            "Jiahao Wu"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper, we introduce two novel methods to solve the American-style\noption pricing problem and its dual form at the same time using neural\nnetworks. Without applying nested Monte Carlo, the first method uses a series\nof neural networks to simultaneously compute both the lower and upper bounds of\nthe option price, and the second one accomplishes the same goal with one global\nnetwork. The avoidance of extra simulations and the use of neural networks\nsignificantly reduce the computational complexity and allow us to price\nBermudan options with frequent exercise opportunities in high dimensions, as\nillustrated by the provided numerical experiments. As a by-product, these\nmethods also derive a hedging strategy for the option, which can also be used\nas a control variate for variance reduction.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12439v3"
    },
    {
        "title": "FuNVol: A Multi-Asset Implied Volatility Market Simulator using\n  Functional Principal Components and Neural SDEs",
        "authors": [
            "Vedant Choudhary",
            "Sebastian Jaimungal",
            "Maxime Bergeron"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We introduce a new approach for generating sequences of implied volatility\n(IV) surfaces across multiple assets that is faithful to historical prices. We\ndo so using a combination of functional data analysis and neural stochastic\ndifferential equations (SDEs) combined with a probability integral transform\npenalty to reduce model misspecification. We demonstrate that learning the\njoint dynamics of IV surfaces and prices produces market scenarios that are\nconsistent with historical features and lie within the sub-manifold of surfaces\nthat are essentially free of static arbitrage. Finally, we demonstrate that\ndelta hedging using the simulated surfaces generates profit and loss (P&L)\ndistributions that are consistent with realised P&Ls.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00859v4"
    },
    {
        "title": "Robust Risk-Aware Option Hedging",
        "authors": [
            "David Wu",
            "Sebastian Jaimungal"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The objectives of option hedging/trading extend beyond mere protection\nagainst downside risks, with a desire to seek gains also driving agent's\nstrategies. In this study, we showcase the potential of robust risk-aware\nreinforcement learning (RL) in mitigating the risks associated with\npath-dependent financial derivatives. We accomplish this by leveraging a policy\ngradient approach that optimises robust risk-aware performance criteria. We\nspecifically apply this methodology to the hedging of barrier options, and\nhighlight how the optimal hedging strategy undergoes distortions as the agent\nmoves from being risk-averse to risk-seeking. As well as how the agent\nrobustifies their strategy. We further investigate the performance of the hedge\nwhen the data generating process (DGP) varies from the training DGP, and\ndemonstrate that the robust strategies outperform the non-robust ones.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.15216v3"
    },
    {
        "title": "A Multilevel Stochastic Approximation Algorithm for Value-at-Risk and\n  Expected Shortfall Estimation",
        "authors": [
            "Stéphane Crépey",
            "Noufel Frikha",
            "Azar Louzi"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We propose a multilevel stochastic approximation (MLSA) scheme for the\ncomputation of the value-at-risk (VaR) and expected shortfall (ES) of a\nfinancial loss, which can only be computed via simulations conditional on the\nrealization of future risk factors. Thus, the problem of estimating its VaR and\nES is nested in nature and can be viewed as an instance of stochastic\napproximation problems with biased innovations. In this framework, for a\nprescribed accuracy $\\epsilon$, the optimal complexity of a nested stochastic\napproximation algorithm is shown to be of order $\\epsilon$--3. To estimate the\nVaR, our MLSA algorithm attains an optimal complexity of order\n$\\epsilon$--2--$\\delta$ , where $\\delta$ \\< 1 is some parameter depending on\nthe integrability degree of the loss, while to estimate the ES, it achieves an\noptimal complexity of order $\\epsilon$--2 |ln $\\epsilon$|2. Numerical studies\nof the joint evolution of the error rate and the execution time demonstrate how\nour MLSA algorithm regains a significant amount of the performance lost due to\nthe nested nature of the problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01207v3"
    },
    {
        "title": "Application of Tensor Neural Networks to Pricing Bermudan Swaptions",
        "authors": [
            "Raj G. Patel",
            "Tomas Dominguez",
            "Mohammad Dib",
            "Samuel Palmer",
            "Andrea Cadarso",
            "Fernando De Lope Contreras",
            "Abdelkader Ratnani",
            "Francisco Gomez Casanova",
            "Senaida Hernández-Santana",
            "Álvaro Díaz-Fernández",
            "Eva Andrés",
            "Jorge Luis-Hita",
            "Escolástico Sánchez-Martínez",
            "Samuel Mugel",
            "Roman Orus"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  The Cheyette model is a quasi-Gaussian volatility interest rate model widely\nused to price interest rate derivatives such as European and Bermudan Swaptions\nfor which Monte Carlo simulation has become the industry standard. In low\ndimensions, these approaches provide accurate and robust prices for European\nSwaptions but, even in this computationally simple setting, they are known to\nunderestimate the value of Bermudan Swaptions when using the state variables as\nregressors. This is mainly due to the use of a finite number of predetermined\nbasis functions in the regression. Moreover, in high-dimensional settings,\nthese approaches succumb to the Curse of Dimensionality. To address these\nissues, Deep-learning techniques have been used to solve the backward\nStochastic Differential Equation associated with the value process for European\nand Bermudan Swaptions; however, these methods are constrained by training time\nand memory. To overcome these limitations, we propose leveraging Tensor Neural\nNetworks as they can provide significant parameter savings while attaining the\nsame accuracy as classical Dense Neural Networks. In this paper we rigorously\nbenchmark the performance of Tensor Neural Networks and Dense Neural Networks\nfor pricing European and Bermudan Swaptions, and we show that Tensor Neural\nNetworks can be trained faster than Dense Neural Networks and provide more\naccurate and robust prices than their Dense counterparts.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09750v2"
    },
    {
        "title": "Systematic Review on Reinforcement Learning in the Field of Fintech",
        "authors": [
            "Nadeem Malibari",
            "Iyad Katib",
            "Rashid Mehmood"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Applications of Reinforcement Learning in the Finance Technology (Fintech)\nhave acquired a lot of admiration lately. Undoubtedly Reinforcement Learning,\nthrough its vast competence and proficiency, has aided remarkable results in\nthe field of Fintech. The objective of this systematic survey is to perform an\nexploratory study on a correlation between reinforcement learning and Fintech\nto highlight the prediction accuracy, complexity, scalability, risks,\nprofitability and performance. Major uses of reinforcement learning in finance\nor Fintech include portfolio optimization, credit risk reduction, investment\ncapital management, profit maximization, effective recommendation systems, and\nbetter price setting strategies. Several studies have addressed the actual\ncontribution of reinforcement learning to the performance of financial\ninstitutions. The latest studies included in this survey are publications from\n2018 onward. The survey is conducted using PRISMA technique which focuses on\nthe reporting of reviews and is based on a checklist and four-phase flow\ndiagram. The conducted survey indicates that the performance of RL-based\nstrategies in Fintech fields proves to perform considerably better than other\nstate-of-the-art algorithms. The present work discusses the use of\nreinforcement learning algorithms in diverse decision-making challenges in\nFintech and concludes that the organizations dealing with finance can benefit\ngreatly from Robo-advising, smart order channelling, market making, hedging and\noptions pricing, portfolio optimization, and optimal execution.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07466v1"
    },
    {
        "title": "Deep Learning for Solving and Estimating Dynamic Macro-Finance Models",
        "authors": [
            "Benjamin Fan",
            "Edward Qiao",
            "Anran Jiao",
            "Zhouzhou Gu",
            "Wenhao Li",
            "Lu Lu"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We develop a methodology that utilizes deep learning to simultaneously solve\nand estimate canonical continuous-time general equilibrium models in financial\neconomics. We illustrate our method in two examples: (1) industrial dynamics of\nfirms and (2) macroeconomic models with financial frictions. Through these\napplications, we illustrate the advantages of our method: generality,\nsimultaneous solution and estimation, leveraging the state-of-art\nmachine-learning techniques, and handling large state space. The method is\nversatile and can be applied to a vast variety of problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.09783v1"
    },
    {
        "title": "The Quadratic Local Variance Gamma Model: an arbitrage-free\n  interpolation of class $\\mathcal{C}^3$ for option prices",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper generalizes the local variance gamma model of Carr and Nadtochiy,\nto a piecewise quadratic local variance function. The formulation encompasses\nthe piecewise linear Bachelier and piecewise linear Black local variance gamma\nmodels. The quadratic local variance function results in an arbitrage-free\ninterpolation of class $\\mathcal{C}^3$. The increased smoothness over the\npiecewise-constant and piecewise-linear representation allows to reduce the\nnumber of knots when interpolating raw market quotes, thus providing an\ninteresting alternative to regularization while reducing the computational\ncost.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13791v1"
    },
    {
        "title": "A Game of Competition for Risk",
        "authors": [
            "Louis Abraham"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this study, we present models where participants strategically select\ntheir risk levels and earn corresponding rewards, mirroring real-world\ncompetition across various sectors. Our analysis starts with a normal form game\ninvolving two players in a continuous action space, confirming the existence\nand uniqueness of a Nash equilibrium and providing an analytical solution. We\nthen extend this analysis to multi-player scenarios, introducing a new\nnumerical algorithm for its calculation. A key novelty of our work lies in\nusing regret minimization algorithms to solve continuous games through\ndiscretization. This groundbreaking approach enables us to incorporate\nadditional real-world factors like market frictions and risk correlations among\nfirms. We also experimentally validate that the Nash equilibrium in our model\nalso serves as a correlated equilibrium. Our findings illuminate how market\nfrictions and risk correlations affect strategic risk-taking. We also explore\nhow policy measures can impact risk-taking and its associated rewards, with our\nmodel providing broader applicability than the Diamond-Dybvig framework. We\nmake our methodology and open-source code available at\nhttps://github.com/louisabraham/cfrgame\n  Finally, we contribute methodologically by advocating the use of algorithms\nin economics, shifting focus from finite games to games with continuous action\nsets. Our study provides a solid framework for analyzing strategic interactions\nin continuous action games, emphasizing the importance of market frictions,\nrisk correlations, and policy measures in strategic risk-taking dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.18941v1"
    },
    {
        "title": "Causality between Sentiment and Cryptocurrency Prices",
        "authors": [
            "Lubdhak Mondal",
            "Udeshya Raj",
            "Abinandhan S",
            "Began Gowsik S",
            "Sarwesh P",
            "Abhijeet Chandra"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This study investigates the relationship between narratives conveyed through\nmicroblogging platforms, namely Twitter, and the value of crypto assets. Our\nstudy provides a unique technique to build narratives about cryptocurrency by\ncombining topic modelling of short texts with sentiment analysis. First, we\nused an unsupervised machine learning algorithm to discover the latent topics\nwithin the massive and noisy textual data from Twitter, and then we revealed\n4-5 cryptocurrency-related narratives, including financial investment,\ntechnological advancement related to crypto, financial and political\nregulations, crypto assets, and media coverage. In a number of situations, we\nnoticed a strong link between our narratives and crypto prices. Our work\nconnects the most recent innovation in economics, Narrative Economics, to a new\narea of study that combines topic modelling and sentiment analysis to relate\nconsumer behaviour to narratives.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.05803v1"
    },
    {
        "title": "Constructing Time-Series Momentum Portfolios with Deep Multi-Task\n  Learning",
        "authors": [
            "Joel Ong",
            "Dorien Herremans"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  A diversified risk-adjusted time-series momentum (TSMOM) portfolio can\ndeliver substantial abnormal returns and offer some degree of tail risk\nprotection during extreme market events. The performance of existing TSMOM\nstrategies, however, relies not only on the quality of the momentum signal but\nalso on the efficacy of the volatility estimator. Yet many of the existing\nstudies have always considered these two factors to be independent. Inspired by\nrecent progress in Multi-Task Learning (MTL), we present a new approach using\nMTL in a deep neural network architecture that jointly learns portfolio\nconstruction and various auxiliary tasks related to volatility, such as\nforecasting realized volatility as measured by different volatility estimators.\nThrough backtesting from January 2000 to December 2020 on a diversified\nportfolio of continuous futures contracts, we demonstrate that even after\naccounting for transaction costs of up to 3 basis points, our approach\noutperforms existing TSMOM strategies. Moreover, experiments confirm that\nadding auxiliary tasks indeed boosts the portfolio's performance. These\nfindings demonstrate that MTL can be a powerful tool in finance.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.13661v1"
    },
    {
        "title": "American options in time-dependent one-factor models: Semi-analytic\n  pricing, numerical methods and ML support",
        "authors": [
            "Andrey Itkin",
            "Dmitry Muravey"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Semi-analytical pricing of American options in a time-dependent\nOrnstein-Uhlenbeck model was presented in [Carr, Itkin, 2020]. It was shown\nthat to obtain these prices one needs to solve (numerically) a nonlinear\nVolterra integral equation of the second kind to find the exercise boundary\n(which is a function of the time only). Once this is done, the option prices\nfollow. It was also shown that computationally this method is as efficient as\nthe forward finite difference solver while providing better accuracy and\nstability. Later this approach called \"the Generalized Integral transform\"\nmethod has been significantly extended by the authors (also, in cooperation\nwith Peter Carr and Alex Lipton) to various time-dependent one factor, and\nstochastic volatility models as applied to pricing barrier options. However,\nfor American options, despite possible, this was not explicitly reported\nanywhere. In this paper our goal is to fill this gap and also discuss which\nnumerical method (including those in machine learning) could be efficient to\nsolve the corresponding Volterra integral equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.13870v1"
    },
    {
        "title": "Modeling Inverse Demand Function with Explainable Dual Neural Networks",
        "authors": [
            "Zhiyu Cao",
            "Zihan Chen",
            "Prerna Mishra",
            "Hamed Amini",
            "Zachary Feinstein"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Financial contagion has been widely recognized as a fundamental risk to the\nfinancial system. Particularly potent is price-mediated contagion, wherein\nforced liquidations by firms depress asset prices and propagate financial\nstress, enabling crises to proliferate across a broad spectrum of seemingly\nunrelated entities. Price impacts are currently modeled via exogenous inverse\ndemand functions. However, in real-world scenarios, only the initial shocks and\nthe final equilibrium asset prices are typically observable, leaving actual\nasset liquidations largely obscured. This missing data presents significant\nlimitations to calibrating the existing models. To address these challenges, we\nintroduce a novel dual neural network structure that operates in two sequential\nstages: the first neural network maps initial shocks to predicted asset\nliquidations, and the second network utilizes these liquidations to derive\nresultant equilibrium prices. This data-driven approach can capture both linear\nand non-linear forms without pre-specifying an analytical structure;\nfurthermore, it functions effectively even in the absence of observable\nliquidation data. Experiments with simulated datasets demonstrate that our\nmodel can accurately predict equilibrium asset prices based solely on initial\nshocks, while revealing a strong alignment between predicted and true\nliquidations. Our explainable framework contributes to the understanding and\nmodeling of price-mediated contagion and provides valuable insights for\nfinancial authorities to construct effective stress tests and regulatory\npolicies.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.14322v2"
    },
    {
        "title": "Alpha-GPT: Human-AI Interactive Alpha Mining for Quantitative Investment",
        "authors": [
            "Saizhuo Wang",
            "Hang Yuan",
            "Leon Zhou",
            "Lionel M. Ni",
            "Heung-Yeung Shum",
            "Jian Guo"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  One of the most important tasks in quantitative investment research is mining\nnew alphas (effective trading signals or factors). Traditional alpha mining\nmethods, either hand-crafted factor synthesizing or algorithmic factor mining\n(e.g., search with genetic programming), have inherent limitations, especially\nin implementing the ideas of quants. In this work, we propose a new alpha\nmining paradigm by introducing human-AI interaction, and a novel prompt\nengineering algorithmic framework to implement this paradigm by leveraging the\npower of large language models. Moreover, we develop Alpha-GPT, a new\ninteractive alpha mining system framework that provides a heuristic way to\n``understand'' the ideas of quant researchers and outputs creative, insightful,\nand effective alphas. We demonstrate the effectiveness and advantage of\nAlpha-GPT via a number of alpha mining experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.00016v1"
    },
    {
        "title": "Nested Multilevel Monte Carlo with Biased and Antithetic Sampling",
        "authors": [
            "Abdul-Lateef Haji-Ali",
            "Jonathan Spence"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We consider the problem of estimating a nested structure of two expectations\ntaking the form $U_0 = E[\\max\\{U_1(Y), \\pi(Y)\\}]$, where $U_1(Y) = E[X\\ |\\ Y]$.\nTerms of this form arise in financial risk estimation and option pricing. When\n$U_1(Y)$ requires approximation, but exact samples of $X$ and $Y$ are\navailable, an antithetic multilevel Monte Carlo (MLMC) approach has been\nwell-studied in the literature. Under general conditions, the antithetic MLMC\nestimator obtains a root mean squared error $\\varepsilon$ with order\n$\\varepsilon^{-2}$ cost. If, additionally, $X$ and $Y$ require approximate\nsampling, careful balancing of the various aspects of approximation is required\nto avoid a significant computational burden. Under strong convergence criteria\non approximations to $X$ and $Y$, randomised multilevel Monte Carlo techniques\ncan be used to construct unbiased Monte Carlo estimates of $U_1$, which can be\npaired with an antithetic MLMC estimate of $U_0$ to recover order\n$\\varepsilon^{-2}$ computational cost. In this work, we instead consider biased\nmultilevel approximations of $U_1(Y)$, which require less strict assumptions on\nthe approximate samples of $X$. Extensions to the method consider an\napproximate and antithetic sampling of $Y$. Analysis shows the resulting\nestimator has order $\\varepsilon^{-2}$ asymptotic cost under the conditions\nrequired by randomised MLMC and order $\\varepsilon^{-2}|\\log\\varepsilon|^3$\ncost under more general assumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.07835v1"
    },
    {
        "title": "Instabilities of Super-Time-Stepping Methods on the Heston Stochastic\n  Volatility Model",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This note explores in more details instabilities of explicit\nsuper-time-stepping schemes, such as the Runge-Kutta-Chebyshev or\nRunge-Kutta-Legendre schemes, noticed in the litterature, when applied to the\nHeston stochastic volatility model. The stability remarks are relevant beyond\nthe scope of super-time-stepping schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.00540v1"
    },
    {
        "title": "Generating drawdown-realistic financial price paths using path\n  signatures",
        "authors": [
            "Emiel Lemahieu",
            "Kris Boudt",
            "Maarten Wyns"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  A novel generative machine learning approach for the simulation of sequences\nof financial price data with drawdowns quantifiably close to empirical data is\nintroduced. Applications such as pricing drawdown insurance options or\ndeveloping portfolio drawdown control strategies call for a host of\ndrawdown-realistic paths. Historical scenarios may be insufficient to\neffectively train and backtest the strategy, while standard parametric Monte\nCarlo does not adequately preserve drawdowns. We advocate a non-parametric\nMonte Carlo approach combining a variational autoencoder generative model with\na drawdown reconstruction loss function. To overcome issues of numerical\ncomplexity and non-differentiability, we approximate drawdown as a linear\nfunction of the moments of the path, known in the literature as path\nsignatures. We prove the required regularity of drawdown function and\nconsistency of the approximation. Furthermore, we obtain close numerical\napproximations using linear regression for fractional Brownian and empirical\ndata. We argue that linear combinations of the moments of a path yield a\nmathematically non-trivial smoothing of the drawdown function, which gives one\nleeway to simulate drawdown-realistic price paths by including drawdown\nevaluation metrics in the learning objective. We conclude with numerical\nexperiments on mixed equity, bond, real estate and commodity portfolios and\nobtain a host of drawdown-realistic paths.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04507v1"
    },
    {
        "title": "PAMS: Platform for Artificial Market Simulations",
        "authors": [
            "Masanori Hirano",
            "Ryosuke Takata",
            "Kiyoshi Izumi"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper presents a new artificial market simulation platform, PAMS:\nPlatform for Artificial Market Simulations. PAMS is developed as a Python-based\nsimulator that is easily integrated with deep learning and enabling various\nsimulation that requires easy users' modification. In this paper, we\ndemonstrate PAMS effectiveness through a study using agents predicting future\nprices by deep learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10729v1"
    },
    {
        "title": "Stock Market Sentiment Classification and Backtesting via Fine-tuned\n  BERT",
        "authors": [
            "Jiashu Lou"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  With the rapid development of big data and computing devices, low-latency\nautomatic trading platforms based on real-time information acquisition have\nbecome the main components of the stock trading market, so the topic of\nquantitative trading has received widespread attention. And for non-strongly\nefficient trading markets, human emotions and expectations always dominate\nmarket trends and trading decisions. Therefore, this paper starts from the\ntheory of emotion, taking East Money as an example, crawling user comment\ntitles data from its corresponding stock bar and performing data cleaning.\nSubsequently, a natural language processing model BERT was constructed, and the\nBERT model was fine-tuned using existing annotated data sets. The experimental\nresults show that the fine-tuned model has different degrees of performance\nimprovement compared to the original model and the baseline model.\nSubsequently, based on the above model, the user comment data crawled is\nlabeled with emotional polarity, and the obtained label information is combined\nwith the Alpha191 model to participate in regression, and significant\nregression results are obtained. Subsequently, the regression model is used to\npredict the average price change for the next five days, and use it as a signal\nto guide automatic trading. The experimental results show that the\nincorporation of emotional factors increased the return rate by 73.8\\% compared\nto the baseline during the trading period, and by 32.41\\% compared to the\noriginal alpha191 model. Finally, we discuss the advantages and disadvantages\nof incorporating emotional factors into quantitative trading, and give possible\ndirections for further research in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.11979v1"
    },
    {
        "title": "The ATM implied skew in the ADO-Heston model",
        "authors": [
            "Andrey Itkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper similar to [P. Carr, A. Itkin, 2019] we construct another\nMarkovian approximation of the rough Heston-like volatility model - the\nADO-Heston model. The characteristic function (CF) of the model is derived\nunder both risk-neutral and real measures which is an unsteady\nthree-dimensional PDE with some coefficients being functions of the time $t$\nand the Hurst exponent $H$. To replicate known behavior of the market implied\nskew we proceed with a wise choice of the market price of risk, and then find a\nclosed form expression for the CF of the log-price and the ATM implied skew.\nBased on the provided example, we claim that the ADO-Heston model (which is a\npure diffusion model but with a stochastic mean-reversion speed of the variance\nprocess, or a Markovian approximation of the rough Heston model) is able\n(approximately) to reproduce the known behavior of the vanilla implied skew at\nsmall $T$. We conclude that the behavior of our implied volatility skew curve\n${\\cal S}(T) \\propto a(H) T^{b\\cdot (H-1/2)}, \\, b = const$, is not exactly\nsame as in rough volatility models since $b \\ne 1$, but seems to be close\nenough for all practical values of $T$. Thus, the proposed Markovian model is\nable to replicate some properties of the corresponding rough volatility model.\nSimilar analysis is provided for the forward starting options where we found\nthat the ATM implied skew for the forward starting options can blow-up for any\n$s > t$ when $T \\to s$. This result, however, contradicts to the observation of\n[E. Alos, D.G. Lorite, 2021] that Markovian approximation is not able to catch\nthis behavior, so remains the question on which one is closer to reality.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.15044v1"
    },
    {
        "title": "Automated regime detection in multidimensional time series data using\n  sliced Wasserstein k-means clustering",
        "authors": [
            "Qinmeng Luan",
            "James Hamp"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Recent work has proposed Wasserstein k-means (Wk-means) clustering as a\npowerful method to identify regimes in time series data, and one-dimensional\nasset returns in particular. In this paper, we begin by studying in detail the\nbehaviour of the Wasserstein k-means clustering algorithm applied to synthetic\none-dimensional time series data. We study the dynamics of the algorithm and\ninvestigate how varying different hyperparameters impacts the performance of\nthe clustering algorithm for different random initialisations. We compute\nsimple metrics that we find are useful in identifying high-quality clusterings.\nThen, we extend the technique of Wasserstein k-means clustering to\nmultidimensional time series data by approximating the multidimensional\nWasserstein distance as a sliced Wasserstein distance, resulting in a method we\ncall `sliced Wasserstein k-means (sWk-means) clustering'. We apply the\nsWk-means clustering method to the problem of automated regime detection in\nmultidimensional time series data, using synthetic data to demonstrate the\nvalidity of the approach. Finally, we show that the sWk-means method is\neffective in identifying distinct market regimes in real multidimensional\nfinancial time series, using publicly available foreign exchange spot rate data\nas a case study. We conclude with remarks about some limitations of our\napproach and potential complementary or alternative approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.01285v1"
    },
    {
        "title": "Applying Reinforcement Learning to Option Pricing and Hedging",
        "authors": [
            "Zoran Stoiljkovic"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This thesis provides an overview of the recent advances in reinforcement\nlearning in pricing and hedging financial instruments, with a primary focus on\na detailed explanation of the Q-Learning Black Scholes approach, introduced by\nHalperin (2017). This reinforcement learning approach bridges the traditional\nBlack and Scholes (1973) model with novel artificial intelligence algorithms,\nenabling option pricing and hedging in a completely model-free and data-driven\nway. This paper also explores the algorithm's performance under different state\nvariables and scenarios for a European put option. The results reveal that the\nmodel is an accurate estimator under different levels of volatility and hedging\nfrequency. Moreover, this method exhibits robust performance across various\nlevels of option's moneyness. Lastly, the algorithm incorporates proportional\ntransaction costs, indicating diverse impacts on profit and loss, affected by\ndifferent statistical properties of the state variables.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04336v1"
    },
    {
        "title": "Integration of Fractional Order Black-Scholes Merton with Neural Network",
        "authors": [
            "Sarit Maitra",
            "Vivek Mishra",
            "Goutam Kr. Kundu",
            "Kapil Arora"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This study enhances option pricing by presenting unique pricing model\nfractional order Black-Scholes-Merton (FOBSM) which is based on the\nBlack-Scholes-Merton (BSM) model. The main goal is to improve the precision and\nauthenticity of option pricing, matching them more closely with the financial\nlandscape. The approach integrates the strengths of both the BSM and neural\nnetwork (NN) with complex diffusion dynamics. This study emphasizes the need to\ntake fractional derivatives into account when analyzing financial market\ndynamics. Since FOBSM captures memory characteristics in sequential data, it is\nbetter at simulating real-world systems than integer-order models. Findings\nreveals that in complex diffusion dynamics, this hybridization approach in\noption pricing improves the accuracy of price predictions. the key contribution\nof this work lies in the development of a novel option pricing model (FOBSM)\nthat leverages fractional calculus and neural networks to enhance accuracy in\ncapturing complex diffusion dynamics and memory effects in financial data.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04464v2"
    },
    {
        "title": "Anomalous diffusion and price impact in the fluid-limit of an order book",
        "authors": [
            "Derick Diana",
            "Tim Gebbie"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We extend a Discrete Time Random Walk (DTRW) numerical scheme to simulate the\nanomalous diffusion of financial market orders in a simulated order book. Here\nusing random walks with Sibuya waiting times to include a time-dependent\nstochastic forcing function with non-uniformly sampled times between order book\nevents in the setting of fractional diffusion. This models the fluid limit of\nan order book by modelling the continuous arrival, cancellation and diffusion\nof orders in the presence of information shocks. We study the impulse response\nand stylised facts of orders undergoing anomalous diffusion for different\nforcing functions and model parameters. Concretely, we demonstrate the price\nimpact for flash limit-orders and market orders and show how the numerical\nmethod generate kinks in the price impact. We use cubic spline interpolation to\ngenerate smoothed price impact curves. The work promotes the use of non-uniform\nsampling in the presence of diffusive dynamics as the preferred simulation\nmethod.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.06079v4"
    },
    {
        "title": "Error Analysis of Option Pricing via Deep PDE Solvers: Empirical Study",
        "authors": [
            "Rawin Assabumrungrat",
            "Kentaro Minami",
            "Masanori Hirano"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Option pricing, a fundamental problem in finance, often requires solving\nnon-linear partial differential equations (PDEs). When dealing with multi-asset\noptions, such as rainbow options, these PDEs become high-dimensional, leading\nto challenges posed by the curse of dimensionality. While deep learning-based\nPDE solvers have recently emerged as scalable solutions to this\nhigh-dimensional problem, their empirical and quantitative accuracy remains not\nwell-understood, hindering their real-world applicability. In this study, we\naimed to offer actionable insights into the utility of Deep PDE solvers for\npractical option pricing implementation. Through comparative experiments, we\nassessed the empirical performance of these solvers in high-dimensional\ncontexts. Our investigation identified three primary sources of errors in Deep\nPDE solvers: (i) errors inherent in the specifications of the target option and\nunderlying assets, (ii) errors originating from the asset model simulation\nmethods, and (iii) errors stemming from the neural network training. Through\nablation studies, we evaluated the individual impact of each error source. Our\nresults indicate that the Deep BSDE method (DBSDE) is superior in performance\nand exhibits robustness against variations in option specifications. In\ncontrast, some other methods are overly sensitive to option specifications,\nsuch as time to expiration. We also find that the performance of these methods\nimproves inversely proportional to the square root of batch size and the number\nof time steps. This observation can aid in estimating computational resources\nfor achieving desired accuracies with Deep PDE solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.07231v1"
    },
    {
        "title": "Fast and Stable Credit Gamma of CVA",
        "authors": [
            "Roberto Daluiso"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Credit Valuation Adjustment is a balance sheet item which is nowadays subject\nto active risk management by specialized traders. However, one of the most\nimportant risk factors, which is the vector of default intensities of the\ncounterparty, affects in a non-differentiable way the most general Monte Carlo\nestimator of the adjustment, through simulation of default times. Thus the\ncomputation of first and second order (pure and mixed) sensitivities involving\nthese inputs cannot rely on direct path-wise differentiation, while any\napproach involving finite differences shows very high statistical noise. We\npresent ad hoc analytical estimators which overcome these issues while offering\nvery low runtime overheads over the baseline computation of the price\nadjustment. We also discuss the conversion of the so-obtained sensitivities to\nmodel parameters (e.g. default intensities) into sensitivities to market quotes\n(e.g. Credit Default Swap spreads).\n",
        "pdf_link": "http://arxiv.org/pdf/2311.11672v1"
    },
    {
        "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and\n  Character Design",
        "authors": [
            "Yangyang Yu",
            "Haohang Li",
            "Zhi Chen",
            "Yuechen Jiang",
            "Yang Li",
            "Denghui Zhang",
            "Rong Liu",
            "Jordan W. Suchow",
            "Khaldoun Khashanah"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Recent advancements in Large Language Models (LLMs) have exhibited notable\nefficacy in question-answering (QA) tasks across diverse domains. Their prowess\nin integrating extensive web knowledge has fueled interest in developing\nLLM-based autonomous agents. While LLMs are efficient in decoding human\ninstructions and deriving solutions by holistically processing historical\ninputs, transitioning to purpose-driven agents requires a supplementary\nrational architecture to process multi-source information, establish reasoning\nchains, and prioritize critical tasks. Addressing this, we introduce\n\\textsc{FinMem}, a novel LLM-based agent framework devised for financial\ndecision-making. It encompasses three core modules: Profiling, to customize the\nagent's characteristics; Memory, with layered message processing, to aid the\nagent in assimilating hierarchical financial data; and Decision-making, to\nconvert insights gained from memories into investment decisions. Notably,\n\\textsc{FinMem}'s memory module aligns closely with the cognitive structure of\nhuman traders, offering robust interpretability and real-time tuning. Its\nadjustable cognitive span allows for the retention of critical information\nbeyond human perceptual limits, thereby enhancing trading outcomes. This\nframework enables the agent to self-evolve its professional knowledge, react\nagilely to new investment cues, and continuously refine trading decisions in\nthe volatile financial environment. We first compare \\textsc{FinMem} with\nvarious algorithmic agents on a scalable real-world financial dataset,\nunderscoring its leading trading performance in stocks. We then fine-tuned the\nagent's perceptual span and character setting to achieve a significantly\nenhanced trading performance. Collectively, \\textsc{FinMem} presents a\ncutting-edge LLM agent framework for automated trading, boosting cumulative\ninvestment returns.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.13743v2"
    },
    {
        "title": "Narratives from GPT-derived Networks of News, and a link to Financial\n  Markets Dislocations",
        "authors": [
            "Deborah Miori",
            "Constantin Petrov"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Starting from a corpus of economic articles from The Wall Street Journal, we\npresent a novel systematic way to analyse news content that evolves over time.\nWe leverage on state-of-the-art natural language processing techniques (i.e.\nGPT3.5) to extract the most important entities of each article available, and\naggregate co-occurrence of entities in a related graph at the weekly level.\nNetwork analysis techniques and fuzzy community detection are tested on the\nproposed set of graphs, and a framework is introduced that allows systematic\nbut interpretable detection of topics and narratives. In parallel, we propose\nto consider the sentiment around main entities of an article as a more accurate\nproxy for the overall sentiment of such piece of text, and describe a\ncase-study to motivate this choice. Finally, we design features that\ncharacterise the type and structure of news within each week, and map them to\nmoments of financial markets dislocations. The latter are identified as dates\nwith unusually high volatility across asset classes, and we find quantitative\nevidence that they relate to instances of high entropy in the high-dimensional\nspace of interconnected news. This result further motivates the pursued efforts\nto provide a novel framework for the systematic analysis of narratives within\nnews.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.14419v1"
    },
    {
        "title": "Copula-based deviation measure of cointegrated financial assets",
        "authors": [
            "Alexander Shulzhenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This study outlines a comprehensive methodology utilizing copulas to discern\ninconsistencies in the behavior exhibited by pairs of financial assets. It\nintroduces a robust approach to establishing the interrelationship between the\nreturns of these assets, exploring potential measures of dependence among the\nstochastic variables represented by these returns. Special emphasis is placed\non scrutinizing the traditional measure of dependence, namely the correlation\ncoefficient, delineating its limitations. Furthermore, the study articulates an\nalternative methodology that offers enhanced stability and informativeness in\nappraising the relationship between financial instrument returns.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.02081v1"
    },
    {
        "title": "CVA Hedging by Risk-Averse Stochastic-Horizon Reinforcement Learning",
        "authors": [
            "Roberto Daluiso",
            "Marco Pinciroli",
            "Michele Trapletti",
            "Edoardo Vittori"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This work studies the dynamic risk management of the risk-neutral value of\nthe potential credit losses on a portfolio of derivatives. Sensitivities-based\nhedging of such liability is sub-optimal because of bid-ask costs, pricing\nmodels which cannot be completely realistic, and a discontinuity at default\ntime. We leverage recent advances on risk-averse Reinforcement Learning\ndeveloped specifically for option hedging with an ad hoc practice-aligned\nobjective function aware of pathwise volatility, generalizing them to\nstochastic horizons. We formalize accurately the evolution of the hedger's\nportfolio stressing such aspects. We showcase the efficacy of our approach by a\nnumerical study for a portfolio composed of a single FX forward contract.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14044v1"
    },
    {
        "title": "Notes on the SWIFT method based on Shannon Wavelets for Option Pricing\n  -- Revisited",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This note revisits the SWIFT method based on Shannon wavelets to price\nEuropean options under models with a known characteristic function in 2023. In\nparticular, it discusses some possible improvements and exposes some concrete\ndrawbacks of the method.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.01758v3"
    },
    {
        "title": "Deep Generative Modeling for Financial Time Series with Application in\n  VaR: A Comparative Review",
        "authors": [
            "Lars Ericson",
            "Xuejun Zhu",
            "Xusi Han",
            "Rao Fu",
            "Shuang Li",
            "Steve Guo",
            "Ping Hu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In the financial services industry, forecasting the risk factor distribution\nconditional on the history and the current market environment is the key to\nmarket risk modeling in general and value at risk (VaR) model in particular. As\none of the most widely adopted VaR models in commercial banks, Historical\nsimulation (HS) uses the empirical distribution of daily returns in a\nhistorical window as the forecast distribution of risk factor returns in the\nnext day. The objectives for financial time series generation are to generate\nsynthetic data paths with good variety, and similar distribution and dynamics\nto the original historical data. In this paper, we apply multiple existing deep\ngenerative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for\nconditional time series generation, and propose and test two new methods for\nconditional multi-step time series generation, namely Encoder-Decoder CGAN and\nConditional TimeVAE. Furthermore, we introduce a comprehensive framework with a\nset of KPIs to measure the quality of the generated time series for financial\nmodeling. The KPIs cover distribution distance, autocorrelation and\nbacktesting. All models (HS, parametric and neural networks) are tested on both\nhistorical USD yield curve data and additional data simulated from GARCH and\nCIR processes. The study shows that top performing models are HS, GARCH and\nCWGAN models. Future research directions in this area are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.10370v1"
    },
    {
        "title": "Fast and General Simulation of Lévy-driven OU processes for Energy\n  Derivatives",
        "authors": [
            "Roberto Baviera",
            "Pietro Manzoni"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  L\\'evy-driven Ornstein-Uhlenbeck (OU) processes represent an intriguing class\nof stochastic processes that have garnered interest in the energy sector for\ntheir ability to capture typical features of market dynamics. However, in the\ncurrent state of play, Monte Carlo simulations of these processes are not\nstraightforward for two main reasons: i) algorithms are available only for some\nspecific processes within this class; ii) they are often computationally\nexpensive. In this paper, we introduce a new simulation technique designed to\naddress both challenges. It relies on the numerical inversion of the\ncharacteristic function, offering a general methodology applicable to all\nL\\'evy-driven OU processes. Moreover, leveraging FFT, the proposed methodology\nensures fast and accurate simulations, providing a solid basis for the\nwidespread adoption of these processes in the energy sector. Lastly, the\nalgorithm allows an optimal control of the numerical error. We apply the\ntechnique to the pricing of energy derivatives, comparing the results with the\nexisting benchmarks. Our findings indicate that the proposed methodology is at\nleast one order of magnitude faster than the existing algorithms, while\nmaintaining an equivalent level of accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.15483v2"
    },
    {
        "title": "Exact simulation scheme for the Ornstein-Uhlenbeck driven stochastic\n  volatility model with the Karhunen-Loève expansions",
        "authors": [
            "Jaehyuk Choi"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study proposes a new exact simulation scheme of the Ornstein-Uhlenbeck\ndriven stochastic volatility model. With the Karhunen-Lo\\`eve expansions, the\nstochastic volatility path following the Ornstein-Uhlenbeck process is\nexpressed as a sine series, and the time integrals of volatility and variance\nare analytically derived as the sums of independent normal random variates. The\nnew method is several hundred times faster than Li and Wu [Eur. J. Oper. Res.,\n2019, 275(2), 768-779] that relies on computationally expensive numerical\ntransform inversion. The simulation algorithm is further improved with the\nconditional Monte-Carlo method and the martingale-preserving control variate on\nthe spot price.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09243v1"
    },
    {
        "title": "Modelling crypto markets by multi-agent reinforcement learning",
        "authors": [
            "Johann Lussange",
            "Stefano Vrizzi",
            "Stefano Palminteri",
            "Boris Gutkin"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Building on a previous foundation work (Lussange et al. 2020), this study\nintroduces a multi-agent reinforcement learning (MARL) model simulating crypto\nmarkets, which is calibrated to the Binance's daily closing prices of $153$\ncryptocurrencies that were continuously traded between 2018 and 2022. Unlike\nprevious agent-based models (ABM) or multi-agent systems (MAS) which relied on\nzero-intelligence agents or single autonomous agent methodologies, our approach\nrelies on endowing agents with reinforcement learning (RL) techniques in order\nto model crypto markets. This integration is designed to emulate, with a\nbottom-up approach to complexity inference, both individual and collective\nagents, ensuring robustness in the recent volatile conditions of such markets\nand during the COVID-19 era. A key feature of our model also lies in the fact\nthat its autonomous agents perform asset price valuation based on two sources\nof information: the market prices themselves, and the approximation of the\ncrypto assets fundamental values beyond what those market prices are. Our MAS\ncalibration against real market data allows for an accurate emulation of crypto\nmarkets microstructure and probing key market behaviors, in both the bearish\nand bullish regimes of that particular time period.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.10803v1"
    },
    {
        "title": "Optimizing Neural Networks for Bermudan Option Pricing: Convergence\n  Acceleration, Future Exposure Evaluation and Interpolation in Counterparty\n  Credit Risk",
        "authors": [
            "Vikranth Lokeshwar Dhandapani",
            "Shashi Jain"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper presents a Monte-Carlo-based artificial neural network framework\nfor pricing Bermudan options, offering several notable advantages. These\nadvantages encompass the efficient static hedging of the target Bermudan option\nand the effective generation of exposure profiles for risk management. We also\nintroduce a novel optimisation algorithm designed to expedite the convergence\nof the neural network framework proposed by Lokeshwar et al. (2022) supported\nby a comprehensive error convergence analysis. We conduct an extensive\ncomparative analysis of the Present Value (PV) distribution under Markovian and\nno-arbitrage assumptions. We compare the proposed neural network model in\nconjunction with the approach initially introduced by Longstaff and Schwartz\n(2001) and benchmark it against the COS model, the pricing model pioneered by\nFang and Oosterlee (2009), across all Bermudan exercise time points.\nAdditionally, we evaluate exposure profiles, including Expected Exposure and\nPotential Future Exposure, generated by our proposed model and the\nLongstaff-Schwartz model, comparing them against the COS model. We also derive\nexposure profiles at finer non-standard grid points or risk horizons using the\nproposed approach, juxtaposed with the Longstaff Schwartz method with linear\ninterpolation and benchmark against the COS method. In addition, we explore the\neffectiveness of various interpolation schemes within the context of the\nLongstaff-Schwartz method for generating exposures at finer grid horizons.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15936v1"
    },
    {
        "title": "Optimizing Portfolio Management and Risk Assessment in Digital Assets\n  Using Deep Learning for Predictive Analysis",
        "authors": [
            "Qishuo Cheng",
            "Le Yang",
            "Jiajian Zheng",
            "Miao Tian",
            "Duan Xin"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Portfolio management issues have been extensively studied in the field of\nartificial intelligence in recent years, but existing deep learning-based\nquantitative trading methods have some areas where they could be improved.\nFirst of all, the prediction mode of stocks is singular; often, only one\ntrading expert is trained by a model, and the trading decision is solely based\non the prediction results of the model. Secondly, the data source used by the\nmodel is relatively simple, and only considers the data of the stock itself,\nignoring the impact of the whole market risk on the stock. In this paper, the\nDQN algorithm is introduced into asset management portfolios in a novel and\nstraightforward way, and the performance greatly exceeds the benchmark, which\nfully proves the effectiveness of the DRL algorithm in portfolio management.\nThis also inspires us to consider the complexity of financial problems, and the\nuse of algorithms should be fully combined with the problems to adapt. Finally,\nin this paper, the strategy is implemented by selecting the assets and actions\nwith the largest Q value. Since different assets are trained separately as\nenvironments, there may be a phenomenon of Q value drift among different assets\n(different assets have different Q value distribution areas), which may easily\nlead to incorrect asset selection. Consider adding constraints so that the Q\nvalues of different assets share a Q value distribution to improve results.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15994v1"
    },
    {
        "title": "A time-stepping deep gradient flow method for option pricing in (rough)\n  diffusion models",
        "authors": [
            "Antonis Papapantoleon",
            "Jasper Rou"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We develop a novel deep learning approach for pricing European options in\ndiffusion models, that can efficiently handle high-dimensional problems\nresulting from Markovian approximations of rough volatility models. The option\npricing partial differential equation is reformulated as an energy minimization\nproblem, which is approximated in a time-stepping fashion by deep artificial\nneural networks. The proposed scheme respects the asymptotic behavior of option\nprices for large levels of moneyness, and adheres to a priori known bounds for\noption prices. The accuracy and efficiency of the proposed method is assessed\nin a series of numerical examples, with particular focus in the lifted Heston\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.00746v1"
    },
    {
        "title": "Quasi-Monte Carlo for Efficient Fourier Pricing of Multi-Asset Options",
        "authors": [
            "Christian Bayer",
            "Chiheb Ben Hammouda",
            "Antonis Papapantoleon",
            "Michael Samet",
            "Raúl Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Efficiently pricing multi-asset options poses a significant challenge in\nquantitative finance. The Monte Carlo (MC) method remains the prevalent choice\nfor pricing engines; however, its slow convergence rate impedes its practical\napplication. Fourier methods leverage the knowledge of the characteristic\nfunction to accurately and rapidly value options with up to two assets.\nNevertheless, they face hurdles in the high-dimensional settings due to the\ntensor product (TP) structure of commonly employed quadrature techniques. This\nwork advocates using the randomized quasi-MC (RQMC) quadrature to improve the\nscalability of Fourier methods with high dimensions. The RQMC technique\nbenefits from the smoothness of the integrand and alleviates the curse of\ndimensionality while providing practical error estimates. Nonetheless, the\napplicability of RQMC on the unbounded domain, $\\mathbb{R}^d$, requires a\ndomain transformation to $[0,1]^d$, which may result in singularities of the\ntransformed integrand at the corners of the hypercube, and deteriorate the rate\nof convergence of RQMC. To circumvent this difficulty, we design an efficient\ndomain transformation procedure based on the derived boundary growth conditions\nof the integrand. This transformation preserves the sufficient regularity of\nthe integrand and hence improves the rate of convergence of RQMC. To validate\nthis analysis, we demonstrate the efficiency of employing RQMC with an\nappropriate transformation to evaluate options in the Fourier space for various\npricing models, payoffs, and dimensions. Finally, we highlight the\ncomputational advantage of applying RQMC over MC or TP in the Fourier domain,\nand over MC in the physical domain for options with up to 15 assets.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.02832v1"
    },
    {
        "title": "Enhancing Price Prediction in Cryptocurrency Using Transformer Neural\n  Network and Technical Indicators",
        "authors": [
            "Mohammad Ali Labbaf Khaniki",
            "Mohammad Manthouri"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study presents an innovative approach for predicting cryptocurrency time\nseries, specifically focusing on Bitcoin, Ethereum, and Litecoin. The\nmethodology integrates the use of technical indicators, a Performer neural\nnetwork, and BiLSTM (Bidirectional Long Short-Term Memory) to capture temporal\ndynamics and extract significant features from raw cryptocurrency data. The\napplication of technical indicators, such facilitates the extraction of\nintricate patterns, momentum, volatility, and trends. The Performer neural\nnetwork, employing Fast Attention Via positive Orthogonal Random features\n(FAVOR+), has demonstrated superior computational efficiency and scalability\ncompared to the traditional Multi-head attention mechanism in Transformer\nmodels. Additionally, the integration of BiLSTM in the feedforward network\nenhances the model's capacity to capture temporal dynamics in the data,\nprocessing it in both forward and backward directions. This is particularly\nadvantageous for time series data where past and future data points can\ninfluence the current state. The proposed method has been applied to the hourly\nand daily timeframes of the major cryptocurrencies and its performance has been\nbenchmarked against other methods documented in the literature. The results\nunderscore the potential of the proposed method to outperform existing models,\nmarking a significant progression in the field of cryptocurrency price\nprediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03606v1"
    },
    {
        "title": "Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution\n  Analyst?",
        "authors": [
            "Bruno de Melo",
            "Jamiel Sheikh"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Performance attribution analysis, defined as the process of explaining the\ndrivers of the excess performance of an investment portfolio against a\nbenchmark, stands as a significant feature of portfolio management and plays a\ncrucial role in the investment decision-making process, particularly within the\nfund management industry. Rooted in a solid financial and mathematical\nframework, the importance and methodologies of this analytical technique are\nextensively documented across numerous academic research papers and books. The\nintegration of large language models (LLMs) and AI agents marks a\ngroundbreaking development in this field. These agents are designed to automate\nand enhance the performance attribution analysis by accurately calculating and\nanalyzing portfolio performances against benchmarks. In this study, we\nintroduce the application of an AI Agent for a variety of essential performance\nattribution tasks, including the analysis of performance drivers and utilizing\nLLMs as calculation engine for multi-level attribution analysis and\nquestion-answering (QA) tasks. Leveraging advanced prompt engineering\ntechniques such as Chain-of-Thought (CoT) and Plan and Solve (PS), and\nemploying a standard agent framework from LangChain, the research achieves\npromising results: it achieves accuracy rates exceeding 93% in analyzing\nperformance drivers, attains 100% in multi-level attribution calculations, and\nsurpasses 84% accuracy in QA exercises that simulate official examination\nstandards. These findings affirm the impactful role of AI agents, prompt\nengineering and evaluation in advancing portfolio management processes,\nhighlighting a significant development in the practical application and\nevaluation of Generative AI technologies within the domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.10482v2"
    },
    {
        "title": "Robust Utility Optimization via a GAN Approach",
        "authors": [
            "Florian Krach",
            "Josef Teichmann",
            "Hanna Wutte"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Robust utility optimization enables an investor to deal with market\nuncertainty in a structured way, with the goal of maximizing the worst-case\noutcome. In this work, we propose a generative adversarial network (GAN)\napproach to (approximately) solve robust utility optimization problems in\ngeneral and realistic settings. In particular, we model both the investor and\nthe market by neural networks (NN) and train them in a mini-max zero-sum game.\nThis approach is applicable for any continuous utility function and in\nrealistic market settings with trading costs, where only observable information\nof the market can be used. A large empirical study shows the versatile\nusability of our method. Whenever an optimal reference strategy is available,\nour method performs on par with it and in the (many) settings without known\noptimal strategy, our method outperforms all other reference strategies.\nMoreover, we can conclude from our study that the trained path-dependent\nstrategies do not outperform Markovian ones. Lastly, we uncover that our\ngenerative approach for learning optimal, (non-) robust investments under\ntrading costs generates universally applicable alternatives to well known\nasymptotic strategies of idealized settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.15243v1"
    },
    {
        "title": "Deep Joint Learning valuation of Bermudan Swaptions",
        "authors": [
            "Francisco Gómez Casanova",
            "Álvaro Leitao",
            "Fernando de Lope Contreras",
            "Carlos Vázquez"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper addresses the problem of pricing involved financial derivatives by\nmeans of advanced of deep learning techniques. More precisely, we smartly\ncombine several sophisticated neural network-based concepts like differential\nmachine learning, Monte Carlo simulation-like training samples and joint\nlearning to come up with an efficient numerical solution. The application of\nthe latter development represents a novelty in the context of computational\nfinance. We also propose a novel design of interdependent neural networks to\nprice early-exercise products, in this case, Bermudan swaptions. The\nimprovements in efficiency and accuracy provided by the here proposed approach\nis widely illustrated throughout a range of numerical experiments. Moreover,\nthis novel methodology can be extended to the pricing of other financial\nderivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.11257v1"
    },
    {
        "title": "Unveiling Nonlinear Dynamics in Catastrophe Bond Pricing: A Machine\n  Learning Perspective",
        "authors": [
            "Xiaowei Chen",
            "Hong Li",
            "Yufan Lu",
            "Rui Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper explores the implications of using machine learning models in the\npricing of catastrophe (CAT) bonds. By integrating advanced machine learning\ntechniques, our approach uncovers nonlinear relationships and complex\ninteractions between key risk factors and CAT bond spreads -- dynamics that are\noften overlooked by traditional linear regression models. Using primary market\nCAT bond transaction records between January 1999 and March 2021, our findings\ndemonstrate that machine learning models not only enhance the accuracy of CAT\nbond pricing but also provide a deeper understanding of how various risk\nfactors interact and influence bond prices in a nonlinear way. These findings\nsuggest that investors and issuers can benefit from incorporating machine\nlearning to better capture the intricate interplay between risk factors when\npricing CAT bonds. The results also highlight the potential for machine\nlearning models to refine our understanding of asset pricing in markets\ncharacterized by complex risk structures.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.00697v2"
    },
    {
        "title": "Gradient-enhanced sparse Hermite polynomial expansions for pricing and\n  hedging high-dimensional American options",
        "authors": [
            "Jiefei Yang",
            "Guanglian Li"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We propose an efficient and easy-to-implement gradient-enhanced least squares\nMonte Carlo method for computing price and Greeks (i.e., derivatives of the\nprice function) of high-dimensional American options. It employs the sparse\nHermite polynomial expansion as a surrogate model for the continuation value\nfunction, and essentially exploits the fast evaluation of gradients. The\nexpansion coefficients are computed by solving a linear least squares problem\nthat is enhanced by gradient information of simulated paths. We analyze the\nconvergence of the proposed method, and establish an error estimate in terms of\nthe best approximation error in the weighted $H^1$ space, the statistical error\nof solving discrete least squares problems, and the time step size. We present\ncomprehensive numerical experiments to illustrate the performance of the\nproposed method. The results show that it outperforms the state-of-the-art\nleast squares Monte Carlo method with more accurate price, Greeks, and optimal\nexercise strategies in high dimensions but with nearly identical computational\ncost, and it can deliver comparable results with recent neural network-based\nmethods up to dimension 100.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.02570v1"
    },
    {
        "title": "Modelling Opaque Bilateral Market Dynamics in Financial Trading:\n  Insights from a Multi-Agent Simulation Study",
        "authors": [
            "Alicia Vidler",
            "Toby Walsh"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Exploring complex adaptive financial trading environments through multi-agent\nbased simulation methods presents an innovative approach within the realm of\nquantitative finance. Despite the dominance of multi-agent reinforcement\nlearning approaches in financial markets with observable data, there exists a\nset of systematically significant financial markets that pose challenges due to\ntheir partial or obscured data availability. We, therefore, devise a\nmulti-agent simulation approach employing small-scale meta-heuristic methods.\nThis approach aims to represent the opaque bilateral market for Australian\ngovernment bond trading, capturing the bilateral nature of bank-to-bank\ntrading, also referred to as \"over-the-counter\" (OTC) trading, and commonly\noccurring between \"market makers\". The uniqueness of the bilateral market,\ncharacterized by negotiated transactions and a limited number of agents, yields\nvaluable insights for agent-based modelling and quantitative finance. The\ninherent rigidity of this market structure, which is at odds with the global\nproliferation of multilateral platforms and the decentralization of finance,\nunderscores the unique insights offered by our agent-based model. We explore\nthe implications of market rigidity on market structure and consider the\nelement of stability, in market design. This extends the ongoing discourse on\ncomplex financial trading environments, providing an enhanced understanding of\ntheir dynamics and implications.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.02849v1"
    },
    {
        "title": "Machine Learning Methods for Pricing Financial Derivatives",
        "authors": [
            "Lei Fan",
            "Justin Sirignano"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Stochastic differential equation (SDE) models are the foundation for pricing\nand hedging financial derivatives. The drift and volatility functions in SDE\nmodels are typically chosen to be algebraic functions with a small number (less\nthan 5) parameters which can be calibrated to market data. A more flexible\napproach is to use neural networks to model the drift and volatility functions,\nwhich provides more degrees-of-freedom to match observed market data. Training\nof models requires optimizing over an SDE, which is computationally\nchallenging. For European options, we develop a fast stochastic gradient\ndescent (SGD) algorithm for training the neural network-SDE model. Our SGD\nalgorithm uses two independent SDE paths to obtain an unbiased estimate of the\ndirection of steepest descent. For American options, we optimize over the\ncorresponding Kolmogorov partial differential equation (PDE). The neural\nnetwork appears as coefficient functions in the PDE. Models are trained on\nlarge datasets (many contracts), requiring either large simulations (many Monte\nCarlo samples for the stock price paths) or large numbers of PDEs (a PDE must\nbe solved for each contract). Numerical results are presented for real market\ndata including S&P 500 index options, S&P 100 index options, and single-stock\nAmerican options. The neural-network-based SDE models are compared against the\nBlack-Scholes model, the Dupire's local volatility model, and the Heston model.\nModels are evaluated in terms of how accurate they are at pricing out-of-sample\nfinancial derivatives, which is a core task in derivative pricing at financial\ninstitutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.00459v1"
    },
    {
        "title": "Pricing and calibration in the 4-factor path-dependent volatility model",
        "authors": [
            "Guido Gazzani",
            "Julien Guyon"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We consider the path-dependent volatility (PDV) model of Guyon and Lekeufack\n(2023), where the instantaneous volatility is a linear combination of a\nweighted sum of past returns and the square root of a weighted sum of past\nsquared returns. We discuss the influence of an additional parameter that\nunlocks enough volatility on the upside to reproduce the implied volatility\nsmiles of S&P 500 and VIX options. This PDV model, motivated by empirical\nstudies, comes with computational challenges, especially in relation to VIX\noptions pricing and calibration. We propose an accurate neural network\napproximation of the VIX which leverages on the Markovianity of the 4-factor\nversion of the model. The VIX is learned as a function of the Markovian factors\nand the model parameters. We use this approximation to tackle the joint\ncalibration of S&P 500 and VIX options.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.02319v1"
    },
    {
        "title": "Stock Movement Prediction with Multimodal Stable Fusion via Gated\n  Cross-Attention Mechanism",
        "authors": [
            "Chang Zong",
            "Hang Zhou"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The accurate prediction of stock movements is crucial for investment\nstrategies. Stock prices are subject to the influence of various forms of\ninformation, including financial indicators, sentiment analysis, news\ndocuments, and relational structures. Predominant analytical approaches,\nhowever, tend to address only unimodal or bimodal sources, neglecting the\ncomplexity of multimodal data. Further complicating the landscape are the\nissues of data sparsity and semantic conflicts between these modalities, which\nare frequently overlooked by current models, leading to unstable performance\nand limiting practical applicability. To address these shortcomings, this study\nintroduces a novel architecture, named Multimodal Stable Fusion with Gated\nCross-Attention (MSGCA), designed to robustly integrate multimodal input for\nstock movement prediction. The MSGCA framework consists of three integral\ncomponents: (1) a trimodal encoding module, responsible for processing\nindicator sequences, dynamic documents, and a relational graph, and\nstandardizing their feature representations; (2) a cross-feature fusion module,\nwhere primary and consistent features guide the multimodal fusion of the three\nmodalities via a pair of gated cross-attention networks; and (3) a prediction\nmodule, which refines the fused features through temporal and dimensional\nreduction to execute precise movement forecasting. Empirical evaluations\ndemonstrate that the MSGCA framework exceeds current leading methods, achieving\nperformance gains of 8.1%, 6.1%, 21.7% and 31.6% on four multimodal datasets,\nrespectively, attributed to its enhanced multimodal fusion stability.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.06594v2"
    },
    {
        "title": "Computation of Robust Option Prices via Structured Multi-Marginal\n  Martingale Optimal Transport",
        "authors": [
            "Linn Engström",
            "Sigrid Källblad",
            "Johan Karlsson"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We introduce an efficient computational framework for solving a class of\nmulti-marginal martingale optimal transport problems, which includes many\nrobust pricing problems of large financial interest. Such problems are\ntypically computationally challenging due to the martingale constraint,\nhowever, by extending the state space we can identify them with problems that\nexhibit a certain sequential martingale structure. Our method exploits such\nstructures in combination with entropic regularisation, enabling fast\ncomputation of optimal solutions and allowing us to solve problems with a large\nnumber of marginals. We demonstrate the method by using it for computing robust\nprice bounds for different options, such as lookback options and Asian options.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.09959v1"
    },
    {
        "title": "Reinforcement Learning for Corporate Bond Trading: A Sell Side\n  Perspective",
        "authors": [
            "Samuel Atkins",
            "Ali Fathi",
            "Sammy Assefa"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  A corporate bond trader in a typical sell side institution such as a bank\nprovides liquidity to the market participants by buying/selling securities and\nmaintaining an inventory. Upon receiving a request for a buy/sell price quote\n(RFQ), the trader provides a quote by adding a spread over a \\textit{prevalent\nmarket price}. For illiquid bonds, the market price is harder to observe, and\ntraders often resort to available benchmark bond prices (such as MarketAxess,\nBloomberg, etc.). In \\cite{Bergault2023ModelingLI}, the concept of \\textit{Fair\nTransfer Price} for an illiquid corporate bond was introduced which is derived\nfrom an infinite horizon stochastic optimal control problem (for maximizing the\ntrader's expected P\\&L, regularized by the quadratic variation). In this paper,\nwe consider the same optimization objective, however, we approach the\nestimation of an optimal bid-ask spread quoting strategy in a data driven\nmanner and show that it can be learned using Reinforcement Learning.\nFurthermore, we perform extensive outcome analysis to examine the\nreasonableness of the trained agent's behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.12983v1"
    },
    {
        "title": "What Teaches Robots to Walk, Teaches Them to Trade too -- Regime\n  Adaptive Execution using Informed Data and LLMs",
        "authors": [
            "Raeid Saqur"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Machine learning techniques applied to the problem of financial market\nforecasting struggle with dynamic regime switching, or underlying correlation\nand covariance shifts in true (hidden) market variables. Drawing inspiration\nfrom the success of reinforcement learning in robotics, particularly in agile\nlocomotion adaptation of quadruped robots to unseen terrains, we introduce an\ninnovative approach that leverages world knowledge of pretrained LLMs (aka.\n'privileged information' in robotics) and dynamically adapts them using\nintrinsic, natural market rewards using LLM alignment technique we dub as\n\"Reinforcement Learning from Market Feedback\" (**RLMF**). Strong empirical\nresults demonstrate the efficacy of our method in adapting to regime shifts in\nfinancial markets, a challenge that has long plagued predictive models in this\ndomain. The proposed algorithmic framework outperforms best-performing SOTA LLM\nmodels on the existing (FLARE) benchmark stock-movement (SM) tasks by more than\n15\\% improved accuracy. On the recently proposed NIFTY SM task, our adaptive\npolicy outperforms the SOTA best performing trillion parameter models like\nGPT-4. The paper details the dual-phase, teacher-student architecture and\nimplementation of our model, the empirical results obtained, and an analysis of\nthe role of language embeddings in terms of Information Gain.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.15508v1"
    },
    {
        "title": "A Contextual Online Learning Theory of Brokerage",
        "authors": [
            "François Bachoc",
            "Tommaso Cesari",
            "Roberto Colomboni"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We study the role of contextual information in the online learning problem of\nbrokerage between traders. At each round, two traders arrive with secret\nvaluations about an asset they wish to trade. The broker suggests a trading\nprice based on contextual data about the asset. Then, the traders decide to buy\nor sell depending on whether their valuations are higher or lower than the\nbrokerage price.\n  We assume the market value of traded assets is an unknown linear function of\na $d$-dimensional vector representing the contextual information available to\nthe broker. Additionally, we model traders' valuations as independent bounded\nzero-mean perturbations of the asset's market value, allowing for potentially\ndifferent unknown distributions across traders and time steps. Consistently\nwith the existing online learning literature, we evaluate the performance of a\nlearning algorithm with the regret with respect to the gain from trade. If the\nnoise distributions admit densities bounded by some constant $L$, then, for any\ntime horizon $T$:\n  - If the agents' valuations are revealed after each interaction, we provide\nan algorithm achieving $O ( L d \\ln T )$ regret, and show a corresponding\nmatching lower bound of $\\Omega( Ld \\ln T )$.\n  - If only their willingness to sell or buy at the proposed price is revealed\nafter each interaction, we provide an algorithm achieving $O(\\sqrt{LdT \\ln T\n})$ regret, and show that this rate is optimal (up to logarithmic factors), via\na lower bound of $\\Omega(\\sqrt{LdT})$.\n  To complete the picture, we show that if the bounded density assumption is\nlifted, then the problem becomes unlearnable, even with full feedback.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01566v1"
    },
    {
        "title": "Exploring Sectoral Profitability in the Indian Stock Market Using Deep\n  Learning",
        "authors": [
            "Jaydip Sen",
            "Hetvi Waghela",
            "Sneha Rakshit"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper explores using a deep learning Long Short-Term Memory (LSTM) model\nfor accurate stock price prediction and its implications for portfolio design.\nDespite the efficient market hypothesis suggesting that predicting stock prices\nis impossible, recent research has shown the potential of advanced algorithms\nand predictive models. The study builds upon existing literature on stock price\nprediction methods, emphasizing the shift toward machine learning and deep\nlearning approaches. Using historical stock prices of 180 stocks across 18\nsectors listed on the NSE, India, the LSTM model predicts future prices. These\npredictions guide buy/sell decisions for each stock and analyze sector\nprofitability. The study's main contributions are threefold: introducing an\noptimized LSTM model for robust portfolio design, utilizing LSTM predictions\nfor buy/sell transactions, and insights into sector profitability and\nvolatility. Results demonstrate the efficacy of the LSTM model in accurately\npredicting stock prices and informing investment decisions. By comparing sector\nprofitability and prediction accuracy, the work provides valuable insights into\nthe dynamics of the current financial markets in India.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01572v1"
    },
    {
        "title": "Reinforcement Learning Pair Trading: A Dynamic Scaling approach",
        "authors": [
            "Hongshen Yang",
            "Avinash Malik"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Cryptocurrency is a cryptography-based digital asset with extremely volatile\nprices. Around USD 70 billion worth of cryptocurrency is traded daily on\nexchanges. Trading cryptocurrency is difficult due to the inherent volatility\nof the crypto market. This study investigates whether Reinforcement Learning\n(RL) can enhance decision-making in cryptocurrency algorithmic trading compared\nto traditional methods. In order to address this question, we combined\nreinforcement learning with a statistical arbitrage trading technique, pair\ntrading, which exploits the price difference between statistically correlated\nassets. We constructed RL environments and trained RL agents to determine when\nand how to trade pairs of cryptocurrencies. We developed new reward shaping and\nobservation/action spaces for reinforcement learning. We performed experiments\nwith the developed reinforcement learner on pairs of BTC-GBP and BTC-EUR data\nseparated by 1 min intervals (n=263,520). The traditional non-RL pair trading\ntechnique achieved an annualized profit of 8.33%, while the proposed RL-based\npair trading technique achieved annualized profits from 9.94% to 31.53%,\ndepending upon the RL learner. Our results show that RL can significantly\noutperform manual and traditional pair trading techniques when applied to\nvolatile markets such as~cryptocurrencies.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16103v2"
    },
    {
        "title": "High order approximations and simulation schemes for the log-Heston\n  process",
        "authors": [
            "Aurélien Alfonsi",
            "Edoardo Lombardo"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We present weak approximations schemes of any order for the Heston model that\nare obtained by using the method developed by Alfonsi and Bally (2021). This\nmethod consists in combining approximation schemes calculated on different\nrandom grids to increase the order of convergence. We apply this method with\neither the Ninomiya-Victoir scheme (2008) or a second-order scheme that samples\nexactly the volatility component, and we show rigorously that we can achieve\nthen any order of convergence. We give numerical illustrations on financial\nexamples that validate the theoretical order of convergence. We also present\npromising numerical results for the multifactor/rough Heston model and hint at\napplications to other models, including the Bates model and the double Heston\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.17151v2"
    },
    {
        "title": "Fine-Tuning Large Language Models for Stock Return Prediction Using\n  Newsflow",
        "authors": [
            "Tian Guo",
            "Emmanuel Hauptmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Large language models (LLMs) and their fine-tuning techniques have\ndemonstrated superior performance in various language understanding and\ngeneration tasks. This paper explores fine-tuning LLMs for stock return\nforecasting with financial newsflow. In quantitative investing, return\nforecasting is fundamental for subsequent tasks like stock picking, portfolio\noptimization, etc. We formulate the model to include text representation and\nforecasting modules. We propose to compare the encoder-only and decoder-only\nLLMs, considering they generate text representations in distinct ways. The\nimpact of these different representations on forecasting performance remains an\nopen question. Meanwhile, we compare two simple methods of integrating LLMs'\ntoken-level representations into the forecasting module. The experiments on\nreal news and investment universes reveal that: (1) aggregated representations\nfrom LLMs' token-level embeddings generally produce return predictions that\nenhance the performance of long-only and long-short portfolios; (2) in the\nrelatively large investment universe, the decoder LLMs-based prediction model\nleads to stronger portfolios, whereas in the small universes, there are no\nconsistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama),\nMistral performs more robustly across different universes; (3) return\npredictions derived from LLMs' text representations are a strong signal for\nportfolio construction, outperforming conventional sentiment scores.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.18103v2"
    },
    {
        "title": "Enhancing Black-Scholes Delta Hedging via Deep Learning",
        "authors": [
            "Chunhui Qiao",
            "Xiangwei Wan"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper proposes a deep delta hedging framework for options, utilizing\nneural networks to learn the residuals between the hedging function and the\nimplied Black-Scholes delta. This approach leverages the smoother properties of\nthese residuals, enhancing deep learning performance. Utilizing ten years of\ndaily S&P 500 index option data, our empirical analysis demonstrates that\nlearning the residuals, using the mean squared one-step hedging error as the\nloss function, significantly improves hedging performance over directly\nlearning the hedging function, often by more than 100%. Adding input features\nwhen learning the residuals enhances hedging performance more for puts than\ncalls, with market sentiment being less crucial. Furthermore, learning the\nresiduals with three years of data matches the hedging performance of directly\nlearning with ten years of data, proving that our method demands less data.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19367v2"
    },
    {
        "title": "Neural Term Structure of Additive Process for Option Pricing",
        "authors": [
            "Jimin Lin",
            "Guixin Liu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The additive process generalizes the L\\'evy process by relaxing its\nassumption of time-homogeneous increments and hence covers a larger family of\nstochastic processes. Recent research in option pricing shows that modeling the\nunderlying log price with an additive process has advantages in easier\nconstruction of the risk-neural measure, an explicit option pricing formula and\ncharacteristic function, and more flexibility to fit the implied volatility\nsurface. Still, the challenge of calibrating an additive model arises from its\ntime-dependent parameterization, for which one has to prescribe parametric\nfunctions for the term structure. For this, we propose the neural term\nstructure model to utilize feedforward neural networks to represent the term\nstructure, which alleviates the difficulty of designing parametric functions\nand thus attenuates the misspecification risk. Numerical studies with S\\&P 500\noption data are conducted to evaluate the performance of the neural term\nstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01642v2"
    },
    {
        "title": "A Path Integral Approach for Time-Dependent Hamiltonians with\n  Applications to Derivatives Pricing",
        "authors": [
            "Mark Stedman",
            "Luca Capriotti"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We generalize a semi-classical path integral approach originally introduced\nby Giachetti and Tognetti [Phys. Rev. Lett. 55, 912 (1985)] and Feynman and\nKleinert [Phys. Rev. A 34, 5080 (1986)] to time-dependent Hamiltonians, thus\nextending the scope of the method to the pricing of financial derivatives. We\nillustrate the accuracy of the approach by presenting results for the\nwell-known, but analytically intractable, Black-Karasinski model for the\ndynamics of interest rates. The accuracy and computational efficiency of this\npath integral approach makes it a viable alternative to fully-numerical schemes\nfor a variety of applications in derivatives pricing.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.02064v1"
    },
    {
        "title": "Enhancing Startup Success Predictions in Venture Capital: A GraphRAG\n  Augmented Multivariate Time Series Method",
        "authors": [
            "Zitian Gao",
            "Yihao Xiao"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In the Venture Capital (VC) industry, predicting the success of startups is\nchallenging due to limited financial data and the need for subjective revenue\nforecasts. Previous methods based on time series analysis often fall short as\nthey fail to incorporate crucial inter-company relationships such as\ncompetition and collaboration. To fill the gap, this paper aims to introduce a\nnovel approach using GraphRAG augmented time series model. With GraphRAG, time\nseries predictive methods are enhanced by integrating these vital relationships\ninto the analysis framework, allowing for a more dynamic understanding of the\nstartup ecosystem in venture capital. Our experimental results demonstrate that\nour model significantly outperforms previous models in startup success\npredictions.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09420v4"
    },
    {
        "title": "A case study on different one-factor Cheyette models for short maturity\n  caplet calibration",
        "authors": [
            "Arun Kumar Polala",
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In [1], we calibrated a one-factor Cheyette SLV model with a local volatility\nthat is linear in the benchmark forward rate and an uncorrelated CIR stochastic\nvariance to 3M caplets of various maturities. While caplet smiles for many\nmaturities could be reasonably well calibrated across the range of strikes, for\ninstance the 1Y maturity could not be calibrated well across that entire range\nof strikes. Here, we study whether models with alternative local volatility\nterms and/or alternative stochastic volatility or variance models can calibrate\nthe 1Y caplet smile better across the strike range better than the model\nstudied in [1]. This is made possible and feasible by the generic simulation,\npricing, and calibration frameworks introduced in [1] and some new frameworks\npresented in this paper. We find that some model settings calibrate well to the\n1Y smile across the strike range under study. In particular, a model setting\nwith a local volatility that is piece-wise linear in the benchmark forward rate\ntogether with an uncorrelated CIR stochastic variance and one with a local\nvolatility that is linear in the benchmark rate together with a correlated\nlognormal stochastic volatility with quadratic drift (QDLNSV) as in [2]\ncalibrate well. We discuss why the later might be a preferable model.\n  [1] Arun Kumar Polala and Bernhard Hientzsch. Parametric differential machine\nlearning for pricing and calibration. arXiv preprint arXiv:2302.06682 , 2023.\n  [2] Artur Sepp and Parviz Rakhmonov. A Robust Stochastic Volatility Model for\nInterest Rate Dynamics. Risk Magazine, 2023\n",
        "pdf_link": "http://arxiv.org/pdf/2408.11257v1"
    },
    {
        "title": "EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large\n  Language Models and Deep Learning Methods",
        "authors": [
            "Hongcheng Ding",
            "Xuanze Zhao",
            "Zixiao Jiang",
            "Shamsul Nahar Abdullah",
            "Deshinta Arrova Dewi"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Accurate forecasting of the EUR/USD exchange rate is crucial for investors,\nbusinesses, and policymakers. This paper proposes a novel framework, IUS, that\nintegrates unstructured textual data from news and analysis with structured\ndata on exchange rates and financial indicators to enhance exchange rate\nprediction. The IUS framework employs large language models for sentiment\npolarity scoring and exchange rate movement classification of texts. These\ntextual features are combined with quantitative features and input into a\nCausality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then\nused to forecast the EUR/USD exchange rate. Experiments demonstrate that the\nproposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE\nby 9.56% compared to the best performing baseline. Results also show the\nbenefits of data fusion, with the combination of unstructured and structured\ndata yielding higher accuracy than structured data alone. Furthermore, feature\nselection using the top 12 important quantitative features combined with the\ntextual features proves most effective. The proposed IUS framework and\nOptuna-Bi-LSTM model provide a powerful new approach for exchange rate\nforecasting through multi-source data integration.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.13214v1"
    },
    {
        "title": "Evaluating Credit VIX (CDS IV) Prediction Methods with Incremental Batch\n  Learning",
        "authors": [
            "Robert Taylor"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper presents the experimental process and results of SVM, Gradient\nBoosting, and an Attention-GRU Hybrid model in predicting the Implied\nVolatility of rolled-over five-year spread contracts of credit default swaps\n(CDS) on European corporate debt during the quarter following mid-May '24, as\nrepresented by the iTraxx/Cboe Europe Main 1-Month Volatility Index (BP\nVolatility). The analysis employs a feature matrix inspired by Merton's\ndeterminants of default probability. Our comparative assessment aims to\nidentify strengths in SOTA and classical machine learning methods for financial\nrisk prediction\n",
        "pdf_link": "http://arxiv.org/pdf/2408.15404v1"
    },
    {
        "title": "Semi-analytical pricing of options written on SOFR futures",
        "authors": [
            "Andrey Itkin",
            "Yerkin Kitapbayev"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In this paper, we propose a semi-analytical approach to pricing options on\nSOFR futures where the underlying SOFR follows a time-dependent CEV model. By\ndefinition, these options change their type at the beginning of the reference\nperiod: before this time, this is an American option written on a SOFR forward\nprice as an underlying, and after this point, this is an arithmetic Asian\noption with an American style exercise written on the daily SOFR rates. We\ndevelop a new version of the GIT method and solve both problems\nsemi-analytically, obtaining the option price, the exercise boundary, and the\noption Greeks. This work is intended to address the concern that the transfer\nfrom LIBOR to SOFR has resulted in a situation in which the options of the key\nmoney market (i.e., futures on the reference rate) are options without any\npricing model available. Therefore, the trading in options on 3M SOFR futures\ncurrently ends before their reference quarter starts, to eliminate the final\nmetamorphosis into exotic options.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.04903v2"
    },
    {
        "title": "QuantFactor REINFORCE: Mining Steady Formulaic Alpha Factors with\n  Variance-bounded REINFORCE",
        "authors": [
            "Junjie Zhao",
            "Chengxi Zhang",
            "Min Qin",
            "Peng Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The goal of alpha factor mining is to discover indicative signals of\ninvestment opportunities from the historical financial market data of assets,\nwhich can be used to predict asset returns and gain excess profits. Recently, a\npromising framework is proposed for generating formulaic alpha factors using\ndeep reinforcement learning, and quickly gained research focuses from both\nacademia and industries. This paper first argues that the originally employed\npolicy training method, i.e., Proximal Policy Optimization (PPO), faces several\nimportant issues in the context of alpha factors mining, making it ineffective\nto explore the search space of the formula. Herein, a novel reinforcement\nlearning based on the well-known REINFORCE algorithm is proposed. Given that\nthe underlying state transition function adheres to the Dirac distribution, the\nMarkov Decision Process within this framework exhibit minimal environmental\nvariability, making REINFORCE algorithm more appropriate than PPO. A new\ndedicated baseline is designed to theoretically reduce the commonly suffered\nhigh variance of REINFORCE. Moreover, the information ratio is introduced as a\nreward shaping mechanism to encourage the generation of steady alpha factors\nthat can better adapt to changes in market volatility. Experimental evaluations\non various real assets data show that the proposed algorithm can increase the\ncorrelation with asset returns by 3.83\\%, and a stronger ability to obtain\nexcess returns compared to the latest alpha factors mining methods, which meets\nthe theoretical results well.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05144v2"
    },
    {
        "title": "MLP, XGBoost, KAN, TDNN, and LSTM-GRU Hybrid RNN with Attention for SPX\n  and NDX European Call Option Pricing",
        "authors": [
            "Boris Ter-Avanesov",
            "Homayoon Beigi"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We explore the performance of various artificial neural network\narchitectures, including a multilayer perceptron (MLP), Kolmogorov-Arnold\nnetwork (KAN), LSTM-GRU hybrid recursive neural network (RNN) models, and a\ntime-delay neural network (TDNN) for pricing European call options. In this\nstudy, we attempt to leverage the ability of supervised learning methods, such\nas ANNs, KANs, and gradient-boosted decision trees, to approximate complex\nmultivariate functions in order to calibrate option prices based on past market\ndata. The motivation for using ANNs and KANs is the Universal Approximation\nTheorem and Kolmogorov-Arnold Representation Theorem, respectively.\nSpecifically, we use S\\&P 500 (SPX) and NASDAQ 100 (NDX) index options traded\nduring 2015-2023 with times to maturity ranging from 15 days to over 4 years\n(OptionMetrics IvyDB US dataset). Black \\& Scholes's (BS) PDE \\cite{Black1973}\nmodel's performance in pricing the same options compared to real data is used\nas a benchmark. This model relies on strong assumptions, and it has been\nobserved and discussed in the literature that real data does not match its\npredictions. Supervised learning methods are widely used as an alternative for\ncalibrating option prices due to some of the limitations of this model. In our\nexperiments, the BS model underperforms compared to all of the others. Also,\nthe best TDNN model outperforms the best MLP model on all error metrics. We\nimplement a simple self-attention mechanism to enhance the RNN models,\nsignificantly improving their performance. The best-performing model overall is\nthe LSTM-GRU hybrid RNN model with attention. Also, the KAN model outperforms\nthe TDNN and MLP models. We analyze the performance of all models by ticker,\nmoneyness category, and over/under/correctly-priced percentage.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06724v3"
    },
    {
        "title": "American option pricing using generalised stochastic hybrid systems",
        "authors": [
            "Evelyn Buckwar",
            "Sascha Desmettre",
            "Agnes Mallinger",
            "Amira Meddah"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper presents a novel approach to pricing American options using\npiecewise diffusion Markov processes (PDifMPs), a type of generalised\nstochastic hybrid system that integrates continuous dynamics with discrete jump\nprocesses. Standard models often rely on constant drift and volatility\nassumptions, which limits their ability to accurately capture the complex and\nerratic nature of financial markets. By incorporating PDifMPs, our method\naccounts for sudden market fluctuations, providing a more realistic model of\nasset price dynamics. We benchmark our approach with the Longstaff-Schwartz\nalgorithm, both in its original form and modified to include PDifMP asset price\ntrajectories. Numerical simulations demonstrate that our PDifMP-based method\nnot only provides a more accurate reflection of market behaviour but also\noffers practical advantages in terms of computational efficiency. The results\nsuggest that PDifMPs can significantly improve the predictive accuracy of\nAmerican options pricing by more closely aligning with the stochastic\nvolatility and jumps observed in real financial markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.07477v1"
    },
    {
        "title": "A Multi-agent Market Model Can Explain the Impact of AI Traders in\n  Financial Markets -- A New Microfoundations of GARCH model",
        "authors": [
            "Kei Nakagawa",
            "Masanori Hirano",
            "Kentaro Minami",
            "Takanobu Mizuta"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The AI traders in financial markets have sparked significant interest in\ntheir effects on price formation mechanisms and market volatility, raising\nimportant questions for market stability and regulation. Despite this interest,\na comprehensive model to quantitatively assess the specific impacts of AI\ntraders remains undeveloped. This study aims to address this gap by modeling\nthe influence of AI traders on market price formation and volatility within a\nmulti-agent framework, leveraging the concept of microfoundations.\nMicrofoundations involve understanding macroeconomic phenomena, such as market\nprice formation, through the decision-making and interactions of individual\neconomic agents. While widely acknowledged in macroeconomics, microfoundational\napproaches remain unexplored in empirical finance, particularly for models like\nthe GARCH model, which captures key financial statistical properties such as\nvolatility clustering and fat tails. This study proposes a multi-agent market\nmodel to derive the microfoundations of the GARCH model, incorporating three\ntypes of agents: noise traders, fundamental traders, and AI traders. By\nmathematically aggregating the micro-structure of these agents, we establish\nthe microfoundations of the GARCH model. We validate this model through\nmulti-agent simulations, confirming its ability to reproduce the stylized facts\nof financial markets. Finally, we analyze the impact of AI traders using\nparameters derived from these microfoundations, contributing to a deeper\nunderstanding of their role in market dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12516v1"
    },
    {
        "title": "KANOP: A Data-Efficient Option Pricing Model using Kolmogorov-Arnold\n  Networks",
        "authors": [
            "Rushikesh Handal",
            "Kazuki Matoya",
            "Yunzhuo Wang",
            "Masanori Hirano"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Inspired by the recently proposed Kolmogorov-Arnold Networks (KANs), we\nintroduce the KAN-based Option Pricing (KANOP) model to value American-style\noptions, building on the conventional Least Square Monte Carlo (LSMC)\nalgorithm. KANs, which are based on Kolmogorov-Arnold representation theorem,\noffer a data-efficient alternative to traditional Multi-Layer Perceptrons,\nrequiring fewer hidden layers to achieve a higher level of performance. By\nleveraging the flexibility of KANs, KANOP provides a learnable alternative to\nthe conventional set of basis functions used in the LSMC model, allowing the\nmodel to adapt to the pricing task and effectively estimate the expected\ncontinuation value. Using examples of standard American and Asian-American\noptions, we demonstrate that KANOP produces more reliable option value\nestimates, both for single-dimensional cases and in more complex scenarios\ninvolving multiple input variables. The delta estimated by the KANOP model is\nalso more accurate than that obtained using conventional basis functions, which\nis crucial for effective option hedging. Graphical illustrations further\nvalidate KANOP's ability to accurately model the expected continuation value\nfor American-style options.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.00419v1"
    },
    {
        "title": "Harnessing Generative AI for Economic Insights",
        "authors": [
            "Manish Jha",
            "Jialin Qian",
            "Michael Weber",
            "Baozhong Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We use generative AI to extract managerial expectations about their economic\noutlook from over 120,000 corporate conference call transcripts. The overall\nmeasure, AI Economy Score, robustly predicts future economic indicators such as\nGDP growth, production, and employment, both in the short term and to 10\nquarters. This predictive power is incremental to that of existing measures,\nincluding survey forecasts. Moreover, industry and firm-level measures provide\nvaluable information about sector-specific and individual firm activities. Our\nfindings suggest that managerial expectations carry unique insights about\neconomic activities, with implications for both macroeconomic and microeconomic\ndecision-making.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.03897v2"
    },
    {
        "title": "Deep Learning Methods for S Shaped Utility Maximisation with a Random\n  Reference Point",
        "authors": [
            "Ashley Davey",
            "Harry Zheng"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We consider the portfolio optimisation problem where the terminal function is\nan S-shaped utility applied at the difference between the wealth and a random\nbenchmark process. We develop several numerical methods for solving the problem\nusing deep learning and duality methods. We use deep learning methods to solve\nthe associated Hamilton-Jacobi-Bellman equation for both the primal and dual\nproblems, and the adjoint equation arising from the stochastic maximum\nprinciple. We compare the solution of this non-concave problem to that of\nconcavified utility, a random function depending on the benchmark, in both\ncomplete and incomplete markets. We give some numerical results for power and\nlog utilities to show the accuracy of the suggested algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.05524v1"
    },
    {
        "title": "Computing Systemic Risk Measures with Graph Neural Networks",
        "authors": [
            "Lukas Gonon",
            "Thilo Meyer-Brandis",
            "Niklas Weber"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper investigates systemic risk measures for stochastic financial\nnetworks of explicitly modelled bilateral liabilities. We extend the notion of\nsystemic risk measures from Biagini, Fouque, Fritelli and Meyer-Brandis (2019)\nto graph structured data. In particular, we focus on an aggregation function\nthat is derived from a market clearing algorithm proposed by Eisenberg and Noe\n(2001). In this setting, we show the existence of an optimal random allocation\nthat distributes the overall minimal bailout capital and secures the network.\nWe study numerical methods for the approximation of systemic risk and optimal\nrandom allocations. We propose to use permutation equivariant architectures of\nneural networks like graph neural networks (GNNs) and a class that we name\n(extended) permutation equivariant neural networks ((X)PENNs). We compare their\nperformance to several benchmark allocations. The main feature of GNNs and\n(X)PENNs is that they are permutation equivariant with respect to the\nunderlying graph data. In numerical experiments we find evidence that these\npermutation equivariant methods are superior to other approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.07222v1"
    },
    {
        "title": "A Dynamic Approach to Stock Price Prediction: Comparing RNN and Mixture\n  of Experts Models Across Different Volatility Profiles",
        "authors": [
            "Diego Vallarino"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This study evaluates the effectiveness of a Mixture of Experts (MoE) model\nfor stock price prediction by comparing it to a Recurrent Neural Network (RNN)\nand a linear regression model. The MoE framework combines an RNN for volatile\nstocks and a linear model for stable stocks, dynamically adjusting the weight\nof each model through a gating network. Results indicate that the MoE approach\nsignificantly improves predictive accuracy across different volatility\nprofiles. The RNN effectively captures non-linear patterns for volatile\ncompanies but tends to overfit stable data, whereas the linear model performs\nwell for predictable trends. The MoE model's adaptability allows it to\noutperform each individual model, reducing errors such as Mean Squared Error\n(MSE) and Mean Absolute Error (MAE). Future work should focus on enhancing the\ngating mechanism and validating the model with real-world datasets to optimize\nits practical applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.07234v1"
    },
    {
        "title": "UCFE: A User-Centric Financial Expertise Benchmark for Large Language\n  Models",
        "authors": [
            "Yuzhe Yang",
            "Yifei Zhang",
            "Yan Hu",
            "Yilin Guo",
            "Ruoli Gan",
            "Yueru He",
            "Mingcong Lei",
            "Xiao Zhang",
            "Haining Wang",
            "Qianqian Xie",
            "Jimin Huang",
            "Honghai Yu",
            "Benyou Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper introduces the UCFE: User-Centric Financial Expertise benchmark,\nan innovative framework designed to evaluate the ability of large language\nmodels (LLMs) to handle complex real-world financial tasks. UCFE benchmark\nadopts a hybrid approach that combines human expert evaluations with dynamic,\ntask-specific interactions to simulate the complexities of evolving financial\nscenarios. Firstly, we conducted a user study involving 804 participants,\ncollecting their feedback on financial tasks. Secondly, based on this feedback,\nwe created our dataset that encompasses a wide range of user intents and\ninteractions. This dataset serves as the foundation for benchmarking 12 LLM\nservices using the LLM-as-Judge methodology. Our results show a significant\nalignment between benchmark scores and human preferences, with a Pearson\ncorrelation coefficient of 0.78, confirming the effectiveness of the UCFE\ndataset and our evaluation approach. UCFE benchmark not only reveals the\npotential of LLMs in the financial sector but also provides a robust framework\nfor assessing their performance and user satisfaction. The benchmark dataset\nand evaluation code are available.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.14059v2"
    },
    {
        "title": "Blending Ensemble for Classification with Genetic-algorithm generated\n  Alpha factors and Sentiments (GAS)",
        "authors": [
            "Quechen Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  With the increasing maturity and expansion of the cryptocurrency market,\nunderstanding and predicting its price fluctuations has become an important\nissue in the field of financial engineering. This article introduces an\ninnovative Genetic Algorithm-generated Alpha Sentiment (GAS) blending ensemble\nmodel specifically designed to predict Bitcoin market trends. The model\nintegrates advanced ensemble learning methods, feature selection algorithms,\nand in-depth sentiment analysis to effectively capture the complexity and\nvariability of daily Bitcoin trading data. The GAS framework combines 34 Alpha\nfactors with 8 news economic sentiment factors to provide deep insights into\nBitcoin price fluctuations by accurately analyzing market sentiment and\ntechnical indicators. The core of this study is using a stacked model\n(including LightGBM, XGBoost, and Random Forest Classifier) for trend\nprediction which demonstrates excellent performance in traditional buy-and-hold\nstrategies. In addition, this article also explores the effectiveness of using\ngenetic algorithms to automate alpha factor construction as well as enhancing\npredictive models through sentiment analysis. Experimental results show that\nthe GAS model performs competitively in daily Bitcoin trend prediction\nespecially when analyzing highly volatile financial assets with rich data.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03035v1"
    },
    {
        "title": "Enforcing asymptotic behavior with DNNs for approximation and regression\n  in finance",
        "authors": [
            "Hardik Routray",
            "Bernhard Hientzsch"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We propose a simple methodology to approximate functions with given\nasymptotic behavior by specifically constructed terms and an unconstrained deep\nneural network (DNN).\n  The methodology we describe extends to various asymptotic behaviors and\nmultiple dimensions and is easy to implement. In this work we demonstrate it\nfor linear asymptotic behavior in one-dimensional examples. We apply it to\nfunction approximation and regression problems where we measure approximation\nof only function values (``Vanilla Machine Learning''-VML) or also\napproximation of function and derivative values (``Differential Machine\nLearning''-DML) on several examples. We see that enforcing given asymptotic\nbehavior leads to better approximation and faster convergence.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05257v1"
    },
    {
        "title": "Hybrid Vector Auto Regression and Neural Network Model for Order Flow\n  Imbalance Prediction in High Frequency Trading",
        "authors": [
            "Abdul Rahman",
            "Neelesh Upadhye"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In high frequency trading, accurate prediction of Order Flow Imbalance (OFI)\nis crucial for understanding market dynamics and maintaining liquidity. This\npaper introduces a hybrid predictive model that combines Vector Auto Regression\n(VAR) with a simple feedforward neural network (FNN) to forecast OFI and assess\ntrading intensity. The VAR component captures linear dependencies, while\nresiduals are fed into the FNN to model non-linear patterns, enabling a\ncomprehensive approach to OFI prediction. Additionally, the model calculates\nthe intensity on the Buy or Sell side, providing insights into which side holds\ngreater trading pressure. These insights facilitate the development of trading\nstrategies by identifying periods of high buy or sell intensity. Using both\nsynthetic and real trading data from Binance, we demonstrate that the hybrid\nmodel offers significant improvements in predictive accuracy and enhances\nstrategic decision-making based on OFI dynamics. Furthermore, we compare the\nhybrid models performance with standalone FNN and VAR models, showing that the\nhybrid approach achieves superior forecasting accuracy across both synthetic\nand real datasets, making it the most effective model for OFI prediction in\nhigh frequency trading.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08382v1"
    },
    {
        "title": "FinRobot: AI Agent for Equity Research and Valuation with Large Language\n  Models",
        "authors": [
            "Tianyu Zhou",
            "Pinqiao Wang",
            "Yilin Wu",
            "Hongyang Yang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  As financial markets grow increasingly complex, there is a rising need for\nautomated tools that can effectively assist human analysts in equity research,\nparticularly within sell-side research. While Generative AI (GenAI) has\nattracted significant attention in this field, existing AI solutions often fall\nshort due to their narrow focus on technical factors and limited capacity for\ndiscretionary judgment. These limitations hinder their ability to adapt to new\ndata in real-time and accurately assess risks, which diminishes their practical\nvalue for investors.\n  This paper presents FinRobot, the first AI agent framework specifically\ndesigned for equity research. FinRobot employs a multi-agent Chain of Thought\n(CoT) system, integrating both quantitative and qualitative analyses to emulate\nthe comprehensive reasoning of a human analyst. The system is structured around\nthree specialized agents: the Data-CoT Agent, which aggregates diverse data\nsources for robust financial integration; the Concept-CoT Agent, which mimics\nan analysts reasoning to generate actionable insights; and the Thesis-CoT\nAgent, which synthesizes these insights into a coherent investment thesis and\nreport. FinRobot provides thorough company analysis supported by precise\nnumerical data, industry-appropriate valuation metrics, and realistic risk\nassessments. Its dynamically updatable data pipeline ensures that research\nremains timely and relevant, adapting seamlessly to new financial information.\nUnlike existing automated research tools, such as CapitalCube and Wright\nReports, FinRobot delivers insights comparable to those produced by major\nbrokerage firms and fundamental research vendors. We open-source FinRobot at\n\\url{https://github. com/AI4Finance-Foundation/FinRobot}.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08804v1"
    },
    {
        "title": "A Review of Reinforcement Learning in Financial Applications",
        "authors": [
            "Yahui Bai",
            "Yuhe Gao",
            "Runzhe Wan",
            "Sheng Zhang",
            "Rui Song"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In recent years, there has been a growing trend of applying Reinforcement\nLearning (RL) in financial applications.\n  This approach has shown great potential to solve decision-making tasks in\nfinance.\n  In this survey, we present a comprehensive study of the applications of RL in\nfinance and conduct a series of meta-analyses to investigate the common themes\nin the literature, such as the factors that most significantly affect RL's\nperformance compared to traditional methods.\n  Moreover, we identify challenges including explainability, Markov Decision\nProcess (MDP) modeling, and robustness that hinder the broader utilization of\nRL in the financial industry and discuss recent advancements in overcoming\nthese challenges.\n  Finally, we propose future research directions, such as benchmarking,\ncontextual RL, multi-agent RL, and model-based RL to address these challenges\nand to further enhance the implementation of RL in finance.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.12746v1"
    },
    {
        "title": "Finding the nonnegative minimal solutions of Cauchy PDEs in a\n  volatility-stabilized market",
        "authors": [
            "Nicole Tianjiao Yang",
            "Tomoyuki Ichiba"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The strong relative arbitrage problem in Stochastic Portfolio Theory seeks to\ngenerate an investment strategy that almost surely outperforms a benchmark\nportfolio at the end of a given time horizon. The highest relative return in\nrelative arbitrage opportunities is characterized by the smallest nonnegative\ncontinuous solution of a Cauchy problem for a partial differential equation\n(PDE). However, solving this type of PDE poses analytical and numerical\nchallenges, due to the high dimensionality and its non-unique solutions. In\nthis paper, we discuss numerical methods to address the relative arbitrage\nproblem and the associated PDE in a volatility-stabilized market, using\ntime-changed Bessel bridges. We present a practical algorithm and demonstrate\nnumerical results through an example in volatility-stabilized markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13558v2"
    },
    {
        "title": "Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
        "authors": [
            "Andrew Lesniewski",
            "Giulio Trigila"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.00036v2"
    },
    {
        "title": "A Consolidated Volatility Prediction with Back Propagation Neural\n  Network and Genetic Algorithm",
        "authors": [
            "Zong Ke",
            "Jingyu Xu",
            "Zizhou Zhang",
            "Yu Cheng",
            "Wenjun Wu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper provides a unique approach with AI algorithms to predict emerging\nstock markets volatility. Traditionally, stock volatility is derived from\nhistorical volatility,Monte Carlo simulation and implied volatility as well. In\nthis paper, the writer designs a consolidated model with back-propagation\nneural network and genetic algorithm to predict future volatility of emerging\nstock markets and found that the results are quite accurate with low errors.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.07223v3"
    },
    {
        "title": "Isogeometric Analysis for the Pricing of Financial Derivatives with\n  Nonlinear Models: Convertible Bonds and Options",
        "authors": [
            "Rakhymzhan Kazbek",
            "Yogi Erlangga",
            "Yerlan Amanbek",
            "Dongming Wei"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Computational efficiency is essential for enhancing the accuracy and\npracticality of pricing complex financial derivatives. In this paper, we\ndiscuss Isogeometric Analysis (IGA) for valuing financial derivatives, modeled\nby two nonlinear Black-Scholes PDEs: the Leland model for European call with\ntransaction costs and the AFV model for convertible bonds with default options.\nWe compare the solutions of IGA with finite difference methods (FDM) and finite\nelement methods (FEM). In particular, very accurate solutions can be\nnumerically calculated on far less mesh (knots) than FDM or FEM, by using\nnon-uniform knots and weighted cubic NURBS, which in turn reduces the\ncomputational time significantly.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.08987v1"
    },
    {
        "title": "Geometric Deep Learning for Realized Covariance Matrix Forecasting",
        "authors": [
            "Andrea Bucci",
            "Michele Palma",
            "Chao Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Traditional methods employed in matrix volatility forecasting often overlook\nthe inherent Riemannian manifold structure of symmetric positive definite\nmatrices, treating them as elements of Euclidean space, which can lead to\nsuboptimal predictive performance. Moreover, they often struggle to handle\nhigh-dimensional matrices. In this paper, we propose a novel approach for\nforecasting realized covariance matrices of asset returns using a\nRiemannian-geometry-aware deep learning framework. In this way, we account for\nthe geometric properties of the covariance matrices, including possible\nnon-linear dynamics and efficient handling of high-dimensionality. Moreover,\nbuilding upon a Fr\\'echet sample mean of realized covariance matrices, we are\nable to extend the HAR model to the matrix-variate. We demonstrate the efficacy\nof our approach using daily realized covariance matrices for the 50 most\ncapitalized companies in the S&P 500 index, showing that our method outperforms\ntraditional approaches in terms of predictive accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.09517v1"
    },
    {
        "title": "Reciprocity in Interbank Markets",
        "authors": [
            "Lutz Honvehlmann"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Weighted reciprocity between two agents can be defined as the minimum of\nsending and receiving value in their bilateral relationship. In financial\nnetworks, such reciprocity characterizes the importance of individual banks as\nboth liquidity absorber and provider, a feature typically attributed to large,\nintermediating dealer banks. In this paper we develop an exponential random\ngraph model that can account for reciprocal links of each node simultaneously\non the topological as well as on the weighted level. We provide an exact\nexpression for the normalizing constant and thus a closed-form solution for the\ngraph probability distribution. Applying this statistical null model to Italian\ninterbank data, we find that before the great financial crisis (i) banks\ndisplayed significantly more weighted reciprocity compared to what the\nlower-order network features (size and volume distributions) would predict (ii)\nwith a disappearance of this deviation once the early periods of the crisis set\nin, (iii) a trend which can be attributed in particular to smaller banks\n(dis)engaging in bilateral high-value trading relationships. Moreover, we show\nthat neglecting reciprocal links and weights can lead to spurious findings of\ntriadic relationships. As the hierarchical structure in the network is found to\nbe compatible with its transitive but not with its intransitive triadic\nsub-graphs, the interbank market seems to be well-characterized by a\nhierarchical core-periphery structure enhanced by non-hierarchical reciprocal\ntrading relationships.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10329v1"
    },
    {
        "title": "Model of an Open, Decentralized Computational Network with\n  Incentive-Based Load Balancing",
        "authors": [
            "German Rodikov"
        ],
        "category": "q-fin.CP",
        "published_year": "2025",
        "summary": "  This paper proposes a model that enables permissionless and decentralized\nnetworks for complex computations. We explore the integration and optimize load\nbalancing in an open, decentralized computational network. Our model leverages\neconomic incentives and reputation-based mechanisms to dynamically allocate\ntasks between operators and coprocessors. This approach eliminates the need for\nspecialized hardware or software, thereby reducing operational costs and\ncomplexities. We present a mathematical model that enhances restaking processes\nin blockchain systems by enabling operators to delegate complex tasks to\ncoprocessors. The model's effectiveness is demonstrated through experimental\nsimulations, showcasing its ability to optimize reward distribution, enhance\nsecurity, and improve operational efficiency.\n  Our approach facilitates a more flexible and scalable network through the use\nof economic commitments, adaptable dynamic rating models, and a coprocessor\nload incentivization system. Supported by experimental simulations, the model\ndemonstrates its capability to optimize resource allocation, enhance system\nresilience, and reduce operational risks. This ensures significant improvements\nin both security and cost-efficiency for the blockchain ecosystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.01219v1"
    },
    {
        "title": "High-frequency lead-lag relationships in the Chinese stock index futures\n  market: tick-by-tick dynamics of calendar spreads",
        "authors": [
            "Guanlin Li",
            "Xiyan Chen",
            "Yingzheng Liu"
        ],
        "category": "q-fin.CP",
        "published_year": "2025",
        "summary": "  Lead-lag relationships, integral to market dynamics, offer valuable insights\ninto the trading behavior of high-frequency traders (HFTs) and the flow of\ninformation at a granular level. This paper investigates the lead-lag\nrelationships between stock index futures contracts of different maturities in\nthe Chinese financial futures market (CFFEX). Using high-frequency\n(tick-by-tick) data, we analyze how price movements in near-month futures\ncontracts influence those in longer-dated contracts, such as next-month,\nquarterly, and semi-annual contracts. Our findings reveal a consistent pattern\nof price discovery, with the near-month contract leading the others by one\ntick, driven primarily by liquidity. Additionally, we identify a negative\nfeedback effect of the \"lead-lag spread\" on the leading asset, which can\npredict returns of leading asset. Backtesting results demonstrate the\nprofitability of trading based on the lead-lag spread signal, even after\naccounting for transaction costs. Altogether, our analysis offers valuable\ninsights to understand and capitalize on the evolving dynamics of futures\nmarkets.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.03171v1"
    },
    {
        "title": "Quantile Mechanics II: Changes of Variables in Monte Carlo methods and\n  GPU-Optimized Normal Quantiles",
        "authors": [
            "William T. Shaw",
            "Thomas Luu",
            "Nick Brickman"
        ],
        "category": "q-fin.CP",
        "published_year": "2009",
        "summary": "  This article presents differential equations and solution methods for the\nfunctions of the form $Q(x) = F^{-1}(G(x))$, where $F$ and $G$ are cumulative\ndistribution functions. Such functions allow the direct recycling of Monte\nCarlo samples from one distribution into samples from another. The method may\nbe developed analytically for certain special cases, and illuminate the idea\nthat it is a more precise form of the traditional Cornish-Fisher expansion. In\nthis manner the model risk of distributional risk may be assessed free of the\nMonte Carlo noise associated with resampling. Examples are given of equations\nfor converting normal samples to Student t, and converting exponential to\nhyperbolic, variance gamma and normal. In the case of the normal distribution,\nthe change of variables employed allows the sampling to take place to good\naccuracy based on a single rational approximation over a very wide range of the\nsample space. The avoidance of any branching statement is of use in optimal GPU\ncomputations as it avoids the effect of {\\it warp divergence}, and we give\nexamples of branch-free normal quantiles that offer performance improvements in\na GPU environment, while retaining the best precision characteristics of\nwell-known methods. We also offer models based on a low-probability of warp\ndivergence. Comparisons of new and old forms are made on the Nvidia Quadro\n4000, GTX 285 and 480, and Tesla C2050 GPUs. We argue that in single-precision\nmode, the change-of-variables approach offers performance competitive with the\nfastest existing scheme while substantially improving precision, and that in\ndouble-precision mode, this approach offers the most GPU-optimal Gaussian\nquantile yet, and without compromise on precision for Monte Carlo applications,\nworking twice as fast as the CUDA 4 library function with increased precision.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.0638v5"
    },
    {
        "title": "Model Selection and Adaptive Markov chain Monte Carlo for Bayesian\n  Cointegrated VAR model",
        "authors": [
            "Gareth W. Peters",
            "Balakrishnan Kannan",
            "Ben Lasscock",
            "Chris Mellen"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  This paper develops a matrix-variate adaptive Markov chain Monte Carlo (MCMC)\nmethodology for Bayesian Cointegrated Vector Auto Regressions (CVAR). We\nreplace the popular approach to sampling Bayesian CVAR models, involving griddy\nGibbs, with an automated efficient alternative, based on the Adaptive\nMetropolis algorithm of Roberts and Rosenthal, (2009). Developing the adaptive\nMCMC framework for Bayesian CVAR models allows for efficient estimation of\nposterior parameters in significantly higher dimensional CVAR series than\npreviously possible with existing griddy Gibbs samplers. For a n-dimensional\nCVAR series, the matrix-variate posterior is in dimension $3n^2 + n$, with\nsignificant correlation present between the blocks of matrix random variables.\nWe also treat the rank of the CVAR model as a random variable and perform joint\ninference on the rank and model parameters. This is achieved with a Bayesian\nposterior distribution defined over both the rank and the CVAR model\nparameters, and inference is made via Bayes Factor analysis of rank.\nPractically the adaptive sampler also aids in the development of automated\nBayesian cointegration models for algorithmic trading systems considering\ninstruments made up of several assets, such as currency baskets. Previously the\nliterature on financial applications of CVAR trading models typically only\nconsiders pairs trading (n=2) due to the computational cost of the griddy\nGibbs. We are able to extend under our adaptive framework to $n >> 2$ and\ndemonstrate an example with n = 10, resulting in a posterior distribution with\nparameters up to dimension 310. By also considering the rank as a random\nquantity we can ensure our resulting trading models are able to adjust to\npotentially time varying market conditions in a coherent statistical framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3830v1"
    },
    {
        "title": "Outperforming the market portfolio with a given probability",
        "authors": [
            "Erhan Bayraktar",
            "Yu-Jui Huang",
            "Qingshuo Song"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Our goal is to resolve a problem proposed by Fernholz and Karatzas [On\noptimal arbitrage (2008) Columbia Univ.]: to characterize the minimum amount of\ninitial capital with which an investor can beat the market portfolio with a\ncertain probability, as a function of the market configuration and time to\nmaturity. We show that this value function is the smallest nonnegative\nviscosity supersolution of a nonlinear PDE. As in Fernholz and Karatzas [On\noptimal arbitrage (2008) Columbia Univ.], we do not assume the existence of an\nequivalent local martingale measure, but merely the existence of a local\nmartingale deflator.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.3224v6"
    },
    {
        "title": "Calculation of aggregate loss distributions",
        "authors": [
            "Pavel V. Shevchenko"
        ],
        "category": "q-fin.CP",
        "published_year": "2010",
        "summary": "  Estimation of the operational risk capital under the Loss Distribution\nApproach requires evaluation of aggregate (compound) loss distributions which\nis one of the classic problems in risk theory. Closed-form solutions are not\navailable for the distributions typically used in operational risk. However\nwith modern computer processing power, these distributions can be calculated\nvirtually exactly using numerical methods. This paper reviews numerical\nalgorithms that can be successfully used to calculate the aggregate loss\ndistributions. In particular Monte Carlo, Panjer recursion and Fourier\ntransformation methods are presented and compared. Also, several closed-form\napproximations based on moment matching and asymptotic result for heavy-tailed\ndistributions are reviewed.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.1108v1"
    },
    {
        "title": "Information Percolation: Some General Cases with an Application to\n  Econophysics",
        "authors": [
            "Alain Bélanger",
            "Gaston Giroux"
        ],
        "category": "q-fin.CP",
        "published_year": "2012",
        "summary": "  We describe, at the microscopic level, the dynamics of N interacting\ncomponents where the probability is very small when N is large that a given\ncomponent interact more than once, directly or indirectly, up to time t, with\nany other component. Due to this fact, we can consider, at the macroscopic\nlevel, the quadratic system of differential equations associated with the\ninteraction and establish an explicit formula for the solution of this system.\nWe moreover apply our results to some models of Econophysics.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.5251v1"
    },
    {
        "title": "Detect & Describe: Deep learning of bank stress in the news",
        "authors": [
            "Samuel Rönnqvist",
            "Peter Sarlin"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  News is a pertinent source of information on financial risks and stress\nfactors, which nevertheless is challenging to harness due to the sparse and\nunstructured nature of natural text. We propose an approach based on\ndistributional semantics and deep learning with neural networks to model and\nlink text to a scarce set of bank distress events. Through unsupervised\ntraining, we learn semantic vector representations of news articles as\npredictors of distress events. The predictive model that we learn can signal\ncoinciding stress with an aggregated index at bank or European level, while\ncrucially allowing for automatic extraction of text descriptions of the events,\nbased on passages with high stress levels. The method offers insight that\nmodels based on other types of data cannot provide, while offering a general\nmeans for interpreting this type of semantic-predictive model. We model bank\ndistress with data on 243 events and 6.6M news articles for 101 large European\nbanks.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.07870v1"
    },
    {
        "title": "Solving the Optimal Trading Trajectory Problem Using a Quantum Annealer",
        "authors": [
            "Gili Rosenberg",
            "Poya Haghnegahdar",
            "Phil Goddard",
            "Peter Carr",
            "Kesheng Wu",
            "Marcos López de Prado"
        ],
        "category": "q-fin.CP",
        "published_year": "2015",
        "summary": "  We solve a multi-period portfolio optimization problem using D-Wave Systems'\nquantum annealer. We derive a formulation of the problem, discuss several\npossible integer encoding schemes, and present numerical examples that show\nhigh success rates. The formulation incorporates transaction costs (including\npermanent and temporary market impact), and, significantly, the solution does\nnot require the inversion of a covariance matrix. The discrete multi-period\nportfolio optimization problem we solve is significantly harder than the\ncontinuous variable problem. We present insight into how results may be\nimproved using suitable software enhancements, and why current quantum\nannealing technology limits the size of problem that can be successfully solved\ntoday. The formulation presented is specifically designed to be scalable, with\nthe expectation that as quantum annealing technology improves, larger problems\nwill be solvable using the same techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.06182v3"
    },
    {
        "title": "Inverse Reinforcement Learning for Marketing",
        "authors": [
            "Igor Halperin"
        ],
        "category": "q-fin.CP",
        "published_year": "2017",
        "summary": "  Learning customer preferences from an observed behaviour is an important\ntopic in the marketing literature. Structural models typically model\nforward-looking customers or firms as utility-maximizing agents whose utility\nis estimated using methods of Stochastic Optimal Control. We suggest an\nalternative approach to study dynamic consumer demand, based on Inverse\nReinforcement Learning (IRL). We develop a version of the Maximum Entropy IRL\nthat leads to a highly tractable model formulation that amounts to\nlow-dimensional convex optimization in the search for optimal model parameters.\nUsing simulations of consumer demand, we show that observational noise for\nidentical customers can be easily confused with an apparent consumer\nheterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04612v1"
    },
    {
        "title": "Deep Hedging",
        "authors": [
            "Hans Bühler",
            "Lukas Gonon",
            "Josef Teichmann",
            "Ben Wood"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We present a framework for hedging a portfolio of derivatives in the presence\nof market frictions such as transaction costs, market impact, liquidity\nconstraints or risk limits using modern deep reinforcement machine learning\nmethods.\n  We discuss how standard reinforcement learning methods can be applied to\nnon-linear reward structures, i.e. in our case convex risk measures. As a\ngeneral contribution to the use of deep learning for stochastic processes, we\nalso show that the set of constrained trading strategies used by our algorithm\nis large enough to $\\epsilon$-approximate any optimal solution.\n  Our algorithm can be implemented efficiently even in high-dimensional\nsituations using modern machine learning tools. Its structure does not depend\non specific market dynamics, and generalizes across hedging instruments\nincluding the use of liquid derivatives. Its computational performance is\nlargely invariant in the size of the portfolio as it depends mainly on the\nnumber of hedging instruments available.\n  We illustrate our approach by showing the effect on hedging under transaction\ncosts in a synthetic market driven by the Heston model, where we outperform the\nstandard \"complete market\" solution.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03042v1"
    },
    {
        "title": "Market Self-Learning of Signals, Impact and Optimal Trading: Invisible\n  Hand Inference with Free Energy",
        "authors": [
            "Igor Halperin",
            "Ilya Feldshteyn"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  We present a simple model of a non-equilibrium self-organizing market where\nasset prices are partially driven by investment decisions of a bounded-rational\nagent. The agent acts in a stochastic market environment driven by various\nexogenous \"alpha\" signals, agent's own actions (via market impact), and noise.\nUnlike traditional agent-based models, our agent aggregates all traders in the\nmarket, rather than being a representative agent. Therefore, it can be\nidentified with a bounded-rational component of the market itself, providing a\nparticular implementation of an Invisible Hand market mechanism. In such\nsetting, market dynamics are modeled as a fictitious self-play of such\nbounded-rational market-agent in its adversarial stochastic environment. As\nrewards obtained by such self-playing market agent are not observed from market\ndata, we formulate and solve a simple model of such market dynamics based on a\nneuroscience-inspired Bounded Rational Information Theoretic Inverse\nReinforcement Learning (BRIT-IRL). This results in effective asset price\ndynamics with a non-linear mean reversion - which in our model is generated\ndynamically, rather than being postulated. We argue that our model can be used\nin a similar way to the Black-Litterman model. In particular, it represents, in\na simple modeling framework, market views of common predictive signals, market\nimpacts and implied optimal dynamic portfolio allocations, and can be used to\nassess values of private signals. Moreover, it allows one to quantify a\n\"market-implied\" optimal investment strategy, along with a measure of market\nrationality. Our approach is numerically light, and can be implemented using\nstandard off-the-shelf software such as TensorFlow.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.06126v1"
    },
    {
        "title": "Analytic Calibration in Andreasen-Huge SABR Model",
        "authors": [
            "K. E. Feldman"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  We derive analytic formulae which link $\\alpha$, $\\nu$ and $\\rho$ parameters\nin Andreasen-Huge style SABR model to the ATM price and option prices at four\nstrikes close to ATM. Based on these formulae we give a characterisation for\nthe SABR parameters in terms of derivatives of the swap rate forward\nprobability density function. We test the analytic result in the application to\nthe interest rate futures option market.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.09108v2"
    },
    {
        "title": "Weak error rates for option pricing under linear rough volatility",
        "authors": [
            "Christian Bayer",
            "Eric Joseph Hall",
            "Raúl Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In quantitative finance, modeling the volatility structure of underlying\nassets is vital to pricing options. Rough stochastic volatility models, such as\nthe rough Bergomi model [Bayer, Friz, Gatheral, Quantitative Finance 16(6),\n887-904, 2016], seek to fit observed market data based on the observation that\nthe log-realized variance behaves like a fractional Brownian motion with small\nHurst parameter, $H < 1/2$, over reasonable timescales. Both time series of\nasset prices and option-derived price data indicate that $H$ often takes values\nclose to $0.1$ or less, i.e., rougher than Brownian motion. This change\nimproves the fit to both option prices and time series of underlying asset\nprices while maintaining parsimoniousness. However, the non-Markovian nature of\nthe driving fractional Brownian motion in rough volatility models poses severe\nchallenges for theoretical and numerical analyses and for computational\npractice. While the explicit Euler method is known to converge to the solution\nof the rough Bergomi and similar models, its strong rate of convergence is only\n$H$. We prove rate $H + 1/2$ for the weak convergence of the Euler method for\nthe rough Stein-Stein model, which treats the volatility as a linear function\nof the driving fractional Brownian motion, and, surprisingly, we prove rate one\nfor the case of quadratic payoff functions. Our proof uses Talay-Tubaro\nexpansions and an affine Markovian representation of the underlying and is\nfurther supported by numerical experiments. These convergence results provide a\nfirst step toward deriving weak rates for the rough Bergomi model, which treats\nthe volatility as a nonlinear function of the driving fractional Brownian\nmotion.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.01219v3"
    },
    {
        "title": "Deep Hedging: Learning to Simulate Equity Option Markets",
        "authors": [
            "Magnus Wiese",
            "Lianjun Bai",
            "Ben Wood",
            "Hans Buehler"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  We construct realistic equity option market simulators based on generative\nadversarial networks (GANs). We consider recurrent and temporal convolutional\narchitectures, and assess the impact of state compression. Option market\nsimulators are highly relevant because they allow us to extend the limited\nreal-world data sets available for the training and evaluation of option\ntrading strategies. We show that network-based generators outperform classical\nmethods on a range of benchmark metrics, and adversarial training achieves the\nbest performance. Our work demonstrates for the first time that GANs can be\nsuccessfully applied to the task of generating multivariate financial time\nseries.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01700v1"
    },
    {
        "title": "Neural networks for option pricing and hedging: a literature review",
        "authors": [
            "Johannes Ruf",
            "Weiguan Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2019",
        "summary": "  Neural networks have been used as a nonparametric method for option pricing\nand hedging since the early 1990s. Far over a hundred papers have been\npublished on this topic. This note intends to provide a comprehensive review.\nPapers are compared in terms of input features, output variables, benchmark\nmodels, performance measures, data partition methods, and underlying assets.\nFurthermore, related work and regularisation techniques are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05620v2"
    },
    {
        "title": "Unbiased estimators for the Heston model with stochastic interest rates",
        "authors": [
            "Chao Zheng",
            "Jiangtao Pan"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  We combine the unbiased estimators in Rhee and Glynn (Operations Research:\n63(5), 1026-1043, 2015) and the Heston model with stochastic interest rates.\nSpecifically, we first develop a semi-exact log-Euler scheme for the Heston\nmodel with stochastic interest rates. Then, under mild assumptions, we show\nthat the convergence rate in the $L^2$ norm is $O(h)$, where $h$ is the step\nsize. The result applies to a large class of models, such as the\nHeston-Hull-While model, the Heston-CIR model and the Heston-Black-Karasinski\nmodel. Numerical experiments support our theoretical convergence rate.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.12072v2"
    },
    {
        "title": "Supporting Crowd-Powered Science in Economics: FRACTI, a Conceptual\n  Framework for Large-Scale Collaboration and Transparent Investigation in\n  Financial Markets",
        "authors": [
            "Jorge Faleiro",
            "Edward Tsang"
        ],
        "category": "q-fin.CP",
        "published_year": "2018",
        "summary": "  Modern investigation in economics and in other sciences requires the ability\nto store, share, and replicate results and methods of experiments that are\noften multidisciplinary and yield a massive amount of data. Given the\nincreasing complexity and growing interaction across diverse bodies of\nknowledge it is becoming imperative to define a platform to properly support\ncollaborative research and track origin, accuracy and use of data. This paper\nstarts by defining a set of methods leveraging scientific principles and\nadvocating the importance of those methods in multidisciplinary, computer\nintensive fields like computational finance. The next part of this paper\ndefines a class of systems called scientific support systems, vis-a-vis usages\nin other research fields such as bioinformatics, physics and engineering. We\noutline a basic set of fundamental concepts, and list our goals and motivation\nfor leveraging such systems to enable large-scale investigation, \"crowd powered\nscience\", in economics. The core of this paper provides an outline of FRACTI in\nfive steps. First we present definitions related to scientific support systems\nintrinsic to finance and describe common characteristics of financial use\ncases. The second step concentrates on what can be exchanged through the\ndefinition of shareable entities called contributions. The third step is the\ndescription of a classification system for building blocks of the conceptual\nframework, called facets. The fourth step introduces the meta-model that will\nenable provenance tracking and representation of data fragments and simulation.\nFinally we describe intended cases of use to highlight main strengths of\nFRACTI: application of the scientific method for investigation in computational\nfinance, large-scale collaboration and simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.07959v1"
    },
    {
        "title": "Hermite Polynomial-based Valuation of American Options with General\n  Jump-Diffusion Processes",
        "authors": [
            "Li Chen",
            "Guang Zhang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We present a new approximation scheme for the price and exercise policy of\nAmerican options. The scheme is based on Hermite polynomial expansions of the\ntransition density of the underlying asset dynamics and the early exercise\npremium representation of the American option price. The advantages of the\nproposed approach are threefold. First, our approach does not require the\ntransition density and characteristic functions of the underlying asset\ndynamics to be attainable in closed form. Second, our approach is fast and\naccurate, while the prices and exercise policy can be jointly produced. Third,\nour approach has a wide range of applications. We show that the proposed\napproximations of the price and optimal exercise boundary converge to the true\nones. We also provide a numerical method based on a step function to implement\nour proposed approach. Applications to nonlinear mean-reverting models, double\nmean-reverting models, Merton's and Kou's jump-diffusion models are presented\nand discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.11870v1"
    },
    {
        "title": "Deep learning of transition probability densities for stochastic asset\n  models with applications in option pricing",
        "authors": [
            "Haozhe Su",
            "M. V. Tretyakov",
            "David P. Newton"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Transition probability density functions (TPDFs) are fundamental to\ncomputational finance, including option pricing and hedging. Advancing recent\nwork in deep learning, we develop novel neural TPDF generators through solving\nbackward Kolmogorov equations in parametric space for cumulative probability\nfunctions. The generators are ultra-fast, very accurate and can be trained for\nany asset model described by stochastic differential equations. These are\n\"single solve\", so they do not require retraining when parameters of the\nstochastic model are changed (e.g. recalibration of volatility). Once trained,\nthe neural TDPF generators can be transferred to less powerful computers where\nthey can be used for e.g. option pricing at speeds as fast as if the TPDF were\nknown in a closed form.\n  We illustrate the computational efficiency of the proposed neural\napproximations of TPDFs by inserting them into numerical option pricing\nmethods. We demonstrate a wide range of applications including the\nBlack-Scholes-Merton model, the standard Heston model, the SABR model, and\njump-diffusion models. These numerical experiments confirm the ultra-fast speed\nand high accuracy of the developed neural TPDF generators.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10467v2"
    },
    {
        "title": "Arbitrage-free neural-SDE market models",
        "authors": [
            "Samuel N. Cohen",
            "Christoph Reisinger",
            "Sheng Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  Modelling joint dynamics of liquid vanilla options is crucial for\narbitrage-free pricing of illiquid derivatives and managing risks of option\ntrade books. This paper develops a nonparametric model for the European options\nbook respecting underlying financial constraints and while being practically\nimplementable. We derive a state space for prices which are free from static\n(or model-independent) arbitrage and study the inference problem where a model\nis learnt from discrete time series data of stock and option prices. We use\nneural networks as function approximators for the drift and diffusion of the\nmodelled SDE system, and impose constraints on the neural nets such that\nno-arbitrage conditions are preserved. In particular, we give methods to\ncalibrate \\textit{neural SDE} models which are guaranteed to satisfy a set of\nlinear inequalities. We validate our approach with numerical experiments using\ndata generated from a Heston stochastic local volatility model.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11053v2"
    },
    {
        "title": "On the Efficiency of 5(4) RK-Embedded Pairs with High Order Compact\n  Scheme and Robin Boundary Condition for Options Valuation",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  When solving the American options with or without dividends, numerical\nmethods often obtain lower convergence rates if further treatment is not\nimplemented even using high-order schemes. In this article, we present a fast\nand explicit fourth-order compact scheme for solving the free boundary options.\nIn particular, the early exercise features with the asset option and option\nsensitivity are computed based on a coupled of nonlinear PDEs with fixed\nboundaries for which a high order analytical approximation is obtained.\nFurthermore, we implement a new treatment at the left boundary by introducing a\nthird-order Robin boundary condition. Rather than computing the optimal\nexercise boundary from the analytical approximation, we simply obtain it from\nthe asset option based on the linear relationship at the left boundary. As\nsuch, a high order convergence rate can be achieved. We validate by examples\nthat the improvement at the left boundary yields a fourth-order convergence\nrate without further implementation of mesh refinement, Rannacher\ntime-stepping, and/or smoothing of the initial condition. Furthermore, we\nextensively compare, the performance of our present method with several 5(4)\nRunge-Kutta pairs and observe that Dormand and Prince and Bogacki and Shampine\n5(4) pairs are faster and provide more accurate numerical solutions. Based on\nnumerical results and comparison with other existing methods, we can validate\nthat the present method is very fast and provides more accurate solutions with\nvery coarse grids.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.10418v3"
    },
    {
        "title": "Multi-Asset Spot and Option Market Simulation",
        "authors": [
            "Magnus Wiese",
            "Ben Wood",
            "Alexandre Pachoud",
            "Ralf Korn",
            "Hans Buehler",
            "Phillip Murray",
            "Lianjun Bai"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  We construct realistic spot and equity option market simulators for a single\nunderlying on the basis of normalizing flows. We address the\nhigh-dimensionality of market observed call prices through an arbitrage-free\nautoencoder that approximates efficient low-dimensional representations of the\nprices while maintaining no static arbitrage in the reconstructed surface.\nGiven a multi-asset universe, we leverage the conditional invertibility\nproperty of normalizing flows and introduce a scalable method to calibrate the\njoint distribution of a set of independent simulators while preserving the\ndynamics of each simulator. Empirical results highlight the goodness of the\ncalibrated simulators and their fidelity.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.06823v1"
    },
    {
        "title": "Estimating risks of option books using neural-SDE market models",
        "authors": [
            "Samuel N. Cohen",
            "Christoph Reisinger",
            "Sheng Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  In this paper, we examine the capacity of an arbitrage-free neural-SDE market\nmodel to produce realistic scenarios for the joint dynamics of multiple\nEuropean options on a single underlying. We subsequently demonstrate its use as\na risk simulation engine for option portfolios. Through backtesting analysis,\nwe show that our models are more computationally efficient and accurate for\nevaluating the Value-at-Risk (VaR) of option portfolios, with better coverage\nperformance and less procyclicality than standard filtered historical\nsimulation approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07148v1"
    },
    {
        "title": "Risk-Neutral Market Simulation",
        "authors": [
            "Magnus Wiese",
            "Phillip Murray"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We develop a risk-neutral spot and equity option market simulator for a\nsingle underlying, under which the joint market process is a martingale. We\nleverage an efficient low-dimensional representation of the market which\npreserves no static arbitrage, and employ neural spline flows to simulate\nsamples which are free from conditional drifts and are highly realistic in the\nsense that among all possible risk-neutral simulators, the obtained\nrisk-neutral simulator is the closest to the historical data with respect to\nthe Kullback-Leibler divergence. Numerical experiments demonstrate the\neffectiveness and highlight both drift removal and fidelity of the calibrated\nsimulator.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13996v1"
    },
    {
        "title": "Detecting data-driven robust statistical arbitrage strategies with deep\n  neural networks",
        "authors": [
            "Ariel Neufeld",
            "Julian Sester",
            "Daiying Yin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We present an approach, based on deep neural networks, that allows\nidentifying robust statistical arbitrage strategies in financial markets.\nRobust statistical arbitrage strategies refer to trading strategies that enable\nprofitable trading under model ambiguity. The presented novel methodology\nallows to consider a large amount of underlying securities simultaneously and\ndoes not depend on the identification of cointegrated pairs of assets, hence it\nis applicable on high-dimensional financial markets or in markets where\nclassical pairs trading approaches fail. Moreover, we provide a method to build\nan ambiguity set of admissible probability measures that can be derived from\nobserved market data. Thus, the approach can be considered as being model-free\nand entirely data-driven. We showcase the applicability of our method by\nproviding empirical investigations with highly profitable trading performances\neven in 50 dimensions, during financial crises, and when the cointegration\nrelationship between asset pairs stops to persist.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.03179v4"
    },
    {
        "title": "Phases of MANES: Multi-Asset Non-Equilibrium Skew Model of a Strongly\n  Non-Linear Market with Phase Transitions",
        "authors": [
            "Igor Halperin"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper presents an analytically tractable and practically-oriented model\nof non-linear dynamics of a multi-asset market in the limit of a large number\nof assets. The asset price dynamics are driven by money flows into the market\nfrom external investors, and their price impact. This leads to a model of a\nmarket as an ensemble of interacting non-linear oscillators with the Langevin\ndynamics. In a homogeneous portfolio approximation, the mean field treatment of\nthe resulting Langevin dynamics produces the McKean-Vlasov equation as a\ndynamic equation for market returns. Due to the strong non-linearity of the\nMcKean-Vlasov equation, the resulting dynamics give rise to ergodicity breaking\nand first- or second-order phase transitions under variations of model\nparameters. Using a tractable potential of the Non-Equilibrium Skew (NES) model\npreviously suggested by the author for a single-stock case, the new Multi-Asset\nNES (MANES) model enables an analytically tractable framework for a multi-asset\nmarket. The equilibrium expected market log-return is obtained as a\nself-consistent mean field of the McKean-Vlasov equation, and derived in closed\nform in terms of parameters that are inferred from market prices of S&P 500\nindex options. The model is able to accurately fit the market data for either a\nbenign or distressed market environments, while using only a single volatility\nparameter.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.07550v1"
    },
    {
        "title": "Machine learning method for return direction forecasting of Exchange\n  Traded Funds using classification and regression models",
        "authors": [
            "Raphael P. B. Piovezan",
            "Pedro Paulo de Andrade Junior"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This article aims to propose and apply a machine learning method to analyze\nthe direction of returns from Exchange Traded Funds (ETFs) using the historical\nreturn data of its components, helping to make investment strategy decisions\nthrough a trading algorithm. In methodological terms, regression and\nclassification models were applied, using standard datasets from Brazilian and\nAmerican markets, in addition to algorithmic error metrics. In terms of\nresearch results, they were analyzed and compared to those of the Na\\\"ive\nforecast and the returns obtained by the buy & hold technique in the same\nperiod of time. In terms of risk and return, the models mostly performed better\nthan the control metrics, with emphasis on the linear regression model and the\nclassification models by logistic regression, support vector machine (using the\nLinearSVC model), Gaussian Naive Bayes and K-Nearest Neighbors, where in\ncertain datasets the returns exceeded by two times and the Sharpe ratio by up\nto four times those of the buy & hold control model.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.12746v2"
    },
    {
        "title": "Hedging option books using neural-SDE market models",
        "authors": [
            "Samuel N. Cohen",
            "Christoph Reisinger",
            "Sheng Wang"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We study the capability of arbitrage-free neural-SDE market models to yield\neffective strategies for hedging options. In particular, we derive\nsensitivity-based and minimum-variance-based hedging strategies using these\nmodels and examine their performance when applied to various option portfolios\nusing real-world data. Through backtesting analysis over typical and stressed\nmarket periods, we show that neural-SDE market models achieve lower hedging\nerrors than Black--Scholes delta and delta-vega hedging consistently over time,\nand are less sensitive to the tenor choice of hedging instruments. In addition,\nhedging using market models leads to similar performance to hedging using\nHeston models, while the former tends to be more robust during stressed market\nperiods.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.15991v1"
    },
    {
        "title": "Distributionally Robust End-to-End Portfolio Construction",
        "authors": [
            "Giorgio Costa",
            "Garud N. Iyengar"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We propose an end-to-end distributionally robust system for portfolio\nconstruction that integrates the asset return prediction model with a\ndistributionally robust portfolio optimization model. We also show how to learn\nthe risk-tolerance parameter and the degree of robustness directly from data.\nEnd-to-end systems have an advantage in that information can be communicated\nbetween the prediction and decision layers during training, allowing the\nparameters to be trained for the final task rather than solely for predictive\nperformance. However, existing end-to-end systems are not able to quantify and\ncorrect for the impact of model risk on the decision layer. Our proposed\ndistributionally robust end-to-end portfolio selection system explicitly\naccounts for the impact of model risk. The decision layer chooses portfolios by\nsolving a minimax problem where the distribution of the asset returns is\nassumed to belong to an ambiguity set centered around a nominal distribution.\nUsing convex duality, we recast the minimax problem in a form that allows for\nefficient training of the end-to-end system.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.05134v1"
    },
    {
        "title": "Efficient Pricing and Calibration of High-Dimensional Basket Options",
        "authors": [
            "Lech A. Grzelak",
            "Juliusz Jablecki",
            "Dariusz Gatarek"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper studies equity basket options -- i.e., multi-dimensional\nderivatives whose payoffs depend on the value of a weighted sum of the\nunderlying stocks -- and develops a new and innovative approach to ensure\nconsistency between options on individual stocks and on the index comprising\nthem. Specifically, we show how to resolve a well-known problem that when\nindividual constituent distributions of an equity index are inferred from the\nsingle-stock option markets and combined in a multi-dimensional\nlocal/stochastic volatility model, the resulting basket option prices will not\ngenerate a skew matching that of the options on the equity index corresponding\nto the basket. To address this ``insufficient skewness'', we proceed in two\nsteps. First, we propose an ``effective'' local volatility model by mapping the\ngeneral multi-dimensional basket onto a collection of marginal distributions.\nSecond, we build a multivariate dependence structure between all the marginal\ndistributions assuming a jump-diffusion model for the effective projection\nparameters, and show how to calibrate the basket to the index smile. Numerical\ntests and calibration exercises demonstrate an excellent fit for a basket of as\nmany as 30 stocks with fast calculation time.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09877v1"
    },
    {
        "title": "Recursive Overbetting of a Satellite Investment Account",
        "authors": [
            "Alex Garivaltis"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  This paper builds a core-satellite model of semi-static Kelly betting and\nlog-optimal investment. We study the problem of a saver whose core portfolio\nconsists in unlevered (1x) retirement plans with no access to margin debt.\nHowever, the agent has a satellite investment account with recourse to\nsignificant, but not unlimited, leverage; accordingly, we study optimal\ncontrollers for the satellite gearing ratio. On a very short time horizon, the\nbest policy is to overbet the satellite, whereby the overriding objective is to\nraise the aggregate beta toward a growth-optimal level. On an infinite horizon,\nby contrast, the correct behavior is to blithely ignore the core and optimize\nthe exponential growth rate of the satellite, which will anyways come to\ndominate the entire bankroll in the limit. For time horizons strictly between\nzero and infinity, the optimal strategy is not so simple: there is a key\ntrade-off between the instantaneous growth rate of the composite bankroll, and\nthat of the satellite itself, which suffers ongoing volatility drag from the\noverbetting. Thus, a very perspicacious policy is called for, since any losses\nin the satellite will constrain the agent's access to leverage in the\ncontinuation problem. We characterize the optimal feedback controller, and\ncompute it in earnest by solving the corresponding HJB equation recursively and\nbackward in time. This solution is then compared to the best open-loop\ncontroller, which, in spite of its relative simplicity, is expected to perform\nsimilarly in practical situations.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.11105v2"
    },
    {
        "title": "Sixth-Order Compact Differencing with Staggered Boundary Schemes and\n  3(2) Bogacki-Shampine Pairs for Pricing Free-Boundary Options",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We propose a stable sixth-order compact finite difference scheme with a\ndynamic fifth-order staggered boundary scheme and 3(2) R-K Bogacki and Shampine\nadaptive time stepping for pricing American style options. To locate, fix and\ncompute the free-boundary simultaneously with option and delta sensitivity, we\nintroduce a Landau transformation. Furthermore, we remove the convective term\nin the pricing model which could further introduce errors. Hence, an efficient\nsixth-order compact scheme can easily be implemented. The main challenge in\ncoupling the sixth order compact scheme in discrete form is to efficiently\naccount for the near-boundary scheme. In this work, we introduce novel fifth-\nand sixth-order Dirichlet near-boundary schemes suitable for solving our model.\nThe optimal exercise boundary and other boundary values are approximated using\na high-order analytical approximation obtained from a novel fifth-order\nstaggered boundary scheme. Furthermore, we investigate the smoothness of the\nfirst and second derivatives of the optimal exercise boundary which is obtained\nfrom this high-order analytical approximation. Coupled with the 3(2) RK-Bogacki\nand Shampine time integration method, the interior values are then approximated\nusing the sixth order compact operator. The expected convergence rate is\nobtained, and our present numerical scheme is very fast and gives highly\naccurate approximations with very coarse grids.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.14379v1"
    },
    {
        "title": "Randomization of Short-Rate Models, Analytic Pricing and Flexibility in\n  Controlling Implied Volatilities",
        "authors": [
            "Lech A. Grzelak"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We focus on extending existing short-rate models, enabling control of the\ngenerated implied volatility while preserving analyticity. We achieve this goal\nby applying the Randomized Affine Diffusion (RAnD) method to the class of\nshort-rate processes under the Heath-Jarrow-Morton framework. Under\narbitrage-free conditions, the model parameters can be exogenously stochastic,\nthus facilitating additional degrees of freedom that enhance the calibration\nprocedure. We show that with the randomized short-rate models, the shapes of\nimplied volatility can be controlled and significantly improve the quality of\nthe model calibration, even for standard 1D variants. In particular, we\nillustrate that randomization applied to the Hull-White model leads to dynamics\nof the local volatility type, with the prices for standard volatility-sensitive\nderivatives explicitly available. The randomized Hull-White (rHW) model offers\nan almost perfect calibration fit to the swaption implied volatilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.05014v2"
    },
    {
        "title": "Deep Quadratic Hedging",
        "authors": [
            "Alessandro Gnoatto",
            "Silvia Lavagnini",
            "Athena Picarelli"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We propose a novel computational procedure for quadratic hedging in\nhigh-dimensional incomplete markets, covering mean-variance hedging and local\nrisk minimization. Starting from the observation that both quadratic approaches\ncan be treated from the point of view of backward stochastic differential\nequations (BSDEs), we (recursively) apply a deep learning-based BSDE solver to\ncompute the entire optimal hedging strategies paths. This allows us to overcome\nthe curse of dimensionality, extending the scope of applicability of quadratic\nhedging in high dimension. We test our approach with a classic Heston model and\nwith a multiasset and multifactor generalization thereof, showing that this\nleads to high levels of accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.12725v2"
    },
    {
        "title": "Silkswap: An asymmetric automated market maker model for stablecoins",
        "authors": [
            "Nicola Cantarutti",
            "Alex Harker",
            "Carter Woetzel"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Silkswap is an automated market maker model designed for efficient stablecoin\ntrading with minimal price impact. The original purpose of Silkswap is to\nfacilitate the trading of fiat-pegged stablecoins with the stablecoin Silk, but\nit can be applied to any pair of stablecoins. The Silkswap invariant is a\nhybrid function that generates an asymmetric price impact curve. We present the\nderivation of the Silkswap model and its mathematical properties. We also\ncompare different numerical methods used to solve the invariant equation.\nFinally, we compare our model with the well-known Curve Finance model.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.07822v1"
    },
    {
        "title": "Neural networks can detect model-free static arbitrage strategies",
        "authors": [
            "Ariel Neufeld",
            "Julian Sester"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this paper we demonstrate both theoretically as well as numerically that\nneural networks can detect model-free static arbitrage opportunities whenever\nthe market admits some. Due to the use of neural networks, our method can be\napplied to financial markets with a high number of traded securities and\nensures almost immediate execution of the corresponding trading strategies. To\ndemonstrate its tractability, effectiveness, and robustness we provide examples\nusing real financial data. From a technical point of view, we prove that a\nsingle neural network can approximately solve a class of convex semi-infinite\nprograms, which is the key result in order to derive our theoretical results\nthat neural networks can detect model-free static arbitrage strategies whenever\nthe financial market admits such opportunities.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.16422v2"
    },
    {
        "title": "Enhancing accuracy for solving American CEV model with high-order\n  compact scheme and adaptive time stepping",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai",
            "Tony Ware"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  In this research work, we propose a high-order time adapted scheme for\npricing a coupled system of fixed-free boundary constant elasticity of variance\n(CEV) model on both equidistant and locally refined space-grid. The performance\nof our method is substantially enhanced to improve irregularities in the model\nwhich are both inherent and induced. Furthermore, the system of coupled PDEs is\nstrongly nonlinear and involves several time-dependent coefficients that\ninclude the first-order derivative of the early exercise boundary. These\ncoefficients are approximated from a fourth-order analytical approximation\nwhich is derived using a regularized square-root function. The semi-discrete\nequation for the option value and delta sensitivity is obtained from a\nnon-uniform fourth-order compact finite difference scheme. Fifth-order 5(4)\nDormand-Prince time integration method is used to solve the coupled system of\ndiscrete equations. Enhancing the performance of our proposed method with local\nmesh refinement and adaptive strategies enables us to obtain highly accurate\nsolution with very coarse space grids, hence reducing computational runtime\nsubstantially. We further verify the performance of our methodology as compared\nwith some of the well-known and better-performing existing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.03984v2"
    },
    {
        "title": "Applying Deep Learning to Calibrate Stochastic Volatility Models",
        "authors": [
            "Abir Sridi",
            "Paul Bilokon"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  Stochastic volatility models, where the volatility is a stochastic process,\ncan capture most of the essential stylized facts of implied volatility surfaces\nand give more realistic dynamics of the volatility smile/skew. However, they\ncome with the significant issue that they take too long to calibrate.\n  Alternative calibration methods based on Deep Learning (DL) techniques have\nbeen recently used to build fast and accurate solutions to the calibration\nproblem. Huge and Savine developed a Differential Machine Learning (DML)\napproach, where Machine Learning models are trained on samples of not only\nfeatures and labels but also differentials of labels to features. The present\nwork aims to apply the DML technique to price vanilla European options (i.e.\nthe calibration instruments), more specifically, puts when the underlying asset\nfollows a Heston model and then calibrate the model on the trained network. DML\nallows for fast training and accurate pricing. The trained neural network\ndramatically reduces Heston calibration's computation time.\n  In this work, we also introduce different regularisation techniques, and we\napply them notably in the case of the DML. We compare their performance in\nreducing overfitting and improving the generalisation error. The DML\nperformance is also compared to the classical DL (without differentiation) one\nin the case of Feed-Forward Neural Networks. We show that the DML outperforms\nthe DL.\n  The complete code for our experiments is provided in the GitHub repository:\nhttps://github.com/asridi/DML-Calibration-Heston-Model\n",
        "pdf_link": "http://arxiv.org/pdf/2309.07843v2"
    },
    {
        "title": "Mean Absolute Directional Loss as a New Loss Function for Machine\n  Learning Problems in Algorithmic Investment Strategies",
        "authors": [
            "Jakub Michańków",
            "Paweł Sakowski",
            "Robert Ślepaczuk"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  This paper investigates the issue of an adequate loss function in the\noptimization of machine learning models used in the forecasting of financial\ntime series for the purpose of algorithmic investment strategies (AIS)\nconstruction. We propose the Mean Absolute Directional Loss (MADL) function,\nsolving important problems of classical forecast error functions in extracting\ninformation from forecasts to create efficient buy/sell signals in algorithmic\ninvestment strategies. Finally, based on the data from two different asset\nclasses (cryptocurrencies: Bitcoin and commodities: Crude Oil), we show that\nthe new loss function enables us to select better hyperparameters for the LSTM\nmodel and obtain more efficient investment strategies, with regard to\nrisk-adjusted return metrics on the out-of-sample data.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10546v1"
    },
    {
        "title": "Characteristics of price related fluctuations in Non-Fungible Token\n  (NFT) market",
        "authors": [
            "Paweł Szydło",
            "Marcin Wątorek",
            "Jarosław Kwapień",
            "Stanisław Drożdż"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  A non-fungible token (NFT) market is a new trading invention based on the\nblockchain technology which parallels the cryptocurrency market. In the present\nwork we study capitalization, floor price, the number of transactions, the\ninter-transaction times, and the transaction volume value of a few selected\npopular token collections. The results show that the fluctuations of all these\nquantities are characterized by heavy-tailed probability distribution\nfunctions, in most cases well described by the stretched exponentials, with a\ntrace of power-law scaling at times, long-range memory, and in several cases\neven the fractal organization of fluctuations, mostly restricted to the larger\nfluctuations, however. We conclude that the NFT market - even though young and\ngoverned by a somewhat different mechanisms of trading - shares several\nstatistical properties with the regular financial markets. However, some\ndifferences are visible in the specific quantitative indicators.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.19747v2"
    },
    {
        "title": "Combining Deep Learning on Order Books with Reinforcement Learning for\n  Profitable Trading",
        "authors": [
            "Koti S. Jaddu",
            "Paul A. Bilokon"
        ],
        "category": "q-fin.CP",
        "published_year": "2023",
        "summary": "  High-frequency trading is prevalent, where automated decisions must be made\nquickly to take advantage of price imbalances and patterns in price action that\nforecast near-future movements. While many algorithms have been explored and\ntested, analytical methods fail to harness the whole nature of the market\nenvironment by focusing on a limited domain. With the evergrowing machine\nlearning field, many large-scale end-to-end studies on raw data have been\nsuccessfully employed to increase the domain scope for profitable trading but\nare very difficult to replicate. Combining deep learning on the order books\nwith reinforcement learning is one way of breaking down large-scale end-to-end\nlearning into more manageable and lightweight components for reproducibility,\nsuitable for retail trading.\n  The following work focuses on forecasting returns across multiple horizons\nusing order flow imbalance and training three temporal-difference learning\nmodels for five financial instruments to provide trading signals. The\ninstruments used are two foreign exchange pairs (GBPUSD and EURUSD), two\nindices (DE40 and FTSE100), and one commodity (XAUUSD). The performances of\nthese 15 agents are evaluated through backtesting simulation, and successful\nmodels proceed through to forward testing on a retail trading platform. The\nresults prove potential but require further minimal modifications for\nconsistently profitable trading to fully handle retail trading costs, slippage,\nand spread fluctuation.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02088v1"
    },
    {
        "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of\n  AI in Stock Selection",
        "authors": [
            "Georgios Fatouros",
            "Konstantinos Metaxas",
            "John Soldatos",
            "Dimosthenis Kyriazis"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper introduces MarketSenseAI, an innovative framework leveraging\nGPT-4's advanced reasoning for selecting stocks in financial markets. By\nintegrating Chain of Thought and In-Context Learning, MarketSenseAI analyzes\ndiverse data sources, including market trends, news, fundamentals, and\nmacroeconomic factors, to emulate expert investment decision-making. The\ndevelopment, implementation, and validation of the framework are elaborately\ndiscussed, underscoring its capability to generate actionable and interpretable\ninvestment signals. A notable feature of this work is employing GPT-4 both as a\npredictive mechanism and signal evaluator, revealing the significant impact of\nthe AI-generated explanations on signal accuracy, reliability and acceptance.\nThrough empirical testing on the competitive S&P 100 stocks over a 15-month\nperiod, MarketSenseAI demonstrated exceptional performance, delivering excess\nalpha of 10% to 30% and achieving a cumulative return of up to 72% over the\nperiod, while maintaining a risk profile comparable to the broader market. Our\nfindings highlight the transformative potential of Large Language Models in\nfinancial decision-making, marking a significant leap in integrating generative\nAI into financial analytics and investment strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03737v2"
    },
    {
        "title": "Emoji Driven Crypto Assets Market Reactions",
        "authors": [
            "Xiaorui Zuo",
            "Yao-Tsung Chen",
            "Wolfgang Karl Härdle"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  In the burgeoning realm of cryptocurrency, social media platforms like\nTwitter have become pivotal in influencing market trends and investor\nsentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based\nBERT model for a multimodal sentiment analysis, focusing on the impact of emoji\nsentiment on cryptocurrency markets. By translating emojis into quantifiable\nsentiment data, we correlate these insights with key market indicators like BTC\nPrice and the VCRIX index. Our architecture's analysis of emoji sentiment\ndemonstrated a distinct advantage over FinBERT's pure text sentiment analysis\nin such predicting power. This approach may be fed into the development of\ntrading strategies aimed at utilizing social media elements to identify and\nforecast market trends. Crucially, our findings suggest that strategies based\non emoji sentiment can facilitate the avoidance of significant market downturns\nand contribute to the stabilization of returns. This research underscores the\npractical benefits of integrating advanced AI-driven analyses into financial\nstrategies, offering a nuanced perspective on the interplay between digital\ncommunication and market dynamics in an academic context.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.10481v2"
    },
    {
        "title": "StockGPT: A GenAI Model for Stock Prediction and Trading",
        "authors": [
            "Dat Mai"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  This paper introduces StockGPT, an autoregressive ``number'' model trained\nand tested on 70 million daily U.S.\\ stock returns over nearly 100 years.\nTreating each return series as a sequence of tokens, StockGPT automatically\nlearns the hidden patterns predictive of future returns via its attention\nmechanism. On a held-out test sample from 2001 to 2023, daily and monthly\nrebalanced long-short portfolios formed from StockGPT predictions yield strong\nperformance. The StockGPT-based portfolios span momentum and long-/short-term\nreversals, eliminating the need for manually crafted price-based strategies,\nand yield highly significant alphas against leading stock market factors,\nsuggesting a novel AI pricing effect. This highlights the immense promise of\ngenerative AI in surpassing human in making complex financial investment\ndecisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.05101v3"
    },
    {
        "title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM\n  Approach",
        "authors": [
            "Haowei Ni",
            "Shuchen Meng",
            "Xupeng Chen",
            "Ziqing Zhao",
            "Andi Chen",
            "Panfeng Li",
            "Shiyao Zhang",
            "Qifu Yin",
            "Yuanqing Wang",
            "Yuxi Chan"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.06634v2"
    },
    {
        "title": "On Accelerating Large-Scale Robust Portfolio Optimization",
        "authors": [
            "Chung-Han Hsieh",
            "Jie-Ling Lu"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Solving large-scale robust portfolio optimization problems is challenging due\nto the high computational demands associated with an increasing number of\nassets, the amount of data considered, and market uncertainty. To address this\nissue, we propose an extended supporting hyperplane approximation approach for\nefficiently solving a class of distributionally robust portfolio problems for a\ngeneral class of additively separable utility functions and polyhedral\nambiguity distribution set, applied to a large-scale set of assets. Our\ntechnique is validated using a large-scale portfolio of the S&P 500 index\nconstituents, demonstrating robust out-of-sample trading performance. More\nimportantly, our empirical studies show that this approach significantly\nreduces computational time compared to traditional concave Expected Log-Growth\n(ELG) optimization, with running times decreasing from several thousand seconds\nto just a few. This method provides a scalable and practical solution to\nlarge-scale robust portfolio optimization, addressing both theoretical and\npractical challenges.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07879v1"
    },
    {
        "title": "MarS: a Financial Market Simulation Engine Powered by Generative\n  Foundation Model",
        "authors": [
            "Junjie Li",
            "Yang Liu",
            "Weiqing Liu",
            "Shikai Fang",
            "Lewen Wang",
            "Chang Xu",
            "Jiang Bian"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  Generative models aim to simulate realistic effects of various actions across\ndifferent contexts, from text generation to visual effects. Despite efforts to\nbuild real-world simulators, leveraging generative models for virtual worlds,\nlike financial markets, remains underexplored. In financial markets, generative\nmodels can simulate market effects of various behaviors, enabling interaction\nwith market scenes and players, and training strategies without financial risk.\nThis simulation relies on the finest structured data in financial market like\norders thus building the finest realistic simulation. We propose Large Market\nModel (LMM), an order-level generative foundation model, for financial market\nsimulation, akin to language modeling in the digital world. Our financial\nMarket Simulation engine (MarS), powered by LMM, addresses the need for\nrealistic, interactive and controllable order generation. Key objectives of\nthis paper include evaluating LMM's scaling law in financial markets, assessing\nMarS's realism, balancing controlled generation with market impact, and\ndemonstrating MarS's potential applications. We showcase MarS as a forecast\ntool, detection system, analysis platform, and agent training environment. Our\ncontributions include pioneering a generative model for financial markets,\ndesigning MarS to meet domain-specific needs, and demonstrating MarS-based\napplications' industry potential.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.07486v1"
    },
    {
        "title": "Solving The Dynamic Volatility Fitting Problem: A Deep Reinforcement\n  Learning Approach",
        "authors": [
            "Emmanuel Gnabeyeu",
            "Omar Karkar",
            "Imad Idboufous"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  The volatility fitting is one of the core problems in the equity derivatives\nbusiness. Through a set of deterministic rules, the degrees of freedom in the\nimplied volatility surface encoding (parametrization, density, diffusion) are\ndefined. Whilst very effective, this approach widespread in the industry is not\nnatively tailored to learn from shifts in market regimes and discover\nunsuspected optimal behaviors. In this paper, we change the classical paradigm\nand apply the latest advances in Deep Reinforcement Learning(DRL) to solve the\nfitting problem. In particular, we show that variants of Deep Deterministic\nPolicy Gradient (DDPG) and Soft Actor Critic (SAC) can achieve at least as good\nas standard fitting algorithms. Furthermore, we explain why the reinforcement\nlearning framework is appropriate to handle complex objective functions and is\nnatively adapted for online learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.11789v1"
    },
    {
        "title": "Sentiment trading with large language models",
        "authors": [
            "Kemal Kirtac",
            "Guido Germano"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We investigate the efficacy of large language models (LLMs) in sentiment\nanalysis of U.S. financial news and their potential in predicting stock market\nreturns. We analyze a dataset comprising 965,375 news articles that span from\nJanuary 1, 2010, to June 30, 2023; we focus on the performance of various LLMs,\nincluding BERT, OPT, FINBERT, and the traditional Loughran-McDonald dictionary\nmodel, which has been a dominant methodology in the finance literature. The\nstudy documents a significant association between LLM scores and subsequent\ndaily stock returns. Specifically, OPT, which is a GPT-3 based LLM, shows the\nhighest accuracy in sentiment prediction with an accuracy of 74.4%, slightly\nahead of BERT (72.5%) and FINBERT (72.2%). In contrast, the Loughran-McDonald\ndictionary model demonstrates considerably lower effectiveness with only 50.1%\naccuracy. Regression analyses highlight a robust positive impact of OPT model\nscores on next-day stock returns, with coefficients of 0.274 and 0.254 in\ndifferent model specifications. BERT and FINBERT also exhibit predictive\nrelevance, though to a lesser extent. Notably, we do not observe a significant\nrelationship between the Loughran-McDonald dictionary model scores and stock\nreturns, challenging the efficacy of this traditional method in the current\nfinancial context. In portfolio performance, the long-short OPT strategy excels\nwith a Sharpe ratio of 3.05, compared to 2.11 for BERT and 2.07 for FINBERT\nlong-short strategies. Strategies based on the Loughran-McDonald dictionary\nyield the lowest Sharpe ratio of 1.23. Our findings emphasize the superior\nperformance of advanced LLMs, especially OPT, in financial market prediction\nand portfolio management, marking a significant shift in the landscape of\nfinancial analysis tools with implications to financial regulation and policy\nanalysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.19245v1"
    },
    {
        "title": "Chi-square simulation of the CIR process and the Heston model",
        "authors": [
            "Simon J. A. Malham",
            "Anke Wiese"
        ],
        "category": "q-fin.CP",
        "published_year": "2008",
        "summary": "  The transition probability of a Cox-Ingersoll-Ross process can be represented\nby a non-central chi-square density. First we prove a new representation for\nthe central chi-square density based on sums of powers of generalized Gaussian\nrandom variables. Second we prove Marsaglia's polar method extends to this\ndistribution, providing a simple, exact, robust and efficient\nacceptance-rejection method for generalized Gaussian sampling and thus central\nchi-square sampling. Third we derive a simple, high-accuracy, robust and\nefficient direct inversion method for generalized Gaussian sampling based on\nthe Beasley-Springer-Moro method. Indeed the accuracy of the approximation to\nthe inverse cumulative distribution function is to the tenth decimal place. We\nthen apply our methods to non-central chi-square variance sampling in the\nHeston model. We focus on the case when the number of degrees of freedom is\nsmall and the zero boundary is attracting and attainable, typical in foreign\nexchange markets. Using the additivity property of the chi-square distribution,\nour methods apply in all parameter regimes.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.4411v5"
    },
    {
        "title": "Error estimates for finite difference approximations of American put\n  option price",
        "authors": [
            "David Šiška"
        ],
        "category": "q-fin.CP",
        "published_year": "2011",
        "summary": "  Finite difference approximations to multi-asset American put option price are\nconsidered. The assets are modelled as a multi-dimensional diffusion process\nwith variable drift and volatility. Approximation error of order one quarter\nwith respect to the time discretisation parameter and one half with respect to\nthe space discretisation parameter is proved by reformulating the corresponding\noptimal stopping problem as a solution of a degenerate Hamilton-Jacobi-Bellman\nequation. Furthermore, the error arising from restricting the discrete problem\nto a finite grid by reducing the original problem to a bounded domain is\nestimated.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.4032v2"
    },
    {
        "title": "Explicit RKF-Compact Scheme for Pricing Regime Switching American\n  Options with Varying Time Step",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai"
        ],
        "category": "q-fin.CP",
        "published_year": "2020",
        "summary": "  In this research work, an explicit Runge-Kutta-Fehlberg (RKF) time\nintegration with a fourth-order compact finite difference scheme in space and a\nhigh order analytical approximation of the optimal exercise boundary is\nemployed for solving the regime-switching pricing model. In detail, we recast\nthe free boundary problem into a system of nonlinear partial differential\nequations with a multi-fixed domain. We then introduce a transformation based\non the square root function with a Lipschitz character from which a high order\nanalytical approximation is obtained to compute the derivative of the optimal\nexercise boundary in each regime. We further compute the boundary values, asset\noption, and the option Greeks for each regime using fourth-order spatial\ndiscretization and adaptive time integration. In particular, the coupled assets\noptions and option Greeks are estimated using Hermite interpolation with Newton\nbasis. Finally, a numerical experiment is carried out with two- and\nfour-regimes examples and results are compared with the existing methods. The\nresults obtained from the numerical experiment show that the present method\nprovides better performance in terms of computational speed and more accurate\nsolutions with a large step size.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.09820v4"
    },
    {
        "title": "Numerical Smoothing with Hierarchical Adaptive Sparse Grids and\n  Quasi-Monte Carlo Methods for Efficient Option Pricing",
        "authors": [
            "Christian Bayer",
            "Chiheb Ben Hammouda",
            "Raúl Tempone"
        ],
        "category": "q-fin.CP",
        "published_year": "2021",
        "summary": "  When approximating the expectations of a functional of a solution to a\nstochastic differential equation, the numerical performance of deterministic\nquadrature methods, such as sparse grid quadrature and quasi-Monte Carlo (QMC)\nmethods, may critically depend on the regularity of the integrand. To overcome\nthis issue and improve the regularity structure of the problem, we consider\ncases in which analytic smoothing (bias-free mollification) cannot be performed\nand introduce a novel numerical smoothing approach by combining a root-finding\nmethod with a one-dimensional numerical integration with respect to a single\nwell-chosen variable. We prove that, under appropriate conditions, the\nresulting function of the remaining variables is highly smooth, potentially\naffording the improved efficiency of adaptive sparse grid quadrature (ASGQ) and\nQMC methods, particularly when combined with hierarchical transformations (ie.,\nthe Brownian bridge and Richardson extrapolation on the weak error). This\napproach facilitates the effective treatment of high dimensionality. Our study\nis motivated by option pricing problems, focusing on dynamics where the\ndiscretization of the asset price is necessary. Based on our analysis and\nnumerical experiments, we demonstrate the advantages of combining numerical\nsmoothing with the ASGQ and QMC methods over these methods without smoothing\nand the Monte Carlo approach. Finally, our approach is generic and can be\napplied to solve a broad class of problems, particularly approximating\ndistribution functions, computing financial Greeks, and estimating risk\nquantities.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.01874v2"
    },
    {
        "title": "Deep learning and American options via free boundary framework",
        "authors": [
            "Chinonso Nwankwo",
            "Nneka Umeorah",
            "Tony Ware",
            "Weizhong Dai"
        ],
        "category": "q-fin.CP",
        "published_year": "2022",
        "summary": "  We propose a deep learning method for solving the American options model with\na free boundary feature. To extract the free boundary known as the early\nexercise boundary from our proposed method, we introduce the Landau\ntransformation. For efficient implementation of our proposed method, we further\nconstruct a dual solution framework consisting of a novel auxiliary function\nand free boundary equations. The auxiliary function is formulated to include\nthe feed forward deep neural network (DNN) output and further mimic the far\nboundary behaviour, smooth pasting condition, and remaining boundary conditions\ndue to the second-order space derivative and first-order time derivative.\nBecause the early exercise boundary and its derivative are not a priori known,\nthe boundary values mimicked by the auxiliary function are in approximate form.\nConcurrently, we then establish equations that approximate the early exercise\nboundary and its derivative directly from the DNN output based on some linear\nrelationships at the left boundary. Furthermore, the option Greeks are obtained\nfrom the derivatives of this auxiliary function. We test our implementation\nwith several examples and compare them with the existing numerical methods. All\nindicators show that our proposed deep learning method presents an efficient\nand alternative way of pricing options with early exercise features.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.11803v2"
    },
    {
        "title": "A deep implicit-explicit minimizing movement method for option pricing\n  in jump-diffusion models",
        "authors": [
            "Emmanuil H. Georgoulis",
            "Antonis Papapantoleon",
            "Costas Smaragdakis"
        ],
        "category": "q-fin.CP",
        "published_year": "2024",
        "summary": "  We develop a novel deep learning approach for pricing European basket options\nwritten on assets that follow jump-diffusion dynamics. The option pricing\nproblem is formulated as a partial integro-differential equation, which is\napproximated via a new implicit-explicit minimizing movement time-stepping\napproach, involving approximation by deep, residual-type Artificial Neural\nNetworks (ANNs) for each time step. The integral operator is discretized via\ntwo different approaches: a) a sparse-grid Gauss--Hermite approximation\nfollowing localised coordinate axes arising from singular value decompositions,\nand b) an ANN-based high-dimensional special-purpose quadrature rule.\nCrucially, the proposed ANN is constructed to ensure the asymptotic behavior of\nthe solution for large values of the underlyings and also leads to consistent\noutputs with respect to a priori known qualitative properties of the solution.\nThe performance and robustness with respect to the dimension of the methods are\nassessed in a series of numerical experiments involving the Merton\njump-diffusion model.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.06740v1"
    }
]