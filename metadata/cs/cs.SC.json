[
    {
        "title": "A correct proof of the heuristic GCD algorithm",
        "authors": [
            "Bernard Parisse"
        ],
        "category": "cs.SC",
        "published_year": "2002",
        "summary": "  In this note, we fill a gap in the proof of the heuristic GCD in the\nmultivariate case made by Char, Geddes and Gonnet (JSC 1989) and give some\nadditionnal information on this method.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0206032v1"
    },
    {
        "title": "Orthonormal RBF wavelet and ridgelet-like series and transforms for\n  high-dimensional problems",
        "authors": [
            "W. Chen"
        ],
        "category": "cs.SC",
        "published_year": "2002",
        "summary": "  This paper developed a systematic strategy establishing RBF on the wavelet\nanalysis, which includes continuous and discrete RBF orthonormal wavelet\ntransforms respectively in terms of singular fundamental solutions and\nnonsingular general solutions of differential operators. In particular, the\nharmonic Bessel RBF transforms were presented for high-dimensional data\nprocessing. It was also found that the kernel functions of convection-diffusion\noperator are feasible to construct some stable ridgelet-like RBF transforms. We\npresented time-space RBF transforms based on non-singular solution and\nfundamental solution of time-dependent differential operators. The present\nmethodology was further extended to analysis of some known RBFs such as the MQ,\nGaussian and pre-wavelet kernel RBFs.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0207006v1"
    },
    {
        "title": "A Note on the DQ Analysis of Anisotropic Plates",
        "authors": [
            "W Chen",
            "Weixing He",
            "Tingxiu Zhong"
        ],
        "category": "cs.SC",
        "published_year": "2002",
        "summary": "  Recently, Bert, Wang and Striz [1, 2] applied the differential quadrature\n(DQ) and harmonic differential quadrature (HDQ) methods to analyze static and\ndynamic behaviors of anisotropic plates. Their studies showed that the methods\nwere conceptually simple and computationally efficient in comparison to other\nnumerical techniques. Based on some recent work by the present author [3, 4],\nthe purpose of this note is to further simplify the formulation effort and\nimprove computing efficiency in applying the DQ and HDQ methods for these\ncases.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0207034v1"
    },
    {
        "title": "Parameterized Type Definitions in Mathematica: Methods and Advantages",
        "authors": [
            "Alina Andreica"
        ],
        "category": "cs.SC",
        "published_year": "2002",
        "summary": "  The theme of symbolic computation in algebraic categories has become of\nutmost importance in the last decade since it enables the automatic modeling of\nmodern algebra theories. On this theoretical background, the present paper\nreveals the utility of the parameterized categorical approach by deriving a\nmultivariate polynomial category (over various coefficient domains), which is\nused by our Mathematica implementation of Buchberger's algorithms for\ndetermining the Groebner basis. These implementations are designed according to\ndomain and category parameterization principles underlining their advantages:\noperation protection, inheritance, generality, easy extendibility. In\nparticular, such an extension of Mathematica, a widely used symbolic\ncomputation system, with a new type system has a certain practical importance.\nThe approach we propose for Mathematica is inspired from D. Gruntz and M.\nMonagan's work in Gauss, for Maple.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0208031v1"
    },
    {
        "title": "Size reduction and partial decoupling of systems of equations",
        "authors": [
            "Thomas Wolf"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  A method is presented that reduces the number of terms of systems of linear\nequations (algebraic, ordinary and partial differential equations). As a\nbyproduct these systems have a tendency to become partially decoupled and are\nmore likely to be factorizable or integrable. A variation of this method is\napplicable to non-linear systems. Modifications to improve efficiency are given\nand examples are shown. This procedure can be used in connection with the\ncomputation of the radical of a differential ideal (differential Groebner\nbasis).\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0301029v1"
    },
    {
        "title": "TCTL Inevitability Analysis of Dense-time Systems",
        "authors": [
            "Farn Wang",
            "Geng-Dian Hwang",
            "Fang Yu"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  Inevitability properties in branching temporal logics are of the syntax\nforall eventually \\phi, where \\phi is an arbitrary (timed) CTL formula. In the\nsense that \"good things will happen\", they are parallel to the \"liveness\"\nproperties in linear temporal logics. Such inevitability properties in\ndense-time logics can be analyzed with greatest fixpoint calculation. We\npresent algorithms to model-check inevitability properties both with and\nwithout requirement of non-Zeno computations. We discuss a technique for early\ndecision on greatest fixpoints in the temporal logics, and experiment with the\neffect of non-Zeno computations on the evaluation of greatest fixpoints. We\nalso discuss the TCTL subclass with only universal path quantifiers which\nallows for the safe abstraction analysis of inevitability properties. Finally,\nwe report our implementation and experiments to show the plausibility of our\nideas.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0304003v2"
    },
    {
        "title": "Quasi-Optimal Arithmetic for Quaternion Polynomials",
        "authors": [
            "Martin Ziegler"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  Fast algorithms for arithmetic on real or complex polynomials are well-known\nand have proven to be not only asymptotically efficient but also very\npractical. Based on Fast Fourier Transform (FFT), they for instance multiply\ntwo polynomials of degree up to N or multi-evaluate one at N points\nsimultaneously within quasi-linear time O(N.polylog N). An extension to (and in\nfact the mere definition of) polynomials over the skew-field H of quaternions\nis promising but still missing. The present work proposes three such\ndefinitions which in the commutative case coincide but for H turn out to\ndiffer, each one satisfying some desirable properties while lacking others. For\neach notion we devise algorithms for according arithmetic; these are\nquasi-optimal in that their running times match lower complexity bounds up to\npolylogarithmic factors.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0304004v2"
    },
    {
        "title": "Digital Version of Green`s Theorem and its Application to The Coverage\n  Problem in Formal Verification",
        "authors": [
            "Eli Appleboim",
            "Emil Saucan"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  We present a novel scheme to the coverage problem, introducing a quantitative\nway to estimate the interaction between a block and its enviroment.This is\nachieved by setting a discrete version of Green`s theorem, specially adapted\nfor Model Checking based verification of integrated circuits.This method is\nbest suited for the coverage problem since it enables one to quantify the\nincompleteness or, on the other hand, the redundancy of a set of rules,\ndescribing the model under verification.Moreover this can be done continuously\nthroughout the verification process, thus enabling the user to pinpoint the\nstages at which incompleteness/redundancy occurs. Although the method is\npresented locally on a small hardware example, we additionally show its\npossibility to provide precise coverage estimation also for large scale\nsystems. We compare this method to others by checking it on the same\ntest-cases.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0309008v1"
    },
    {
        "title": "Efficient dot product over word-size finite fields",
        "authors": [
            "Jean-Guillaume Dumas"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  We want to achieve efficiency for the exact computation of the dot product of\ntwo vectors over word-size finite fields. We therefore compare the practical\nbehaviors of a wide range of implementation techniques using different\nrepresentations. The techniques used include oating point representations,\ndiscrete logarithms, tabulations, Montgomery reduction, delayed modulus.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0404008v2"
    },
    {
        "title": "An unexpected application of minimization theory to module\n  decompositions",
        "authors": [
            "Gerard Duchamp",
            "Hatem Hadj Kacem",
            "Eric Laugerotte"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  The aim of this work is to show how we can decompose a module (if\ndecomposable) into an indecomposable module with the help of the minimization\nprocess.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0405060v1"
    },
    {
        "title": "A novel approach to symbolic algebra",
        "authors": [
            "Thomas Fischbacher"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  A prototype for an extensible interactive graphical term manipulation system\nis presented that combines pattern matching and nondeterministic evaluation to\nprovide a convenient framework for doing tedious algebraic manipulations that\nso far had to be done manually in a semi-automatic fashion.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0406002v1"
    },
    {
        "title": "FORM Matters: Fast Symbolic Computation under UNIX",
        "authors": [
            "Michael M. Tung"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  We give a brief introduction to FORM, a symbolic programming language for\nmassive batch operations, designed by J.A.M. Vermaseren. In particular, we\nstress various methods to efficiently use FORM under the UNIX operating system.\nSeveral scripts and examples are given, and suggestions on how to use the vim\neditor as development platform.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0409048v1"
    },
    {
        "title": "From Tensor Equations to Numerical Code -- Computer Algebra Tools for\n  Numerical Relativity",
        "authors": [
            "Christiane Lechner",
            "Dana Alic",
            "Sascha Husa"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  In this paper we present our recent work in developing a computer-algebra\ntool for systems of partial differential equations (PDEs), termed \"Kranc\". Our\nwork is motivated by the problem of finding solutions of the Einstein equations\nthrough numerical simulations. Kranc consists of Mathematica based\ncomputer-algebra packages, that facilitate the task of dealing with symbolic\ntensorial calculations and realize the conversion of systems of partial\ndifferential evolution equations into parallelized C or Fortran code.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0411063v1"
    },
    {
        "title": "Jordan Normal and Rational Normal Form Algorithms",
        "authors": [
            "Bernard Parisse",
            "Morgane Vaughan"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  In this paper, we present a determinist Jordan normal form algorithms based\non the Fadeev formula: \\[(\\lambda \\cdot I-A) \\cdot B(\\lambda)=P(\\lambda) \\cdot\nI\\] where $B(\\lambda)$ is $(\\lambda \\cdot I-A)$'s comatrix and $P(\\lambda)$ is\n$A$'s characteristic polynomial. This rational Jordan normal form algorithm\ndiffers from usual algorithms since it is not based on the Frobenius/Smith\nnormal form but rather on the idea already remarked in Gantmacher that the\nnon-zero column vectors of $B(\\lambda_0)$ are eigenvectors of $A$ associated to\n$\\lambda_0$ for any root $\\lambda_0$ of the characteristical polynomial. The\ncomplexity of the algorithm is $O(n^4)$ field operations if we know the\nfactorization of the characteristic polynomial (or $O(n^5 \\ln(n))$ operations\nfor a matrix of integers of fixed size). This algorithm has been implemented\nusing the Maple and Giac/Xcas computer algebra systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0412005v1"
    },
    {
        "title": "Efficient Computation of the Characteristic Polynomial",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clément Pernet",
            "Zhendong Wan"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  This article deals with the computation of the characteristic polynomial of\ndense matrices over small finite fields and over the integers. We first present\ntwo algorithms for the finite fields: one is based on Krylov iterates and\nGaussian elimination. We compare it to an improvement of the second algorithm\nof Keller-Gehrig. Then we show that a generalization of Keller-Gehrig's third\nalgorithm could improve both complexity and computational time. We use these\nresults as a basis for the computation of the characteristic polynomial of\ninteger matrices. We first use early termination and Chinese remaindering for\ndense matrices. Then a probabilistic approach, based on integer minimal\npolynomial and Hensel factorization, is particularly well suited to sparse\nand/or structured matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0501074v2"
    },
    {
        "title": "Tensor manipulation in GPL Maxima",
        "authors": [
            "Viktor Toth"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  GPL Maxima is an open-source computer algebra system based on DOE-MACSYMA.\nGPL Maxima included two tensor manipulation packages from DOE-MACSYMA, but\nthese were in various states of disrepair. One of the two packages, CTENSOR,\nimplemented component-based tensor manipulation; the other, ITENSOR, treated\ntensor symbols as opaque, manipulating them based on their index properties.\nThe present paper describes the state in which these packages were found, the\nsteps that were needed to make the packages fully functional again, and the new\nfunctionality that was implemented to make them more versatile. A third\npackage, ATENSOR, was also implemented; fully compatible with the identically\nnamed package in the commercial version of MACSYMA, ATENSOR implements abstract\ntensor algebras.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0503073v2"
    },
    {
        "title": "Towards a diagrammatic modeling of the LinBox C++ linear algebra library",
        "authors": [
            "Jean-Guillaume Dumas",
            "Dominique Duval"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We propose a new diagrammatic modeling language, DML. The paradigm used is\nthat of the category theory and in particular of the pushout tool. We show that\nmost of the object-oriented structures can be described with this tool and have\nmany examples in C++, ranging from virtual inheritance and polymorphism to\ntemplate genericity. With this powerful tool, we propose a quite simple\ndescription of the C++ LinBox library. This library has been designed for\nefficiency and genericity and therefore makes heavy usage of complex template\nand polymorphic mecanism. Be reverse engineering, we are able to describe in a\nsimple manner the complex structure of archetypes in LinBox.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0510057v1"
    },
    {
        "title": "ParFORM: recent development",
        "authors": [
            "M. Tentyukov",
            "J. A. M. Vermaseren",
            "H. M. Staudenmaier"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We report on the status of our project of parallelization of the symbolic\nmanipulation program FORM. We have now parallel versions of FORM running on\nCluster- or SMP-architectures. These versions can be used to run arbitrary FORM\nprograms in parallel.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0510093v1"
    },
    {
        "title": "Fast (Multi-)Evaluation of Linearly Recurrent Sequences: Improvements\n  and Applications",
        "authors": [
            "Martin Ziegler"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  For a linearly recurrent vector sequence P[n+1] = A(n) * P[n], consider the\nproblem of calculating either the n-th term P[n] or L<=n arbitrary terms\nP[n_1],...,P[n_L], both for the case of constant coefficients A(n)=A and for a\nmatrix A(n) with entries polynomial in n. We improve and extend known\nalgorithms for this problem and present new applications for it. Specifically\nit turns out that for instance * any family (p_n) of classical orthogonal\npolynomials admits evaluation at given x within O(n^{1/2} log n) operations\nINDEPENDENT of the family (p_n) under consideration. * For any L indices\nn_1,...,n_L <= n, the values p_{n_i}(x) can be calculated simultaneously using\nO(n^{1/2} log n + L log(n/L)) arithmetic operations; again this running time\nbound holds uniformly. * Every hypergeometric (or, more generally, holonomic)\nfunction admits approximate evaluation up to absolute error e>0 within\nO((log(1/e)^{1/2} loglog(1/e)) -- as opposed to O(log(1/e)) -- arithmetic\nsteps. * Given m and a polynomial p of degree d over a field of characteristic\nzero, the coefficient of p^m to term X^n can be computed within O(d^2\nM(n^{1/2})) steps where M(n) denotes the cost of multiplying two degree-n\npolynomials. * The same time bound holds for the joint calculation of any\nL<=n^{1/2} desired coefficients of p^m to terms X^{n_i}, n_1,...,n_L <= n.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0511033v1"
    },
    {
        "title": "An introspective algorithm for the integer determinant",
        "authors": [
            "Jean-Guillaume Dumas",
            "Anna Urbanska"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We present an algorithm computing the determinant of an integer matrix A. The\nalgorithm is introspective in the sense that it uses several distinct\nalgorithms that run in a concurrent manner. During the course of the algorithm\npartial results coming from distinct methods can be combined. Then, depending\non the current running time of each method, the algorithm can emphasize a\nparticular variant. With the use of very fast modular routines for linear\nalgebra, our implementation is an order of magnitude faster than other existing\nimplementations. Moreover, we prove that the expected complexity of our\nalgorithm is only O(n^3 log^{2.5}(n ||A||)) bit operations in the dense case\nand O(Omega n^{1.5} log^2(n ||A||) + n^{2.5}log^3(n||A||)) in the sparse case,\nwhere ||A|| is the largest entry in absolute value of the matrix and Omega is\nthe cost of matrix-vector multiplication in the case of a sparse matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0511066v5"
    },
    {
        "title": "Dense Linear Algebra over Finite Fields: the FFLAS and FFPACK packages",
        "authors": [
            "Jean-Guillaume Dumas",
            "Pascal Giorgi",
            "Clément Pernet"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  In the past two decades, some major efforts have been made to reduce exact\n(e.g. integer, rational, polynomial) linear algebra problems to matrix\nmultiplication in order to provide algorithms with optimal asymptotic\ncomplexity. To provide efficient implementations of such algorithms one need to\nbe careful with the underlying arithmetic. It is well known that modular\ntechniques such as the Chinese remainder algorithm or the p-adic lifting allow\nvery good practical performance, especially when word size arithmetic are used.\nTherefore, finite field arithmetic becomes an important core for efficient\nexact linear algebra libraries. In this paper, we study high performance\nimplementations of basic linear algebra routines over word size prime fields:\nspecially the matrix multiplication; our goal being to provide an exact\nalternate to the numerical BLAS library. We show that this is made possible by\na carefull combination of numerical computations and asymptotically faster\nalgorithms. Our kernel has several symbolic linear algebra applications enabled\nby diverse matrix multiplication reductions: symbolic triangularization, system\nsolving, determinant and matrix inverse implementations are thus studied.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0601133v3"
    },
    {
        "title": "Computing spectral sequences",
        "authors": [
            "A. Romero",
            "J. Rubio",
            "F. Sergeraert"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  In this paper, a set of programs enhancing the Kenzo system is presented.\nKenzo is a Common Lisp program designed for computing in Algebraic Topology, in\nparticular it allows the user to calculate homology and homotopy groups of\ncomplicated spaces. The new programs presented here entirely compute Serre and\nEilenberg-Moore spectral sequences, in particular the groups and differential\nmaps for arbitrary r. They also determine when the spectral sequence has\nconverged and describe the filtration of the target homology groups induced by\nthe spectral sequence.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0602064v1"
    },
    {
        "title": "Solving Sparse Integer Linear Systems",
        "authors": [
            "Wayne Eberly",
            "Mark Giesbrecht",
            "Pascal Giorgi",
            "Arne Storjohann",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  We propose a new algorithm to solve sparse linear systems of equations over\nthe integers. This algorithm is based on a $p$-adic lifting technique combined\nwith the use of block matrices with structured blocks. It achieves a sub-cubic\ncomplexity in terms of machine operations subject to a conjecture on the\neffectiveness of certain sparse projections. A LinBox-based implementation of\nthis algorithm is demonstrated, and emphasizes the practical benefits of this\nnew method over the previous state of the art.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603082v1"
    },
    {
        "title": "Polynomial Time Nondimensionalisation of Ordinary Differential Equations\n  via their Lie Point Symmetries",
        "authors": [
            "Évelyne Hubert",
            "Alexandre Sedoglavic"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  Lie group theory states that knowledge of a $m$-parameters solvable group of\nsymmetries of a system of ordinary differential equations allows to reduce by\n$m$ the number of equation. We apply this principle by finding dilatations and\ntranslations that are Lie point symmetries of considered ordinary differential\nsystem. By rewriting original problem in an invariant coordinates set for these\nsymmetries, one can reduce the involved number of parameters. This process is\nclassically call nondimensionalisation in dimensional analysis. We present an\nalgorithm based on this standpoint and show that its arithmetic complexity is\npolynomial in input's size.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604060v1"
    },
    {
        "title": "Fast computation of power series solutions of systems of differential\n  equations",
        "authors": [
            "Alin Bostan",
            "Frédéric Chyzak",
            "François Ollivier",
            "Bruno Salvy",
            "Éric Schost",
            "Alexandre Sedoglavic"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  We propose new algorithms for the computation of the first N terms of a\nvector (resp. a basis) of power series solutions of a linear system of\ndifferential equations at an ordinary point, using a number of arithmetic\noperations which is quasi-linear with respect to N. Similar results are also\ngiven in the non-linear case. This extends previous results obtained by Brent\nand Kung for scalar differential equations of order one and two.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604101v1"
    },
    {
        "title": "SAT Techniques for Lexicographic Path Orders",
        "authors": [
            "Harald Zankl"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  This seminar report is concerned with expressing LPO-termination of term\nrewrite systems as a satisfiability problem in propositional logic. After\nrelevant algorithms are explained, experimental results are reported.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605021v1"
    },
    {
        "title": "Low Complexity Algorithms for Linear Recurrences",
        "authors": [
            "Alin Bostan",
            "Frédéric Chyzak",
            "Bruno Salvy",
            "Thomas Cluzeau"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  We consider two kinds of problems: the computation of polynomial and rational\nsolutions of linear recurrences with coefficients that are polynomials with\ninteger coefficients; indefinite and definite summation of sequences that are\nhypergeometric over the rational numbers. The algorithms for these tasks all\ninvolve as an intermediate quantity an integer $N$ (dispersion or root of an\nindicial polynomial) that is potentially exponential in the bit size of their\ninput. Previous algorithms have a bit complexity that is at least quadratic in\n$N$. We revisit them and propose variants that exploit the structure of\nsolutions and avoid expanding polynomials of degree $N$. We give two\nalgorithms: a probabilistic one that detects the existence or absence of\nnonzero polynomial and rational solutions in $O(\\sqrt{N}\\log^{2}N)$ bit\noperations; a deterministic one that computes a compact representation of the\nsolution in $O(N\\log^{3}N)$ bit operations. Similar speed-ups are obtained in\nindefinite and definite hypergeometric summation. We describe the results of an\nimplementation.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605068v1"
    },
    {
        "title": "Complexity of Resolution of Parametric Systems of Polynomial Equations\n  and Inequations",
        "authors": [
            "Guillaume Moroz"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  Consider a system of n polynomial equations and r polynomial inequations in n\nindeterminates of degree bounded by d with coefficients in a polynomial ring of\ns parameters with rational coefficients of bit-size at most $\\sigma$. From the\nreal viewpoint, solving such a system often means describing some\nsemi-algebraic sets in the parameter space over which the number of real\nsolutions of the considered parametric system is constant. Following the works\nof Lazard and Rouillier, this can be done by the computation of a discriminant\nvariety. In this report we focus on the case where for a generic specialization\nof the parameters the system of equations generates a radical zero-dimensional\nideal, which is usual in the applications. In this case, we provide a\ndeterministic method computing the minimal discriminant variety reducing the\nproblem to a problem of elimination. Moreover, we prove that the degree of the\ncomputed minimal discriminant variety is bounded by $D:=(n+r)d^{(n+1)}$ and\nthat the complexity of our method is $\\sigma^{\\mathcal{O}(1)}\nD^{\\mathcal{O}(n+s)}$ bit-operations on a deterministic Turing machine.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0606031v1"
    },
    {
        "title": "Strong bi-homogeneous Bézout theorem and its use in effective real\n  algebraic geometry",
        "authors": [
            "Mohab Safey El Din",
            "Philippe Trebuchet"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  Let f1, ..., fs be a polynomial family in Q[X1,..., Xn] (with s less than n)\nof degree bounded by D. Suppose that f1, ..., fs generates a radical ideal, and\ndefines a smooth algebraic variety V. Consider a projection P. We prove that\nthe degree of the critical locus of P restricted to V is bounded by\nD^s(D-1)^(n-s) times binomial of n and n-s. This result is obtained in two\nsteps. First the critical points of P restricted to V are characterized as\nprojections of the solutions of Lagrange's system for which a bi-homogeneous\nstructure is exhibited. Secondly we prove a bi-homogeneous B\\'ezout Theorem,\nwhich bounds the sum of the degrees of the equidimensional components of the\nradical of an ideal generated by a bi-homogeneous polynomial family. This\nresult is improved when f1,..., fs is a regular sequence. Moreover, we use\nLagrange's system to design an algorithm computing at least one point in each\nconnected component of a smooth real algebraic set. This algorithm generalizes,\nto the non equidimensional case, the one of Safey El Din and Schost. The\nevaluation of the output size of this algorithm gives new upper bounds on the\nfirst Betti number of a smooth real algebraic set. Finally, we estimate its\narithmetic complexity and prove that in the worst cases it is polynomial in n,\ns, D^s(D-1)^(n-s) and the binomial of n and n-s, and the complexity of\nevaluation of f1,..., fs.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0610051v2"
    },
    {
        "title": "Bounds on the coefficients of the characteristic and minimal polynomials",
        "authors": [
            "Jean-Guillaume Dumas"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  This note presents absolute bounds on the size of the coefficients of the\ncharacteristic and minimal polynomials depending on the size of the\ncoefficients of the associated matrix. Moreover, we present algorithms to\ncompute more precise input-dependant bounds on these coefficients. Such bounds\nare e.g. useful to perform deterministic chinese remaindering of the\ncharacteristic or minimal polynomial of an integer matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0610136v4"
    },
    {
        "title": "Groebner Bases Applied to Systems of Linear Difference Equations",
        "authors": [
            "V. P. Gerdt"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  In this paper we consider systems of partial (multidimensional) linear\ndifference equations. Specifically, such systems arise in scientific computing\nunder discretization of linear partial differential equations and in\ncomputational high energy physics as recurrence relations for multiloop Feynman\nintegrals. The most universal algorithmic tool for investigation of linear\ndifference systems is based on their transformation into an equivalent Groebner\nbasis form. We present an algorithm for this transformation implemented in\nMaple. The algorithm and its implementation can be applied to automatic\ngeneration of difference schemes for linear partial differential equations and\nto reduction of Feynman integrals. Some illustrative examples are given.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0611041v1"
    },
    {
        "title": "Reduction of Algebraic Parametric Systems by Rectification of their\n  Affine Expanded Lie Symmetries",
        "authors": [
            "Alexandre Sedoglavic"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  Lie group theory states that knowledge of a $m$-parameters solvable group of\nsymmetries of a system of ordinary differential equations allows to reduce by\n$m$ the number of equations. We apply this principle by finding some\n\\emph{affine derivations} that induces \\emph{expanded} Lie point symmetries of\nconsidered system. By rewriting original problem in an invariant coordinates\nset for these symmetries, we \\emph{reduce} the number of involved parameters.\nWe present an algorithm based on this standpoint whose arithmetic complexity is\n\\emph{quasi-polynomial} in input's size.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0612094v1"
    },
    {
        "title": "Symmetric Subresultants and Applications",
        "authors": [
            "Cyril Brunie",
            "Philippe Saux Picart"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  Schur's transforms of a polynomial are used to count its roots in the unit\ndisk. These are generalized them by introducing the sequence of symmetric\nsub-resultants of two polynomials. Although they do have a determinantal\ndefinition, we show that they satisfy a structure theorem which allows us to\ncompute them with a type of Euclidean division. As a consequence, a fast\nalgorithm based on a dichotomic process and FFT is designed. We prove also that\nthese symmetric sub-resultants have a deep link with Toeplitz matrices.\nFinally, we propose a new algorithm of inversion for such matrices. It has the\nsame cost as those already known, however it is fraction-free and consequently\nwell adapted to computer algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0612119v2"
    },
    {
        "title": "Time- and Space-Efficient Evaluation of Some Hypergeometric Constants",
        "authors": [
            "Howard Cheng",
            "Guillaume Hanrot",
            "Emmanuel Thomé",
            "Eugene Zima",
            "Paul Zimmermann"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  The currently best known algorithms for the numerical evaluation of\nhypergeometric constants such as $\\zeta(3)$ to $d$ decimal digits have time\ncomplexity $O(M(d) \\log^2 d)$ and space complexity of $O(d \\log d)$ or $O(d)$.\nFollowing work from Cheng, Gergel, Kim and Zima, we present a new algorithm\nwith the same asymptotic complexity, but more efficient in practice. Our\nimplementation of this algorithm improves slightly over existing programs for\nthe computation of $\\pi$, and we announce a new record of 2 billion digits for\n$\\zeta(3)$.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0701151v1"
    },
    {
        "title": "Towards a New ODE Solver Based on Cartan's Equivalence Method",
        "authors": [
            "R. Dridi",
            "M. Petitot"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  The aim of the present paper is to propose an algorithm for a new ODE--solver\nwhich should improve the abilities of current solvers to handle second order\ndifferential equations. The paper provides also a theoretical result revealing\nthe relationship between the change of coordinates, that maps the generic\nequation to a given target equation, and the symmetry $\\D$-groupoid of this\ntarget.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0702065v2"
    },
    {
        "title": "Formal proof for delayed finite field arithmetic using floating point\n  operators",
        "authors": [
            "Sylvie Boldo",
            "Marc Daumas",
            "Pascal Giorgi"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  Formal proof checkers such as Coq are capable of validating proofs of\ncorrection of algorithms for finite field arithmetics but they require\nextensive training from potential users. The delayed solution of a triangular\nsystem over a finite field mixes operations on integers and operations on\nfloating point numbers. We focus in this report on verifying proof obligations\nthat state that no round off error occurred on any of the floating point\noperations. We use a tool named Gappa that can be learned in a matter of\nminutes to generate proofs related to floating point arithmetic and hide\ntechnicalities of formal proof checkers. We found that three facilities are\nmissing from existing tools. The first one is the ability to use in Gappa new\nlemmas that cannot be easily expressed as rewriting rules. We coined the second\none ``variable interchange'' as it would be required to validate loop\ninterchanges. The third facility handles massive loop unrolling and argument\ninstantiation by generating traces of execution for a large number of cases. We\nhope that these facilities may sometime in the future be integrated into\nmainstream code validation.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703026v3"
    },
    {
        "title": "Towards an exact adaptive algorithm for the determinant of a rational\n  matrix",
        "authors": [
            "Anna Urbanska"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  In this paper we propose several strategies for the exact computation of the\ndeterminant of a rational matrix. First, we use the Chinese Remaindering\nTheorem and the rational reconstruction to recover the rational determinant\nfrom its modular images. Then we show a preconditioning for the determinant\nwhich allows us to skip the rational reconstruction process and reconstruct an\ninteger result. We compare those approaches with matrix preconditioning which\nallow us to treat integer instead of rational matrices. This allows us to\nintroduce integer determinant algorithms to the rational determinant problem.\nIn particular, we discuss the applicability of the adaptive determinant\nalgorithm of [9] and compare it with the integer Chinese Remaindering scheme.\nWe present an analysis of the complexity of the strategies and evaluate their\nexperimental performance on numerous examples. This experience allows us to\ndevelop an adaptive strategy which would choose the best solution at the run\ntime, depending on matrix properties. All strategies have been implemented in\nLinBox linear algebra library.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.0014v1"
    },
    {
        "title": "Q-adic Transform revisited",
        "authors": [
            "Jean-Guillaume Dumas"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  We present an algorithm to perform a simultaneous modular reduction of\nseveral residues. This algorithm is applied fast modular polynomial\nmultiplication. The idea is to convert the $X$-adic representation of modular\npolynomials, with $X$ an indeterminate, to a $q$-adic representation where $q$\nis an integer larger than the field characteristic. With some control on the\ndifferent involved sizes it is then possible to perform some of the $q$-adic\narithmetic directly with machine integers or floating points. Depending also on\nthe number of performed numerical operations one can then convert back to the\n$q$-adic or $X$-adic representation and eventually mod out high residues. In\nthis note we present a new version of both conversions: more tabulations and a\nway to reduce the number of divisions involved in the process are presented.\nThe polynomial multiplication is then applied to arithmetic in small finite\nfield extensions.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.0510v5"
    },
    {
        "title": "Reconstruction of eye movements during blinks",
        "authors": [
            "M. S. Baptista",
            "C. Bohn",
            "R. Kliegl",
            "R. Engbert",
            "J. Kurths"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In eye movement research in reading, the amount of data plays a crucial role\nfor the validation of results. A methodological problem for the analysis of the\neye movement in reading are blinks, when readers close their eyes. Blinking\nrate increases with increasing reading time, resulting in high data losses,\nespecially for older adults or reading impaired subjects. We present a method,\nbased on the symbolic sequence dynamics of the eye movements, that reconstructs\nthe horizontal position of the eyes while the reader blinks. The method makes\nuse of an observed fact that the movements of the eyes before closing or after\nopening contain information about the eyes movements during blinks. Test\nresults indicate that our reconstruction method is superior to methods that use\nsimpler interpolation approaches. In addition, analyses of the reconstructed\ndata show no significant deviation from the usual behavior observed in readers.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.2201v2"
    },
    {
        "title": "Compressed Modular Matrix Multiplication",
        "authors": [
            "Jean-Guillaume Dumas",
            "Laurent Fousse",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We propose to store several integers modulo a small prime into a single\nmachine word. Modular addition is performed by addition and possibly\nsubtraction of a word containing several times the modulo. Modular\nMultiplication is not directly accessible but modular dot product can be\nperformed by an integer multiplication by the reverse integer. Modular\nmultiplication by a word containing a single residue is a also possible.\nTherefore matrix multiplication can be performed on such a compressed storage.\nWe here give bounds on the sizes of primes and matrices for which such a\ncompression is possible. We also explicit the details of the required\ncompressed arithmetic routines.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.1975v1"
    },
    {
        "title": "Towards a Symbolic-Numeric Method to Compute Puiseux Series: The Modular\n  Part",
        "authors": [
            "Adrien Poteaux",
            "Marc Rybowicz"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We have designed a new symbolic-numeric strategy to compute efficiently and\naccurately floating point Puiseux series defined by a bivariate polynomial over\nan algebraic number field. In essence, computations modulo a well chosen prime\n$p$ are used to obtain the exact information required to guide floating point\ncomputations. In this paper, we detail the symbolic part of our algorithm:\nFirst of all, we study modular reduction of Puiseux series and give a good\nreduction criterion to ensure that the information required by the numerical\npart is preserved. To establish our results, we introduce a simple modification\nof classical Newton polygons, that we call \"generic Newton polygons\", which\nhappen to be very convenient. Then, we estimate the arithmetic complexity of\ncomputing Puiseux series over finite fields and improve known bounds. Finally,\nwe give bit-complexity bounds for deterministic and randomized versions of the\nsymbolic part. The details of the numerical part will be described in a\nforthcoming paper.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.3027v1"
    },
    {
        "title": "Products of Ordinary Differential Operators by Evaluation and\n  Interpolation",
        "authors": [
            "Alin Bostan",
            "Frédéric Chyzak",
            "Nicolas Le Roux"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  It is known that multiplication of linear differential operators over ground\nfields of characteristic zero can be reduced to a constant number of matrix\nproducts. We give a new algorithm by evaluation and interpolation which is\nfaster than the previously-known one by a constant factor, and prove that in\ncharacteristic zero, multiplication of differential operators and of matrices\nare computationally equivalent problems. In positive characteristic, we show\nthat differential operators can be multiplied in nearly optimal time.\nTheoretical results are validated by intensive experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.2181v1"
    },
    {
        "title": "Power Series Composition and Change of Basis",
        "authors": [
            "Alin Bostan",
            "Bruno Salvy",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  Efficient algorithms are known for many operations on truncated power series\n(multiplication, powering, exponential, ...). Composition is a more complex\ntask. We isolate a large class of power series for which composition can be\nperformed efficiently. We deduce fast algorithms for converting polynomials\nbetween various bases, including Euler, Bernoulli, Fibonacci, and the\northogonal Laguerre, Hermite, Jacobi, Krawtchouk, Meixner and\nMeixner-Pollaczek.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.2337v1"
    },
    {
        "title": "Fast Conversion Algorithms for Orthogonal Polynomials",
        "authors": [
            "Alin Bostan",
            "Bruno Salvy",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We discuss efficient conversion algorithms for orthogonal polynomials. We\ndescribe a known conversion algorithm from an arbitrary orthogonal basis to the\nmonomial basis, and deduce a new algorithm of the same complexity for the\nconverse operation.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.2373v1"
    },
    {
        "title": "A local construction of the Smith normal form of a matrix polynomial",
        "authors": [
            "Jon Wilkening",
            "Jia Yu"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We present an algorithm for computing a Smith form with multipliers of a\nregular matrix polynomial over a field. This algorithm differs from previous\nones in that it computes a local Smith form for each irreducible factor in the\ndeterminant separately and then combines them into a global Smith form, whereas\nother algorithms apply a sequence of unimodular row and column operations to\nthe original matrix. The performance of the algorithm in exact arithmetic is\nreported for several test cases.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.2978v2"
    },
    {
        "title": "How to turn a scripting language into a domain specific language for\n  computer algebra",
        "authors": [
            "Raphael Jolly",
            "Heinz Kredel"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We have developed two computer algebra systems, meditor [Jolly:2007] and JAS\n[Kredel:2006]. These CAS systems are available as Java libraries. For the\nuse-case of interactively entering and manipulating mathematical expressions,\nthere is a need of a scripting front-end for our libraries. Most other CAS\ninvent and implement their own scripting interface for this purpose. We,\nhowever, do not want to reinvent the wheel and propose to use a contemporary\nscripting language with access to Java code. In this paper we discuss the\nrequirements for a scripting language in computer algebra and check whether the\nlanguages Python, Ruby, Groovy and Scala meet these requirements. We conclude\nthat, with minor problems, any of these languages is suitable for our purpose.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.1061v2"
    },
    {
        "title": "Stable normal forms for polynomial system solving",
        "authors": [
            "Bernard Mourrain",
            "Philippe Trébuchet"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  This paper describes and analyzes a method for computing border bases of a\nzero-dimensional ideal $I$. The criterion used in the computation involves\nspecific commutation polynomials and leads to an algorithm and an\nimplementation extending the one provided in [MT'05]. This general border basis\nalgorithm weakens the monomial ordering requirement for \\grob bases\ncomputations. It is up to date the most general setting for representing\nquotient algebras, embedding into a single formalism Gr\\\"obner bases, Macaulay\nbases and new representation that do not fit into the previous categories. With\nthis formalism we show how the syzygies of the border basis are generated by\ncommutation relations. We also show that our construction of normal form is\nstable under small perturbations of the ideal, if the number of solutions\nremains constant. This new feature for a symbolic algorithm has a huge impact\non the practical efficiency as it is illustrated by the experiments on\nclassical benchmark polynomial systems, at the end of the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.0067v1"
    },
    {
        "title": "Moment matrices, trace matrices and the radical of ideals",
        "authors": [
            "Itnuit Janovitz-Freireich",
            "Agnes Szanto",
            "Bernard Mourrain",
            "Lajos Ronyai"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  Let $f_1,...,f_s \\in \\mathbb{K}[x_1,...,x_m]$ be a system of polynomials\ngenerating a zero-dimensional ideal $\\I$, where $\\mathbb{K}$ is an arbitrary\nalgebraically closed field. Assume that the factor algebra\n$\\A=\\mathbb{K}[x_1,...,x_m]/\\I$ is Gorenstein and that we have a bound\n$\\delta>0$ such that a basis for $\\A$ can be computed from multiples of\n$f_1,...,f_s$ of degrees at most $\\delta$. We propose a method using Sylvester\nor Macaulay type resultant matrices of $f_1,...,f_s$ and $J$, where $J$ is a\npolynomial of degree $\\delta$ generalizing the Jacobian, to compute moment\nmatrices, and in particular matrices of traces for $\\A$. These matrices of\ntraces in turn allow us to compute a system of multiplication matrices\n$\\{M_{x_i}|i=1,...,m\\}$ of the radical $\\sqrt{\\I}$, following the approach in\nthe previous work by Janovitz-Freireich, R\\'{o}nyai and Sz\\'ant\\'o.\nAdditionally, we give bounds for $\\delta$ for the case when $\\I$ has finitely\nmany projective roots in $\\mathbb{P}^m_\\CC$.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.0088v1"
    },
    {
        "title": "Detecting lacunary perfect powers and computing their roots",
        "authors": [
            "Mark Giesbrecht",
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We consider solutions to the equation f = h^r for polynomials f and h and\ninteger r > 1. Given a polynomial f in the lacunary (also called sparse or\nsuper-sparse) representation, we first show how to determine if f can be\nwritten as h^r and, if so, to find such an r. This is a Monte Carlo randomized\nalgorithm whose cost is polynomial in the number of non-zero terms of f and in\nlog(deg f), i.e., polynomial in the size of the lacunary representation, and it\nworks over GF(q)[x] (for large characteristic) as well as Q[x]. We also give\ntwo deterministic algorithms to compute the perfect root h given f and r. The\nfirst is output-sensitive (based on the sparsity of h) and works only over\nQ[x]. A sparsity-sensitive Newton iteration forms the basis for the second\napproach to computing h, which is extremely efficient and works over both\nGF(q)[x] (for large characteristic) and Q[x], but depends on a number-theoretic\nconjecture. Work of Erdos, Schinzel, Zannier, and others suggests that both of\nthese algorithms are unconditionally polynomial-time in the lacunary size of\nthe input polynomial f. Finally, we demonstrate the efficiency of the\nrandomized detection algorithm and the latter perfect root computation\nalgorithm with an implementation in the C++ library NTL.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.1848v2"
    },
    {
        "title": "Fast algorithms for differential equations in positive characteristic",
        "authors": [
            "Alin Bostan",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We address complexity issues for linear differential equations in\ncharacteristic $p>0$: resolution and computation of the $p$-curvature. For\nthese tasks, our main focus is on algorithms whose complexity behaves well with\nrespect to $p$. We prove bounds linear in $p$ on the degree of polynomial\nsolutions and propose algorithms for testing the existence of polynomial\nsolutions in sublinear time $\\tilde{O}(p^{1/2})$, and for determining a whole\nbasis of the solution space in quasi-linear time $\\tilde{O}(p)$; the\n$\\tilde{O}$ notation indicates that we hide logarithmic factors. We show that\nfor equations of arbitrary order, the $p$-curvature can be computed in\nsubquadratic time $\\tilde{O}(p^{1.79})$, and that this can be improved to\n$O(\\log(p))$ for first order equations and to $\\tilde{O}(p)$ for classes of\nsecond order equations.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.3843v1"
    },
    {
        "title": "On finding multiplicities of characteristic polynomial factors of\n  black-box matrices",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clément Pernet",
            "B. David Saunders"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We present algorithms and heuristics to compute the characteristic polynomial\nof a matrix given its minimal polynomial. The matrix is represented as a\nblack-box, i.e., by a function to compute its matrix-vector product. The\nmethods apply to matrices either over the integers or over a large enough\nfinite field. Experiments show that these methods perform efficiently in\npractice. Combined in an adaptive strategy, these algorithms reach significant\nspeedups in practice for some integer matrices arising in an application from\ngraph theory.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.4747v2"
    },
    {
        "title": "A baby steps/giant steps Monte Carlo algorithm for computing roadmaps in\n  smooth compact real hypersurfaces",
        "authors": [
            "Mohab Safey El Din",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We consider the problem of constructing roadmaps of real algebraic sets. The\nproblem was introduced by Canny to answer connectivity questions and solve\nmotion planning problems. Given $s$ polynomial equations with rational\ncoefficients, of degree $D$ in $n$ variables, Canny's algorithm has a Monte\nCarlo cost of $s^n\\log(s) D^{O(n^2)}$ operations in $\\mathbb{Q}$; a\ndeterministic version runs in time $s^n \\log(s) D^{O(n^4)}$. The next\nimprovement was due to Basu, Pollack and Roy, with an algorithm of\ndeterministic cost $s^{d+1} D^{O(n^2)}$ for the more general problem of\ncomputing roadmaps of semi-algebraic sets ($d \\le n$ is the dimension of an\nassociated object). We give a Monte Carlo algorithm of complexity\n$(nD)^{O(n^{1.5})}$ for the problem of computing a roadmap of a compact\nhypersurface $V$ of degree $D$ in $n$ variables; we also have to assume that\n$V$ has a finite number of singular points. Even under these extra assumptions,\nno previous algorithm featured a cost better than $D^{O(n^2)}$.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.1612v1"
    },
    {
        "title": "A bound on the minimum of a real positive polynomial over the standard\n  simplex",
        "authors": [
            "Saugata Basu",
            "Richard Leroy",
            "Marie-Francoise Roy"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We consider the problem of bounding away from 0 the minimum value m taken by\na polynomial P of Z[X_1,...,X_k] over the standard simplex, assuming that m>0.\nRecent algorithmic developments in real algebraic geometry enable us to obtain\na positive lower bound on m in terms of the dimension k, the degree d and the\nbitsize of the coefficients of P. The bound is explicit, and obtained without\nany extra assumption on P, in contrast with previous results reported in the\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.3304v1"
    },
    {
        "title": "Computations modulo regular chains",
        "authors": [
            "Xin Li",
            "Marc Moreno Maza",
            "Wei Pan"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  The computation of triangular decompositions are based on two fundamental\noperations: polynomial GCDs modulo regular chains and regularity test modulo\nsaturated ideals. We propose new algorithms for these core operations relying\non modular methods and fast polynomial arithmetic. Our strategies take also\nadvantage of the context in which these operations are performed. We report on\nextensive experimentation, comparing our code to pre-existing Maple\nimplementations, as well as more optimized Magma functions. In most cases, our\nnew code outperforms the other packages by several orders of magnitude.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.3690v2"
    },
    {
        "title": "Computing Cylindrical Algebraic Decomposition via Triangular\n  Decomposition",
        "authors": [
            "Changbo Chen",
            "Marc Moreno Maza",
            "Bican Xia",
            "Lu Yang"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  Cylindrical algebraic decomposition is one of the most important tools for\ncomputing with semi-algebraic sets, while triangular decomposition is among the\nmost important approaches for manipulating constructible sets. In this paper,\nfor an arbitrary finite set $F \\subset {\\R}[y_1, ..., y_n]$ we apply\ncomprehensive triangular decomposition in order to obtain an $F$-invariant\ncylindrical decomposition of the $n$-dimensional complex space, from which we\nextract an $F$-invariant cylindrical algebraic decomposition of the\n$n$-dimensional real space. We report on an implementation of this new approach\nfor constructing cylindrical algebraic decompositions.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.5221v1"
    },
    {
        "title": "Effective Bounds for P-Recursive Sequences",
        "authors": [
            "Marc Mezzarobba",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We describe an algorithm that takes as input a complex sequence $(u_n)$ given\nby a linear recurrence relation with polynomial coefficients along with initial\nvalues, and outputs a simple explicit upper bound $(v_n)$ such that $|u_n| \\leq\nv_n$ for all $n$. Generically, the bound is tight, in the sense that its\nasymptotic behaviour matches that of $u_n$. We discuss applications to the\nevaluation of power series with guaranteed precision.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.2452v2"
    },
    {
        "title": "A Non-Holonomic Systems Approach to Special Function Identities",
        "authors": [
            "Frédéric Chyzak",
            "Manuel Kauers",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We extend Zeilberger's approach to special function identities to cases that\nare not holonomic. The method of creative telescoping is thus applied to\ndefinite sums or integrals involving Stirling or Bernoulli numbers, incomplete\nGamma function or polylogarithms, which are not covered by the holonomic\nframework. The basic idea is to take into account the dimension of appropriate\nideals in Ore algebras. This unifies several earlier extensions and provides\nalgorithms for summation and integration in classes that had not been\naccessible to computer algebra before.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.2761v1"
    },
    {
        "title": "La Résolvante de Lagrange et ses Applications",
        "authors": [
            "Annick Valibouze"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  In this paper, the changes of representations of a group are used in order to\ndescribe its action as algebraic Galois group of an univariate polynomial on\nthe roots of factors of any Lagrange resolvent. By this way, the Galois group\nof resolvent factors are pre-determinated. In follows, different applications\nare exposed; in particular, some classical results of algebraic Galois theory.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3827v1"
    },
    {
        "title": "Successive Difference Substitution Based on Column Stochastic Matrix and\n  Mechanical Decision for Positive Semi-definite Forms",
        "authors": [
            "Yong Yao"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  The theory part of this paper is sketched as follows. Based on column\nstochastic average matrix $T_n$ selected as a basic substitution matrix, the\nmethod of advanced successive difference substitution is established. Then, a\nset of necessary and sufficient conditions for deciding positive semi-definite\nform on $\\R^n_+$ is derived from this method. And furthermore, it is proved\nthat the sequence of SDS sets of a positive definite form is positively\nterminating.\n  Worked out according to these results, the Maple program TSDS3 not only\nautomatically proves the polynomial inequalities, but also outputs counter\nexamples for the false. Sometimes TSDS3 does not halt, but it is very useful by\nexperimenting on so many examples.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.4030v3"
    },
    {
        "title": "Continued Fraction Expansion of Real Roots of Polynomial Systems",
        "authors": [
            "Angelos Mantzaflaris",
            "Bernard Mourrain",
            "Elias P. P. Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We present a new algorithm for isolating the real roots of a system of\nmultivariate polynomials, given in the monomial basis. It is inspired by\nexisting subdivision methods in the Bernstein basis; it can be seen as\ngeneralization of the univariate continued fraction algorithm or alternatively\nas a fully analog of Bernstein subdivision in the monomial basis. The\nrepresentation of the subdivided domains is done through homographies, which\nallows us to use only integer arithmetic and to treat efficiently unbounded\nregions. We use univariate bounding functions, projection and preconditionning\ntechniques to reduce the domain of search. The resulting boxes have optimized\nrational coordinates, corresponding to the first terms of the continued\nfraction expansion of the real roots. An extension of Vincent's theorem to\nmultivariate polynomials is proved and used for the termination of the\nalgorithm. New complexity bounds are provided for a simplified version of the\nalgorithm. Examples computed with a preliminary C++ implementation illustrate\nthe approach.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.3993v2"
    },
    {
        "title": "Symbolic Script Programming for Java",
        "authors": [
            "Raphael Jolly",
            "Heinz Kredel"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  Computer algebra in Java is a promising field of development. It has not yet\nreached an industrial strength, in part because of a lack of good user\ninterfaces. Using a general purpose scripting language can bring a natural\nmathematical notation, akin to the one of specialized interfaces included in\nmost computer algebra systems. We present such an interface for Java computer\nalgebra libraries, using scripts available in the JSR 223 framework. We\nintroduce the concept of `symbolic programming' and show its usefulness by\nprototypes of symbolic polynomials and polynomial rings.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.2315v2"
    },
    {
        "title": "Chebyshev Expansions for Solutions of Linear Differential Equations",
        "authors": [
            "Alexandre Benoit",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  A Chebyshev expansion is a series in the basis of Chebyshev polynomials of\nthe first kind. When such a series solves a linear differential equation, its\ncoefficients satisfy a linear recurrence equation. We interpret this equation\nas the numerator of a fraction of linear recurrence operators. This\ninterpretation lets us give a simple view of previous algorithms, analyze their\ncomplexity, and design a faster one for large orders.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.2888v1"
    },
    {
        "title": "Generating functions of Chebyshev-like polynomials",
        "authors": [
            "Alin Bostan",
            "Bruno Salvy",
            "Khang Tran"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  In this short note, we give simple proofs of several results and conjectures\nformulated by Stolarsky and Tran concerning generating functions of some\nfamilies of Chebyshev-like polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.0291v3"
    },
    {
        "title": "The Piranha algebraic manipulator",
        "authors": [
            "Francesco Biscani"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  In this paper we present a specialised algebraic manipulation package devoted\nto Celestial Mechanics. The system, called Piranha, is built on top of a\ngeneric and extensible framework, which allows to treat efficiently and in a\nunified way the algebraic structures most commonly encountered in Celestial\nMechanics (such as multivariate polynomials and Poisson series). In this\ncontribution we explain the architecture of the software, with special focus on\nthe implementation of series arithmetics, show its current capabilities, and\npresent benchmarks indicating that Piranha is competitive, performance-wise,\nwith other specialised manipulators.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.2076v1"
    },
    {
        "title": "An Efficient Algorithm for Factoring Polynomials over Algebraic\n  Extension Field",
        "authors": [
            "Yao Sun",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  A new efficient algorithm is proposed for factoring polynomials over an\nalgebraic extension field. The extension field is defined by a polynomial ring\nmodulo a maximal ideal. If the maximal ideal is given by its Groebner basis, no\nextra Groebner basis computation is needed for factoring a polynomial over this\nextension field. Nothing more than linear algebraic technique is used to get a\npolynomial over the ground field by a generic linear map. Then this polynomial\nis factorized over the ground field. From these factors, the factorization of\nthe polynomial over the extension field is obtained. The new algorithm has been\nimplemented and computer experiments indicate that the new algorithm is very\nefficient, particularly in complicated examples.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.2300v2"
    },
    {
        "title": "Computing modular correspondences for abelian varieties",
        "authors": [
            "Jean-Charles Faugère",
            "David Lubicz",
            "Damien Robert"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  The aim of this paper is to give a higher dimensional equivalent of the\nclassical modular polynomials $\\Phi_\\ell(X,Y)$. If $j$ is the $j$-invariant\nassociated to an elliptic curve $E_k$ over a field $k$ then the roots of\n$\\Phi_\\ell(j,X)$ correspond to the $j$-invariants of the curves which are\n$\\ell$-isogeneous to $E_k$. Denote by $X_0(N)$ the modular curve which\nparametrizes the set of elliptic curves together with a $N$-torsion subgroup.\nIt is possible to interpret $\\Phi_\\ell(X,Y)$ as an equation cutting out the\nimage of a certain modular correspondence $X_0(\\ell) \\to X_0(1) \\times X_0(1)$\nin the product $X_0(1) \\times X_0(1)$. Let $g$ be a positive integer and\n$\\overn \\in \\N^g$. We are interested in the moduli space that we denote by\n$\\Mn$ of abelian varieties of dimension $g$ over a field $k$ together with an\nample symmetric line bundle $\\pol$ and a symmetric theta structure of type\n$\\overn$. If $\\ell$ is a prime and let $\\overl=(\\ell, ..., \\ell)$, there exists\na modular correspondence $\\Mln \\to \\Mn \\times \\Mn$. We give a system of\nalgebraic equations defining the image of this modular correspondence.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.4668v1"
    },
    {
        "title": "Completeness of the WDS method in Checking Positivity of Integral Forms",
        "authors": [
            "Xiaorong Hou",
            "Junwei Shao"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  Examples show that integral forms can be efficiently proved positive\nsemidefinite by the WDS method, but it was unknown that how many steps of\nsubstitutions are needed, or furthermore, which integral forms is this method\napplicable for. In this paper, we give upper bounds of step numbers of WDS\nrequired in proving that an integral form is positive definite, positive\nsemidefinite, or not positive semidefinite, thus deducing that the WDS method\nis complete.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.1649v1"
    },
    {
        "title": "Simplex Subdivisions and Nonnegativity Decision of Forms",
        "authors": [
            "Xiaorong Hou",
            "Song Xu"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  This paper mainly studies nonnegativity decision of forms based on variable\nsubstitutions. Unlike existing research, the paper regards simplex subdivisions\nas new perspectives to study variable substitutions, gives some subdivisions of\nthe simplex T_n, introduces the concept of convergence of the subdivision\nsequence, and presents a sufficient and necessary condition for the convergent\nself-similar subdivision sequence. Then the relationships between subdivisions\nand their corresponding substitutions are established. Moreover, it is proven\nthat if the form F is indefinite on T_n and the sequence of the successive\nL-substitution sets is convergent, then the sequence of sets {SLS^(m)(F)} is\nnegatively terminating, and an algorithm for deciding indefinite forms with a\ncounter-example is obtained. Thus, various effective substitutions for deciding\npositive semi-definite forms and indefinite forms are gained, which are beyond\nthe weighted difference substitutions characterized by \"difference\".\n",
        "pdf_link": "http://arxiv.org/pdf/0912.4430v1"
    },
    {
        "title": "A Complete Method for Checking Hurwitz Stability of a Polytope of\n  Matrices",
        "authors": [
            "Junwei Shao",
            "Xiaorong Hou"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We present a novel method for checking the Hurwitz stability of a polytope of\nmatrices. First we prove that the polytope matrix is stable if and only if two\nhomogenous polynomials are positive on a simplex, then through a newly proposed\nmethod, i.e., the weighted difference substitution method, the latter can be\nchecked in finite steps. Examples show the efficiency of our method.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.0304v1"
    },
    {
        "title": "A complete algorithm to find exact minimal polynomial by approximations",
        "authors": [
            "Xiaolin Qin",
            "Yong Feng",
            "Jingwei Chen",
            "Jingzhong Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We present a complete algorithm for finding an exact minimal polynomial from\nits approximate value by using an improved parameterized integer relation\nconstruction method. Our result is superior to the existence of error\ncontrolling on obtaining an exact rational number from its approximation. The\nalgorithm is applicable for finding exact minimal polynomial of an algebraic\nnumber by its approximate root. This also enables us to provide an efficient\nmethod of converting the rational approximation representation to the minimal\npolynomial representation, and devise a simple algorithm to factor multivariate\npolynomials with rational coefficients.\n  Compared with the subsistent methods, our method combines advantage of high\nefficiency in numerical computation, and exact, stable results in symbolic\ncomputation. we also discuss some applications to some transcendental numbers\nby approximations. Moreover, the Digits of our algorithm is far less than the\nLLL-lattice basis reduction technique in theory. In this paper, we completely\nimplement how to obtain exact results by numerical approximate computations.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.0649v1"
    },
    {
        "title": "Gröbner Bases of Bihomogeneous Ideals generated by Polynomials of\n  Bidegree (1,1): Algorithms and Complexity",
        "authors": [
            "Jean-Charles Faugère",
            "Mohab Safey El Din",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Solving multihomogeneous systems, as a wide range of structured algebraic\nsystems occurring frequently in practical problems, is of first importance.\nExperimentally, solving these systems with Gr\\\"obner bases algorithms seems to\nbe easier than solving homogeneous systems of the same degree. Nevertheless,\nthe reasons of this behaviour are not clear. In this paper, we focus on\nbilinear systems (i.e. bihomogeneous systems where all equations have bidegree\n(1,1)). Our goal is to provide a theoretical explanation of the aforementionned\nexperimental behaviour and to propose new techniques to speed up the Gr\\\"obner\nbasis computations by using the multihomogeneous structure of those systems.\nThe contributions are theoretical and practical. First, we adapt the classical\nF5 criterion to avoid reductions to zero which occur when the input is a set of\nbilinear polynomials. We also prove an explicit form of the Hilbert series of\nbihomogeneous ideals generated by generic bilinear polynomials and give a new\nupper bound on the degree of regularity of generic affine bilinear systems.\nThis leads to new complexity bounds for solving bilinear systems. We propose\nalso a variant of the F5 Algorithm dedicated to multihomogeneous systems which\nexploits a structural property of the Macaulay matrix which occurs on such\ninputs. Experimental results show that this variant requires less time and\nmemory than the classical homogeneous F5 Algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.4004v2"
    },
    {
        "title": "NumGfun: a Package for Numerical and Analytic Computation with D-finite\n  Functions",
        "authors": [
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  This article describes the implementation in the software package NumGfun of\nclassical algorithms that operate on solutions of linear differential equations\nor recurrence relations with polynomial coefficients, including what seems to\nbe the first general implementation of the fast high-precision numerical\nevaluation algorithms of Chudnovsky & Chudnovsky. In some cases, our\ndescriptions contain improvements over existing algorithms. We also provide\nreferences to relevant ideas not currently used in NumGfun.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3077v2"
    },
    {
        "title": "A New Proof for the Correctness of F5 (F5-Like) Algorithm",
        "authors": [
            "Yao Sun",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  The famous F5 algorithm for computing Gr\\\"obner basis was presented by\nFaug\\`ere in 2002 without complete proofs for its correctness. The current\nauthors have simplified the original F5 algorithm into an F5 algorithm in\nBuchberger's style (F5B algorithm), which is equivalent to original F5\nalgorithm and may deduce some F5-like versions. In this paper, the F5B\nalgorithm is briefly revisited and a new complete proof for the correctness of\nF5B algorithm is proposed. This new proof is not limited to homogeneous systems\nand does not depend on the strategy of selecting critical pairs (i.e. the\nstrategy deciding which critical pair is computed first) such that any strategy\ncould be utilized in F5B (F5) algorithm. From this new proof, we find that the\nspecial reduction procedure (F5-reduction) is the key of F5 algorithm, so\nmaintaining this special reduction, various variation algorithms become\navailable. A natural variation of F5 algorithm, which transforms original F5\nalgorithm to a non-incremental algorithm, is presented and proved in this paper\nas well. This natural variation has been implemented over the Boolean ring. The\ntwo revised criteria in this natural variation are also able to reject almost\nall unnecessary computations and few polynomials reduce to 0 in most examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.0084v4"
    },
    {
        "title": "On Computing Groebner Basis in the Rings of Differential Operators",
        "authors": [
            "Xiaodong Ma",
            "Yao Sun",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Insa and Pauer presented a basic theory of Groebner basis for differential\noperators with coefficients in a commutative ring in 1998, and a criterion was\nproposed to determine if a set of differential operators is a Groebner basis.\nIn this paper, we will give a new criterion such that Insa and Pauer's\ncriterion could be concluded as a special case and one could compute the\nGroebner basis more efficiently by this new criterion.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2090v2"
    },
    {
        "title": "Multiplication of sparse Laurent polynomials and Poisson series on\n  modern hardware architectures",
        "authors": [
            "Francesco Biscani"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  In this paper we present two algorithms for the multiplication of sparse\nLaurent polynomials and Poisson series (the latter being algebraic structures\ncommonly arising in Celestial Mechanics from the application of perturbation\ntheories). Both algorithms first employ the Kronecker substitution technique to\nreduce multivariate multiplication to univariate multiplication, and then use\nthe schoolbook method to perform the univariate multiplication. The first\nalgorithm, suitable for moderately-sparse multiplication, uses the exponents of\nthe monomials resulting from the univariate multiplication as trivial hash\nvalues in a one dimensional lookup array of coefficients. The second algorithm,\nsuitable for highly-sparse multiplication, uses a cache-optimised hash table\nwhich stores the coefficient-exponent pairs resulting from the multiplication\nusing the exponents as keys. Both algorithms have been implemented with\nattention to modern computer hardware architectures. Particular care has been\ndevoted to the efficient exploitation of contemporary memory hierarchies\nthrough cache-blocking techniques and cache-friendly term ordering. The first\nalgorithm has been parallelised for shared-memory multicore architectures,\nwhereas the second algorithm is in the process of being parallelised. We\npresent benchmarks comparing our algorithms to the routines of other computer\nalgebra systems, both in sequential and parallel mode.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4548v1"
    },
    {
        "title": "Some Results on the Functional Decomposition of Polynomials",
        "authors": [
            "Mark Giesbrecht"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  If g and h are functions over some field, we can consider their composition f\n= g(h). The inverse problem is decomposition: given f, determine the ex-\nistence of such functions g and h. In this thesis we consider functional decom-\npositions of univariate and multivariate polynomials, and rational functions\nover a field F of characteristic p. In the polynomial case, \"wild\" behaviour\noccurs in both the mathematical and computational theory of the problem if p\ndivides the degree of g. We consider the wild case in some depth, and deal with\nthose polynomials whose decompositions are in some sense the \"wildest\": the\nadditive polynomials. We determine the maximum number of decompositions and\nshow some polynomial time algorithms for certain classes of polynomials with\nwild decompositions. For the rational function case we present a definition of\nthe problem, a normalised version of the problem to which the general problem\nreduces, and an exponential time solution to the normal problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.5433v1"
    },
    {
        "title": "When can we decide that a P-finite sequence is positive?",
        "authors": [
            "Manuel Kauers",
            "Veronika Pillwein"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We consider two algorithms which can be used for proving positivity of\nsequences that are defined by a linear recurrence equation with polynomial\ncoefficients (P-finite sequences). Both algorithms have in common that while\nthey do succeed on a great many examples, there is no guarantee for them to\nterminate, and they do in fact not terminate for every input. For some\nrestricted classes of P-finite recurrence equations of order up to three we\nprovide a priori criteria that assert the termination of the algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0600v1"
    },
    {
        "title": "Partial Denominator Bounds for Partial Linear Difference Equations",
        "authors": [
            "Manuel Kauers",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We investigate which polynomials can possibly occur as factors in the\ndenominators of rational solutions of a given partial linear difference\nequation (PLDE). Two kinds of polynomials are to be distinguished, we call them\n/periodic/ and /aperiodic/. The main result is a generalization of a well-known\ndenominator bounding technique for univariate equations to PLDEs. This\ngeneralization is able to find all the aperiodic factors of the denominators\nfor a given PLDE.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0602v1"
    },
    {
        "title": "Random polynomials and expected complexity of bisection methods for real\n  solving",
        "authors": [
            "Ioannis Z. Emiris",
            "André Galligo",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Our probabilistic analysis sheds light to the following questions: Why do\nrandom polynomials seem to have few, and well separated real roots, on the\naverage? Why do exact algorithms for real root isolation may perform\ncomparatively well or even better than numerical ones? We exploit results by\nKac, and by Edelman and Kostlan in order to estimate the real root separation\nof degree $d$ polynomials with i.i.d.\\ coefficients that follow two zero-mean\nnormal distributions: for SO(2) polynomials, the $i$-th coefficient has\nvariance ${d \\choose i}$, whereas for Weyl polynomials its variance is\n${1/i!}$. By applying results from statistical physics, we obtain the expected\n(bit) complexity of \\func{sturm} solver, $\\sOB(r d^2 \\tau)$, where $r$ is the\nnumber of real roots and $\\tau$ the maximum coefficient bitsize. Our bounds are\ntwo orders of magnitude tighter than the record worst case ones. We also derive\nan output-sensitive bound in the worst case. The second part of the paper shows\nthat the expected number of real roots of a degree $d$ polynomial in the\nBernstein basis is $\\sqrt{2d}\\pm\\OO(1)$, when the coefficients are i.i.d.\\\nvariables with moderate standard deviation. Our paper concludes with\nexperimental results which corroborate our analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.2001v2"
    },
    {
        "title": "The DMM bound: multivariate (aggregate) separation bounds",
        "authors": [
            "Ioannis Z. Emiris",
            "Bernard Mourrain",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  In this paper we derive aggregate separation bounds, named after\nDavenport-Mahler-Mignotte (\\dmm), on the isolated roots of polynomial systems,\nspecifically on the minimum distance between any two such roots. The bounds\nexploit the structure of the system and the height of the sparse (or toric)\nresultant by means of mixed volume, as well as recent advances on aggregate\nroot bounds for univariate polynomials, and are applicable to arbitrary\npositive dimensional systems. We improve upon Canny's gap theorem\n\\cite{c-crmp-87} by a factor of $\\OO(d^{n-1})$, where $d$ bounds the degree of\nthe polynomials, and $n$ is the number of variables. One application is to the\nbitsize of the eigenvalues and eigenvectors of an integer matrix, which also\nyields a new proof that the problem is polynomial. We also compare against\nrecent lower bounds on the absolute value of the root coordinates by Brownawell\nand Yap \\cite{by-issac-2009}, obtained under the hypothesis there is a\n0-dimensional projection. Our bounds are in general comparable, but exploit\nsparseness; they are also tighter when bounding the value of a positive\npolynomial over the simplex. For this problem, we also improve upon the bounds\nin \\cite{bsr-arxix-2009,jp-arxiv-2009}. Our analysis provides a precise\nasymptotic upper bound on the number of steps that subdivision-based algorithms\nperform in order to isolate all real roots of a polynomial system. This leads\nto the first complexity bound of Milne's algorithm \\cite{Miln92} in 2D.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.5610v2"
    },
    {
        "title": "The F5 Algorithm in Buchberger's Style",
        "authors": [
            "Yao Sun",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  The famous F5 algorithm for computing \\gr basis was presented by Faug\\`ere in\n2002. The original version of F5 is given in programming codes, so it is a bit\ndifficult to understand. In this paper, the F5 algorithm is simplified as F5B\nin a Buchberger's style such that it is easy to understand and implement. In\norder to describe F5B, we introduce F5-reduction, which keeps the signature of\nlabeled polynomials unchanged after reduction. The equivalence between F5 and\nF5B is also shown. At last, some versions of the F5 algorithm are illustrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.5299v2"
    },
    {
        "title": "From matrix interpretations over the rationals to matrix interpretations\n  over the naturals",
        "authors": [
            "Salvador Lucas"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Matrix interpretations generalize linear polynomial interpretations and have\nbeen proved useful in the implementation of tools for automatically proving\ntermination of Term Rewriting Systems. In view of the successful use of\nrational coefficients in polynomial interpretations, we have recently\ngeneralized traditional matrix interpretations (using natural numbers in the\nmatrix entries) to incorporate real numbers. However, existing results which\nformally prove that polynomials over the reals are more powerful than\npolynomials over the naturals for proving termination of rewrite systems failed\nto be extended to matrix interpretations. In this paper we get deeper into this\nproblem. We show that, under some conditions, it is possible to transform a\nmatrix interpretation over the rationals satisfying a set of symbolic\nconstraints into a matrix interpretation over the naturals (using bigger\nmatrices) which still satisfies the constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.0143v1"
    },
    {
        "title": "Bit-size estimates for triangular sets in positive dimension",
        "authors": [
            "Xavier Dahan",
            "Abdulilah Kadri",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We give bit-size estimates for the coefficients appearing in triangular sets\ndescribing positive-dimensional algebraic sets defined over Q. These estimates\nare worst case upper bounds; they depend only on the degree and height of the\nunderlying algebraic sets. We illustrate the use of these results in the\ncontext of a modular algorithm. This extends results by the first and last\nauthor, which were confined to the case of dimension 0. Our strategy is to get\nback to dimension 0 by evaluation and inter- polation techniques. Even though\nthe main tool (height theory) remains the same, new difficulties arise to\ncontrol the growth of the coefficients during the interpolation process.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.3459v1"
    },
    {
        "title": "Improved complexity bounds for real root isolation using Continued\n  Fractions",
        "authors": [
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We consider the problem of isolating the real roots of a square-free\npolynomial with integer coefficients using (variants of) the continued fraction\nalgorithm (CF). We introduce a novel way to compute a lower bound on the\npositive real roots of univariate polynomials. This allows us to derive a worst\ncase bound of $\\sOB(d^6 + d^4\\tau^2 + d^3\\tau^2)$ for isolating the real roots\nof a polynomial with integer coefficients using the classic variant of CF,\nwhere $d$ is the degree of the polynomial and $\\tau$ the maximum bitsize of its\ncoefficients. This improves the previous bound by Sharma \\cite{sharma-tcs-2008}\nby a factor of $d^3$ and matches the bound derived by Mehlhorn and Ray\n\\cite{mr-jsc-2009} for another variant of CF; it also matches the worst case\nbound of the subdivision-based solvers. We present a new variant of CF, we call\nit iCF, that isolates the real roots of a polynomial with integer coefficients\nin $\\sOB(d^5+d^4\\tau)$, thus improving the current known bound for the problem\nby a factor of $d$. If the polynomial has only real roots, then our bound\nbecomes $\\sOB(d^4+d^3\\tau+ d^2\\tau^2)$, thus matching the bound of the\nnumerical algorithms by Reif \\cite{r-focs-1993} and by Ben-Or and Tiwari\n\\cite{bt-joc-1990}. Actually the latter bound holds in a more general setting,\nthat is under the rather mild assumption that $\\Omega(d/\\lg^c{d})$, where\n$c\\geq 0$ is a constant, roots contribute to the sign variations of the\ncoefficient list of the polynomial. This is the only bound on exact algorithms\nthat matches the one of the numerical algorithms by Pan \\cite{Pan02jsc} and\nSch\\\"onhage \\cite{Sch82}. To our knowledge the presented bounds are the best\nknown for the problem of real root isolation for algorithms based on exact\ncomputations.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.1764v2"
    },
    {
        "title": "Improved complexity bounds for real root isolation using Continued\n  Fractions",
        "authors": [
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We consider the problem of isolating the real roots of a square-free\npolynomial with integer coefficients using (variants of) the continued fraction\nalgorithm (CF). We introduce a novel way to compute a lower bound on the\npositive real roots of univariate polynomials. This allows us to derive a worst\ncase bound of $\\sOB(d^6 + d^4\\tau^2 + d^3\\tau^2)$ for isolating the real roots\nof a polynomial with integer coefficients using the classic variant\n\\cite{Akritas:implementation} of CF, where $d$ is the degree of the polynomial\nand $\\tau$ the maximum bitsize of its coefficients. This improves the previous\nbound of Sharma \\cite{sharma-tcs-2008} by a factor of $d^3$ and matches the\nbound derived by Mehlhorn and Ray \\cite{mr-jsc-2009} for another variant of CF;\nit also matches the worst case bound of the subdivision-based solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.2006v2"
    },
    {
        "title": "Théorie de Galois effective : aide mémoire",
        "authors": [
            "Annick Valibouze"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  This paper collects many results on galoisian ideals and Galois theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.3442v1"
    },
    {
        "title": "Computing Differential Equations for Integrals Associated to Smooth Fano\n  Polytopes",
        "authors": [
            "Hiromasa Nakayama",
            "Nobuki Takayama"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We give an approximate algorithm of computing holonomic systems of linear\ndifferential equations for definite integrals with parameters. We show that\nthis algorithm gives a correct answer in finite steps, but we have no general\nstopping condition. We apply the approximate method to find differential\nequations for integrals associated to smooth Fano polytopes. They are\ninterested in the study of K3 surfaces and the toric mirror symmetry. In this\nclass of integrals, we can apply Stienstra's rank formula to our algorithm,\nwhich gives a stopping condition of the approximate algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5353v1"
    },
    {
        "title": "A Refined Denominator Bounding Algorithm for Multivariate Linear\n  Difference Equations",
        "authors": [
            "Manuel Kauers",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We continue to investigate which polynomials can possibly occur as factors in\nthe denominators of rational solutions of a given partial linear difference\nequation.\n  In an earlier article we had introduced the distinction between periodic and\naperiodic factors in the denominator, and we gave an algorithm for predicting\nthe aperiodic ones. Now we extend this technique towards the periodic case and\npresent a refined algorithm which also finds most of the periodic factors.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.2803v1"
    },
    {
        "title": "Deflation and Certified Isolation of Singular Zeros of Polynomial\n  Systems",
        "authors": [
            "Angelos Mantzaflaris",
            "Bernard Mourrain"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We develop a new symbolic-numeric algorithm for the certification of singular\nisolated points, using their associated local ring structure and certified\nnumerical computations. An improvement of an existing method to compute inverse\nsystems is presented, which avoids redundant computation and reduces the size\nof the intermediate linear systems to solve. We derive a one-step deflation\ntechnique, from the description of the multiplicity structure in terms of\ndifferentials. The deflated system can be used in Newton-based iterative\nschemes with quadratic convergence. Starting from a polynomial system and a\nsmall-enough neighborhood, we obtain a criterion for the existence and\nuniqueness of a singular root of a given multiplicity structure, applying a\nwell-chosen symbolic perturbation. Standard verification methods, based eg. on\ninterval arithmetic and a fixed point theorem, are employed to certify that\nthere exists a unique perturbed system with a singular root in the domain.\nApplications to topological degree computation and to the analysis of real\nbranches of an implicit curve illustrate the method.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.3140v1"
    },
    {
        "title": "A Generalized Criterion for Signature Related Gröbner Basis Algorithms",
        "authors": [
            "Yao Sun",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  A generalized criterion for signature related algorithms to compute Gr\\\"obner\nbasis is proposed in this paper. Signature related algorithms are a popular\nkind of algorithms for computing Gr\\\"obner basis, including the famous F5\nalgorithm, the extended F5 algorithm and the GVW algorithm. The main purpose of\ncurrent paper is to study in theory what kind of criteria is correct in\nsignature related algorithms and provide a generalized method to develop new\ncriteria. For this purpose, a generalized criterion is proposed. The\ngeneralized criterion only relies on a general partial order defined on a set\nof polynomials. When specializing the partial order to appropriate specific\norders, the generalized criterion can specialize to almost all existing\ncriteria of signature related algorithms. For {\\em admissible} partial orders,\na complete proof of the correctness of the algorithm based on this generalized\ncriterion is also presented. This proof has no extra requirements on the\ncomputing order of critical pairs, and is also valid for non-homogeneous\npolynomial systems. More importantly, the partial orders implied by existing\ncriteria are admissible. Besides, one can also check whether a new criterion is\ncorrect in signature related algorithms or even develop new criteria by using\nother admissible partial orders in the generalized criterion.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.3382v2"
    },
    {
        "title": "Multiplicity Preserving Triangular Set Decomposition of Two Polynomials",
        "authors": [
            "Jin-San Cheng",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  In this paper, a multiplicity preserving triangular set decomposition\nalgorithm is proposed for a system of two polynomials. The algorithm decomposes\nthe variety defined by the polynomial system into unmixed components\nrepresented by triangular sets, which may have negative multiplicities. In the\nbivariate case, we give a complete algorithm to decompose the system into\nmultiplicity preserving triangular sets with positive multiplicities. We also\nanalyze the complexity of the algorithm in the bivariate case. We implement our\nalgorithm and show the effectiveness of the method with extensive experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.3603v1"
    },
    {
        "title": "Generalized companion matrix for approximate GCD",
        "authors": [
            "Paola Boito",
            "Olivier Ruatta"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We study a variant of the univariate approximate GCD problem, where the\ncoefficients of one polynomial f(x)are known exactly, whereas the coefficients\nof the second polynomial g(x)may be perturbed. Our approach relies on the\nproperties of the matrix which describes the operator of multiplication by gin\nthe quotient ring C[x]=(f). In particular, the structure of the null space of\nthe multiplication matrix contains all the essential information about GCD(f;\ng). Moreover, the multiplication matrix exhibits a displacement structure that\nallows us to design a fast algorithm for approximate GCD computation with\nquadratic complexity w.r.t. polynomial degrees.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.1809v1"
    },
    {
        "title": "Root Isolation of Zero-dimensional Polynomial Systems with Linear\n  Univariate Representation",
        "authors": [
            "Jin-San Cheng",
            "Xiao-Shan Gao",
            "Leilei Guo"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  In this paper, a linear univariate representation for the roots of a\nzero-dimensional polynomial equation system is presented, where the roots of\nthe equation system are represented as linear combinations of roots of several\nunivariate polynomial equations. The main advantage of this representation is\nthat the precision of the roots can be easily controlled. In fact, based on the\nlinear univariate representation, we can give the exact precisions needed for\nroots of the univariate equations in order to obtain the roots of the equation\nsystem to a given precision. As a consequence, a root isolation algorithm for a\nzero-dimensional polynomial equation system can be easily derived from its\nlinear univariate representation.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.4681v1"
    },
    {
        "title": "Root Refinement for Real Polynomials",
        "authors": [
            "Michael Kerber",
            "Michael Sagraloff"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We consider the problem of approximating all real roots of a square-free\npolynomial $f$. Given isolating intervals, our algorithm refines each of them\nto a width of $2^{-L}$ or less, that is, each of the roots is approximated to\n$L$ bits after the binary point. Our method provides a certified answer for\narbitrary real polynomials, only considering finite approximations of the\npolynomial coefficients and choosing a suitable working precision adaptively.\nIn this way, we get a correct algorithm that is simple to implement and\npractically efficient. Our algorithm uses the quadratic interval refinement\nmethod; we adapt that method to be able to cope with inaccuracies when\nevaluating $f$, without sacrificing its quadratic convergence behavior. We\nprove a bound on the bit complexity of our algorithm in terms of the degree of\nthe polynomial, the size and the separation of the roots, that is, parameters\nexclusively related to the geometric location of the roots. Our bound is near\noptimal and significantly improves previous work on integer polynomials.\nFurthermore, it essentially matches the best known theoretical bounds on root\napproximation which are obtained by very sophisticated algorithms. We also\ninvestigate the practical behavior of the algorithm and demonstrate how closely\nthe practical performance matches our asymptotic bounds.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.1362v3"
    },
    {
        "title": "A Worst-case Bound for Topology Computation of Algebraic Curves",
        "authors": [
            "Michael Kerber",
            "Michael Sagraloff"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  Computing the topology of an algebraic plane curve $\\mathcal{C}$ means to\ncompute a combinatorial graph that is isotopic to $\\mathcal{C}$ and thus\nrepresents its topology in $\\mathbb{R}^2$. We prove that, for a polynomial of\ndegree $n$ with coefficients bounded by $2^\\rho$, the topology of the induced\ncurve can be computed with $\\tilde{O}(n^8(n+\\rho^2))$ bit operations\ndeterministically, and with $\\tilde{O}(n^8\\rho^2)$ bit operations with a\nrandomized algorithm in expectation. Our analysis improves previous best known\ncomplexity bounds by a factor of $n^2$. The improvement is based on new\ntechniques to compute and refine isolating intervals for the real roots of\npolynomials, and by the consequent amortized analysis of the critical fibers of\nthe algebraic curve.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.1510v1"
    },
    {
        "title": "A note on Solving Parametric Polynomial Systems",
        "authors": [
            "Asieh Pourhaghani"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  Lazard and Rouillier in [9], by introducing the concept of discriminant\nvariety, have described a new and efficient algorithm for solving parametric\npolynomial systems. In this paper we modify this algorithm, and we show that\nwith our improvements the output of our algorithm is always minimal and it does\nnot need to compute the radical of ideals.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.4682v1"
    },
    {
        "title": "A Generalized Criterion for Signature-based Algorithms to Compute\n  Gröbner Bases",
        "authors": [
            "Yao Sun",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  A generalized criterion for signature-based algorithms to compute Gr\\\"obner\nbases is proposed in this paper. This criterion is named by \"generalized\ncriterion\", because it can be specialized to almost all existing criteria for\nsignature-based algorithms which include the famous F5 algorithm, F5C, extended\nF5, G$^2$V and the GVW algorithm. The main purpose of current paper is to study\nin theory which kind of criteria is correct in signature-based algorithms and\nprovide a generalized method to develop new criteria. For this purpose, by\nstudying some key facts and observations of signature-based algorithms, a\ngeneralized criterion is proposed. The generalized criterion only relies on a\npartial order defined on a set of polynomials. When specializing the partial\norder to appropriate specific orders, the generalized criterion can specialize\nto almost all existing criteria of signature-based algorithms. For {\\em\nadmissible} partial orders, a proof is presented for the correctness of the\nalgorithm that is based on this generalized criterion. And the partial orders\nimplied by the criteria of F5 and GVW are also shown to be admissible. More\nimportantly, the generalized criterion provides an effective method to check\nwhether a new criterion is correct as well as to develop new criteria for\nsignature-based algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.4918v1"
    },
    {
        "title": "On Consensus under Polynomial Protocols",
        "authors": [
            "Joel George Manathara",
            "Ambedkar Dukkipati",
            "Debasish Ghose"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  In this paper we explore the possibility of using computational algebraic\nmethods to analyze a class of consensus protocols. We state some necessary\nconditions for convergence under consensus protocols that are polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.3584v1"
    },
    {
        "title": "Solving Detachability Problem for the Polynomial Ring by Signature-based\n  Groebner Basis Algorithms",
        "authors": [
            "Yao Sun",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  Signature-based algorithms are a popular kind of algorithms for computing\nGroebner basis, including the famous F5 algorithm, F5C, extended F5, G2V and\nthe GVW algorithm. In this paper, an efficient method is proposed to solve the\ndetachability problem. The new method only uses the outputs of signature-based\nalgorithms, and no extra Groebner basis computations are needed. When a\nGroebner basis is obtained by signature-based algorithms, the detachability\nproblem can be settled in polynomial time.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.1301v1"
    },
    {
        "title": "Trading Order for Degree in Creative Telescoping",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We analyze the differential equations produced by the method of creative\ntelescoping applied to a hyperexponential term in two variables. We show that\nequations of low order have high degree, and that higher order equations have\nlower degree. More precisely, we derive degree bounding formulas which allow to\nestimate the degree of the output equations from creative telescoping as a\nfunction of the order. As an application, we show how the knowledge of these\nformulas can be used to improve, at least in principle, the performance of\ncreative telescoping implementations, and we deduce bounds on the asymptotic\ncomplexity of creative telescoping for hyperexponential terms.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4508v2"
    },
    {
        "title": "A fast algorithm for reversion of power series",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We give an algorithm for reversion of formal power series, based on an\nefficient way to implement the Lagrange inversion formula. Our algorithm\nrequires $O(n^{1/2}(M(n) + MM(n^{1/2})))$ operations where $M(n)$ and $MM(n)$\nare the costs of polynomial and matrix multiplication respectively. This\nmatches the asymptotic complexity of an algorithm of Brent and Kung, but we\nachieve a constant factor speedup whose magnitude depends on the polynomial and\nmatrix multiplication algorithms used. Benchmarks confirm that the algorithm\nperforms well in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4772v3"
    },
    {
        "title": "Structure of lexicographic Groebner bases in three variables of ideals\n  of dimension zero",
        "authors": [
            "X. Dahan"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We generalize the structural theorem of Lazard in 1985, from 2 variables to 3\nvariables. We use the Gianni-Kalkbrener result to do this, which implies some\nrestrictions inside which lies the case of a radical ideal.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.3185v1"
    },
    {
        "title": "Generating Loop Invariants by Computing Vanishing Ideals of Sample\n  Points",
        "authors": [
            "Bin Wu",
            "Liyong Shen",
            "Min Wu",
            "Zhengfeng Yang",
            "Zhenbing Zeng"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  Loop invariants play a very important role in proving correctness of\nprograms. In this paper, we address the problem of generating invariants of\npolynomial loop programs. We present a new approach, for generating polynomial\nequation invariants of polynomial loop programs through computing vanishing\nideals of sample points. We apply rational function interpolation, based on\nearly termination technique, to generate invariants of loop programs with\nsymbolic initial values. Our approach avoids first-order quantifier elimination\nand cylindrical algebraic decomposition(CAD). An algorithm for generating\npolynomial invariants is proposed and some examples are given to illustrate the\nalgorithm. Furthermore, we demonstrate on a set of loop programs with symbolic\ninitial values that our algorithm can yield polynomial invariants with degrees\nhigh up to 15.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.0732v1"
    },
    {
        "title": "Note on fast division algorithm for polynomials using Newton iteration",
        "authors": [
            "Zhengjun Cao",
            "Hanyue Cao"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  The classical division algorithm for polynomials requires $O(n^2)$ operations\nfor inputs of size $n$. Using reversal technique and Newton iteration, it can\nbe improved to $O({M}(n))$, where ${M}$ is a multiplication time. But the\nmethod requires that the degree of the modulo, $x^l$, should be the power of 2.\nIf $l$ is not a power of 2 and $f(0)=1$, Gathen and Gerhard suggest to compute\nthe inverse,$f^{-1}$, modulo $x^{\\lceil l/2^r\\rceil}, x^{\\lceil\nl/2^{r-1}\\rceil},..., x^{\\lceil l/2\\rceil}, x^l$, separately. But they did not\nspecify the iterative step. In this note, we show that the original Newton\niteration formula can be directly used to compute $f^{-1}\\,{mod}\\,x^{l}$\nwithout any additional cost, when $l$ is not a power of 2.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.4014v1"
    },
    {
        "title": "On the Complexity of the Generalized MinRank Problem",
        "authors": [
            "Jean-Charles Faugère",
            "Mohab Safey El Din",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We study the complexity of solving the \\emph{generalized MinRank problem},\ni.e. computing the set of points where the evaluation of a polynomial matrix\nhas rank at most $r$. A natural algebraic representation of this problem gives\nrise to a \\emph{determinantal ideal}: the ideal generated by all minors of size\n$r+1$ of the matrix. We give new complexity bounds for solving this problem\nusing Gr\\\"obner bases algorithms under genericity assumptions on the input\nmatrix. In particular, these complexity bounds allow us to identify families of\ngeneralized MinRank problems for which the arithmetic complexity of the solving\nprocess is polynomial in the number of solutions. We also provide an algorithm\nto compute a rational parametrization of the variety of a 0-dimensional and\nradical system of bi-degree $(D,1)$. We show that its complexity can be bounded\nby using the complexity bounds for the generalized MinRank problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.4411v2"
    },
    {
        "title": "Abstracting Path Conditions for Effective Symbolic Execution",
        "authors": [
            "Marek Trtík"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We present an algorithm for tests generation tools based on symbolic\nexecution. The algorithm is supposed to help in situations, when a tool is\nrepeatedly failing to cover some code by tests. The algorithm then provides the\ntool a necessary condition strongly narrowing space of program paths, which\nmust be checked for reaching the uncovered code. We also discuss integration of\nthe algorithm into the tools and we provide experimental results showing a\npotential of the algorithm to be valuable in the tools, when properly\nimplemented there.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.4703v1"
    },
    {
        "title": "Critical Points and Gröbner Bases: the Unmixed Case",
        "authors": [
            "Jean-Charles Faugère",
            "Mohab Safey El Din",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We consider the problem of computing critical points of the restriction of a\npolynomial map to an algebraic variety. This is of first importance since the\nglobal minimum of such a map is reached at a critical point. Thus, these points\nappear naturally in non-convex polynomial optimization which occurs in a wide\nrange of scientific applications (control theory, chemistry, economics,...).\nCritical points also play a central role in recent algorithms of effective real\nalgebraic geometry. Experimentally, it has been observed that Gr\\\"obner basis\nalgorithms are efficient to compute such points. Therefore, recent software\nbased on the so-called Critical Point Method are built on Gr\\\"obner bases\nengines. Let $f_1,..., f_p$ be polynomials in $ \\Q[x_1,..., x_n]$ of degree\n$D$, $V\\subset\\C^n$ be their complex variety and $\\pi_1$ be the projection map\n$(x_1,.., x_n)\\mapsto x_1$. The critical points of the restriction of $\\pi_1$\nto $V$ are defined by the vanishing of $f_1,..., f_p$ and some maximal minors\nof the Jacobian matrix associated to $f_1,..., f_p$. Such a system is\nalgebraically structured: the ideal it generates is the sum of a determinantal\nideal and the ideal generated by $f_1,..., f_p$. We provide the first\ncomplexity estimates on the computation of Gr\\\"obner bases of such systems\ndefining critical points. We prove that under genericity assumptions on\n$f_1,..., f_p$, the complexity is polynomial in the generic number of critical\npoints, i.e. $D^p(D-1)^{n-p}{{n-1}\\choose{p-1}}$. More particularly, in the\nquadratic case D=2, the complexity of such a Gr\\\"obner basis computation is\npolynomial in the number of variables $n$ and exponential in $p$. We also give\nexperimental evidence supporting these theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.0179v1"
    },
    {
        "title": "Computational linear algebra over finite fields",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clément Pernet"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We present here algorithms for efficient computation of linear algebra\nproblems over finite fields.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3735v1"
    },
    {
        "title": "Matrix Formula of Differential Resultant for First Order Generic\n  Ordinary Differential Polynomials",
        "authors": [
            "Zhi-Yong Zhang",
            "Chun-Ming Yuan",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  In this paper, a matrix representation for the differential resultant of two\ngeneric ordinary differential polynomials $f_1$ and $f_2$ in the differential\nindeterminate $y$ with order one and arbitrary degree is given. That is, a\nnon-singular matrix is constructed such that its determinant contains the\ndifferential resultant as a factor. Furthermore, the algebraic sparse resultant\nof $f_1, f_2, \\delta f_1, \\delta f_2$ treated as polynomials in $y, y', y\"$ is\nshown to be a non-zero multiple of the differential resultant of $f_1, f_2$.\nAlthough very special, this seems to be the first matrix representation for a\nclass of nonlinear generic differential polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3773v1"
    },
    {
        "title": "Fast Computation of Common Left Multiples of Linear Ordinary\n  Differential Operators",
        "authors": [
            "Alin Bostan",
            "Frédéric Chyzak",
            "Ziming Li",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We study tight bounds and fast algorithms for LCLMs of several linear\ndifferential operators with polynomial coefficients. We analyze the arithmetic\ncomplexity of existing algorithms for LCLMs, as well as the size of their\noutputs. We propose a new algorithm that recasts the LCLM computation in a\nlinear algebra problem on a polynomial matrix. This algorithm yields sharp\nbounds on the coefficient degrees of the LCLM, improving by one order of\nmagnitude the best bounds obtained using previous algorithms. The complexity of\nthe new algorithm is almost optimal, in the sense that it nearly matches the\narithmetic size of the output.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.0879v1"
    },
    {
        "title": "Power Series Solutions of Singular (q)-Differential Equations",
        "authors": [
            "Alin Bostan",
            "Muhammad F. I. Chowdhury",
            "Romain Lebreton",
            "Bruno Salvy",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We provide algorithms computing power series solutions of a large class of\ndifferential or $q$-differential equations or systems. Their number of\narithmetic operations grows linearly with the precision, up to logarithmic\nterms.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.3414v1"
    },
    {
        "title": "Power Series Solution to Non-Linear Partial Differential equations of\n  Mathematical Physics",
        "authors": [
            "E. Lopez-Sandoval",
            "A. Mello",
            "J. J. Godina Nava"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Power Series Solution method has been used traditionally for to solve Linear\nDifferential Equations, in Ordinary and Partial form. But this method has been\nlimited to this kind of problems. We present the solution of problems of Non\nLinear Partial Differential equations of Physical Mathematical using power\nseries.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.2346v5"
    },
    {
        "title": "Real Root Isolation of Polynomial Equations Based on Hybrid Computation",
        "authors": [
            "Fei Shen",
            "Wenyuan Wu",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  A new algorithm for real root isolation of polynomial equations based on\nhybrid computation is presented in this paper. Firstly, the approximate\n(complex) zeros of the given polynomial equations are obtained via homotopy\ncontinuation method. Then, for each approximate zero, an initial box relying on\nthe Kantorovich theorem is constructed, which contains the corresponding\naccurate zero. Finally, the Krawczyk interval iteration with interval\narithmetic is applied to the initial boxes so as to check whether or not the\ncorresponding approximate zeros are real and to obtain the real root isolation\nboxes. Meanwhile, an empirical construction of initial box is provided for\nhigher performance. Our experiments on many benchmarks show that the new hybrid\nmethod is more efficient, compared with the traditional symbolic approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.3019v3"
    },
    {
        "title": "On lexicographic Groebner bases of radical ideals in dimension zero:\n  interpolation and structure",
        "authors": [
            "Xavier Dahan"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Due to the elimination property held by the lexicographic monomial order, the\ncorresponding Groebner bases display strong structural properties from which\nmeaningful informations can easily be extracted. We study these properties for\nradical ideals of (co)dimension zero. The proof presented relies on a\ncombinatorial decomposition of the finite set of points whereby iterated\nLagrange interpolation formulas permit to reconstruct a minimal Groebner basis.\nThis is the first fully explicit interpolation formula for polynomials forming\na lexicographic Groebner basis, from which the structure property can easily be\nread off. The inductive nature of the proof also yield as a byproduct a\ntriangular decomposition algorithm from the Groebner basis.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.3887v3"
    },
    {
        "title": "Generic Regular Decompositions for Generic Zero-Dimensional Systems",
        "authors": [
            "Xiaoxian Tang",
            "Zhenghong Chen",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Two new concepts, generic regular decomposition and\nregular-decomposition-unstable (RDU) variety for generic zero-dimensional\nsystems, are introduced in this paper and an algorithm is proposed for\ncomputing a generic regular decomposition and the associated RDU variety of a\ngiven generic zero-dimensional system simultaneously. The solutions of the\ngiven system can be expressed by finitely many zero-dimensional regular chains\nif the parameter value is not on the RDU variety.\n  The so called weakly relatively simplicial decomposition plays a crucial role\nin the algorithm, which is based on the theories of subresultant chains.\nFurthermore, the algorithm can be naturally adopted to compute a non-redundant\nWu's decomposition and the decomposition is stable at any parameter value that\nis not on the RDU variety. The algorithm has been implemented with Maple 15 and\nexperimented with a number of benchmarks from the literature. Empirical results\nare also presented to show the good performance of the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.6112v4"
    },
    {
        "title": "A new Truncated Fourier Transform algorithm",
        "authors": [
            "Andrew Arnold"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Truncated Fourier Transforms (TFTs), first introduced by Van der Hoeven,\nrefer to a family of algorithms that attempt to smooth \"jumps\" in complexity\nexhibited by FFT algorithms. We present an in-place TFT whose time complexity,\nmeasured in terms of ring operations, is comparable to existing not-in-place\nTFT methods. We also describe a transformation that maps between two families\nof TFT algorithms that use different sets of evaluation points.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4960v3"
    },
    {
        "title": "An Incremental Algorithm for Computing Cylindrical Algebraic\n  Decompositions",
        "authors": [
            "Changbo Chen",
            "Marc Moreno Maza"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  In this paper, we propose an incremental algorithm for computing cylindrical\nalgebraic decompositions. The algorithm consists of two parts: computing a\ncomplex cylindrical tree and refining this complex tree into a cylindrical tree\nin real space. The incrementality comes from the first part of the algorithm,\nwhere a complex cylindrical tree is constructed by refining a previous complex\ncylindrical tree with a polynomial constraint. We have implemented our\nalgorithm in Maple. The experimentation shows that the proposed algorithm\noutperforms existing ones for many examples taken from the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.5543v1"
    },
    {
        "title": "Multiple precision evaluation of the Airy Ai function with reduced\n  cancellation",
        "authors": [
            "Sylvain Chevillard",
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  The series expansion at the origin of the Airy function Ai(x) is alternating\nand hence problematic to evaluate for x > 0 due to cancellation. Based on a\nmethod recently proposed by Gawronski, M\\\"uller, and Reinhard, we exhibit two\nfunctions F and G, both with nonnegative Taylor expansions at the origin, such\nthat Ai(x) = G(x)/F(x). The sums are now well-conditioned, but the Taylor\ncoefficients of G turn out to obey an ill-conditioned three-term recurrence. We\nuse the classical Miller algorithm to overcome this issue. We bound all errors\nand our implementation allows an arbitrary and certified accuracy, that can be\nused, e.g., for providing correct rounding in arbitrary precision.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.4731v2"
    },
    {
        "title": "Program Verification in the presence of complex numbers, functions with\n  branch cuts etc",
        "authors": [
            "James H. Davenport",
            "Russell Bradford",
            "Matthew England",
            "David Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  In considering the reliability of numerical programs, it is normal to \"limit\nour study to the semantics dealing with numerical precision\" (Martel, 2005). On\nthe other hand, there is a great deal of work on the reliability of programs\nthat essentially ignores the numerics. The thesis of this paper is that there\nis a class of problems that fall between these two, which could be described as\n\"does the low-level arithmetic implement the high-level mathematics\". Many of\nthese problems arise because mathematics, particularly the mathematics of the\ncomplex numbers, is more difficult than expected: for example the complex\nfunction log is not continuous, writing down a program to compute an inverse\nfunction is more complicated than just solving an equation, and many algebraic\nsimplification rules are not universally valid.\n  The good news is that these problems are theoretically capable of being\nsolved, and are practically close to being solved, but not yet solved, in\nseveral real-world examples. However, there is still a long way to go before\nimplementations match the theoretical possibilities.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.5417v1"
    },
    {
        "title": "Desingularization Explains Order-Degree Curves for Ore Operators",
        "authors": [
            "Shaoshi Chen",
            "Maximilian Jaroschek",
            "Manuel Kauers",
            "Michael F. Singer"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Desingularization is the problem of finding a left multiple of a given Ore\noperator in which some factor of the leading coefficient of the original\noperator is removed. An order-degree curve for a given Ore operator is a curve\nin the $(r,d)$-plane such that for all points $(r,d)$ above this curve, there\nexists a left multiple of order $r$ and degree $d$ of the given operator. We\ngive a new proof of a desingularization result by Abramov and van Hoeij for the\nshift case, and show how desingularization implies order-degree curves which\nare extremely accurate in examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.0917v1"
    },
    {
        "title": "Finding Hyperexponential Solutions of Linear ODEs by Numerical\n  Evaluation",
        "authors": [
            "Fredrik Johansson",
            "Manuel Kauers",
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present a new algorithm for computing hyperexponential solutions of\nordinary linear differential equations with polynomial coefficients. The\nalgorithm relies on interpreting formal series solutions at the singular points\nas analytic functions and evaluating them numerically at some common ordinary\npoint. The numerical data is used to determine a small number of combinations\nof the formal series that may give rise to hyperexponential solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.2486v1"
    },
    {
        "title": "Creative telescoping for rational functions using the Griffiths-Dwork\n  method",
        "authors": [
            "Alin Bostan",
            "Pierre Lairez",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Creative telescoping algorithms compute linear differential equations\nsatisfied by multiple integrals with parameters. We describe a precise and\nelementary algorithmic version of the Griffiths-Dwork method for the creative\ntelescoping of rational functions. This leads to bounds on the order and degree\nof the coefficients of the differential equation, and to the first complexity\nresult which is simply exponential in the number of variables. One of the\nimportant features of the algorithm is that it does not need to compute\ncertificates. The approach is vindicated by a prototype implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.4313v2"
    },
    {
        "title": "From Approximate Factorization to Root Isolation with Application to\n  Cylindrical Algebraic Decomposition",
        "authors": [
            "Kurt Mehlhorn",
            "Michael Sagraloff",
            "Pengming Wang"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present an algorithm for isolating the roots of an arbitrary complex\npolynomial $p$ that also works for polynomials with multiple roots provided\nthat the number $k$ of distinct roots is given as part of the input. It outputs\n$k$ pairwise disjoint disks each containing one of the distinct roots of $p$,\nand its multiplicity. The algorithm uses approximate factorization as a\nsubroutine.\n  In addition, we apply the new root isolation algorithm to a recent algorithm\nfor computing the topology of a real planar algebraic curve specified as the\nzero set of a bivariate integer polynomial and for isolating the real solutions\nof a bivariate polynomial system. For input polynomials of degree $n$ and\nbitsize $\\tau$, we improve the currently best running time from\n$\\tO(n^{9}\\tau+n^{8}\\tau^{2})$ (deterministic) to $\\tO(n^{6}+n^{5}\\tau)$\n(randomized) for topology computation and from $\\tO(n^{8}+n^{7}\\tau)$\n(deterministic) to $\\tO(n^{6}+n^{5}\\tau)$ (randomized) for solving bivariate\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.4870v2"
    },
    {
        "title": "Closed form solutions of linear difference equations in terms of\n  symmetric products",
        "authors": [
            "Yongjae Cha"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper we show how to find a closed form solution for third order\ndifference operators in terms of solutions of second order operators. This work\nis an extension of previous results on finding closed form solutions of\nrecurrence equations and a counterpart to existing results on differential\nequations. As motivation and application for this work, we discuss the problem\nof proving positivity of sequences given merely in terms of their defining\nrecurrence relation. The main advantage of the present approach to earlier\nmethods attacking the same problem is that our algorithm provides\nhuman-readable and verifiable, i.e., certified proofs.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.4983v1"
    },
    {
        "title": "Complexity of Creative Telescoping for Bivariate Rational Functions",
        "authors": [
            "Alin Bostan",
            "Shaoshi Chen",
            "Frédéric Chyzak",
            "Ziming Li"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  The long-term goal initiated in this work is to obtain fast algorithms and\nimplementations for definite integration in Almkvist and Zeilberger's framework\nof (differential) creative telescoping. Our complexity-driven approach is to\nobtain tight degree bounds on the various expressions involved in the method.\nTo make the problem more tractable, we restrict to bivariate rational\nfunctions. By considering this constrained class of inputs, we are able to\nblend the general method of creative telescoping with the well-known Hermite\nreduction. We then use our new method to compute diagonals of rational power\nseries arising from combinatorics.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5045v1"
    },
    {
        "title": "Complexity Estimates for Two Uncoupling Algorithms",
        "authors": [
            "Alin Bostan",
            "Frédéric Chyzak",
            "Élie De Panafieu"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Uncoupling algorithms transform a linear differential system of first order\ninto one or several scalar differential equations. We examine two approaches to\nuncoupling: the cyclic-vector method (CVM) and the\nDanilevski-Barkatou-Z\\\"urcher algorithm (DBZ). We give tight size bounds on the\nscalar equations produced by CVM, and design a fast variant of CVM whose\ncomplexity is quasi-optimal with respect to the output size. We exhibit a\nstrong structural link between CVM and DBZ enabling to show that, in the\ngeneric case, DBZ has polynomial complexity and that it produces a single\nequation, strongly related to the output of CVM. We prove that algorithm CVM is\nfaster than DBZ by almost two orders of magnitude, and provide experimental\nresults that validate the theoretical complexity analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5414v2"
    },
    {
        "title": "On the Complexity of Computing Gröbner Bases for Quasi-homogeneous\n  Systems",
        "authors": [
            "Jean-Charles Faugère",
            "Mohab Safey El Din",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Let $\\K$ be a field and $(f_1, \\ldots, f_n)\\subset \\K[X_1, \\ldots, X_n]$ be a\nsequence of quasi-homogeneous polynomials of respective weighted degrees $(d_1,\n\\ldots, d_n)$ w.r.t a system of weights $(w_{1},\\dots,w_{n})$. Such systems are\nlikely to arise from a lot of applications, including physics or cryptography.\nWe design strategies for computing Gr\\\"obner bases for quasi-homogeneous\nsystems by adapting existing algorithms for homogeneous systems to the\nquasi-homogeneous case. Overall, under genericity assumptions, we show that for\na generic zero-dimensional quasi-homogeneous system, the complexity of the full\nstrategy is polynomial in the weighted B\\'ezout bound $\\prod_{i=1}^{n}d_{i} /\n\\prod_{i=1}^{n}w_{i}$. We provide some experimental results based on generic\nsystems as well as systems arising from a cryptography problem. They show that\ntaking advantage of the quasi-homogeneous structure of the systems allow us to\nsolve systems that were out of reach otherwise.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5612v3"
    },
    {
        "title": "A simple and fast algorithm for computing exponentials of power series",
        "authors": [
            "Alin Bostan",
            "Eric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  As was initially shown by Brent, exponentials of truncated power series can\nbe computed using a constant number of polynomial multiplications. This note\ngives a relatively simple algorithm with a low constant factor.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5804v1"
    },
    {
        "title": "Representation, simplification and display of fractional powers of\n  rational numbers in computer algebra",
        "authors": [
            "Albert D. Rich",
            "David R. Stoutemyer"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Simplification of fractional powers of positive rational numbers and of sums,\nproducts and powers of such numbers is taught in beginning algebra. Such\nnumbers can often be expressed in many ways, as this article discusses in some\ndetail. Since they are such a restricted subset of algebraic numbers, it might\nseem that good simplification of them must already be implemented in all widely\nused computer algebra systems. However, the algorithm taught in beginning\nalgebra uses integer factorization, which can consume unacceptable time for the\nlarge numbers that often arise within computer algebra. Therefore some systems\napparently use various ad hoc techniques that can return an incorrect result\nbecause of not simplifying to 0 the difference between two equivalent such\nexpressions. Even systems that avoid this flaw often do not return the same\nresult for all equivalent such input forms, or return an unnecessarily bulky\nresult that does not have any other compensating useful property. This article\nidentifies some of these deficiencies, then describes the advantages and\ndisadvantages of various alternative forms and how to overcome the deficiencies\nwithout costly integer factorization.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.2169v1"
    },
    {
        "title": "Computer-Aided Derivation of Multi-scale Models: A Rewriting Framework",
        "authors": [
            "Bin Yang",
            "Walid Belkhir",
            "Michel Lenczner"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We introduce a framework for computer-aided derivation of multi-scale models.\nIt relies on a combination of an asymptotic method used in the field of partial\ndifferential equations with term rewriting techniques coming from computer\nscience.\n  In our approach, a multi-scale model derivation is characterized by the\nfeatures taken into account in the asymptotic analysis. Its formulation\nconsists in a derivation of a reference model associated to an elementary\nnominal model, and in a set of transformations to apply to this proof until it\ntakes into account the wanted features. In addition to the reference model\nproof, the framework includes first order rewriting principles designed for\nasymptotic model derivations, and second order rewriting principles dedicated\nto transformations of model derivations. We apply the method to generate a\nfamily of homogenized models for second order elliptic equations with periodic\ncoefficients that could be posed in multi-dimensional domains, with possibly\nmulti-domains and/or thin domains.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.2224v1"
    },
    {
        "title": "An Algorithm for Computing the Limit Points of the Quasi-component of a\n  Regular Chain",
        "authors": [
            "Parisa Alvandi",
            "Changbo Chen",
            "Marc Moreno Maza"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  For a regular chain $R$, we propose an algorithm which computes the\n(non-trivial) limit points of the quasi-component of $R$, that is, the set\n$\\bar{W(R)} \\setminus W(R)$. Our procedure relies on Puiseux series expansions\nand does not require to compute a system of generators of the saturated ideal\nof $R$. We focus on the case where this saturated ideal has dimension one and\nwe discuss extensions of this work in higher dimensions. We provide\nexperimental results illustrating the benefits of our algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.4688v1"
    },
    {
        "title": "An implementation of CAD in Maple utilising McCallum projection",
        "authors": [
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets. Originally introduced by Collins in the\n1970s for use in quantifier elimination it has since found numerous\napplications within algebraic geometry and beyond. Following from his original\nwork in 1988, McCallum presented an improved algorithm, CADW, which offered a\nhuge increase in the practical utility of CAD. In 2009 a team based at the\nUniversity of Western Ontario presented a new and quite separate algorithm for\nCAD, which was implemented and included in the computer algebra system Maple.\nAs part of a wider project at Bath investigating CAD and its applications,\nCollins and McCallum's CAD algorithms have been implemented in Maple. This\nreport details these implementations and compares them to Qepcad and the\nOntario algorithm.\n  The implementations were originally undertaken to facilitate research into\nthe connections between the algorithms. However, the ability of the code to\nguarantee order-invariant output has led to its use in new research on CADs\nwhich are minimal for certain problems. In addition, the implementation\ndescribed here is of interest as the only full implementation of CADW, (since\nQepcad does not currently make use of McCallum's delineating polynomials), and\nhence can solve problems not admissible to other CAD implementations.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6401v1"
    },
    {
        "title": "Sparse FGLM algorithms",
        "authors": [
            "Jean-Charles Faugère",
            "Chenqi Mou"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Given a zero-dimensional ideal I in K[x1,...,xn] of degree D, the\ntransformation of the ordering of its Groebner basis from DRL to LEX is a key\nstep in polynomial system solving and turns out to be the bottleneck of the\nwhole solving process. Thus it is of crucial importance to design efficient\nalgorithms to perform the change of ordering.\n  The main contributions of this paper are several efficient methods for the\nchange of ordering which take advantage of the sparsity of multiplication\nmatrices in the classical FGLM algorithm. Combing all these methods, we propose\na deterministic top-level algorithm that automatically detects which method to\nuse depending on the input. As a by-product, we have a fast implementation that\nis able to handle ideals of degree over 40000. Such an implementation\noutperforms the Magma and Singular ones, as shown by our experiments.\n  First for the shape position case, two methods are designed based on the\nWiedemann algorithm: the first is probabilistic and its complexity to complete\nthe change of ordering is O(D(N1+nlog(D))), where N1 is the number of nonzero\nentries of a multiplication matrix; the other is deterministic and computes the\nLEX Groebner basis of the radical of I via Chinese Remainder Theorem. Then for\nthe general case, the designed method is characterized by the\nBerlekamp-Massey-Sakata algorithm from Coding Theory to handle the\nmulti-dimensional linearly recurring relations. Complexity analyses of all\nproposed methods are also provided.\n  Furthermore, for generic polynomial systems, we present an explicit formula\nfor the estimation of the sparsity of one main multiplication matrix, and prove\nits construction is free. With the asymptotic analysis of such sparsity, we are\nable to show for generic systems the complexity above becomes $O(\\sqrt{6/n \\pi}\nD^{2+(n-1)/n}})$.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.1238v1"
    },
    {
        "title": "A probabilistic algorithm to compute the real dimension of a\n  semi-algebraic set",
        "authors": [
            "Mohab Safey El Din",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Let $\\RR$ be a real closed field (e.g. the field of real numbers) and\n$\\mathscr{S} \\subset \\RR^n$ be a semi-algebraic set defined as the set of\npoints in $\\RR^n$ satisfying a system of $s$ equalities and inequalities of\nmultivariate polynomials in $n$ variables, of degree at most $D$, with\ncoefficients in an ordered ring $\\ZZ$ contained in $\\RR$. We consider the\nproblem of computing the {\\em real dimension}, $d$, of $\\mathscr{S}$. The real\ndimension is the first topological invariant of interest; it measures the\nnumber of degrees of freedom available to move in the set. Thus, computing the\nreal dimension is one of the most important and fundamental problems in\ncomputational real algebraic geometry. The problem is ${\\rm\nNP}_{\\mathbb{R}}$-complete in the Blum-Shub-Smale model of computation. The\ncurrent algorithms (probabilistic or deterministic) for computing the real\ndimension have complexity $(s \\, D)^{O(d(n-d))}$, that becomes $(s \\,\nD)^{O(n^2)}$ in the worst-case. The existence of a probabilistic or\ndeterministic algorithm for computing the real dimension with single\nexponential complexity with a factor better than ${O(n^2)}$ in the exponent in\nthe worst-case, is a longstanding open problem. We provide a positive answer to\nthis problem by introducing a probabilistic algorithm for computing the real\ndimension of a semi-algebraic set with complexity $(s\\, D)^{O(n)}$.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.1928v2"
    },
    {
        "title": "Faster sparse interpolation of straight-line programs",
        "authors": [
            "Andrew Arnold",
            "Mark Giesbrecht",
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We give a new probabilistic algorithm for interpolating a \"sparse\" polynomial\nf given by a straight-line program. Our algorithm constructs an approximation\nf* of f, such that their difference probably has at most half the number of\nterms of f, then recurses on their difference. Our approach builds on previous\nwork by Garg and Schost (2009), and Giesbrecht and Roche (2011), and is\nasymptotically more efficient in terms of the total cost of the probes required\nthan previous methods, in many cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.3483v2"
    },
    {
        "title": "Efficient Calculation of Determinants of Symbolic Matrices with Many\n  Variables",
        "authors": [
            "Tanya Khovanova",
            "Ziv Scully"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Efficient matrix determinant calculations have been studied since the 19th\ncentury. Computers expand the range of determinants that are practically\ncalculable to include matrices with symbolic entries. However, the fastest\ndeterminant algorithms for numerical matrices are often not the fastest for\nsymbolic matrices with many variables. We compare the performance of two\nalgorithms, fraction-free Gaussian elimination and minor expansion, on symbolic\nmatrices with many variables. We show that, under a simplified theoretical\nmodel, minor expansion is faster in most situations. We then propose\noptimizations for minor expansion and demonstrate their effectiveness with\nempirical data.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4691v1"
    },
    {
        "title": "Intrinsic complexity estimates in polynomial optimization",
        "authors": [
            "Bernd Bank",
            "Marc Giusti",
            "Joos Heintz",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  It is known that point searching in basic semialgebraic sets and the search\nfor globally minimal points in polynomial optimization tasks can be carried out\nusing $(s\\,d)^{O(n)}$ arithmetic operations, where $n$ and $s$ are the numbers\nof variables and constraints and $d$ is the maximal degree of the polynomials\ninvolved.\\spar \\noindent We associate to each of these problems an intrinsic\nsystem degree which becomes in worst case of order $(n\\,d)^{O(n)}$ and which\nmeasures the intrinsic complexity of the task under consideration.\\spar\n\\noindent We design non-uniformly deterministic or uniformly probabilistic\nalgorithms of intrinsic, quasi-polynomial complexity which solve these\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5214v2"
    },
    {
        "title": "Polynomial Systems Solving by Fast Linear Algebra",
        "authors": [
            "Jean-Charles Faugère",
            "Pierrick Gaudry",
            "Louise Huot",
            "Guénaël Renault"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Polynomial system solving is a classical problem in mathematics with a wide\nrange of applications. This makes its complexity a fundamental problem in\ncomputer science. Depending on the context, solving has different meanings. In\norder to stick to the most general case, we consider a representation of the\nsolutions from which one can easily recover the exact solutions or a certified\napproximation of them. Under generic assumption, such a representation is given\nby the lexicographical Gr\\\"obner basis of the system and consists of a set of\nunivariate polynomials. The best known algorithm for computing the\nlexicographical Gr\\\"obner basis is in $\\widetilde{O}(d^{3n})$ arithmetic\noperations where $n$ is the number of variables and $d$ is the maximal degree\nof the equations in the input system. The notation $\\widetilde{O}$ means that\nwe neglect polynomial factors in $n$. We show that this complexity can be\ndecreased to $\\widetilde{O}(d^{\\omega n})$ where $2 \\leq \\omega < 2.3727$ is\nthe exponent in the complexity of multiplying two dense matrices. Consequently,\nwhen the input polynomial system is either generic or reaches the B\\'ezout\nbound, the complexity of solving a polynomial system is decreased from\n$\\widetilde{O}(D^3)$ to $\\widetilde{O}(D^\\omega)$ where $D$ is the number of\nsolutions of the system. To achieve this result we propose new algorithms which\nrely on fast linear algebra. When the degree of the equations are bounded\nuniformly by a constant we propose a deterministic algorithm. In the unbounded\ncase we present a Las Vegas algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.6039v2"
    },
    {
        "title": "Optimising Problem Formulation for Cylindrical Algebraic Decomposition",
        "authors": [
            "Russell Bradford",
            "James H. Davenport",
            "Matthew England",
            "David Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Cylindrical algebraic decomposition (CAD) is an important tool for the study\nof real algebraic geometry with many applications both within mathematics and\nelsewhere. It is known to have doubly exponential complexity in the number of\nvariables in the worst case, but the actual computation time can vary greatly.\nIt is possible to offer different formulations for a given problem leading to\ngreat differences in tractability. In this paper we suggest a new measure for\nCAD complexity which takes into account the real geometry of the problem. This\nleads to new heuristics for choosing: the variable ordering for a CAD problem,\na designated equational constraint, and formulations for truth-table invariant\nCADs (TTICADs). We then consider the possibility of using Groebner bases to\nprecondition TTICAD and when such formulations constitute the creation of a new\nproblem.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7222v2"
    },
    {
        "title": "A Symbolic Approach to Boundary Problems for Linear Partial Differential\n  Equations: Applications to the Completely Reducible Case of the Cauchy\n  Problem with Constant Coefficients",
        "authors": [
            "Markus Rosenkranz",
            "Nalina Phisanbut"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We introduce a general algebraic setting for describing linear boundary\nproblems in a symbolic computation context, with emphasis on the case of\npartial differential equations. The general setting is then applied to the\nCauchy problem for completely reducible partial differential equations with\nconstant coefficients. While we concentrate on the theoretical features in this\npaper, the underlying operator ring is implemented and provides a sufficient\nbasis for all methods presented here.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7380v1"
    },
    {
        "title": "Cylindrical Algebraic Decompositions for Boolean Combinations",
        "authors": [
            "Russell Bradford",
            "James H. Davenport",
            "Matthew England",
            "Scott McCallum",
            "David Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  This article makes the key observation that when using cylindrical algebraic\ndecomposition (CAD) to solve a problem with respect to a set of polynomials, it\nis not always the signs of those polynomials that are of paramount importance\nbut rather the truth values of certain quantifier free formulae involving them.\nThis motivates our definition of a Truth Table Invariant CAD (TTICAD). We\ngeneralise the theory of equational constraints to design an algorithm which\nwill efficiently construct a TTICAD for a wide class of problems, producing\nstronger results than when using equational constraints alone. The algorithm is\nimplemented fully in Maple and we present promising results from\nexperimentation.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7603v1"
    },
    {
        "title": "An implementation of CAD in Maple utilising problem formulation,\n  equational constraints and truth-table invariance",
        "authors": [
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets, with applications within algebraic\ngeometry and beyond. We recently reported on a new implementation of CAD in\nMaple which implemented the original algorithm of Collins and the subsequent\nimprovement to projection by McCallum. Our implementation was in contrast to\nMaple's in-built CAD command, based on a quite separate theory. Although\ninitially developed as an investigative tool to compare the algorithms, we\nfound and reported that our code offered functionality not currently available\nin any other existing implementations. One particularly important piece of\nfunctionality is the ability to produce order-invariant CADs. This has allowed\nus to extend the implementation to produce CADs invariant with respect to\neither equational constraints (ECCADs) or the truth-tables of sequences of\nformulae (TTICADs). This new functionality is contained in the second release\nof our code, along with commands to consider problem formulation which can be a\nmajor factor in the tractability of a CAD. In the report we describe the new\nfunctionality and some theoretical discoveries it prompted. We describe how the\nCADs produced using equational constraints are able to take advantage of not\njust improved projection but also improvements in the lifting phase. We also\npresent an extension to the original TTICAD algorithm which increases both the\napplicability of TTICAD and its relative benefit over other algorithms. The\ncode and an introductory Maple worksheet / pdf demonstrating the full\nfunctionality of the package are freely available online.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3062v1"
    },
    {
        "title": "Deciding Nonnegativity of Polynomials by MAPLE",
        "authors": [
            "Lu Yang",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  There have been some effective tools for solving (constant/parametric)\nsemi-algebraic systems in Maple's library RegularChains since Maple 13. By\nusing the functions of the library, e.g., RealRootClassfication, one can prove\nand discover polynomial inequalities. This paper is more or less a user guide\non using RealRootClassfication to prove the nonnegativity of polynomials. We\nshow by examples how to use this powerful tool to prove a polynomial is\nnonnegative under some polynomial inequality and/or equation constraints. Some\ntricks for using the tool are also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.4059v1"
    },
    {
        "title": "Software for Evaluating Relevance of Steps in Algebraic Transformations",
        "authors": [
            "Rein Prank"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Students of our department solve algebraic exercises in mathematical logic in\na computerized environment. They construct transformations step by step and the\nprogram checks the syntax, equivalence of expressions and completion of the\ntask. With our current project, we add a program component for checking\nrelevance of the steps.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.6749v1"
    },
    {
        "title": "Signature-Based Gröbner Basis Algorithms --- Extended MMM Algorithm\n  for computing Gröbner bases",
        "authors": [
            "Yao Sun"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Signature-based algorithms is a popular kind of algorithms for computing\nGr\\\"obner bases, and many related papers have been published recently. In this\npaper, no new signature-based algorithms and no new proofs are presented.\nInstead, a view of signature-based algorithms is given, that is,\nsignature-based algorithms can be regarded as an extended version of the famous\nMMM algorithm. By this view, this paper aims to give an easier way to\nunderstand signature-based Gr\\\"obner basis algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.2371v1"
    },
    {
        "title": "Computing Equilibria of Semi-algebraic Economies Using Triangular\n  Decomposition and Real Solution Classification",
        "authors": [
            "Xiaoliang Li",
            "Dongming Wang"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper, we are concerned with the problem of determining the existence\nof multiple equilibria in economic models. We propose a general and complete\napproach for identifying multiplicities of equilibria in semi-algebraic\neconomies, which may be expressed as semi-algebraic systems. The approach is\nbased on triangular decomposition and real solution classification, two\npowerful tools of algebraic computation. Its effectiveness is illustrated by\ntwo examples of application.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.5029v1"
    },
    {
        "title": "On the Complexity of Computing Critical Points with Gröbner Bases",
        "authors": [
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Computing the critical points of a polynomial function $q\\in\\mathbb\nQ[X_1,\\ldots,X_n]$ restricted to the vanishing locus $V\\subset\\mathbb R^n$ of\npolynomials $f_1,\\ldots, f_p\\in\\mathbb Q[X_1,\\ldots, X_n]$ is of first\nimportance in several applications in optimization and in real algebraic\ngeometry. These points are solutions of a highly structured system of\nmultivariate polynomial equations involving maximal minors of a Jacobian\nmatrix. We investigate the complexity of solving this problem by using\nGr\\\"obner basis algorithms under genericity assumptions on the coefficients of\nthe input polynomials. The main results refine known complexity bounds (which\ndepend on the maximum $D=\\max(deg(f_1),\\ldots,deg(f_p),deg(q))$) to bounds\nwhich depend on the list of degrees $(deg(f_1),\\ldots,deg(f_p),deg(q))$: we\nprove that the Gr\\\"obner basis computation can be performed in\n$\\delta^{O(\\log(A)/\\log(G))}$ arithmetic operations in $\\mathbb Q$, where\n$\\delta$ is the algebraic degree of the ideal vanishing on the critical points,\nand $A$ and $G$ are the arithmetic and geometric average of a multiset\nconstructed from the sequence of degrees. As a by-product, we prove that\nsolving such generic optimization problems with Gr\\\"obner bases requires at\nmost $D^{O(n)}$ arithmetic operations in $\\mathbb Q$, which meets the best\nknown complexity bound for this problem. Finally, we illustrate these\ncomplexity results with experiments, giving evidence that these bounds are\nrelevant for applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.2138v3"
    },
    {
        "title": "A probabilistic and deterministic modular algorithm for computing\n  Groebner basis over $\\Q$",
        "authors": [
            "Bernard Parisse"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Modular algorithm are widely used in computer algebra systems (CAS), for\nexample to compute efficiently the gcd of multivariate polynomials. It is known\nto work to compute Groebner basis over $\\Q$, but it does not seem to be popular\namong CAS implementers. In this paper, I will show how to check a candidate\nGroebner basis (obtained by reconstruction of several Groebner basis modulo\ndistinct prime numbers) with a given error probability, that may be 0 if a\ncertified Groebner basis is desired. This algorithm is now the default\nalgorithm used by the Giac/Xcas computer algebra system with competitive\ntimings, thanks to a trick that can accelerate computing Groebner basis modulo\na prime once the computation has been done modulo another prime.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.4044v2"
    },
    {
        "title": "Introduction to the Symbolic Integration System",
        "authors": [
            "Weiguang Mao"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Symbolic integration is an important module of a typical Computer Algebra\nSystem. As for now, Mathematica, Matlab, Maple and Sage are all mainstream CAS.\nThey share the same framework for symbolic integration at some points. In this\nbook first we review the state of the art in the field of CAS. Then we focus on\ntypical frameworks of the current symbolic integration systems and summarize\nthe main mathematical theories behind these frameworks. Based on the\nopen-source computer algebra system maTHmU developed by our team in our\nuniversity, we propose a potential framework to improve the performance of the\ncurrent symbolic integration system.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.6655v1"
    },
    {
        "title": "On the Parameterized Complexity of Associative and Commutative\n  Unification",
        "authors": [
            "Tatsuya Akutsu",
            "Takeyuki Tamura",
            "Atsuhiro Takasu"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  This paper studies the unification problem with associative, commutative, and\nassociative-commutative functions mainly from a viewpoint of the parameterized\ncomplexity on the number of variables. It is shown that both associative and\nassociative-commutative unification problems are $W[1]$-hard. A fixed-parameter\nalgorithm and a polynomial-time algorithm are presented for special cases of\ncommutative unification in which one input term is variable-free and the number\nof variables is bounded by a constant, respectively. Related results including\nthose on the string and tree edit distance problems with variables are shown\ntoo.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.0919v1"
    },
    {
        "title": "Evaluating parametric holonomic sequences using rectangular splitting",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We adapt the rectangular splitting technique of Paterson and Stockmeyer to\nthe problem of evaluating terms in holonomic sequences that depend on a\nparameter. This approach allows computing the $n$-th term in a recurrent\nsequence of suitable type using $O(n^{1/2})$ \"expensive\" operations at the cost\nof an increased number of \"cheap\" operations.\n  Rectangular splitting has little overhead and can perform better than either\nnaive evaluation or asymptotically faster algorithms for ranges of $n$\nencountered in applications. As an example, fast numerical evaluation of the\ngamma function is investigated. Our work generalizes two previous algorithms of\nSmith.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3741v1"
    },
    {
        "title": "On the length of integers in telescopers for proper hypergeometric terms",
        "authors": [
            "Manuel Kauers",
            "Lily Yen"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We show that the number of digits in the integers of a creative telescoping\nrelation of expected minimal order for a bivariate proper hypergeometric term\nhas essentially cubic growth with the problem size. For telescopers of higher\norder but lower degree we obtain a quintic bound. Experiments suggest that\nthese bounds are tight. As applications of our results, we give an improved\nbound on the maximal possible integer root of the leading coefficient of a\ntelescoper, and the first discussion of the bit complexity of creative\ntelescoping.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3720v2"
    },
    {
        "title": "Analyzing the Dual Space of the Saturated Ideal of a Regular Set and the\n  Local Multiplicities of its Zeros",
        "authors": [
            "Xiaoliang Li",
            "Wei Niu"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper, we are concerned with the problem of counting the\nmultiplicities of a zero-dimensional regular set's zeros. We generalize the\nsquarefree decomposition of univariate polynomials to the so-called pseudo\nsquarefree decomposition of multivariate polynomials, and then propose an\nalgorithm for decomposing a regular set into a finite number of simple sets.\nFrom the output of this algorithm, the multiplicities of zeros could be\ndirectly read out, and the real solution isolation with multiplicity can also\nbe easily produced. As a main theoretical result of this paper, we analyze the\nstructure of dual space of the saturated ideal generated by a simple set as\nwell as a regular set. Experiments with a preliminary implementation show the\nefficiency of our method.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6897v2"
    },
    {
        "title": "Comprehensive Border Bases for Zero Dimensional Parametric Polynomial\n  Ideals",
        "authors": [
            "Abhishek Dubey",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper, we extend the idea of comprehensive Gr\\\"{o}bner bases given by\nWeispfenning (1992) to border bases for zero dimensional parametric polynomial\nideals. For this, we introduce a notion of comprehensive border bases and\nborder system, and prove their existence even in the cases where they do not\ncorrespond to any term order. We further present algorithms to compute\ncomprehensive border bases and border system. Finally, we study the relation\nbetween comprehensive Gr\\\"{o}bner bases and comprehensive border bases w.r.t. a\nterm order and give an algorithm to compute such comprehensive border bases\nfrom comprehensive Gr\\\"{o}bner bases.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.0453v2"
    },
    {
        "title": "A Generic Position Based Method for Real Root Isolation of\n  Zero-Dimensional Polynomial Systems",
        "authors": [
            "Jin-San Cheng",
            "Kai Jin"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We improve the local generic position method for isolating the real roots of\na zero-dimensional bivariate polynomial system with two polynomials and extend\nthe method to general zero-dimensional polynomial systems. The method mainly\ninvolves resultant computation and real root isolation of univariate polynomial\nequations. The roots of the system have a linear univariate representation. The\ncomplexity of the method is $\\tilde{O}_B(N^{10})$ for the bivariate case, where\n$N=\\max(d,\\tau)$, $d$ resp., $\\tau$ is an upper bound on the degree, resp., the\nmaximal coefficient bitsize of the input polynomials. The algorithm is\ncertified with probability 1 in the multivariate case. The implementation shows\nthat the method is efficient, especially for bivariate polynomial systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.0462v1"
    },
    {
        "title": "On the Complexity of the F5 Gröbner basis Algorithm",
        "authors": [
            "Magali Bardet",
            "Jean-Charles Faugère",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We study the complexity of Gr\\\"obner bases computation, in particular in the\ngeneric situation where the variables are in simultaneous Noether position with\nrespect to the system.\n  We give a bound on the number of polynomials of degree $d$ in a Gr\\\"obner\nbasis computed by Faug\\`ere's $F_5$ algorithm~(Fau02) in this generic case for\nthe grevlex ordering (which is also a bound on the number of polynomials for a\nreduced Gr\\\"obner basis, independently of the algorithm used). Next, we analyse\nmore precisely the structure of the polynomials in the Gr\\\"obner bases with\nsignatures that $F_5$ computes and use it to bound the complexity of the\nalgorithm.\n  Our estimates show that the version of~$F_5$ we analyse, which uses only\nstandard Gaussian elimination techniques, outperforms row reduction of the\nMacaulay matrix with the best known algorithms for moderate degrees, and even\nfor degrees up to the thousands if Strassen's multiplication is used. The\ndegree being fixed, the factor of improvement grows exponentially with the\nnumber of variables.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.1655v2"
    },
    {
        "title": "Special Algorithm for Stability Analysis of Multistable Biological\n  Regulatory Systems",
        "authors": [
            "Hoon Hong",
            "Xiaoxian Tang",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We consider the problem of counting (stable) equilibriums of an important\nfamily of algebraic differential equations modeling multistable biological\nregulatory systems. The problem can be solved, in principle, using real\nquantifier elimination algorithms, in particular real root classification\nalgorithms. However, it is well known that they can handle only very small\ncases due to the enormous computing time requirements. In this paper, we\npresent a special algorithm which is much more efficient than the general\nmethods. Its efficiency comes from the exploitation of certain interesting\nstructures of the family of differential equations.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.1780v2"
    },
    {
        "title": "Hrushovski's Algorithm for Computing the Galois Group of a Linear\n  Differential Equation",
        "authors": [
            "Ruyong Feng"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present a detailed and simplified version of Hrushovski's algorithm that\ndetermines the Galois group of a linear differential equation. There are three\nmajor ingredients in this algorithm. The first is to look for a degree bound\nfor proto-Galois groups, which enables one to compute one of them. The second\nis to determine the identity component of the Galois group that is the pullback\nof a torus to the proto-Galois group. The third is to recover the Galois group\nfrom its identity component and a finite Galois group.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.5029v3"
    },
    {
        "title": "A Generalized Apagodu-Zeilberger Algorithm",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  The Apagodu-Zeilberger algorithm can be used for computing annihilating\noperators for definite sums over hypergeometric terms, or for definite\nintegrals over hyperexponential functions. In this paper, we propose a\ngeneralization of this algorithm which is applicable to arbitrary\n$\\partial$-finite functions. In analogy to the hypergeometric case, we\nintroduce the notion of proper $\\partial$-finite functions. We show that the\nalgorithm always succeeds for these functions, and we give a tight a priori\nbound for the order of the output operator.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.2409v3"
    },
    {
        "title": "Sparse Gröbner Bases: the Unmixed Case",
        "authors": [
            "Jean-Charles Faugere",
            "Pierre-Jean Spaenlehauer",
            "Jules Svartz"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Toric (or sparse) elimination theory is a framework developped during the\nlast decades to exploit monomial structures in systems of Laurent polynomials.\nRoughly speaking, this amounts to computing in a \\emph{semigroup algebra},\n\\emph{i.e.} an algebra generated by a subset of Laurent monomials. In order to\nsolve symbolically sparse systems, we introduce \\emph{sparse Gr\\\"obner bases},\nan analog of classical Gr\\\"obner bases for semigroup algebras, and we propose\nsparse variants of the $F_5$ and FGLM algorithms to compute them. Our prototype\n\"proof-of-concept\" implementation shows large speed-ups (more than 100 for some\nexamples) compared to optimized (classical) Gr\\\"obner bases software. Moreover,\nin the case where the generating subset of monomials corresponds to the points\nwith integer coordinates in a normal lattice polytope $\\mathcal P\\subset\\mathbb\nR^n$ and under regularity assumptions, we prove complexity bounds which depend\non the combinatorial properties of $\\mathcal P$. These bounds yield new\nestimates on the complexity of solving $0$-dim systems where all polynomials\nshare the same Newton polytope (\\emph{unmixed case}). For instance, we\ngeneralize the bound $\\min(n_1,n_2)+1$ on the maximal degree in a Gr\\\"obner\nbasis of a $0$-dim. bilinear system with blocks of variables of sizes\n$(n_1,n_2)$ to the multilinear case: $\\sum n_i - \\max(n_i)+1$. We also propose\na variant of Fr\\\"oberg's conjecture which allows us to estimate the complexity\nof solving overdetermined sparse systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.7205v3"
    },
    {
        "title": "A Short Note on Zero-error Computation for Algebraic Numbers by IPSLQ",
        "authors": [
            "Yong Feng",
            "Jingwei Chen",
            "Wenyuan Wu"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  The PSLQ algorithm is one of the most popular algorithm for finding\nnontrivial integer relations for several real numbers. In the present work, we\npresent an incremental version of PSLQ. For some applications needing to call\nPSLQ many times, such as finding the minimal polynomial of an algebraic number\nwithout knowing the degree, the incremental PSLQ algorithm is more efficient\nthan PSLQ, both theoretically and practically.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.4026v1"
    },
    {
        "title": "Model-based construction of Open Non-uniform Cylindrical Algebraic\n  Decompositions",
        "authors": [
            "Christopher W. Brown"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  In this paper we introduce the notion of an Open Non-uniform Cylindrical\nAlgebraic Decomposition (NuCAD), and present an efficient model-based algorithm\nfor constructing an Open NuCAD from an input formula. A NuCAD is a\ngeneralization of Cylindrical Algebraic Decomposition (CAD) as defined by\nCollins in his seminal work from the early 1970s, and as extended in concepts\nlike Hong's partial CAD. A NuCAD, like a CAD, is a decomposition of\nn-dimensional real space into cylindrical cells. But unlike a CAD, the cells in\na NuCAD need not be arranged cylindrically. It is in this sense that NuCADs are\nnot uniformly cylindrical. However, NuCADs--- like CADs --- carry a tree-like\nstructure that relates different cells. It is a very different tree but, as\nwith the CAD tree structure, it allows some operations to be performed\nefficiently, for example locating the containing cell for an arbitrary input\npoint.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.6487v1"
    },
    {
        "title": "Procesamiento topo-geométrico de imágenes neuronales",
        "authors": [
            "Ana Romero",
            "Jónathan Heras",
            "Gadea Mata",
            "Miguel Morales y Julio Rubio"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Fruit of the relationship of our research group with the team coordinated by\nthe biologist Miguel Morales (http://spineup.es), we have applied different\ntopo-geometric techniques for neuronal image processing. The images, captured\nwith a powerful confocal microscope, allow to study the evolution of synaptic\ndensity under the influence of various substances, with the aim of studying\nneurodegenerative diseases like Alzheimer.\n  In the paper we make a brief review of the techniques that appear in our\nbioinformatic problems, including the calculation of ordinary and persistent\nhomology (for which one can use the program Kenzo for symbolic computation in\nalgebraic topology ) and classical problems of digital topology as skeleton\nlocation and path tracking. We focus on some particular cases of recent\napplication, with which we will illustrate the previous techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.6719v1"
    },
    {
        "title": "Hierarchical Comprehensive Triangular Decomposition",
        "authors": [
            "Zhenghong Chen",
            "Xiaoxian Tang",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  The concept of comprehensive triangular decomposition (CTD) was first\nintroduced by Chen et al. in their CASC'2007 paper and could be viewed as an\nanalogue of comprehensive Grobner systems for parametric polynomial systems.\nThe first complete algorithm for computing CTD was also proposed in that paper\nand implemented in the RegularChains library in Maple. Following our previous\nwork on generic regular decomposition for parametric polynomial systems, we\nintroduce in this paper a so-called hierarchical strategy for computing CTDs.\nRoughly speaking, for a given parametric system, the parametric space is\ndivided into several sub-spaces of different dimensions and we compute CTDs\nover those sub-spaces one by one. So, it is possible that, for some benchmarks,\nit is difficult to compute CTDs in reasonable time while this strategy can\nobtain some \"partial\" solutions over some parametric sub-spaces. The program\nbased on this strategy has been tested on a number of benchmarks from the\nliterature. Experimental results on these benchmarks with comparison to\nRegularChains are reported and may be valuable for developing more efficient\ntriangularization tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0599v1"
    },
    {
        "title": "A Difference Ring Theory for Symbolic Summation",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  A summation framework is developed that enhances Karr's difference field\napproach. It covers not only indefinite nested sums and products in terms of\ntranscendental extensions, but it can treat, e.g., nested products defined over\nroots of unity. The theory of the so-called $R\\Pi\\Sigma^*$-extensions is\nsupplemented by algorithms that support the construction of such difference\nrings automatically and that assist in the task to tackle symbolic summation\nproblems. Algorithms are presented that solve parameterized telescoping\nequations, and more generally parameterized first-order difference equations,\nin the given difference ring. As a consequence, one obtains algorithms for the\nsummation paradigms of telescoping and Zeilberger's creative telescoping. With\nthis difference ring theory one obtains a rigorous summation machinery that has\nbeen applied to numerous challenging problems coming, e.g., from combinatorics\nand particle physics.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.2776v2"
    },
    {
        "title": "Solving Polynomial Equations with Equation Constraints: the\n  Zero-dimensional Case",
        "authors": [
            "Ye Liang"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  A zero-dimensional polynomial ideal may have a lot of complex zeros. But\nsometimes, only some of them are needed. In this paper, for a zero-dimensional\nideal $I$, we study its complex zeros that locate in another variety\n$\\textbf{V}(J)$ where $J$ is an arbitrary ideal.\n  The main problem is that for a point in $\\textbf{V}(I) \\cap\n\\textbf{V}(J)=\\textbf{V}(I+J)$, its multiplicities w.r.t. $I$ and $I+J$ may be\ndifferent. Therefore, we cannot get the multiplicity of this point w.r.t. $I$\nby studying $I + J$. A straightforward way is that first compute the points of\n$\\textbf{V}(I + J)$, then study their multiplicities w.r.t. $I$. But the former\nstep is difficult to realize exactly.\n  In this paper, we propose a natural geometric explanation of the localization\nof a polynomial ring corresponding to a semigroup order. Then, based on this\nview, using the standard basis method and the border basis method, we introduce\na way to compute the complex zeros of $I$ in $\\textbf{V}(J)$ with their\nmultiplicities w.r.t. $I$. As an application, we compute the sum of Milnor\nnumbers of the singular points on a polynomial hypersurface and work out all\nthe singular points on the hypersurface with their Milnor numbers.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.3639v1"
    },
    {
        "title": "Computing the determinant of a matrix with polynomial entries by\n  approximation",
        "authors": [
            "Xiaolin Qin",
            "Zhi Sun",
            "Tuo Leng",
            "Yong Feng"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Computing the determinant of a matrix with the univariate and multivariate\npolynomial entries arises frequently in the scientific computing and\nengineering fields. In this paper, an effective algorithm is presented for\ncomputing the determinant of a matrix with polynomial entries using hybrid\nsymbolic and numerical computation. The algorithm relies on the Newton's\ninterpolation method with error control for solving Vandermonde systems. It is\nalso based on a novel approach for estimating the degree of variables, and the\ndegree homomorphism method for dimension reduction. Furthermore, the\nparallelization of the method arises naturally.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5879v2"
    },
    {
        "title": "A canonical form for the continuous piecewise polynomial functions",
        "authors": [
            "Jorge Caravantes",
            "M. Angeles Gomez-Molleda",
            "Laureano Gonzalez-Vega"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We present in this paper a canonical form for the elements in the ring of\ncontinuous piecewise polynomial functions. This new representation is based on\nthe use of a particular class of functions\n$$\\{C_i(P):P\\in\\Q[x],i=0,\\ldots,\\deg(P)\\}$$ defined by $$C_i(P)(x)= \\left\\{\n\\begin{array}{cll}0 & \\mbox{ if } & x \\leq \\alpha \\\\ P(x) & \\mbox{ if } & x\n\\geq \\alpha \\end{array} \\right.$$ where $\\alpha$ is the $i$-th real root of the\npolynomial $P$. These functions will allow us to represent and manipulate\neasily every continuous piecewise polynomial function through the use of the\ncorresponding canonical form.\n  It will be also shown how to produce a \"rational\" representation of each\nfunction $C_{i}(P)$ allowing its evaluation by performing only operations in\n$\\Q$ and avoiding the use of any real algebraic number.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.6919v1"
    },
    {
        "title": "A streamlined difference ring theory: Indefinite nested sums, the\n  alternating sign and the parameterized telescoping problem",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We present an algebraic framework to represent indefinite nested sums over\nhypergeometric expressions in difference rings. In order to accomplish this\ntask, parts of Karr's difference field theory have been extended to a ring\ntheory in which also the alternating sign can be expressed. The underlying\nmachinery relies on algorithms that compute all solutions of a given\nparameterized telescoping equation. As a consequence, we can solve the\ntelescoping and creative telescoping problem in such difference rings.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.2782v2"
    },
    {
        "title": "A Successive Resultant Projection for Cylindrical Algebraic\n  Decomposition",
        "authors": [
            "Yong Yao",
            "Jia Xu",
            "Lu Yang"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  This note shows the equivalence of two projection operators which both can be\nused in cylindrical algebraic decomposition (CAD) . One is known as Brown's\nProjection (C. W. Brown (2001)); the other was proposed by Lu Yang in his\nearlier work (L.Yang and S.~H. Xia (2000)) that is sketched as follows: given a\npolynomial $f$ in $x_1,\\,x_2,\\,\\cdots$, by $f_1$ denote the resultant of $f$\nand its partial derivative with respect to $x_1$ (removing the multiple\nfactors), by $f_2$ denote the resultant of $f_1$ and its partial derivative\nwith respect to $x_2$, (removing the multiple factors), $\\cdots$, repeat this\nprocedure successively until the last resultant becomes a univariate\npolynomial. Making use of an identity, the equivalence of these two projection\noperators is evident.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.4861v1"
    },
    {
        "title": "Probabilistic analysis of Wiedemann's algorithm for minimal polynomial\n  computation",
        "authors": [
            "Gavin Harrison",
            "Jeremy Johnson",
            "B. David Saunders"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Blackbox algorithms for linear algebra problems start with projection of the\nsequence of powers of a matrix to a sequence of vectors (Lanczos), a sequence\nof scalars (Wiedemann) or a sequence of smaller matrices (block methods). Such\nalgorithms usually depend on the minimal polynomial of the resulting sequence\nbeing that of the given matrix. Here exact formulas are given for the\nprobability that this occurs. They are based on the generalized Jordan normal\nform (direct sum of companion matrices of the elementary divisors) of the\nmatrix. Sharp bounds follow from this for matrices of unknown elementary\ndivisors. The bounds are valid for all finite field sizes and show that a small\nblocking factor can give high probability of success for all cardinalities and\nmatrix dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.5071v3"
    },
    {
        "title": "On the complexity of computing Gröbner bases for weighted homogeneous\n  systems",
        "authors": [
            "Jean-Charles Faugère",
            "Mohab Safey El Din",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Solving polynomial systems arising from applications is frequently made\neasier by the structure of the systems. Weighted homogeneity (or\nquasi-homogeneity) is one example of such a structure: given a system of\nweights $W=(w\\_{1},\\dots,w\\_{n})$, $W$-homogeneous polynomials are polynomials\nwhich are homogeneous w.r.t the weighted degree\n$\\deg\\_{W}(X\\_{1}^{\\alpha\\_{1}},\\dots,X\\_{n}^{\\alpha\\_{n}}) = \\sum\nw\\_{i}\\alpha\\_{i}$. Gr\\\"obner bases for weighted homogeneous systems can be\ncomputed by adapting existing algorithms for homogeneous systems to the\nweighted homogeneous case. We show that in this case, the complexity estimate\nfor Algorithm~\\F5 $\\left(\\binom{n+\\dmax-1}{\\dmax}^{\\omega}\\right)$ can be\ndivided by a factor $\\left(\\prod w\\_{i} \\right)^{\\omega}$. For zero-dimensional\nsystems, the complexity of Algorithm~\\FGLM $nD^{\\omega}$ (where $D$ is the\nnumber of solutions of the system) can be divided by the same factor\n$\\left(\\prod w\\_{i} \\right)^{\\omega}$. Under genericity assumptions, for\nzero-dimensional weighted homogeneous systems of $W$-degree\n$(d\\_{1},\\dots,d\\_{n})$, these complexity estimates are polynomial in the\nweighted B\\'ezout bound $\\prod\\_{i=1}^{n}d\\_{i} / \\prod\\_{i=1}^{n}w\\_{i}$.\nFurthermore, the maximum degree reached in a run of Algorithm \\F5 is bounded by\nthe weighted Macaulay bound $\\sum (d\\_{i}-w\\_{i}) + w\\_{n}$, and this bound is\nsharp if we can order the weights so that $w\\_{n}=1$. For overdetermined\nsemi-regular systems, estimates from the homogeneous case can be adapted to the\nweighted case. We provide some experimental results based on systems arising\nfrom a cryptography problem and from polynomial inversion problems. They show\nthat taking advantage of the weighted homogeneous structure yields substantial\nspeed-ups, and allows us to solve systems which were otherwise out of reach.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.7547v2"
    },
    {
        "title": "Real root finding for rank defects in linear Hankel matrices",
        "authors": [
            "Didier Henrion",
            "Simone Naldi",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Let $H\\_0, ..., H\\_n$ be $m \\times m$ matrices with entries in $\\QQ$ and\nHankel structure, i.e. constant skew diagonals. We consider the linear Hankel\nmatrix $H(\\vecx)=H\\_0+\\X\\_1H\\_1+...+\\X\\_nH\\_n$ and the problem of computing\nsample points in each connected component of the real algebraic set defined by\nthe rank constraint ${\\sf rank}(H(\\vecx))\\leq r$, for a given integer $r \\leq\nm-1$. Computing sample points in real algebraic sets defined by rank defects in\nlinear matrices is a general problem that finds applications in many areas such\nas control theory, computational geometry, optimization, etc. Moreover, Hankel\nmatrices appear in many areas of engineering sciences. Also, since Hankel\nmatrices are symmetric, any algorithmic development for this problem can be\nseen as a first step towards a dedicated exact algorithm for solving\nsemi-definite programming problems, i.e. linear matrix inequalities. Under some\ngenericity assumptions on the input (such as smoothness of an incidence\nvariety), we design a probabilistic algorithm for tackling this problem. It is\nan adaptation of the so-called critical point method that takes advantage of\nthe special structure of the problem. Its complexity reflects this: it is\nessentially quadratic in specific degree bounds on an incidence variety. We\nreport on practical experiments and analyze how the algorithm takes advantage\nof this special structure. A first implementation outperforms existing\nimplementations for computing sample points in general real algebraic sets: it\ntackles examples that are out of reach of the state-of-the-art.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.02473v1"
    },
    {
        "title": "On Sequences, Rational Functions and Decomposition",
        "authors": [
            "Graham H. Norton"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Our overall goal is to unify and extend some results in the literature\nrelated to the approximation of generating functions of finite and infinite\nsequences over a field by rational functions. In our approach, numerators play\na significant role. We revisit a theorem of Niederreiter on (i) linear\ncomplexities and (ii) '$n^{th}$ minimal polynomials' of an infinite sequence,\nproved using partial quotients. We prove (i) and its converse from first\nprinciples and generalise (ii) to rational functions where the denominator need\nnot have minimal degree. We prove (ii) in two parts: firstly for geometric\nsequences and then for sequences with a jump in linear complexity. The basic\nidea is to decompose the denominator as a sum of polynomial multiples of two\npolynomials of minimal degree; there is a similar decomposition for the\nnumerators. The decomposition is unique when the denominator has degree at most\nthe length of the sequence. The proof also applies to rational functions\nrelated to finite sequences, generalising a result of Massey. We give a number\nof applications to rational functions associated to sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.06152v3"
    },
    {
        "title": "Groebner basis in Boolean rings is not polynomial-space",
        "authors": [
            "Mark van Hoeij"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We give an example where the number of elements of a Groebner basis in a\nBoolean ring is not polynomially bounded in terms of the bitsize and degrees of\nthe input.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07220v2"
    },
    {
        "title": "On the Computation of the Galois Group of Linear Difference Equations",
        "authors": [
            "Ruyong Feng"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We present an algorithm that determines the Galois group of linear difference\nequations with rational function coefficients.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.02239v1"
    },
    {
        "title": "A Triangular Decomposition Algorithm for Differential Polynomial Systems\n  with Elementary Computation Complexity",
        "authors": [
            "Wei Zhu",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  In this paper, a new triangular decomposition algorithm is proposed for\nordinary differential polynomial systems, which has triple exponential\ncomputational complexity. The key idea is to eliminate one algebraic variable\nfrom a set of polynomials in one step using the theory of multivariate\nresultant. This seems to be the first differential triangular decomposition\nalgorithm with elementary computation complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.04380v1"
    },
    {
        "title": "An implementation of Sub-CAD in Maple",
        "authors": [
            "Matthew England",
            "David Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets, with applications in algebraic geometry\nand beyond. We have previously reported on an implementation of CAD in Maple\nwhich offers the original projection and lifting algorithm of Collins along\nwith subsequent improvements.\n  Here we report on new functionality: specifically the ability to build\ncylindrical algebraic sub-decompositions (sub-CADs) where only certain cells\nare returned. We have implemented algorithms to return cells of a prescribed\ndimensions or higher (layered {\\scad}s), and an algorithm to return only those\ncells on which given polynomials are zero (variety {\\scad}s). These offer\nsubstantial savings in output size and computation time.\n  The code described and an introductory Maple worksheet / pdf demonstrating\nthe full functionality of the package are freely available online at\nhttp://opus.bath.ac.uk/43911/.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06599v1"
    },
    {
        "title": "One-Step Stochastic Processes Simulation Software Package",
        "authors": [
            "E. G. Eferina",
            "A. V. Korolkova",
            "M. N. Gevorkyan",
            "D. S. Kulyabov",
            "L. A. Sevastyanov"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Background. It is assumed that the introduction of stochastic in mathematical\nmodel makes it more adequate. But there is virtually no methods of coordinated\n(depended on structure of the system) stochastic introduction into\ndeterministic models. Authors have improved the method of stochastic models\nconstruction for the class of one-step processes and illustrated by models of\npopulation dynamics. Population dynamics was chosen for study because its\ndeterministic models were sufficiently well explored that allows to compare the\nresults with already known ones.\n  Purpose. To optimize the models creation as much as possible some routine\noperations should be automated. In this case, the process of drawing up the\nmodel equations can be algorithmized and implemented in the computer algebra\nsystem. Furthermore, on the basis of these results a set of programs for\nnumerical experiment can be obtained.\n  Method. The computer algebra system Axiom is used for analytical calculations\nimplementation. To perform the numerical experiment FORTRAN and Julia languages\nare used. The method Runge--Kutta method for stochastic differential equations\nis used as numerical method.\n  Results. The program compex for creating stochastic one-step processes models\nis constructed. Its application is illustrated by the predator-prey population\ndynamic system.\n  Conclusions. Computer algebra systems are very convenient for the purposes of\nrapid prototyping in mathematical models design and analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.07342v1"
    },
    {
        "title": "Index reduction of differential algebraic equations by differential\n  algebraic elimination",
        "authors": [
            "Xiaolin Qin",
            "Lu Yang",
            "Yong Feng",
            "Bernhard Bachmann",
            "Peter Fritzson"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  High index differential algebraic equations (DAEs) are ordinary differential\nequations (ODEs) with constraints and arise frequently from many mathematical\nmodels of physical phenomenons and engineering fields. In this paper, we\ngeneralize the idea of differential elimination with Dixon resultant to\npolynomially nonlinear DAEs. We propose a new algorithm for index reduction of\nDAEs and establish the notion of differential algebraic elimination, which can\nprovide the differential algebraic resultant of the enlarged system of original\nequations. To make use of structure of DAEs, variable pencil technique is given\nto determine the termination of differentiation. Moreover, we also provide a\nheuristics method for removing the extraneous factors from differential\nalgebraic resultant. The experimentation shows that the proposed algorithm\noutperforms existing ones for many examples taken from the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.04977v1"
    },
    {
        "title": "An algorithm for computing Grobner basis and the complexity evaluation",
        "authors": [
            "Yong-Jin Kim",
            "Hyon-Song Paek",
            "Nam-Chol Kim",
            "Chong-Il Byon"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  In this paper, we suggest a new efficient algorithm in order to compute\nS-polynomial reduction rapidly in the known algorithm for computing Grobner\nbases, and compare the complexity with others.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.03217v1"
    },
    {
        "title": "Open Weak CAD and its Applications",
        "authors": [
            "Jingjun Han",
            "Liyun Dai",
            "Hoon Hong",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  The concept of open weak CAD is introduced. Every open CAD is an open weak\nCAD. On the contrary, an open weak CAD is not necessarily an open CAD. An\nalgorithm for computing projection polynomials of open weak CADs is proposed.\nThe key idea is to compute the intersection of projection factor sets produced\nby different projection orders. The resulting open weak CAD often has smaller\nnumber of sample points than open CADs. The algorithm can be used for computing\nsample points for all open connected components of $ f\\neq0$ for a given\npolynomial $f$. It can also be used for many other applications, such as\ntesting semi-definiteness of polynomials and copositive problems. In fact, we\nsolved several difficult semi-definiteness problems efficiently by using the\nalgorithm. Furthermore, applying the algorithm to copositive problems, we find\nan explicit expression of the polynomials producing open weak CADs under some\nconditions, which significantly improves the efficiency of solving copositive\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.03834v3"
    },
    {
        "title": "Formulas for Continued Fractions. An Automated Guess and Prove Approach",
        "authors": [
            "Sébastien Maulat",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We describe a simple method that produces automatically closed forms for the\ncoefficients of continued fractions expansions of a large number of special\nfunctions. The function is specified by a non-linear differential equation and\ninitial conditions. This is used to generate the first few coefficients and\nfrom there a conjectured formula. This formula is then proved automatically\nthanks to a linear recurrence satisfied by some remainder terms. Extensive\nexperiments show that this simple approach and its straightforward\ngeneralization to difference and $q$-difference equations capture a large part\nof the formulas in the literature on continued fractions.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.04203v1"
    },
    {
        "title": "Algebraic Local Cohomology with Parameters and Parametric Standard Bases\n  for Zero-Dimensional Ideals",
        "authors": [
            "Katsusuke Nabeshima",
            "Shinichi Tajima"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  A computation method of algebraic local cohomology with parameters,\nassociated with zero-dimensional ideal with parameter, is introduced. This\ncomputation method gives us in particular a decomposition of the parameter\nspace depending on the structure of algebraic local cohomology classes. This\ndecomposition informs us several properties of input ideals and the output of\nour algorithm completely describes the multiplicity structure of input ideals.\nAn efficient algorithm for computing a parametric standard basis of a given\nzero-dimensional ideal, with respect to an arbitrary local term order, is also\ndescribed as an application of the computation method. The algorithm can always\noutput \"reduced\" standard basis of a given zero-dimensional ideal, even if the\nzero-dimensional ideal has parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.06724v1"
    },
    {
        "title": "Algebraic Diagonals and Walks",
        "authors": [
            "Alin Bostan",
            "Louis Dumont",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  The diagonal of a multivariate power series F is the univariate power series\nDiag(F) generated by the diagonal terms of F. Diagonals form an important class\nof power series; they occur frequently in number theory, theoretical physics\nand enumerative combinatorics. We study algorithmic questions related to\ndiagonals in the case where F is the Taylor expansion of a bivariate rational\nfunction. It is classical that in this case Diag(F) is an algebraic function.\nWe propose an algorithm that computes an annihilating polynomial for Diag(F).\nGenerically, it is its minimal polynomial and is obtained in time quasi-linear\nin its size. We show that this minimal polynomial has an exponential size with\nrespect to the degree of the input rational function. We then address the\nrelated problem of enumerating directed lattice walks. The insight given by our\nstudy leads to a new method for expanding the generating power series of\nbridges, excursions and meanders. We show that their first N terms can be\ncomputed in quasi-linear complexity in N, without first computing a very large\npolynomial equation.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.04080v1"
    },
    {
        "title": "Algebraic Diagonals and Walks: Algorithms, Bounds, Complexity",
        "authors": [
            "Alin Bostan",
            "Louis Dumont",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  The diagonal of a multivariate power series F is the univariate power series\nDiag(F) generated by the diagonal terms of F. Diagonals form an important class\nof power series; they occur frequently in number theory, theoretical physics\nand enumerative combinatorics. We study algorithmic questions related to\ndiagonals in the case where F is the Taylor expansion of a bivariate rational\nfunction. It is classical that in this case Diag(F) is an algebraic function.\nWe propose an algorithm that computes an annihilating polynomial for Diag(F).\nWe give a precise bound on the size of this polynomial and show that\ngenerically, this polynomial is the minimal polynomial and that its size\nreaches the bound. The algorithm runs in time quasi-linear in this bound, which\ngrows exponentially with the degree of the input rational function. We then\naddress the related problem of enumerating directed lattice walks. The insight\ngiven by our study leads to a new method for expanding the generating power\nseries of bridges, excursions and meanders. We show that their first N terms\ncan be computed in quasi-linear complexity in N, without first computing a very\nlarge polynomial equation.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.04526v1"
    },
    {
        "title": "On p-adic differential equations with separation of variables",
        "authors": [
            "Pierre Lairez",
            "Tristan Vaccon"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Several algorithms in computer algebra involve the computation of a power\nseries solution of a given ordinary differential equation. Over finite fields,\nthe problem is often lifted in an approximate $p$-adic setting to be\nwell-posed. This raises precision concerns: how much precision do we need on\nthe input to compute the output accurately? In the case of ordinary\ndifferential equations with separation of variables, we make use of the recent\ntechnique of differential precision to obtain optimal bounds on the stability\nof the Newton iteration. The results apply, for example, to algorithms for\nmanipulating algebraic numbers over finite fields, for computing isogenies\nbetween elliptic curves or for deterministically finding roots of polynomials\nin finite fields. The new bounds lead to significant speedups in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00244v2"
    },
    {
        "title": "Reduction-Based Creative Telescoping for Algebraic Functions",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Continuing a series of articles in the past few years on creative telescoping\nusing reductions, we develop a new algorithm to construct minimal telescopers\nfor algebraic functions. This algorithm is based on Trager's Hermite reduction\nand on polynomial reduction, which was originally designed for hyperexponential\nfunctions and extended to the algebraic case in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00424v1"
    },
    {
        "title": "Fast Computation of Minimal Interpolation Bases in Popov Form for\n  Arbitrary Shifts",
        "authors": [
            "Claude-Pierre Jeannerod",
            "Vincent Neiger",
            "Eric Schost",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We compute minimal bases of solutions for a general interpolation problem,\nwhich encompasses Hermite-Pad\\'e approximation and constrained multivariate\ninterpolation, and has applications in coding theory and security.\n  This problem asks to find univariate polynomial relations between $m$ vectors\nof size $\\sigma$; these relations should have small degree with respect to an\ninput degree shift. For an arbitrary shift, we propose an algorithm for the\ncomputation of an interpolation basis in shifted Popov normal form with a cost\nof $\\mathcal{O}\\tilde{~}(m^{\\omega-1} \\sigma)$ field operations, where $\\omega$\nis the exponent of matrix multiplication and the notation\n$\\mathcal{O}\\tilde{~}(\\cdot)$ indicates that logarithmic terms are omitted.\n  Earlier works, in the case of Hermite-Pad\\'e approximation and in the general\ninterpolation case, compute non-normalized bases. Since for arbitrary shifts\nsuch bases may have size $\\Theta(m^2 \\sigma)$, the cost bound\n$\\mathcal{O}\\tilde{~}(m^{\\omega-1} \\sigma)$ was feasible only with restrictive\nassumptions on the shift that ensure small output sizes. The question of\nhandling arbitrary shifts with the same complexity bound was left open.\n  To obtain the target cost for any shift, we strengthen the properties of the\noutput bases, and of those obtained during the course of the algorithm: all the\nbases are computed in shifted Popov form, whose size is always $\\mathcal{O}(m\n\\sigma)$. Then, we design a divide-and-conquer scheme. We recursively reduce\nthe initial interpolation problem to sub-problems with more convenient shifts\nby first computing information on the degrees of the intermediate bases.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00651v2"
    },
    {
        "title": "Fast Computation of Shifted Popov Forms of Polynomial Matrices via\n  Systems of Modular Polynomial Equations",
        "authors": [
            "Vincent Neiger"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We give a Las Vegas algorithm which computes the shifted Popov form of an $m\n\\times m$ nonsingular polynomial matrix of degree $d$ in expected\n$\\widetilde{\\mathcal{O}}(m^\\omega d)$ field operations, where $\\omega$ is the\nexponent of matrix multiplication and $\\widetilde{\\mathcal{O}}(\\cdot)$\nindicates that logarithmic factors are omitted. This is the first algorithm in\n$\\widetilde{\\mathcal{O}}(m^\\omega d)$ for shifted row reduction with arbitrary\nshifts.\n  Using partial linearization, we reduce the problem to the case $d \\le \\lceil\n\\sigma/m \\rceil$ where $\\sigma$ is the generic determinant bound, with $\\sigma\n/ m$ bounded from above by both the average row degree and the average column\ndegree of the matrix. The cost above becomes $\\widetilde{\\mathcal{O}}(m^\\omega\n\\lceil \\sigma/m \\rceil)$, improving upon the cost of the fastest previously\nknown algorithm for row reduction, which is deterministic.\n  Our algorithm first builds a system of modular equations whose solution set\nis the row space of the input matrix, and then finds the basis in shifted Popov\nform of this set. We give a deterministic algorithm for this second step\nsupporting arbitrary moduli in $\\widetilde{\\mathcal{O}}(m^{\\omega-1} \\sigma)$\nfield operations, where $m$ is the number of unknowns and $\\sigma$ is the sum\nof the degrees of the moduli. This extends previous results with the same cost\nbound in the specific cases of order basis computation and M-Pad\\'e\napproximation, in which the moduli are products of known linear factors.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00710v2"
    },
    {
        "title": "Linear Time Interactive Certificates for the Minimal Polynomial and the\n  Determinant of a Sparse Matrix",
        "authors": [
            "Jean-Guillaume Dumas",
            "Erich Kaltofen",
            "Emmanuel Thomé",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Computational problem certificates are additional data structures for each\noutput, which can be used by a-possibly randomized-verification algorithm that\nproves the correctness of each output. In this paper, we give an algorithm that\ncomputes a certificate for the minimal polynomial of sparse or structured nxn\nmatrices over an abstract field, of sufficiently large cardinality, whose Monte\nCarlo verification complexity requires a single matrix-vector multiplication\nand a linear number of extra field operations. We also propose a novel\npreconditioner that ensures irreducibility of the characteristic polynomial of\nthe generically preconditioned matrix. This preconditioner takes linear time to\nbe applied and uses only two random entries. We then combine these two\ntechniques to give algorithms that compute certificates for the determinant,\nand thus for the characteristic polynomial, whose Monte Carlo verification\ncomplexity is therefore also linear.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00810v2"
    },
    {
        "title": "Algorithms for Simultaneous Padé Approximations",
        "authors": [
            "Johan S. R. Nielsen",
            "Arne Storjohann"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We describe how to solve simultaneous Pad\\'e approximations over a power\nseries ring $K[[x]]$ for a field $K$ using $O~(n^{\\omega - 1} d)$ operations in\n$K$, where $d$ is the sought precision and $n$ is the number of power series to\napproximate. We develop two algorithms using different approaches. Both\nalgorithms return a reduced sub-bases that generates the complete set of\nsolutions to the input approximations problem that satisfy the given degree\nconstraints. Our results are made possible by recent breakthroughs in fast\ncomputations of minimal approximant bases and Hermite Pad\\'e approximations.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00836v2"
    },
    {
        "title": "Computing with quasiseparable matrices",
        "authors": [
            "Clement Pernet"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  The class of quasiseparable matrices is defined by a pair of bounds, called\nthe quasiseparable orders, on the ranks of the maximal sub-matrices entirely\nlocated in their strictly lower and upper triangular parts. These arise\nnaturally in applications, as e.g. the inverse of band matrices, and are widely\nused for they admit structured representations allowing to compute with them in\ntime linear in the dimension and quadratic with the quasiseparable order. We\nshow, in this paper, the connection between the notion of quasisepa-rability\nand the rank profile matrix invariant, presented in [Dumas \\& al. ISSAC'15].\nThis allows us to propose an algorithm computing the quasiseparable orders (rL,\nrU) in time O(n^2 s^($\\omega$--2)) where s = max(rL, rU) and $\\omega$ the\nexponent of matrix multiplication. We then present two new structured\nrepresentations, a binary tree of PLUQ decompositions, and the Bruhat\ngenerator, using respectively O(ns log n/s) and O(ns) field elements instead of\nO(ns^2) for the previously known generators. We present algorithms computing\nthese representations in time O(n^2 s^($\\omega$--2)). These representations\nallow a matrix-vector product in time linear in the size of their\nrepresentation. Lastly we show how to multiply two such structured matrices in\ntime O(n^2 s^($\\omega$--2)).\n",
        "pdf_link": "http://arxiv.org/pdf/1602.01246v2"
    },
    {
        "title": "A fast, deterministic algorithm for computing a Hermite Normal Form of a\n  polynomial matrix",
        "authors": [
            "George Labahn",
            "Wei Zhou"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Given a square, nonsingular matrix of univariate polynomials $\\mathbf{F} \\in\n\\mathbb{K}[x]^{n \\times n}$ over a field $\\mathbb{K}$, we give a fast,\ndeterministic algorithm for finding the Hermite normal form of $\\mathbf{F}$\nwith complexity $O^{\\sim}\\left(n^{\\omega}d\\right)$ where $d$ is the degree of\n$\\mathbf{F}$. Here soft-$O$ notation is Big-$O$ with log factors removed and\n$\\omega$ is the exponent of matrix multiplication. The method relies of a fast\nalgorithm for determining the diagonal entries of its Hermite normal form,\nhaving as cost $O^{\\sim}\\left(n^{\\omega}s\\right)$ operations with $s$ the\naverage of the column degrees of $\\mathbf{F}$.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.02049v1"
    },
    {
        "title": "On Gröbner Bases and Krull Dimension of Residue Class Rings of\n  Polynomial Rings over Integral Domains",
        "authors": [
            "Maria Francis",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Given an ideal $\\mathfrak{a}$ in $A[x_1, \\ldots, x_n]$, where $A$ is a\nNoetherian integral domain, we propose an approach to compute the Krull\ndimension of $A[x_1,\\ldots,x_n]/\\mathfrak{a}$, when the residue class\npolynomial ring is a free $A$-module. When $A$ is a field, the Krull dimension\nof $A[x_1,\\ldots,x_n]/\\mathfrak{a}$ has several equivalent algorithmic\ndefinitions by which it can be computed. But this is not true in the case of\narbitrary Noetherian rings. For a Noetherian integral domain, $A$ we introduce\nthe notion of combinatorial dimension of $A[x_1, \\ldots,x_n]/\\mathfrak{a}$ and\ngive a Gr\\\"obner basis method to compute it for residue class polynomial rings\nthat have a free $A$-module representation w.r.t. a lexicographic ordering. For\nsuch $A$-algebras, we derive a relation between Krull dimension and\ncombinatorial dimension of $A[x_1, \\ldots, x_n]/\\mathfrak{a}$. An immediate\napplication of this relation is that it gives a uniform method, the first of\nits kind, to compute the dimension of $A[x_1, \\ldots, x_n]/\\mathfrak{a}$\nwithout having to consider individual properties of the ideal. For $A$-algebras\nthat have a free $A$-module representation w.r.t. degree compatible monomial\norderings, we introduce the concepts of Hilbert function, Hilbert series and\nHilbert polynomials and show that Gr\\\"obner basis methods can be used to\ncompute these quantities. We then proceed to show that the combinatorial\ndimension of such $A$-algebras is equal to the degree of the Hilbert\npolynomial. This enables us to extend the relation between Krull dimension and\ncombinatorial dimension to $A$-algebras with a free $A$-module representation\nw.r.t. a degree compatible ordering as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.04300v4"
    },
    {
        "title": "An Illustrated Introduction to the Truncated Fourier Transform",
        "authors": [
            "Paul Vrbik"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  The Truncated Fourier Transform (TFT) is a variation of the Discrete Fourier\nTransform (DFT/FFT) that allows for input vectors that do NOT have length $2^n$\nfor $n$ a positive integer. We present the univariate version of the TFT,\noriginally due to Joris van der Hoeven, heavily illustrating the presentation\nin order to make these methods accessible to a broader audience.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.04562v2"
    },
    {
        "title": "GBLA -- Gröbner Basis Linear Algebra Package",
        "authors": [
            "Brice Boyer",
            "Christian Eder",
            "Jean-Charles Faugère",
            "Sylvian Lachartre",
            "Fayssal Martani"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  This is a system paper about a new GPLv2 open source C library GBLA\nimplementing and improving the idea of Faug\\`ere and Lachartre (GB reduction).\nWe further exploit underlying structures in matrices generated during Gr\\\"obner\nbasis computations in algorithms like F4 or F5 taking advantage of block\npatterns by using a special data structure called multilines. Moreover, we\ndiscuss a new order of operations for the reduction process. In various\ndifferent experimental results we show that GBLA performs better than GB\nreduction or Magma in sequential computations (up to 40% faster) and scales\nmuch better than GB reduction for a higher number of cores: On 32 cores we\nreach a scaling of up to 26. GBLA is up to 7 times faster than GB reduction.\nFurther, we compare different parallel schedulers GBLA can be used with. We\nalso developed a new advanced storage format that exploits the fact that our\nmatrices are coming from Gr\\\"obner basis computations, shrinking storage by a\nfactor of up to 4. A huge database of our matrices is freely available with\nGBLA.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.06097v1"
    },
    {
        "title": "Sparse Representations of Clifford and Tensor algebras in Maxima",
        "authors": [
            "Dimiter Prodanov",
            "Viktor T. Toth"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Clifford algebras have broad applications in science and engineering. The use\nof Clifford algebras can be further promoted in these fields by availability of\ncomputational tools that automate tedious routine calculations. We offer an\nextensive demonstration of the applications of Clifford algebras in\nelectromagnetism using the geometric algebra G3 = Cl(3,0) as a computational\nmodel in the Maxima computer algebra system. We compare the geometric\nalgebra-based approach with conventional symbolic tensor calculations supported\nby Maxima, based on the itensor package. The Clifford algebra functionality of\nMaxima is distributed as two new packages called clifford - for basic\nsimplification of Clifford products, outer products, scalar products and\ninverses; and cliffordan - for applications of geometric calculus.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.06967v1"
    },
    {
        "title": "Rigorous Multiple-Precision Evaluation of D-Finite Functions in SageMath",
        "authors": [
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We present a new open source implementation in the SageMath computer algebra\nsystem of algorithms for the numerical solution of linear ODEs with polynomial\ncoefficients. Our code supports regular singular connection problems and\nprovides rigorous error bounds.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01967v1"
    },
    {
        "title": "Numeric Deduction in Symbolic Computation. Application to Normalizing\n  Transformations",
        "authors": [
            "Ivan I. Shevchenko"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Algorithms of numeric (in exact arithmetic) deduction of analytical\nexpressions, proposed and described by Shevchenko and Vasiliev (1993), are\ndeveloped and implemented in a computer algebra code. This code is built as a\nsuperstructure for the computer algebra package by Shevchenko and Sokolsky\n(1993a) for normalization of Hamiltonian systems of ordinary differential\nequations, in order that high complexity problems of normalization could be\nsolved. As an example, a resonant normal form of a Hamiltonian describing the\nhyperboloidal precession of a dynamically symmetric satellite is derived by\nmeans of the numeric deduction technique. The technique provides a considerable\neconomy, about 30 times in this particular application, in computer memory\nconsumption. It is naturally parallelizable. Thus the economy of memory\nconsumption is convertible into a gain in computation speed.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.02016v1"
    },
    {
        "title": "Fast, deterministic computation of the Hermite normal form and\n  determinant of a polynomial matrix",
        "authors": [
            "George Labahn",
            "Vincent Neiger",
            "Wei Zhou"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Given a nonsingular $n \\times n$ matrix of univariate polynomials over a\nfield $\\mathbb{K}$, we give fast and deterministic algorithms to compute its\ndeterminant and its Hermite normal form. Our algorithms use\n$\\widetilde{\\mathcal{O}}(n^\\omega \\lceil s \\rceil)$ operations in $\\mathbb{K}$,\nwhere $s$ is bounded from above by both the average of the degrees of the rows\nand that of the columns of the matrix and $\\omega$ is the exponent of matrix\nmultiplication. The soft-$O$ notation indicates that logarithmic factors in the\nbig-$O$ are omitted while the ceiling function indicates that the cost is\n$\\widetilde{\\mathcal{O}}(n^\\omega)$ when $s = o(1)$. Our algorithms are based\non a fast and deterministic triangularization method for computing the diagonal\nentries of the Hermite form of a nonsingular matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.04176v2"
    },
    {
        "title": "Automatic Library Generation for Modular Polynomial Multiplication",
        "authors": [
            "Lingchuan Meng"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Polynomial multiplication is a key algorithm underlying computer algebra\nsystems (CAS) and its efficient implementation is crucial for the performance\nof CAS. In this paper we design and implement algorithms for polynomial\nmultiplication using approaches based the fast Fourier transform (FFT) and the\ntruncated Fourier transform (TFT). We improve on the state-of-the-art in both\ntheoretical and practical performance. The {\\SPIRAL} library generation system\nis extended and used to automatically generate and tune the performance of a\npolynomial multiplication library that is optimized for memory hierarchy,\nvectorization and multi-threading, using new and existing algorithms. The\nperformance tuning has been aided by the use of automation where many code\nchoices are generated and intelligent search is utilized to find the \"best\"\nimplementation on a given architecture. The performance of autotuned\nimplementations is comparable to, and in some cases better than, the best\nhand-tuned code.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.01010v1"
    },
    {
        "title": "Some Open Problems related to Creative Telescoping",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Creative telescoping is the method of choice for obtaining information about\ndefinite sums or integrals. It has been intensively studied since the early\n1990s, and can now be considered as a classical technique in computer algebra.\nAt the same time, it is still subject of ongoing research. In this paper, we\npresent a selection of open problems in this context. We would be curious to\nhear about any substantial progress on any of these problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.03768v1"
    },
    {
        "title": "A Fast Algorithm for Computing the Truncated Resultant",
        "authors": [
            "Guillaume Moroz",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Let P and Q be two polynomials in K[x, y] with degree at most d, where K is a\nfield. Denoting by R $\\in$ K[x] the resultant of P and Q with respect to y, we\npresent an algorithm to compute R mod x^k in O~(kd) arithmetic operations in K,\nwhere the O~ notation indicates that we omit polylogarithmic factors. This is\nan improvement over state-of-the-art algorithms that require to compute R in\nO~(d^3) operations before computing its first k coefficients.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.04259v1"
    },
    {
        "title": "Symbolic Solutions of Simultaneous First-order PDEs in One Unknown",
        "authors": [
            "Célestin Wafo Soh"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We propose and implement an algorithm for solving an overdetermined system of\npartial differential equations in one unknown. Our approach relies on\nBour-Mayer method to determine compatibility conditions via Jacobi-Mayer\nbrackets. We solve compatible systems recursively by imitating what one would\ndo with pen and paper: Solve one equation, substitute the solution into the\nremaining equations and iterate the process until the equations of the system\nare exhausted. The method we employ for assessing the consistency of the\nunderlying system differs from the traditional use of differential Gr\\\"obner\nbases yet seems more efficient and straightforward to implement. We are not\naware of a computer algebra system that adopts the procedure we advocate in\nthis work.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.01974v1"
    },
    {
        "title": "A lattice formulation of the F4 completion procedure",
        "authors": [
            "Chenavier Cyrille"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We write a procedure for constructing noncommutative Groebner bases.\nReductions are done by particular linear projectors, called reduction\noperators. The operators enable us to use a lattice construction to reduce\nsimultaneously each S-polynomial into a unique normal form. We write an\nimplementation as well as an example to illustrate our procedure. Moreover, the\nlattice construction is done by Gaussian elimination, which relates our\nprocedure to the F4 algorithm for constructing commutative Groebner bases.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.02077v3"
    },
    {
        "title": "Roots multiplicity without companion matrices",
        "authors": [
            "Przemysław Koprowski"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We show a method for constructing a polynomial interpolating roots'\nmultiplicities of another polynomial, that does not use companion matrices.\nThis leads to a modification to Guersenzvaig--Szechtman square-free\ndecomposition algorithm that is more efficient both in theory and in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.06120v1"
    },
    {
        "title": "Laderman matrix multiplication algorithm can be constructed using\n  Strassen algorithm and related tensor's isotropies",
        "authors": [
            "Alexandre Sedoglavic"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In 1969, V. Strassen improves the classical~2x2 matrix multiplication\nalgorithm. The current upper bound for 3x3 matrix multiplication was reached by\nJ.B. Laderman in 1976. This note presents a geometric relationship between\nStrassen and Laderman algorithms. By doing so, we retrieve a geometric\nformulation of results very similar to those presented by O. Sykora in 1977.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.08298v4"
    },
    {
        "title": "Sparse Polynomial Interpolation with Finitely Many Values for the\n  Coefficients",
        "authors": [
            "Qiao-Long Huang",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we give new sparse interpolation algorithms for black box\npolynomial f whose coefficients are from a finite set. In the univariate case,\nwe recover f from one evaluation of f(a) for a sufficiently large number a. In\nthe multivariate case, we introduce the modified Kronecker substitution to\nreduce the interpolation of a multivariate polynomial to the univariate case.\nBoth algorithms have polynomial bit-size complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.04359v2"
    },
    {
        "title": "Efficiently Computing Real Roots of Sparse Polynomials",
        "authors": [
            "Gorav Jindal",
            "Michael Sagraloff"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We propose an efficient algorithm to compute the real roots of a sparse\npolynomial $f\\in\\mathbb{R}[x]$ having $k$ non-zero real-valued coefficients. It\nis assumed that arbitrarily good approximations of the non-zero coefficients\nare given by means of a coefficient oracle. For a given positive integer $L$,\nour algorithm returns disjoint disks\n$\\Delta_{1},\\ldots,\\Delta_{s}\\subset\\mathbb{C}$, with $s<2k$, centered at the\nreal axis and of radius less than $2^{-L}$ together with positive integers\n$\\mu_{1},\\ldots,\\mu_{s}$ such that each disk $\\Delta_{i}$ contains exactly\n$\\mu_{i}$ roots of $f$ counted with multiplicity. In addition, it is ensured\nthat each real root of $f$ is contained in one of the disks. If $f$ has only\nsimple real roots, our algorithm can also be used to isolate all real roots.\n  The bit complexity of our algorithm is polynomial in $k$ and $\\log n$, and\nnear-linear in $L$ and $\\tau$, where $2^{-\\tau}$ and $2^{\\tau}$ constitute\nlower and upper bounds on the absolute values of the non-zero coefficients of\n$f$, and $n$ is the degree of $f$. For root isolation, the bit complexity is\npolynomial in $k$ and $\\log n$, and near-linear in $\\tau$ and\n$\\log\\sigma^{-1}$, where $\\sigma$ denotes the separation of the real roots.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.06979v1"
    },
    {
        "title": "A Case Study on the Parametric Occurrence of Multiple Steady States",
        "authors": [
            "Russell Bradford",
            "James H. Davenport",
            "Matthew England",
            "Hassan Errami",
            "Vladimir Gerdt",
            "Dima Grigoriev",
            "Charles Hoyt",
            "Marek Kosta",
            "Ovidiu Radulescu",
            "Thomas Sturm",
            "Andreas Weber"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We consider the problem of determining multiple steady states for positive\nreal values in models of biological networks. Investigating the potential for\nthese in models of the mitogen-activated protein kinases (MAPK) network has\nconsumed considerable effort using special insights into the structure of\ncorresponding models. Here we apply combinations of symbolic computation\nmethods for mixed equality/inequality systems, specifically virtual\nsubstitution, lazy real triangularization and cylindrical algebraic\ndecomposition. We determine multistationarity of an 11-dimensional MAPK network\nwhen numeric values are known for all but potentially one parameter. More\nprecisely, our considered model has 11 equations in 11 variables and 19\nparameters, 3 of which are of interest for symbolic treatment, and furthermore\npositivity conditions on all variables and parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.08997v1"
    },
    {
        "title": "Denominator Bounds for Systems of Recurrence Equations using\n  $ΠΣ$-Extensions",
        "authors": [
            "Johannes Middeke",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We consider linear systems of recurrence equations whose coefficients are\ngiven in terms of indefinite nested sums and products covering, e.g., the\nharmonic numbers, hypergeometric products, $q$-hypergeometric products or their\nmixed versions. These linear systems are formulated in the setting of\n$\\Pi\\Sigma$-extensions and our goal is to find a denominator bound (also known\nas universal denominator) for the solutions; i.e., a non-zero polynomial $d$\nsuch that the denominator of every solution of the system divides $d$. This is\nthe first step in computing all rational solutions of such a rather general\nrecurrence system. Once the denominator bound is known, the problem of solving\nfor rational solutions is reduced to the problem of solving for polynomial\nsolutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00280v1"
    },
    {
        "title": "Apparent Singularities of D-finite Systems",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers",
            "Ziming Li",
            "Yi Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We generalize the notions of singularities and ordinary points from linear\nordinary differential equations to D-finite systems. Ordinary points of a\nD-finite system are characterized in terms of its formal power series\nsolutions. We also show that apparent singularities can be removed like in the\nunivariate case by adding suitable additional solutions to the system at hand.\nSeveral algorithms are presented for removing and detecting apparent\nsingularities. In addition, an algorithm is given for computing formal power\nseries solutions of a D-finite system at apparent singularities.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00838v1"
    },
    {
        "title": "Non-linear Associative-Commutative Many-to-One Pattern Matching with\n  Sequence Variables",
        "authors": [
            "Manuel Krebber"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Pattern matching is a powerful tool which is part of many functional\nprogramming languages as well as computer algebra systems such as Mathematica.\nAmong the existing systems, Mathematica offers the most expressive pattern\nmatching. Unfortunately, no open source alternative has comparable pattern\nmatching capabilities. Notably, these features include support for associative\nand/or commutative function symbols and sequence variables. While those\nfeatures have individually been subject of previous research, their\ncomprehensive combination has not yet been investigated. Furthermore, in many\napplications, a fixed set of patterns is matched repeatedly against different\nsubjects. This many-to-one matching can be sped up by exploiting similarities\nbetween patterns. Discrimination nets are the state-of-the-art solution for\nmany-to-one matching. In this thesis, a generalized discrimination net which\nsupports the full feature set is presented. All algorithms have been\nimplemented as an open-source library for Python. In experiments on real world\nexamples, significant speedups of many-to-one over one-to-one matching have\nbeen observed.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00907v1"
    },
    {
        "title": "Representing ($q$--)hypergeometric products and mixed versions in\n  difference rings",
        "authors": [
            "Evans Doe Ocansey",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In recent years, Karr's difference field theory has been extended to the\nso-called $R\\Pi\\Sigma$-extensions in which one can represent not only\nindefinite nested sums and products that can be expressed by transcendental\nring extensions, but one can also handle algebraic products of the form\n$\\alpha^n$ where $\\alpha$ is a root of unity. In this article we supplement\nthis summation theory substantially by the following building block. We provide\nnew algorithms that represent a finite number of hypergeometric or mixed\n$(q_1,...,q_e)$-multibasic hypergeometric products in such a difference ring.\nThis new insight provides a complete summation machinery that enables one to\nformulate such products and indefinite nested sums defined over such products\nin $R\\Pi\\Sigma$-extensions fully automatically. As a side-product, one obtains\ncompactified expressions where the products are algebraically independent among\neach other, and one can solve the zero-recognition problem for such products.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.01368v2"
    },
    {
        "title": "Compile-Time Symbolic Differentiation Using C++ Expression Templates",
        "authors": [
            "Drosos Kourounis",
            "Leonidas Gergidis",
            "Michael Saunders",
            "Andrea Walther",
            "Olaf Schenk"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Template metaprogramming is a popular technique for implementing compile time\nmechanisms for numerical computing. We demonstrate how expression templates can\nbe used for compile time symbolic differentiation of algebraic expressions in\nC++ computer programs. Given a positive integer $N$ and an algebraic function\nof multiple variables, the compiler generates executable code for the $N$th\npartial derivatives of the function. Compile-time simplification of the\nderivative expressions is achieved using recursive templates. A detailed\nanalysis indicates that current C++ compiler technology is already sufficient\nfor practical use of our results, and highlights a number of issues where\nfurther improvements may be desirable.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.01729v1"
    },
    {
        "title": "Automated Generation of Non-Linear Loop Invariants Utilizing\n  Hypergeometric Sequences",
        "authors": [
            "Andreas Humenberger",
            "Maximilian Jaroschek",
            "Laura Kovács"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Analyzing and reasoning about safety properties of software systems becomes\nan especially challenging task for programs with complex flow and, in\nparticular, with loops or recursion. For such programs one needs additional\ninformation, for example in the form of loop invariants, expressing properties\nto hold at intermediate program points. In this paper we study program loops\nwith non-trivial arithmetic, implementing addition and multiplication among\nnumeric program variables. We present a new approach for automatically\ngenerating all polynomial invariants of a class of such programs. Our approach\nturns programs into linear ordinary recurrence equations and computes closed\nform solutions of these equations. These closed forms express the most precise\ninductive property, and hence invariant. We apply Gr\\\"obner basis computation\nto obtain a basis of the polynomial invariant ideal, yielding thus a finite\nrepresentation of all polynomial invariants. Our work significantly extends the\nclass of so-called P-solvable loops by handling multiplication with the loop\ncounter variable. We implemented our method in the Mathematica package Aligator\nand showcase the practical use of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.02863v2"
    },
    {
        "title": "Computing Canonical Bases of Modules of Univariate Relations",
        "authors": [
            "Vincent Neiger",
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We study the computation of canonical bases of sets of univariate relations\n$(p_1,\\ldots,p_m) \\in \\mathbb{K}[x]^{m}$ such that $p_1 f_1 + \\cdots + p_m f_m\n= 0$; here, the input elements $f_1,\\ldots,f_m$ are from a quotient\n$\\mathbb{K}[x]^n/\\mathcal{M}$, where $\\mathcal{M}$ is a $\\mathbb{K}[x]$-module\nof rank $n$ given by a basis $\\mathbf{M}\\in\\mathbb{K}[x]^{n\\times n}$ in\nHermite form. We exploit the triangular shape of $\\mathbf{M}$ to generalize a\ndivide-and-conquer approach which originates from fast minimal approximant\nbasis algorithms. Besides recent techniques for this approach, we rely on\nhigh-order lifting to perform fast modular products of polynomial matrices of\nthe form $\\mathbf{P}\\mathbf{F} \\bmod \\mathbf{M}$.\n  Our algorithm uses $O\\tilde{~}(m^{\\omega-1}D + n^{\\omega} D/m)$ operations in\n$\\mathbb{K}$, where $D = \\mathrm{deg}(\\det(\\mathbf{M}))$ is the\n$\\mathbb{K}$-vector space dimension of $\\mathbb{K}[x]^n/\\mathcal{M}$,\n$O\\tilde{~}(\\cdot)$ indicates that logarithmic factors are omitted, and\n$\\omega$ is the exponent of matrix multiplication. This had previously only\nbeen achieved for a diagonal matrix $\\mathbf{M}$. Furthermore, our algorithm\ncan be used to compute the shifted Popov form of a nonsingular matrix within\nthe same cost bound, up to logarithmic factors, as the previously fastest known\nalgorithm, which is randomized.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.10649v1"
    },
    {
        "title": "Fast Computation of the Roots of Polynomials Over the Ring of Power\n  Series",
        "authors": [
            "Vincent Neiger",
            "Johan Rosenkilde",
            "Eric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We give an algorithm for computing all roots of polynomials over a univariate\npower series ring over an exact field $\\mathbb{K}$. More precisely, given a\nprecision $d$, and a polynomial $Q$ whose coefficients are power series in $x$,\nthe algorithm computes a representation of all power series $f(x)$ such that\n$Q(f(x)) = 0 \\bmod x^d$. The algorithm works unconditionally, in particular\nalso with multiple roots, where Newton iteration fails. Our main motivation\ncomes from coding theory where instances of this problem arise and multiple\nroots must be handled.\n  The cost bound for our algorithm matches the worst-case input and output size\n$d \\deg(Q)$, up to logarithmic factors. This improves upon previous algorithms\nwhich were quadratic in at least one of $d$ and $\\deg(Q)$. Our algorithm is a\nrefinement of a divide \\& conquer algorithm by Alekhnovich (2005), where the\ncost of recursive steps is better controlled via the computation of a factor of\n$Q$ which has a smaller degree while preserving the roots.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.10658v1"
    },
    {
        "title": "Rational Solutions of High-Order Algebraic Ordinary Differential\n  Equations",
        "authors": [
            "Thieu N. Vo",
            "Yi Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We consider algebraic ordinary differential equations (AODEs) and study their\npolynomial and rational solutions. A sufficient condition for an AODE to have a\ndegree bound for its polynomial solutions is presented. An AODE satisfying this\ncondition is called \\emph{noncritical}. We prove that usual low order classes\nof AODEs are noncritical. For rational solutions, we determine a class of\nAODEs, which are called \\emph{maximally comparable}, such that the poles of\ntheir rational solutions are recognizable from their coefficients. This\ngeneralizes a fact from linear AODEs, that the poles of their rational\nsolutions are the zeros of the corresponding highest coefficient. An algorithm\nfor determining all rational solutions, if there is any, of certain maximally\ncomparable AODEs, which covers $78.54\\%$ AODEs from a standard differential\nequations collection by Kamke, is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.04174v6"
    },
    {
        "title": "In-depth comparison of the Berlekamp -- Massey -- Sakata and the\n  Scalar-FGLM algorithms: the non adaptive variants",
        "authors": [
            "Jérémy Berthomieu",
            "Jean-Charles Faugère"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We compare thoroughly the Berlekamp -- Massey -- Sakata algorithm and the\nScalar-FGLM algorithm, which compute both the ideal of relations of a\nmulti-dimensional linear recurrent sequence. Suprisingly, their behaviors\ndiffer. We detail in which way they do and prove that it is not possible to\ntweak one of the algorithms in order to mimic exactly the behavior of the\nother.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.07168v1"
    },
    {
        "title": "Faster Interpolation Algorithms for Sparse Multivariate Polynomials\n  Given by Straight-Line Programs\\",
        "authors": [
            "Qiao-Long Huang",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we propose new deterministic and Monte Carlo interpolation\nalgorithms for sparse multivariate polynomials represented by straight-line\nprograms. Let $f$ be an $n$-variate polynomial given by a straight-line\nprogram, which has a degree bound $D$ and a term bound $T$. Our deterministic\nalgorithm is quadratic in $n,T$ and cubic in $\\log D$ in the Soft-Oh sense,\nwhich has better complexities than existing deterministic interpolation\nalgorithms in most cases. Our Monte Carlo interpolation algorithms have better\ncomplexities than existing Monte Carlo interpolation algorithms and are the\nfirst algorithms whose complexities are linear in $nT$ in the Soft-Oh sense.\nSince $nT$ is a factor of the size of $f$, our Monte Carlo algorithms are\noptimal in $n$ and $T$ in the Soft-Oh sense.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.08979v4"
    },
    {
        "title": "The Potential and Challenges of CAD with Equational Constraints for\n  SC-Square",
        "authors": [
            "James H. Davenport",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Cylindrical algebraic decomposition (CAD) is a core algorithm within Symbolic\nComputation, particularly for quantifier elimination over the reals and\npolynomial systems solving more generally. It is now finding increased\napplication as a decision procedure for Satisfiability Modulo Theories (SMT)\nsolvers when working with non-linear real arithmetic. We discuss the potentials\nfrom increased focus on the logical structure of the input brought by the SMT\napplications and SC-Square project, particularly the presence of equational\nconstraints. We also highlight the challenges for exploiting these: primitivity\nrestrictions, well-orientedness questions, and the prospect of incrementality.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.00312v1"
    },
    {
        "title": "Computation of the Adjoint Matrix",
        "authors": [
            "Alkiviadis Akritas",
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  The best method for computing the adjoint matrix of an order $n$ matrix in an\narbitrary commutative ring requires $O(n^{\\beta+1/3}\\log n \\log \\log n)$\noperations, provided the complexity of the algorithm for multiplying two\nmatrices is $\\gamma n^\\beta+o(n^\\beta)$. For a commutative domain -- and under\nthe same assumptions -- the complexity of the best method is ${6\\gamma\nn^\\beta}/{(2^{\\beta}-2)}+o(n^\\beta)$. In the present work a new method is\npresented for the computation of the adjoint matrix in a commutative domain.\nDespite the fact that the number of operations required is now 1.5 times more,\nthan that of the best method, this new method permits a better parallelization\nof the computational process and may be successfully employed for computations\nin parallel computational systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09450v1"
    },
    {
        "title": "Solution of a System of Linear Equations in an Integral Ring",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  A modified Gauss's algorithm for solving a system of linear equations in an\nintegral ring is proposed, as well as an appropriate algorithm for calculating\nthe elements of the adjoint matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09452v1"
    },
    {
        "title": "Effective Matrix Methods in Commutative Domains",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Effective matrix methods for solving standard linear algebra problems in a\ncommutative domains are discussed. Two of them are new. There are a methods for\ncomputing adjoined matrices and solving system of linear equations in a\ncommutative domains.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09456v1"
    },
    {
        "title": "Algorithms for the solution of systems of linear equations in\n  commutative ring",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Solution methods for linear equation systems in a commutative ring are\ndiscussed. Four methods are compared, in the setting of several different\nrings: Dodgson's method [1], Bareiss's method [2] and two methods of the author\n- method by forward and back-up procedures [3] and a one-pass method [4]. We\nshow that for the number of coefficient operations, or for the number of\noperations in the finite rings, or for modular computation in the polynomial\nrings the one-pass method [4] is the best. The method of forward and back-up\nprocedures [3] is the best for the polynomial rings when we make use of\nclassical algorithms for polynomial operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.11471v1"
    },
    {
        "title": "Algorithms for the Computing Determinants in Commutative Rings",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Two known computation methods and one new computation method for matrix\ndeterminant over an integral domain are discussed. For each of the methods we\nevaluate the computation times for different rings and show that the new method\nis the best.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.11472v1"
    },
    {
        "title": "Computing Lower Rank Approximations of Matrix Polynomials",
        "authors": [
            "Mark Giesbrecht",
            "Joseph Haraldson",
            "George Labahn"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Given an input matrix polynomial whose coefficients are floating point\nnumbers, we consider the problem of finding the nearest matrix polynomial which\nhas rank at most a specified value. This generalizes the problem of finding a\nnearest matrix polynomial that is algebraically singular with a prescribed\nlower bound on the dimension given in a previous paper by the authors. In this\npaper we prove that such lower rank matrices at minimal distance always exist,\nsatisfy regularity conditions, and are all isolated and surrounded by a basin\nof attraction of non-minimal solutions. In addition, we present an iterative\nalgorithm which, on given input sufficiently close to a rank-at-most matrix,\nproduces that matrix. The algorithm is efficient and is proven to converge\nquadratically given a sufficiently good starting point. An implementation\ndemonstrates the effectiveness and numerical robustness of our algorithm in\npractice.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04007v1"
    },
    {
        "title": "Block-Krylov techniques in the context of sparse-FGLM algorithms",
        "authors": [
            "Seung Gyu Hyun",
            "Vincent Neiger",
            "Hamid Rahkooy",
            "Eric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Consider a zero-dimensional ideal $I$ in $\\mathbb{K}[X_1,\\dots,X_n]$.\nInspired by Faug\\`ere and Mou's Sparse FGLM algorithm, we use Krylov sequences\nbased on multiplication matrices of $I$ in order to compute a description of\nits zero set by means of univariate polynomials.\n  Steel recently showed how to use Coppersmith's block-Wiedemann algorithm in\nthis context; he describes an algorithm that can be easily parallelized, but\nonly computes parts of the output in this manner. Using generating series\nexpressions going back to work of Bostan, Salvy, and Schost, we show how to\ncompute the entire output for a small overhead, without making any assumption\non the ideal $I$ other than it having dimension zero. We then propose a\nrefinement of this idea that partially avoids the introduction of a generic\nlinear form. We comment on experimental results obtained by an implementation\nbased on the C++ libraries Eigen, LinBox and NTL.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04177v2"
    },
    {
        "title": "Revisit Sparse Polynomial Interpolation based on Randomized Kronecker\n  Substitution",
        "authors": [
            "Qiao-Long Huang",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, a new reduction based interpolation algorithm for black-box\nmultivariate polynomials over finite fields is given. The method is based on\ntwo main ingredients. A new Monte Carlo method is given to reduce black-box\nmultivariate polynomial interpolation to black-box univariate polynomial\ninterpolation over any ring. The reduction algorithm leads to multivariate\ninterpolation algorithms with better or the same complexities most cases when\ncombining with various univariate interpolation algorithms. We also propose a\nmodified univariate Ben-or and Tiwarri algorithm over the finite field, which\nhas better total complexity than the Lagrange interpolation algorithm.\nCombining our reduction method and the modified univariate Ben-or and Tiwarri\nalgorithm, we give a Monte Carlo multivariate interpolation algorithm, which\nhas better total complexity in most cases for sparse interpolation of black-box\npolynomial over finite fields.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.05481v2"
    },
    {
        "title": "Can one design a geometry engine? On the (un)decidability of affine\n  Euclidean geometries",
        "authors": [
            "J. A. Makowsky"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We survey the status of decidabilty of the consequence relation in various\naxiomatizations of Euclidean geometry. We draw attention to a widely overlooked\nresult by Martin Ziegler from 1980, which proves Tarski's conjecture on the\nundecidability of finitely axiomatizable theories of fields. We elaborate on\nhow to use Ziegler's theorem to show that the consequence relations for the\nfirst order theory of the Hilbert plane and the Euclidean plane are\nundecidable. As new results we add: (A) The first order consequence relations\nfor Wu's orthogonal and metric geometries (Wen-Ts\\\"un Wu, 1984), and for the\naxiomatization of Origami geometry (J. Justin 1986, H. Huzita 1991)are\nundecidable.\n  It was already known that the universal theory of Hilbert planes and Wu's\northogonal geometry is decidable. We show here using elementary model theoretic\ntools that (B) the universal first order consequences of any geometric theory\n$T$ of Pappian planes which is consistent with the analytic geometry of the\nreals is decidable.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.07474v3"
    },
    {
        "title": "A non-commutative algorithm for multiplying (7 $\\times$ 7) matrices\n  using 250 multiplications",
        "authors": [
            "Alexandre Sedoglavic"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We present a non-commutative algorithm for multiplying (7x7) matrices using\n250 multiplications and a non-commutative algorithm for multiplying (9x9)\nmatrices using 520 multiplications. These algorithms are obtained using the\nsame divide-and-conquer technique.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.07935v1"
    },
    {
        "title": "Resolving zero-divisors using Hensel lifting",
        "authors": [
            "John Kluesner",
            "Michael Monagan"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Algorithms which compute modulo triangular sets must respect the presence of\nzero-divisors. We present Hensel lifting as a tool for dealing with them. We\ngive an application: a modular algorithm for computing GCDs of univariate\npolynomials with coefficients modulo a radical triangular set over the\nrationals. Our modular algorithm naturally generalizes previous work from\nalgebraic number theory. We have implemented our algorithm using Maple's RECDEN\npackage. We compare our implementation with the procedure RegularGcd in the\nRegularChains package.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.03161v1"
    },
    {
        "title": "Desingularization in the $q$-Weyl algebra",
        "authors": [
            "Christoph Koutschan",
            "Yi Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this paper, we study the desingularization problem in the first $q$-Weyl\nalgebra. We give an order bound for desingularized operators, and thus derive\nan algorithm for computing desingularized operators in the first $q$-Weyl\nalgebra. Moreover, an algorithm is presented for computing a generating set of\nthe first $q$-Weyl closure of a given $q$-difference operator. As an\napplication, we certify that several instances of the colored Jones polynomial\nare Laurent polynomial sequences by computing the corresponding desingularized\noperator.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.04160v2"
    },
    {
        "title": "Fast computation of approximant bases in canonical form",
        "authors": [
            "Claude-Pierre Jeannerod",
            "Vincent Neiger",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this article, we design fast algorithms for the computation of approximant\nbases in shifted Popov normal form. We first recall the algorithm known as\nPM-Basis, which will be our second fundamental engine after polynomial matrix\nmultiplication: most other fast approximant basis algorithms basically aim at\nefficiently reducing the input instance to instances for which PM-Basis is\nfast. Such reductions usually involve partial linearization techniques due to\nStorjohann, which have the effect of balancing the degrees and dimensions in\nthe manipulated matrices.\n  Following these ideas, Zhou and Labahn gave two algorithms which are faster\nthan PM-Basis for important cases including Hermite-Pade approximation, yet\nonly for shifts whose values are concentrated around the minimum or the maximum\nvalue. The three mentioned algorithms were designed for balanced orders and\ncompute approximant bases that are generally not normalized. Here, we show how\nthey can be modified to return the shifted Popov basis without impact on their\ncost bound; besides, we extend Zhou and Labahn's algorithms to arbitrary\norders.\n  Furthermore, we give an algorithm which handles arbitrary shifts with one\nextra logarithmic factor in the cost bound compared to the above algorithms. To\nthe best of our knowledge, this improves upon previously known algorithms for\narbitrary shifts, including for particular cases such as Hermite-Pade\napproximation. This algorithm is based on a recent divide and conquer approach\nwhich reduces the general case to the case where information on the output\ndegree is available. As outlined above, we solve the latter case via partial\nlinearizations and PM-Basis.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.04553v2"
    },
    {
        "title": "The Complexity of Subdivision for Diameter-Distance Tests",
        "authors": [
            "Michael Burr",
            "Shuhong Gao",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We present a general framework for analyzing the complexity of\nsubdivision-based algorithms whose tests are based on the sizes of regions and\ntheir distance to certain sets (often varieties) intrinsic to the problem under\nstudy. We call such tests diameter-distance tests. We illustrate that\ndiameter-distance tests are common in the literature by proving that many\ninterval arithmetic-based tests are, in fact, diameter-distance tests. For this\nclass of algorithms, we provide both non-adaptive bounds for the complexity,\nbased on separation bounds, as well as adaptive bounds, by applying the\nframework of continuous amortization.\n  Using this structure, we provide the first complexity analysis for the\nalgorithm by Plantinga and Vegeter for approximating real implicit curves and\nsurfaces. We present both adaptive and non-adaptive a priori worst-case bounds\non the complexity of this algorithm both in terms of the number of subregions\nconstructed and in terms of the bit complexity for the construction. Finally,\nwe construct families of hypersurfaces to prove that our bounds are tight.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05864v1"
    },
    {
        "title": "Block SOS Decomposition",
        "authors": [
            "Haokun Li",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  A widely used method for solving SOS (Sum Of Squares) decomposition problem\nis to reduce it to the problem of semi-definite programs (SDPs) which can be\nefficiently solved in theory. In practice, although many SDP solvers can work\nout some problems of big scale, the efficiency and reliability of such method\ndecrease greatly while the input size increases. Recently, by exploiting the\nsparsity of the input SOS decomposition problem, some preprocessing algorithms\nwere proposed [5,17], which first divide the input problem satisfying special\ndefinitions or properties into smaller SDP problems and then pass the smaller\nones to SDP solvers to obtain reliable results efficiently. A natural question\nis that to what extent the above mentioned preprocessing algorithms work. That\nis, how many polynomials satisfying those definitions or properties are there\nin the SOS polynomials? In this paper, we define a concept of block SOS\ndecomposable polynomials which is a generalization of those special classes in\n[5] and [17]. Roughly speaking, it is a class of polynomials whose SOS\ndecomposition problem can be transformed into smaller ones (in other words, the\ncorresponding SDP matrices can be block-diagnolized) by considering their\nsupports only (coefficients are not considered). Then we prove that the set of\nblock SOS decomposable polynomials has measure zero in the set of SOS\npolynomials. That means if we only consider supports (not with coefficients) of\npolynomials, such algorithms decreasing the size of SDPs for those SDP-based\nSOS solvers can only work on very few polynomials. As a result, this shows that\nthe SOS decomposition problems that can be optimized by the above mentioned\npreprocessing algorithms are very few.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07954v2"
    },
    {
        "title": "Desingularization of First Order Linear Difference Systems with Rational\n  Function Coefficients",
        "authors": [
            "Moulay A. Barkatou",
            "Maximilian Jaroschek"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  It is well known that for a first order system of linear difference equations\nwith rational function coefficients, a solution that is holomorphic in some\nleft half plane can be analytically continued to a meromorphic solution in the\nwhole complex plane. The poles stem from the singularities of the rational\nfunction coefficients of the system. Just as for differential equations, not\nall of these singularities necessarily lead to poles in solutions, as they\nmight be what is called removable. In our work, we show how to detect and\nremove these singularities and further study the connection between poles of\nsolutions and removable singularities. We describe two algorithms to\n(partially) desingularize a given difference system and present a\ncharacterization of removable singularities in terms of shifts of the original\nsystem.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01150v1"
    },
    {
        "title": "A Signature-based Algorithm for computing Computing Gröbner Bases over\n  Principal Ideal Domains",
        "authors": [
            "Maria Francis",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Signature-based algorithms have become a standard approach for Gr\\\"obner\nbasis computations for polynomial systems over fields, but how to extend these\ntechniques to coefficients in general rings is not yet as well understood.\n  In this paper, we present a proof-of-concept signature-based algorithm for\ncomputing Gr\\\"obner bases over commutative integral domains. It is adapted from\na general version of M\\\"oller's algorithm (1988) which considers reductions by\nmultiple polynomials at each step. This algorithm performs reductions with\nnon-decreasing signatures, and in particular, signature drops do not occur.\nWhen the coefficients are from a principal ideal domain (e.g. the ring of\nintegers or the ring of univariate polynomials over a field), we prove\ncorrectness and termination of the algorithm, and we show how to use signature\nproperties to implement classic signature-based criteria to eliminate some\nredundant reductions. In particular, if the input is a regular sequence, the\nalgorithm operates without any reduction to 0.\n  We have written a toy implementation of the algorithm in Magma. Early\nexperimental results suggest that the algorithm might even be correct and\nterminate in a more general setting, for polynomials over a unique\nfactorization domain (e.g. the ring of multivariate polynomials over a field or\na PID).\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01388v3"
    },
    {
        "title": "On the chordality of polynomial sets in triangular decomposition in\n  top-down style",
        "authors": [
            "Chenqi Mou",
            "Yang Bai"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this paper the chordal graph structures of polynomial sets appearing in\ntriangular decomposition in top-down style are studied when the input\npolynomial set to decompose has a chordal associated graph. In particular, we\nprove that the associated graph of one specific triangular set computed in any\nalgorithm for triangular decomposition in top-down style is a subgraph of the\nchordal graph of the input polynomial set and that all the polynomial sets\nincluding all the computed triangular sets appearing in one specific\nsimply-structured algorithm for triangular decomposition in top-down style\n(Wang's method) have associated graphs which are subgraphs of the the chordal\ngraph of the input polynomial set. These subgraph structures in triangular\ndecomposition in top-down style are multivariate generalization of existing\nresults for Gaussian elimination and may lead to specialized efficient\nalgorithms and refined complexity analyses for triangular decomposition of\nchordal polynomial sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01752v1"
    },
    {
        "title": "Certification of minimal approximant bases",
        "authors": [
            "Pascal Giorgi",
            "Vincent Neiger"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  For a given computational problem, a certificate is a piece of data that one\n(the prover) attaches to the output with the aim of allowing efficient\nverification (by the verifier) that this output is correct. Here, we consider\nthe minimal approximant basis problem, for which the fastest known algorithms\noutput a polynomial matrix of dimensions $m \\times m$ and average degree $D/m$\nusing $O\\tilde{~}(m^\\omega \\frac{D}{m})$ field operations. We propose a\ncertificate which, for typical instances of the problem, is computed by the\nprover using $O(m^\\omega \\frac{D}{m})$ additional field operations and allows\nverification of the approximant basis by a Monte Carlo algorithm with cost\nbound $O(m^\\omega + m D)$.\n  Besides theoretical interest, our motivation also comes from the fact that\napproximant bases arise in most of the fastest known algorithms for linear\nalgebra over the univariate polynomials; thus, this work may help in designing\ncertificates for other polynomial matrix computations. Furthermore,\ncryptographic challenges such as breaking records for discrete logarithm\ncomputations or for integer factorization rely in particular on computing\nminimal approximant bases for large instances: certificates can then be used to\nprovide reliable computation on outsourced and error-prone clusters.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01920v2"
    },
    {
        "title": "Computing Popov and Hermite forms of rectangular polynomial matrices",
        "authors": [
            "Vincent Neiger",
            "Johan Rosenkilde",
            "Grigory Solomatov"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We consider the computation of two normal forms for matrices over the\nunivariate polynomials: the Popov form and the Hermite form. For matrices which\nare square and nonsingular, deterministic algorithms with satisfactory cost\nbounds are known. Here, we present deterministic, fast algorithms for\nrectangular input matrices. The obtained cost bound for the Popov form matches\nthe previous best known randomized algorithm, while the cost bound for the\nHermite form improves on the previous best known ones by a factor which is at\nleast the largest dimension of the input matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01928v2"
    },
    {
        "title": "Additive Decompositions in Primitive Extensions",
        "authors": [
            "Shaoshi Chen",
            "Hao Du",
            "Ziming Li"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  This paper extends the classical Ostrogradsky-Hermite reduction for rational\nfunctions to more general functions in primitive extensions of certain types.\nFor an element $f$ in such an extension $K$, the extended reduction decomposes\n$f$ as the sum of a derivative in $K$ and another element $r$ such that $f$ has\nan antiderivative in $K$ if and only if $r=0$; and $f$ has an elementary\nantiderivative over $K$ if and only if $r$ is a linear combination of\nlogarithmic derivatives over the constants when $K$ is a logarithmic extension.\nMoreover, $r$ is minimal in some sense. Additive decompositions may lead to\nreduction-based creative-telescoping methods for nested logarithmic functions,\nwhich are not necessarily $D$-finite.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.02329v1"
    },
    {
        "title": "Exact algorithms for semidefinite programs with degenerate feasible set",
        "authors": [
            "Didier Henrion",
            "Simone Naldi",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Given symmetric matrices $A_0, A_1, \\ldots, A_n$ of size $m$ with rational\nentries, the set of real vectors $x = (x_1, \\ldots, x_n)$ such that the matrix\n$A_0 + x_1 A_1 + \\cdots + x_n A_n$ has non-negative eigenvalues is called a\nspectrahedron. Minimization of linear functions over spectrahedra is called\nsemidefinite programming. Such problems appear frequently in control theory and\nreal algebra, especially in the context of nonnegativity certificates for\nmultivariate polynomials based on sums of squares. Numerical software for\nsemidefinite programming are mostly based on interior point methods, assuming\nnon-degeneracy properties such as the existence of an interior point in the\nspectrahedron. In this paper, we design an exact algorithm based on symbolic\nhomotopy for solving semidefinite programs without assumptions on the feasible\nset, and we analyze its complexity. Because of the exactness of the output, it\ncannot compete with numerical routines in practice. However, we prove that\nsolving such problems can be done in polynomial time if either $n$ or $m$ is\nfixed.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.02834v2"
    },
    {
        "title": "On Probabilistic Term Rewriting",
        "authors": [
            "Martin Avanzini",
            "Ugo Dal Lago",
            "Akihisa Yamada"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We study the termination problem for probabilistic term rewrite systems. We\nprove that the interpretation method is sound and complete for a strengthening\nof positive almost sure termination, when abstract reduction systems and term\nrewrite systems are considered. Two instances of the interpretation method -\npolynomial and matrix interpretations - are analyzed and shown to capture\ninteresting and nontrivial examples when automated. We capture probabilistic\ncomputation in a novel way by way of multidistribution reduction sequences,\nthis way accounting for both the nondeterminism in the choice of the redex and\nthe probabilism intrinsic in firing each rule.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.09774v1"
    },
    {
        "title": "On Exact Polya and Putinar's Representations",
        "authors": [
            "Victor Magron",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We consider the problem of finding exact sums of squares (SOS) decompositions\nfor certain classes of non-negative multivariate polynomials, relying on\nsemidefinite programming (SDP) solvers.\n  We start by providing a hybrid numeric-symbolic algorithm computing exact\nrational SOS decompositions for polynomials lying in the interior of the SOS\ncone. It computes an approximate SOS decomposition for a perturbation of the\ninput polynomial with an arbitrary-precision SDP solver. An exact SOS\ndecomposition is obtained thanks to the perturbation terms. We prove that bit\ncomplexity estimates on output size and runtime are both polynomial in the\ndegree of the input polynomial and simply exponential in the number of\nvariables. Next, we apply this algorithm to compute exact Polya and Putinar's\nrepresentations respectively for positive definite forms and positive\npolynomials over basic compact semi-algebraic sets. We also compare the\nimplementation of our algorithms with existing methods in computer algebra\nincluding cylindrical algebraic decomposition and critical point method.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.10339v1"
    },
    {
        "title": "Solving determinantal systems using homotopy techniques",
        "authors": [
            "Jonathan D. Hauenstein",
            "Mohab Safey El Din",
            "Éric Schost",
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Let $\\K$ be a field of characteristic zero and $\\Kbar$ be an algebraic\nclosure of $\\K$. Consider a sequence of polynomials$G=(g\\_1,\\dots,g\\_s)$ in\n$\\K[X\\_1,\\dots,X\\_n]$, a polynomial matrix $\\F=[f\\_{i,j}] \\in\n\\K[X\\_1,\\dots,X\\_n]^{p \\times q}$, with $p \\leq q$,and the algebraic set\n$V\\_p(F, G)$ of points in $\\KKbar$ at which all polynomials in $\\G$ and all\n$p$-minors of $\\F$vanish. Such polynomial systems appear naturally in e.g.\npolynomial optimization, computational geometry.We provide bounds on the number\nof isolated points in $V\\_p(F, G)$ depending on the maxima of the degrees in\nrows (resp. columns) of $\\F$. Next, we design homotopy algorithms for computing\nthose points. These algorithms take advantage of the determinantal structure of\nthe system defining $V\\_p(F, G)$. In particular, the algorithms run in time\nthat is polynomial in the bound on the number of isolated points.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.10409v1"
    },
    {
        "title": "Definite Sums as Solutions of Linear Recurrences With Polynomial\n  Coefficients",
        "authors": [
            "Marko Petkovšek"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We present an algorithm which, given a linear recurrence operator $L$ with\npolynomial coefficients, $m \\in \\mathbb{N}\\setminus\\{0\\}$, $a_1,a_2,\\ldots,a_m\n\\in \\mathbb{N}\\setminus\\{0\\}$ and $b_1,b_2,\\ldots,b_m \\in \\mathbb{K}$, returns\na linear recurrence operator $L'$ with rational coefficients such that for\nevery sequence $h$, \\[ L\\left(\\sum_{k=0}^\\infty \\prod_{i=1}^m \\binom{a_i n +\nb_i}{k} h_k\\right) = 0 \\] if and only if $L' h = 0$.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.02964v1"
    },
    {
        "title": "Summer Research Report: Towards Incremental Lazard Cylindrical Algebraic\n  Decomposition",
        "authors": [
            "Alexander I. Cowen-Rivers",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Cylindrical Algebraic Decomposition (CAD) is an important tool within\ncomputational real algebraic geometry, capable of solving many problems to do\nwith polynomial systems over the reals, but known to have worst-case\ncomputational complexity doubly exponential in the number of variables. It has\nlong been studied by the Symbolic Computation community and is implemented in a\nvariety of computer algebra systems, however, it has also found recent interest\nin the Satisfiability Checking community for use with SMT-solvers. The SCSC\nProject seeks to build bridges between these communities.\n  The present report describes progress made during a Research Internship in\nSummer 2017 funded by the EU H2020 SCSC CSA. We describe a proof of concept\nimplementation of an Incremental CAD algorithm in Maple, where CADs are built\nand refined incrementally by polynomial constraint, in contrast to the usual\napproach of a single computation from a single input. This advance would make\nCAD of use to SMT-solvers who search for solutions by constantly reformulating\nlogical formula and querying solvers like CAD for whether a logical solution is\nadmissible. We describe experiments for the proof of concept, which clearly\ndisplay the computational advantages when compared to iterated re-computation.\nIn addition, the project implemented this work under the recently verified\nLazard projection scheme (with corresponding Lazard evaluation). That is the\nminimal complete CAD method in theory, and this is the first documented\nimplementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.08564v1"
    },
    {
        "title": "Quantifier Elimination for Reasoning in Economics",
        "authors": [
            "Casey B. Mulligan",
            "Russell Bradford",
            "James H. Davenport",
            "Matthew England",
            "Zak Tonks"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We consider the use of Quantifier Elimination (QE) technology for automated\nreasoning in economics. QE dates back to Tarski's work in the 1940s with\nsoftware to perform it dating to the 1970s. There is a great body of work\nconsidering its application in science and engineering but we show here how it\ncan also find application in the social sciences. We explain how many suggested\ntheorems in economics could either be proven, or even have their hypotheses\nshown to be inconsistent, automatically; and describe the application of this\nin both economics education and research. We describe a bank of QE examples\ngathered from economics literature and note the structure of these are, on\naverage, quite different to those occurring in the computer algebra literature.\nThis leads us to suggest a new incremental QE approach based on result\nmemorization of commonly occurring generic QE results.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.10037v2"
    },
    {
        "title": "Computing an LLL-reduced basis of the orthogonal lattice",
        "authors": [
            "Jingwei Chen",
            "Damien Stehlé",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  As a typical application, the Lenstra-Lenstra-Lovasz lattice basis reduction\nalgorithm (LLL) is used to compute a reduced basis of the orthogonal lattice\nfor a given integer matrix, via reducing a special kind of lattice bases. With\nsuch bases in input, we propose a new technique for bounding from above the\nnumber of iterations required by the LLL algorithm. The main technical\ningredient is a variant of the classical LLL potential, which could prove\nuseful to understand the behavior of LLL for other families of input bases.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03418v1"
    },
    {
        "title": "Generalized Hermite Reduction, Creative Telescoping and Definite\n  Integration of D-Finite Functions",
        "authors": [
            "Alin Bostan",
            "Frédéric Chyzak",
            "Pierre Lairez",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Hermite reduction is a classical algorithmic tool in symbolic integration. It\nis used to decompose a given rational function as a sum of a function with\nsimple poles and the derivative of another rational function. We extend Hermite\nreduction to arbitrary linear differential operators instead of the pure\nderivative, and develop efficient algorithms for this reduction. We then apply\nthe generalized Hermite reduction to the computation of linear operators\nsatisfied by single definite integrals of D-finite functions of several\ncontinuous or discrete parameters. The resulting algorithm is a generalization\nof reduction-based methods for creative telescoping.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03445v1"
    },
    {
        "title": "Towards Mixed Gr{ö}bner Basis Algorithms: the Multihomogeneous and\n  Sparse Case",
        "authors": [
            "Matías Bender",
            "Jean-Charles Faugère",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  One of the biggest open problems in computational algebra is the design of\nefficient algorithms for Gr{\\\"o}bner basis computations that take into account\nthe sparsity of the input polynomials. We can perform such computations in the\ncase of unmixed polynomial systems, that is systems with polynomials having the\nsame support, using the approach of Faug{\\`e}re, Spaenlehauer, and Svartz\n[ISSAC'14]. We present two algorithms for sparse Gr{\\\"o}bner bases computations\nfor mixed systems. The first one computes with mixed sparse systems and\nexploits the supports of the polynomials. Under regularity assumptions, it\nperforms no reductions to zero. For mixed, square, and 0-dimensional\nmultihomogeneous polynomial systems, we present a dedicated, and potentially\nmore efficient, algorithm that exploits different algebraic properties that\nperforms no reduction to zero. We give an explicit bound for the maximal degree\nappearing in the computations.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03577v2"
    },
    {
        "title": "On the Annihilator Ideal of an Inverse Form. A Simplification",
        "authors": [
            "Graham H. Norton"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We simplify an earlier paper of the same title by not using syzygy\npolynomials and by not using a trichotomy of inverse forms. Let $\\K$ be a field\nand $\\M=\\K[x^{-1},z^{-1}]$ denote Macaulay's $\\K[x,z]$ module of inverse\npolynomials; here $z$ and $z^{-1}$ are homogenising variables. An inverse form\n$F\\in\\M$ has a homogeneous annihilator ideal, $\\I_F$\\,. In an earlier paper we\ninductively constructed an ordered pair ($f_1$\\,,\\,$f_2$) of forms in $\\K[x,z]$\nwhich generate $\\I_F$. We used syzygy polynomials to show that the intermediate\nforms give a minimal grlex Groebner basis, which can be efficiently reduced.\n  We give a significantly shorter proof that the intermediate forms are a\nminimal grlex Groebner basis for $\\I_F$\\,. We also simplify our proof that\neither $ F$ is already reduced or a monomial of $f_1$ can be reduced by\n$f_2$\\,. The algorithm that computes $f_1\\,,f_2$ yields a variant of the\nBerlekamp-Massey algorithm which does not use the last 'length change' approach\nof Massey.\n  These new proofs avoid the three separate cases, 'triples' and the technical\nfactorisation of intermediate 'essential' forms. We also show that $f_1,f_2$ is\na maximal $\\R$ regular sequence for $\\I_F$\\,, so that $\\I_F$ is a complete\nintersection.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03995v1"
    },
    {
        "title": "Bilinear systems with two supports: Koszul resultant matrices,\n  eigenvalues, and eigenvectors",
        "authors": [
            "Matías Bender",
            "Jean-Charles Faugère",
            "Angelos Mantzaflaris",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  A fundamental problem in computational algebraic geometry is the computation\nof the resultant. A central question is when and how to compute it as the\ndeterminant of a matrix. whose elements are the coefficients of the input\npolynomials up-to sign. This problem is well understood for unmixed\nmultihomogeneous systems, that is for systems consisting of multihomogeneous\npolynomials with the * 1 same support. However, little is known for mixed\nsystems, that is for systems consisting of polynomials with different supports.\nWe consider the computation of the multihomogeneous resultant of bilinear\nsystems involving two different supports. We present a constructive approach\nthat expresses the resultant as the exact determinant of a Koszul resultant\nmatrix, that is a matrix constructed from maps in the Koszul complex. We\nexploit the resultant matrix to propose an algorithm to solve such systems. In\nthe process we extend the classical eigenvalues and eigenvectors criterion to a\nmore general setting. Our extension of the eigenvalues criterion applies to a\ngeneral class of matrices, including the Sylvester-type and the Koszul-type\nones.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.05060v1"
    },
    {
        "title": "New bounds and efficient algorithm for sparse difference resultant",
        "authors": [
            "Chun-Ming Yuan",
            "Zhi-Yong Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  The sparse difference resultant introduced in \\citep{gao-2015} is a basic\nconcept in difference elimination theory.\n  In this paper, we show that the sparse difference resultant of a generic\nLaurent transformally essential system can be computed via the sparse resultant\nof a simple algebraic system arising from the difference system. Moreover, new\norder bounds of sparse difference resultant are found. Then we propose an\nefficient algorithm to compute sparse difference resultant which is the\nquotient of two determinants whose elements are the coefficients of the\npolynomials in the algebraic system.\n  The complexity of the algorithm is analyzed and experimental results show the\nefficiency of the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.00057v3"
    },
    {
        "title": "Computation of gcd chain over the power of an irreducible polynomial",
        "authors": [
            "Xavier Dahan"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  A notion of gcd chain has been introduced by the author at ISSAC 2017 for two\nunivariate monic polynomials with coefficients in a ring R = k[x_1, ..., x_n\n]/(T) where T is a primary triangular set of dimension zero. A complete\nalgorithm to compute such a gcd chain remains challenging. This work treats\ncompletely the case of a triangular set T = (T_1 (x)) in one variable, namely a\npower of an irreducible polynomial. This seemingly \"easy\" case reveals the main\nsteps necessary for treating the general case, and it allows to isolate the\nparticular one step that does not directly extend and requires more care.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.09056v2"
    },
    {
        "title": "A nearly optimal algorithm to decompose binary forms",
        "authors": [
            "Matías Bender",
            "Jean-Charles Faugère",
            "Ludovic Perret",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Symmetric tensor decomposition is an important problem with applications in\nseveral areas for example signal processing, statistics, data analysis and\ncomputational neuroscience. It is equivalent to Waring's problem for\nhomogeneous polynomials, that is to write a homogeneous polynomial in n\nvariables of degree D as a sum of D-th powers of linear forms, using the\nminimal number of summands. This minimal number is called the rank of the\npolynomial/tensor. We focus on decomposing binary forms, a problem that\ncorresponds to the decomposition of symmetric tensors of dimension 2 and order\nD. Under this formulation, the problem finds its roots in invariant theory\nwhere the decompositions are known as canonical forms. In this context many\ndifferent algorithms were proposed. We introduce a superfast algorithm that\nimproves the previous approaches with results from structured linear algebra.\nIt achieves a softly linear arithmetic complexity bound. To the best of our\nknowledge, the previously known algorithms have at least quadratic complexity\nbounds. Our algorithm computes a symbolic decomposition in $O(M(D) log(D))$\narithmetic operations, where $M(D)$ is the complexity of multiplying two\npolynomials of degree D. It is deterministic when the decomposition is unique.\nWhen the decomposition is not unique, our algorithm is randomized. We present a\nMonte Carlo version of it and we show how to modify it to a Las Vegas one,\nwithin the same complexity. From the symbolic decomposition, we approximate the\nterms of the decomposition with an error of $2^{--$\\epsilon$}$ , in $O(D\nlog^2(D) (log^2(D) + log($\\epsilon$)))$ arithmetic operations. We use results\nfrom Kaltofen and Yagati (1989) to bound the size of the representation of the\ncoefficients involved in the decomposition and we bound the algebraic degree of\nthe problem by min(rank, D -- rank + 1). We show that this bound can be tight.\nWhen the input polynomial has integer coefficients, our algorithm performs, up\nto poly-logarithmic factors, $O\\_{bit} (D{\\ell} + D^4 + D^3 $\\tau$)$ bit\noperations, where $$\\tau$$ is the maximum bitsize of the coefficients and\n$2^{--{\\ell}}$ is the relative error of the terms in the decomposition.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.12588v2"
    },
    {
        "title": "Computing Nearby Non-trivial Smith Forms",
        "authors": [
            "Mark Giesbrecht",
            "Joseph Haraldson",
            "George Labahn"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We consider the problem of computing the nearest matrix polynomial with a\nnon-trivial Smith Normal Form. We show that computing the Smith form of a\nmatrix polynomial is amenable to numeric computation as an optimization\nproblem. Furthermore, we describe an effective optimization technique to find a\nnearby matrix polynomial with a non-trivial Smith form. The results are then\ngeneralized to include the computation of a matrix polynomial having a maximum\nspecified number of ones in the Smith Form (i.e., with a maximum specified\nMcCoy rank). We discuss the geometry and existence of solutions and how our\nresults can be used for an error analysis. We develop an optimization-based\napproach and demonstrate an iterative numerical method for computing a nearby\nmatrix polynomial with the desired spectral properties. We also describe an\nimplementation of our algorithms and demonstrate the robustness with examples\nin Maple.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.04590v2"
    },
    {
        "title": "A New Deflation Method For Verifying the Isolated Singular Zeros of\n  Polynomial Systems",
        "authors": [
            "Jin-San Cheng",
            "Xiaojie Dou",
            "Junyi Wen"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this paper, we develop a new deflation technique for refining or verifying\nthe isolated singular zeros of polynomial systems. Starting from a polynomial\nsystem with an isolated singular zero, by computing the derivatives of the\ninput polynomials directly or the linear combinations of the related\npolynomials, we construct a new system, which can be used to refine or verify\nthe isolated singular zero of the input system. In order to preserve the\naccuracy in numerical computation as much as possible, new variables are\nintroduced to represent the coefficients of the linear combinations of the\nrelated polynomials. To our knowledge, it is the first time that considering\nthe deflation problem of polynomial systems from the perspective of the linear\ncombination. Some acceleration strategies are proposed to reduce the scale of\nthe final system. We also give some further analysis of the tolerances we use,\nwhich can help us have a better understanding of our method.The experiments\nshow that our method is effective and efficient. Especially, it works well for\nzeros with high multiplicities of large systems. It also works for isolated\nsingular zeros of non-polynomial systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11534v1"
    },
    {
        "title": "Quadratic Probabilistic Algorithms for Normal Bases",
        "authors": [
            "Mark Giesbrecht",
            "Armin Jamshidpey",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  It is well known that for any finite Galois extension field $K/F$, with\nGalois group $G = \\mathrm{Gal}(K/F)$, there exists an element $\\alpha \\in K$\nwhose orbit $G\\cdot\\alpha$ forms an $F$-basis of $K$. Such an element $\\alpha$\nis called \\emph{normal} and $G\\cdot\\alpha$ is called a normal basis. In this\npaper we introduce a probabilistic algorithm for finding a normal element when\n$G$ is either a finite abelian or a metacyclic group. The algorithm is based on\nthe fact that deciding whether a random element $\\alpha \\in K$ is normal can be\nreduced to deciding whether $\\sum_{\\sigma \\in G} \\sigma(\\alpha)\\sigma \\in K[G]$\nis invertible. In an algebraic model, the cost of our algorithm is quadratic in\nthe size of $G$ for metacyclic $G$ and slightly subquadratic for abelian $G$.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03278v1"
    },
    {
        "title": "On some classes of irreducible polynomials",
        "authors": [
            "Jaime Gutierrez",
            "Jorge Jimenez Urroz"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The aim of the paper is to produce new families of irreducible polynomials,\ngeneralizing previous results in the area. One example of our general result is\nthat for a near-separated polynomial, i.e., polynomials of the form\n$F(x,y)=f_1(x)f_2(y)-f_2(x)f_1(y)$, then $F(x,y)+r$ is always irreducible for\nany constant $r$ different from zero. We also provide the biggest known family\nof HIP polynomials in several variables. These are polynomials\n$p(x_1,\\ldots,x_n) \\in K[x_1,\\ldots,x_n]$ over a zero characteristic field $K$\nsuch that $p(h_1(x_1),\\ldots,h_n(x_n))$ is irreducible over $K$ for every\n$n$-tuple $h_1(x_1),\\ldots,h_n(x_n)$ of non constant one variable polynomials\nover $K$. The results can also be applied to fields of positive characteristic,\nwith some modifications.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.08441v1"
    },
    {
        "title": "Cylindrical Algebraic Decomposition with Equational Constraints",
        "authors": [
            "Matthew England",
            "Russell Bradford",
            "James H. Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Cylindrical Algebraic Decomposition (CAD) has long been one of the most\nimportant algorithms within Symbolic Computation, as a tool to perform\nquantifier elimination in first order logic over the reals. More recently it is\nfinding prominence in the Satisfiability Checking community as a tool to\nidentify satisfying solutions of problems in nonlinear real arithmetic.\n  The original algorithm produces decompositions according to the signs of\npolynomials, when what is usually required is a decomposition according to the\ntruth of a formula containing those polynomials. One approach to achieve that\ncoarser (but hopefully cheaper) decomposition is to reduce the polynomials\nidentified in the CAD to reflect a logical structure which reduces the solution\nspace dimension: the presence of Equational Constraints (ECs).\n  This paper may act as a tutorial for the use of CAD with ECs: we describe all\nnecessary background and the current state of the art. In particular, we\npresent recent work on how McCallum's theory of reduced projection may be\nleveraged to make further savings in the lifting phase: both to the polynomials\nwe lift with and the cells lifted over. We give a new complexity analysis to\ndemonstrate that the double exponent in the worst case complexity bound for CAD\nreduces in line with the number of ECs. We show that the reduction can apply to\nboth the number of polynomials produced and their degree.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.08999v1"
    },
    {
        "title": "Testing zero-dimensionality of varieties at a point",
        "authors": [
            "Katsusuke Nabeshima",
            "Shinichi Tajima"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Effective methods are introduced for testing zero-dimensionality of varieties\nat a point. The motivation of this paper is to compute and analyze deformations\nof isolated hypersurface singularities. As an application, methods for\ncomputing local dimensions are also described. For the case where a given ideal\ncontains parameters, the proposed algorithms can output in particular a\ndecomposition of a parameter space into strata according to the local dimension\nat a point of the associated varieties. The key of the proposed algorithms is\nthe use of the notion of comprehensive Gr\\\"obner systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.12365v1"
    },
    {
        "title": "A Simple and Fast Algorithm for Computing the $N$-th Term of a Linearly\n  Recurrent Sequence",
        "authors": [
            "Alin Bostan",
            "Ryuhei Mori"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We present a simple and fast algorithm for computing the $N$-th term of a\ngiven linearly recurrent sequence. Our new algorithm uses $O(\\mathsf{M}(d) \\log\nN)$ arithmetic operations, where $d$ is the order of the recurrence, and\n$\\mathsf{M}(d)$ denotes the number of arithmetic operations for computing the\nproduct of two polynomials of degree $d$. The state-of-the-art algorithm, due\nto Charles Fiduccia (1985), has the same arithmetic complexity up to a constant\nfactor. Our algorithm is simpler, faster and obtained by a totally different\nmethod. We also discuss several algorithmic applications, notably to polynomial\nmodular exponentiation, powering of matrices and high-order lifting.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.08822v1"
    },
    {
        "title": "Robots, computer algebra and eight connected components",
        "authors": [
            "Jose Capco",
            "Mohab Safey El Din",
            "Josef Schicho"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Answering connectivity queries in semi-algebraic sets is a long-standing and\nchallenging computational issue with applications in robotics, in particular\nfor the analysis of kinematic singularities. One task there is to compute the\nnumber of connected components of the complementary of the singularities of the\nkinematic map. Another task is to design a continuous path joining two given\npoints lying in the same connected component of such a set. In this paper, we\npush forward the current capabilities of computer algebra to obtain\ncomputer-aided proofs of the analysis of the kinematic singularities of various\nrobots used in industry. We first show how to combine mathematical reasoning\nwith easy symbolic computations to study the kinematic singularities of an\ninfinite family (depending on paramaters) modelled by the UR-series produced by\nthe company ``Universal Robots''. Next, we compute roadmaps (which are curves\nused to answer connectivity queries) for this family of robots. We design an\nalgorithm for ``solving'' positive dimensional polynomial system depending on\nparameters. The meaning of solving here means partitioning the parameter's\nspace into semi-algebraic components over which the number of connected\ncomponents of the semi-algebraic set defined by the input system is invariant.\nPractical experiments confirm our computer-aided proof and show that such an\nalgorithm can already be used to analyze the kinematic singularities of the\nUR-series family. The number of connected components of the complementary of\nthe kinematic singularities of generic robots in this family is $8$.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.13392v1"
    },
    {
        "title": "Using the distribution of cells by dimension in a cylindrical algebraic\n  decomposition",
        "authors": [
            "David Wilson",
            "Matthew England",
            "Russell Bradford",
            "James H. Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We investigate the distribution of cells by dimension in cylindrical\nalgebraic decompositions (CADs). We find that they follow a standard\ndistribution which seems largely independent of the underlying problem or CAD\nalgorithm used. Rather, the distribution is inherent to the cylindrical\nstructure and determined mostly by the number of variables.\n  This insight is then combined with an algorithm that produces only\nfull-dimensional cells to give an accurate method of predicting the number of\ncells in a complete CAD. Since constructing only full-dimensional cells is\nrelatively inexpensive (involving no costly algebraic number calculations) this\nleads to heuristics for helping with various questions of problem formulation\nfor CAD, such as choosing an optimal variable ordering. Our experiments\ndemonstrate that this approach can be highly effective.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.1781v1"
    },
    {
        "title": "Fast and deterministic computation of the determinant of a polynomial\n  matrix",
        "authors": [
            "Wei Zhou",
            "George Labahn"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Given a square, nonsingular matrix of univariate polynomials\n$\\mathbf{F}\\in\\mathbb{K}[x]^{n\\times n}$ over a field $\\mathbb{K}$, we give a\ndeterministic algorithm for finding the determinant of $\\mathbf{F}$. The\ncomplexity of the algorithm is $\\bigO \\left(n^{\\omega}s\\right)$ field\noperations where $s$ is the average column degree or the average row degree of\n$\\mathbf{F}$. Here $\\bigO$ notation is Big-$O$ with log factors omitted and\n$\\omega$ is the exponent of matrix multiplication.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.5462v1"
    },
    {
        "title": "On Ideal Lattices and Gröbner Bases",
        "authors": [
            "Maria Francis",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  In this paper, we draw a connection between ideal lattices and Gr\\\"{o}bner\nbases in the multivariate polynomial rings over integers. We study extension of\nideal lattices in $\\mathbb{Z}[x]/\\langle f \\rangle$ (Lyubashevsky \\&\nMicciancio, 2006) to ideal lattices in\n$\\mathbb{Z}[x_1,\\ldots,x_n]/\\mathfrak{a}$, the multivariate case, where $f$ is\na polynomial in $\\mathbb{Z}[X]$ and $\\mathfrak{a}$ is an ideal in\n$\\mathbb{Z}[x_1,\\ldots,x_n]$. Ideal lattices in univariate case are interpreted\nas generalizations of cyclic lattices. We introduce a notion of multivariate\ncyclic lattices and we show that multivariate ideal lattices are indeed a\ngeneralization of them. We show that the fact that existence of ideal lattice\nin univariate case if and only if $f$ is monic translates to short reduced\nGr\\\"obner basis (Francis \\& Dukkipati, 2014) of $\\mathfrak{a}$ is monic in\nmultivariate case. We, thereby, give a necessary and sufficient condition for\nresidue class polynomial rings over $\\mathbb{Z}$ to have ideal lattices. We\nalso characterize ideals in $\\mathbb{Z}[x_1,\\ldots,x_n]$ that give rise to full\nrank lattices.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.7788v2"
    },
    {
        "title": "Algorithms for zero-dimensional ideals using linear recurrent sequences",
        "authors": [
            "Vincent Neiger",
            "Hamid Rahkooy",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Inspired by Faug\\`ere and Mou's sparse FGLM algorithm, we show how using\nlinear recurrent multi-dimensional sequences can allow one to perform\noperations such as the primary decomposition of an ideal, by computing the\nannihilator of one or several such sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.01971v1"
    },
    {
        "title": "Measured Multiseries and Integration",
        "authors": [
            "John Shackell"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  A paper by Bruno Salvy and the author introduced measured multiseries and\ngave an algorithm to compute these for a large class of elementary functions,\nmodulo a zero-equivalence method for constants. This gave a theoretical\nbackground for the implementation that Salvy was developing at that time. The\nmain result of the present article is an algorithm to calculate measured\nmultiseries for integrals of functions of the form h*sin G, where h and G\nbelong to a Hardy field. The process can reiterated with the resulting algebra,\nand also applied to solutions of a second order differential equation of a\nparticular form.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.02235v1"
    },
    {
        "title": "Rational invariants of even ternary forms under the orthogonal group",
        "authors": [
            "Paul Görlach",
            "Evelyne Hubert",
            "Théo Papadopoulo"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this article we determine a generating set of rational invariants of\nminimal cardinality for the action of the orthogonal group $\\mathrm{O}_3$ on\nthe space $\\mathbb{R}[x,y,z]_{2d}$ of ternary forms of even degree $2d$. The\nconstruction relies on two key ingredients: On one hand, the Slice Lemma allows\nus to reduce the problem to dermining the invariants for the action on a\nsubspace of the finite subgroup $\\mathrm{B}_3$ of signed permutations. On the\nother hand, our construction relies in a fundamental way on specific bases of\nharmonic polynomials. These bases provide maps with prescribed\n$\\mathrm{B}_3$-equivariance properties. Our explicit construction of these\nbases should be relevant well beyond the scope of this paper. The expression of\nthe $\\mathrm{B}_3$-invariants can then be given in a compact form as the\ncomposition of two equivariant maps. Instead of providing (cumbersome) explicit\nexpressions for the $\\mathrm{O}_3$-invariants, we provide efficient algorithms\nfor their evaluation and rewriting. We also use the constructed\n$\\mathrm{B}_3$-invariants to determine the $\\mathrm{O}_3$-orbit locus and\nprovide an algorithm for the inverse problem of finding an element in\n$\\mathbb{R}[x,y,z]_{2d}$ with prescribed values for its invariants. These are\nthe computational issues relevant in brain imaging.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.09979v3"
    },
    {
        "title": "An Additive Decomposition in S-Primitive Towers",
        "authors": [
            "Hao Du",
            "Jing Guo",
            "Ziming Li",
            "Elaine Wong"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We consider the additive decomposition problem in primitive towers and\npresent an algorithm to decompose a function in an S-primitive tower as a sum\nof a derivative in the tower and a remainder which is minimal in some sense.\nSpecial instances of S-primitive towers include differential fields generated\nby finitely many logarithmic functions and logarithmic integrals. A function in\nan S-primitive tower is integrable in the tower if and only if the remainder is\nequal to zero. The additive decomposition is achieved by viewing our towers not\nas a traditional chain of extension fields, but rather as a direct sum of\ncertain subrings. Furthermore, we can determine whether or not a function in an\nS-primitive tower has an elementary integral without solving any differential\nequations. We also show that a kind of S-primitive towers, known as logarithmic\ntowers, can be embedded into a particular extension where we can obtain a finer\nremainder.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.02355v1"
    },
    {
        "title": "Signature-based algorithms for Gr{ö}bner bases over Tate algebras",
        "authors": [
            "Xavier Caruso",
            "Tristan Vaccon",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Introduced by Tate in [Ta71], Tate algebras play a major role in the context\nof analytic geometry over the-adics, where they act as a counterpart to the use\nof polynomial algebras in classical algebraic geometry. In [CVV19] the\nformalism of Gr{\\\"o}bner bases over Tate algebras has been introduced and\neffectively implemented. One of the bottleneck in the algorithms was the time\nspent on reduction , which are significantly costlier than over polynomials. In\nthe present article, we introduce two signature-based Gr{\\\"o}bner bases\nalgorithms for Tate algebras, in order to avoid many reductions. They have been\nimplemented in SageMath. We discuss their superiority based on numerical\nevidences.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.04491v2"
    },
    {
        "title": "A divide-and-conquer algorithm for computing Gröbner bases of syzygies\n  in finite dimension",
        "authors": [
            "Simone Naldi",
            "Vincent Neiger"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Let $f_1,\\ldots,f_m$ be elements in a quotient $R^n / N$ which has finite\ndimension as a $K$-vector space, where $R = K[X_1,\\ldots,X_r]$ and $N$ is an\n$R$-submodule of $R^n$. We address the problem of computing a Gr\\\"obner basis\nof the module of syzygies of $(f_1,\\ldots,f_m)$, that is, of vectors\n$(p_1,\\ldots,p_m) \\in R^m$ such that $p_1 f_1 + \\cdots + p_m f_m = 0$.\n  An iterative algorithm for this problem was given by Marinari, M\\\"oller, and\nMora (1993) using a dual representation of $R^n / N$ as the kernel of a\ncollection of linear functionals. Following this viewpoint, we design a\ndivide-and-conquer algorithm, which can be interpreted as a generalization to\nseveral variables of Beckermann and Labahn's recursive approach for matrix\nPad\\'e and rational interpolation problems. To highlight the interest of this\nmethod, we focus on the specific case of bivariate Pad\\'e approximation and\nshow that it improves upon the best known complexity bounds.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06404v2"
    },
    {
        "title": "On the Uniqueness of Simultaneous Rational Function Reconstruction",
        "authors": [
            "Eleonora Guerrini",
            "Romain Lebreton",
            "Ilaria Zappatore"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  This paper focuses on the problem of reconstructing a vector of rational\nfunctions given some evaluations, or more generally given their remainders\nmodulo different polynomials. The special case of rational functions sharing\nthe same denominator, a.k.a.Simultaneous Rational Function Reconstruction\n(SRFR), has many applications from linear system solving to coding theory,\nprovided that SRFR has a unique solution. The number of unknowns in SRFR is\nsmaller than for a general vector of rational function. This allows to reduce\nthe number of evaluation points needed to guarantee the existence of a\nsolution, but we may lose its uniqueness. In this work, we prove that\nuniqueness is guaranteed for a generic instance.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08748v1"
    },
    {
        "title": "Factorization in categories of systems of linear partial differential\n  equations",
        "authors": [
            "S. P. Tsarev"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We start with elementary algebraic theory of factorization of linear ordinary\ndifferential equations developed in the period 1880-1930. After exposing these\nclassical results we sketch more sophisticated algorithmic approaches developed\nin the last 20 years.\n  The main part of this paper is devoted to modern generalizations of the\nnotion of factorization to the case of systems of linear partial differential\nequations and their relation with explicit solvability of nonlinear partial\ndifferential equations based on some constructions from the theory of abelian\ncategories.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.1341v1"
    },
    {
        "title": "Analyzing the Topology Types arising in a Family of Algebraic Curves\n  Depending On Two Parameters",
        "authors": [
            "Juan Gerardo Alcazar"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  Given the implicit equation $F(x,y,t,s)$ of a family of algebraic plane\ncurves depending on the parameters $t,s$, we provide an algorithm for studying\nthe topology types arising in the family. For this purpose, the algorithm\ncomputes a finite partition of the parameter space so that the topology type of\nthe family stays invariant over each element of the partition. The ideas\ncontained in the paper can be seen as a generalization of the ideas in\n\\cite{JGRS}, where the problem is solved for families of algebraic curves\ndepending on one parameter, to the two-parameters case.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.1676v2"
    },
    {
        "title": "Creative Telescoping for Holonomic Functions",
        "authors": [
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  The aim of this article is twofold: on the one hand it is intended to serve\nas a gentle introduction to the topic of creative telescoping, from a practical\npoint of view; for this purpose its application to several problems is\nexemplified. On the other hand, this chapter has the flavour of a survey\narticle: the developments in this area during the last two decades are sketched\nand a selection of references is compiled in order to highlight the impact of\ncreative telescoping in numerous contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.4554v1"
    },
    {
        "title": "Fast polynomial evaluation and composition",
        "authors": [
            "Guillaume Moroz"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  The library \\emph{fast\\_polynomial} for Sage compiles multivariate\npolynomials for subsequent fast evaluation. Several evaluation schemes are\nhandled, such as H\\\"orner, divide and conquer and new ones can be added easily.\nNotably, a new scheme is introduced that improves the classical divide and\nconquer scheme when the number of terms is not a pure power of two. Natively,\nthe library handles polynomials over gmp big integers, boost intervals, python\nnumeric types. And any type that supports addition and multiplication can\nextend the library thanks to the template design. Finally, the code is\nparallelized for the divide and conquer schemes, and memory allocation is\nlocalized and optimized for the different evaluation schemes. This extended\nabstract presents the concepts behind the \\emph{fast\\_polynomial} library. The\nsage package can be downloaded at\n\\url{http://trac.sagemath.org/sage_trac/ticket/13358}.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.5655v2"
    },
    {
        "title": "A nearly optimal algorithm for deciding connectivity queries in smooth\n  and bounded real algebraic sets",
        "authors": [
            "Mohab Safey El Din",
            "Eric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  A roadmap for a semi-algebraic set $S$ is a curve which has a non-empty and\nconnected intersection with all connected components of $S$. Hence, this kind\nof object, introduced by Canny, can be used to answer connectivity queries\n(with applications, for instance, to motion planning) but has also become of\ncentral importance in effective real algebraic geometry, since it is used in\nhigher-level algorithms. In this paper, we provide a probabilistic algorithm\nwhich computes roadmaps for smooth and bounded real algebraic sets. Its output\nsize and running time are polynomial in $(nD)^{n\\log(d)}$, where $D$ is the\nmaximum of the degrees of the input polynomials, $d$ is the dimension of the\nset under consideration and $n$ is the number of variables. More precisely, the\nrunning time of the algorithm is essentially subquadratic in the output size.\nEven under our assumptions, it is the first roadmap algorithm with output size\nand running time polynomial in $(nD)^{n\\log(d)}$.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7836v3"
    },
    {
        "title": "Fast Algorithms for Refined Parameterized Telescoping in Difference\n  Fields",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Parameterized telescoping (including telescoping and creative telescoping)\nand refined versions of it play a central role in the research area of symbolic\nsummation. Karr introduced 1981 $\\Pi\\Sigma$-fields, a general class of\ndifference fields, that enables one to consider this problem for indefinite\nnested sums and products covering as special cases, e.g., the\n($q$--)hypergeometric case and their mixed versions. This survey article\npresents the available algorithms in the framework of $\\Pi\\Sigma$-extensions\nand elaborates new results concerning efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7887v2"
    },
    {
        "title": "An Improvement over the GVW Algorithm for Inhomogeneous Polynomial\n  Systems",
        "authors": [
            "Yao Sun",
            "Dongdai Lin",
            "Dingkang Wang"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  The GVW algorithm is a signature-based algorithm for computing Gr\\\"obner\nbases. If the input system is not homogeneous, some J-pairs with higher\nsignatures but lower degrees are rejected by GVW's Syzygy Criterion, instead,\nGVW have to compute some J-pairs with lower signatures but higher degrees.\nConsequently, degrees of polynomials appearing during the computations may\nunnecessarily grow up higher and the computation become more expensive. In this\npaper, a variant of the GVW algorithm, called M-GVW, is proposed and mutant\npairs are introduced to overcome inconveniences brought by inhomogeneous input\npolynomials. Some techniques from linear algebra are used to improve the\nefficiency. Both GVW and M-GVW have been implemented in C++ and tested by many\nexamples from boolean polynomial rings. The timings show M-GVW usually performs\nmuch better than the original GVW algorithm when mutant pairs are found.\nBesides, M-GVW is also compared with intrinsic Gr\\\"obner bases functions on\nMaple, Singular and Magma. Due to the efficient routines from the M4RI library,\nthe experimental results show that M-GVW is very efficient.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1428v2"
    },
    {
        "title": "The Secant-Newton Map is Optimal Among Contracting $n^{th}$ Degree Maps\n  for $n^{th}$ Root Computation",
        "authors": [
            "Kayla Bishop",
            "Hoon Hong"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Consider the problem: given a real number $x$ and an error bound $\\epsilon$,\nfind an interval such that it contains the $\\sqrt[n]{x}$ and its width is less\nthan $\\epsilon$. One way to solve the problem is to start with an initial\ninterval and to repeatedly update it by applying an interval refinement map on\nit until it becomes narrow enough. In this paper, we prove that the well known\nSecant-Newton map is optimal among a certain family of natural generalizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2371v1"
    },
    {
        "title": "Nearly Optimal Computations with Structured Matrices",
        "authors": [
            "Victor Y. Pan",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We estimate the Boolean complexity of multiplication of structured matrices\nby a vector and the solution of nonsingular linear systems of equations with\nthese matrices. We study four basic most popular classes, that is, Toeplitz,\nHankel, Cauchy and Van-der-monde matrices, for which the cited computational\nproblems are equivalent to the task of polynomial multiplication and division\nand polynomial and rational multipoint evaluation and interpolation. The\nBoolean cost estimates for the latter problems have been obtained by Kirrinnis\nin \\cite{kirrinnis-joc-1998}, except for rational interpolation, which we\nsupply now. All known Boolean cost estimates for these problems rely on using\nKronecker product. This implies the $d$-fold precision increase for the $d$-th\ndegree output, but we avoid such an increase by relying on distinct techniques\nbased on employing FFT. Furthermore we simplify the analysis and make it more\ntransparent by combining the representation of our tasks and algorithms in\nterms of both structured matrices and polynomials and rational functions. This\nalso enables further extensions of our estimates to cover Trummer's important\nproblem and computations with the popular classes of structured matrices that\ngeneralize the four cited basic matrix classes.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4768v1"
    },
    {
        "title": "Accelerated Approximation of the Complex Roots of a Univariate\n  Polynomial (Extended Abstract)",
        "authors": [
            "Victor Y. Pan",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Highly efficient and even nearly optimal algorithms have been developed for\nthe classical problem of univariate polynomial root-finding (see, e.g.,\n\\cite{P95}, \\cite{P02}, \\cite{MNP13}, and the bibliography therein), but this\nis still an area of active research. By combining some powerful techniques\ndeveloped in this area we devise new nearly optimal algorithms, whose\nsubstantial merit is their simplicity, important for the implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4775v1"
    },
    {
        "title": "Problem formulation for truth-table invariant cylindrical algebraic\n  decomposition by incremental triangular decomposition",
        "authors": [
            "Matthew England",
            "Russell Bradford",
            "Changbo Chen",
            "James H. Davenport",
            "Marc Moreno Maza",
            "David Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Cylindrical algebraic decompositions (CADs) are a key tool for solving\nproblems in real algebraic geometry and beyond. We recently presented a new CAD\nalgorithm combining two advances: truth-table invariance, making the CAD\ninvariant with respect to the truth of logical formulae rather than the signs\nof polynomials; and CAD construction by regular chains technology, where first\na complex decomposition is constructed by refining a tree incrementally by\nconstraint. We here consider how best to formulate problems for input to this\nalgorithm. We focus on a choice (not relevant for other CAD algorithms) about\nthe order in which constraints are presented. We develop new heuristics to help\nmake this choice and thus allow the best use of the algorithm in practice. We\nalso consider other choices of problem formulation for CAD, as discussed in\nCICM 2013, revisiting these in the context of the new algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6371v1"
    },
    {
        "title": "An Elimination Method to Solve Interval Polynomial Systems",
        "authors": [
            "Sajjad Rahmany",
            "Abdolali Basiri",
            "Benyamin M. -Alizadeh"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  There are several efficient methods to solve linear interval polynomial\nsystems in the context of interval computations, however, the general case of\ninterval polynomial systems is not yet covered as well. In this paper we\nintroduce a new elimination method to solve and analyse interval polynomial\nsystems, in general case. This method is based on computational algebraic\ngeometry concepts such as polynomial ideals and Groebner basis computation.\nSpecially, we use the comprehensive Groebner system concept to keep the\ndependencies between interval coefficients. At the end of paper, we will state\nsome applications of our method to evaluate its performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.02423v1"
    },
    {
        "title": "A Fast Algorithm for Computing the p-Curvature",
        "authors": [
            "Alin Bostan",
            "Xavier Caruso",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We design an algorithm for computing the $p$-curvature of a differential\nsystem in positive characteristic $p$. For a system of dimension $r$ with\ncoefficients of degree at most $d$, its complexity is $\\softO (p d r^\\omega)$\noperations in the ground field (where $\\omega$ denotes the exponent of matrix\nmultiplication), whereas the size of the output is about $p d r^2$. Our\nalgorithm is then quasi-optimal assuming that matrix multiplication is\n(\\emph{i.e.} $\\omega = 2$). The main theoretical input we are using is the\nexistence of a well-suited ring of series with divided powers for which an\nanalogue of the Cauchy--Lipschitz Theorem holds.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.05645v1"
    },
    {
        "title": "A Probabilistic Algorithm for Computing Data-Discriminants of Likelihood\n  Equations",
        "authors": [
            "Jose Israel Rodriguez",
            "Xiaoxian Tang"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  An algebraic approach to the maximum likelihood estimation problem is to\nsolve a very structured parameterized polynomial system called likelihood\nequations that have finitely many complex (real or non-real) solutions. The\nonly solutions that are statistically meaningful are the real solutions with\npositive coordinates. In order to classify the parameters (data) according to\nthe number of real/positive solutions, we study how to efficiently compute the\ndiscriminants, say data-discriminants (DD), of the likelihood equations. We\ndevelop a probabilistic algorithm with three different strategies for computing\nDDs. Our implemented probabilistic algorithm based on Maple and FGb is more\nefficient than our previous version presented in ISSAC2015, and is also more\nefficient than the standard elimination for larger benchmarks. By applying\nRAGlib to a DD we compute, we give the real root classification of 3 by 3\nsymmetric matrix model.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.03901v2"
    },
    {
        "title": "Computing Chebyshev knot diagrams",
        "authors": [
            "P. -V Koseleff",
            "D Pecker",
            "Fabrice Rouillier",
            "C Tran"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  A Chebyshev curve $\\mathcal{C}(a,b,c,\\phi)$ has a parametrization of the\nform$ x(t)=T\\_a(t)$; \\ $y(t)=T\\_b(t)$; $z(t)= T\\_c(t + \\phi)$, where $a,b,c$are\nintegers, $T\\_n(t)$ is the Chebyshev polynomialof degree $n$ and $\\phi \\in\n\\mathbb{R}$. When $\\mathcal{C}(a,b,c,\\phi)$ is nonsingular,it defines a\npolynomial knot. We determine all possible knot diagrams when $\\phi$ varies.\nLet $a,b,c$ be integers, $a$ is odd, $(a,b)=1$, we show that one can list all\npossible knots $\\mathcal{C}(a,b,c,\\phi)$ in$\\tilde{\\mathcal{O}}(n^2)$ bit\noperations, with $n=abc$.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.07766v2"
    },
    {
        "title": "Time and space efficient generators for quasiseparable matrices",
        "authors": [
            "Clement Pernet",
            "Arne Storjohann"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  The class of quasiseparable matrices is defined by the property that any\nsubmatrix entirely below or above the main diagonal has small rank, namely\nbelow a bound called the order of quasiseparability. These matrices arise\nnaturally in solving PDE's for particle interaction with the Fast Multi-pole\nMethod (FMM), or computing generalized eigenvalues. From these application\nfields, structured representations and algorithms have been designed in\nnumerical linear algebra to compute with these matrices in time linear in the\nmatrix dimension and either quadratic or cubic in the quasiseparability order.\nMotivated by the design of the general purpose exact linear algebra library\nLinBox, and by algorithmic applications in algebraic computing, we adapt\nexisting techniques introduce novel ones to use quasiseparable matrices in\nexact linear algebra, where sub-cubic matrix arithmetic is available. In\nparticular, we will show, the connection between the notion of\nquasiseparability and the rank profile matrix invariant, that we have\nintroduced in 2015. It results in two new structured representations, one being\na simpler variation on the hierarchically semiseparable storage, and the second\none exploiting the generalized Bruhat decomposition. As a consequence, most\nbasic operations, such as computing the quasiseparability orders, applying a\nvector, a block vector, multiplying two quasiseparable matrices together,\ninverting a quasiseparable matrix, can be at least as fast and often faster\nthan previous existing algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.00396v2"
    },
    {
        "title": "Functional Decomposition using Principal Subfields",
        "authors": [
            "Luiz E. Allem",
            "Juliane Capaverde",
            "Mark van Hoeij",
            "Jonas Szutkoski"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Let $f\\in K(t)$ be a univariate rational function. It is well known that any\nnon-trivial decomposition $g \\circ h$, with $g,h\\in K(t)$, corresponds to a\nnon-trivial subfield $K(f(t))\\subsetneq L \\subsetneq K(t)$ and vice-versa. In\nthis paper we use the idea of principal subfields and fast\nsubfield-intersection techniques to compute the subfield lattice of\n$K(t)/K(f(t))$. This yields a Las Vegas type algorithm with improved complexity\nand better run times for finding all non-equivalent complete decompositions of\n$f$.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.03529v2"
    },
    {
        "title": "Criteria for Finite Difference Groebner Bases of Normal Binomial\n  Difference Ideals",
        "authors": [
            "Yu-Ao Chen",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we give decision criteria for normal binomial difference\npolynomial ideals in the univariate difference polynomial ring F{y} to have\nfinite difference Groebner bases and an algorithm to compute the finite\ndifference Groebner bases if these criteria are satisfied. The novelty of these\ncriteria lies in the fact that complicated properties about difference\npolynomial ideals are reduced to elementary properties of univariate\npolynomials in Z[x].\n",
        "pdf_link": "http://arxiv.org/pdf/1701.06248v1"
    },
    {
        "title": "Bounds for Substituting Algebraic Functions into D-finite Functions",
        "authors": [
            "Manuel Kauers",
            "Gleb Pogudin"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  It is well known that the composition of a D-finite function with an\nalgebraic function is again D-finite. We give the first estimates for the\norders and the degrees of annihilating operators for the compositions. We find\nthat the analysis of removable singularities leads to an order-degree curve\nwhich is much more accurate than the order-degree curve obtained from the usual\nlinear algebra reasoning.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.07802v3"
    },
    {
        "title": "Riemann Tensor Polynomial Canonicalization by Graph Algebra Extension",
        "authors": [
            "Hongbo Li",
            "Zhang Li",
            "Yang Li"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Tensor expression simplification is an \"ancient\" topic in computer algebra, a\nrepresentative of which is the canonicalization of Riemann tensor polynomials.\nPractically fast algorithms exist for monoterm canonicalization, but not for\nmultiterm canonicalization. Targeting the multiterm difficulty, in this paper\nwe establish the extension theory of graph algebra, and propose a\ncanonicalization algorithm for Riemann tensor polynomials based on this theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.08487v1"
    },
    {
        "title": "Certificates for triangular equivalence and rank profiles",
        "authors": [
            "Jean-Guillaume Dumas",
            "David Lucas",
            "Clément Pernet"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we give novel certificates for triangular equivalence and rank\nprofiles. These certificates enable to verify the row or column rank profiles\nor the whole rank profile matrix faster than recomputing them, with a\nnegligible overall overhead. We first provide quadratic time and space\nnon-interactive certificates saving the logarithmic factors of previously known\nones. Then we propose interactive certificates for the same problems whose\nMonte Carlo verification complexity requires a small constant number of\nmatrix-vector multiplications, a linear space, and a linear number of extra\nfield operations. As an application we also give an interactive protocol,\ncertifying the determinant of dense matrices, faster than the best previously\nknown one.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.03755v2"
    },
    {
        "title": "Algorithm for computing semi-Fourier sequences of expressions involving\n  exponentiations and integrations",
        "authors": [
            "Hoon Hong",
            "Adam Strzebonski"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We provide an algorithm for computing semi-Fourier sequences for expressions\nconstructed from arithmetic operations, exponentiations and integrations. The\nsemi-Fourier sequence is a relaxed version of Fourier sequence for polynomials\n(expressions made of additions and multiplications).\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07060v1"
    },
    {
        "title": "Fast generalized Bruhat decomposition",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  The deterministic recursive pivot-free algorithms for the computation of\ngeneralized Bruhat decomposition of the matrix in the field and for the\ncomputation of the inverse matrix are presented. This method has the same\ncomplexity as algorithm of matrix multiplication and it is suitable for the\nparallel computer systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07242v1"
    },
    {
        "title": "Triangular Decomposition of Matrices in a Domain",
        "authors": [
            "Gennadi Malaschonok",
            "Anton Scherbinin"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Deterministic recursive algorithms for the computation of matrix triangular\ndecompositions with permutations like LU and Bruhat decomposition are presented\nfor the case of commutative domains. This decomposition can be considered as a\ngeneralization of LU and Bruhat decompositions, because they both may be easily\nobtained from this triangular decomposition. Algorithms have the same\ncomplexity as the algorithm of matrix multiplication.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07243v1"
    },
    {
        "title": "Generalized Bruhat decomposition in commutative domains",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Deterministic recursive algorithms for the computation of generalized Bruhat\ndecomposition of the matrix in commutative domain are presented. This method\nhas the same complexity as the algorithm of matrix multiplication.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07248v1"
    },
    {
        "title": "Decomposition of polynomial sets into characteristic pairs",
        "authors": [
            "Dongming Wang",
            "Rina Dong",
            "Chenqi Mou"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  A characteristic pair is a pair (G,C) of polynomial sets in which G is a\nreduced lexicographic Groebner basis, C is the minimal triangular set contained\nin G, and C is normal. In this paper, we show that any finite polynomial set P\ncan be decomposed algorithmically into finitely many characteristic pairs with\nassociated zero relations, which provide representations for the zero set of P\nin terms of those of Groebner bases and those of triangular sets. The algorithm\nwe propose for the decomposition makes use of the inherent connection between\nRitt characteristic sets and lexicographic Groebner bases and is based\nessentially on the structural properties and the computation of lexicographic\nGroebner bases. Several nice properties about the decomposition and the\nresulting characteristic pairs, in particular relationships between the\nGroebner basis and the triangular set in each pair, are established. Examples\nare given to illustrate the algorithm and some of the properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.08664v1"
    },
    {
        "title": "Deterministic Interpolation of Sparse Black-box Multivariate Polynomials\n  using Kronecker Type Substitutions",
        "authors": [
            "Qiao-Long Huang",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we propose two new deterministic interpolation algorithms for\na sparse multivariate polynomial given as a standard black-box by introducing\nnew Kronecker type substitutions. Let $f\\in \\RB[x_1,\\dots,x_n]$ be a sparse\nblack-box polynomial with a degree bound $D$. When $\\RB=\\C$ or a finite field,\nour algorithms either have better bit complexity or better bit complexity in\n$D$ than existing deterministic algorithms. In particular, in the case of\ndeterministic algorithms for standard black-box models, our second algorithm\nhas the current best complexity in $D$ which is the dominant factor in the\ncomplexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.01301v2"
    },
    {
        "title": "On the bit-size of non-radical triangular sets",
        "authors": [
            "Xavier Dahan"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We present upper bounds on the bit-size of coefficients of non-radical\nlexicographical Groebner bases in purely triangular form (triangular sets) of\ndimension zero. This extends a previous work [Dahan-Schost, Issac'2004],\nconstrained to radical triangular sets; it follows the same technical steps,\nbased on interpolation. However, key notion of height of varieties is not\navailable for points with multiplicities; therefore the bounds obtained are\nless universal and depend on some input data. We also introduce a related\nfamily of non- monic polynomials that have smaller coefficients, and smaller\nbounds. It is not obvious to compute them from the initial triangular set\nthough.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.06396v1"
    },
    {
        "title": "Univariate Contraction and Multivariate Desingularization of Ore Ideals",
        "authors": [
            "Yi Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Ore operators with polynomial coefficients form a common algebraic\nabstraction for representing D-finite functions. They form the Ore ring\n$K(x)[D_x]$, where $K$ is the constant field. Suppose $K$ is the quotient field\nof some principal ideal domain $R$. The ring $R[x][D_x]$ consists of elements\nin $K(x)[D_x]$ without \"denominator\".\n  Given $L \\in K(x)[D_x]$, it generates a left ideal $I$ in $K(x)[D_x]$. We\ncall $I \\cap R[x][D_x]$ the univariate contraction of $I$.\n  When $L$ is a linear ordinary differential or difference operator, we design\na contraction algorithm for $L$ by using desingularized operators as proposed\nby Chen, Jaroschek, Kauers and Singer. When $L$ is an ordinary differential\noperator and $R = K$, our algorithm is more elementary than known algorithms.\nIn other cases, our results are new.\n  We propose the notion of completely desingularized operators, study their\nproperties, and design an algorithm for computing them. Completely\ndesingularized operators have interesting applications such as certifying\ninteger sequences and checking special cases of a conjecture of Krattenthaler.\n  A D-finite system is a finite set of linear homogeneous partial differential\nequations in several variables, whose solution space is of finite dimension.\nFor such systems, we give the notion of a singularity in terms of the\npolynomials appearing in them. We show that a point is a singularity of the\nsystem unless it admits a basis of power series solutions in which the starting\nmonomials are as small as possible with respect to some term order. Then a\nsingularity is apparent if the system admits a full basis of power series\nsolutions, the starting terms of which are not as small as possible. We prove\nthat apparent singularities in the multivariate case can be removed like in the\nunivariate case by adding suitable additional solutions to the original system.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.07445v1"
    },
    {
        "title": "On the Annihilator Ideal of an Inverse Form",
        "authors": [
            "Graham H. Norton"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Let $K$ be a field. We simplify and extend work of Althaler \\& D\\\"ur on\nfinite sequences over $K$ by regarding $K[x^{-1},z^{-1}]$ as a $K[x,z]$ module,\nand studying forms in $K[x^{-1},z^{-1}]$ from first principles. Then we apply\nour results to finite sequences.\n  First we define the annihilator ideal $I_F$ of a non-zero form $F\\in\nK[x^{-1},z^{-1}]$, a homogeneous ideal. We inductively construct an ordered\npair ($f_1$\\,,\\,$f_2$) of forms which generate $I_F$\\,; our generators are\nspecial in that $z$ does not divide the leading grlex monomial of $f_1$ but $z$\ndivides $f_2$\\,, and the sum of their total degrees is always $2-|F|$, where\n$|F|$ is the total degree of $F$. We show that $f_1,f_2$ is a maximal regular\nsequence for $I_F$, so that the height of $I_F$ is 2. The corresponding\nalgorithm is $\\sim |F|^2/2$.\n  The row vector obtained by accumulating intermediate forms of the\nconstruction gives a minimal grlex Gr\\\"obner basis for $I_F$ for no extra\ncomputational cost other than storage and apply this to determining $\\dim_K\n(K[x,z] /I_F)$\\,. We show that either the form vector is reduced or a monomial\nof $f_1$ can be reduced by $f_2$\\,. This enables us to efficiently construct\nthe unique reduced Gr\\\"obner basis for $I_F$ from the vector extension of our\nalgorithm.\n  Then we specialise to the inverse form of a finite sequence, obtaining\ngenerator forms for its annihilator ideal and a corresponding algorithm which\ndoes not use the last 'length change' of Massey. We compute the intersection of\ntwo annihilator ideals using syzygies in $K[x,z]^5$. This improves a result of\nAlthaler \\& D\\\"ur. Finally, dehomogenisation induces a one-to-one\ncorrespondence ($f_1$\\,,$f_2$) $\\mapsto$ (minimal polynomial, auxiliary\npolynomial), the output of the author's variant of the Berlekamp-Massey\nalgorithm. So we can also solve the LFSR synthesis problem via the\ncorresponding algorithm for sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.07731v2"
    },
    {
        "title": "Definite Sums of Hypergeometric Terms and Limits of P-Recursive\n  Sequences",
        "authors": [
            "Hui Huang"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  The ubiquity of the class of D-finite functions and P-recursive sequences in\nsymbolic computation is widely recognized. In this thesis, the presented work\nconsists of two parts related to this class.\n  In the first part, we generalize the reduction-based creative telescoping\nalgorithms to the hypergeometric setting, which allows to deal with definite\nsums of hypergeometric terms more quickly. We first modify the\nAbramov-Petkovsek reduction, and then design a new algorithm to compute minimal\ntelescopers for bivariate hypergeometric terms based on the modified reduction.\nThis new algorithm can avoid the costly computation of certificates, and\noutperforms the classical Zeilberger algorithm no matter whether certificates\nare computed or not according to the computational experiments. Moreover, we\nalso derive order bounds for minimal telescopers. These bounds are sometimes\nbetter, and never worse than the known ones.\n  In the second part of the thesis, we study the class of D-finite numbers. It\nconsists of the limits of convergent P-recursive sequences. Typically, this\nclass contains many well-known mathematical constants in addition to the\nalgebraic numbers. Our definition of the class of D-finite numbers depends on\ntwo subrings of the field of complex numbers. We investigate how different\nchoices of these two subrings affect the class. Moreover, we show that D-finite\nnumbers over the Gaussian rational field are essentially the same as the values\nof D-finite functions at non-singular algebraic number arguments (so-called the\nregular holonomic constants). This result makes it easier to recognize certain\nnumbers as belonging to this class.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08566v1"
    },
    {
        "title": "New Features in the Second Version of the Cadabra Computer Algebra\n  System",
        "authors": [
            "D. S. Kulyabov",
            "A. V. Korolkova",
            "L. A. Sevastianov"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In certain scientific domains, there is a need for tensor operations. To\nfacilitate tensor computations,computer algebra systems are employed. In our\nresearch, we have been using Cadabra as the main computer algebra system for\nseveral years. Recently, an operable second version of this software was\nreleased. In this version, a number of improvements were made that can be\nregarded as revolutionary ones. The most significant improvements are the\nimplementation of component computations and the change in the ideology of the\nCadabra's software mechanism as compared to the first version. This paper\nprovides a brief overview of the key improvements in the Cadabra system.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.02599v1"
    },
    {
        "title": "Homotopy techniques for solving sparse column support determinantal\n  polynomial systems",
        "authors": [
            "George Labahn",
            "Mohab Safey El Din",
            "Éric Schost",
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Let $\\mathbf{K}$ be a field of characteristic zero with\n$\\overline{\\mathbf{K}}$ its algebraic closure. Given a sequence of polynomials\n$\\mathbf{g} = (g_1, \\ldots, g_s) \\in \\mathbf{K}[x_1, \\ldots , x_n]^s$ and a\npolynomial matrix $\\mathbf{F} = [f_{i,j}] \\in \\mathbf{K}[x_1, \\ldots, x_n]^{p\n\\times q}$, with $p \\leq q$, we are interested in determining the isolated\npoints of $V_p(\\mathbf{F},\\mathbf{g})$, the algebraic set of points in\n$\\overline{\\mathbf{K}}$ at which all polynomials in $\\mathbf{g}$ and all\n$p$-minors of $\\mathbf{F}$ vanish, under the assumption $n = q - p + s + 1$.\nSuch polynomial systems arise in a variety of applications including for\nexample polynomial optimization and computational geometry. We design a\nrandomized sparse homotopy algorithm for computing the isolated points in\n$V_p(\\mathbf{F},\\mathbf{g})$ which takes advantage of the determinantal\nstructure of the system defining $V_p(\\mathbf{F}, \\mathbf{g})$. Its complexity\nis polynomial in the maximum number of isolated solutions to such systems\nsharing the same sparsity pattern and in some combinatorial quantities attached\nto the structure of such systems. It is the first algorithm which takes\nadvantage both on the determinantal structure and sparsity of input\npolynomials. We also derive complexity bounds for the particular but important\ncase where $\\mathbf{g}$ and the columns of $\\mathbf{F}$ satisfy weighted degree\nconstraints. Such systems arise naturally in the computation of critical points\nof maps restricted to algebraic sets when both are invariant by the action of\nthe symmetric group.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.00844v1"
    },
    {
        "title": "Computing critical points for invariant algebraic systems",
        "authors": [
            "Jean-Charles Faugère",
            "George Labahn",
            "Mohab Safey El Din",
            "Éric Schost",
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Let $\\mathbf{K}$ be a field and $\\phi$, $\\mathbf{f} = (f_1, \\ldots, f_s)$ in\n$\\mathbf{K}[x_1, \\dots, x_n]$ be multivariate polynomials (with $s < n$)\ninvariant under the action of $\\mathcal{S}_n$, the group of permutations of\n$\\{1, \\dots, n\\}$. We consider the problem of computing the points at which\n$\\mathbf{f}$ vanish and the Jacobian matrix associated to $\\mathbf{f}, \\phi$ is\nrank deficient provided that this set is finite. We exploit the invariance\nproperties of the input to split the solution space according to the orbits of\n$\\mathcal{S}_n$. This allows us to design an algorithm which gives a triangular\ndescription of the solution space and which runs in time polynomial in $d^s$,\n${{n+d}\\choose{d}}$ and $\\binom{n}{s+1}$ where $d$ is the maximum degree of the\ninput polynomials. When $d,s$ are fixed, this is polynomial in $n$ while when\n$s$ is fixed and $d \\simeq n$ this yields an exponential speed-up with respect\nto the usual polynomial system solving algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.00847v1"
    },
    {
        "title": "Guessing Gr{ö}bner Bases of Structured Ideals of Relations of\n  Sequences",
        "authors": [
            "Jérémy Berthomieu",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Assuming sufficiently many terms of a n-dimensional table defined over a\nfield are given, we aim at guessing the linear recurrence relations with either\nconstant or polynomial coefficients they satisfy. In many applications, the\ntable terms come along with a structure: for instance, they may be zero outside\nof a cone, they may be built from a Gr{\\\"o}bner basis of an ideal invariant\nunder the action of a finite group. Thus, we show how to take advantage of this\nstructure to both reduce the number of table queries and the number of\noperations in the base field to recover the ideal of relations of the table. In\napplications like in combinatorics, where all these zero terms make us guess\nmany fake relations, this allows us to drastically reduce these wrong guesses.\nThese algorithms have been implemented and, experimentally, they let us handle\nexamples that we could not manage otherwise. Furthermore, we show which kind of\ncone and lattice structures are preserved by skew polynomial multiplication.\nThis allows us to speed up the guessing of linear recurrence relations with\npolynomial coefficients by computing sparse Gr{\\\"o}bner bases or Gr{\\\"o}bner\nbases of an ideal invariant under the action of a finite group in a ring of\nskew polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.05248v2"
    },
    {
        "title": "Computer-Assisted Proofs of Some Identities for Bessel Functions of\n  Fractional Order",
        "authors": [
            "Stefan Gerhold",
            "Manuel Kauers",
            "Christoph Koutschan",
            "Peter Paule",
            "Carsten Schneider",
            "Burkhard Zimmermann"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We employ computer algebra algorithms to prove a collection of identities\ninvolving Bessel functions with half-integer orders and other special\nfunctions. These identities appear in the famous Handbook of Mathematical\nFunctions, as well as in its successor, the DLMF, but their proofs were lost.\nWe use generating functions and symbolic summation techniques to produce new\nproofs for them.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.4818v2"
    },
    {
        "title": "Sparse multivariate factorization by mean of a few bivariate\n  factorizations",
        "authors": [
            "Bernard Parisse"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We describe an algorithm to factor sparse multivariate polynomials using O(d)\nbivariate factorizations where d is the number of variables. This algorithm is\nimplemented in the Giac/Xcas computer algebra system.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.02569v1"
    },
    {
        "title": "A note about \"Faster algorithms for computing Hong's bound on absolute\n  positiveness\" by K. Mehlhorn and S. Ray",
        "authors": [
            "Przemysław Koprowski"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We show that a linear-time algorithm for computing Hong's bound for positive\nroots of a univariate polynomial, described by K. Mehlhorn and S. Ray in an\narticle \"Faster algorithms for computing Hong's bound on absolute\npositiveness\", is incorrect. We present a corrected version.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.06548v1"
    },
    {
        "title": "Reduction-Based Creative Telescoping for Fuchsian D-finite Functions",
        "authors": [
            "Shaoshi Chen",
            "Mark van Hoeij",
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Continuing a series of articles in the past few years on creative telescoping\nusing reductions, we adapt Trager's Hermite reduction for algebraic functions\nto fuchsian D-finite functions and develop a reduction-based creative\ntelescoping algorithm for this class of functions, thereby generalizing our\nrecent reduction-based algorithm for algebraic functions, presented at ISSAC\n2016.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.07421v1"
    },
    {
        "title": "Reverse Engineering of Irreducible Polynomials in GF(2^m) Arithmetic",
        "authors": [
            "Cunxi Yu",
            "Daniel Holcomb",
            "Maciej Ciesielski"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Current techniques for formally verifying circuits implemented in Galois\nfield (GF) arithmetic are limited to those with a known irreducible polynomial\nP(x). This paper presents a computer algebra based technique that extracts the\nirreducible polynomial P(x) used in the implementation of a multiplier in\nGF(2^m). The method is based on first extracting a unique polynomial in Galois\nfield of each output bit independently. P(x) is then obtained by analyzing the\nalgebraic expression in GF(2^m) of each output bit. We demonstrate that this\nmethod is able to reverse engineer the irreducible polynomial of an n-bit GF\nmultiplier in n threads. Experiments were performed on Mastrovito and\nMontgomery multipliers with different P (x), including NIST-recommended\npolynomials and optimal polynomials for different microprocessor architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.04588v1"
    },
    {
        "title": "Efficient sparse polynomial factoring using the Funnel heap",
        "authors": [
            "Fatima K. Abu Salem",
            "Khalil El-Harake",
            "Karl Gemayel"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  This work is a comprehensive extension of Abu-Salem et al. (2015) that\ninvestigates the prowess of the Funnel Heap for implementing sums of products\nin the polytope method for factoring polynomials, when the polynomials are in\nsparse distributed representation. We exploit that the work and cache\ncomplexity of an Insert operation using Funnel Heap can be refined to de- pend\non the rank of the inserted monomial product, where rank corresponds to its\nlifetime in Funnel Heap. By optimising on the pattern by which insertions and\nextractions occur during the Hensel lifting phase of the polytope method, we\nare able to obtain an adaptive Funnel Heap that minimises all of the work,\ncache, and space complexity of this phase. Additionally, we conduct a detailed\nempirical study confirming the superiority of Funnel Heap over the generic\nBinary Heap once swaps to external memory begin to take place. We demonstrate\nthat Funnel Heap is a more efficient merger than the cache oblivious k-merger,\nwhich fails to achieve its optimal (and amortised) cache complexity when used\nfor performing sums of products. This provides an empirical proof of concept\nthat the overlapping approach for perform- ing sums of products using one\nglobal Funnel Heap is more suited than the serialised approach, even when the\nlatter uses the best merging structures available.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.05403v1"
    },
    {
        "title": "Computing solutions of linear Mahler equations",
        "authors": [
            "Frédéric Chyzak",
            "Thomas Dreyfus",
            "Philippe Dumas",
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Mahler equations relate evaluations of the same function $f$ at iterated\n$b$th powers of the variable. They arise in particular in the study of\nautomatic sequences and in the complexity analysis of divide-and-conquer\nalgorithms. Recently, the problem of solving Mahler equations in closed form\nhas occurred in connection with number-theoretic questions. A difficulty in the\nmanipulation of Mahler equations is the exponential blow-up of degrees when\napplying a Mahler operator to a polynomial. In this work, we present algorithms\nfor solving linear Mahler equations for series, polynomials, and rational\nfunctions, and get polynomial-time complexity under a mild assumption.\nIncidentally, we develop an algorithm for computing the gcrd of a family of\nlinear Mahler operators.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.05518v2"
    },
    {
        "title": "Fast Matrix Multiplication and Symbolic Computation",
        "authors": [
            "Jean-Guillaume Dumas",
            "Victor Pan"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  The complexity of matrix multiplication (hereafter MM) has been intensively\nstudied since 1969, when Strassen surprisingly decreased the exponent 3 in the\ncubic cost of the straightforward classical MM to log 2 (7) $\\approx$ 2.8074.\nApplications to some fundamental problems of Linear Algebra and Computer\nScience have been immediately recognized, but the researchers in Computer\nAlgebra keep discovering more and more applications even today, with no sign of\nslowdown. We survey the unfinished history of decreasing the exponent towards\nits information lower bound 2, recall some important techniques discovered in\nthis process and linked to other fields of computing, reveal sample surprising\napplications to fast computation of the inner products of two vectors and\nsummation of integers, and discuss the curse of recursion, which separates the\nprogress in fast MM into its most acclaimed and purely theoretical part and\ninto valuable acceleration of MM of feasible sizes. Then, in the second part of\nour paper, we cover fast MM in realistic symbolic computations and discuss\napplications and implementation of fast exact matrix multiplication. We first\nreview how most of exact linear algebra can be reduced to matrix multiplication\nover small finite fields. Then we highlight the differences in the design of\napproximate and exact implementations of fast MM, taking into account nowadays\nprocessor and memory hierarchies. In the concluding section we comment on\ncurrent perspectives of the study of fast MM.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.05766v1"
    },
    {
        "title": "Comparative study of space filling curves for cache oblivious TU\n  Decomposition",
        "authors": [
            "Fatima K. Abu Salem",
            "Mira Al Arab"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We examine several matrix layouts based on space-filling curves that allow\nfor a cache-oblivious adaptation of parallel TU decomposition for rectangular\nmatrices over finite fields. The TU algorithm of \\cite{Dumas} requires index\nconversion routines for which the cost to encode and decode the chosen curve is\nsignificant. Using a detailed analysis of the number of bit operations required\nfor the encoding and decoding procedures, and filtering the cost of lookup\ntables that represent the recursive decomposition of the Hilbert curve, we show\nthat the Morton-hybrid order incurs the least cost for index conversion\nroutines that are required throughout the matrix decomposition as compared to\nthe Hilbert, Peano, or Morton orders. The motivation lies in that cache\nefficient parallel adaptations for which the natural sequential evaluation\norder demonstrates lower cache miss rate result in overall faster performance\non parallel machines with private or shared caches, on GPU's, or even cloud\ncomputing platforms. We report on preliminary experiments that demonstrate how\nthe TURBO algorithm in Morton-hybrid layout attains orders of magnitude\nimprovement in performance as the input matrices increase in size. For example,\nwhen $N = 2^{13}$, the row major TURBO algorithm concludes within about 38.6\nhours, whilst the Morton-hybrid algorithm with truncation size equal to $64$\nconcludes within 10.6 hours.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.06069v1"
    },
    {
        "title": "In-depth comparison of the Berlekamp--Massey--Sakata and the Scalar-FGLM\n  algorithms: the adaptive variants",
        "authors": [
            "Jérémy Berthomieu",
            "Jean-Charles Faugère"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  The Berlekamp--Massey--Sakata algorithm and the Scalar-FGLM algorithm both\ncompute the ideal of relations of a multidimensional linear recurrent\nsequence.Whenever quering a single sequence element is prohibitive, the\nbottleneck of these algorithms becomes the computation of all the needed\nsequence terms. As such, having adaptive variants of these algorithms, reducing\nthe number of sequence queries, becomes mandatory.A native adaptive variant of\nthe Scalar-FGLM algorithm was presented by its authors, the so-called Adaptive\nScalar-FGLM algorithm.In this paper, our first contribution is to make the\nBerlekamp--Massey--Sakata algorithm more efficient by making it adaptive to\navoid some useless relation test-ings. This variant allows us to divide by four\nin dimension 2 and by seven in dimension 3 the number of basic operations\nperformed on some sequence family.Then, we compare the two adaptive algorithms.\nWe show that their behaviors differ in a way that it is not possible to tweak\none of the algorithms in order to mimic exactly the behavior of the other. We\ndetail precisely the differences and the similarities of both algorithms and\nconclude that in general the Adaptive Scalar-FGLM algorithm needs fewer queries\nand performs fewer basic operations than the Adaptive Berlekamp--Massey--Sakata\nalgorithm.We also show that these variants are always more efficient than the\noriginal algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.00978v1"
    },
    {
        "title": "Machine Learning for Mathematical Software",
        "authors": [
            "M. England"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  While there has been some discussion on how Symbolic Computation could be\nused for AI there is little literature on applications in the other direction.\nHowever, recent results for quantifier elimination suggest that, given enough\nexample problems, there is scope for machine learning tools like Support Vector\nMachines to improve the performance of Computer Algebra Systems. We survey the\nauthors own work and similar applications for other mathematical software.\n  It may seem that the inherently probabilistic nature of machine learning\ntools would invalidate the exact results prized by mathematical software.\nHowever, algorithms and implementations often come with a range of choices\nwhich have no effect on the mathematical correctness of the end result but a\ngreat effect on the resources required to find it, and thus here, machine\nlearning can have a significant impact.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.10920v1"
    },
    {
        "title": "Non-linear Real Arithmetic Benchmarks derived from Automated Reasoning\n  in Economics",
        "authors": [
            "C. Mulligan",
            "R. Bradford",
            "J. H. Davenport",
            "M. England",
            "Z. Tonks"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We consider problems originating in economics that may be solved\nautomatically using mathematical software. We present and make freely available\na new benchmark set of such problems. The problems have been shown to fall\nwithin the framework of non-linear real arithmetic, and so are in theory\nsoluble via Quantifier Elimination (QE) technology as usually implemented in\ncomputer algebra systems. Further, they all can be phrased in prenex normal\nform with only existential quantifiers and so are also admissible to those\nSatisfiability Module Theory (SMT) solvers that support the QF_NRA. There is a\ngreat body of work considering QE and SMT application in science and\nengineering, but we demonstrate here that there is potential for this\ntechnology also in the social sciences.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.11447v1"
    },
    {
        "title": "Gr{ö}bner Basis over Semigroup Algebras: Algorithms and Applications\n  for Sparse Polynomial Systems",
        "authors": [
            "Matías Bender",
            "Jean-Charles Faugère",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Gr{\\\"o}bner bases is one the most powerful tools in algorithmic non-linear\nalgebra. Their computation is an intrinsically hard problem with a complexity\nat least single exponential in the number of variables. However, in most of the\ncases, the polynomial systems coming from applications have some kind of\nstructure. For example , several problems in computer-aided design, robotics,\nvision, biology , kinematics, cryptography, and optimization involve sparse\nsystems where the input polynomials have a few non-zero terms. Our approach to\nexploit sparsity is to embed the systems in a semigroup algebra and to compute\nGr{\\\"o}bner bases over this algebra. Up to now, the algorithms that follow this\napproach benefit from the sparsity only in the case where all the polynomials\nhave the same sparsity structure, that is the same Newton polytope. We\nintroduce the first algorithm that overcomes this restriction. Under regularity\nassumptions, it performs no redundant computations. Further, we extend this\nalgorithm to compute Gr{\\\"o}bner basis in the standard algebra and solve sparse\npolynomials systems over the torus $(C*)^n$. The complexity of the algorithm\ndepends on the Newton polytopes.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.00208v1"
    },
    {
        "title": "Identifying the Parametric Occurrence of Multiple Steady States for some\n  Biological Networks",
        "authors": [
            "R. Bradford",
            "J. H. Davenport",
            "M. England",
            "H. Errami",
            "V. Gerdt",
            "D. Grigoriev",
            "C. Hoyt",
            "M. Kosta",
            "O. Radulescu",
            "T. Sturm",
            "A. Weber"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We consider a problem from biological network analysis of determining regions\nin a parameter space over which there are multiple steady states for positive\nreal values of variables and parameters. We describe multiple approaches to\naddress the problem using tools from Symbolic Computation. We describe how\nprogress was made to achieve semi-algebraic descriptions of the\nmultistationarity regions of parameter space, and compare symbolic results to\nnumerical methods. The biological networks studied are models of the\nmitogen-activated protein kinases (MAPK) network which has already consumed\nconsiderable effort using special insights into its structure of corresponding\nmodels. Our main example is a model with 11 equations in 11 variables and 19\nparameters, 3 of which are of interest for symbolic treatment. The model also\nimposes positivity conditions on all variables and parameters.\n  We apply combinations of symbolic computation methods designed for mixed\nequality/inequality systems, specifically virtual substitution, lazy real\ntriangularization and cylindrical algebraic decomposition, as well as a\nsimplification technique adapted from Gaussian elimination and graph theory. We\nare able to determine multistationarity of our main example over a\n2-dimensional parameter space. We also study a second MAPK model and a symbolic\ngrid sampling technique which can locate such regions in 3-dimensional\nparameter space.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.04882v1"
    },
    {
        "title": "Automatic Generation of Moment-Based Invariants for Prob-Solvable Loops",
        "authors": [
            "Ezio Bartocci",
            "Laura Kovács",
            "Miroslav Stankovič"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  One of the main challenges in the analysis of probabilistic programs is to\ncompute invariant properties that summarise loop behaviours. Automation of\ninvariant generation is still at its infancy and most of the times targets only\nexpected values of the program variables, which is insufficient to recover the\nfull probabilistic program behaviour. We present a method to automatically\ngenerate moment-based invariants of a subclass of probabilistic programs,\ncalled Prob-Solvable loops, with polynomial assignments over random variables\nand parametrised distributions. We combine methods from symbolic summation and\nstatistics to derive invariants as valid properties over higher-order moments,\nsuch as expected values or variances, of program variables. We successfully\nevaluated our work on several examples where full automation for computing\nhigher-order moments and invariants over program variables was not yet\npossible.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02835v3"
    },
    {
        "title": "An Algorithmic Approach to Limit Cycles of Nonlinear Differential\n  Systems: the Averaging Method Revisited",
        "authors": [
            "Bo Huang",
            "Chee Yap"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  This paper introduces an algorithmic approach to the analysis of bifurcation\nof limit cycles from the centers of nonlinear continuous differential systems\nvia the averaging method. We develop three algorithms to implement the\naveraging method. The first algorithm allows to transform the considered\ndifferential systems to the normal formal of averaging. Here, we restricted the\nunperturbed term of the normal form of averaging to be identically zero. The\nsecond algorithm is used to derive the computational formulae of the averaged\nfunctions at any order. The third algorithm is based on the first two\nalgorithms that determines the exact expressions of the averaged functions for\nthe considered differential systems. The proposed approach is implemented in\nMaple and its effectiveness is shown by several examples. Moreover, we report\nsome incorrect results in published papers on the averaging method.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03315v1"
    },
    {
        "title": "Implementations of efficient univariate polynomial matrix algorithms and\n  application to bivariate resultants",
        "authors": [
            "Seung Gyu Hyun",
            "Vincent Neiger",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Complexity bounds for many problems on matrices with univariate polynomial\nentries have been improved in the last few years. Still, for most related\nalgorithms, efficient implementations are not available, which leaves open the\nquestion of the practical impact of these algorithms, e.g. on applications such\nas decoding some error-correcting codes and solving polynomial systems or\nstructured linear systems. In this paper, we discuss implementation aspects for\nmost fundamental operations: multiplication, truncated inversion, approximants,\ninterpolants, kernels, linear system solving, determinant, and basis reduction.\nWe focus on prime fields with a word-size modulus, relying on Shoup's C++\nlibrary NTL. Combining these new tools to implement variants of Villard's\nalgorithm for the resultant of generic bivariate polynomials (ISSAC 2018), we\nget better performance than the state of the art for large parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04356v1"
    },
    {
        "title": "Change of basis for m-primary ideals in one and two variables",
        "authors": [
            "Seung Gyu Hyun",
            "Stephen Melczer",
            "Éric Schost",
            "Catherine St-Pierre"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Following recent work by van der Hoeven and Lecerf (ISSAC 2017), we discuss\nthe complexity of linear mappings, called untangling and tangling by those\nauthors, that arise in the context of computations with univariate polynomials.\nWe give a slightly faster tangling algorithm and discuss new applications of\nthese techniques. We show how to extend these ideas to bivariate settings, and\nuse them to give bounds on the arithmetic complexity of certain algebras.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04614v1"
    },
    {
        "title": "Lonely Points in Simplices",
        "authors": [
            "Maximilian Jaroschek",
            "Manuel Kauers",
            "Laura Kovacs"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Given a lattice L in Z^m and a subset A of R^m, we say that a point in A is\nlonely if it is not equivalent modulo L to another point of A. We are\ninterested in identifying lonely points for specific choices of L when A is a\ndilated standard simplex, and in conditions on L which ensure that the number\nof lonely points is unbounded as the simplex dilation goes to infinity.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.08747v1"
    },
    {
        "title": "New ways to multiply 3 x 3-matrices",
        "authors": [
            "Marijn J. H. Heule",
            "Manuel Kauers",
            "Martina Seidl"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  It is known since the 1970s that no more than 23 multiplications are required\nfor computing the product of two 3 x 3-matrices. It is not known whether this\ncan also be done with fewer multiplications. However, there are several\nmutually inequivalent ways of doing the job with 23 multiplications. In this\narticle, we extend this list considerably by providing more than 13 000 new and\nmutually inequivalent schemes for multiplying 3 x 3-matrices using 23\nmultiplications. Moreover, we show that the set of all these schemes is a\nmanifold of dimension at least 17.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.10192v1"
    },
    {
        "title": "Factorizations for a Class of Multivariate Polynomial Matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Following the works by Lin et al. (Circuits Syst. Signal Process. 20(6):\n601-618, 2001) and Liu et al. (Circuits Syst. Signal Process. 30(3): 553-566,\n2011), we investigate how to factorize a class of multivariate polynomial\nmatrices. The main theorem in this paper shows that an $l\\times m$ polynomial\nmatrix admits a factorization with respect to a polynomial if the polynomial\nand all the $(l-1)\\times (l-1)$ reduced minors of the matrix generate the unit\nideal. This result is a further generalization of previous works, and based on\nthis, we give an algorithm which can be used to factorize more polonomial\nmatrices. In addition, an illustrate example is given to show that our main\ntheorem is non-trivial and valuable.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11872v1"
    },
    {
        "title": "Counting invariant subspaces and decompositions of additive polynomials",
        "authors": [
            "Joachim von zur Gathen",
            "Mark Giesbrecht",
            "Konstantin Ziegler"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The functional (de)composition of polynomials is a topic in pure and computer\nalgebra with many applications. The structure of decompositions of (suitably\nnormalized) polynomials f(x) = g(h(x)) in F[x] over a field F is well\nunderstood in many cases, but less well when the degree of f is divisible by\nthe positive characteristic p of F. This work investigates the decompositions\nof r-additive polynomials, where every exponent and also the field size is a\npower of r, which itself is a power of p.\n  The decompositions of an r-additive polynomial f are intimately linked to the\nFrobenius-invariant subspaces of its root space V in the algebraic closure of\nF. We present an efficient algorithm to compute the rational Jordan form of the\nFrobenius automorphism on V. A formula of Fripertinger (2011) then counts the\nnumber of Frobenius-invariant subspaces of a given dimension and we derive the\nnumber of decompositions with prescribed degrees.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.00212v2"
    },
    {
        "title": "Computing syzygies in finite dimension using fast linear algebra",
        "authors": [
            "Vincent Neiger",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We consider the computation of syzygies of multivariate polynomials in a\nfinite-dimensional setting: for a $\\mathbb{K}[X_1,\\dots,X_r]$-module\n$\\mathcal{M}$ of finite dimension $D$ as a $\\mathbb{K}$-vector space, and given\nelements $f_1,\\dots,f_m$ in $\\mathcal{M}$, the problem is to compute syzygies\nbetween the $f_i$'s, that is, polynomials $(p_1,\\dots,p_m)$ in\n$\\mathbb{K}[X_1,\\dots,X_r]^m$ such that $p_1 f_1 + \\dots + p_m f_m = 0$ in\n$\\mathcal{M}$. Assuming that the multiplication matrices of the $r$ variables\nwith respect to some basis of $\\mathcal{M}$ are known, we give an algorithm\nwhich computes the reduced Gr\\\"obner basis of the module of these syzygies, for\nany monomial order, using $O(m D^{\\omega-1} + r D^\\omega \\log(D))$ operations\nin the base field $\\mathbb{K}$, where $\\omega$ is the exponent of matrix\nmultiplication. Furthermore, assuming that $\\mathcal{M}$ is itself given as\n$\\mathcal{M} = \\mathbb{K}[X_1,\\dots,X_r]^n/\\mathcal{N}$, under some assumptions\non $\\mathcal{N}$ we show that these multiplication matrices can be computed\nfrom a Gr\\\"obner basis of $\\mathcal{N}$ within the same complexity bound. In\nparticular, taking $n=1$, $m=1$ and $f_1=1$ in $\\mathcal{M}$, this yields a\nchange of monomial order algorithm along the lines of the FGLM algorithm with a\ncomplexity bound which is sub-cubic in $D$.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01848v2"
    },
    {
        "title": "Sparse Interpolation With Errors in Chebyshev Basis Beyond\n  Redundant-Block Decoding",
        "authors": [
            "Erich L. Kaltofen",
            "Zhi-Hong Yang"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We present sparse interpolation algorithms for recovering a polynomial with\n$\\le B$ terms from $N$ evaluations at distinct values for the variable when\n$\\le E$ of the evaluations can be erroneous. Our algorithms perform exact\narithmetic in the field of scalars $\\mathsf{K}$ and the terms can be standard\npowers of the variable or Chebyshev polynomials, in which case the\ncharacteristic of $\\mathsf{K}$ is $\\ne 2$. Our algorithms return a list of\nvalid sparse interpolants for the $N$ support points and run in\npolynomial-time. For standard power basis our algorithms sample at $N = \\lfloor\n\\frac{4}{3} E + 2 \\rfloor B$ points, which are fewer points than $N = 2(E+1)B -\n1$ given by Kaltofen and Pernet in 2014. For Chebyshev basis our algorithms\nsample at $N = \\lfloor \\frac{3}{2} E + 2 \\rfloor B$ points, which are also\nfewer than the number of points required by the algorithm given by Arnold and\nKaltofen in 2015, which has $N = 74 \\lfloor \\frac{E}{13} + 1 \\rfloor$ for $B =\n3$ and $E \\ge 222$. Our method shows how to correct $2$ errors in a block of\n$4B$ points for standard basis and how to correct $1$ error in a block of $3B$\npoints for Chebyshev Basis.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05719v5"
    },
    {
        "title": "Evaluation of Chebyshev polynomials on intervals and application to root\n  finding",
        "authors": [
            "Viviane Ledoux",
            "Guillaume Moroz"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In approximation theory, it is standard to approximate functions by\npolynomials expressed in the Chebyshev basis. Evaluating a polynomial $f$ of\ndegree n given in the Chebyshev basis can be done in $O(n)$ arithmetic\noperations using the Clenshaw algorithm. Unfortunately, the evaluation of $f$\non an interval $I$ using the Clenshaw algorithm with interval arithmetic\nreturns an interval of width exponential in $n$. We describe a variant of the\nClenshaw algorithm based on ball arithmetic that returns an interval of width\nquadratic in $n$ for an interval of small enough width. As an application, our\nvariant of the Clenshaw algorithm can be used to design an efficient root\nfinding algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05843v1"
    },
    {
        "title": "Towards identification of explicit solutions to overdetermined systems\n  of differential equations",
        "authors": [
            "Maxim Zaytsev",
            "V'yacheslav Akkerman"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The authors proposed a general way to find particular solutions for\noverdetermined systems of PDEs previously, where the number of equations is\ngreater than the number of unknown functions. In this paper, we propose an\nalgorithm for finding solutions for overdetermined PDE systems, where we use a\nmethod for finding an explicit solution for overdetermined algebraic\n(polynomial) equations. Using this algorithm, the solution of some\noverdetermined PDE systems can be obtained in explicit form. The main\ndifficulty of this algorithm is the huge number of polynomial equations that\narise, which need to be investigated and solved numerically or explicitly. For\nexample, the overdetermined hydrodynamic equations obtained earlier by the\nauthors give a minimum of 10 million such equations. However, if they are\nsolved explicitly, then we can write out the solution of the hydrodynamic\nequations in a general form, which is of great scientific interest.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.12126v1"
    },
    {
        "title": "Differentiable Set Operations for Algebraic Expressions",
        "authors": [
            "Jasdeep Singh Grover"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Basic principles of set theory have been applied in the context of\nprobability and binary computation. Applying the same principles on\ninequalities is less common but can be extremely beneficial in a variety of\nfields. This paper formulates a novel approach to directly apply set operations\non inequalities to produce resultant inequalities with differentiable\nboundaries. The suggested approach uses inequalities of the form Ei:\nfi(x1,x2,..,xn) and an expression of set operations in terms of Ei like, (E1\nand E2) or E3, or can be in any standard form like the Conjunctive Normal Form\n(CNF) to produce an inequality F(x1,x2,..,xn)<=1 which represents the resulting\nbounded region from the expressions and has a differentiable boundary. To\nensure differentiability of the solution, a trade-off between representation\naccuracy and curvature at borders (especially corners) is made. A set of\nparameters is introduced which can be fine-tuned to improve the accuracy of\nthis approach. The various applications of the suggested approach have also\nbeen discussed which range from computer graphics to modern machine learning\nsystems to fascinating demonstrations for educational purposes (current use). A\npython script to parse such expressions is also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.12181v1"
    },
    {
        "title": "A Condition for Multiplicity Structure of Univariate Polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We consider the problem of finding a condition for a univariate polynomial\nhaving a given multiplicity structure when the number of distinct roots is\ngiven. It is well known that such conditions can be written as conjunctions of\nseveral polynomial equations and one inequation in the coefficients, by using\nrepeated parametric gcd's. In this paper, we give a novel condition which is\nnot based on repeated gcd's. Furthermore, it is shown that the number of\npolynomials in the condition is optimal and the degree of polynomials is\nsmaller than that in the previous condition based on repeated gcd's.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.02388v2"
    },
    {
        "title": "On fast multiplication of a matrix by its transpose",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clement Pernet",
            "Alexandre Sedoglavic"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We present a non-commutative algorithm for the multiplication of a\n2x2-block-matrix by its transpose using 5 block products (3 recursive calls and\n2 general products) over C or any finite field.We use geometric considerations\non the space of bilinear forms describing 2x2 matrix products to obtain this\nalgorithm and we show how to reduce the number of involved additions.The\nresulting algorithm for arbitrary dimensions is a reduction of multiplication\nof a matrix by its transpose to general matrix product, improving by a constant\nfactor previously known reductions.Finally we propose schedules with low memory\nfootprint that support a fast and memory efficient practical implementation\nover a finite field.To conclude, we show how to use our result in LDLT\nfactorization.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.04109v4"
    },
    {
        "title": "On mu-Symmetric Polynomials",
        "authors": [
            "Jing Yang",
            "Chee K. Yap"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  In this paper, we study functions of the roots of a univariate polynomial in\nwhich the roots have a given multiplicity structure $\\mu$. Traditionally, root\nfunctions are studied via the theory of symmetric polynomials; we extend this\ntheory to $\\mu$-symmetric polynomials. We were motivated by a conjecture from\nBecker et al.~(ISSAC 2016) about the $\\mu$-symmetry of a particular root\nfunction $D^+(\\mu)$, called D-plus. To investigate this conjecture, it was\ndesirable to have fast algorithms for checking if a given root function is\n$\\mu$-symmetric. We designed three such algorithms: one based on Gr\\\"{o}bner\nbases, another based on preprocessing and reduction, and the third based on\nsolving linear equations. We implemented them in Maple and experiments show\nthat the latter two algorithms are significantly faster than the first.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.07403v1"
    },
    {
        "title": "Rational Solutions of First Order Algebraic Ordinary Differential\n  Equations",
        "authors": [
            "Ruyong Feng",
            "Shuang Feng"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Let $f(t, y,y')=\\sum_{i=0}^d a_i(t, y)y'^i=0$ be a first order ordinary\ndifferential equation with polynomial coefficients. Eremenko in 1999 proved\nthat there exists a constant $C$ such that every rational solution of $f(t,\ny,y')=0$ is of degree not greater than $C$. Examples show that this degree\nbound $C$ depends not only on the degrees of $f$ in $t,y,y'$ but also on the\ncoefficients of $f$ viewed as polynomial in $t,y,y'$. In this paper, we show\nthat if $$\\max_{i=0}^d \\{{\\rm deg}(a_i,y)-2(d-i)\\}>0 $$ then the degree bound\n$C$ only depends on the degrees of $f$, and furthermore we present an explicit\nexpression for $C$ in terms of the degrees of $f$.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01289v1"
    },
    {
        "title": "On Rational and Hypergeometric Solutions of Linear Ordinary Difference\n  Equations in $Π\\mathbfΣ^*$-field extensions",
        "authors": [
            "Sergei A. Abramov",
            "Manuel Bronstein",
            "Marko Petkovšek",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We present a complete algorithm that computes all hypergeometric solutions of\nhomogeneous linear difference equations and rational solutions of parameterized\nlinear difference equations in the setting of $\\Pi\\Sigma^*$-fields. More\ngenerally, we provide a flexible framework for a big class of difference fields\nthat is built by a tower of $\\Pi\\Sigma^*$-field extensions over a difference\nfield that satisfies certain algorithmic properties. As a consequence one can\ncompute all solutions in terms of indefinite nested sums and products that\narise within the components of a parameterized linear difference equation, and\none can find all hypergeometric solutions that are defined over the arising\nsums and products of a homogeneous linear difference equation.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.04944v2"
    },
    {
        "title": "Generalizing The Davenport-Mahler-Mignotte Bound -- The Weighted Case",
        "authors": [
            "Vikram Sharma"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Root separation bounds play an important role as a complexity measure in\nunderstanding the behaviour of various algorithms in computational algebra,\ne.g., root isolation algorithms. A classic result in the univariate setting is\nthe Davenport-Mahler-Mignotte (DMM) bound. One way to state the bound is to\nconsider a directed acyclic graph $(V,E)$ on a subset of roots of a degree $d$\npolynomial $f(z) \\in \\mathbb{C}[z]$, where the edges point from a root of\nsmaller absolute value to one of larger absolute, and the in-degrees of all\nvertices is at most one. Then the DMM bound is an amortized lower bound on the\nfollowing product: $\\prod_{(\\alpha,\\beta) \\in E}|\\alpha-\\beta|$. However, the\nlower bound involves the discriminant of the polynomial $f$, and becomes\ntrivial if the polynomial is not square-free. This was resolved by Eigenwillig,\n(2008), by using a suitable subdiscriminant instead of the discriminant.\nEscorcielo-Perrucci, 2016, further dropped the in-degree constraint on the\ngraph by using the theory of finite differences. Emiris et al., 2019, have\ngeneralized their result to handle the case where the exponent of the term\n$|\\alpha-\\beta|$ in the product is at most the multiplicity of either of the\nroots. In this paper, we generalize these results by allowing arbitrary\npositive integer weights on the edges of the graph, i.e., for a weight function\n$w: E \\rightarrow \\mathbb{Z}_{>0}$, we derive an amortized lower bound on\n$\\prod_{(\\alpha,\\beta) \\in E}|\\alpha-\\beta|^{w(\\alpha,\\beta)}$. Such a product\noccurs in the complexity estimates of some recent algorithms for root\nclustering (e.g., Becker et al., 2016), where the weights are usually some\nfunction of the multiplicity of the roots. Because of its amortized nature, our\nbound is arguably better than the bounds obtained by manipulating existing\nresults to accommodate the weights.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07843v1"
    },
    {
        "title": "On Kahan's Rules for Determining Branch Cuts",
        "authors": [
            "Frédéric Chyzak",
            "James Davenport",
            "Christoph Koutschan",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  In computer algebra there are different ways of approaching the mathematical\nconcept of functions, one of which is by defining them as solutions of\ndifferential equations. We compare different such approaches and discuss the\noccurring problems. The main focus is on the question of determining possible\nbranch cuts. We explore the extent to which the treatment of branch cuts can be\nrendered (more) algorithmic, by adapting Kahan's rules to the differential\nequation setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.2809v2"
    },
    {
        "title": "Computing the Hermite Form of a Matrix of Ore Polynomials",
        "authors": [
            "Mark Giesbrecht",
            "Myung Sub Kim"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  Let R=F[D;sigma,delta] be the ring of Ore polynomials over a field (or skew\nfield) F, where sigma is a automorphism of F and delta is a sigma-derivation.\nGiven a an m by n matrix A over R, we show how to compute the Hermite form H of\nA and a unimodular matrix U such that UA=H. The algorithm requires a polynomial\nnumber of operations in F in terms of both the dimensions m and n, and the\ndegree of the entries in A. When F=k(z) for some field k, it also requires time\npolynomial in the degree in z, and if k is the rational numbers Q, it requires\ntime polynomial in the bit length of the coefficients as well. Explicit\nanalyses are provided for the complexity, in particular for the important cases\nof differential and shift polynomials over Q(z). To accomplish our algorithm,\nwe apply the Dieudonne determinant and quasideterminant theory for Ore\npolynomial rings to get explicit bounds on the degrees and sizes of entries in\nH and U.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.3656v3"
    },
    {
        "title": "On the complexity of computing with zero-dimensional triangular sets",
        "authors": [
            "Adrien Poteaux",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We study the complexity of some fundamental operations for triangular sets in\ndimension zero. Using Las-Vegas algorithms, we prove that one can perform such\noperations as change of order, equiprojectable decomposition, or quasi-inverse\ncomputation with a cost that is essentially that of modular composition. Over\nan abstract field, this leads to a subquadratic cost (with respect to the\ndegree of the underlying algebraic set). Over a finite field, in a boolean RAM\nmodel, we obtain a quasi-linear running time using Kedlaya and Umans' algorithm\nfor modular composition. Conversely, we also show how to reduce the problem of\nmodular composition to change of order for triangular sets, so that all these\nproblems are essentially equivalent. Our algorithms are implemented in Maple;\nwe present some experimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.4323v1"
    },
    {
        "title": "A Note on the Space Complexity of Fast D-Finite Function Evaluation",
        "authors": [
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We state and analyze a generalization of the \"truncation trick\" suggested by\nGourdon and Sebah to improve the performance of power series evaluation by\nbinary splitting. It follows from our analysis that the values of D-finite\nfunctions (i.e., functions described as solutions of linear differential\nequations with polynomial coefficients) may be computed with error bounded by\n2^(-p) in time O(p*(lg p)^(3+o(1))) and space O(p). The standard fast algorithm\nfor this task, due to Chudnovsky and Chudnovsky, achieves the same time\ncomplexity bound but requires \\Theta(p*lg p) bits of memory.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5097v1"
    },
    {
        "title": "Formal Solutions of Completely Integrable Pfaffian Systems With Normal\n  Crossings",
        "authors": [
            "Moulay A. Barkatou",
            "Maximilian Jaroschek",
            "Suzy S. Maddah"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  In this paper, we present an algorithm for computing a fundamental matrix of\nformal solutions of completely integrable Pfaffian systems with normal\ncrossings in several variables. This algorithm is a generalization of a method\ndeveloped for the bivariate case based on a combination of several reduction\ntechniques and is implemented in the computer algebra system Maple.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.00180v3"
    },
    {
        "title": "Improved Polynomial Remainder Sequences for Ore Polynomials",
        "authors": [
            "Maximilian Jaroschek"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Polynomial remainder sequences contain the intermediate results of the\nEuclidean algorithm when applied to (non-)commutative polynomials. The running\ntime of the algorithm is dependent on the size of the coefficients of the\nremainders. Different ways have been studied to make these as small as\npossible. The subresultant sequence of two polynomials is a polynomial\nremainder sequence in which the size of the coefficients is optimal in the\ngeneric case, but when taking the input from applications, the coefficients are\noften larger than necessary. We generalize two improvements of the subresultant\nsequence to Ore polynomials and derive a new bound for the minimal coefficient\nsize. Our approach also yields a new proof for the results in the commutative\ncase, providing a new point of view on the origin of the extraneous factors of\nthe coefficients.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.01128v1"
    },
    {
        "title": "On the robust hardness of Gröbner basis computation",
        "authors": [
            "Gwen Spencer",
            "David Rolnick"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  The computation of Gr\\\"obner bases is an established hard problem. By\ncontrast with many other problems, however, there has been little investigation\nof whether this hardness is robust. In this paper, we frame and present results\non the problem of approximate computation of Gr\\\"obner bases. We show that it\nis NP-hard to construct a Gr\\\"obner basis of the ideal generated by a set of\npolynomials, even when the algorithm is allowed to discard a $(1 - \\epsilon)$\nfraction of the generators, and likewise when the algorithm is allowed to\ndiscard variables (and the generators containing them). Our results shows that\ncomputation of Gr\\\"obner bases is robustly hard even for simple polynomial\nsystems (e.g. maximum degree 2, with at most 3 variables per generator). We\nconclude by greatly strengthening results for the Strong $c$-Partial Gr\\\"obner\nproblem posed by De Loera et al. Our proofs also establish interesting\nconnections between the robust hardness of Gr\\\"obner bases and that of SAT\nvariants and graph-coloring.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.06436v3"
    },
    {
        "title": "Contraction of Ore Ideals with Applications",
        "authors": [
            "Yi Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Ore operators form a common algebraic abstraction of linear ordinary\ndifferential and recurrence equations. Given an Ore operator $L$ with\npolynomial coefficients in $x$, it generates a left ideal $I$ in the Ore\nalgebra over the field $\\mathbf{k}(x)$ of rational functions. We present an\nalgorithm for computing a basis of the contraction ideal of $I$ in the Ore\nalgebra over the ring $R[x]$ of polynomials, where $R$ may be either\n$\\mathbf{k}$ or a domain with $\\mathbf{k}$ as its fraction field. This\nalgorithm is based on recent work on desingularization for Ore operators by\nChen, Jaroschek, Kauers and Singer. Using a basis of the contraction ideal, we\ncompute a completely desingularized operator for $L$ whose leading coefficient\nnot only has minimal degree in $x$ but also has minimal content. Completely\ndesingularized operators have interesting applications such as certifying\ninteger sequences and checking special cases of a conjecture of Krattenthaler.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.07922v8"
    },
    {
        "title": "Probabilistic Analysis of Block Wiedemann for Leading Invariant Factors",
        "authors": [
            "Gavin Harrison",
            "Jeremy Johnson",
            "B. David Saunders"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We determine the probability, structure dependent, that the block Wiedemann\nalgorithm correctly computes leading invariant factors. This leads to a tight\nlower bound for the probability, structure independent. We show, using block\nsize slightly larger than $r$, that the leading $r$ invariant factors are\ncomputed correctly with high probability over any field. Moreover, an algorithm\nis provided to compute the probability bound for a given matrix size and thus\nto select the block size needed to obtain the desired probability. The worst\ncase probability bound is improved, post hoc, by incorporating the partial\ninformation about the invariant factors.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.03864v1"
    },
    {
        "title": "Solving First Order Autonomous Algebraic Ordinary Differential Equations\n  by Places",
        "authors": [
            "Sebastian Falkensteiner",
            "J. Rafael Sendra"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Given a first-order autonomous algebraic ordinary differential equation, we\npresent a method for computing formal power series solutions by means of\nplaces. We provide an algorithm for computing a full characterization of\npossible initial values, classified in terms of the number of distinct formal\npower series solutions extending them. In addition, if a particular initial\nvalue is given, we present a second algorithm that computes all the formal\npower series solutions, up to a suitable degree, corresponding to it.\nFurthermore, when the ground field is the field of the complex numbers, we\nprove that the computed formal power series solutions are all convergent in\nsuitable neighborhoods.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.04731v2"
    },
    {
        "title": "Convolutions of Liouvillian Sequences",
        "authors": [
            "Sergei A. Abramov",
            "Marko Petkovšek",
            "Helena Zakrajšek"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  While Liouvillian sequences are closed under many operations, simple examples\nshow that they are not closed under convolution, and the same goes for\nd'Alembertian sequences. Nevertheless, we show that d'Alembertian sequences are\nclosed under convolution with rationally d'Alembertian sequences, and that\nLiouvillian sequences are closed under convolution with rationally Liouvillian\nsequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.08747v1"
    },
    {
        "title": "On Existence and Uniqueness of Formal Power Series Solutions of\n  Algebraic Ordinary Differential Equations",
        "authors": [
            "Sebastian Falkensteiner",
            "Yi Zhang",
            "Thieu N. Vo"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Given an algebraic ordinary differential equation (AODE), we propose a\ncomputational method to determine when a truncated power series can be extended\nto a formal power series solution. If a certain regularity condition on the\ngiven AODE or on the initial values is fulfilled, we compute all of the\nsolutions. Moreover, when the existence is confirmed, we present the algebraic\nstructure of the set of all formal power series solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.09646v3"
    },
    {
        "title": "Multiplying boolean Polynomials with Frobenius Partitions in Additive\n  Fast Fourier Transform",
        "authors": [
            "Ming-Shing Chen",
            "Chen-Mou Cheng",
            "Po-Chun Kuo",
            "Wen-Ding Li",
            "Bo-Yin Yang"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We show a new algorithm and its implementation for multiplying\nbit-polynomials of large degrees. The algorithm is based on evaluating\npolynomials at a specific set comprising a natural set for evaluation with\nadditive FFT and a high order element under Frobenius map of $\\mathbb{F}_{2}$.\nWith the high order element, we can derive more values of the polynomials under\nFrobenius map. Besides, we also adapt the additive FFT to efficiently evaluate\npolynomials at the set with an encoding process.\n  For the implementation, we reorder the computations in the additive FFT for\nreducing the number of memory writes and hiding the latency for reads. The\nalgebraic operations, including field multiplication, bit-matrix transpose, and\nbit-matrix multiplication, are implemented with efficient SIMD instructions. As\na result, we effect a software of best known efficiency, shown in our\nexperiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.11301v1"
    },
    {
        "title": "Verification Protocols with Sub-Linear Communication for Polynomial\n  Matrix Operations",
        "authors": [
            "David Lucas",
            "Vincent Neiger",
            "Clément Pernet",
            "Daniel S. Roche",
            "Johan Rosenkilde"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We design and analyze new protocols to verify the correctness of various\ncomputations on matrices over the ring F[x] of univariate polynomials over a\nfield F. For the sake of efficiency, and because many of the properties we\nverify are specific to matrices over a principal ideal domain, we cannot simply\nrely on previously-developed linear algebra protocols for matrices over a\nfield. Our protocols are interactive, often randomized, and feature a constant\nnumber of rounds of communication between the Prover and Verifier. We seek to\nminimize the communication cost so that the amount of data sent during the\nprotocol is significantly smaller than the size of the result being verified,\nwhich can be useful when combining protocols or in some multi-party settings.\nThe main tools we use are reductions to existing linear algebra verification\nprotocols and a new protocol to verify that a given vector is in the F[x]-row\nspace of a given matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.01272v2"
    },
    {
        "title": "What Can (and Can't) we Do with Sparse Polynomials?",
        "authors": [
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Simply put, a sparse polynomial is one whose zero coefficients are not\nexplicitly stored. Such objects are ubiquitous in exact computing, and so\nnaturally we would like to have efficient algorithms to handle them. However,\nwith this compact storage comes new algorithmic challenges, as fast algorithms\nfor dense polynomials may no longer be efficient. In this tutorial we examine\nthe state of the art for sparse polynomial algorithms in three areas:\narithmetic, interpolation, and factorization. The aim is to highlight recent\nprogress both in theory and in practice, as well as opportunities for future\nwork.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.08289v1"
    },
    {
        "title": "Tropical Differential Groebner Basis",
        "authors": [
            "Youren Hu",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In this paper, the tropical differential Gr\\\"obner basis is studied, which is\na natural generalization of the tropical Gr\\\"obner basis to the recently\nintroduced tropical differential algebra. Like the differential Gr\\\"obner\nbasis, the tropical differential Gr\\\"obner basis generally contains an infinite\nnumber of elements. We give a Buchberger style criterion for the tropical\ndifferential Gr\\\"obner basis. For ideals generated by homogeneous linear\ndifferential polynomials with constant coefficients, we give a complete\nalgorithm to compute the tropical differential Gr\\\"obner basis.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.02275v1"
    },
    {
        "title": "Asymptotic Solutions of Polynomial Equations with Exp-Log Coefficients",
        "authors": [
            "Adam Strzeboński"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We present an algorithm for computing asymptotic approximations of roots of\npolynomials with exp-log function coefficients. The real and imaginary parts of\nthe approximations are given as explicit exp-log expressions. We provide a\nmethod for deciding which approximations correspond to real roots. We report on\nimplementation of the algorithm and present empirical data.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.06796v1"
    },
    {
        "title": "Computing the volume of compact semi-algebraic sets",
        "authors": [
            "Pierre Lairez",
            "Marc Mezzarobba",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Let $S\\subset R^n$ be a compact basic semi-algebraic set defined as the real\nsolution set of multivariate polynomial inequalities with rational\ncoefficients. We design an algorithm which takes as input a polynomial system\ndefining $S$ and an integer $p\\geq 0$ and returns the $n$-dimensional volume of\n$S$ at absolute precision $2^{-p}$.Our algorithm relies on the relationship\nbetween volumes of semi-algebraic sets and periods of rational integrals. It\nmakes use of algorithms computing the Picard-Fuchs differential equation of\nappropriate periods, properties of critical points, and high-precision\nnumerical integration of differential equations.The algorithm runs in\nessentially linear time with respect to~$p$. This improves upon the previous\nexponential bounds obtained by Monte-Carlo or moment-based methods. Assuming a\nconjecture of Dimca, the arithmetic cost of the algebraic subroutines for\ncomputing Picard-Fuchs equations and critical points is singly exponential in\n$n$ and polynomial in the maximum degree of the input.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11705v1"
    },
    {
        "title": "Gröbner Bases with Reduction Machines",
        "authors": [
            "Georgiana Şurlea",
            "Adrian Crăciun"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In this paper, we make a contribution to the computation of Gr\\\"obner bases.\nFor polynomial reduction, instead of choosing the leading monomial of a\npolynomial as the monomial with respect to which the reduction process is\ncarried out, we investigate what happens if we make that choice arbitrarily. It\nturns out not only this is possible (the fact that this produces a normal form\nbeing already known in the literature), but, for a fixed choice of reductors,\nthe obtained normal form is the same no matter the order in which we reduce the\nmonomials. To prove this, we introduce reduction machines, which work by\nreducing each monomial independently and then collecting the result. We show\nthat such a machine can simulate any such reduction. We then discuss different\nimplementations of these machines. Some of these implementations address\ninherent inefficiencies in reduction machines (repeating the same\ncomputations). We describe a first implementation and look at some experimental\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01746v1"
    },
    {
        "title": "Elimination-based certificates for triangular equivalence and rank\n  profiles",
        "authors": [
            "Jean-Guillaume Dumas",
            "Erich Kaltofen",
            "David Lucas",
            "Clément Pernet"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In this paper, we give novel certificates for triangular equivalence and rank\nprofiles. These certificates enable somebody to verify the row or column rank\nprofiles or the whole rank profile matrix faster than recomputing them, with a\nnegligible overall overhead. We first provide quadratic time and space\nnon-interactive certificates saving the logarithmic factors of previously known\nones. Then we propose interactive certificates for the same problems whose\nMonte Carlo verification complexity requires a small constant number of\nmatrix-vector multiplications, a linear space, and a linear number of extra\nfield operations , with a linear number of interactions. As an application we\nalso give an interactive protocol, certifying the determinant or the signature\nof dense matrices, faster for the Prover than the best previously known one.\nFinally we give linear space and constant round certificates for the row or\ncolumn rank profiles.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.05692v1"
    },
    {
        "title": "Fast Derivatives for Multilinear Polynomials",
        "authors": [
            "Valeri Aronov"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The article considers linear functions of many (n) variables - multilinear\npolynomials (MP). The three-steps evaluation is presented that uses the minimal\npossible number of floating point operations for non-sparse MP at each step.\nThe minimal number of additions is achieved in the algorithm for fast MP\nderivatives (FMPD) calculation. The cost of evaluating all first derivatives\napproaches to only 1/8 of MP evaluation with a growing number of variables. The\nFMPD algorithm structure exhibits similarity to the Fast Fourier Transformation\n(FFT) algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.02235v2"
    },
    {
        "title": "Entropy supplementary conservation law for non-linear systems of PDEs\n  with non-conservative terms: application to the modelling and analysis of\n  complex fluid flows using computer algebra",
        "authors": [
            "Pierre Cordesse",
            "Marc Massot"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In the present contribution, we investigate first-order nonlinear systems of\npartial differential equations which are constituted of two parts: a system of\nconservation laws and non-conservative first order terms. Whereas the theory of\nfirst-order systems of conservation laws is well established and the conditions\nfor the existence of supplementary conservation laws, and more specifically of\nan entropy supplementary conservation law for smooth solutions, well known,\nthere exists so far no general extension to obtain such supplementary\nconservation laws when non-conservative terms are present. We propose a\nframework in order to extend the existing theory and show that the presence of\nnon-conservative terms somewhat complexifies the problem since numerous\ncombinations of the conservative and non-conservative terms can lead to a\nsupplementary conservation law. We then identify a restricted framework in\norder to design and analyze physical models of complex fluid flows by means of\ncomputer algebra and thus obtain the entire ensemble of possible combination of\nconservative and non-conservative terms with the objective of obtaining\nspecifically an entropy supplementary conservation law. The theory as well as\ndeveloped computer algebra tool are then applied to a Baer-Nunziato two-phase\nflow model and to a multicomponent plasma fluid model. The first one is a\nfirst-order fluid model, with non-conservative terms impacting on the linearly\ndegenerate field and requires a closure since there is no way to derive\ninterfacial quantities from averaging principles and we need guidance in order\nto close the pressure and velocity of the interface and the thermodynamics of\nthe mixture. The second one involves first order terms for the heavy species\ncoupled to second order terms for the electrons, the non-conservative terms\nimpact the genuinely nonlinear fields and the model can be rigorously derived\nfrom kinetic theory. We show how the theory allows to recover the whole\nspectrum of closures obtained so far in the literature for the two-phase flow\nsystem as well as conditions when one aims at extending the thermodynamics and\nalso applies to the plasma case, where we recover the usual entropy\nsupplementary equation, thus assessing the effectiveness and scope of the\nproposed theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.02313v1"
    },
    {
        "title": "Minimal representations and algebraic relations for single nested\n  products",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Recently, it has been shown constructively how a finite set of hypergeometric\nproducts, multibasic hypergeometric products or their mixed versions can be\nmodeled properly in the setting of formal difference rings. Here special\nemphasis is put on robust constructions: whenever further products have to be\nconsidered, one can reuse --up to some mild modifications-- the already\nexisting difference ring. In this article we relax this robustness criteria and\nseek for another form of optimality. We will elaborate a general framework to\nrepresent a finite set of products in a formal difference ring where the number\nof transcendental product generators is minimal. As a bonus we are able to\ndescribe explicitly all relations among the given input products.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.04837v1"
    },
    {
        "title": "A Root-Free Splitting-Lemma for Systems of Linear Differential Equations",
        "authors": [
            "Eckhard Pflügel"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We consider the formal reduction of a system of linear differential equations\nand show that, if the system can be block-diagonalised through transformation\nwith a ramified Shearing-transformation and following application of the\nSplitting Lemma, and if the spectra of the leading block matrices of the\nramified system satisfy a symmetry condition, this block-diagonalisation can\nalso be achieved through an unramified transformation. Combined with classical\nresults by Turritin and Wasow as well as work by Balser, this yields a\nconstructive and simple proof of the existence of an unramified block-diagonal\nform from which formal invariants such as the Newton polygon can be read\ndirectly. Our result is particularly useful for designing efficient algorithms\nfor the formal reduction of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05837v1"
    },
    {
        "title": "Chain Rules for Hessian and Higher Derivatives Made Easy by Tensor\n  Calculus",
        "authors": [
            "Maciej Skorski"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Computing multivariate derivatives of matrix-like expressions in the compact,\ncoordinate free fashion is very important for both theory and applied\ncomputations (e.g. optimization and machine learning).\n  The critical components of such computations are \\emph{chain and product\nrules} for derivatives. Although they are taught early in simple scenarios,\npractical applications involve high-dimensional arrays; in this context it is\nvery hard to find easy accessible and compact explanation.\n  This paper discusses how to relatively simply carry such derivations based on\nthe (simplified as adapted in applied computer science) concept of tensors.\nNumerical examples in modern Python libraries are provided. This discussion\nsimplifies and illustrates an earlier exposition by Manton (2012).\n",
        "pdf_link": "http://arxiv.org/pdf/1911.13292v1"
    },
    {
        "title": "On the Complexity of Solving Generic Over-determined Bilinear Systems",
        "authors": [
            "John B. Baena",
            "Daniel Cabarcas",
            "Javier Verbel"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  In this paper, we study the complexity of solving generic over-determined\nbilinear systems over a finite field $\\mathbb{F}$. Given a generic bilinear\nsequence $B \\in \\mathbb{F}[\\mathbf{x},\\mathbf{y}]$, with respect to a partition\nof variables $\\mathbf{x}$, $\\mathbf{y}$, we show that, the solutions of the\nsystem $B= \\mathbf{0}$ can be efficiently found on the\n$\\mathbb{F}[\\mathbf{y}]$-module generated by $B$. Following this observation,\nwe propose three variations of Gr\\\"obner basis algorithms, that only involve\nmultiplication by monomials in they-variables, namely, $\\mathbf{y}$-XL, based\non the XL algorithm, $\\mathbf{y}$-MLX, based on the mutant XL algorithm, and\n$\\mathbf{y}$-HXL, basedon a hybrid approach. We define notions of regularity\nfor over-determined bilinear systems,that capture the idea of genericity, and\nwe develop the necessary theoretical tools to estimate the complexity of the\nalgorithms for such sequences. We also present extensive experimental results,\ntesting our conjecture, verifying our results, and comparing the complexity of\nthe various methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.09442v1"
    },
    {
        "title": "A Generic and Executable Formalization of Signature-Based Gröbner\n  Basis Algorithms",
        "authors": [
            "Alexander Maletzky"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We present a generic and executable formalization of signature-based\nalgorithms (such as Faug\\`ere's $F_5$) for computing Gr\\\"obner bases, as well\nas their mathematical background, in the Isabelle/HOL proof assistant. Said\nalgorithms are currently the best known algorithms for computing Gr\\\"obner\nbases in terms of computational efficiency. The formal development attempts to\nbe as generic as possible, generalizing most known variants of signature-based\nalgorithms, but at the same time the implemented functions are effectively\nexecutable on concrete input for efficiently computing mechanically verified\nGr\\\"obner bases. Besides correctness the formalization also proves that under\ncertain conditions the algorithms a-priori detect and avoid all useless\nreductions to zero, and return minimal signature Gr\\\"obner bases.\n  To the best of our knowledge, the formalization presented here is the only\nformalization of signature-based Gr\\\"obner basis algorithms in existence so\nfar.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.02239v1"
    },
    {
        "title": "Fast Computation of the $N$-th Term of a $q$-Holonomic Sequence and\n  Applications",
        "authors": [
            "Alin Bostan",
            "Sergey Yurkevich"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  In 1977, Strassen invented a famous baby-step/giant-step algorithm that\ncomputes the factorial $N!$ in arithmetic complexity quasi-linear in\n$\\sqrt{N}$. In 1988, the Chudnovsky brothers generalized Strassen's algorithm\nto the computation of the $N$-th term of any holonomic sequence in essentially\nthe same arithmetic complexity. We design $q$-analogues of these algorithms. We\nfirst extend Strassen's algorithm to the computation of the $q$-factorial of\n$N$, then Chudnovskys' algorithm to the computation of the $N$-th term of any\n$q$-holonomic sequence. Both algorithms work in arithmetic complexity\nquasi-linear in $\\sqrt{N}$; surprisingly, they are simpler than their analogues\nin the holonomic case. We provide a detailed cost analysis, in both arithmetic\nand bit complexity models. Moreover, we describe various algorithmic\nconsequences, including the acceleration of polynomial and rational solving of\nlinear $q$-differential equations, and the fast evaluation of large classes of\npolynomials, including a family recently considered by Nogneng and Schost.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.08656v1"
    },
    {
        "title": "SymFields: An Open Source Symbolic Fields Analysis Tool for General\n  Curvilinear Coordinates in Python",
        "authors": [
            "Nan Chu"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  An open source symbolic tool for vector fields analysis 'SymFields' is\ndeveloped in Python. The SymFields module is constructed upon Python symbolic\nmodule sympy, which could only conduct scaler field analysis. With SymFields\nmodule, you can conduct vector analysis for general curvilinear coordinates\nregardless whether it is orthogonal or not. In SymFields, the differential\noperators based on metric tensor are normalized to real physical values, which\nmeans your can use real physical value of the vector fields as inputs. This\ncould greatly free the physicists from the tedious calculation under\ncomplicated coordinates.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10723v1"
    },
    {
        "title": "Notes on Computational Graph and Jacobian Accumulation",
        "authors": [
            "Yichong Zhou"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  The optimal calculation order of a computational graph can be represented by\na set of algebraic expressions. Computational graph and algebraic expression\nboth have close relations and significant differences, this paper looks into\nthese relations and differences, making plain their interconvertibility. By\nrevealing different types of multiplication relations in algebraic expressions\nand their elimination dependencies in line-graph, we establish a theoretical\nlimit on the efficiency of face elimination.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.15034v1"
    },
    {
        "title": "Choosing the Variable Ordering for Cylindrical Algebraic Decomposition\n  via Exploiting Chordal Structure",
        "authors": [
            "Haokun Li",
            "Bican Xia",
            "Huiying Zhang",
            "Tao Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Cylindrical algebraic decomposition (CAD) plays an important role in the\nfield of real algebraic geometry and many other areas. As is well-known, the\nchoice of variable ordering while computing CAD has a great effect on the time\nand memory use of the computation as well as the number of sample points\ncomputed. In this paper, we indicate that typical CAD algorithms, if executed\nwith respect to a special kind of variable orderings (called \"the perfect\nelimination orderings\"), naturally preserve chordality, which is an important\nproperty on sparsity of variables. Experimentation suggests that if the\nassociated graph of the polynomial system in question is chordal (\\emph{resp.},\nis nearly chordal), then a perfect elimination ordering of the associated graph\n(\\emph{resp.}, of a minimal chordal completion of the associated graph) can be\na good variable ordering for the CAD computation. That is, by using the perfect\nelimination orderings, the CAD computation may produce a much smaller full set\nof projection polynomials than by using other naive variable orderings. More\nimportantly, for the complexity analysis of the CAD computation via a perfect\nelimination ordering, a so-called $(m,d)$-property of the full set of\nprojection polynomials obtained via such an ordering is given, through which\nthe \"size\" of this set is characterized. This property indicates that when the\ncorresponding perfect elimination tree has a lower height, the full set of\nprojection polynomials also tends to have a smaller \"size\". This is well\nconsistent with the experimental results, hence the perfect elimination\norderings with lower elimination tree height are further recommended to be used\nin the CAD projection.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00823v2"
    },
    {
        "title": "Computing Limits of Quotients of Multivariate Real Analytic Functions",
        "authors": [
            "Adam Strzebonski"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We present an algorithm for computing limits of quotients of real analytic\nfunctions. The algorithm is based on computation of a bound on the Lojasiewicz\nexponent and requires the denominator to have an isolated zero at the limit\npoint.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01242v1"
    },
    {
        "title": "Term Algebras, Canonical Representations and Difference Ring Theory for\n  Symbolic Summation",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  A general overview of the existing difference ring theory for symbolic\nsummation is given. Special emphasis is put on the user interface: the\ntranslation and back translation of the corresponding representations within\nthe term algebra and the formal difference ring setting. In particular,\ncanonical (unique) representations and their refinements in the introduced term\nalgebra are explored by utilizing the available difference ring theory. Based\non that, precise input-output specifications of the available tools of the\nsummation package Sigma are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01471v3"
    },
    {
        "title": "Proceedings 11th International Workshop on Computing with Terms and\n  Graphs",
        "authors": [
            "Patrick Bahr"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Graphs, and graph transformation systems, are used in many areas within\nComputer Science: to represent data structures and algorithms, to define\ncomputation models, as a general modelling tool to study complex systems, etc.\nResearch in term and graph rewriting ranges from theoretical questions to\npractical implementation issues. Relevant research areas include: the modelling\nof first- and higher-order term rewriting by graph rewriting, graphical\nframeworks such as interaction nets and sharing graphs (optimal reduction),\nrewrite calculi for the analysis of functional programs, graph reduction\nimplementations of programming languages, graphical calculi modelling\nconcurrent and mobile computations, object-oriented systems, graphs as a model\nof biological or chemical systems, and automated reasoning and symbolic\ncomputation systems working on shared structures. The aim of the TERMGRAPH\nworkshop is to bring together researchers working in these different domains\nand to foster their interaction, to provide a forum for presenting new ideas\nand work in progress, and to enable newcomers to learn about current activities\nin this area.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01804v1"
    },
    {
        "title": "Solving linear difference equations with coefficients in rings with\n  idempotent representations",
        "authors": [
            "Jakob Ablinger",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We introduce a general reduction strategy that enables one to search for\nsolutions of parameterized linear difference equations in difference rings.\nHere we assume that the ring itself can be decomposed by a direct sum of\nintegral domains (using idempotent elements) that enjoys certain technical\nfeatures and that the coefficients of the difference equation are not\ndegenerated. Using this mechanism we can reduce the problem to find solutions\nin a ring (with zero-divisors) to search solutions in several copies of\nintegral domains. Utilizing existing solvers in this integral domain setting,\nwe obtain a general solver where the components of the linear difference\nequations and the solutions can be taken from difference rings that are built\ne.g., by $R\\Pi\\Sigma$-extensions over $\\Pi\\Sigma$-fields. This class of\ndifference rings contains, e.g., nested sums and products, products over roots\nof unity and nested sums defined over such objects.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03307v1"
    },
    {
        "title": "Algorithms for Linearly Recurrent Sequences of Truncated Polynomials",
        "authors": [
            "Seung Gyu Hyun",
            "Vincent Neiger",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Linear recurrent sequences are those whose elements are defined as linear\ncombinations of preceding elements, and finding recurrence relations is a\nfundamental problem in computer algebra. In this paper, we focus on sequences\nwhose elements are vectors over the ring $\\mathbb{A} = \\mathbb{K}[x]/(x^d)$ of\ntruncated polynomials. Finding the ideal of their recurrence relations has\napplications such as the computation of minimal polynomials and determinants of\nsparse matrices over $\\mathbb{A}$. We present three methods for finding this\nideal: a Berlekamp-Massey-like approach due to Kurakin, one which computes the\nkernel of some block-Hankel matrix over $\\mathbb{A}$ via a minimal approximant\nbasis, and one based on bivariate Pad\\'e approximation. We propose complexity\nimprovements for the first two methods, respectively by avoiding the\ncomputation of redundant relations and by exploiting the Hankel structure to\ncompress the approximation problem. Then we confirm these improvements\nempirically through a C++ implementation, and we discuss the above-mentioned\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03583v2"
    },
    {
        "title": "Symbolic computation of hypergeometric type and non-holonomic power\n  series",
        "authors": [
            "Bertrand Teguia Tabuguia",
            "Wolfram Koepf"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  A term $a_n$ is $m$-fold hypergeometric, for a given positive integer $m$, if\nthe ratio $a_{n+m}/a_n$ is a rational function over a field $K$ of\ncharacteristic zero. We establish the structure of holonomic recurrence\nequation, i.e. linear and homogeneous recurrence equations having polynomial\ncoefficients, that have $m$-fold hypergeometric term solutions over $K$, for\nany positive integer $m$. Consequently, we describe an algorithm, say\n$mfoldHyper$, that extends van Hoeij's algorithm (1998) which computes a basis\nof the subspace of hypergeometric $(m=1)$ term solutions of holonomic\nrecurrence equations to the more general case of $m$-fold hypergeometric terms.\n  We generalize the concept of hypergeometric type power series introduced by\nKoepf (1992), by considering linear combinations of Laurent-Puiseux series\nwhose coefficients are $m$-fold hypergeometric terms. Thus thanks to\n$mfoldHyper$, we deduce a complete procedure to compute these power series;\nindeed, it turns out that every linear combination of power series with\n$m$-fold hypergeometric term coefficients, for finitely many values of $m$, is\ndetected.\n  On the other hand, we investigate an algorithm to represent power series of\nnon-holonomic functions. The algorithm follows the same steps of Koepf's\nalgorithm, but instead of seeking holonomic differential equations, quadratic\ndifferential equations are computed and the Cauchy product rule is used to\ndeduce recurrence equations for the power series coefficients. This algorithm\ndefines a normal function that yields together with enough initial values\nnormal forms for many power series of non-holonomic functions. Therefore,\nnon-trivial identities are automatically proved using this approach.\n  This paper is accompanied by implementations in the Computer Algebra Systems\n(CAS) Maxima 5.44.0 and Maple 2019.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04157v1"
    },
    {
        "title": "Fast real and complex root-finding methods for well-conditioned\n  polynomials",
        "authors": [
            "Guillaume Moroz"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Given a polynomial $p$ of degree $d$ and a bound $\\kappa$ on a condition\nnumber of $p$, we present the first root-finding algorithms that return all its\nreal and complex roots with a number of bit operations quasi-linear in $d\n\\log^2(\\kappa)$. More precisely, several condition numbers can be defined\ndepending on the norm chosen on the coefficients of the polynomial. Let $p(x) =\n\\sum\\_{k=0}^d a\\_k x^k = \\sum\\_{k=0}^d \\sqrt{\\binom d k} b\\_k x^k$. We call the\ncondition number associated with a perturbation of the $a\\_k$ the hyperbolic\ncondition number $\\kappa\\_h$, and the one associated with a perturbation of the\n$b\\_k$ the elliptic condition number $\\kappa\\_e$. For each of these condition\nnumbers, we present algorithms that find the real and the complex roots of $p$\nin $O\\left(d\\log^2(d\\kappa)\\ \\text{polylog}(\\log(d\\kappa))\\right)$ bit\noperations.Our algorithms are well suited for random polynomials since\n$\\kappa\\_h$ (resp. $\\kappa\\_e$) is bounded by a polynomial in $d$ with high\nprobability if the $a\\_k$ (resp. the $b\\_k$) are independent, centered Gaussian\nvariables of variance $1$.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04180v1"
    },
    {
        "title": "On exact division and divisibility testing for sparse polynomials",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  No polynomial-time algorithm is known to test whether a sparse polynomial G\ndivides another sparse polynomial $F$. While computing the quotient Q=F quo G\ncan be done in polynomial time with respect to the sparsities of F, G and Q,\nthis is not yet sufficient to get a polynomial-time divisibility test in\ngeneral. Indeed, the sparsity of the quotient Q can be exponentially larger\nthan the ones of F and G. In the favorable case where the sparsity #Q of the\nquotient is polynomial, the best known algorithm to compute Q has a non-linear\nfactor #G#Q in the complexity, which is not optimal.\n  In this work, we are interested in the two aspects of this problem. First, we\npropose a new randomized algorithm that computes the quotient of two sparse\npolynomials when the division is exact. Its complexity is quasi-linear in the\nsparsities of F, G and Q. Our approach relies on sparse interpolation and it\nworks over any finite field or the ring of integers. Then, as a step toward\nfaster divisibility testing, we provide a new polynomial-time algorithm when\nthe divisor has a specific shape. More precisely, we reduce the problem to\nfinding a polynomial S such that QS is sparse and testing divisibility by S can\nbe done in polynomial time. We identify some structure patterns in the divisor\nG for which we can efficiently compute such a polynomial~S.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04826v2"
    },
    {
        "title": "On FGLM Algorithms with Tate Algebras",
        "authors": [
            "Xavier Caruso",
            "Tristan Vaccon",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Tate introduced in [Ta71] the notion of Tate algebras to serve, in the\ncontext of analytic geometry over the-adics, as a counterpart of polynomial\nalgebras in classical algebraic geometry. In [CVV19, CVV20] the formalism of\nGr{\\\"o}bner bases over Tate algebras has been introduced and advanced\nsignature-based algorithms have been proposed. In the present article, we\nextend the FGLM algorithm of [FGLM93] to Tate algebras. Beyond allowing for\nfast change of ordering, this strategy has two other important benefits. First,\nit provides an efficient algorithm for changing the radii of convergence which,\nin particular, makes effective the bridge between the polynomial setting and\nthe Tate setting and may help in speeding up the computation of Gr{\\\"o}bner\nbasis over Tate algebras. Second, it gives the foundations for designing a fast\nalgorithm for interreduction, which could serve as basic primitive in our\nprevious algorithms and accelerate them significantly.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.05324v1"
    },
    {
        "title": "Lazy Hermite Reduction and Creative Telescoping for Algebraic Functions",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Bronstein's lazy Hermite reduction is a symbolic integration technique that\nreduces algebraic functions to integrands with only simple poles without the\nprior computation of an integral basis. We sharpen the lazy Hermite reduction\nby combining it with the polynomial reduction to solve the decomposition\nproblem of algebraic functions. The sharpened reduction is then used to design\na reduction-based telescoping algorithm for algebraic functions in two\nvariables.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06538v2"
    },
    {
        "title": "Root Radii and Subdivision for Polynomial Root-Finding",
        "authors": [
            "Rémi Imbach",
            "Victor Y. Pan"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We depart from our approximation of 2000 of all root radii of a polynomial,\nwhich has readily extended Sch{\\\"o}nhage's efficient algorithm of 1982 for a\nsingle root radius. We revisit this extension, advance it, based on our simple\nbut novel idea, and yield significant practical acceleration of the known near\noptimal subdivision algorithms for complex and real root-finding of user's\nchoice. We achieve this by means of significant saving of exclusion tests and\nTaylor's shifts, which are the bottleneck of subdivision root-finders. This\nsaving relies on our novel recipes for the initialization of root-finding\niterations of independent interest. We demonstrate our practical progress with\nnumerical tests, provide extensive analysis of the resulting algorithms, and\nshow that, like the preceding subdivision root-finders, they support near\noptimal Boolean complexity bounds.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.10821v2"
    },
    {
        "title": "Isolating Bounded and Unbounded Real Roots of a Mixed\n  Trigonometric-Polynomial",
        "authors": [
            "Rizeng Chen",
            "Haokun Li",
            "Bican Xia",
            "Tianqi Zhao",
            "Tao Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Mixed trigonometric-polynomials (MTPs) are functions of the form\n$f(x,\\sin{x}, \\cos{x})$ with $f\\in\\mathbb{Q}[x_1,x_2,x_3]$. In this paper, an\nalgorithm ``isolating\" all the real roots of an MTP is provided and\nimplemented. It automatically divides the real roots into two parts: one\nconsists of finitely many ``bounded\" roots in an interval $[\\mu_-,\\mu_+]$ while\nthe other consists of probably countably many ``periodic\" roots in\n$\\mathbb{R}\\backslash[\\mu_-,\\mu_+]$. For bounded roots, the algorithm returns\nisolating intervals and corresponding multiplicities while for periodic roots,\nit returns finitely many mutually disjoint small intervals\n$I_i\\subset[-\\pi,\\pi]$, integers $c_i>0$ and multisets of root multiplicity\n$\\{m_{j,i}\\}_{j=1}^{c_i}$ such that any periodic root $t>\\mu_+$ is in the set\n$(\\sqcup_i\\cup_{k\\in\\mathbb{N}}(I_i+2k\\pi))$ and any interval\n$I_i+2k\\pi\\subset(\\mu_+,\\infty)$ contains exactly $c_i$ periodic roots with\nmultiplicities $m_{1,i},...,m_{c_i,i}$, respectively. The effectiveness and\nefficiency of the algorithm are shown by experiments. %In particular, our\nresults indicate that the ``distributions\" of the roots of an MTP in the\n``periods\" $(-\\pi,\\pi]+2k\\pi$ sufficiently far from $0$ share a same pattern.\nBesides, the method used to isolate the roots in $[\\mu_-,\\mu_+]$ is applicable\nto any other bounded interval as well. The algorithm takes advantages of the\nweak Fourier sequence technique and deals with the intervals period-by-period\nwithout scaling the coordinate so to keep the length of the sequence short. The\nnew approaches can easily be modified to decide whether there is any root, or\nwhether there are infinitely many roots in unbounded intervals of the form\n$(-\\infty,a)$ or $(a,\\infty)$ with $a\\in\\mathbb{Q}$.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.05847v1"
    },
    {
        "title": "Computational Tutorial on Gröbner bases embedding Sage in LaTeX with\n  SageTEX",
        "authors": [
            "Edinah K. Gnang"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Elementary tutorial on implementation aspects of Gr\\\"obner bases computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1177v1"
    },
    {
        "title": "Order-Degree Curves for Hypergeometric Creative Telescoping",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Creative telescoping applied to a bivariate proper hypergeometric term\nproduces linear recurrence operators with polynomial coefficients, called\ntelescopers. We provide bounds for the degrees of the polynomials appearing in\nthese operators. Our bounds are expressed as curves in the (r,d)-plane which\nassign to every order r a bound on the degree d of the telescopers. These\ncurves are hyperbolas, which reflect the phenomenon that higher order\ntelescopers tend to have lower degree, and vice versa.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1982v1"
    },
    {
        "title": "Truth Table Invariant Cylindrical Algebraic Decomposition",
        "authors": [
            "Russell Bradford",
            "James H. Davenport",
            "Matthew England",
            "Scott McCallum",
            "David Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  When using cylindrical algebraic decomposition (CAD) to solve a problem with\nrespect to a set of polynomials, it is likely not the signs of those\npolynomials that are of paramount importance but rather the truth values of\ncertain quantifier free formulae involving them. This observation motivates our\narticle and definition of a Truth Table Invariant CAD (TTICAD).\n  In ISSAC 2013 the current authors presented an algorithm that can efficiently\nand directly construct a TTICAD for a list of formulae in which each has an\nequational constraint. This was achieved by generalising McCallum's theory of\nreduced projection operators. In this paper we present an extended version of\nour theory which can be applied to an arbitrary list of formulae, achieving\nsavings if at least one has an equational constraint. We also explain how the\ntheory of reduced projection operators can allow for further improvements to\nthe lifting phase of CAD algorithms, even in the context of a single equational\nconstraint.\n  The algorithm is implemented fully in Maple and we present both promising\nresults from experimentation and a complexity analysis showing the benefits of\nour contributions.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.0645v3"
    },
    {
        "title": "Essentially optimal interactive certificates in linear algebra",
        "authors": [
            "Jean-Guillaume Dumas",
            "Erich Kaltofen"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Certificates to a linear algebra computation are additional data structures\nfor each output, which can be used by a---possibly randomized---verification\nalgorithm that proves the correctness of each output. The certificates are\nessentially optimal if the time (and space) complexity of verification is\nessentially linear in the input size $N$, meaning $N$ times a factor\n$N^{o(1)}$, i.e., a factor $N^{\\eta(N)}$ with $\\lim\\_{N\\to \\infty} \\eta(N)$ $=$\n$0$. We give algorithms that compute essentially optimal certificates for the\npositive semidefiniteness, Frobenius form, characteristic and minimal\npolynomial of an $n\\times n$ dense integer matrix $A$. Our certificates can be\nverified in Monte-Carlo bit complexity $(n^2 \\log\\|A\\|)^{1+o(1)}$, where\n$\\log\\|A\\|$ is the bit size of the integer entries, solving an open problem in\n[Kaltofen, Nehring, Saunders, Proc.\\ ISSAC 2011] subject to computational\nhardness assumptions. Second, we give algorithms that compute certificates for\nthe rank of sparse or structured $n\\times n$ matrices over an abstract field,\nwhose Monte Carlo verification complexity is $2$ matrix-times-vector products\n$+$ $n^{1+o(1)}$ arithmetic operations in the field. For example, if the\n$n\\times n$ input matrix is sparse with $n^{1+o(1)}$ non-zero entries, our rank\ncertificate can be verified in $n^{1+o(1)}$ field operations. This extends also\nto integer matrices with only an extra $\\|A\\|^{1+o(1)}$ factor. All our\ncertificates are based on interactive verification protocols with the\ninteraction removed by a Fiat-Shamir identification heuristic. The validity of\nour verification procedure is subject to standard computational hardness\nassumptions from cryptography.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4567v4"
    },
    {
        "title": "Sparse interpolation over finite fields via low-order roots of unity",
        "authors": [
            "Andrew Arnold",
            "Mark Giesbrecht",
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We present a new Monte Carlo algorithm for the interpolation of a\nstraight-line program as a sparse polynomial $f$ over an arbitrary finite field\nof size $q$. We assume a priori bounds $D$ and $T$ are given on the degree and\nnumber of terms of $f$. The approach presented in this paper is a hybrid of the\ndiversified and recursive interpolation algorithms, the two previous fastest\nknown probabilistic methods for this problem. By making effective use of the\ninformation contained in the coefficients themselves, this new algorithm\nimproves on the bit complexity of previous methods by a \"soft-Oh\" factor of\n$T$, $\\log D$, or $\\log q$.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4744v2"
    },
    {
        "title": "Constructing Fewer Open Cells by GCD Computation in CAD Projection",
        "authors": [
            "Jingjun Han",
            "Liyun Dai",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  A new projection operator based on cylindrical algebraic decomposition (CAD)\nis proposed. The new operator computes the intersection of projection factor\nsets produced by different CAD projection orders. In other words, it computes\nthe gcd of projection polynomials in the same variables produced by different\nCAD projection orders. We prove that the new operator still guarantees\nobtaining at least one sample point from every connected component of the\nhighest dimension, and therefore, can be used for testing semi-definiteness of\npolynomials. Although the complexity of the new method is still doubly\nexponential, in many cases, the new operator does produce smaller projection\nfactor sets and fewer open cells. Some examples of testing semi-definiteness of\npolynomials, which are difficult to be solved by existing tools, have been\nworked out efficiently by our program based on the new method.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4953v2"
    },
    {
        "title": "Formulating problems for real algebraic geometry",
        "authors": [
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We discuss issues of problem formulation for algorithms in real algebraic\ngeometry, focussing on quantifier elimination by cylindrical algebraic\ndecomposition. We recall how the variable ordering used can have a profound\neffect on both performance and output and summarise what may be done to assist\nwith this choice. We then survey other questions of problem formulation and\nalgorithm optimisation that have become pertinent following advances in CAD\ntheory, including both work that is already published and work that is\ncurrently underway. With implementations now in reach of real world\napplications and new theory meaning algorithms are far more sensitive to the\ninput, our thesis is that intelligently formulating problems for algorithms,\nand indeed choosing the correct algorithm variant for a problem, is key to\nimproving the practical use of both quantifier elimination and symbolic real\nalgebraic geometry in general.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.3461v1"
    },
    {
        "title": "On the Efficiency of Solving Boolean Polynomial Systems with the\n  Characteristic Set Method",
        "authors": [
            "Zhenyu Huang",
            "Yao Sun",
            "Dongdai Lin"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  An improved characteristic set algorithm for solving Boolean polynomial\nsystems is proposed. This algorithm is based on the idea of converting all the\npolynomials into monic ones by zero decomposition, and using additions to\nobtain pseudo-remainders. Three important techniques are applied in the\nalgorithm. The first one is eliminating variables by new generated linear\npolynomials. The second one is optimizing the strategy of choosing polynomial\nfor zero decomposition. The third one is to compute add-remainders to eliminate\nthe leading variable of new generated monic polynomials. By analyzing the depth\nof the zero decomposition tree, we present some complexity bounds of this\nalgorithm, which are lower than the complexity bounds of previous\ncharacteristic set algorithms. Extensive experimental results show that this\nnew algorithm is more efficient than previous characteristic set algorithms for\nsolving Boolean polynomial systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.4596v4"
    },
    {
        "title": "Una metodología para realizar Diferenciación Automática Anidada",
        "authors": [
            "Juan Luis Valerdi",
            "Fernando Raul Rodriguez"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  En este trabajo se presenta una propuesta para realizar Diferenciaci\\'on\nAutom\\'atica Anidada utilizando cualquier biblioteca de Diferenciaci\\'on\nAutom\\'atica que permita sobrecarga de operadores. Para calcular las derivadas\nanidadas en una misma evaluaci\\'on de la funci\\'on, la cual se asume que sea\nanal\\'itica, se trabaja con el modo forward utilizando una nueva estructura\nllamada SuperAdouble, que garantiza que se aplique correctamente la\nDiferenciaci\\'on Autom\\'atica y se calculen el valor y la derivada que se\nrequiera.\n  This paper proposes a framework to apply Nested Automatic Differentiation\nusing any library of Automatic Differentiation which allows operator\noverloading. To compute nested derivatives of a function while it is being\nevaluated, which is assumed to be analytic, a new structure called SuperAdouble\nis used in the forward mode. This new class guarantees the correct application\nof Automatic Differentiation to calculate the value and derivative of a\nfunction where is required.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.4779v1"
    },
    {
        "title": "Cylindrical Algebraic Decomposition Using Local Projections",
        "authors": [
            "Adam Strzebonski"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We present an algorithm which computes a cylindrical algebraic decomposition\nof a semialgebraic set using projection sets computed for each cell separately.\nSuch local projection sets can be significantly smaller than the global\nprojection set used by the Cylindrical Algebraic Decomposition (CAD) algorithm.\nThis leads to reduction in the number of cells the algorithm needs to\nconstruct. We give an empirical comparison of our algorithm and the classical\nCAD algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.4925v1"
    },
    {
        "title": "A fast algorithm for computing the characteristic polynomial of the\n  p-curvature",
        "authors": [
            "Alin Bostan",
            "Xavier Caruso",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We discuss theoretical and algorithmic questions related to the $p$-curvature\nof differential operators in characteristic $p$. Given such an operator $L$,\nand denoting by $\\Chi(L)$ the characteristic polynomial of its $p$-curvature,\nwe first prove a new, alternative, description of $\\Chi(L)$. This description\nturns out to be particularly well suited to the fast computation of $\\Chi(L)$\nwhen $p$ is large: based on it, we design a new algorithm for computing\n$\\Chi(L)$, whose cost with respect to $p$ is $\\softO(p^{0.5})$ operations in\nthe ground field. This is remarkable since, prior to this work, the fastest\nalgorithms for this task, and even for the subtask of deciding nilpotency of\nthe $p$-curvature, had merely slightly subquadratic complexity\n$\\softO(p^{1.79})$.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5341v1"
    },
    {
        "title": "Computing necessary integrability conditions for planar parametrized\n  homogeneous potentials",
        "authors": [
            "Alin Bostan",
            "Thierry Combot",
            "Safey El Din Mohab"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Let $V\\in\\mathbb{Q}(i)(\\a_1,\\dots,\\a_n)(\\q_1,\\q_2)$ be a rationally\nparametrized planar homogeneous potential of homogeneity degree $k\\neq -2, 0,\n2$. We design an algorithm that computes polynomial \\emph{necessary} conditions\non the parameters $(\\a_1,\\dots,\\a_n)$ such that the dynamical system associated\nto the potential $V$ is integrable. These conditions originate from those of\nthe Morales-Ramis-Sim\\'o integrability criterion near all Darboux points. The\nimplementation of the algorithm allows to treat applications that were out of\nreach before, for instance concerning the non-integrability of polynomial\npotentials up to degree $9$. Another striking application is the first complete\nproof of the non-integrability of the \\emph{collinear three body problem}.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5342v1"
    },
    {
        "title": "Diferenciación Automática Anidada. Un enfoque algebraico",
        "authors": [
            "Juan Luis Valerdi"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  En este trabajo se presenta una propuesta para realizar Diferenciaci\\'on\nAutom\\'atica Anidada utilizando cualquier biblioteca de Diferenciaci\\'on\nAutom\\'atica que permita sobrecarga de operadores. Para calcular las derivadas\nanidadas en una misma evaluaci\\'on de la funci\\'on, la cual se asume que sea\nanal'itica, se trabaja con el modo forward utilizando una nueva estructura\nllamada SuperAdouble, que garantiza que se aplique correctamente la\ndiferenciaci\\'on autom\\'atica y se calculen el valor y la derivada que se\nrequiera. Tambi\\'en se presenta un enfoque algebraico de la Diferenciaci\\'on\nAutom\\'atica y en particular del espacio de los SuperAdoubles.\n  This paper proposes a framework to apply Nested Automatic Differentiation\nusing any library of Automatic Differentiation which allows operator\noverloading. To compute nested derivatives of a function while it is being\nevaluated, which is assumed to be analytic, a new structure called SuperAdouble\nis used in the forward mode. This new class guarantees the correct application\nof Automatic Differentiation to calculate the value and derivative of a\nfunction where is required. Also, an Automatic Differentiation algebraic point\nof view is presented with particular emphasis in Nested Automatic\nDifferentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5854v1"
    },
    {
        "title": "A comparison of three heuristics to choose the variable ordering for CAD",
        "authors": [
            "Zongyan Huang",
            "Matthew England",
            "David Wilson",
            "James H. Davenport",
            "Lawrence C. Paulson"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Cylindrical algebraic decomposition (CAD) is a key tool for problems in real\nalgebraic geometry and beyond. When using CAD there is often a choice over the\nvariable ordering to use, with some problems infeasible in one ordering but\nsimple in another. Here we discuss a recent experiment comparing three\nheuristics for making this choice on thousands of examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6082v1"
    },
    {
        "title": "Using the Regular Chains Library to build cylindrical algebraic\n  decompositions by projecting and lifting",
        "authors": [
            "Matthew England",
            "David Wilson",
            "Russell Bradford",
            "James H. Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Cylindrical algebraic decomposition (CAD) is an important tool, both for\nquantifier elimination over the reals and a range of other applications.\nTraditionally, a CAD is built through a process of projection and lifting to\nmove the problem within Euclidean spaces of changing dimension. Recently, an\nalternative approach which first decomposes complex space using triangular\ndecomposition before refining to real space has been introduced and implemented\nwithin the RegularChains Library of Maple. We here describe a freely available\npackage ProjectionCAD which utilises the routines within the RegularChains\nLibrary to build CADs by projection and lifting. We detail how the projection\nand lifting algorithms were modified to allow this, discuss the motivation and\nsurvey the functionality of the package.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6090v1"
    },
    {
        "title": "Choosing a variable ordering for truth-table invariant cylindrical\n  algebraic decomposition by incremental triangular decomposition",
        "authors": [
            "Matthew England",
            "Russell Bradford",
            "James H. Davenport",
            "David Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Cylindrical algebraic decomposition (CAD) is a key tool for solving problems\nin real algebraic geometry and beyond. In recent years a new approach has been\ndeveloped, where regular chains technology is used to first build a\ndecomposition in complex space. We consider the latest variant of this which\nbuilds the complex decomposition incrementally by polynomial and produces CADs\non whose cells a sequence of formulae are truth-invariant. Like all CAD\nalgorithms the user must provide a variable ordering which can have a profound\nimpact on the tractability of a problem. We evaluate existing heuristics to\nhelp with the choice for this algorithm, suggest improvements and then derive a\nnew heuristic more closely aligned with the mechanics of the new algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6094v1"
    },
    {
        "title": "A Monomial-Oriented GVW for Computing Gröbner Bases",
        "authors": [
            "Yao Sun",
            "Dingkang Wang",
            "Zhenyu Huang",
            "Dongdai Lin"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  The GVW algorithm, presented by Gao et al., is a signature-based algorithm\nfor computing Gr\\\"obner bases. In this paper, a variant of GVW is presented.\nThis new algorithm is called a monomial-oriented GVW algorithm or mo-GVW\nalgorithm for short. The mo-GVW algorithm presents a new frame of GVW and\nregards {\\em labeled monomials} instead of {\\em labeled polynomials} as basic\nelements of the algorithm. Being different from the original GVW algorithm, for\neach labeled monomial, the mo-GVW makes efforts to find the smallest signature\nthat can generate this monomial. The mo-GVW algorithm also avoids generating\nJ-pairs, and uses efficient methods of searching reducers and checking\ncriteria. Thus, the mo-GVW algorithm has a better performance during practical\nimplementations.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.0105v1"
    },
    {
        "title": "Data-Discriminants of Likelihood Equations",
        "authors": [
            "Jose Israel Rodriguez",
            "Xiaoxian Tang"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Maximum likelihood estimation (MLE) is a fundamental computational problem in\nstatistics. The problem is to maximize the likelihood function with respect to\ngiven data on a statistical model. An algebraic approach to this problem is to\nsolve a very structured parameterized polynomial system called likelihood\nequations. For general choices of data, the number of complex solutions to the\nlikelihood equations is finite and called the ML-degree of the model. The only\nsolutions to the likelihood equations that are statistically meaningful are the\nreal/positive solutions. However, the number of real/positive solutions is not\ncharacterized by the ML-degree. We use discriminants to classify data according\nto the number of real/positive solutions of the likelihood equations. We call\nthese discriminants data-discriminants (DD). We develop a probabilistic\nalgorithm for computing DDs. Experimental results show that, for the benchmarks\nwe have tried, the probabilistic algorithm is more efficient than the standard\nelimination algorithm. Based on the computational results, we discuss the real\nroot classification problem for the 3 by 3 symmetric matrix~model.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.00334v5"
    },
    {
        "title": "Improving the use of equational constraints in cylindrical algebraic\n  decomposition",
        "authors": [
            "Matthew England",
            "Russell Bradford",
            "James H. Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  When building a cylindrical algebraic decomposition (CAD) savings can be made\nin the presence of an equational constraint (EC): an equation logically implied\nby a formula.\n  The present paper is concerned with how to use multiple ECs, propagating\nthose in the input throughout the projection set. We improve on the approach of\nMcCallum in ISSAC 2001 by using the reduced projection theory to make savings\nin the lifting phase (both to the polynomials we lift with and the cells lifted\nover). We demonstrate the benefits with worked examples and a complexity\nanalysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.04466v2"
    },
    {
        "title": "Subtropical Real Root Finding",
        "authors": [
            "Thomas Sturm"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We describe a new incomplete but terminating method for real root finding for\nlarge multivariate polynomials. We take an abstract view of the polynomial as\nthe set of exponent vectors associated with sign information on the\ncoefficients. Then we employ linear programming to heuristically find roots.\nThere is a specialized variant for roots with exclusively positive coordinates,\nwhich is of considerable interest for applications in chemistry and systems\nbiology. An implementation of our method combining the computer algebra system\nReduce with the linear programming solver Gurobi has been successfully applied\nto input data originating from established mathematical models used in these\nareas. We have solved several hundred problems with up to more than 800000\nmonomials in up to 10 variables with degrees up to 12. Our method has failed\ndue to its incompleteness in less than 8 percent of the cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.04836v1"
    },
    {
        "title": "Computing the Rank Profile Matrix",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clément Pernet",
            "Ziad Sultan"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  The row (resp. column) rank profile of a matrix describes the staircase shape\nof its row (resp. column) echelon form. In an ISSAC'13 paper, we proposed a\nrecursive Gaussian elimination that can compute simultaneously the row and\ncolumn rank profiles of a matrix as well as those of all of its leading\nsub-matrices, in the same time as state of the art Gaussian elimination\nalgorithms. Here we first study the conditions making a Gaus-sian elimination\nalgorithm reveal this information. Therefore, we propose the definition of a\nnew matrix invariant, the rank profile matrix, summarizing all information on\nthe row and column rank profiles of all the leading sub-matrices. We also\nexplore the conditions for a Gaussian elimination algorithm to compute all or\npart of this invariant, through the corresponding PLUQ decomposition. As a\nconsequence, we show that the classical iterative CUP decomposition algorithm\ncan actually be adapted to compute the rank profile matrix. Used, in a Crout\nvariant, as a base-case to our ISSAC'13 implementation, it delivers a\nsignificant improvement in efficiency. Second, the row (resp. column) echelon\nform of a matrix are usually computed via different dedicated triangular\ndecompositions. We show here that, from some PLUQ decompositions, it is\npossible to recover the row and column echelon forms of a matrix and of any of\nits leading sub-matrices thanks to an elementary post-processing algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.05239v2"
    },
    {
        "title": "Numerically Safe Gaussian Elimination with No Pivoting",
        "authors": [
            "Victor Pan",
            "Liang Zhao"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Gaussian elimination with no pivoting and block Gaussian elimination are\nattractive alternatives to the customary but communication intensive Gaussian\nelimination with partial pivoting (hereafter we use the acronyms GENP, BGE, and\nGEPP} provided that the computations proceed safely and numerically safely},\nthat is, run into neither division by 0 nor numerical problems. Empirically,\nsafety and numerical safety of GENP have been consistently observed in a number\nof papers where an input matrix was pre-processed with various structured\nmultipliers chosen ad hoc. Our present paper provides missing formal support\nfor this empirical observation and explains why it was elusive so far. Namely\nwe prove that GENP is numerically unsafe for a specific class of input matrices\nin spite of its pre-processing with some well-known and well-tested structured\nmultipliers, but we also prove that GENP and BGE are safe and numerically safe\nfor the average input matrix pre-processed with any nonsingular and\nwell-conditioned multiplier. This should embolden search for sparse and\nstructured multipliers, and we list and test some new classes of them. We also\nseek randomized pre-processing that universally (that is, for all input\nmatrices) supports (i) safe GENP and BGE with probability 1 and/or (ii)\nnumerically safe GENP and BGE with a probability close to 1.We achieve goal (i)\nwith a Gaussian structured multiplier and goal (ii) with a Gaussian\nunstructured multiplier and alternatively with Gaussian structured\naugmentation. We consistently confirm all these formal results with our tests\nof GENP for benchmark inputs. We have extended our approach to other\nfundamental matrix computations and keep working on further extensions.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.05385v11"
    },
    {
        "title": "Real Polynomial Root-finding by Means of Matrix and Polynomial\n  Iterations",
        "authors": [
            "Victor Y. Pan",
            "Liang Zhao"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Univariate polynomial root-finding is a classical subject, still important\nfor modern computing. Frequently one seeks just the real roots of a polynomial\nwith real coefficients. They can be approximated at a low computational cost if\nthe polynomial has no nonreal roots, but for high degree polynomials, nonreal\nroots are typically much more numerous than the real ones. The challenge is\nknown for a long time, and the subject has been intensively studied.\nNevertheless, we produce some novel ideas and techniques and obtain dramatic\nacceleration of the known algorithms. In order to achieve our progress we\nexploit the correlation between the computations with matrices and polynomials,\nrandomized matrix computations, and complex plane geometry, extend the\ntechniques of the matrix sign iterations, and use the structure of the\ncompanion matrix of the input polynomial. The results of our extensive tests\nwith benchmark polynomials and random matrices are quite encouraging. In\nparticular in our tests the number of iterations required for convergence of\nour algorithms grew very slowly (if at all) as we increased the degree of the\nunivariate input polynomials and the dimension of the input matrices from 64 to\n1024.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.05390v3"
    },
    {
        "title": "Accelerated Approximation of the Complex Roots and Factors of a\n  Univariate Polynomial",
        "authors": [
            "Victor Y. Pan",
            "Elias P. Tsigaridas",
            "Vitaly Zaderman",
            "Liang Zhao"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  The algorithms of Pan (1995) and(2002) approximate the roots of a complex\nunivariate polynomial in nearly optimal arithmetic and Boolean time but require\nprecision of computing that exceeds the degree of the polynomial. This causes\nnumerical stability problems when the degree is large. We observe, however,\nthat such a difficulty disappears at the initial stage of the algorithms, and\nin our present paper we extend this stage to root-finding within a nearly\noptimal arithmetic and Boolean complexity bounds provided that some mild\ninitial isolation of the roots of the input polynomial has been ensured.\nFurthermore our algorithm is nearly optimal for the approximation of the roots\nisolated in a fixed disc, square or another region on the complex plane rather\nthan all complex roots of a polynomial. Moreover the algorithm can be applied\nto a polynomial given by a black box for its evaluation (even if its\ncoefficients are not known); it promises to be of practical value for\npolynomial root-finding and factorization, the latter task being of interest on\nits own right. We also provide a new support for a winding number algorithm,\nwhich enables extension of our progress to obtaining mild initial\napproximations to the roots. We conclude with summarizing our algorithms and\ntheir extension to the approximation of isolated multiple roots and root\nclusters.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.05392v3"
    },
    {
        "title": "A Modular Algorithm for Computing Polynomial GCDs over Number Fields\n  presented with Multiple Extensions",
        "authors": [
            "Mark van Hoeij",
            "Michael Monagan"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We consider the problem of computing the monic gcd of two polynomials over a\nnumber field L = Q(alpha_1,...,alpha_n). Langemyr and McCallum have already\nshown how Brown's modular GCD algorithm for polynomials over Q can be modified\nto work for Q(alpha) and subsequently, Langemyr extended the algorithm to L[x].\nEncarnacion also showed how to use rational number to make the algorithm for\nQ(alpha) output sensitive, that is, the number of primes used depends on the\nsize of the integers in the gcd and not on bounds based on the input\npolynomials.\n  Our first contribution is an extension of Encarnacion's modular GCD algorithm\nto the case n>1, which, like Encarnacion's algorithm, is is output sensitive.\n  Our second contribution is a proof that it is not necessary to test if p\ndivides the discriminant. This simplifies the algorithm; it is correct without\nthis test.\n  Our third contribution is a modification to the algorithm to treat the case\nof reducible extensions. Such cases arise when solving systems of polynomial\nequations.\n  Our fourth contribution is an implementation of the modular GCD algorithm in\nMaple and in Magma. Both implementations use a recursive dense polynomial data\nstructure for representing polynomials over number fields with multiple field\nextensions.\n  Our fifth contribution is a primitive fraction-free algorithm. This is the\nbest non-modular approach. We present timing comparisons of the Maple and Magma\nimplementations demonstrating various optimizations and comparing them with the\nmonic Euclidan algorithm and our primitive fraction-free algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.01038v1"
    },
    {
        "title": "Encoding and Decoding Algorithms for Arbitrary Dimensional Hilbert Order",
        "authors": [
            "Hui Liu",
            "Tao Cui",
            "Wei Leng",
            "Linbo Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Hilbert order is widely applied in many areas. However, most of the\nalgorithms are confined to low dimensional cases. In this paper, algorithms for\nencoding and decoding arbitrary dimensional Hilbert order are presented. Eight\nalgorithms are proposed. Four algorithms are based on arithmetic operations and\nthe other four algorithms are based on bit operations. For the algorithms\ncomplexities, four of them are linear and the other four are constant for given\ninputs. In the end of the paper, algorithms for two dimensional Hilbert order\nare presented to demonstrate the usage of the algorithms introduced.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.01274v1"
    },
    {
        "title": "Fast Computation of the Rank Profile Matrix and the Generalized Bruhat\n  Decomposition",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clement Pernet",
            "Ziad Sultan"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  The row (resp. column) rank profile of a matrix describes the stair-case\nshape of its row (resp. column) echelon form. We here propose a new matrix\ninvariant, the rank profile matrix, summarizing all information on the row and\ncolumn rank profiles of all the leading sub-matrices. We show that this normal\nform exists and is unique over any ring, provided that the notion of McCoy's\nrank is used, in the presence of zero divisors. We then explore the conditions\nfor a Gaussian elimination algorithm to compute all or part of this invariant,\nthrough the corresponding PLUQ decomposition. This enlarges the set of known\nElimination variants that compute row or column rank profiles. As a consequence\na new Crout base case variant significantly improves the practical efficiency\nof previously known implementations over a finite field. With matrices of very\nsmall rank, we also generalize the techniques of Storjohann and Yang to the\ncomputation of the rank profile matrix, achieving an $(r^\\omega+mn)^{1+o(1)}$\ntime complexity for an $m \\times n$ matrix of rank $r$, where $\\omega$ is the\nexponent of matrix multiplication. Finally, by give connections to the Bruhat\ndecomposition, and several of its variants and generalizations. Thus, our\nalgorithmic improvements for the PLUQ factorization, and their implementations,\ndirectly apply to these decompositions. In particular, we show how a PLUQ\ndecomposition revealing the rank profile matrix also reveals both a row and a\ncolumn echelon form of the input matrix or of any of its leading sub-matrices,\nby a simple post-processing made of row and column permutations.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.01798v2"
    },
    {
        "title": "Factorization of C-finite Sequences",
        "authors": [
            "Manuel Kauers",
            "Doron Zeilberger"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We discuss how to decide whether a given C-finite sequence can be written\nnontrivially as a product of two other C-finite sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.02756v1"
    },
    {
        "title": "Finding best possible constant for a polynomial inequality",
        "authors": [
            "Lu Yang",
            "Ju Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Given a multi-variant polynomial inequality with a parameter, how to find the\nbest possible value of this parameter that satisfies the inequality? For\ninstance, find the greatest number $k$ that satisfies $ a^3+b^3+c^3+\nk(a^2b+b^2c+c^2a)-(k+1)(ab^2+bc^2+ca^2)\\geq 0 $ for all nonnegative real\nnumbers $ a,b,c $. Analogues problems often appeared in studies of inequalities\nand were dealt with by various methods. In this paper, a general algorithm is\nproposed for finding the required best possible constant. The algorithm can be\neasily implemented by computer algebra tools such as Maple.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.01338v1"
    },
    {
        "title": "Matrix factoring by fraction-free reduction",
        "authors": [
            "Johannes Middeke",
            "David J. Jeffrey"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We consider exact matrix decomposition by Gauss-Bareiss reduction. We\ninvestigate two aspects of the process: common row and column factors and the\ninfluence of pivoting strategies. We identify two types of common factors:\nsystematic and statistical. Systematic factors depend on the process, while\nstatistical factors depend on the specific data. We show that existing\nfraction-free QR (Gram-Schmidt) algorithms create a common factor in the last\ncolumn of Q. We relate the existence of row factors in LU decomposition to\nfactors appearing in the Smith normal form of the matrix. For statistical\nfactors, we identify mechanisms and give estimates of the frequency. Our\nconclusions are tested by experimental data. For pivoting strategies, we\ncompare the sizes of output factors obtained by different strategies. We also\ncomment on timing differences.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.03565v1"
    },
    {
        "title": "Summation Theory II: Characterizations of\n  $\\boldsymbol{RΠΣ^*}$-extensions and algorithmic aspects",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Recently, $R\\Pi\\Sigma^*$-extensions have been introduced which extend Karr's\n$\\Pi\\Sigma^*$-fields substantially: one can represent expressions not only in\nterms of transcendental sums and products, but one can work also with products\nover primitive roots of unity. Since one can solve the parameterized\ntelescoping problem in such rings, covering as special cases the summation\nparadigms of telescoping and creative telescoping, one obtains a rather\nflexible toolbox for symbolic summation. This article is the continuation of\nthis work. Inspired by Singer's Galois theory of difference equations we will\nwork out several alternative characterizations of $R\\Pi\\Sigma^*$-extensions:\nadjoining naively sums and products leads to an $R\\Pi\\Sigma^*$-extension iff\nthe obtained difference ring is simple iff the ring can be embedded into the\nring of sequences iff the ring can be given by the interlacing of\n$\\Pi\\Sigma^*$-extensions. From the viewpoint of applications this leads to a\nfully automatic machinery to represent indefinite nested sums and products in\nsuch $R\\Pi\\Sigma^*$-rings. In addition, we work out how the parameterized\ntelescoping paradigm can be used to prove algebraic independence of indefinite\nnested sums. Furthermore, one obtains an alternative reduction tactic to solve\nthe parameterized telescoping problem in basic $R\\Pi\\Sigma^*$-extensions\nexploiting the interlacing property.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.04285v2"
    },
    {
        "title": "Solution of Interpolation Problems via the Hankel Polynomial\n  Construction",
        "authors": [
            "Alexei Yu. Uteshev",
            "Ivan Baravy"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We treat the interpolation problem $ \\{f(x_j)=y_j\\}_{j=1}^N $ for polynomial\nand rational functions. Developing the approach by C.Jacobi, we represent the\ninterpolants by virtue of the Hankel polynomials generated by the sequences $\n\\{\\sum_{j=1}^N x_j^ky_j/W^{\\prime}(x_j) \\}_{k\\in \\mathbb N} $ and $\n\\{\\sum_{j=1}^N x_j^k/(y_jW^{\\prime}(x_j)) \\}_{k\\in \\mathbb N} $; here $\nW(x)=\\prod_{j=1}^N(x-x_j) $. The obtained results are applied for the error\ncorrection problem, i.e. the problem of reconstructing the polynomial from a\nredundant set of its values some of which are probably erroneous. The problem\nof evaluation of the resultant of polynomials $ p(x) $ and $ q(x) $ from the\nset of values $ \\{p(x_j)/q(x_j) \\}_{j=1}^N $ is also tackled within the\nframework of this approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.08752v1"
    },
    {
        "title": "Using Two Types of Computer Algebra Systems to Solve Maxwell Optics\n  Problems",
        "authors": [
            "D. S. Kulyabov"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  To synthesize Maxwell optics systems, the mathematical apparatus of tensor\nand vector analysis is generally employed. This mathematical apparatus implies\nexecuting a great number of simple stereotyped operations, which are adequately\nsupported by computer algebra systems. In this paper, we distinguish between\ntwo stages of working with a mathematical model: model development and model\nusage. Each of these stages implies its own computer algebra system. As a model\nproblem, we consider the problem of geometrization of Maxwell's equations. Two\ncomputer algebra systems---Cadabra and FORM---are selected for use at different\nstages of investigation.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00832v1"
    },
    {
        "title": "Determinantal sets, singularities and application to optimal control in\n  medical imagery",
        "authors": [
            "Bernard Bonnard",
            "Jean-Charles Faugère",
            "Alain Jacquemard",
            "Mohab Safey El Din",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Control theory has recently been involved in the field of nuclear magnetic\nresonance imagery. The goal is to control the magnetic field optimally in order\nto improve the contrast between two biological matters on the pictures.\nGeometric optimal control leads us here to analyze mero-morphic vector fields\ndepending upon physical parameters , and having their singularities defined by\na deter-minantal variety. The involved matrix has polynomial entries with\nrespect to both the state variables and the parameters. Taking into account the\nphysical constraints of the problem, one needs to classify, with respect to the\nparameters, the number of real singularities lying in some prescribed\nsemi-algebraic set. We develop a dedicated algorithm for real root\nclassification of the singularities of the rank defects of a polynomial matrix,\ncut with a given semi-algebraic set. The algorithm works under some genericity\nassumptions which are easy to check. These assumptions are not so restrictive\nand are satisfied in the aforementioned application. As more general strategies\nfor real root classification do, our algorithm needs to compute the critical\nloci of some maps, intersections with the boundary of the semi-algebraic\ndomain, etc. In order to compute these objects, the determinantal structure is\nexploited through a stratifi-cation by the rank of the polynomial matrix. This\nspeeds up the computations by a factor 100. Furthermore, our implementation is\nable to solve the application in medical imagery, which was out of reach of\nmore general algorithms for real root classification. For instance,\ncomputational results show that the contrast problem where one of the matters\nis water is partitioned into three distinct classes.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00887v2"
    },
    {
        "title": "The complexity of cylindrical algebraic decomposition with respect to\n  polynomial degree",
        "authors": [
            "Matthew England",
            "James H. Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Cylindrical algebraic decomposition (CAD) is an important tool for working\nwith polynomial systems, particularly quantifier elimination. However, it has\ncomplexity doubly exponential in the number of variables. The base algorithm\ncan be improved by adapting to take advantage of any equational constraints\n(ECs): equations logically implied by the input. Intuitively, we expect the\ndouble exponent in the complexity to decrease by one for each EC. In ISSAC 2015\nthe present authors proved this for the factor in the complexity bound\ndependent on the number of polynomials in the input. However, the other term,\nthat dependent on the degree of the input polynomials, remained unchanged.\n  In the present paper the authors investigate how CAD in the presence of ECs\ncould be further refined using the technology of Groebner Bases to move towards\nthe intuitive bound for polynomial degree.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02494v1"
    },
    {
        "title": "Critical Point Computations on Smooth Varieties: Degree and Complexity\n  bounds",
        "authors": [
            "Mohab Safey El Din",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Let V $\\subset$ C n be an equidimensional algebraic set and g be an n-variate\npolynomial with rational coefficients. Computing the critical points of the map\nthat evaluates g at the points of V is a cornerstone of several algorithms in\nreal algebraic geometry and optimization. Under the assumption that the\ncritical locus is finite and that the projective closure of V is smooth, we\nprovide sharp upper bounds on the degree of the critical locus which depend\nonly on deg(g) and the degrees of the generic polar varieties associated to V.\nHence, in some special cases where the degrees of the generic polar varieties\ndo not reach the worst-case bounds, this implies that the number of critical\npoints of the evaluation map of g is less than the currently known degree\nbounds. We show that, given a lifting fiber of V , a slight variant of an\nalgorithm due to Bank, Giusti, Heintz, Lecerf, Matera and Solern{\\'o} computes\nthese critical points in time which is quadratic in this bound up to\nlogarithmic factors, linear in the complexity of evaluating the input system\nand polynomial in the number of variables and the maximum degree of the input\npolynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02518v1"
    },
    {
        "title": "Need Polynomial Systems be Doubly-exponential?",
        "authors": [
            "James H. Davenport",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Polynomial Systems, or at least their algorithms, have the reputation of\nbeing doubly-exponential in the number of variables [Mayr and Mayer, 1982],\n[Davenport and Heintz, 1988]. Nevertheless, the Bezout bound tells us that that\nnumber of zeros of a zero-dimensional system is singly-exponential in the\nnumber of variables. How should this contradiction be reconciled?\n  We first note that [Mayr and Ritscher, 2013] shows that the doubly\nexponential nature of Gr\\\"{o}bner bases is with respect to the dimension of the\nideal, not the number of variables. This inspires us to consider what can be\ndone for Cylindrical Algebraic Decomposition which produces a\ndoubly-exponential number of polynomials of doubly-exponential degree.\n  We review work from ISSAC 2015 which showed the number of polynomials could\nbe restricted to doubly-exponential in the (complex) dimension using McCallum's\ntheory of reduced projection in the presence of equational constraints. We then\ndiscuss preliminary results showing the same for the degree of those\npolynomials. The results are under primitivity assumptions whose importance we\nillustrate.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02912v1"
    },
    {
        "title": "Extended Hardness Results for Approximate Gröbner Basis Computation",
        "authors": [
            "Gwen Spencer"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Two models were recently proposed to explore the robust hardness of Gr\\\"obner\nbasis computation. Given a polynomial system, both models allow an algorithm to\nselectively ignore some of the polynomials: the algorithm is only responsible\nfor returning a Gr\\\"obner basis for the ideal generated by the remaining\npolynomials. For the $q$-Fractional Gr\\\"obner Basis Problem the algorithm is\nallowed to ignore a constant $(1-q)$-fraction of the polynomials (subject to\none natural structural constraint). Here we prove a new strongest-parameter\nresult: even if the algorithm is allowed to choose a $(3/10-\\epsilon)$-fraction\nof the polynomials to ignore, and need only compute a Gr\\\"obner basis with\nrespect to some lexicographic order for the remaining polynomials, this cannot\nbe accomplished in polynomial time (unless $P=NP$). This statement holds even\nif every polynomial has maximum degree 3. Next, we prove the first robust\nhardness result for polynomial systems of maximum degree 2: for the\n$q$-Fractional model a $(1/5-\\epsilon)$ fraction of the polynomials may be\nignored without losing provable NP-Hardness. Both theorems hold even if every\npolynomial contains at most three distinct variables. Finally, for the Strong\n$c$-partial Gr\\\"obner Basis Problem of De Loera et al. we give conditional\nresults that depend on famous (unresolved) conjectures of Khot and Dinur, et\nal.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.04472v1"
    },
    {
        "title": "Efficient Algorithms for Mixed Creative Telescoping",
        "authors": [
            "Alin Bostan",
            "Louis Dumont",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Creative telescoping is a powerful computer algebra paradigm -initiated by\nDoron Zeilberger in the 90's- for dealing with definite integrals and sums with\nparameters. We address the mixed continuous-discrete case, and focus on the\nintegration of bivariate hypergeometric-hyperexponential terms. We design a new\ncreative telescoping algorithm operating on this class of inputs, based on a\nHermite-like reduction procedure. The new algorithm has two nice features: it\nis efficient and it delivers, for a suitable representation of the input, a\nminimal-order telescoper. Its analysis reveals tight bounds on the sizes of the\ntelescoper it produces.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.05082v1"
    },
    {
        "title": "Computing Small Certificates of Inconsistency of Quadratic Fewnomial\n  Systems",
        "authors": [
            "Jean-Charles Faugere",
            "Pierre-Jean Spaenlehauer",
            "Jules Svartz"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  B{\\'e}zout 's theorem states that dense generic systems of n multivariate\nquadratic equations in n variables have 2 n solutions over algebraically closed\nfields. When only a small subset M of monomials appear in the equations\n(fewnomial systems), the number of solutions may decrease dramatically. We\nfocus in this work on subsets of quadratic monomials M such that generic\nsystems with support M do not admit any solution at all. For these systems,\nHilbert's Nullstellensatz ensures the existence of algebraic certificates of\ninconsistency. However, up to our knowledge all known bounds on the sizes of\nsuch certificates -including those which take into account the Newton polytopes\nof the polynomials- are exponential in n. Our main results show that if the\ninequality 2|M| -- 2n $\\le$ $\\sqrt$ 1 + 8{\\nu} -- 1 holds for a quadratic\nfewnomial system -- where {\\nu} is the matching number of a graph associated\nwith M, and |M| is the cardinality of M -- then there exists generically a\ncertificate of inconsistency of linear size (measured as the number of\ncoefficients in the ground field K). Moreover this certificate can be computed\nwithin a polynomial number of arithmetic operations. Next, we evaluate how\noften this inequality holds, and we give evidence that the probability that the\ninequality is satisfied depends strongly on the number of squares. More\nprecisely, we show that if M is picked uniformly at random among the subsets of\nn + k + 1 quadratic monomials containing at least $\\Omega$(n 1/2+$\\epsilon$)\nsquares, then the probability that the inequality holds tends to 1 as n grows.\nInterestingly, this phenomenon is related with the matching number of random\ngraphs in the Erd{\\\"o}s-Renyi model. Finally, we provide experimental results\nshowing that certificates in inconsistency can be computed for systems with\nmore than 10000 variables and equations.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.05889v1"
    },
    {
        "title": "Computation of the Similarity Class of the p-Curvature",
        "authors": [
            "Alin Bostan",
            "Xavier Caruso",
            "Eric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  The $p$-curvature of a system of linear differential equations in positive\ncharacteristic $p$ is a matrix that measures how far the system is from having\na basis of polynomial solutions. We show that the similarity class of the\n$p$-curvature can be determined without computing the $p$-curvature itself.\nMore precisely, we design an algorithm that computes the invariant factors of\nthe $p$-curvature in time quasi-linear in $\\sqrt p$. This is much less than the\nsize of the $p$-curvature, which is generally linear in $p$. The new algorithm\nallows to answer a question originating from the study of the Ising model in\nstatistical physics.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.06126v1"
    },
    {
        "title": "Bit complexity for multi-homogeneous polynomial system solving\n  Application to polynomial minimization",
        "authors": [
            "Mohab Safey El Din",
            "Eric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Multi-homogeneous polynomial systems arise in many applications. We provide\nbit complexity estimates for solving them which, up to a few extra other\nfactors, are quadratic in the number of solutions and linear in the height of\nthe input system under some genericity assumptions. The assumptions essentially\nimply that the Jacobian matrix of the system under study has maximal rank at\nthe solution set and that this solution set if finite. The algorithm is\nprobabilistic and a probability analysis is provided. Next, we apply these\nresults to the problem of optimizing a linear map on the real trace of an\nalgebraic set. Under some genericity assumptions, we provide bit complexity\nestimates for solving this polynomial minimization problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.07433v2"
    },
    {
        "title": "Sparse Rational Function Interpolation with Finitely Many Values for the\n  Coefficients",
        "authors": [
            "Qiao-Long Huang",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we give new sparse interpolation algorithms for black box\nunivariate and multivariate rational functions h=f/g whose coefficients are\nintegers with an upper bound. The main idea is as follows: choose a proper\ninteger beta and let h(beta) = a/b with gcd(a,b)=1. Then f and g can be\ncomputed by solving the polynomial interpolation problems f(beta)=ka and\ng(beta)=ka for some integer k. It is shown that the univariate interpolation\nalgorithm is almost optimal and multivariate interpolation algorithm has low\ncomplexity in T but the data size is exponential in n.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.00914v1"
    },
    {
        "title": "Algorithms for Weighted Sums of Squares Decomposition of Non-negative\n  Univariate Polynomials",
        "authors": [
            "Victor Magron",
            "Mohab Safey El Din",
            "Markus Schweighofer"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  It is well-known that every non-negative univariate real polynomial can be\nwritten as the sum of two polynomial squares with real coefficients. When one\nallows a weighted sum of finitely many squares instead of a sum of two squares,\nthen one can choose all coefficients in the representation to lie in the field\ngenerated by the coefficients of the polynomial.\n  In this article, we describe, analyze and compare both from the theoretical\nand practical points of view, two algorithms computing such a weighted sums of\nsquares decomposition for univariate polynomials with rational coefficients.\n  The first algorithm, due to the third author relies on real root isolation,\nquadratic approximations of positive polynomials and square-free decomposition\nbut its complexity was not analyzed. We provide bit complexity estimates, both\non runtime and output size of this algorithm. They are exponential in the\ndegree of the input univariate polynomial and linear in the maximum bitsize of\nits complexity. This analysis is obtained using quantifier elimination and root\nisolation bounds.\n  The second algorithm, due to Chevillard, Harrison, Joldes and Lauter, relies\non complex root isolation and square-free decomposition and has been introduced\nfor certifying positiveness of polynomials in the context of computer\narithmetics. Again, its complexity was not analyzed. We provide bit complexity\nestimates, both on runtime and output size of this algorithm, which are\npolynomial in the degree of the input polynomial and linear in the maximum\nbitsize of its complexity. This analysis is obtained using Vieta's formula and\nroot isolation bounds.\n  Finally, we report on our implementations of both algorithms. While the\nsecond algorithm is, as expected from the complexity result, more efficient on\nmost of examples, we exhibit families of non-negative polynomials for which the\nfirst algorithm is better.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.03941v1"
    },
    {
        "title": "Symbolic Versus Numerical Computation and Visualization of Parameter\n  Regions for Multistationarity of Biological Networks",
        "authors": [
            "Matthew England",
            "Hassan Errami",
            "Dima Grigoriev",
            "Ovidiu Radulescu",
            "Thomas Sturm",
            "Andreas Weber"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We investigate models of the mitogenactivated protein kinases (MAPK) network,\nwith the aim of determining where in parameter space there exist multiple\npositive steady states. We build on recent progress which combines various\nsymbolic computation methods for mixed systems of equalities and inequalities.\nWe demonstrate that those techniques benefit tremendously from a newly\nimplemented graph theoretical symbolic preprocessing method. We compare\ncomputation times and quality of results of numerical continuation methods with\nour symbolic approach before and after the application of our preprocessing.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.08794v1"
    },
    {
        "title": "Bivariate Extensions of Abramov's Algorithm for Rational Summation",
        "authors": [
            "Shaoshi Chen"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Abramov's algorithm enables us to decide whether a univariate rational\nfunction can be written as a difference of another rational function, which has\nbeen a fundamental algorithm for rational summation. In 2014, Chen and Singer\ngeneralized Abramov's algorithm to the case of rational functions in two\n($q$-)discrete variables. In this paper we solve the remaining three mixed\ncases, which completes our recent project on bivariate extensions of Abramov's\nalgorithm for rational summation.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.09134v1"
    },
    {
        "title": "An Effective Framework for Constructing Exponent Lattice Basis of\n  Nonzero Algebraic Numbers",
        "authors": [
            "Tao Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Computing a basis for the exponent lattice of algebraic numbers is a basic\nproblem in the field of computational number theory with applications to many\nother areas. The main cost of a well-known algorithm\n\\cite{ge1993algorithms,kauers2005algorithms} solving the problem is on\ncomputing the primitive element of the extended field generated by the given\nalgebraic numbers. When the extended field is of large degree, the problem\nseems intractable by the tool implementing the algorithm. In this paper, a\nspecial kind of exponent lattice basis is introduced. An important feature of\nthe basis is that it can be inductively constructed, which allows us to deal\nwith the given algebraic numbers one by one when computing the basis. Based on\nthis, an effective framework for constructing exponent lattice basis is\nproposed. Through computing a so-called pre-basis first and then solving some\nlinear Diophantine equations, the basis can be efficiently constructed. A new\ncertificate for multiplicative independence and some techniques for decreasing\ndegrees of algebraic numbers are provided to speed up the computation. The new\nalgorithm has been implemented with Mathematica and its effectiveness is\nverified by testing various examples. Moreover, the algorithm is applied to\nprogram verification for finding invariants of linear loops.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.02712v3"
    },
    {
        "title": "Aligator.jl - A Julia Package for Loop Invariant Generation",
        "authors": [
            "Andreas Humenberger",
            "Maximilian Jaroschek",
            "Laura Kovács"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We describe the Aligator.jl software package for automatically generating all\npolynomial invariants of the rich class of extended P-solvable loops with\nnested conditionals. Aligator.jl is written in the programming language Julia\nand is open-source. Aligator.jl transforms program loops into a system of\nalgebraic recurrences and implements techniques from symbolic computation to\nsolve recurrences, derive closed form solutions of loop variables and infer the\nideal of polynomial invariants by variable elimination based on Gr\\\"obner basis\ncomputation.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.05394v1"
    },
    {
        "title": "Putting Fürer Algorithm into Practice with the BPAS Library",
        "authors": [
            "Sviatoslav Covanov",
            "Davood Mohajerani",
            "Marc Moreno-Maza",
            "Lin-Xiao Wang"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Fast algorithms for integer and polynomial multiplication play an important\nrole in scientific computing as well as in other disciplines. In 1971,\nSch{\\\"o}nhage and Strassen designed an algorithm that improved the\nmultiplication time for two integers of at most $n$ bits to $\\mathcal{O}(\\log n\n\\log \\log n)$. In 2007, Martin F\\\"urer presented a new algorithm that runs in\n$O \\left(n \\log n\\ \\cdot 2^{O(\\log^* n)} \\right)$, where $\\log^* n$ is the\niterated logarithm of $n$.\n  We explain how we can put F\\\"urer's ideas into practice for multiplying\npolynomials over a prime field $\\mathbb{Z} / p \\mathbb{Z}$, for which $p$ is a\nGeneralized Fermat prime of the form $p = r^k + 1$ where $k$ is a power of $2$\nand $r$ is of machine word size. When $k$ is at least 8, we show that\nmultiplication inside such a prime field can be efficiently implemented via\nFast Fourier Transform (FFT). Taking advantage of Cooley-Tukey tensor formula\nand the fact that $r$ is a $2k$-th primitive root of unity in $\\mathbb{Z} / p\n\\mathbb{Z}$, we obtain an efficient implementation of FFT over $\\mathbb{Z} / p\n\\mathbb{Z}$. This implementation outperforms comparable implementations either\nusing other encodings of $\\mathbb{Z} / p \\mathbb{Z}$ or other ways to perform\nmultiplication in $\\mathbb{Z} / p \\mathbb{Z}$.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01490v1"
    },
    {
        "title": "Complexity Estimates for Fourier-Motzkin Elimination",
        "authors": [
            "Rui-Juan Jing",
            "Marc Moreno-Maza",
            "Delaram Talaashrafi"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this paper, we propose a new method for removing all the redundant\ninequalities generated by Fourier-Motzkin elimination. This method is based on\nan improved version of Balas' work and can also be used to remove all the\nredundant inequalities in the input system. Moreover, our method only uses\narithmetic operations on matrices and avoids resorting to linear programming\ntechniques. Algebraic complexity estimates and experimental results show that\nour method outperforms alternative approaches, in particular those based on\nlinear programming and simplex algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01510v2"
    },
    {
        "title": "Linear Differential Equations as a Data-Structure",
        "authors": [
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  A lot of information concerning solutions of linear differential equations\ncan be computed directly from the equation. It is therefore natural to consider\nthese equations as a data-structure, from which mathematical properties can be\ncomputed. A variety of algorithms has thus been designed in recent years that\ndo not aim at \"solving\", but at computing with this representation. Many of\nthese results are surveyed here.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08616v1"
    },
    {
        "title": "On Exact Reznick, Hilbert-Artin and Putinar's Representations",
        "authors": [
            "Victor Magron",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We consider the problem of computing exact sums of squares (SOS)\ndecompositions for certain classes of non-negative multivariate polynomials,\nrelying on semidefinite programming (SDP) solvers.\n  We provide a hybrid numeric-symbolic algorithm computing exact rational SOS\ndecompositions with rational coefficients for polynomials lying in the interior\nof the SOS cone. The first step of this algorithm computes an approximate SOS\ndecomposition for a perturbation of the input polynomial with an\narbitrary-precision SDP solver. Next, an exact SOS decomposition is obtained\nthanks to the perturbation terms and a compensation phenomenon. We prove that\nbit complexity estimates on output size and runtime are both singly exponential\nin the cardinality of the Newton polytope (or doubly exponential in the number\nof variables). Next, we apply this algorithm to compute exact Reznick,\nHilbert-Artin's representation and Putinar's representations respectively for\npositive definite forms and positive polynomials over basic compact\nsemi-algebraic sets. We also report on practical experiments done with the\nimplementation of these algorithms and existing alternatives such as the\ncritical point method and cylindrical algebraic decomposition.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.10062v4"
    },
    {
        "title": "Chordal Graphs in Triangular Decomposition in Top-Down Style",
        "authors": [
            "Chenqi Mou",
            "Yang Bai",
            "Jiahua Lai"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this paper, we first prove that when the associated graph of a polynomial\nset is chordal, a particular triangular set computed by a general algorithm in\ntop-down style for computing the triangular decomposition of this polynomial\nset has an associated graph as a subgraph of this chordal graph. Then for\nWang's method and a subresultant-based algorithm for triangular decomposition\nin top-down style and for a subresultant-based algorithm for regular\ndecomposition in top-down style, we prove that all the polynomial sets\nappearing in the process of triangular decomposition with any of these\nalgorithms have associated graphs as subgraphs of this chordal graph. These\ntheoretical results can be viewed as non-trivial polynomial generalization of\nexisting ones for sparse Gaussian elimination, inspired by which we further\npropose an algorithm for sparse triangular decomposition in top-down style by\nmaking use of the chordal structure of the polynomial set. The effectiveness of\nthe proposed algorithm for triangular decomposition, when the polynomial set is\nchordal and sparse with respect to the variables, is demonstrated by\npreliminary experimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.11023v1"
    },
    {
        "title": "On Fast Matrix Inversion via Fast Matrix Multiplication",
        "authors": [
            "Zak Tonks"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Volker Strassen first suggested an algorithm to multiply matrices with worst\ncase running time less than the conventional $\\mathcal{O}(n^3)$ operations in\n1969. He also presented a recursive algorithm with which to invert matrices,\nand calculate determinants using matrix multiplication. James R. Bunch & John\nE. Hopcroft improved upon this in 1974 by providing modifications to the\ninversion algorithm in the case where principal submatrices were singular,\namongst other improvements. We cover the case of multivariate polynomial matrix\ninversion, where it is noted that conventional methods that assume a field will\nexperience major setbacks. Initially, the author and others published a\npresentation of a fraction free formulation of inversion via matrix\nmultiplication along with motivations, however analysis of this presentation\nwas rudimentary. We hence provide a discussion of the true complexities of this\nfraction free method arising from matrix multiplication, and arrive at its\nlimitations.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.00904v1"
    },
    {
        "title": "Spectral Approach to Verifying Non-linear Arithmetic Circuits",
        "authors": [
            "Cunxi Yu",
            "Tiankai Su",
            "Atif Yasin",
            "Maciej Ciesielski"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  This paper presents a fast and effective computer algebraic method for\nanalyzing and verifying non-linear integer arithmetic circuits using a novel\nalgebraic spectral model. It introduces a concept of algebraic spectrum, a\nnumerical form of polynomial expression; it uses the distribution of\ncoefficients of the monomials to determine the type of arithmetic function\nunder verification. In contrast to previous works, the proof of functional\ncorrectness is achieved by computing an algebraic spectrum combined with a\nlocal rewriting of word-level polynomials. The speedup is achieved by\npropagating coefficients through the circuit using And-Inverter Graph (AIG)\ndatastructure. The effectiveness of the method is demonstrated with experiments\nincluding standard and Booth multipliers, and other synthesized non-linear\narithmetic circuits up to 1024 bits containing over 12 million gates.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.02950v1"
    },
    {
        "title": "Signature-based Möller's algorithm for strong Gröbner bases over\n  PIDs",
        "authors": [
            "Maria Francis",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Signature-based algorithms are the latest and most efficient approach as of\ntoday to compute Gr\\\"obner bases for polynomial systems over fields. Recently,\npossible extensions of these techniques to general rings have attracted the\nattention of several authors.\n  In this paper, we present a signature-based version of M\\\"oller's classical\nvariant of Buchberger's algorithm for computing strong Gr\\\"obner bases over\nPrincipal Ideal Domains (or PIDs). It ensures that the signatures do not\ndecrease during the algorithm, which makes it possible to apply classical\nsignature criteria for further optimization. In particular, with the F5\ncriterion, the signature version of M\\\"oller's algorithm computes a Gr\\\"obner\nbasis without reductions to zero for a polynomial system given by a regular\nsequence. We also show how Buchberger's chain criterion can be implemented so\nas to be compatible with the signatures.\n  We prove correctness and termination of the algorithm. Furthermore, we have\nwritten a toy implementation in Magma, allowing us to quantitatively compare\nthe efficiency of the various criteria for eliminating S-pairs.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.09586v1"
    },
    {
        "title": "Effective certification of approximate solutions to systems of equations\n  involving analytic functions",
        "authors": [
            "Michael Burr",
            "Kisun Lee",
            "Anton Leykin"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We develop algorithms for certifying an approximation to a nonsingular\nsolution of a square system of equations built from univariate analytic\nfunctions. These algorithms are based on the existence of oracles for\nevaluating basic data about the input analytic functions. One approach for\ncertification is based on alpha-theory while the other is based on the Krawczyk\ngeneralization of Newton's iteration. We show that the necessary oracles exist\nfor D-finite functions and compare the two algorithmic approaches for this case\nusing our software implementation in SageMath.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.10384v2"
    },
    {
        "title": "Computing the Characteristic Polynomial of a Finite Rank Two Drinfeld\n  Module",
        "authors": [
            "Yossef Musleh",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Motivated by finding analogues of elliptic curve point counting techniques,\nwe introduce one deterministic and two new Monte Carlo randomized algorithms to\ncompute the characteristic polynomial of a finite rank-two Drinfeld module. We\ncompare their asymptotic complexity to that of previous algorithms given by\nGekeler, Narayanan and Garai-Papikian and discuss their practical behavior. In\nparticular, we find that all three approaches represent either an improvement\nin complexity or an expansion of the parameter space over which the algorithm\nmay be applied. Some experimental results are also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12731v1"
    },
    {
        "title": "Computing strong regular characteristic pairs with Groebner bases",
        "authors": [
            "Rina Dong",
            "Dongming Wang"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The W-characteristic set of a polynomial ideal is the minimal triangular set\ncontained in the reduced lexicographical Groebner basis of the ideal. A pair\n(G,C) of polynomial sets is a strong regular characteristic pair if G is a\nreduced lexicographical Groebner basis, C is the W-characteristic set of the\nideal <G>, the saturated ideal sat(C) of C is equal to <G>, and C is regular.\nIn this paper, we show that for any polynomial ideal I with given generators\none can either detect that I is unit, or construct a strong regular\ncharacteristic pair (G,C) by computing Groebner bases such that\nI$\\subseteq$sat(C)=<G> and sat(C) divides I, so the ideal I can be split into\nthe saturated ideal sat(C) and the quotient ideal I:sat(C). Based on this\nstrategy of splitting by means of quotient and with Groebner basis and ideal\ncomputations, we devise a simple algorithm to decompose an arbitrary polynomial\nset F into finitely many strong regular characteristic pairs, from which two\nrepresentations for the zeros of F are obtained: one in terms of strong regular\nGroebner bases and the other in terms of regular triangular sets. We present\nsome properties about strong regular characteristic pairs and characteristic\ndecomposition and illustrate the proposed algorithm and its performance by\nexamples and experimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.13537v2"
    },
    {
        "title": "An Algorithm for Computing a Minimal Comprehensive Gröbner\\, Basis of\n  a Parametric Polynomial System",
        "authors": [
            "Deepak Kapur",
            "Yiming Yang"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  An algorithm to generate a minimal comprehensive Gr\\\"obner\\, basis of a\nparametric polynomial system from an arbitrary faithful comprehensive\nGr\\\"obner\\, system is presented. A basis of a parametric polynomial ideal is a\ncomprehensive Gr\\\"obner\\, basis if and only if for every specialization of\nparameters in a given field, the specialization of the basis is a Gr\\\"obner\\,\nbasis of the associated specialized polynomial ideal. The key idea used in\nensuring minimality is that of a polynomial being essential with respect to a\ncomprehensive Gr\\\"obner\\, basis. The essentiality check is performed by\ndetermining whether a polynomial can be covered for various specializations by\nother polynomials in the associated branches in a comprehensive Gr\\\"obner\\,\nsystem. The algorithm has been implemented and successfully tried on many\nexamples from the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07957v1"
    },
    {
        "title": "Generic bivariate multi-point evaluation, interpolation and modular\n  composition with precomputation",
        "authors": [
            "Vincent Neiger",
            "Johan Rosenkilde",
            "Grigory Solomatov"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Suppose $\\mathbb{K}$ is a large enough field and $\\mathcal{P} \\subset\n\\mathbb{K}^2$ is a fixed, generic set of points which is available for\nprecomputation. We introduce a technique called \\emph{reshaping} which allows\nus to design quasi-linear algorithms for both: computing the evaluations of an\ninput polynomial $f \\in \\mathbb{K}[x,y]$ at all points of $\\mathcal{P}$; and\ncomputing an interpolant $f \\in \\mathbb{K}[x,y]$ which takes prescribed values\non $\\mathcal{P}$ and satisfies an input $y$-degree bound. Our genericity\nassumption is explicit and we prove that it holds for most point sets over a\nlarge enough field. If $\\mathcal{P}$ violates the assumption, our algorithms\nstill work and the performance degrades smoothly according to a distance from\nbeing generic. To show that the reshaping technique may have an impact on other\nrelated problems, we apply it to modular composition: suppose generic\npolynomials $M \\in \\mathbb{K}[x]$ and $A \\in \\mathbb{K}[x]$ are available for\nprecomputation, then given an input $f \\in \\mathbb{K}[x,y]$ we show how to\ncompute $f(x, A(x)) \\operatorname{rem} M(x)$ in quasi-linear time.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12468v2"
    },
    {
        "title": "A Family of Denominator Bounds for First Order Linear Recurrence Systems",
        "authors": [
            "Mark van Hoeij",
            "Moulay Barkatou",
            "Johannes Middeke"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  For linear recurrence systems, the problem of finding rational solutions is\nreduced to the problem of computing polynomial solutions by computing a content\nbound or a denominator bound. There are several bounds in the literature. The\nsharpest bound leads to polynomial solutions of lower degrees, but this\nadvantage need not compensate for the time spent on computing that bound.\n  To strike the best balance between sharpness of the bound versus CPU time\nspent obtaining it, we will give a family of bounds. The $J$'th member of this\nfamily is similar to (Abramov, Barkatou, 1998) when $J=1$, similar to (van\nHoeij, 1998) when $J$ is large, and novel for intermediate values of $J$, which\ngive the best balance between sharpness and CPU time.\n  The setting for our content bounds are systems $\\tau(Y) = MY$ where $\\tau$ is\nan automorphism of a UFD, and $M$ is an invertible matrix with entries in its\nfield of fractions. This setting includes the shift case, the $q$-shift case,\nthe multi-basic case and others. We give two versions, a global version, and a\nversion that bounds each entry separately.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.02926v1"
    },
    {
        "title": "On Minor Left Prime Factorization Problem for Multivariate Polynomial\n  Matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  A new necessary and sufficient condition for the existence of minor left\nprime factorizations of multivariate polynomial matrices without full row rank\nis presented. The key idea is to establish a relationship between a matrix and\nits full row rank submatrix. Based on the new result, we propose an algorithm\nfor factorizing matrices and have implemented it on the computer algebra system\nMaple. Two examples are given to illustrate the effectiveness of the algorithm,\nand experimental data shows that the algorithm is efficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.06998v1"
    },
    {
        "title": "On Factor Left Prime Factorization Problems for Multivariate Polynomial\n  Matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  This paper is concerned with factor left prime factorization problems for\nmultivariate polynomial matrices without full row rank. We propose a necessary\nand sufficient condition for the existence of factor left prime factorizations\nof a class of multivariate polynomial matrices, and then design an algorithm to\ncompute all factor left prime factorizations if they exist. We implement the\nalgorithm on the computer algebra system Maple, and two examples are given to\nillustrate the effectiveness of the algorithm. The results presented in this\npaper are also true for the existence of factor right prime factorizations of\nmultivariate polynomial matrices without full column rank.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.07007v1"
    },
    {
        "title": "New Remarks on the Factorization and Equivalence Problems for a Class of\n  Multivariate Polynomial Matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  This paper is concerned with the factorization and equivalence problems of\nmultivariate polynomial matrices. We present some new criteria for the\nexistence of matrix factorizations for a class of multivariate polynomial\nmatrices, and obtain a necessary and sufficient condition for the equivalence\nof a square polynomial matrix and a diagonal matrix. Based on the constructive\nproof of the new criteria, we give a factorization algorithm and prove the\nuniqueness of the factorization. We implement the algorithm on Maple, and two\nillustrative examples are given to show the effectiveness of the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.07088v1"
    },
    {
        "title": "Creative Telescoping on Multiple Sums",
        "authors": [
            "Christoph Koutschan",
            "Elaine Wong"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We showcase a collection of practical strategies to deal with a problem\narising from an analysis of integral estimators derived via quasi-Monte Carlo\nmethods. The problem reduces to a triple binomial sum, thereby enabling us to\nopen up the holonomic toolkit, which contains tools such as creative\ntelescoping that can be used to deduce a recurrence satisfied by the sum. While\napplying these techniques, a host of issues arose that partly needed to be\nresolved by hand. In other words, no creative telescoping implementation\ncurrently exists that can resolve all these issues automatically. Thus, we felt\nthe need to compile the different strategies we tried and the difficulties that\nwe encountered along the way. In particular, we highlight the necessity of the\ncertificate in these computations and how its complexity can greatly influence\nthe computation time.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08889v2"
    },
    {
        "title": "LDU factorization",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  LU-factorization of matrices is one of the fundamental algorithms of linear\nalgebra. The widespread use of supercomputers with distributed memory requires\na review of traditional algorithms, which were based on the common memory of a\ncomputer. Matrix block recursive algorithms are a class of algorithms that\nprovide coarse-grained parallelization. The block recursive LU factorization\nalgorithm was obtained in 2010. This algorithm is called LEU-factorization. It,\nlike the traditional LU-algorithm, is designed for matrices over number fields.\nHowever, it does not solve the problem of numerical instability. We propose a\ngeneralization of the LEU algorithm to the case of a commutative domain and its\nfield of quotients. This LDU factorization algorithm decomposes the matrix over\nthe commutative domain into a product of three matrices, in which the matrices\nL and U belong to the commutative domain, and the elements of the weighted\ntruncated permutation matrix D are the elements inverse to the product of some\npair of minors. All elements are calculated without errors, so the problem of\ninstability does not arise.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.04108v1"
    },
    {
        "title": "Representation of hypergeometric products of higher nesting depths in\n  difference rings",
        "authors": [
            "Evans Doe Ocansey",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  A non-trivial symbolic machinery is presented that can rephrase\nalgorithmically a finite set of nested hypergeometric products in appropriately\ndesigned difference rings. As a consequence, one obtains an alternative\nrepresentation in terms of one single product defined over a root of unity and\nnested hypergeometric products which are algebraically independent among each\nother. In particular, one can solve the zero-recognition problem: the input\nexpression of nested hypergeometric products evaluates to zero if and only if\nthe output expression is the zero expression. Combined with available symbolic\nsummation algorithms in the setting of difference rings, one obtains a general\nmachinery that can represent (and simplify) nested sums defined over nested\nproducts.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.08775v1"
    },
    {
        "title": "Some fast algorithms multiplying a matrix by its adjoint",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clément Pernet",
            "Alexandre Sedoglavic"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We present a non-commutative algorithm for the multiplication of a 2 x 2\nblock-matrix by its adjoint, defined by a matrix ring anti-homomorphism. This\nalgorithm uses 5 block products (3 recursive calls and 2 general products)over\nC or in positive characteristic. The resulting algorithm for arbitrary\ndimensions is a reduction of multiplication of a matrix by its adjoint to\ngeneral matrix product, improving by a constant factor previously known\nreductions. We prove also that there is no algorithm derived from bilinear\nforms using only four products and the adjoint of one of them. Second we give\nnovel dedicated algorithms for the complex field and the quaternions to\nalternatively compute the multiplication taking advantage of the structure of\nthe matrix-polynomial arithmetic involved. We then analyze the respective\nranges of predominance of the two strategies. Finally we propose schedules with\nlow memory footprint that support a fast and memory efficient practical\nimplementation over a prime field.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.01025v1"
    },
    {
        "title": "PTOPO: Computing the Geometry and the Topology of Parametric Curves",
        "authors": [
            "Christina Katsamaki",
            "Fabrice Rouillier",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We consider the problem of computing the topology and describing the geometry\nof a parametric curve in $\\mathbb{R}^n$. We present an algorithm, PTOPO, that\nconstructs an abstract graph that is isotopic to the curve in the embedding\nspace. Our method exploits the benefits of the parametric representation and\ndoes not resort to implicitization.\n  Most importantly, we perform all computations in the parameter space and not\nin the implicit space. When the parametrization involves polynomials of degree\nat most $d$ and maximum bitsize of coefficients $\\tau$, then the worst case bit\ncomplexity of PTOPO is $\n\\tilde{\\mathcal{O}}_B(nd^6+nd^5\\tau+d^4(n^2+n\\tau)+d^3(n^2\\tau+\nn^3)+n^3d^2\\tau)$. This bound matches the current record bound\n$\\tilde{\\mathcal{O}}_B(d^6+d^5\\tau)$ for the problem of computing the topology\nof a plane algebraic curve given in implicit form. For plane and space curves,\nif $N = \\max\\{d, \\tau \\}$, the complexity of PTOPO becomes\n$\\tilde{\\mathcal{O}}_B(N^6)$, which improves the state-of-the-art result, due\nto Alc\\'azar and D\\'iaz-Toca [CAGD'10], by a factor of $N^{10}$. In the same\ntime complexity, we obtain a graph whose straight-line embedding is isotopic to\nthe curve. However, visualizing the curve on top of the abstract graph\nconstruction, increases the bound to $\\tilde{\\mathcal{O}}_B(N^7)$. For curves\nof general dimension, we can also distinguish between ordinary and non-ordinary\nreal singularities and determine their multiplicities in the same expected\ncomplexity of PTOPO by employing the algorithm of Blasco and P\\'erez-D\\'iaz\n[CAGD'19]. We have implemented PTOPO in Maple for the case of plane and space\ncurves. Our experiments illustrate its practical nature.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.01925v2"
    },
    {
        "title": "Telescopers for differential forms with one parameter",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Ziming Li",
            "Michael F. Singer",
            "Stephen Watt"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Telescopers for a function are linear differential (resp. difference)\noperators annihilated by the definite integral (resp. definite sum) of this\nfunction. They play a key role in Wilf-Zeilberger theory and algorithms for\ncomputing them have been extensively studied in the past thirty years. In this\npaper, we introduce the notion of telescopers for differential forms with\n$D$-finite function coefficients. These telescopers appear in several areas of\nmathematics, for instance parametrized differential Galois theory and mirror\nsymmetry. We give a sufficient and necessary condition for the existence of\ntelescopers for a differential form and describe a method to compute them if\nthey exist. Algorithms for verifying this condition are also given.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.06576v2"
    },
    {
        "title": "On the computation of asymptotic critical values of polynomial maps and\n  applications",
        "authors": [
            "Jérémy Berthomieu",
            "Andrew Ferguson",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Let $\\mathbf{f} = \\left(f_1, \\dots, f_p\\right) $ be a polynomial tuple in\n$\\mathbb{Q}[z_1, \\dots, z_n]$ and let $d = \\max_{1 \\leq i \\leq p} \\deg f_i$. We\nconsider the problem of computing the set of asymptotic critical values of the\npolynomial mapping, with the assumption that this mapping is dominant,\n$\\mathbf{f}: z \\in \\mathbb{K}^n \\to (f\\_1(z), \\dots, f\\_p(z)) \\in \\mathbb{K}^p$\nwhere $\\mathbb{K}$ is either $\\mathbb{R}$ or $\\mathbb{C}$. This is the set of\nvalues $c$ in the target space of $\\mathbf{f}$ such that there exists a\nsequence of points $(\\mathbf{x}_i)_{i\\in \\mathbb{N}}$ for which\n$\\mathbf{f}(\\mathbf{x}_i)$ tends to $c$ and $\\|\\mathbf{x}_i\\| \\kappa {\\rm d}\n\\mathbf{f}(\\mathbf{x}_i))$ tends to $0$ when $i$ tends to infinity where ${\\rm\nd} \\mathbf{f}$ is the differential of $\\mathbf{f}$ and $\\kappa$ is a function\nmeasuring the distance of a linear operator to the set of singular linear\noperators from $\\mathbb{K}^n$ to $\\mathbb{K}^p$. Computing the union of the\nclassical and asymptotic critical values allows one to put into practice\ngeneralisations of Ehresmann's fibration theorem. This leads to natural and\nefficient applications in polynomial optimisation and computational real\nalgebraic geometry. Going back to previous works by Kurdyka, Orro and Simon, we\ndesign new algorithms to compute asymptotic critical values. Through\nrandomisation, we introduce new geometric characterisations of asymptotic\ncritical values. This allows us to dramatically reduce the complexity of\ncomputing such values to a cost that is essentially $O(d^{2n(p+1)})$ arithmetic\noperations in $\\mathbb{Q}$. We also obtain tighter degree bounds on a\nhypersurface containing the asymptotic critical values, showing that the degree\nis at most $p^{n-p+1}(d-1)^{n-p}(d+1)^{p}$. Next, we show how to apply these\nalgorithms to unconstrained polynomial optimisation problems and the problem of\ncomputing sample points per connected component of a semi-algebraic set defined\nby a single inequality/inequation. We report on the practical capabilities of\nour implementation of this algorithm. It shows how the practical efficiency\nsurpasses the current state-of-the-art algorithms for computing asymptotic\ncritical values by tackling examples that were previously out of reach.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.00913v1"
    },
    {
        "title": "Computing the Characteristic Polynomial of Generic Toeplitz-like and\n  Hankel-like Matrices",
        "authors": [
            "Clément Pernet",
            "Hippolyte Signargout",
            "Pierre Karpman",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  New algorithms are presented for computing annihilating polynomials of\nToeplitz, Hankel, and more generally Toeplitz+ Hankel-like matrices over a\nfield. Our approach follows works on Coppersmith's block Wiedemann method with\nstructured projections, which have been recently successfully applied for\ncomputing the bivariate resultant. A first baby-step/giant step approach --\ndirectly derived using known techniques on structured matrices -- gives a\nrandomized Monte Carlo algorithm for the minimal polynomial of an $n\\times n$\nToeplitz or Hankel-like matrix of displacement rank $\\alpha$ using $\\tilde\nO(n^{\\omega - c(\\omega)} \\alpha^{c(\\omega)})$ arithmetic operations, where\n$\\omega$ is the exponent of matrix multiplication and $c(2.373)\\approx 0.523$\nfor the best known value of $\\omega$. For generic Toeplitz+Hankel-like matrices\na second algorithm computes the characteristic polynomial in $\\tilde\nO(n^{2-1/\\omega})$ operations when the displacement rank is considered\nconstant. Previous algorithms required $O(n^2)$ operations while the exponents\npresented here are respectively less than $1.86$ and $1.58$ with the best known\nestimate for $\\omega$.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.02497v1"
    },
    {
        "title": "msolve: A Library for Solving Polynomial Systems",
        "authors": [
            "Jérémy Berthomieu",
            "Christian Eder",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We present a new open source C library \\texttt{msolve} dedicated to solving\nmultivariate polynomial systems of dimension zero through computer algebra\nmethods. The core algorithmic framework of \\texttt{msolve} relies on Gr\\''obner\nbases and linear algebra based algorithms for polynomial system solving. It\nrelies on Gr\\''obner basis computation w.r.t.\\ the degree reverse\nlexicographical order, Gr\\''obner conversion to a lexicographical Gr\\''obner\nbasis and real solving of univariate polynomials. We explain in detail how\nthese three main steps of the solving process are implemented, how we exploit\n\\texttt{AVX2} instruction processors and the more general implementation ideas\nwe put into practice to better exploit the computational capabilities of this\nalgorithmic framework. We compare the practical performances of \\texttt{msolve}\nwith leading computer algebra systems such as \\textsc{Magma}, \\textsc{Maple},\n\\textsc{Singular} on a wide range of systems with finitely many complex\nsolutions, showing that \\texttt{msolve} can tackle systems which were out of\nreach by the computer algebra software state-of-the-art.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.03572v2"
    },
    {
        "title": "The D-plus Discriminant and Complexity of Root Clustering",
        "authors": [
            "Jing Yang",
            "Chee K. Yap"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Let $p(x)$ be an integer polynomial with $m\\ge 2$ distinct roots\n$\\rho_1,\\ldots,\\rho_m$ whose multiplicities are\n$\\boldsymbol{\\mu}=(\\mu_1,\\ldots,\\mu_m)$. We define the D-plus discriminant of\n$p(x)$ to be $D^+(p):= \\prod_{1\\le i<j\\le m}(\\rho_i-\\rho_j)^{\\mu_i+\\mu_j}$. We\nfirst prove a conjecture that $D^+(p)$ is a $\\boldsymbol{\\mu}$-symmetric\nfunction of its roots $\\rho_1,\\ldots,\\rho_m$. Our main result gives an explicit\nformula for $D^+(p)$, as a rational function of its coefficients. Our proof is\nideal-theoretic, based on re-casting the classic Poisson resultant as the\n\"symbolic Poisson formula\". The D-plus discriminant first arose in the\ncomplexity analysis of a root clustering algorithm from Becker et al. (ISSAC\n2016). The bit-complexity of this algorithm is proportional to a quantity\n$\\log(|D^+(p)|^{-1})$. As an application of our main result, we give an\nexplicit upper bound on this quantity in terms of the degree of $p$ and its\nleading coefficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03856v2"
    },
    {
        "title": "Computing the dimension of real algebraic sets",
        "authors": [
            "Piere Lairez",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Let $V$ be the set of real common solutions to $F = (f_1, \\ldots, f_s)$ in\n$\\mathbb{R}[x_1, \\ldots, x_n]$ and $D$ be the maximum total degree of the\n$f_i$'s. We design an algorithm which on input $F$ computes the dimension of\n$V$. Letting $L$ be the evaluation complexity of $F$ and $s=1$, it runs using\n$O^\\sim \\big (L D^{n(d+3)+1}\\big )$ arithmetic operations in $\\mathbb{Q}$ and\nat most $D^{n(d+1)}$ isolations of real roots of polynomials of degree at most\n$D^n$. Our algorithm depends on the real geometry of $V$; its practical\nbehavior is more governed by the number of topology changes in the fibers of\nsome well-chosen maps. Hence, the above worst-case bounds are rarely reached in\npractice, the factor $D^{nd}$ being in general much lower on practical\nexamples. We report on an implementation showing its ability to solve problems\nwhich were out of reach of the state-of-the-art implementations.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10255v2"
    },
    {
        "title": "Resultant-based Elimination in Ore Algebra",
        "authors": [
            "Raqeeb Rasheed"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We consider resultant-based methods for elimination of indeterminates of Ore\npolynomial systems in Ore algebra. We start with defining the concept of\nresultant for bivariate Ore polynomials then compute it by the Dieudonne\ndeterminant of the polynomial coefficients. Additionally, we apply\nnoncommutative versions of evaluation and interpolation techniques to the\ncomputation process to improve the efficiency of the method. The implementation\nof the algorithms will be performed in Maple to evaluate the performance of the\napproaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.14799v3"
    },
    {
        "title": "The DEWCAD Project: Pushing Back the Doubly Exponential Wall of\n  Cylindrical Algebraic Decomposition",
        "authors": [
            "R. Bradford",
            "J. H. Davenport",
            "M. England",
            "A. Sadeghimanesh",
            "A. Uncu"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  This abstract seeks to introduce the ISSAC community to the DEWCAD project,\nwhich is based at Coventry University and the University of Bath, in the United\nKingdom. The project seeks to push back the Doubly Exponential Wall of\nCylindrical Algebraic Decomposition, through the integration of SAT/SMT\ntechnology, the extension of Lazard projection theory, and the development of\nnew algorithms based on CAD technology but without producing CADs themselves.\nThe project also seeks to develop applications of CAD and will focus on\napplications in the domains of economics and bio-network analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.08740v1"
    },
    {
        "title": "Certifying a probabilistic parallel modular algorithm for rational\n  univariate representation",
        "authors": [
            "Bernard Parisse"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  This paper is about solving polynomial systems. It first recalls how to do\nthat efficiently with a very high probability of correctness by reconstructing\na rational univariate representation (rur) using Groebner revlex computation,\nBerlekamp-Massey algorithm and Hankel linear system solving modulo several\nprimes in parallel. Then it introduces a new method (theorem \\ref{prop:check})\nfor rur certification that is effective for most polynomial systems.These\nalgorithms are implemented in\nhttps://www-fourier.univ-grenoble-alpes.fr/~parisse/giac.html since version\n1.7.0-13 or 1.7.0-17 for certification, it has (July 2021) leading performances\non multiple CPU, at least for an open-source software.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.10912v3"
    },
    {
        "title": "Multivariate Power Series in Maple",
        "authors": [
            "Mohammadali Asadi",
            "Alexander Brandt",
            "Mahsa Kazemi",
            "Marc Moreno Maza",
            "Erik Postma"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We present MultivariatePowerSeries, a Maple library introduced in Maple 2021,\nproviding a variety of methods to study formal multivariate power series and\nunivariate polynomials over such series. This library offers a simple and\neasy-to-use user interface. Its implementation relies on lazy evaluation\ntechniques and takes advantage of Maple's features for object-oriented\nprogramming. The exposed methods include Weierstrass Preparation Theorem and\nfactorization via Hensel's lemma. The computational performance is demonstrated\nby means of an experimental comparison with software counterparts.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.15519v1"
    },
    {
        "title": "Polynomial-Division-Based Algorithms for Computing Linear Recurrence\n  Relations",
        "authors": [
            "Jérémy Berthomieu",
            "Jean-Charles Faugère"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Sparse polynomial interpolation, sparse linear system solving or modular\nrational reconstruction are fundamental problems in Computer Algebra. They come\ndown to computing linear recurrence relations of a sequence with the\nBerlekamp-Massey algorithm. Likewise, sparse multivariate polynomial\ninterpolation and multidimensional cyclic code decoding require guessing linear\nrecurrence relations of a multivariate sequence.Several algorithms solve this\nproblem. The so-called Berlekamp-Massey-Sakata algorithm (1988) uses polynomial\nadditions and shifts by a monomial. The Scalar-FGLM algorithm (2015) relies on\nlinear algebra operations on a multi-Hankel matrix, a multivariate\ngeneralization of a Hankel matrix. The Artinian Gorenstein border basis\nalgorithm (2017) uses a Gram-Schmidt process.We propose a new algorithm for\ncomputing the Gr{\\\"o}bner basis of the ideal of relations of a sequence based\nsolely on multivariate polynomial arithmetic. This algorithm allows us to both\nrevisit the Berlekamp-Massey-Sakata algorithm through the use of polynomial\ndivisions and to completely revise the Scalar-FGLM algorithm without linear\nalgebra operations.A key observation in the design of this algorithm is to work\non the mirror of the truncated generating series allowing us to use polynomial\narithmetic modulo a monomial ideal. It appears to have some similarities with\nPad{\\'e} approximants of this mirror polynomial.As an addition from the paper\npublished at the ISSAC conferance, we give an adaptive variant of this\nalgorithm taking into account the shape of the final Gr{\\\"o}bner basis\ngradually as it is discovered. The main advantage of this algorithm is that its\ncomplexity in terms of operations and sequence queries only depends on the\noutput Gr{\\\"o}bner basis.All these algorithms have been implemented in Maple\nand we report on our comparisons.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.02582v1"
    },
    {
        "title": "Digital Collections of Examples in Mathematical Sciences",
        "authors": [
            "James Harold Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Some aspects of Computer Algebra (notably Computation Group Theory and\nComputational Number Theory) have some good databases of examples, typically of\nthe form \"all the X up to size n\". But most of the others, especially on the\npolynomial side, are lacking such, despite the utility they have demonstrated\nin the related fields of SAT and SMT solving. We claim that the field would be\nenhanced by such community-maintained databases, rather than each author\nhand-selecting a few, which are often too large or error-prone to print, and\ntherefore difficult for subsequent authors to reproduce.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.12908v2"
    },
    {
        "title": "ATLAS: Interactive and Educational Linear Algebra System Containing\n  Non-Standard Methods",
        "authors": [
            "Akhilesh Pai",
            "James Harold Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  While there are numerous linear algebra teaching tools, they tend to be\nfocused on the basics, and not handle the more advanced aspects. This project\naims to fill that gap, focusing specifically on methods like Strassen's fast\nmatrix multiplication.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.13942v1"
    },
    {
        "title": "Computer algebra in Julia",
        "authors": [
            "Dmitry S. Kulyabov",
            "Anna V. Korolkova"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Recently, the place of the main programming language for scientific and\nengineering computations has been little by little taken by Julia. Some users\nwant to work completely within the Julia framework as they work within the\nPython framework. There are libraries for Julia that cover the majority of\nscientific and engineering computations demands. The aim of this paper is to\ncombine the usage of the Julia framework for numerical computations and for\nsymbolic computations in mathematical modeling problems. The main functional\ndomains determining various variants of the application of computer algebra\nsystems are described. In each of these domains, generic representatives of\ncomputer algebra systems in Julia are distinguished. The conclusion is that it\nis possible (and even convenient) to use computer algebra systems within the\nJulia framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12301v1"
    },
    {
        "title": "On the representation of non-holonomic univariate power series",
        "authors": [
            "Bertrand Teguia Tabuguia",
            "Wolfram Koepf"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Holonomic functions play an essential role in Computer Algebra since they\nallow the application of many symbolic algorithms. Among all algorithmic\nattempts to find formulas for power series, the holonomic property remains the\nmost important requirement to be satisfied by the function under consideration.\nThe targeted functions mainly summarize that of meromorphic functions. However,\nexpressions like $\\tan(z)$, $z/(\\exp(z)-1)$, $\\sec(z)$, etc., particularly,\nreciprocals, quotients and compositions of holonomic functions, are generally\nnot holonomic. Therefore their power series are inaccessible by the holonomic\nframework. From the mathematical dictionaries, one can observe that most of the\nknown closed-form formulas of non-holonomic power series involve another\nsequence whose evaluation depends on some finite summations. In the case of\n$\\tan(z)$ and $\\sec(z)$ the corresponding sequences are the Bernoulli and Euler\nnumbers, respectively. Thus providing a symbolic approach that yields complete\nrepresentations when linear summations for power series coefficients of\nnon-holonomic functions appear, might be seen as a step forward towards the\nrepresentation of non-holonomic power series.\n  By adapting the method of ansatz with undetermined coefficients, we build an\nalgorithm that computes least-order quadratic differential equations with\npolynomial coefficients for a large class of non-holonomic functions. A\ndifferential equation resulting from this procedure is converted into a\nrecurrence equation by applying the Cauchy product formula and rewriting powers\ninto polynomials and derivatives into shifts. Finally, using enough initial\nvalues we are able to give normal form representations to characterize several\nnon-holonomic power series and prove non-trivial identities. We discuss this\nalgorithm and its implementation for Maple 2022.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.09574v3"
    },
    {
        "title": "Computing elements of certain form in ideals to prove properties of\n  operators",
        "authors": [
            "Clemens Hofstadler",
            "Clemens G. Raab",
            "Georg Regensburger"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Proving statements about linear operators expressed in terms of identities\noften leads to finding elements of certain form in noncommutative polynomial\nideals. We illustrate this by examples coming from actual operator statements\nand discuss relevant algorithmic methods for finding such polynomials based on\nnoncommutative Gr\\\"obner bases. In particular, we present algorithms for\ncomputing the intersection of a two-sided ideal with a one-sided ideal as well\nas for computing homogeneous polynomials in two-sided ideals and monomials in\none-sided ideals. All methods presented in this work are implemented in the\nMathematica package OperatorGB.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.12933v2"
    },
    {
        "title": "A Symbolic Approach to Detecting Hardware Trojans Triggered by Don't\n  Care Transitions",
        "authors": [
            "Ruochen Dai",
            "Tuba Yavuz"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Due to the globalization of Integrated Circuit (IC) supply chain, hardware\ntrojans and the attacks that can trigger them have become an important security\nissue. One type of hardware Trojans leverages the don't care transitions in\nFinite State Machines (FSMs) of hardware designs. In this paper, we present a\nsymbolic approach to detecting don't care transitions and the hidden Trojans.\nOur detection approach works at both RTL and gate-level, does not require a\ngolden design, and works in three stages. In the first stage, it explores the\nreachable states. In the second stage, it performs an approximate analysis to\nfind the don't care transitions. In the third stage, it performs a state-space\nexploration from reachable states that have incoming don't care transitions to\nfind behavioral discrepancies with respect to what has been observed in the\nfirst stage. We also present a pruning technique based on the reachability of\nFSM states. We present a methodology that leverages both RTL and gate-level for\nsoundness and efficiency. Specifically, we show that don't care transitions\nmust be detected at the gate-level, i.e., after synthesis has been performed,\nfor soundness. However, under specific conditions, Trojan detection can be\nperformed more efficiently at RTL. Evaluation of our approach on a set of\nbenchmarks from OpenCores and TrustHub and using gate-level representation\ngenerated by two synthesis tools, Yosys and Synopsis Design Compiler (SDC),\nshows that our approach is both efficient (up to 10X speedup w.r.t. no pruning)\nand precise (0% false positives) in detecting don't care transitions and the\nTrojans that leverage them. Additionally, the total analysis time can achieve\nup to 3.40X (using Yosys) and 2.52X (SDC) speedup when synthesis preserves the\nFSM structure and the Trojan detection is performed at RTL.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.03989v1"
    },
    {
        "title": "A fast algorithm for computing the Smith normal form with multipliers\n  for a nonsingular integer matrix",
        "authors": [
            "Stavros Birmpilis",
            "George Labahn",
            "Arne Storjohann"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  A Las Vegas randomized algorithm is given to compute the Smith multipliers\nfor a nonsingular integer matrix $A$, that is, unimodular matrices $U$ and $V$\nsuch that $AV=US$, with $S$ the Smith normal form of $A$. The expected running\ntime of the algorithm is about the same as required to multiply together two\nmatrices of the same dimension and size of entries as $A$. Explicit bounds are\ngiven for the size of the entries in both unimodular multipliers. The main tool\nused by the algorithm is the Smith massager, a relaxed version of $V$, the\nunimodular matrix specifying the column operations of the Smith computation.\nFrom the perspective of efficiency, the main tools used are fast linear solving\nand partial linearization of integer matrices. As an application of the Smith\nwith multipliers algorithm, a fast algorithm is given to find the fractional\npart of the inverse of the input matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09949v2"
    },
    {
        "title": "Quasi-equivalence of heights in algebraic function fields of one\n  variable",
        "authors": [
            "Ruyong Feng",
            "Shuang Feng",
            "Li-Yong Shen"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  For points $(a,b)$ on an algebraic curve over a field $K$ with height\n$\\mathfrak{h}$, the asymptotic relation between $\\mathfrak{h}(a)$ and\n$\\mathfrak{h}(b)$ has been extensively studied in diophantine geometry. When\n$K=\\overline{k(t)}$ is the field of algebraic functions in $t$ over a field $k$\nof characteristic zero, Eremenko in 1998 proved the following quasi-equivalence\nfor an absolute logarithmic height $\\mathfrak{h}$ in $K$: Given $P\\in K[X,Y]$\nirreducible over $K$ and $\\epsilon>0$, there is a constant $C$ only depending\non $P$ and $\\epsilon$ such that for each $(a,b)\\in K^2$ with $P(a,b)=0$, $$\n  (1-\\epsilon) \\deg(P,Y) \\mathfrak{h}(b)-C \\leq \\deg(P,X) \\mathfrak{h}(a) \\leq\n(1+\\epsilon) \\deg(P,Y) \\mathfrak{h}(b)+C. $$ In this article, we shall give an\nexplicit bound for the constant $C$ in terms of the total degree of $P$, the\nheight of $P$ and $\\epsilon$. This result is expected to have applications in\nsome other areas such as symbolic computation of differential and difference\nequations.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.13025v1"
    },
    {
        "title": "A Method for the Automated Discovery of Angle Theorems",
        "authors": [
            "Philip Todd"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  The Naive Angle Method, used by Geometry Expressions for solving problems\nwhich involve only angle constraints, represents a geometrical configuration as\na sparse linear system. Linear systems with the same underlying matrix\nstructure underpin a number of different geometrical theorems. We use a graph\ntheoretical approach to define a generalization of the matrix structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.00543v1"
    },
    {
        "title": "Simple algorithm for GCD of polynomials",
        "authors": [
            "Pasquale Nardone",
            "Giorgio Sonnino"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Based on the Bezout approach we propose a simple algorithm to determine the\n{\\tt gcd} of two polynomials which doesn't need division, like the Euclidean\nalgorithm, or determinant calculations, like the Sylvester matrix algorithm.\nThe algorithm needs only $n$ steps for polynomials of degree $n$. Formal\nmanipulations give the discriminant or the resultant for any degree without\nneeding division nor determinant calculation.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06940v1"
    },
    {
        "title": "Symbolic-Numeric Integration of Univariate Expressions based on Sparse\n  Regression",
        "authors": [
            "Shahriar Iravanian",
            "Carl Julius Martensen",
            "Alessandro Cheli",
            "Shashi Gowda",
            "Anand Jain",
            "Yingbo Ma",
            "Chris Rackauckas"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Most computer algebra systems (CAS) support symbolic integration as core\nfunctionality. The majority of the integration packages use a combination of\nheuristic algebraic and rule-based (integration table) methods. In this paper,\nwe present a hybrid (symbolic-numeric) methodology to calculate the indefinite\nintegrals of univariate expressions. The primary motivation for this work is to\nadd symbolic integration functionality to a modern CAS (the symbolic\nmanipulation packages of SciML, the Scientific Machine Learning ecosystem of\nthe Julia programming language), which is mainly designed toward numerical and\nmachine learning applications and has a different set of features than\ntraditional CAS. The symbolic part of our method is based on the combination of\ncandidate terms generation (borrowed from the Homotopy operators theory) with\nrule-based expression transformations provided by the underlying CAS. The\nnumeric part is based on sparse-regression, a component of Sparse\nIdentification of Nonlinear Dynamics (SINDy) technique. We show that this\nsystem can solve a large variety of common integration problems using only a\nfew dozen basic integration rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.12468v2"
    },
    {
        "title": "On the computation of Gröbner bases for matrix-weighted homogeneous\n  systems",
        "authors": [
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this paper, we examine the structure of systems that are weighted\nhomogeneous for several systems of weights, and how it impacts the computation\nof Gr\\\"obner bases. We present several linear algebra algorithms for computing\nGr\\\"obner bases for systems with this structure, either directly or by reducing\nto existing structures. We also present suitable optimization techniques.\n  As an opening towards complexity studies, we discuss potential definitions of\nregularity and prove that they are generic if non-empty. Finally, we present\nexperimental data from a prototype implementation of the algorithms in\nSageMath.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05742v3"
    },
    {
        "title": "Square-free Strong Triangular Decomposition of Zero-dimensional\n  Polynomial Systems",
        "authors": [
            "Haokun Li",
            "Bican Xia",
            "Tianqi Zhao"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Triangular decomposition with different properties has been used for various\ntypes of problem solving, e.g. geometry theorem proving, real solution\nisolation of zero-dimensional polynomial systems, etc. In this paper, the\nconcepts of strong chain and square-free strong triangular decomposition\n(SFSTD) of zero-dimensional polynomial systems are defined. Because of its good\nproperties, SFSTD may be a key way to many problems related to zero-dimensional\npolynomial systems, such as real solution isolation and computing radicals of\nzero-dimensional ideals. Inspired by the work of Wang and of Dong and Mou, we\npropose an algorithm for computing SFSTD based on Gr\\\"obner bases computation.\nThe novelty of the algorithm is that we make use of saturated ideals and\nseparant to ensure that the zero sets of any two strong chains have no\nintersection and every strong chain is square-free, respectively. On one hand,\nwe prove that the arithmetic complexity of the new algorithm can be single\nexponential in the square of the number of variables, which seems to be among\nthe rare complexity analysis results for triangular-decomposition methods. On\nthe other hand, we show experimentally that, on a large number of examples in\nthe literature, the new algorithm is far more efficient than a popular\ntriangular-decomposition method based on pseudo-division. Furthermore, it is\nalso shown that, on those examples, the methods based on SFSTD for real\nsolution isolation and for computing radicals of zero-dimensional ideals are\nvery efficient.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06044v1"
    },
    {
        "title": "Guessing with Little Data",
        "authors": [
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Reconstructing a hypothetical recurrence equation from the first terms of an\ninfinite sequence is a classical and well-known technique in experimental\nmathematics. We propose a variation of this technique which can succeed with\nfewer input terms.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07966v2"
    },
    {
        "title": "Desingularization and p-Curvature of Recurrence Operators",
        "authors": [
            "Yi Zhou",
            "Mark van Hoeij"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Linear recurrence operators in characteristic $p$ are classified by their\n$p$-curvature. For a recurrence operator $L$, denote by $\\chi(L)$ the\ncharacteristic polynomial of its $p$-curvature. We can obtain information about\nthe factorization of $L$ by factoring $\\chi(L)$. The main theorem of this paper\ngives an unexpected relation between $\\chi(L)$ and the true singularities of\n$L$. An application is to speed up a fast algorithm for computing $\\chi(L)$ by\ndesingularizing $L$ first. Another contribution of this paper is faster\ndesingularization.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.08931v1"
    },
    {
        "title": "A New Type of Gröbner Basis and Its Complexity",
        "authors": [
            "Sheng-Ming Ma"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  The new type of ideal basis introduced herein constitutes a compromise\nbetween the Gr\\\"obner bases based on the Buchberger's algorithm and the\ncharacteristic sets based on the Wu's method. It reduces the complexity of the\ntraditional Gr\\\"obner bases and subdues the notorious intermediate expression\nswell problem and intermediate coefficient swell problem to a substantial\nextent. The computation of an $S$-polynomial for the new bases requires at most\n$O(m\\ln^2m\\ln\\ln m)$ word operations whereas $O(m^6\\ln^2m)$ word operations are\nrequisite in the Buchberger's algorithm. Here $m$ denotes the upper bound for\nthe numbers of terms both in the leading coefficients and for the rest of the\npolynomials. The new bases are for zero-dimensional polynomial ideals and based\non univariate pseudo-divisions. However in contrast to the pseudo-divisions in\nthe Wu's method for the characteristic sets, the new bases retain the algebraic\ninformation of the original ideal and in particular, solve the ideal membership\nproblem. In order to determine the authentic factors of the eliminant, we\nanalyze the multipliers of the pseudo-divisions and develop an algorithm over\nprincipal quotient rings with zero divisors.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09493v1"
    },
    {
        "title": "A Signature-based Algorithm for Computing the Nondegenerate Locus of a\n  Polynomial System",
        "authors": [
            "Christian Eder",
            "Pierre Lairez",
            "Rafael Mohr",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Polynomial system solving arises in many application areas to model\nnon-linear geometric properties. In such settings, polynomial systems may come\nwith degeneration which the end-user wants to exclude from the solution set.\nThe nondegenerate locus of a polynomial system is the set of points where the\ncodimension of the solution set matches the number of equations. Computing the\nnondegenerate locus is classically done through ideal-theoretic operations in\ncommutative algebra such as saturation ideals or equidimensional decompositions\nto extract the component of maximal codimension. By exploiting the algebraic\nfeatures of signature-based Gr\\\"obner basis algorithms we design an algorithm\nwhich computes a Gr\\\"obner basis of the equations describing the closure of the\nnondegenerate locus of a polynomial system, without computing first a Gr\\\"obner\nbasis for the whole polynomial system.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13784v2"
    },
    {
        "title": "On the complexity of invariant polynomials under the action of finite\n  reflection groups",
        "authors": [
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Let $\\mathbb{K}[x_1, \\dots, x_n]$ be a multivariate polynomial ring over a\nfield $\\mathbb{K}$. Let $(u_1, \\dots, u_n)$ be a sequence of $n$ algebraically\nindependent elements in $\\mathbb{K}[x_1, \\dots, x_n]$. Given a polynomial $f$\nin $\\mathbb{K}[u_1, \\dots, u_n]$, a subring of $\\mathbb{K}[x_1, \\dots, x_n]$\ngenerated by the $u_i$'s, we are interested infinding the unique polynomial\n$f_{\\rm new}$ in $\\mathbb{K}[e_1,\\dots, e_n]$, where $e_1, \\dots, e_n$ are new\nvariables, such that $f_{\\mathrm{new}}(u_1, \\dots, u_n) = f(x_1, \\dots, x_n)$.\nWe provide an algorithm and analyze its arithmetic complexity to compute\n$f_{\\mathrm{new}}$ knowing $f$ and $(u_1, \\dots, u_n)$.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04123v2"
    },
    {
        "title": "Computing critical points for algebraic systems defined by\n  hyperoctahedral invariant polynomials",
        "authors": [
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Let $\\mathbb{K}$ be a field of characteristic zero and $\\mathbb{K}[x_1,\n\\dots, x_n]$ the corresponding multivariate polynomial ring. Given a sequence\nof $s$ polynomials $\\mathbf{f} = (f_1, \\dots, f_s)$ and a polynomial $\\phi$,\nall in $\\mathbb{K}[x_1, \\dots, x_n]$ with $s<n$, we consider the problem of\ncomputing the set $W(\\phi, \\mathbf{f})$ of points at which $\\mathbf{f}$\nvanishes and the Jacobian matrix of $\\mathbf{f}, \\phi$ with respect to $x_1,\n\\dots, x_n$ does not have full rank. This problem plays an essential role in\nmany application areas.\n  In this paper we focus on a case where the polynomials are all invariant\nunder the action of the signed symmetric group $B_n$. We introduce a notion\ncalled {\\em hyperoctahedral representation} to describe $B_n$-invariant sets.\nWe study the invariance properties of the input polynomials to split $W(\\phi,\n\\mathbf{f})$ according to the orbits of $B_n$ and then design an algorithm\nwhose output is a {hyperoctahedral representation} of $W(\\phi, \\mathbf{f})$.\nThe runtime of our algorithm is polynomial in the total number of points\ndescribed by the output.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.16094v2"
    },
    {
        "title": "Reachability Analysis of Linear System",
        "authors": [
            "Shiping Chen",
            "Xinyu Ge"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this paper, we propose a decision procedure of reachability for linear\nsystem {\\xi}' = A{\\xi} + u, where the matrix A's eigenvalues can be arbitrary\nalgebraic numbers and the input u is a vector of trigonometric-exponential\npolynomials. If the initial set contains only one point, the reachability\nproblem under consideration is resorted to the decidability of the sign of\ntrigonometric-exponential polynomial and then achieved by being reduced to\nverification of a series of univariate polynomial inequalities through Taylor\nexpansions of the related exponential functions and trigonometric functions. If\nthe initial set is open semi-algebraic, we will propose a decision procedure\nbased on openCAD and an algorithm of real roots isolation derivated from the\nsign-deciding procedure for the trigonometric-exponential polynomials. The\nexperimental results indicate the efficiency of our approach. Furthermore, the\nabove procedures are complete under the assumption of Schanuel Conjecture\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00230v1"
    },
    {
        "title": "A Vergleichsstellensatz of Strassen's Type for a Noncommutative\n  Preordered Semialgebra through the Semialgebra of its Fractions",
        "authors": [
            "Tao Zheng",
            "Lihong Zhi"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Preordered semialgebras and semirings are two kinds of algebraic structures\noccurring in real algebraic geometry frequently and usually play important\nroles therein. They have many interesting and promising applications in the\nfields of real algebraic geometry, probability theory, theoretical computer\nscience, quantum information theory, \\emph{etc.}. In these applications,\nStrassen's Vergleichsstellensatz and its generalized versions, which are\nanalogs of those Positivstellens\\\"atze in real algebraic geometry, play\nimportant roles. While these Vergleichsstellens\\\"atze accept only a commutative\nsetting (for the semirings in question), we prove in this paper a\nnoncommutative version of one of the generalized Vergleichsstellens\\\"atze\nproposed by Fritz [\\emph{Comm. Algebra}, 49 (2) (2021), pp. 482-499]. The most\ncrucial step in our proof is to define the semialgebra of the fractions of a\nnoncommutative semialgebra, which generalizes the definitions in the\nliterature. Our new Vergleichsstellensatz characterizes the relaxed preorder on\na noncommutative semialgebra induced by all monotone homomorphisms to\n$\\mathbb{R}_+$ by three other equivalent conditions on the semialgebra of its\nfractions equipped with the derived preorder, which may result in more\napplications in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.02577v3"
    },
    {
        "title": "Calculation of Integrals in MathPartner",
        "authors": [
            "Gennadi I. Malaschonok",
            "Alexandr V. Seliverstov"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We present the possibilities provided by the MathPartner service of\ncalculating definite and indefinite integrals. MathPartner contains software\nimplementation of the Risch algorithm and provides users with the ability to\ncompute antiderivatives for elementary functions. Certain integrals, including\nimproper integrals, can be calculated using numerical algorithms. In this case,\nevery user has the ability to indicate the required accuracy with which he\nneeds to know the numerical value of the integral. We highlight special\nfunctions allowing us to calculate complete elliptic integrals. These include\nfunctions for calculating the arithmetic-geometric mean and the\ngeometric-harmonic mean, which allow us to calculate the complete elliptic\nintegrals of the first kind. The set also includes the modified\narithmetic-geometric mean, proposed by Semjon Adlaj, which allows us to\ncalculate the complete elliptic integrals of the second kind as well as the\ncircumference of an ellipse. The Lagutinski algorithm is of particular\ninterest. For given differentiation in the field of bivariate rational\nfunctions, one can decide whether there exists a rational integral. The\nalgorithm is based on calculating the Lagutinski determinant. Mikhail\nLagutinski (1871--1915) had worked at Kharkiv (Ukraine). This year we are\ncelebrating his 150th anniversary.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.11061v1"
    },
    {
        "title": "New features in MathPartner 2021",
        "authors": [
            "Gennadi Malaschonok",
            "Alexandr Seliverstov"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We introduce new features in the MathPartner service that have recently\nbecome available to users. We highlight the functions for calculating both\narithmetic-geometric mean and geometric-harmonic mean. They allow calculating\ncomplete elliptic integrals of the first kind. They are useful for solving many\nphysics problems, for example, one can calculate the period of a simple\npendulum. Next, one can calculate the modified arithmetic-geometric mean\nproposed by Semjon Adlaj. Consequently, one can calculate the complete elliptic\nintegrals of the second kind as well as the circumference of an ellipse.\nFurthermore, one can also calculate the Sylvester matrices of the first and the\nsecond kind. Thus, by means of a few strings, one can calculate the resultant\nof two polynomials as well as the discriminant of a binary form. Some new\nmatrix functions are also added. So, today the list of matrix functions\nincludes the transpose, adjugate, conjugate, inverse, generalized inverse, and\npseudo inverse of a matrix, the matrix determinant, the kernel, the echelon\nform, the characteristic polynomial, the Bruhat decomposition, the triangular\nLSU decomposition, which is an exact block recursive LU decomposition, the QR\nblock recursive decomposition, and the singular value decomposition. In\naddition, two block-recursive functions have been implemented for calculating\nthe Cholesky decomposition of symmetric positive-definite matrices: one\nfunction for sparse matrices with the standard multiplication algorithm and\nanother function for dense matrices with multiplication according to the\nWinograd--Strassen algorithm. The linear programming problems can be solved\ntoo. So, the MathPartner service has become better and handy. It is freely\navailable at http://mathpar.ukma.edu.ua/ as well as at http://mathpar.com.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.11118v1"
    },
    {
        "title": "MathPartner Computer Algebra",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this paper, we describe general characteristics of the MathPartner\ncomputer algebra system (CAS) and Mathpar programming language thereof.\nMathPartner can be used for scientific and engineering calculations, as well as\nin high schools and universities. It allows one to carry out both simple\ncalculations (acting as a scientific calculator) and complex calculations with\nlarge-scale mathematical objects. Mathpar is a procedural language; it supports\na large number of elementary and special functions, as well as matrix and\npolynomial operators. This service allows one to build function images and\nanimate them. MathPartner also makes it possible to solve some symbolic\ncomputation problems on supercomputers with distributed memory. We highlight\nmain differences of MathPartner from other CASs and describe the Mathpar\nlanguage along with the user service provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.11549v1"
    },
    {
        "title": "Order-Degree-Height Surfaces for Linear Operators",
        "authors": [
            "Hui Huang",
            "Manuel Kauers",
            "Gargi Mukherjee"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  It is known for linear operators with polynomial coefficients annihilating a\ngiven D-finite function that there is a trade-off between order and degree.\nRaising the order may give room for lowering the degree. The relationship\nbetween order and degree is typically described by a hyperbola known as the\norder-degree curve. In this paper, we add the height into the picture, i.e., a\nmeasure for the size of the coefficients in the polynomial coefficients. For\ncertain situations, we derive relationships between order, degree, and height\nthat can be viewed as order-degree-height surfaces.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.06030v1"
    },
    {
        "title": "Symbolic-Numeric Factorization of Differential Operators",
        "authors": [
            "Frédéric Chyzak",
            "Alexandre Goyer",
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We present a symbolic-numeric Las Vegas algorithm for factoring Fuchsian\nordinary differential operators with rational function coefficients. The new\nalgorithm combines ideas of van Hoeij's \"local-to-global\" method and of the\n''analytic'' approach proposed by van der Hoeven. It essentially reduces to the\nformer in ''easy'' cases where the local-to-global method succeeds, and to an\noptimized variant of the latter in the \"hardest\" cases, while handling\nintermediate cases more efficiently than both.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08991v3"
    },
    {
        "title": "Synthesizing Mathematical Identities with E-Graphs",
        "authors": [
            "Ian Briggs",
            "Pavel Panchekha"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Identities compactly describe properties of a mathematical expression and can\nbe leveraged into faster and more accurate function implementations. However,\nidentities must currently be discovered manually, which requires a lot of\nexpertise. We propose a two-phase synthesis and deduplication pipeline that\ndiscovers these identities automatically. In the synthesis step, a set of\nrewrite rules is composed, using an e-graph, to discover candidate identities.\nHowever, most of these candidates are duplicates, which a secondary\ndeduplication step discards using integer linear programming and another\ne-graph. Applied to a set of 61 benchmarks, the synthesis phase generates 7215\ncandidate identities which the deduplication phase then reduces down to 125\ncore identities.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.07086v1"
    },
    {
        "title": "About MathPartner web service",
        "authors": [
            "Gennadi Malaschonok",
            "Ivan Borisov"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  The report is devoted to the current state of the MathPartner computer\nalgebra web project. We discuss the main directions of development of the\nproject and give several examples of using it to solve selected problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.07088v1"
    },
    {
        "title": "Accelerated Subdivision for Clustering Roots of Polynomials given by\n  Evaluation Oracles",
        "authors": [
            "Rémi Imbach",
            "Victor Y. Pan"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In our quest for the design, the analysis and the implementation of a\nsubdivision algorithm for finding the complex roots of univariate polynomials\ngiven by oracles for their evaluation, we present sub-algorithms allowing\nsubstantial acceleration of subdivision for complex roots clustering for such\npolynomials. We rely on Cauchy sums which approximate power sums of the roots\nin a fixed complex disc and can be computed in a small number of evaluations\n--polylogarithmic in the degree. We describe root exclusion, root counting,\nroot radius approximation and a procedure for contracting a disc towards the\ncluster of root it contains, called $\\varepsilon$-compression. To demonstrate\nthe efficiency of our algorithms, we combine them in a prototype root\nclustering algorithm. For computing clusters of roots of polynomials that can\nbe evaluated fast, our implementation competes advantageously with user's\nchoice for root finding, MPsolve.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.08622v1"
    },
    {
        "title": "New heuristic to choose a cylindrical algebraic decomposition variable\n  ordering motivated by complexity analysis",
        "authors": [
            "Tereso del Río",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  It is well known that the variable ordering can be critical to the efficiency\nor even tractability of the cylindrical algebraic decomposition (CAD)\nalgorithm. We propose new heuristics inspired by complexity analysis of CAD to\nchoose the variable ordering. These heuristics are evaluated against existing\nheuristics with experiments on the SMT-LIB benchmarks using both existing\nperformance metrics and a new metric we propose for the problem at hand. The\nbest of these new heuristics chooses orderings that lead to timings on average\n17% slower than the virtual-best: an improvement compared to the prior\nstate-of-the-art which achieved timings 25% slower.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.13480v1"
    },
    {
        "title": "Guessing With Quadratic Differential Equations",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  By holonomic guessing, we denote the process of finding a linear differential\nequation with polynomial coefficients satisfied by the generating function of a\nsequence, for which only a few first terms are known. Holonomic guessing has\nbeen used in computer algebra for over three decades to demonstrate the value\nof the guess-and-prove paradigm in intuition processes preceding proofs, as\npropagated in The Art of Solving (Polya, 1978). Among the prominent packages\nused to perform guessing, one can cite the Maple Gfun package of Salvy and\nZimmermann; the Mathematica GeneratingFunctions package of Mallinger; and the\nSage ore_algebra package of Kauers, Jaroschek, and Johansson.\n  We propose an approach that extends holonomic guessing by allowing the\ntargeted differential equations to be of degree at most two. Consequently, it\nenables us to capture more generating functions than just holonomic functions.\nThe corresponding recurrence equations are similar to known equations for the\nBernoulli, Euler, and Bell numbers. As a result, our software finds the correct\nrecurrence and differential equations for the generating functions of the\nup/down numbers (https://oeis.org/A000111), the evaluations of the zeta\nfunction at positive even integers, the Taylor coefficients of the Lambert W\nfunction, and many more. Our Maple implementation ($delta2guess$) is part of\nthe FPS package which can be downloaded at\nhttp://www.mathematik.uni-kassel.de/~bteguia/FPS_webpage/FPS.htm\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01037v1"
    },
    {
        "title": "Bit Complexity of Polynomial GCD on Sparse Representation",
        "authors": [
            "Qiao-Long Huang",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  An input- and output-sensitive GCD algorithm for multi-variate polynomials\nover finite fields is proposed by combining the modular method with the\nBen-Or/Tiwari sparse interpolation. The bit complexity of the algorithm is\ngiven and is sensitive to the sparse representation, while for previous sparse\nGCD algorithms, the complexities were given only in some special cases. It is\nshown that the new algorithm is superior both in theory and in practice\ncomparing with existing GCD algorithms: the complexity in the degree is\ndecreased from quadratic to linear and the running times are decreased by 1-3\norders of magnitude in various benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.13874v1"
    },
    {
        "title": "A Note on the Games-Chan Algorithm",
        "authors": [
            "Graham H. Norton"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  The Games-Chan algorithm finds the minimal period of a periodic binary\nsequence of period $2^n$, in $n$ iterations. We generalise this to periodic\n$q$-ary sequences (where $q$ is a prime power) using generating functions and\npolynomials and apply this to find the multiplicity of $x-1$ in a $q$-ary\npolynomial $f$ in $\\log_{\\,q}\\deg(f)$ iterations.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.00148v2"
    },
    {
        "title": "SC-Square: Overview to 2021",
        "authors": [
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  This extended abstract was written to accompany an invited talk at the 2021\nSC-Square Workshop, where the author was asked to give an overview of SC-Square\nprogress to date. The author first reminds the reader of the definition of\nSC-Square, then briefly outlines some of the history, before picking out some\n(personal) scientific highlights.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04359v1"
    },
    {
        "title": "Clifford algebra in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Here I present the 'clifford' package for working with Clifford algebras in\nthe R programming language. The algebra is described and package idiom is\ngiven.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.13659v2"
    },
    {
        "title": "Disordered vectors in R: introducing the disordR package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Objects in the {\\tt stl map} class of {\\tt C++} associate a value to each of\na set of keys. Accessing values or keys of such an object is problematic in the\nR programming language because the value-key pairs are not stored in a\nwell-defined order. This document motivates and discusses the concept of\n\"disordered vector\" as implemented by the {\\tt disordR} package which\nfacilitates the handling of {\\tt map} objects. Values and keys of a map are\nstored in an implementation-specific way so certain extraction and replacement\noperations should be forbidden. For example, if values are real, then the\n\"first\" value is implementation specific\\ldots but the maximum value has a\nwell-defined result. The {\\tt disordR} package makes forbidden operations\nimpossible while allowing transparent R idiom for permitted operations. An\nillustrative R session is given in which the package is used abstractly,\nwithout reference to any particular application, and then shows how it can be\nused to manipulate multivariate polynomials. The {\\tt disordR} package is a\ndependency of {\\tt clifford}, {\\tt freealg}, {\\tt hyper2}, {\\tt mvp}, {\\tt\nspray}, {\\tt stokes}, and {\\tt weyl}. The {\\tt disordR} package is available on\nCRAN at \\url{https://CRAN.R-project.org/package=disordR}.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.03856v2"
    },
    {
        "title": "Sparse arrays in R: the spray package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this short article I introduce the spray package, which provides some\nfunctionality for handling sparse arrays. The package uses the C++ Standard\nTemplate Library's map class to store and retrieve elements. One natural\napplication for sparse arrays is multivariate polynomials and I give two\nexamples of the package in use, one drawn from the fields of random walks on\nlattices and one from the field of recreational combinatorics. The package is\navailable on CRAN at https://CRAN.R-project.org/package=spray.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.10848v1"
    },
    {
        "title": "Reductions in Higher-Order Rewriting and Their Equivalence",
        "authors": [
            "Pablo Barenbaum",
            "Eduardo Bonelli"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Proof terms are syntactic expressions that represent computations in term\nrewriting. They were introduced by Meseguer and exploited by van Oostrom and de\nVrijer to study equivalence of reductions in (left-linear) first-order term\nrewriting systems. We study the problem of extending the notion of proof term\nto higher-order rewriting, which generalizes the first-order setting by\nallowing terms with binders and higher-order substitution. In previous works\nthat devise proof terms for higher-order rewriting, such as Bruggink's, it has\nbeen noted that the challenge lies in reconciling composition of proof terms\nand higher-order substitution (\\b{eta}-equivalence). This led Bruggink to\nreject \"nested\" composition, other than at the outermost level. In this paper,\nwe propose a notion of higher-order proof term we dub rewrites that supports\nnested composition. We then define two notions of equivalence on rewrites,\nnamely permutation equivalence and projection equivalence, and show that they\ncoincide. We also propose a standardization procedure, that computes a\ncanonical representative of the permutation equivalence class of a rewrite.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.15654v2"
    },
    {
        "title": "Fast multivariate polynomials in R: the mvp package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this short article I introduce the mvp package, which provides some\nfunctionality for handling multivariate polynomials. The package uses the C++\nStandard Template Library's map class to store and retrieve elements; it\nconforms to disordR discipline for coefficients. The package is available on\nCRAN at https://CRAN.R-project.org/package=mvp.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.15991v1"
    },
    {
        "title": "Stokes's theorem in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this short article I introduce the stokes package which provides\nfunctionality for working with tensors, alternating forms, wedge products, and\nrelated concepts from the exterior calculus. Notation and spirit follow Spivak.\nStokes's generalized integral theorem, viz $\\int_{\\partial X}\\phi=\\int_Xd\\phi$,\nis demonstrated here using the package; it is available on CRAN\nathttps://CRAN.R-project.org/package=stokes.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.17008v1"
    },
    {
        "title": "The free algebra in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  The free algebra is an interesting and useful algebraic object. Here I\nintroduce \"freealg\", an R package which furnishes computational support for\nfree algebras. The package uses the standard template library's \"map\" class for\nefficiency, which uses the fact that the order of the terms is algebraically\nimmaterial. The package follows \"disordR\" discipline. I demonstrate some\nproperties of free algebra using the package, and showcase package idiom. The\npackage is available on CRAN at https://CRAN.R-project.org/package=freealg.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.04002v1"
    },
    {
        "title": "Flip Graphs for Matrix Multiplication",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We introduce a new method for discovering matrix multiplication schemes based\non random walks in a certain graph, which we call the flip graph. Using this\nmethod, we were able to reduce the number of multiplications for the matrix\nformats (4, 4, 5) and (5, 5, 5), both in characteristic two and for arbitrary\nground fields.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01175v1"
    },
    {
        "title": "The free group in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Here I present the freegroup package for working with the free group on a\nfinite set of symbols. The package is vectorised; internally it uses an\nefficient matrix-based representation for free group objects but uses a\nconfigurable print method. A range of R-centric functionality is provided. It\nis available on CRAN at https://CRAN.R-project.org/package=freegroup.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.05883v1"
    },
    {
        "title": "Quantum algebra in R: the weyl package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Weyl algebra is a simple noncommutative system used in quantum mechanics.\nHere I introduce the weyl package, written in the R computing language, which\nfurnishes functionality for working with univariate and multivariate Weyl\nalgebras. The package is available on CRAN at\nhttps://CRAN.R-project.org/package=weyl.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.09230v1"
    },
    {
        "title": "Levelwise construction of a single cylindrical algebraic cell",
        "authors": [
            "Jasper Nalbach",
            "Erika Ábrahám",
            "Philippe Specht",
            "Christopher W. Brown",
            "James H. Davenport",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Satisfiability Modulo Theories (SMT) solvers check the satisfiability of\nquantifier-free first-order logic formulas. We consider the theory of\nnon-linear real arithmetic where the formulae are logical combinations of\npolynomial constraints. Here a commonly used tool is the Cylindrical Algebraic\nDecomposition (CAD) to decompose real space into cells where the constraints\nare truth-invariant through the use of projection polynomials.\n  An improved approach is to repackage the CAD theory into a search-based\nalgorithm: one that guesses sample points to satisfy the formula, and\ngeneralizes guesses that conflict constraints to cylindrical cells around\nsamples which are avoided in the continuing search. Such an approach can lead\nto a satisfying assignment more quickly, or conclude unsatisfiability with\nfewer cells. A notable example of this approach is Jovanovi\\'c and de Moura's\nNLSAT algorithm. Since these cells are produced locally to a sample we might\nneed fewer projection polynomials than the traditional CAD projection. The\noriginal NLSAT algorithm reduced the set a little; while Brown's single cell\nconstruction reduced it much further still. However, the shape and size of the\ncell produced depends on the order in which the polynomials are considered.\n  This paper proposes a method to construct such cells levelwise, i.e. built\nlevel-by-level according to a variable ordering. We still use a reduced number\nof projection polynomials, but can now consider a variety of different\nreductions and use heuristics to select the projection polynomials in order to\noptimise the shape of the cell under construction. We formulate all the\nnecessary theory as a proof system: while not a common presentation for work in\nthis field, it allows an elegant decoupling of heuristics from the algorithm\nand its proof of correctness.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.09309v2"
    },
    {
        "title": "Pourchet's theorem in action: decomposing univariate nonnegative\n  polynomials as sums of five squares",
        "authors": [
            "Victor Magron",
            "Przemysław Koprowski",
            "Tristan Vaccon"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Pourchet proved in 1971 that every nonnegative univariate polynomial with\nrational coefficients is a sum of five or fewer squares. Nonetheless, there are\nno known algorithms for constructing such a decomposition. The sole purpose of\nthe present paper is to present a set of algorithms that decompose a given\nnonnegative polynomial into a sum of six (five under some unproven conjecture\nor when allowing weights) squares of polynomials. Moreover, we prove that the\nbinary complexity can be expressed polynomially in terms of classical\noperations of computer algebra and algorithmic number theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.02202v1"
    },
    {
        "title": "Short proofs of ideal membership",
        "authors": [
            "Clemens Hofstadler",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  A cofactor representation of an ideal element, that is, a representation in\nterms of the generators, can be considered as a certificate for ideal\nmembership. Such a representation is typically not unique, and some can be a\nlot more complicated than others. In this work, we consider the problem of\ncomputing sparsest cofactor representations, i.e., representations with a\nminimal number of terms, of a given element in a polynomial ideal. While we\nfocus on the more general case of noncommutative polynomials, all results also\napply to the commutative setting. We show that the problem of computing\ncofactor representations with a bounded number of terms is decidable and\nNP-complete. Moreover, we provide a practical algorithm for computing sparse\n(not necessarily optimal) representations by translating the problem into a\nlinear optimization problem and by exploiting properties of signature-based\nGr\\\"obner basis algorithms. We show that for a certain class of ideals,\nrepresentations computed by this method are actually optimal, and we present\nexperimental data illustrating that it can lead to noticeably sparser cofactor\nrepresentations.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.02832v3"
    },
    {
        "title": "Refined telescoping algorithms in $RΠΣ$-extensions to reduce the\n  degrees of the denominators",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We present a general framework in the setting of difference ring extensions\nthat enables one to find improved representations of indefinite nested sums\nsuch that the arising denominators within the summands have reduced degrees.\nThe underlying (parameterized) telescoping algorithms can be executed in\n$R\\Pi\\Sigma$-ring extensions that are built over general $\\Pi\\Sigma$-fields. An\nimportant application of this toolbox is the simplification of d'Alembertian\nand Liouvillian solutions coming from recurrence relations where the\ndenominators of the arising sums do not factor nicely.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03563v1"
    },
    {
        "title": "Beating binary powering for polynomial matrices",
        "authors": [
            "Alin Bostan",
            "Vincent Neiger",
            "Sergey Yurkevich"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  The $N$th power of a polynomial matrix of fixed size and degree can be\ncomputed by binary powering as fast as multiplying two polynomials of linear\ndegree in~$N$. When Fast Fourier Transform (FFT) is available, the resulting\ncomplexity is \\emph{softly linear} in~$N$, i.e.~linear in~$N$ with extra\nlogarithmic factors. We show that it is possible to beat binary powering, by an\nalgorithm whose complexity is \\emph{purely linear} in~$N$, even in absence of\nFFT. The key result making this improvement possible is that the entries of the\n$N$th power of a polynomial matrix satisfy linear differential equations with\npolynomial coefficients whose orders and degrees are independent of~$N$.\nSimilar algorithms are proposed for two related problems: computing the $N$th\nterm of a C-finite sequence of polynomials, and modular exponentiation to the\npower $N$ for bivariate polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04299v2"
    },
    {
        "title": "Exact computations with quasiseparable matrices",
        "authors": [
            "Clément Pernet",
            "Hippolyte Signargout",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Quasi-separable matrices are a class of rank-structured matriceswidely used\nin numerical linear algebra and of growing interestin computer algebra, with\napplications in e.g. the linearization ofpolynomial matrices. Various\nrepresentation formats exist for thesematrices that have rarely been\ncompared.We show how the most central formats SSS and HSS can beadapted to\nsymbolic computation, where the exact rank replacesthreshold based numerical\nranks. We clarify their links and comparethem with the Bruhat format. To this\nend, we state their space andtime cost estimates based on fast matrix\nmultiplication, and comparethem, with their leading constants. The comparison\nis supportedby software experiments.We make further progresses for the Bruhat\nformat, for which wegive a generation algorithm, following a Crout elimination\nscheme,which specializes into fast algorithms for the construction from asparse\nmatrix or from the sum of Bruhat representations.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04515v1"
    },
    {
        "title": "Hermite Reduction for D-finite Functions via Integral Bases",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Trager's Hermite reduction solves the integration problem for algebraic\nfunctions via integral bases. A generalization of this algorithm to D-finite\nfunctions has so far been limited to the Fuchsian case. In the present paper,\nwe remove this restriction and propose a reduction algorithm based on integral\nbases that is applicable to arbitrary D-finite functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04652v1"
    },
    {
        "title": "Lazard-style CAD and Equational Constraints",
        "authors": [
            "James H. Davenport",
            "Akshar S. Nair",
            "Gregory K. Sankaran",
            "Ali K. Uncu"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  McCallum-style Cylindrical Algebra Decomposition (CAD) is a major improvement\non the original Collins version, and has had many subsequent advances, notably\nfor total or partial equational constraints. But it suffers from a problem with\nnullification. The recently-justified Lazard-style CAD does not have this\nproblem. However, transporting the equational constraints work to Lazard-style\ndoes reintroduce nullification issues. This paper explains the problem, and the\nsolutions to it, based on the second author's Ph.D. thesis and the\nBrown--McCallum improvement to Lazard.\n  With a single equational constraint, we can gain the same improvements in\nLazard-style as in McCallum-style CAD . Moreover, our approach does not fail\nwhere McCallum would due to nullification. Unsurprisingly, it does not achieve\nthe same level of improvement as it does in the non-nullified cases. We also\nconsider the case of multiple equational constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05813v2"
    },
    {
        "title": "Fast evaluation and root finding for polynomials with floating-point\n  coefficients",
        "authors": [
            "Rémi Imbach",
            "Guillaume Moroz"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Evaluating or finding the roots of a polynomial $f(z) = f_0 + \\cdots + f_d\nz^d$ with floating-point number coefficients is a ubiquitous problem. By using\na piecewise approximation of $f$ obtained with a careful use of the Newton\npolygon of $f$, we improve state-of-the-art upper bounds on the number of\noperations to evaluate and find the roots of a polynomial. In particular, if\nthe coefficients of $f$ are given with $m$ significant bits, we provide for the\nfirst time an algorithm that finds all the roots of $f$ with a relative\ncondition number lower than $2^m$, using a number of bit operations\nquasi-linear in the bit-size of the floating-point representation of $f$.\nNotably, our new approach handles efficiently polynomials with coefficients\nranging from $2^{-d}$ to $2^d$, both in theory and in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06244v1"
    },
    {
        "title": "Transcendence Certificates for D-finite Functions",
        "authors": [
            "Manuel Kauers",
            "Christoph Koutschan",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Although in theory we can decide whether a given D-finite function is\ntranscendental, transcendence proofs remain a challenge in practice. Typically,\ntranscendence is certified by checking certain incomplete sufficient\nconditions. In this paper we propose an additional such condition which catches\nsome cases on which other tests fail.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06396v2"
    },
    {
        "title": "A Poly-algorithmic Approach to Quantifier Elimination",
        "authors": [
            "James H. Davenport",
            "Zak P. Tonks",
            "Ali K. Uncu"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Cylindrical Algebraic Decomposition (CAD) was the first practical means for\ndoing real quantifier elimination (QE), and is still a major method, with many\nimprovements since Collins' original method. Nevertheless, its complexity is\ninherently doubly exponential in the number of variables. Where applicable,\nvirtual term substitution (VTS) is more effective, turning a QE problem in $n$\nvariables to one in $n-1$ variables in one application, and so on. Hence there\nis scope for hybrid methods: doing VTS where possible then using CAD.\n  This paper describes such a poly-algorithmic implementation, based on the\nsecond author's Ph.D. thesis. The version of CAD used is based on a new\nimplementation of Lazard's recently-justified method, with some improvements to\nhandle equational constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06814v2"
    },
    {
        "title": "Computing the Characteristic Polynomial of Endomorphisms of a finite\n  Drinfeld Module using Crystalline Cohomology",
        "authors": [
            "Yossef Musleh",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We present a new algorithm for computing the characteristic polynomial of an\narbitrary endomorphism of a finite Drinfeld module using its associated\ncrystalline cohomology. Our approach takes inspiration from Kedlaya's p-adic\nalgorithm for computing the characteristic polynomial of the Frobenius\nendomorphism on a hyperelliptic curve using Monsky-Washnitzer cohomology. The\nmethod is specialized using a baby-step giant-step algorithm for the particular\ncase of the Frobenius endomorphism, and in this case we include a complexity\nanalysis that demonstrates asymptotic gains over previously existing approaches\n",
        "pdf_link": "http://arxiv.org/pdf/2302.08611v1"
    },
    {
        "title": "Elimination ideal and bivariate resultant over finite fields",
        "authors": [
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  A new algorithm is presented for computing the largest degree invariant\nfactor of the Sylvester matrix (with respect either to $x$ or $y$) associated\nto two polynomials $a$ and $b$ in $\\mathbb F_q[x,y]$ which have no non-trivial\ncommon divisors. The algorithm is randomized of the Monte Carlo type and\nrequires $O((de)^{1+\\epsilon}\\log(q) ^{1+o(1)})$ bit operations, where $d$ an\n$e$ respectively bound the input degrees in $x$ and in $y$. It follows that the\nsame complexity estimate is valid for computing: a generator of the elimination\nideal $\\langle a,b \\rangle \\cap \\mathbb F_q[x]$ (or $\\mathbb F_q[y]$), as soon\nas the polynomial system $a=b=0$ has not roots at infinity; the resultant of\n$a$ and $b$ when they are sufficiently generic, especially so that the\nSylvester matrix has a unique non-trivial invariant factor. Our approach is to\nuse the reduction of the problem to a problem of minimal polynomial in the\nquotient algebra $\\mathbb F_q[x,y]/\\langle a,b \\rangle$. By proposing a new\nmethod based on structured polynomial matrix division for computing with the\nelements in the quotient, we manage to improve the best known complexity\nbounds.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.08891v1"
    },
    {
        "title": "In-place fast polynomial modular remainder",
        "authors": [
            "Jean-Guillaume Dumas",
            "Bruno Grenet"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We consider the simultaneously fast and in-place computation of the Euclidean\npolynomial modular remainder $R(X) $\\not\\equiv$ A(X) \\mod B(X)$ with $A$ and\n$B$ of respective degrees $n$ and $m $\\le$ n$. But fast algorithms for this\nusually come at the expense of (potentially large) extra temporary space. To\nremain in-place a further issue is to avoid the storage of the whole quotient\n$Q(X)$ such that $A=BQ+R$. If the multiplication of two polynomials of degree\n$k$ can be performed with $M(k)$ operations and $O(k)$ extra space, and if it\nis allowed to use the input space of $A$ or $B$ for intermediate computations,\nbut putting $A$ and $B$ back to their initial states after the completion of\nthe remainder computation, we here propose an in-place algorithm (that is with\nits extra required space reduced to $O(1)$ only) using at most $O(n/m\nM(m)\\log(m)$ arithmetic operations, if $\\M(m)$ is quasi-linear, or $O(n/m\nM(m)}$ otherwise. We also propose variants that compute -- still in-place and\nwith the same kind of complexity bounds -- the over-place remainder $A(X)\n$\\not\\equiv$ A(X) \\mod B(X)$, the accumulated remainder $R(X) += A(X) \\mod\nB(X)$ and the accumulated modular multiplication $R(X) += A(X)C(X) \\mod B(X)$.\nTo achieve this, we develop techniques for Toeplitz matrix operations which\noutput is also part of the input. Fast and in-place accumulating versions are\nobtained for the latter, and thus for convolutions, and then used for\npolynomial remaindering. This is realized via further reductions to accumulated\npolynomial multiplication, for which fast in-place algorithms have recently\nbeen developed.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.13600v6"
    },
    {
        "title": "Jordan algebra in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this short article I introduce the \"jordan\" package which provides\nfunctionality for working with different types of Jordan algebra. I give some\nnumerical verification of the Jordan identity for the five types of Jordan\nalgebras. The package is available on CRAN at\nhttps://CRAN.R-project.org/package=stokes.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06062v1"
    },
    {
        "title": "Distance Evaluation to the Set of Defective Matrices",
        "authors": [
            "Alexei Yu. Uteshev",
            "Elizaveta A. Kalinina",
            "Marina V. Goncharova"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We treat the problem of the Frobenius distance evaluation from a given matrix\n$ A \\in \\mathbb R^{n\\times n} $ with distinct eigenvalues to the manifold of\nmatrices with multiple eigenvalues. On restricting considerations to the rank $\n1 $ real perturbation matrices, we prove that the distance in question equals $\n\\sqrt{z_{\\ast}} $ where $ z_{\\ast} $ is a positive (generically, the least\npositive) zero of the algebraic equation $$ \\mathcal F(z) = 0, \\ \\mbox{where} \\\n\\mathcal F(z):= \\mathcal D_{\\lambda} \\left( \\det \\left[ (\\lambda I - A)(\\lambda\nI - A^{\\top})-z I_n \\right] \\right)/z^n $$ and $ \\mathcal D_{\\lambda} $ stands\nfor the discriminant of the polynomial treated with respect to $\\lambda $. In\nthe framework of this approach we also provide the procedure for finding the\nnearest to $ A $ matrix with multiple eigenvalue. Generalization of the problem\nto the case of complex perturbations is also discussed. Several examples are\npresented clarifying the computational aspects of the approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07235v1"
    },
    {
        "title": "Supercomputer Environment for Recursive Matrix Algorithms",
        "authors": [
            "Gennadi Malaschonok",
            "Alla Sidko"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  A new runtime environment for the execution of recursive matrix algorithms on\na supercomputer with distributed memory is proposed. It is designed both for\ndense and sparse matrices. The environment ensures decentralized control of the\ncomputation process. As an example of a block recursive algorithm, the Cholesky\nfactorization of a symmetric positive definite matrix in the form of a block\ndichotomous algorithm is described. The results of experiments with different\nnumbers of cores are presented, demonstrating good scalability of the proposed\nsolution.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11017v1"
    },
    {
        "title": "Two Variants of Bezout Subresultants for Several Univariate Polynomials",
        "authors": [
            "Weidong Wang",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper, we develop two variants of Bezout subresultant formulas for\nseveral polynomials, i.e., hybrid Bezout subresultant polynomial and\nnon-homogeneous Bezout subresultant polynomial. Rather than simply extending\nthe variants of Bezout subresultant formulas developed by Diaz-Toca and\nGonzalez-Vega in 2004 for two polynomials to arbitrary number of polynomials,\nwe propose a new approach to formulating two variants of the Bezout-type\nsubresultant polynomials for a set of univariate polynomials. Experimental\nresults show that the Bezout-type subresultant formulas behave better than\nother known formulas when used to compute multi-polynomial subresultants, among\nwhich the non-homogeneous Bezout-type formula shows the best performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.00262v2"
    },
    {
        "title": "Efficient Generic Quotients Using Exact Arithmetic",
        "authors": [
            "Stephen M. Watt"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  The usual formulation of efficient division uses Newton iteration to compute\nan inverse in a related domain where multiplicative inverses exist. On one\nhand, Newton iteration allows quotients to be calculated using an efficient\nmultiplication method. On the other hand, working in another domain is not\nalways desirable and can lead to a library structure where arithmetic domains\nare interdependent. This paper uses the concept of a whole shifted inverse and\nmodified Newton iteration to compute quotients efficiently without leaving the\noriginal domain. The iteration is generic to domains having a suitable shift\noperation, such as integers or polynomials with coefficients that do not\nnecessarily commute.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01753v5"
    },
    {
        "title": "Operations for D-Algebraic Functions",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  A function is differentially algebraic (or simply D-algebraic) if there is a\npolynomial relationship between some of its derivatives and the indeterminate\nvariable. Many functions in the sciences, such as Mathieu functions, the\nWeierstrass elliptic functions, and holonomic or D-finite functions are\nD-algebraic. These functions form a field, and are closed under composition,\ntaking functional inverse, and derivation. We present implementation for each\nunderlying operation. We also give a systematic way for computing an algebraic\ndifferential equation from a linear differential equation with D-finite\nfunction coefficients. Each command is a feature of our Maple package $NLDE$\navailable at https://mathrepo.mis.mpg.de/OperationsForDAlgebraicFunctions.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09675v2"
    },
    {
        "title": "On Rueppel's Linear Complexity Conjecture",
        "authors": [
            "Graham H. Norton"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Rueppel's conjecture on the linear complexity of the first $n$ terms of the\nsequence $(1,1,0,1,0^3,1,0^7,1,0^{15},\\ldots)$ was first proved by Dai using\nthe Euclidean algorithm. We have previously shown that we can attach a\nhomogeneous (annihilator) ideal of $F[x,z]$ to the first $n$ terms of a\nsequence over a field $F$ and construct a pair of generating forms for it. This\napproach gives another proof of Rueppel's conjecture. We also prove additional\nproperties of these forms and deduce the outputs of the LFSR synthesis\nalgorithm applied to the first $n$ terms. Further, dehomogenising the leading\ngenerators yields the minimal polynomials of Dai.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00405v1"
    },
    {
        "title": "Bézout Subresultants for Univariate Polynomials in General Basis",
        "authors": [
            "Jing Yang",
            "Wei Yang"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Subresultant is a powerful tool for developing various algorithms in computer\nalgebra. Subresultants for polynomials in standard basis (i.e., power basis)\nhave been well studied so far. With the popularity of basis-preserving\nalgorithms, resultants and subresultants in non-standard basis are drawing more\nand more attention. In this paper, we develop a formula for B\\'ezout\nsubresultants of univariate polynomials in general basis, which covers a broad\nrange of non-standard bases. More explicitly, the input polynomials are\nprovided in a given general basis and the resulting subresultants are\nB\\'ezout-type expressions in the same basis. It is shown that the subresultants\nshare the essential properties as the subresultants in standard basis.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.03906v1"
    },
    {
        "title": "Efficient Quotients of Non-Commutative Polynomials",
        "authors": [
            "Stephen M. Watt"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  It is shown how to compute quotients efficiently in non-commutative\nunivariate polynomial rings. This extends earlier work where efficient generic\nquotients were studied with a primary focus on commutative domains. Fast\nalgorithms are given for left and right quotients of polynomials where the\nvariable commutes with coefficients. These algorithms are based on the concept\nof the ``whole shifted inverse'', which is a specialized quotient where the\ndividend is a power of the polynomial variable. It is also shown that when the\nvariable does not commute with coefficients, that is for skew polynomials, left\nand right whole shifted inverses are defined and may be used to compute right\nand left quotients. In this case their computation is not asymptotically fast,\nbut once obtained, they may be used to compute multiple quotients, each with\none multiplication. Examples are shown of polynomials with matrix coefficients,\ndifferential operators and difference operators. In addition, a\nproof-of-concept generic Maple implementations is given.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.17877v4"
    },
    {
        "title": "Some New Non-Commutative Matrix Multiplication Algorithms of Size\n  $(n,m,6)$",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  For various $2\\leq n,m \\leq 6$, we propose some new algorithms for\nmultiplying an $n\\times m$ matrix with an $m \\times 6$ matrix over a possibly\nnoncommutative coefficient ring.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.00882v1"
    },
    {
        "title": "On Isolating Roots in a Multiple Field Extension",
        "authors": [
            "Christina Katsamaki",
            "Fabrice Rouillier"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We address univariate root isolation when the polynomial's coefficients are\nin a multiple field extension. We consider a polynomial $F \\in L[Y]$, where $L$\nis a multiple algebraic extension of $\\mathbb{Q}$. We provide aggregate bounds\nfor $F$ and algorithmic and bit-complexity results for the problem of isolating\nits roots. For the latter problem we follow a common approach based on\nunivariate root isolation algorithms. For the particular case where $F$ does\nnot have multiple roots, we achieve a bit-complexity in\n$\\tilde{\\mathcal{O}}_B(n d^{2n+2}(d+n\\tau))$, where $d$ is the total degree and\n$\\tau$ is the bitsize of the involved polynomials.In the general case we need\nto enhance our algorithm with a preprocessing step that determines the number\nof distinct roots of $F$. We follow a numerical, yet certified, approach that\nhas bit-complexity $\\tilde{\\mathcal{O}}_B(n^2d^{3n+3}\\tau + n^3 d^{2n+4}\\tau)$.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.04271v1"
    },
    {
        "title": "Exploiting Strict Constraints in the Cylindrical Algebraic Covering",
        "authors": [
            "Philipp Bär",
            "Jasper Nalbach",
            "Erika Ábrahám",
            "Christopher W. Brown"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  One of the few available complete methods for checking the satisfiability of\nsets of polynomial constraints over the reals is the cylindrical algebraic\ncovering (CAlC) method. In this paper, we propose an extension for this method\nto exploit the strictness of input constraints for reducing the computational\neffort. We illustrate the concepts on a multidimensional example and provide\nexperimental results to evaluate the usefulness of our proposed extension.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.16757v1"
    },
    {
        "title": "Rational Solutions of Parametric First-Order Algebraic Differential\n  Equations",
        "authors": [
            "Sebastian Falkensteiner",
            "Rafael Sendra"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper we give a procedure for finding rational solutions of a given\nfirst-order ODE with functional and constant coefficients which occur in a\nrational way. We derive an associated system with the same solvability, and\nsufficient and necessary conditions for the existence of rational solutions are\ngiven. In the case where all parametric coefficients are constant, we give an\nalgorithm to compute the rational solutions. In the case where one functional\ncoefficient appears, we algorithmically find rational general solutions which\nrationally depend on the appearing transcendental constant. In the other cases,\nthe presented procedure is not completely algorithmic.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.05102v1"
    },
    {
        "title": "A Program That Simplifies Regular Expressions (Tool paper)",
        "authors": [
            "Baudouin Le Charlier"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper presents the main features of a system that aims to transform\nregular expressions into shorter equivalent expressions. The system is also\ncapable of computing other operations useful for simplification, such as\nchecking the inclusion of regular languages. The main novelty of this work is\nthat it combines known but distinct ways of representing regular languages into\na global unified data structure that makes the operations more efficient. In\naddition, representations of regular languages are dynamically reduced as\noperations are performed on them. Expressions are normalized and represented by\na unique identifier (an integer). Expressions found to be equivalent (i.e.\ndenoting the same regular language) are grouped into equivalence classes from\nwhich a shortest representative is chosen. The article briefly describes the\nmain algorithms working on the global data structure. Some of them are direct\nadaptations of well-known algorithms, but most of them incorporate new ideas,\nwhich are really necessary to make the system efficient. Finally, to show its\nusefulness, the system is applied to some examples from the literature.\nStatistics on randomly generated sets of expressions are also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06436v1"
    },
    {
        "title": "Reduction-Based Creative Telescoping for Definite Summation of D-finite\n  Functions",
        "authors": [
            "Hadrien Brochet",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Creative telescoping is an algorithmic method initiated by Zeilberger to\ncompute definite sums by synthesizing summands that telescope, called\ncertificates. We describe a creative telescoping algorithm that computes\ntelescopers for definite sums of D-finite functions as well as the associated\ncertificates in a compact form. The algorithm relies on a discrete analogue of\nthe generalized Hermite reduction, or equivalently, a generalization of the\nAbramov-Petkov\\v{s}ek reduction. We provide a Maple implementation with good\ntimings on a variety of examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07216v2"
    },
    {
        "title": "In-place accumulation of fast multiplication formulae",
        "authors": [
            "Jean-Guillaume Dumas",
            "Bruno Grenet"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper deals with simultaneously fast and in-place algorithms for\nformulae where the result has to be linearly accumulated: some of the output\nvariables are also input variables, linked by a linear dependency. Fundamental\nexamples include the in-place accumulated multiplication of polynomials or\nmatrices, C+=AB. The difficulty is to combine in-place computations with fast\nalgorithms: those usually come at the expense of (potentially large) extra\ntemporary space, but with accumulation the output variables are not even\navailable to store intermediate values. We first propose a novel automatic\ndesign of fast and in-place accumulating algorithms for any bilinear formulae\n(and thus for polynomial and matrix multiplication) and then extend it to any\nlinear accumulation of a collection of functions. For this, we relax the\nin-place model to any algorithm allowed to modify its inputs, provided that\nthose are restored to their initial state afterwards. This allows us, in fine,\nto derive unprecedented in-place accumulating algorithms for fast polynomial\nmultiplications and for Strassen-like matrix multiplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12712v3"
    },
    {
        "title": "The free Abelian group in R: the frab package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this short article I introduce the frab package which provides an\nalternative interpretation of named vectors in the R programming language; it\nis available on CRAN. The underlying mathematical object is the free Abelian\ngroup.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.13184v1"
    },
    {
        "title": "Iterated Resultants in CAD",
        "authors": [
            "James H. Davenport",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Cylindrical Algebraic Decomposition (CAD) by projection and lifting requires\nmany iterated univariate resultants. It has been observed that these often\nfactor, but to date this has not been used to optimise implementations of CAD.\nWe continue the investigation into such factorisations, writing in the specific\ncontext of SC-Square.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.16750v1"
    },
    {
        "title": "Algoritmos para Multiplicação Matricial",
        "authors": [
            "M. S. O. Poloi",
            "T. O. Quinelato"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  The goal of this article is to study algorithms that compute the product\nbetween two matrixes, specifically using the ingenuous methods of Strassen and\nStrassen-Winograd, which will be presented in Section 2. At present, the cited\nmethods are not the most optimal considering the arithmetic complexity of these\nalgorithms (see Table 1). However, changes to the Strassen and\nStrassen-Winograd methods will be exposed which will result in a reduction in\ntheir memory allocation and/or execution time. The algorithms in this study\nwere implemented using the Julia programming language, version 1.9.1, with the\naid of the packages Pluto (notebooks), Plots (graphic visualization of the\nresults) and BenchmarkTools (measurement of memory allocation and execution\ntime of the algorithms).\n  --\n  O objetivo deste artigo \\'e estudar algoritmos que computam o produto entre\nduas matrizes, mais especificamente utilizando os m\\'etodos ing\\^enuo, de\nStrassen e de Strassen-Winograd, que ser\\~ao apresentados na Se\\c{c}\\~ao 2.\nAtualmente, os m\\'etodos citados n\\~ao s\\~ao os mais otimizados considerando a\ncomplexidade aritm\\'etica de seus algoritmos (vide Tabela 1). No entanto,\nser\\~ao expostas modifica\\c{c}\\~oes dos m\\'etodos de Strassen e\nStrassen-Winograd que conseguem reduzir sua aloca\\c{c}\\~ao de mem\\'oria e/ou\ntempo de execu\\c{c}\\~ao. Os algoritmos do problema em estudo foram\nimplementados utilizando a linguagem de programa\\c{c}\\~ao Julia, na vers\\~ao\n1.9.1, com o aux\\'ilio dos pacotes Pluto (notebooks), Plots (visualiza\\c{c}\\~ao\ngr\\'afica dos resultados) e BenchmarkTools (medi\\c{c}\\~ao de aloca\\c{c}\\~ao de\nmem\\'oria e tempo de execu\\c{c}\\~ao dos algoritmos).\n",
        "pdf_link": "http://arxiv.org/pdf/2309.00628v1"
    },
    {
        "title": "FMplex: Exploring a Bridge between Fourier-Motzkin and Simplex",
        "authors": [
            "Valentin Promies",
            "Jasper Nalbach",
            "Erika Ábrahám",
            "Paul Kobialka"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper we present a quantifier elimination method for conjunctions of\nlinear real arithmetic constraints. Our algorithm is based on the\nFourier-Motzkin variable elimination procedure, but by case splitting we are\nable to reduce the worst-case complexity from doubly to singly exponential. The\nadaption of the procedure for SMT solving has strong correspondence to the\nsimplex algorithm, therefore we name it FMplex. Besides the theoretical\nfoundations, we provide an experimental evaluation in the context of SMT\nsolving. This is an extended version of the authors' work previously published\nat the fourteenth International Symposium on Games, Automata, Logics, and\nFormal Verification (GandALF 2023).\n",
        "pdf_link": "http://arxiv.org/pdf/2309.03138v4"
    },
    {
        "title": "FMplex: A Novel Method for Solving Linear Real Arithmetic Problems",
        "authors": [
            "Jasper Nalbach",
            "Valentin Promies",
            "Erika Ábrahám",
            "Paul Kobialka"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper we introduce a novel quantifier elimination method for\nconjunctions of linear real arithmetic constraints. Our algorithm is based on\nthe Fourier-Motzkin variable elimination procedure, but by case splitting we\nare able to reduce the worst-case complexity from doubly to singly exponential.\nThe adaption of the procedure for SMT solving has strong correspondence to the\nsimplex algorithm, therefore we name it FMplex. Besides the theoretical\nfoundations, we provide an experimental evaluation in the context of SMT\nsolving.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.00995v1"
    },
    {
        "title": "Reducing Hyperexponential Functions over Monomial Extensions",
        "authors": [
            "Shaoshi Chen",
            "Hao Du",
            "Yiman Gao",
            "Ziming Li"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We extend the shell and kernel reductions for hyperexponential functions over\nthe field of rational functions to a monomial extension. Both of the reductions\nare incorporated into one algorithm. As an application, we present an additive\ndecomposition in rationally hyperexponential towers. The decomposition yields\nan alternative algorithm for computing elementary integrals over such towers.\nThe alternative can find some elementary integrals that are unevaluated by the\nintegrators in the latest versions of Maple and Mathematica.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.01194v1"
    },
    {
        "title": "A Novel Application of Polynomial Solvers in mmWave Analog Radio\n  Beamforming",
        "authors": [
            "Snehal Bhayani",
            "Praneeth Susarla",
            "S. S. Krishna Chaitanya Bulusu",
            "Olli Silven",
            "Markku Juntti",
            "Janne Heikkila"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Beamforming is a signal processing technique where an array of antenna\nelements can be steered to transmit and receive radio signals in a specific\ndirection. The usage of millimeter wave (mmWave) frequencies and multiple input\nmultiple output (MIMO) beamforming are considered as the key innovations of 5th\nGeneration (5G) and beyond communication systems. The technique initially\nperforms a beam alignment procedure, followed by data transfer in the aligned\ndirections between the transmitter and the receiver. Traditionally, beam\nalignment involves periodical and exhaustive beam sweeping at both transmitter\nand the receiver, which is a slow process causing extra communication overhead\nwith MIMO and massive MIMO radio units. In applications such as beam tracking,\nangular velocity, beam steering etc., the beam alignment procedure is optimized\nby estimating the beam directions using first order polynomial approximations.\nRecent learning-based SOTA strategies for fast mmWave beam alignment also\nrequire exploration over exhaustive beam pairs during the training procedure,\ncausing overhead to learning strategies for higher antenna configurations. In\nthis work, we first optimize the beam alignment cost functions e.g. the data\nrate, to reduce the beam sweeping overhead by applying polynomial\napproximations of its partial derivatives which can then be solved as a system\nof polynomial equations using well-known tools from algebraic geometry. At this\npoint, a question arises: 'what is a good polynomial approximation?' In this\nwork, we attempt to obtain a 'good polynomial approximation'. Preliminary\nexperiments indicate that our estimated polynomial approximations attain a\nso-called sweet-spot in terms of the solver speed and accuracy, when evaluated\non test beamforming problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.18103v1"
    },
    {
        "title": "Linear difference operators with sequence coefficients having\n  infinite-dimentional solution spaces",
        "authors": [
            "Sergei Abramov",
            "Gleb Pogudin"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  The notion of lacunary infinite numerical sequence is introduced. It is shown\nthat for an arbitrary linear difference operator L with coefficients belonging\nto the set R of infinite numerical sequences, a criterion (i.e., a necessary\nand sufficient condition) for the infinite dimensionality of its space $V_L$ of\nsolutions belonging to R is the presence of a lacunary sequence in $V_L$.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02217v1"
    },
    {
        "title": "On the dimension of the solution space of linear difference equations\n  over the ring of infinite sequences",
        "authors": [
            "Sergei Abramov",
            "Gleb Pogudin"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  For a linear difference equation with the coefficients being computable\nsequences, we establish algorithmic undecidability of the problem of\ndetermining the dimension of the solution space including the case when some\nadditional prior information on the dimension is available.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02219v2"
    },
    {
        "title": "Reduction-based Creative Telescoping for P-recursive Sequences via\n  Integral Bases",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers",
            "Rong-Hua Wang"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We propose a way to split a given bivariate P-recursive sequence into a\nsummable part and a non-summable part in such a way that the non-summable part\nis minimal in some sense. This decomposition gives rise to a new\nreduction-based creative telescoping algorithm based on the concept of integral\nbases.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.05246v1"
    },
    {
        "title": "On the Existence of Telescopers for P-recursive Sequences",
        "authors": [
            "Lixin Du"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We extend the criterion on the existence of telescopers for hypergeometric\nterms to the case of P-recursive sequences. This criterion is based on the\nconcept of integral bases and the generalized Abramov-Petkovsek reduction for\nP-recursive sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06065v1"
    },
    {
        "title": "Efficient Local Search for Nonlinear Real Arithmetic",
        "authors": [
            "Zhonghan Wang",
            "Bohua Zhan",
            "Bohan Li",
            "Shaowei Cai"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Local search has recently been applied to SMT problems over various\narithmetic theories. Among these, nonlinear real arithmetic poses special\nchallenges due to its uncountable solution space and potential need to solve\nhigher-degree polynomials. As a consequence, existing work on local search only\nconsidered fragments of the theory. In this work, we analyze the difficulties\nand propose ways to address them, resulting in an efficient search algorithm\nthat covers the full theory of nonlinear real arithmetic. In particular, we\npresent two algorithmic improvements: incremental computation of variable\nscores and temporary relaxation of equality constraints. We also discuss choice\nof candidate moves and a look-ahead mechanism in case when no critical moves\nare available. The resulting implementation is competitive on satisfiable\nproblem instances against complete methods such as MCSAT in existing SMT\nsolvers.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.14249v1"
    },
    {
        "title": "Hybrid Intervals and Symbolic Block Matrices",
        "authors": [
            "Mike Ghesquiere",
            "Stephen M. Watt"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Structured matrices with symbolic sizes appear frequently in the literature,\nespecially in the description of algorithms for linear algebra. Recent work has\ntreated these symbolic structured matrices themselves as computational objects,\nshowing how to add matrices with blocks of different symbolic sizes in a\ngeneral way while avoiding a combinatorial explosion of cases. The present\narticle introduces the concept of hybrid intervals, in which points may have\nnegative multiplicity. Various operations on hybrid intervals have compact and\nelegant formulations that do not require cases to handle different orders of\nthe end points. This makes them useful to represent symbolic block matrix\nstructures and to express arithmetic on symbolic block matrices compactly. We\nuse these ideas to formulate symbolic block matrix addition and multiplication\nin a compact and uniform way.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.16571v1"
    },
    {
        "title": "${L}^{\\infty}$-norm computation for linear time-invariant systems\n  depending on parameters",
        "authors": [
            "Alban Quadrat",
            "Fabrice Rouillier",
            "Grace Younes"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper focuses on representing the $L^{\\infty}$-norm of\nfinite-dimensional linear time-invariant systems with parameter-dependent\ncoefficients. Previous studies tackled the problem in a non-parametric scenario\nby simplifying it to finding the maximum $y$-projection of real solutions $(x,\ny)$ of a system of the form $\\Sigma=\\{P=0, \\, \\partial P/\\partial x=0\\}$, where\n$P \\in \\Z[x, y]$. To solve this problem, standard computer algebra methods were\nemployed and analyzed \\cite{bouzidi2021computation}.\n  In this paper, we extend our approach to address the parametric case. We aim\nto represent the \"maximal\" $y$-projection of real solutions of $\\Sigma$ as a\nfunction of the given parameters. %a set of parameters $\\alpha$. To accomplish\nthis, we utilize cylindrical algebraic decomposition. This method allows us to\ndetermine the desired value as a function of the parameters within specific\nregions of parameter space.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.00760v2"
    },
    {
        "title": "Computing greatest common divisor of several parametric univariate\n  polynomials via generalized subresultant polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper, we tackle the following problem: compute the gcd for several\nunivariate polynomials with parametric coefficients. It amounts to partitioning\nthe parameter space into ``cells'' so that the gcd has a uniform expression\nover each cell and constructing a uniform expression of gcd in each cell. We\ntackle the problem as follows. We begin by making a natural and obvious\nextension of subresultant polynomials of two polynomials to several\npolynomials. Then we develop the following structural theories about them.\n  1. We generalize Sylvester's theory to several polynomials, in order to\nobtain an elegant relationship between generalized subresultant polynomials and\nthe gcd of several polynomials, yielding an elegant algorithm.\n  2. We generalize Habicht's theory to several polynomials, in order to obtain\na systematic relationship between generalized subresultant polynomials and\npseudo-remainders, yielding an efficient algorithm.\n  Using the generalized theories, we present a simple (structurally elegant)\nalgorithm which is significantly more efficient (both in the output size and\ncomputing time) than algorithms based on previous approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00408v2"
    },
    {
        "title": "Submodule approach to creative telescoping",
        "authors": [
            "Mark van Hoeij"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  This paper proposes ideas to speed up the process of creative telescoping,\nparticularly when the telescoper is reducible. One can interpret telescoping as\ncomputing an annihilator $L \\in D$ for an element $m$ in a $D$-module $M$. The\nmain idea is to look for submodules of $M$. If $N$ is a non-trivial submodule\nof $M$, constructing the minimal operator $R$ of the image of $m$ in $M/N$\ngives a right-factor of $L$ in $D$. Then $L = L' R$ where the left-factor $L'$\nis the telescoper of $R(m) \\in N$. To expedite computing $L'$, compute the\naction of $D$ on a natural basis of $N$, then obtain $L'$ with a cyclic vector\ncomputation.\n  The next main idea is that when $N$ has automorphisms, use them to construct\nsubmodules. An automorphism with distinct eigenvalues can be used to decompose\n$N$ as a direct sum $N_1 \\oplus \\cdots \\oplus N_k$. Then $L'$ is the LCLM\n(Least Common Left Multiple) of $L_1, \\ldots, L_k$ where $L_i$ is the\ntelescoper of the projection of $R(m)$ on $N_i$. An LCLM can greatly increase\nthe degrees of coefficients, so $L'$ and $L$ can be much larger expressions\nthan the factors $L_1,\\ldots,L_k$ and $R$. Examples show that computing each\nfactor $L_i$ and $R$ seperately can save a lot of CPU time compared to\ncomputing $L$ in expanded form with standard creative telescoping.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08455v2"
    },
    {
        "title": "Hypergeometric Solutions of Linear Difference Systems",
        "authors": [
            "Moulay Barkatou",
            "Mark van Hoeij",
            "Johannes Middeke",
            "Yi Zhou"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We extend Petkov\\v{s}ek's algorithm for computing hypergeometric solutions of\nscalar difference equations to the case of difference systems $\\tau(Y) = M Y$,\nwith $M \\in {\\rm GL}_n(C(x))$, where $\\tau$ is the shift operator.\nHypergeometric solutions are solutions of the form $\\gamma P$ where $P \\in\nC(x)^n$ and $\\gamma$ is a hypergeometric term over $C(x)$, i.e.\n${\\tau(\\gamma)}/{\\gamma} \\in C(x)$. Our contributions concern efficient\ncomputation of a set of candidates for ${\\tau(\\gamma)}/{\\gamma}$ which we write\nas $\\lambda = c\\frac{A}{B}$ with monic $A, B \\in C[x]$, $c \\in C^*$. Factors of\nthe denominators of $M^{-1}$ and $M$ give candidates for $A$ and $B$, while\nanother algorithm is needed for $c$. We use the super-reduction algorithm to\ncompute candidates for $c$, as well as other ingredients to reduce the list of\ncandidates for $A/B$. To further reduce the number of candidates $A/B$, we\nbound the so-called type of $A/B$ by bounding local types. Our algorithm has\nbeen implemented in Maple and experiments show that our implementation can\nhandle systems of high dimension, which is useful for factoring operators.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08470v2"
    },
    {
        "title": "Creative Telescoping for Hypergeometric Double Sums",
        "authors": [
            "Peter Paule",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We present efficient methods for calculating linear recurrences of\nhypergeometric double sums and, more generally, of multiple sums. In\nparticular, we supplement this approach with the algorithmic theory of\ncontiguous relations, which guarantees the applicability of our method for many\ninput sums. In addition, we elaborate new techniques to optimize the underlying\nkey task of our method to compute rational solutions of parameterized linear\nrecurrences.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16314v1"
    },
    {
        "title": "Computing Krylov iterates in the time of matrix multiplication",
        "authors": [
            "Vincent Neiger",
            "Clément Pernet",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Krylov methods rely on iterated matrix-vector products $A^k u_j$ for an\n$n\\times n$ matrix $A$ and vectors $u_1,\\ldots,u_m$. The space spanned by all\niterates $A^k u_j$ admits a particular basis -- the \\emph{maximal Krylov basis}\n-- which consists of iterates of the first vector $u_1, Au_1, A^2u_1,\\ldots$,\nuntil reaching linear dependency, then iterating similarly the subsequent\nvectors until a basis is obtained. Finding minimal polynomials and Frobenius\nnormal forms is closely related to computing maximal Krylov bases. The fastest\nway to produce these bases was, until this paper, Keller-Gehrig's 1985\nalgorithm whose complexity bound $O(n^\\omega \\log(n))$ comes from repeated\nsquarings of $A$ and logarithmically many Gaussian eliminations. Here\n$\\omega>2$ is a feasible exponent for matrix multiplication over the base\nfield. We present an algorithm computing the maximal Krylov basis in\n$O(n^\\omega\\log\\log(n))$ field operations when $m \\in O(n)$, and even\n$O(n^\\omega)$ as soon as $m\\in O(n/\\log(n)^c)$ for some fixed real $c>0$. As a\nconsequence, we show that the Frobenius normal form together with a\ntransformation matrix can be computed deterministically in $O(n^\\omega\n(\\log\\log(n))^2)$, and therefore matrix exponentiation~$A^k$ can be performed\nin the latter complexity if $\\log(k) \\in O(n^{\\omega-1-\\varepsilon})$ for some\nfixed $\\varepsilon>0$. A key idea for these improvements is to rely on fast\nalgorithms for $m\\times m$ polynomial matrices of average degree $n/m$,\ninvolving high-order lifting and minimal kernel bases.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07345v2"
    },
    {
        "title": "Two Algorithms for Computing Rational Univariate Representations of\n  Zero-Dimensional Ideals with Parameters",
        "authors": [
            "Dingkang Wang",
            "Jingjing Wei",
            "Fanghui Xiao",
            "Xiaopeng Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Based on the partition of parameter space, two algorithms for computing the\nrational univariate representation of zero-dimensional ideals with parameters\nare presented in the paper. Unlike the rational univariate representation of\nzero-dimensional ideals without parameters, the number of zeros of\nzero-dimensional ideals with parameters under various specializations is\ndifferent, which leads to choosing and checking the separating element, the key\nto computing the rational univariate representation, is difficult. In order to\npick out the separating element, we first ensure that under each branch the\nideal has the same number of zeros by partitioning the parameter space.\nSubsequently two ideas are given to choose and check the separating element.\nOne idea is that by extending the subresultant theorem to parametric cases, we\nutilize the extended subresultant theorem to choose the separating element with\nthe further partition of parameter space and then with the help of parametric\ngreatest common divisor theory compute rational univariate representations.\nAnother one is that we go straight to choose and check the separating element\nby the computation of parametric greatest common divisors, then immediately get\nthe rational univariate representations. Based on these, we design two\ndifferent algorithms for computing rational univariate representations of\nzero-dimensional ideals with parameters. Furthermore, the algorithms have been\nimplemented on Singular and the performance comparison are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16519v2"
    },
    {
        "title": "Power Series Composition in Near-Linear Time",
        "authors": [
            "Yasunori Kinoshita",
            "Baitian Li"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We present an algebraic algorithm that computes the composition of two power\nseries in softly linear time complexity. The previous best algorithms are\n$\\mathop{\\mathrm O}(n^{1+o(1)})$ by Kedlaya and Umans (FOCS 2008) and an\n$\\mathop{\\mathrm O}(n^{1.43})$ algebraic algorithm by Neiger, Salvy, Schost and\nVillard (JACM 2023).\n  Our algorithm builds upon the recent Graeffe iteration approach to manipulate\nrational power series introduced by Bostan and Mori (SOSA 2021).\n",
        "pdf_link": "http://arxiv.org/pdf/2404.05177v2"
    },
    {
        "title": "Connectivity in Symmetric Semi-Algebraic Sets",
        "authors": [
            "Cordian Riener",
            "Robin Schabert",
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Semi-algebraic set is a subset of the real space defined by polynomial\nequations and inequalities. In this paper, we consider the problem of deciding\nwhether two given points in a semi-algebraic set are connected. We restrict to\nthe case when all equations and inequalities are invariant under the action of\nthe symmetric group and their degrees at most $d<n$, where $n$ is the number of\nvariables. Additionally, we assume that the two points are in the same\nfundamental domain of the action of the symmetric group, by assuming that the\ncoordinates of two given points are sorted in non-decreasing order. We\nconstruct and analyze an algorithm that solves this problem, by taking\nadvantage of the group action, and has a complexity being polynomial in $n$.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09749v3"
    },
    {
        "title": "Reduction systems and degree bounds for integration",
        "authors": [
            "Hao Du",
            "Clemens G. Raab"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In symbolic integration, the Risch--Norman algorithm aims to find closed\nforms of elementary integrals over differential fields by an ansatz for the\nintegral, which usually is based on heuristic degree bounds. Norman presented\nan approach that avoids degree bounds and only relies on the completion of\nreduction systems. We give a formalization of his approach and we develop a\nrefined completion process, which terminates in more instances. In some\nsituations when the algorithm does not terminate, one can detect patterns\nallowing to still describe infinite reduction systems that are complete. We\npresent such infinite systems for the fields generated by Airy functions and\ncomplete elliptic integrals, respectively. Moreover, we show how complete\nreduction systems can be used to find rigorous degree bounds. In particular, we\ngive a general formula for weighted degree bounds and we apply it to find tight\nbounds for above examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.13042v1"
    },
    {
        "title": "Reconciling Explanations in Multi-Model Systems through Probabilistic\n  Argumentation",
        "authors": [
            "Shengxin Hong",
            "Xiuyi Fan"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Explainable Artificial Intelligence (XAI) has become critical in enhancing\nthe transparency and trustworthiness of AI systems, especially as these systems\nare increasingly deployed in high-stakes domains such as healthcare and\nfinance. Despite the progress made in developing explanation generation\ntechniques for individual machine learning (ML) models, significant challenges\nremain in achieving coherent and comprehensive explanations in multi-model\nsystems. This paper addresses these challenges by focusing on the explanation\nreconciliation problem (ERP) within multi-model systems. Traditional\nexplanation generation technique often fall short in multi-model systems\ncontexts, where explanations from different models can conflict and fail to\nform a cohesive narrative. Through the use of probabilistic argumentation and\nknowledge representation techniques, we propose a framework for generating\nholistic explanations that align with human cognitive processes. Our approach\ninvolves mapping uncertain explanation information to probabilistic arguments\nand introducing criteria for explanation reconciliation based on user\nperspectives such as optimism, pessimism, fairness. In addition, we introduce\nthe relative independence assumption to optimise the search space for\ncomputational explanations.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.13419v2"
    },
    {
        "title": "How to generate all possible rational Wilf-Zeilberger forms?",
        "authors": [
            "Shaoshi Chen",
            "Christoph Koutschan",
            "Yisen Wang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Wilf-Zeilberger pairs are fundamental in the algorithmic theory of Wilf and\nZeilberger for computer-generated proofs of combinatorial identities.\nWilf-Zeilberger forms are their high-dimensional generalizations, which can be\nused for proving and discovering convergence acceleration formulas. This paper\npresents a structural description of all possible rational such forms, which\ncan be viewed as an additive analog of the classical Ore-Sato theorem. Based on\nthis analog, we show a structural decomposition of so-called multivariate\nhyperarithmetic terms, which extend multivariate hypergeometric terms to the\nadditive setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.02430v1"
    },
    {
        "title": "Certifying Phase Abstraction",
        "authors": [
            "Nils Froleyks",
            "Emily Yu",
            "Armin Biere",
            "Keijo Heljanko"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Certification helps to increase trust in formal verification of\nsafety-critical systems which require assurance on their correctness. In\nhardware model checking, a widely used formal verification technique, phase\nabstraction is considered one of the most commonly used preprocessing\ntechniques. We present an approach to certify an extended form of phase\nabstraction using a generic certificate format. As in earlier works our\napproach involves constructing a witness circuit with an inductive invariant\nproperty that certifies the correctness of the entire model checking process,\nwhich is then validated by an independent certificate checker. We have\nimplemented and evaluated the proposed approach including certification for\nvarious preprocessing configurations on hardware model checking competition\nbenchmarks. As an improvement on previous work in this area, the proposed\nmethod is able to efficiently complete certification with an overhead of a\nfraction of model checking time.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04297v1"
    },
    {
        "title": "Bridging Syntax and Semantics of Lean Expressions in E-Graphs",
        "authors": [
            "Marcus Rossel",
            "Andrés Goens"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Interactive theorem provers, like Isabelle/HOL, Coq and Lean, have expressive\nlanguages that allow the formalization of general mathematical objects and\nproofs. In this context, an important goal is to reduce the time and effort\nneeded to prove theorems. A significant means of achieving this is by improving\nproof automation. We have implemented an early prototype of proof automation\nfor equational reasoning in Lean by using equality saturation. To achieve this,\nwe need to bridge the gap between Lean's expression semantics and the\nsyntactically driven e-graphs in equality saturation. This involves handling\nbound variables, implicit typing, as well as Lean's definitional equality,\nwhich is more general than syntactic equality and involves notions like\n$\\alpha$-equivalence, $\\beta$-reduction, and $\\eta$-reduction. In this extended\nabstract, we highlight how we attempt to bridge this gap, and which challenges\nremain to be solved. Notably, while our techniques are partially unsound, the\nresulting proof automation remains sound by virtue of Lean's proof checking.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.10188v1"
    },
    {
        "title": "Jacobi Stability Analysis for Systems of ODEs Using Symbolic Computation",
        "authors": [
            "Bo Huang",
            "Dongming Wang",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  The classical theory of Kosambi-Cartan-Chern (KCC) developed in differential\ngeometry provides a powerful method for analyzing the behaviors of dynamical\nsystems. In the KCC theory, the properties of a dynamical system are described\nin terms of five geometrical invariants, of which the second corresponds to the\nso-called Jacobi stability of the system. Different from that of the Lyapunov\nstability that has been studied extensively in the literature, the analysis of\nthe Jacobi stability has been investigated more recently using geometrical\nconcepts and tools. It turns out that the existing work on the Jacobi stability\nanalysis remains theoretical and the problem of algorithmic and symbolic\ntreatment of Jacobi stability analysis has yet to be addressed. In this paper,\nwe initiate our study on the problem for a class of ODE systems of arbitrary\ndimension and propose two algorithmic schemes using symbolic computation to\ncheck whether a nonlinear dynamical system may exhibit Jacobi stability. The\nfirst scheme, based on the construction of the complex root structure of a\ncharacteristic polynomial and on the method of quantifier elimination, is\ncapable of detecting the existence of the Jacobi stability of the given\ndynamical system. The second algorithmic scheme exploits the method of\nsemi-algebraic system solving and allows one to determine conditions on the\nparameters for a given dynamical system to have a prescribed number of Jacobi\nstable fixed points. Several examples are presented to demonstrate the\neffectiveness of the proposed algorithmic schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.10578v3"
    },
    {
        "title": "The Recovery of $λ$ from a Hilbert Polynomial",
        "authors": [
            "Joseph Donato",
            "Monica Lewis"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In the study of Hilbert schemes, the integer partition $\\lambda$ helps\nresearchers identify some geometric and combinatorial properties of the scheme\nin question. To aid researchers in extracting such information from a Hilbert\npolynomial, we describe an efficient algorithm which can identify if\n$p(x)\\in\\mathbb{Q}[x]$ is a Hilbert polynomial and if so, recover the integer\npartition $\\lambda$ associated with it.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.12886v2"
    },
    {
        "title": "On the Problem of Separating Variables in Multivariate Polynomial Ideals",
        "authors": [
            "Manfred Buchacher",
            "Manuel Kauers"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  For a given ideal I in K[x_1,...,x_n,y_1,...,y_m] in a polynomial ring with\nn+m variables, we want to find all elements that can be written as f-g for some\nf in K[x_1,...,x_n] and some g in K[y_1,...,y_m], i.e., all elements of I that\ncontain no term involving at the same time one of the x_1,...,x_n and one of\nthe y_1,...,y_m. For principal ideals and for ideals of dimension zero, we give\na algorithms that compute all these polynomials in a finite number of steps.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.19223v1"
    },
    {
        "title": "DNLSAT: A Dynamic Variable Ordering MCSAT Framework for Nonlinear Real\n  Arithmetic",
        "authors": [
            "Zhonghan Wang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Satisfiability modulo nonlinear real arithmetic theory (SMT(NRA)) solving is\nessential to multiple applications, including program verification, program\nsynthesis and software testing. In this context, recently model constructing\nsatisfiability calculus (MCSAT) has been invented to directly search for models\nin the theory space. Although following papers discussed practical directions\nand updates on MCSAT, less attention has been paid to the detailed\nimplementation. In this paper, we present an efficient implementation of\ndynamic variable orderings of MCSAT, called dnlsat. We show carefully designed\ndata structures and promising mechanisms, such as branching heuristic, restart,\nand lemma management. Besides, we also give a theoretical study of potential\ninfluences brought by the dynamic variablr ordering. The experimental\nevaluation shows that dnlsat accelerates the solving speed and solves more\nsatisfiable instances than other state-of-the-art SMT solvers.\n  Demonstration Video: https://youtu.be/T2Z0gZQjnPw\n  Code: https://github.com/yogurt-shadow/dnlsat/tree/master/code\n  Benchmark https://zenodo.org/records/10607722/files/QF_NRA.tar.zst?download=1\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18964v1"
    },
    {
        "title": "Algorithms for Recursive Block Matrices",
        "authors": [
            "Stephen M. Watt"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We study certain linear algebra algorithms for recursive block matrices. This\nrepresentation has useful practical and theoretical properties. We summarize\nsome previous results for block matrix inversion and present some results on\ntriangular decomposition of block matrices. The case of inverting matrices over\na ring that is neither formally real nor formally complex was inspired by\nGonzalez-Vega et al.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.03976v1"
    },
    {
        "title": "Probabilistic Shoenfield Machines",
        "authors": [
            "Maksymilian Bujok",
            "Adam Mata"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  This article provides the theoretical framework of Probabilistic Shoenfield\nMachines (PSMs), an extension of the classical Shoenfield Machine that models\nrandomness in the computation process. PSMs are brought in contexts where\ndeterministic computation is insufficient, such as randomized algorithms. By\nallowing transitions to multiple possible states with certain probabilities,\nPSMs can solve problems and make decisions based on probabilistic outcomes,\nhence expanding the variety of possible computations. We provide an overview of\nPSMs, detailing their formal definitions as well as the computation mechanism\nand their equivalence with Non-deterministic Shoenfield Machines (NSM).\n",
        "pdf_link": "http://arxiv.org/pdf/2407.05777v1"
    },
    {
        "title": "Equality of morphic sequences",
        "authors": [
            "Hans Zantema"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Morphic sequences form a natural class of infinite sequences, typically\ndefined as the coding of a fixed point of a morphism. Different morphisms and\ncodings may yield the same morphic sequence. This paper investigates how to\nprove that two such representations of a morphic sequence by morphisms\nrepresent the same sequence. In particular, we focus on the smallest\nrepresentations of the subsequences of the binary Fibonacci sequence obtained\nby only taking the even or odd elements. The proofs we give are induction\nproofs of several properties simultaneously, and are typically found fully\nautomatically by a tool that we developed.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.15721v2"
    },
    {
        "title": "Recent Developments in Real Quantifier Elimination and Cylindrical\n  Algebraic Decomposition",
        "authors": [
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  This extended abstract accompanies an invited talk at CASC 2024, which\nsurveys recent developments in Real Quantifier Elimination (QE) and Cylindrical\nAlgebraic Decomposition (CAD). After introducing these concepts we will first\nconsider adaptations of CAD inspired by computational logic, in particular the\nalgorithms which underpin modern SAT solvers. CAD theory has found use in\ncollaboration with these via the Satisfiability Modulo Theory (SMT) paradigm;\nwhile the ideas behind SAT/SMT have led to new algorithms for Real QE. Second\nwe will consider the optimisation of CAD through the use of Machine Learning\n(ML). The choice of CAD variable ordering has become a key case study for the\nuse of ML to tune algorithms in computer algebra. We will also consider how\nexplainable AI techniques might give insight for improved computer algebra\nsoftware without any reliance on ML in the final code.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19781v1"
    },
    {
        "title": "An Abstraction-Preserving Block Matrix Implementation in Maple",
        "authors": [
            "David J. Jeffrey",
            "Stephen M. Watt"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  A Maple implementation of partitioned matrices is described. A recursive\nblock data structure is used, with all operations preserving the block\nabstraction. These include constructor functions, ring operations such as\naddition and product, and inversion. The package is demonstrated by calculating\nthe PLU factorization of a block matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.02112v1"
    },
    {
        "title": "First steps towards Computational Polynomials in Lean",
        "authors": [
            "James Harold Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  The proof assistant Lean has support for abstract polynomials, but this is\nnot necessarily the same as support for computations with polynomials. Lean is\nalso a functional programming language, so it should be possible to implement\ncomputational polynomials in Lean. It turns out not to be as easy as the naive\nauthor thought.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04564v2"
    },
    {
        "title": "MathPartner: An Artificial Intelligence Cloud Service",
        "authors": [
            "Gennadi Malaschonok",
            "Alexandr Seliverstov"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In a broad sense, artificial intelligence is a service to find a solution to\ncomplex intellectual problems. In this sense, the MathPartner service provides\nartificial intelligence that allows us to formulate questions and receive\nanswers to questions formulated in a mathematical language. For mathematicians\nand physicists today, such a language is \\LaTeX. The MathPartner service uses a\ndialect of \\LaTeX, which is called Mathpar. The service is a cloud-based\ncomputer algebra system and provides users with the opportunity to solve many\nmathematical problems. In this publication, we focus only on a small class of\nextremum problems, which are widely applied in economics, management,\nlogistics, and in many engineering fields. In particular, we consider the\nshortest path problem and discuss an algorithm that is based on the tropical\nmathematics. The ability to work with many types of classical and tropical\nalgebras, which are freely available to users, is an important distinguishing\nfeature of this intelligent tool for symbolic-numerical calculations. We also\nconsider the use of the simplex algorithm for solving optimization problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04999v1"
    },
    {
        "title": "Towards Verified Polynomial Factorisation",
        "authors": [
            "James H. Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Computer algebra systems are really good at factoring polynomials, i.e.\nwriting f as a product of irreducible factors. It is relatively easy to verify\nthat we have a factorisation, but verifying that these factors are irreducible\nis a much harder problem. This paper reports work-in-progress to do such\nverification in Lean.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09533v1"
    },
    {
        "title": "A Generalization of Habicht's Theorem for Subresultants of Several\n  Univariate Polynomials",
        "authors": [
            "Hoon Hong",
            "Jiaqi Meng",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Subresultants of two univariate polynomials are one of the most classic and\nubiquitous objects in computational algebra and algebraic geometry. In 1948,\nHabicht discovered and proved interesting relationships among subresultants.\nThose relationships were found to be useful for both structural understanding\nand efficient computation. Often one needs to consider several (possibly more\nthan two) polynomials. It is rather straightforward to generalize the notion of\nsubresultants to several polynomials. However, it is not obvious (in fact,\nquite challenging) to generalize the Habicht's result to several polynomials.\nThe main contribution of this paper is to provide such a generalization.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12727v1"
    },
    {
        "title": "A Syzygial Method for Equidimensional Decomposition",
        "authors": [
            "Rafael Mohr"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Based on a theorem by Vasconcelos, we give an algorithm for equidimensional\ndecomposition of algebraic sets using syzygy computations via Gr\\\"obner bases.\nThis algorithm avoids the use of elimination, homological algebra and\nprocessing the input equations one-by-one present in previous algorithms. We\nexperimentally demonstrate the practical interest of our algorithm compared to\nthe state of the art.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.17785v1"
    },
    {
        "title": "Generalized Fixed-Depth Prefix and Postfix Symbolic Regression Grammars",
        "authors": [
            "Edward Finkelstein"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We develop faultless, fixed-depth, string-based, prefix and postfix symbolic\nregression grammars, capable of producing \\emph{any} expression from a set of\noperands, unary operators and/or binary operators. Using these grammars, we\noutline simplified forms of 5 popular heuristic search strategies: Brute Force\nSearch, Monte Carlo Tree Search, Particle Swarm Optimization, Genetic\nProgramming, and Simulated Annealing. For each algorithm, we compare the\nrelative performance of prefix vs postfix for ten ground-truth expressions\nimplemented entirely within a common C++/Eigen framework. Our experiments show\na comparatively strong correlation between the average number of nodes per\nlayer of the ground truth expression tree and the relative performance of\nprefix vs postfix. The fixed-depth grammars developed herein can enhance\nscientific discovery by increasing the efficiency of symbolic regression,\nenabling faster identification of accurate mathematical models across various\ndisciplines.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.08137v1"
    },
    {
        "title": "Algorithmic reduction of polynomially nonlinear PDE systems to\n  parametric ODE systems",
        "authors": [
            "Siyuan Deng",
            "Michelle Hatzel",
            "Gregory Reid",
            "Wenqiang Yang",
            "Wenyuan Wu"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Differential-elimination algorithms apply a finite number of differentiations\nand eliminations to systems of partial differential equations. For systems that\nare polynomially nonlinear with rational number coefficients, they guarantee\nthe inclusion of missing integrability conditions and the statement of of\nexistence and uniqueness theorems for local analytic solutions of such systems.\nFurther, they are useful in obtaining systems in a form more amenable to exact\nand approximate solution methods.\n  Maple's \\maple{dsolve} and \\maple{pdsolve} algorithms for solving PDE and ODE\noften automatically call such routines during applications. Indeed, even casual\nusers of Maple's dsolve and pdsolve commands have probably unknowingly used\nMaple's differential-elimination algorithms.\n  Suppose that a system of PDE has been reduced by differential-elimination to\na system whose automatic existence and uniqueness algorithm has been determined\nto be finite-dimensional. We present an algorithm for rewriting the output as a\nsystem of parameterized ODE. Exact methods and numerical methods for solving\nODE and DAE can be applied to this form.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12110v1"
    },
    {
        "title": "Extensions of the Cylindrical Algebraic Covering Method for Quantifiers",
        "authors": [
            "Jasper Nalbach",
            "Gereon Kremer"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  The cylindrical algebraic covering method was originally proposed to decide\nthe satisfiability of a set of non-linear real arithmetic constraints. We\nreformulate and extend the cylindrical algebraic covering method to allow for\nchecking the truth of arbitrary non-linear arithmetic formulas, adding support\nfor both quantifiers and Boolean structure. Furthermore, we also propose a\nvariant to perform quantifier elimination on such formulas. After introducing\nthe algorithm, we elaborate on various extensions, optimizations and\nheuristics. Finally, we present an experimental evaluation of our\nimplementation and provide a comparison with state-of-the-art SMT solvers and\nquantifier elimination tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03070v1"
    },
    {
        "title": "Case Frames and Case-Based Arguments in Statutory Interpretation",
        "authors": [
            "Michal Araszkiewicz"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We introduce a novel conceptual Case Frame model that represents the content\nof cases involving statutory interpretation within civil law frameworks,\naccompanied by an associated argument scheme enriched with critical questions.\nBy validating our approach with a modest dataset, we demonstrate its robustness\nand practical applicability. Our model not only provides a structured method\nfor analyzing statutory interpretation but also highlights the distinct needs\nof lawyers operating under statutory law compared to those reasoning with\ncommon law precedents. The model presented here is a step towards developing a\nhybrid Machine Learning and Argumentation system that includes a module for\nconstructing well-structured arguments from textual datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06873v1"
    },
    {
        "title": "Symbolic Algorithm for Solving SLAEs with Multi-Diagonal Coefficient\n  Matrices",
        "authors": [
            "Milena Veneva"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  This paper presents a generalised symbolic algorithm for solving systems of\nlinear algebraic equations with multi-diagonal coefficient matrices. The\nalgorithm is given in a pseudocode. A theorem which gives the condition for\ncorrectness of the algorithm is formulated and proven. Formula for the\ncomplexity of the multi-diagonal numerical algorithm is obtained.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11889v1"
    },
    {
        "title": "On Minimal and Minimum Cylindrical Algebraic Decompositions",
        "authors": [
            "Lucas Michel",
            "Pierre Mathonet",
            "Naïm Zénaïdi"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We consider cylindrical algebraic decompositions (CADs) as a tool for\nrepresenting semi-algebraic subsets of $\\mathbb{R}^n$. In this framework, a CAD\n$\\mathscr{C}$ is adapted to a given set $S$ if $S$ is a union of cells of\n$\\mathscr{C}$. Different algorithms computing an adapted CAD may produce\ndifferent outputs, usually with redundant cell divisions. In this paper we\nanalyse the possibility to remove the superfluous data. More precisely we\nconsider the set CAD$(S)$ of CADs that are adapted to $S$, endowed with the\nrefinement partial order and we study the existence of minimal and minimum\nelements in this poset.\n  We show that for every semi-algebraic set $S$ of $\\mathbb{R}^n$ and every CAD\n$\\mathscr{C}$ adapted to $S$, there is a minimal CAD adapted to $S$ and smaller\n(i.e. coarser) than or equal to $\\mathscr{C}$. Moreover, when $n=1$ or $n=2$,\nwe strengthen this result by proving the existence of a minimum element in\nCAD$(S)$. Astonishingly for $n \\geq 3$, there exist semi-algebraic sets whose\nassociated poset of adapted CADs does not admit a minimum. We prove this result\nby providing explicit examples. We finally use a reduction relation on CAD$(S)$\nto define an algorithm for the computation of minimal CADs. We conclude with a\ncharacterization of those semi-algebraic sets $S$ for which CAD$(S)$ has a\nminimum by means of confluence of the associated reduction system.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13218v1"
    },
    {
        "title": "Botfip-LLM: An Enhanced Multimodal Scientific Computing Framework\n  Leveraging Knowledge Distillation from Large Language Models",
        "authors": [
            "Tianhao Chen",
            "Pengbo Xu",
            "Pengbo Xu"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In recent years, the introduction of AI technologies has brought\ntransformative changes to scientific computing. However, AI models typically\nfocus on single-task and single-modal data processing, limiting their\napplication. To address this, multimodal scientific computing frameworks have\nbecome a trend. The Botfip framework aligns function images with symbolic\noperation trees through multimodal training, extracting deep scientific\ninformation. However, Botfip struggles with processing Formula Strings, leading\nto inadequate understanding in multimodal learning. To enhance Botfip's\nlearning of Formula Strings and expand its applicability to related tasks, we\npropose the Botfip-LLM framework based on knowledge distillation, incorporating\npre-trained large language models for aligning symbolic tree data. Experimental\nanalysis shows that the choice of LLM is crucial, with ChatGLM-2 outperforming\nothers in training and testing. Botfip-LLM not only improves performance,\ngeneralization, and extrapolation over the original Botfip model but also\nsignificantly enhances applicability to Formula String-related tasks, enabling\nmore diverse task handling.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.15525v1"
    },
    {
        "title": "Semantics of Division for Polynomial Solvers",
        "authors": [
            "Christopher W. Brown"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  How to handle division in systems that compute with logical formulas\ninvolving what would otherwise be polynomial constraints over the real numbers\nis a surprisingly difficult question. This paper argues that existing\napproaches from both the computer algebra and computational logic communities\nare unsatisfactory for systems that consider the satisfiability of formulas\nwith quantifiers or that perform quantifier elimination. To address this, we\npropose the notion of the fair-satisfiability of a formula, use it to\ncharacterize formulas with divisions that are well-defined, meaning that they\nadequately guard divisions against division by zero, and provide a translation\nalgorithm that converts a formula with divisions into a purely polynomial\nformula that is satisfiable if and only if the original formula is\nfair-satisfiable. This provides a semantics for division with some nice\nproperties, which we describe and prove in the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.00963v1"
    },
    {
        "title": "A Monadic Calculus with Episodic Flows",
        "authors": [
            "Sotirios Henning"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We define computational atoms named \"actions\" equipped primarily with three\noperations: reduction, collection, and inspection. We show how actions can be\nused for decision-making algorithms from simple axioms. We describe the\nencodings of typical data structures as actions, and provide a method of\nanalysis for algorithms on the basis of data mutation.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.07939v1"
    },
    {
        "title": "Positivity Proofs for Linear Recurrences through Contracted Cones",
        "authors": [
            "Alaa Ibrahim",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Deciding the positivity of a sequence defined by a linear recurrence with\npolynomial coefficients and initial condition is difficult in general. Even in\nthe case of recurrences with constant coefficients, it is known to be decidable\nonly for order up to~5. We consider a large class of linear recurrences of\narbitrary order, with polynomial coefficients, for which an algorithm decides\npositivity for initial conditions outside of a hyperplane. The underlying\nalgorithm constructs a cone, contracted by the recurrence operator, that allows\na proof of positivity by induction. The existence and construction of such\ncones relies on the extension of the classical Perron-Frobenius theory to\nmatrices leaving a cone invariant.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.08576v1"
    },
    {
        "title": "Invariants: Computation and Applications",
        "authors": [
            "Irina A. Kogan"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Invariants withstand transformations and, therefore, represent the essence of\nobjects or phenomena. In mathematics, transformations often constitute a group\naction. Since the 19th century, studying the structure of various types of\ninvariants and designing methods and algorithms to compute them remains an\nactive area of ongoing research with an abundance of applications. In this\nincredibly vast topic, we focus on two particular themes displaying a fruitful\ninterplay between the differential and algebraic invariant theories. First, we\nshow how an algebraic adaptation of the moving frame method from differential\ngeometry leads to a practical algorithm for computing a generating set of\nrational invariants. Then we discuss the notion of differential invariant\nsignature, its role in solving equivalence problems in geometry and algebra,\nand some successes and challenges in designing algorithms based on this notion.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.13306v1"
    },
    {
        "title": "An Algorithm for Discriminating the Complete Multiplicities of a\n  Parametric Univariate Polynomial",
        "authors": [
            "Simin Qin",
            "Bican Xia",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In this paper, we tackle the parametric complete multiplicity problem for a\nunivariate polynomial. Our approach to the parametric complete multiplicity\nproblem has a significant difference from the classical method, which relies on\nrepeated gcd computation. Instead, we introduce a novel technique that uses\nincremental gcds of the given polynomial and its high-order derivatives. This\napproach, formulated as non-nested subresultants, sidesteps the exponential\nexpansion of polynomial degrees in the generated condition. We also uncover the\nhidden structure between the incremental gcds and pseudo-remainders. Our\nanalysis reveals that the conditions produced by our new algorithm are simpler\nthan those generated by the classical approach in most cases. Experiments show\nthat our algorithm is faster than the one based on repeated gcd computation for\nproblems with relatively big size.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.20332v1"
    },
    {
        "title": "THOI: An efficient and accessible library for computing higher-order\n  interactions enhanced by batch-processing",
        "authors": [
            "Laouen Belloli",
            "Pedro Mediano",
            "Rodrigo Cofré",
            "Diego Fernandez Slezak",
            "Rubén Herzog"
        ],
        "category": "cs.SC",
        "published_year": "2025",
        "summary": "  Complex systems are characterized by nonlinear dynamics, multi-level\ninteractions, and emergent collective behaviors. Traditional analyses that\nfocus solely on pairwise interactions often oversimplify these systems,\nneglecting the higher-order interactions critical for understanding their full\ncollective dynamics. Recent advances in multivariate information theory provide\na principled framework for quantifying these higher-order interactions,\ncapturing key properties such as redundancy, synergy, shared randomness, and\ncollective constraints. However, two major challenges persist: accurately\nestimating joint entropies and addressing the combinatorial explosion of\ninteracting terms. To overcome these challenges, we introduce THOI (Torch-based\nHigh-Order Interactions), a novel, accessible, and efficient Python library for\ncomputing high-order interactions in continuous-valued systems. THOI leverages\nthe well-established Gaussian copula method for joint entropy estimation,\ncombined with state-of-the-art batch and parallel processing techniques to\noptimize performance across CPU, GPU, and TPU environments. Our results\ndemonstrate that THOI significantly outperforms existing tools in terms of\nspeed and scalability. For larger systems, where exhaustive analysis is\ncomputationally impractical, THOI integrates optimization strategies that make\nhigher-order interaction analysis feasible. We validate THOI accuracy using\nsynthetic datasets with parametrically controlled interactions and further\nillustrate its utility by analyzing fMRI data from human subjects in wakeful\nresting states and under deep anesthesia. Finally, we analyzed over 900\nreal-world and synthetic datasets, establishing a comprehensive framework for\napplying higher-order interaction (HOI) analysis in complex systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.03381v1"
    },
    {
        "title": "A Unification of Zeilberger's Algorithm and Its q-Analogue",
        "authors": [
            "Shaoshi Chen",
            "Hao Du",
            "Yiman Gao",
            "Hui Huang",
            "Ziming Li"
        ],
        "category": "cs.SC",
        "published_year": "2025",
        "summary": "  We adapt the theory of normal and special polynomials from symbolic\nintegration to the summation setting, and then built up a general framework\nembracing both the usual shift case and the q-shift case. In the context of\nthis general framework, we develop a unified reduction algorithm, and\nsubsequently a creative telescoping algorithm, applicable to both\nhypergeometric terms and their q-analogues. Our algorithms allow to split up\nthe usual shift case and the q-shift case only when it is really necessary, and\nthus instantly reveal the intrinsic differences between these two cases.\nComputational experiments are also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.03837v1"
    },
    {
        "title": "Recursive matrix algorithms, distributed dynamic control, scaling,\n  stability",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "category": "cs.SC",
        "published_year": "2025",
        "summary": "  The report is devoted to the concept of creating block-recursive matrix\nalgorithms for computing on a supercomputer with distributed memory and dynamic\ndecentralized control.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.05318v1"
    },
    {
        "title": "The integration of systems of linear PDEs using conservation laws of\n  syzygies",
        "authors": [
            "Thomas Wolf"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  A new integration technique is presented for systems of linear partial\ndifferential equations (PDEs) for which syzygies can be formulated that obey\nconservation laws. These syzygies come for free as a by-product of the\ndifferential Groebner Basis computation. Compared with the more obvious way of\nintegrating a single equation and substituting the result in other equations\nthe new technique integrates more than one equation at once and therefore\nintroduces temporarily fewer new functions of integration that in addition\ndepend on fewer variables. Especially for high order PDE systems in many\nvariables the conventional integration technique may lead to an explosion of\nthe number of functions of integration which is avoided with the new method. A\nfurther benefit is that redundant free functions in the solution are either\nprevented or that their number is at least reduced.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0301028v1"
    },
    {
        "title": "gTybalt - a free computer algebra system",
        "authors": [
            "Stefan Weinzierl"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  This article documents the free computer algebra system \"gTybalt\". The\nprogram is build on top of other packages, among others GiNaC, TeXmacs and\nRoot. It offers the possibility of interactive symbolic calculations within the\nC++ programming language. Mathematical formulae are visualized using TeX fonts.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0304043v1"
    },
    {
        "title": "Computing Igusa's Local Zeta Functions of Univariate Polynomials, and\n  Linear Feedback Shift Registers",
        "authors": [
            "W. A. Zuniga-Galindo"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  We give a polynomial time algorithm for computing the Igusa local zeta\nfunction $Z(s,f)$ attached to a polynomial $f(x)\\in \\QTR{Bbb}{Z}[x]$, in one\nvariable, with splitting field $\\QTR{Bbb}{Q}$, and a prime number $p$. We also\npropose a new class of Linear Feedback Shift Registers based on the computation\nof Igusa's local zeta function.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0309050v1"
    },
    {
        "title": "Weak Bezout inequality for D-modules",
        "authors": [
            "Dima Grigoriev"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  Let $\\{w_{i,j}\\}_{1\\leq i\\leq n, 1\\leq j\\leq s} \\subset\nL_m=F(X_1,...,X_m)[{\\partial \\over \\partial X_1},..., {\\partial \\over \\partial\nX_m}]$ be linear partial differential operators of orders with respect to\n${\\partial \\over \\partial X_1},..., {\\partial \\over \\partial X_m}$ at most $d$.\nWe prove an upper bound n(4m^2d\\min\\{n,s\\})^{4^{m-t-1}(2(m-t))} on the leading\ncoefficient of the Hilbert-Kolchin polynomial of the left $L_m$-module\n$<\\{w_{1,j}, ..., w_{n,j}\\}_{1\\leq j \\leq s} > \\subset L_m^n$ having the\ndifferential type $t$ (also being equal to the degree of the Hilbert-Kolchin\npolynomial). The main technical tool is the complexity bound on solving systems\nof linear equations over {\\it algebras of fractions} of the form\n$$L_m(F[X_1,..., X_m, {\\partial \\over \\partial X_1},..., {\\partial \\over\n\\partial X_k}])^{-1}.$$\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0311053v1"
    },
    {
        "title": "Maple+GrTensorII libraries for cosmology",
        "authors": [
            "Dumitru N. Vulcanov",
            "Valentina D. Vulcanov"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  The article mainly presents some results in using MAPLE platform for computer\nalgebra and GrTensorII package in doing calculations for theoretical and\nnumerical cosmology\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0409006v1"
    },
    {
        "title": "Efficient polynomial time algorithms computing industrial-strength\n  primitive roots",
        "authors": [
            "Jacques Dubrois",
            "Jean-Guillaume Dumas"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  E. Bach, following an idea of T. Itoh, has shown how to build a small set of\nnumbers modulo a prime p such that at least one element of this set is a\ngenerator of $\\pF{p}$\\cite{Bach:1997:sppr,Itoh:2001:PPR}. E. Bach suggests also\nthat at least half of his set should be generators. We show here that a slight\nvariant of this set can indeed be made to contain a ratio of primitive roots as\nclose to 1 as necessary. We thus derive several algorithms computing primitive\nroots correct with very high probability in polynomial time. In particular we\npresent an asymptotically $O^{\\sim}(\\sqrt{\\frac{1}{\\epsilon}}log^1.5(p) +\n\\log^2(p))$ algorithm providing primitive roots of $p$ with probability of\ncorrectness greater than $1-\\epsilon$ and several $O(log^\\alpha(p))$, $\\alpha\n\\leq 5.23$ algorithms computing \"Industrial-strength\" primitive roots with\nprobabilities e.g. greater than the probability of \"hardware malfunctions\".\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0409029v2"
    },
    {
        "title": "Can Computer Algebra be Liberated from its Algebraic Yoke ?",
        "authors": [
            "R. Barrere"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  So far, the scope of computer algebra has been needlessly restricted to exact\nalgebraic methods. Its possible extension to approximate analytical methods is\ndiscussed. The entangled roles of functional analysis and symbolic programming,\nespecially the functional and transformational paradigms, are put forward. In\nthe future, algebraic algorithms could constitute the core of extended symbolic\nmanipulation systems including primitives for symbolic approximations.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0502015v1"
    },
    {
        "title": "The complexity of computing the Hilbert polynomial of smooth\n  equidimensional complex projective varieties",
        "authors": [
            "Peter Buergisser",
            "Martin Lotz"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We continue the study of counting complexity begun in [Buergisser, Cucker 04]\nand [Buergisser, Cucker, Lotz 05] by proving upper and lower bounds on the\ncomplexity of computing the Hilbert polynomial of a homogeneous ideal. We show\nthat the problem of computing the Hilbert polynomial of a smooth\nequidimensional complex projective variety can be reduced in polynomial time to\nthe problem of counting the number of complex common zeros of a finite set of\nmultivariate polynomials. Moreover, we prove that the more general problem of\ncomputing the Hilbert polynomial of a homogeneous ideal is polynomial space\nhard. This implies polynomial space lower bounds for both the problems of\ncomputing the rank and the Euler characteristic of cohomology groups of\ncoherent sheaves on projective space, improving the #P-lower bound of Bach (JSC\n1999).\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0502044v1"
    },
    {
        "title": "Computing the Rank and a Small Nullspace Basis of a Polynomial Matrix",
        "authors": [
            "Arne Storjohann",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We reduce the problem of computing the rank and a nullspace basis of a\nunivariate polynomial matrix to polynomial matrix multiplication. For an input\nn x n matrix of degree d over a field K we give a rank and nullspace algorithm\nusing about the same number of operations as for multiplying two matrices of\ndimension n and degree d. If the latter multiplication is done in\nMM(n,d)=softO(n^omega d) operations, with omega the exponent of matrix\nmultiplication over K, then the algorithm uses softO(MM(n,d)) operations in K.\nThe softO notation indicates some missing logarithmic factors. The method is\nrandomized with Las Vegas certification. We achieve our results in part through\na combination of matrix Hensel high-order lifting and matrix minimal fraction\nreconstruction, and through the computation of minimal or small degree vectors\nin the nullspace seen as a K[x]-module\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0505030v1"
    },
    {
        "title": "Asymptotically fast polynomial matrix algorithms for multivariable\n  systems",
        "authors": [
            "Claude-Pierre Jeannerod",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We present the asymptotically fastest known algorithms for some basic\nproblems on univariate polynomial matrices: rank, nullspace, determinant,\ngeneric inverse, reduced form. We show that they essentially can be reduced to\ntwo computer algebra techniques, minimal basis computations and matrix fraction\nexpansion/reconstruction, and to polynomial matrix multiplication. Such\nreductions eventually imply that all these problems can be solved in about the\nsame amount of time as polynomial matrix multiplication.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0508113v1"
    },
    {
        "title": "Computing the Kalman form",
        "authors": [
            "Clément Pernet",
            "Aude Rondepierre",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We present two algorithms for the computation of the Kalman form of a linear\ncontrol system. The first one is based on the technique developed by\nKeller-Gehrig for the computation of the characteristic polynomial. The cost is\na logarithmic number of matrix multiplications. To our knowledge, this improves\nthe best previously known algebraic complexity by an order of magnitude. Then\nwe also present a cubic algorithm proven to more efficient in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0510014v4"
    },
    {
        "title": "Extension of the functionality of the symbolic program FORM by external\n  software",
        "authors": [
            "M. Tentyukov",
            "J. A. M. Vermaseren"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  We describe the implementation of facilities for the communication with\nexternal resources in the Symbolic Manipulation System FORM. This is done\naccording to the POSIX standards defined for the UNIX operating system. We\npresent a number of examples that illustrate the increased power due to these\nnew capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604052v2"
    },
    {
        "title": "A Recursive Method for Determining the One-Dimensional Submodules of\n  Laurent-Ore Modules",
        "authors": [
            "Ziming Li",
            "Michael F. Singer",
            "Min Wu",
            "Dabin Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  We present a method for determining the one-dimensional submodules of a\nLaurent-Ore module. The method is based on a correspondence between\nhyperexponential solutions of associated systems and one-dimensional\nsubmodules. The hyperexponential solutions are computed recursively by solving\na sequence of first-order ordinary matrix equations. As the recursion proceeds,\nthe matrix equations will have constant coefficients with respect to the\noperators that have been considered.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604084v1"
    },
    {
        "title": "Efficient algorithm for computing the Euler-Poincaré characteristic of\n  a semi-algebraic set defined by few quadratic inequalities",
        "authors": [
            "Saugata Basu"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  We present an algorithm which takes as input a closed semi-algebraic set, $S\n\\subset \\R^k$, defined by \\[ P_1 \\leq 0, ..., P_\\ell \\leq 0, P_i \\in\n\\R[X_1,...,X_k], \\deg(P_i) \\leq 2, \\] and computes the Euler-Poincar\\'e\ncharacteristic of $S$. The complexity of the algorithm is $k^{O(\\ell)}$.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605082v1"
    },
    {
        "title": "A linear algebra approach to the differentiation index of generic DAE\n  systems",
        "authors": [
            "Lisi D'Alfonso",
            "Gabriela Jeronimo",
            "Pablo Solerno"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  The notion of differentiation index for DAE systems of arbitrary order with\ngeneric second members is discussed by means of the study of the behavior of\nthe ranks of certain Jacobian associated sub-matrices. As a by-product, we\nobtain upper bounds for the regularity of the Hilbert-Kolchin function and the\norder of the ideal associated to the DAE systems under consideration, not\ndepending on characteristic sets. Some quantitative and algorithmic results\nconcerning differential transcendence bases and induced equivalent explicit ODE\nsystems are also established.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0608064v2"
    },
    {
        "title": "On factorization and solution of multidimensional linear partial\n  differential equations",
        "authors": [
            "S. P. Tsarev"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  We describe a method of obtaining closed-form complete solutions of certain\nsecond-order linear partial differential equations with more than two\nindependent variables. This method generalizes the classical method of Laplace\ntransformations of second-order hyperbolic equations in the plane and is based\non an idea given by Ulisse Dini in 1902.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0609075v2"
    },
    {
        "title": "Differential Equations for Algebraic Functions",
        "authors": [
            "Alin Bostan",
            "Frédéric Chyzak",
            "Bruno Salvy",
            "Grégoire Lecerf",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  It is classical that univariate algebraic functions satisfy linear\ndifferential equations with polynomial coefficients. Linear recurrences follow\nfor the coefficients of their power series expansions. We show that the linear\ndifferential equation of minimal order has coefficients whose degree is cubic\nin the degree of the function. We also show that there exists a linear\ndifferential equation of order linear in the degree whose coefficients are only\nof quadratic degree. Furthermore, we prove the existence of recurrences of\norder and degree close to optimal. We study the complexity of computing these\ndifferential equations and recurrences. We deduce a fast algorithm for the\nexpansion of algebraic series.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703121v2"
    },
    {
        "title": "A Proof of a Recursion for Bessel Moments",
        "authors": [
            "Jonathan M. Borwein",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  We provide a proof of a conjecture in (Bailey, Borwein, Borwein, Crandall\n2007) on the existence and form of linear recursions for moments of powers of\nthe Bessel function $K_0$.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.1409v2"
    },
    {
        "title": "Differential invariants of a Lie group action: syzygies on a generating\n  set",
        "authors": [
            "Evelyne Hubert"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  Given a group action, known by its infinitesimal generators, we exhibit a\ncomplete set of syzygies on a generating set of differential invariants. For\nthat we elaborate on the reinterpretation of Cartan's moving frame by Fels and\nOlver (1999). This provides constructive tools for exploring algebras of\ndifferential invariants.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4318v4"
    },
    {
        "title": "On Ritt's decomposition Theorem in the case of finite fields",
        "authors": [
            "Jaime Gutierrez",
            "David Sevilla"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  A classical theorem by Ritt states that all the complete decomposition chains\nof a univariate polynomial satisfying a certain tameness condition have the\nsame length. In this paper we present our conclusions about the generalization\nof these theorem in the case of finite coefficient fields when the tameness\ncondition is dropped.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.3976v2"
    },
    {
        "title": "On decomposition of tame polynomials and rational functions",
        "authors": [
            "Jaime Gutierrez",
            "David Sevilla"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In this paper we present algorithmic considerations and theoretical results\nabout the relation between the orders of certain groups associated to the\ncomponents of a polynomial and the order of the group that corresponds to the\npolynomial, proving it for arbitrary tame polynomials, and considering the case\nof rational functions.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.1649v1"
    },
    {
        "title": "Computation of unirational fields",
        "authors": [
            "Jaime Gutierrez",
            "David Sevilla"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  One of the main contributions which Volker Weispfenning made to mathematics\nis related to Groebner bases theory. In this paper we present an algorithm for\ncomputing all algebraic intermediate subfields in a separably generated\nunirational field extension (which in particular includes the zero\ncharacteristic case). One of the main tools is Groebner bases theory. Our\nalgorithm also requires computing primitive elements and factoring over\nalgebraic extensions. Moreover, the method can be extended to finitely\ngenerated K-algebras.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.1679v1"
    },
    {
        "title": "Computation of unirational fields (extended abstract)",
        "authors": [
            "Jaime Gutierrez",
            "David Sevilla"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In this paper we present an algorithm for computing all algebraic\nintermediate subfields in a separably generated unirational field extension\n(which in particular includes the zero characteristic case). One of the main\ntools is Groebner bases theory. Our algorithm also requires computing computing\nprimitive elements and factoring over algebraic extensions. Moreover, the\nmethod can be extended to finitely generated K-algebras.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.1707v1"
    },
    {
        "title": "\"E pluribus unum\" or How to Derive Single-equation Descriptions for\n  Output-quantities in Nonlinear Circuits using Differential Algebra",
        "authors": [
            "Eberhard H. -A. Gerbracht"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In this paper we describe by a number of examples how to deduce one single\ncharacterizing higher order differential equation for output quantities of an\nanalog circuit.\n  In the linear case, we apply basic \"symbolic\" methods from linear algebra to\nthe system of differential equations which is used to model the analog circuit.\nFor nonlinear circuits and their corresponding nonlinear differential\nequations, we show how to employ computer algebra tools implemented in Maple,\nwhich are based on differential algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.2992v1"
    },
    {
        "title": "Computing the fixing group of a rational function",
        "authors": [
            "Jaime Gutierrez",
            "Rosario Rubio",
            "David Sevilla"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  Let G=Aut_K (K(x)) be the Galois group of the transcendental degree one pure\nfield extension K(x)/K. In this paper we describe polynomial time algorithms\nfor computing the field Fix(H) fixed by a subgroup H < G and for computing the\nfixing group G_f of a rational function f in K(x).\n",
        "pdf_link": "http://arxiv.org/pdf/0805.2331v1"
    },
    {
        "title": "Unirational fields of transcendence degree one and functional\n  decomposition",
        "authors": [
            "Jaime Gutierrez",
            "Rosario Rubio",
            "David Sevilla"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In this paper we present an algorithm to compute all unirational fields of\ntranscendence degree one containing a given finite set of multivariate rational\nfunctions. In particular, we provide an algorithm to decompose a multivariate\nrational function f of the form f=g(h), where g is a univariate rational\nfunction and h a multivariate one.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.2338v1"
    },
    {
        "title": "Simultaneous Modular Reduction and Kronecker Substitution for Small\n  Finite Fields",
        "authors": [
            "Jean-Guillaume Dumas",
            "Laurent Fousse",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We present algorithms to perform modular polynomial multiplication or modular\ndot product efficiently in a single machine word. We pack polynomials into\nintegers and perform several modular operations with machine integer or\nfloating point arithmetic. The modular polynomials are converted into integers\nusing Kronecker substitution (evaluation at a sufficiently large integer). With\nsome control on the sizes and degrees, arithmetic operations on the polynomials\ncan be performed directly with machine integers or floating point numbers and\nthe number of conversions can be reduced. We also present efficient ways to\nrecover the modular values of the coefficients. This leads to practical gains\nof quite large constant factors for polynomial multiplication, prime field\nlinear algebra and small extension field arithmetic.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.0063v1"
    },
    {
        "title": "Obtaining Exact Interpolation Multivariate Polynomial by Approximation",
        "authors": [
            "Yong Feng",
            "Jingzhong Zhang",
            "Xiaolin Qin",
            "Xun Yuan"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In some fields such as Mathematics Mechanization, automated reasoning and\nTrustworthy Computing etc., exact results are needed. Symbolic computations are\nused to obtain the exact results. Symbolic computations are of high complexity.\nIn order to improve the situation, exactly interpolating methods are often\nproposed for the exact results and approximate interpolating methods for the\napproximate ones. In this paper, we study how to obtain exact interpolation\npolynomial with rational coefficients by approximate interpolating methods.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.1476v1"
    },
    {
        "title": "An Unified Definition of Data Mining",
        "authors": [
            "Christoph Schommer"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  Since many years, theoretical concepts of Data Mining have been developed and\nimproved. Data Mining has become applied to many academic and industrial\nsituations, and recently, soundings of public opinion about privacy have been\ncarried out. However, a consistent and standardized definition is still\nmissing, and the initial explanation given by Frawley et al. has pragmatically\noften changed over the years. Furthermore, alternative terms like Knowledge\nDiscovery have been conjured and forged, and a necessity of a Data Warehouse\nhas been endeavoured to persuade the users. In this work, we pick up current\ndefinitions and introduce an unified definition that covers existing attempted\nexplanations. For this, we appeal to the natural original of chemical states of\naggregation.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.2696v1"
    },
    {
        "title": "Liouvillian Solutions of Difference-Differential Equations",
        "authors": [
            "Ruyong Feng",
            "Michael F. Singer",
            "Min Wu"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  For a field k$with an automorphism \\sigma and a derivation \\delta, we\nintroduce the notion of liouvillian solutions of linear difference-differential\nsystems {\\sigma(Y) = AY, \\delta(Y) = BY} over k and characterize the existence\nof liouvillian solutions in terms of the Galois group of the systems. We will\ngive an algorithm to decide whether such a system has liouvillian solutions\nwhen k = C(x,t), \\sigma(x) = x+1, \\delta = d/dt$ and the size of the system is\na prime.\n",
        "pdf_link": "http://arxiv.org/pdf/0810.1574v1"
    },
    {
        "title": "Kaltofen's division-free determinant algorithm differentiated for matrix\n  adjoint computation",
        "authors": [
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  Kaltofen has proposed a new approach in 1992 for computing matrix\ndeterminants without divisions. The algorithm is based on a baby steps/giant\nsteps construction of Krylov subspaces, and computes the determinant as the\nconstant term of a characteristic polynomial. For matrices over an abstract\nring, by the results of Baur and Strassen, the determinant algorithm, actually\na straight-line program, leads to an algorithm with the same complexity for\ncomputing the adjoint of a matrix. However, the latter adjoint algorithm is\nobtained by the reverse mode of automatic differentiation, hence somehow is not\n\"explicit\". We present an alternative (still closely related) algorithm for the\nadjoint thatcan be implemented directly, we mean without resorting to an\nautomatic transformation. The algorithm is deduced by applying program\ndifferentiation techniques \"by hand\" to Kaltofen's method, and is completely\ndecribed. As subproblem, we study the differentiation of programs that compute\nminimum polynomials of lineraly generated sequences, and we use a lazy\npolynomial evaluation mechanism for reducing the cost of Strassen's avoidance\nof divisions in our case.\n",
        "pdf_link": "http://arxiv.org/pdf/0810.5647v1"
    },
    {
        "title": "A Sparse Flat Extension Theorem for Moment Matrices",
        "authors": [
            "Monique Laurent",
            "Bernard Mourrain"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In this note we prove a generalization of the flat extension theorem of Curto\nand Fialkow for truncated moment matrices. It applies to moment matrices\nindexed by an arbitrary set of monomials and its border, assuming that this set\nis connected to 1. When formulated in a basis-free setting, this gives an\nequivalent result for truncated Hankel operators.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.2563v1"
    },
    {
        "title": "On the Computation of Matrices of Traces and Radicals of Ideals",
        "authors": [
            "Itnuit Janovitz-Freireich",
            "Bernard Mourrain",
            "Lajos Ronayi",
            "Agnes Szanto"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  Let $f_1,...,f_s \\in \\mathbb{K}[x_1,...,x_m]$ be a system of polynomials\ngenerating a zero-dimensional ideal $\\I$, where $\\mathbb{K}$ is an arbitrary\nalgebraically closed field. We study the computation of \"matrices of traces\"\nfor the factor algebra $\\A := \\CC[x_1, ..., x_m]/ \\I$, i.e. matrices with\nentries which are trace functions of the roots of $\\I$. Such matrices of traces\nin turn allow us to compute a system of multiplication matrices\n$\\{M_{x_i}|i=1,...,m\\}$ of the radical $\\sqrt{\\I}$. We first propose a method\nusing Macaulay type resultant matrices of $f_1,...,f_s$ and a polynomial $J$ to\ncompute moment matrices, and in particular matrices of traces for $\\A$. Here\n$J$ is a polynomial generalizing the Jacobian. We prove bounds on the degrees\nneeded for the Macaulay matrix in the case when $\\I$ has finitely many\nprojective roots in $\\mathbb{P}^m_\\CC$. We also extend previous results which\nwork only for the case where $\\A$ is Gorenstein to the non-Gorenstein case. The\nsecond proposed method uses Bezoutian matrices to compute matrices of traces of\n$\\A$. Here we need the assumption that $s=m$ and $f_1,...,f_m$ define an affine\ncomplete intersection. This second method also works if we have higher\ndimensional components at infinity. A new explicit description of the\ngenerators of $\\sqrt{\\I}$ are given in terms of Bezoutians.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.2778v1"
    },
    {
        "title": "Symmetric tensor decomposition",
        "authors": [
            "Jerome Brachat",
            "Pierre Comon",
            "Bernard Mourrain",
            "Elias Tsigaridas"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We present an algorithm for decomposing a symmetric tensor, of dimension n\nand order d as a sum of rank-1 symmetric tensors, extending the algorithm of\nSylvester devised in 1886 for binary forms. We recall the correspondence\nbetween the decomposition of a homogeneous polynomial in n variables of total\ndegree d as a sum of powers of linear forms (Waring's problem), incidence\nproperties on secant varieties of the Veronese Variety and the representation\nof linear forms as a linear combination of evaluations at distinct points. Then\nwe reformulate Sylvester's approach from the dual point of view. Exploiting\nthis duality, we propose necessary and sufficient conditions for the existence\nof such a decomposition of a given rank, using the properties of Hankel (and\nquasi-Hankel) matrices, derived from multivariate polynomials and normal form\ncomputations. This leads to the resolution of polynomial equations of small\ndegree in non-generic cases. We propose a new algorithm for symmetric tensor\ndecomposition, based on this characterization and on linear algebra\ncomputations with these Hankel matrices. The impact of this contribution is\ntwo-fold. First it permits an efficient computation of the decomposition of any\ntensor of sub-generic rank, as opposed to widely used iterative algorithms with\nunproved global convergence (e.g. Alternate Least Squares or gradient\ndescents). Second, it gives tools for understanding uniqueness conditions, and\nfor detecting the rank.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.3706v2"
    },
    {
        "title": "Graphical Reasoning in Compact Closed Categories for Quantum Computation",
        "authors": [
            "Lucas Dixon",
            "Ross Duncan"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  Compact closed categories provide a foundational formalism for a variety of\nimportant domains, including quantum computation. These categories have a\nnatural visualisation as a form of graphs. We present a formalism for\nequational reasoning about such graphs and develop this into a generic proof\nsystem with a fixed logical kernel for equational reasoning about compact\nclosed categories. Automating this reasoning process is motivated by the slow\nand error prone nature of manual graph manipulation. A salient feature of our\nsystem is that it provides a formal and declarative account of derived results\nthat can include `ellipses'-style notation. We illustrate the framework by\ninstantiating it for a graphical language of quantum computation and show how\nthis can be used to perform symbolic computation.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.0514v1"
    },
    {
        "title": "A formal calculus on the Riordan near algebra",
        "authors": [
            "Laurent Poinsot",
            "Gérard Duchamp"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  The Riordan group is the semi-direct product of a multiplicative group of\ninvertible series and a group, under substitution, of non units. The Riordan\nnear algebra, as introduced in this paper, is the Cartesian product of the\nalgebra of formal power series and its principal ideal of non units, equipped\nwith a product that extends the multiplication of the Riordan group. The later\nis naturally embedded as a subgroup of units into the former. In this paper, we\nprove the existence of a formal calculus on the Riordan algebra. This formal\ncalculus plays a role similar to those of holomorphic calculi in the Banach or\nFr\\'echet algebras setting, but without the constraint of a radius of\nconvergence. Using this calculus, we define \\emph{en passant} a notion of\ngeneralized powers in the Riordan group.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.2853v4"
    },
    {
        "title": "Multihomogeneous Resultant Formulae for Systems with Scaled Support",
        "authors": [
            "Ioannis Z. Emiris",
            "Angelos Mantzaflaris"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  Constructive methods for matrices of multihomogeneous (or multigraded)\nresultants for unmixed systems have been studied by Weyman, Zelevinsky,\nSturmfels, Dickenstein and Emiris. We generalize these constructions to mixed\nsystems, whose Newton polytopes are scaled copies of one polytope, thus taking\na step towards systems with arbitrary supports. First, we specify matrices\nwhose determinant equals the resultant and characterize the systems that admit\nsuch formulae. Bezout-type determinantal formulae do not exist, but we describe\nall possible Sylvester-type and hybrid formulae. We establish tight bounds for\nall corresponding degree vectors, and specify domains that will surely contain\nsuch vectors; the latter are new even for the unmixed case. Second, we make use\nof multiplication tables and strong duality theory to specify resultant\nmatrices explicitly, for a general scaled system, thus including unmixed\nsystems. The encountered matrices are classified; these include a new type of\nSylvester-type matrix as well as Bezout-type matrices, known as partial\nBezoutians. Our public-domain Maple implementation includes efficient storage\nof complexes in memory, and construction of resultant matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.4064v3"
    },
    {
        "title": "Bounding the radii of balls meeting every connected component of\n  semi-algebraic sets",
        "authors": [
            "Saugata Basu",
            "Marie-Francoise Roy"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We prove explicit bounds on the radius of a ball centered at the origin which\nis guaranteed to contain all bounded connected components of a semi-algebraic\nset $S \\subset \\mathbbm{R}^k$ defined by a quantifier-free formula involving\n$s$ polynomials in $\\mathbbm{Z}[X_1, ..., X_k]$ having degrees at most $d$, and\nwhose coefficients have bitsizes at most $\\tau$. Our bound is an explicit\nfunction of $s, d, k$ and $\\tau$, and does not contain any undetermined\nconstants. We also prove a similar bound on the radius of a ball guaranteed to\nintersect every connected component of $S$ (including the unbounded\ncomponents). While asymptotic bounds of the form $2^{\\tau d^{O (k)}}$ on these\nquantities were known before, some applications require bounds which are\nexplicit and which hold for all values of $s, d, k$ and $\\tau$. The bounds\nproved in this paper are of this nature.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.1340v1"
    },
    {
        "title": "The Hilbert scheme of points and its link with border basis",
        "authors": [
            "Mariemi Alonso",
            "Jérome Brachat",
            "Bernard Mourrain"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  In this paper, we give new explicit representations of the Hilbert scheme of\n$\\mu$ points in $\\PP^{r}$ as a projective subvariety of a Grassmanniann\nvariety. This new explicit description of the Hilbert scheme is simpler than\nthe previous ones and global. It involves equations of degree $2$. We show how\nthese equations are deduced from the commutation relations characterizing\nborder bases. Next, we consider infinitesimal perturbations of an input system\nof equations on this Hilbert scheme and describe its tangent space. We propose\nan effective criterion to test if it is a flat deformation, that is if the\nperturbed system remains on the Hilbert scheme of the initial equations. This\ncriterion involves in particular formal reduction with respect to border bases.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.3503v2"
    },
    {
        "title": "Generic design of Chinese remaindering schemes",
        "authors": [
            "Jean-Guillaume Dumas",
            "Thierry Gautier",
            "Jean-Louis Roch"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We propose a generic design for Chinese remainder algorithms. A Chinese\nremainder computation consists in reconstructing an integer value from its\nresidues modulo non coprime integers. We also propose an efficient linear data\nstructure, a radix ladder, for the intermediate storage and computations. Our\ndesign is structured into three main modules: a black box residue computation\nin charge of computing each residue; a Chinese remaindering controller in\ncharge of launching the computation and of the termination decision; an integer\nbuilder in charge of the reconstruction computation. We then show that this\ndesign enables many different forms of Chinese remaindering (e.g.\ndeterministic, early terminated, distributed, etc.), easy comparisons between\nthese forms and e.g. user-transparent parallelism at different parallel grains.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.4150v1"
    },
    {
        "title": "Gradual sub-lattice reduction and a new complexity for factoring\n  polynomials",
        "authors": [
            "Mark Van Hoeij",
            "Andrew Novocin"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We present a lattice algorithm specifically designed for some classical\napplications of lattice reduction. The applications are for lattice bases with\na generalized knapsack-type structure, where the target vectors are boundably\nshort. For such applications, the complexity of the algorithm improves\ntraditional lattice reduction by replacing some dependence on the bit-length of\nthe input vectors by some dependence on the bound for the output vectors. If\nthe bit-length of the target vectors is unrelated to the bit-length of the\ninput, then our algorithm is only linear in the bit-length of the input\nentries, which is an improvement over the quadratic complexity floating-point\nLLL algorithms. To illustrate the usefulness of this algorithm we show that a\ndirect application to factoring univariate polynomials over the integers leads\nto the first complexity bound improvement since 1984. A second application is\nalgebraic number reconstruction, where a new complexity bound is obtained as\nwell.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0739v1"
    },
    {
        "title": "Stability Analysis of Linear Uncertain Systems via Checking Positivity\n  of Forms on Simplices",
        "authors": [
            "Xiaorong Hou",
            "Junwei Shao"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  In this paper, we mainly study the robust stability of linear continuous\nsystems with parameter uncertainties, a more general kind of uncertainties for\nsystem matrices is considered, i.e., entries of system matrices are rational\nfunctions of uncertain parameters which are varying in intervals. we present a\nmethod which can check the robust Hurwitz stability of such uncertain systems\nin finite steps. Examples show the efficiency of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.3181v1"
    },
    {
        "title": "A Fast Approach to Creative Telescoping",
        "authors": [
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  In this note we reinvestigate the task of computing creative telescoping\nrelations in differential-difference operator algebras. Our approach is based\non an ansatz that explicitly includes the denominators of the delta parts. We\ncontribute several ideas of how to make an implementation of this approach\nreasonably fast and provide such an implementation. A selection of examples\nshows that it can be superior to existing methods by a large factor.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3314v2"
    },
    {
        "title": "Symbolic Domain Decomposition",
        "authors": [
            "Jacques Carette",
            "Alan P. Sexton",
            "Volker Sorge",
            "Stephen M. Watt"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Decomposing the domain of a function into parts has many uses in mathematics.\nA domain may naturally be a union of pieces, a function may be defined by\ncases, or different boundary conditions may hold on different regions. For any\nparticular problem the domain can be given explicitly, but when dealing with a\nfamily of problems given in terms of symbolic parameters, matters become more\ndifficult. This article shows how hybrid sets, that is multisets allowing\nnegative multiplicity, may be used to express symbolic domain decompositions in\nan efficient, elegant and uniform way, simplifying both computation and\nreasoning. We apply this theory to the arithmetic of piecewise functions and\nsymbolic matrices and show how certain operations may be reduced from\nexponential to linear complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.5549v1"
    },
    {
        "title": "Generic design of Chinese remaindering schemes",
        "authors": [
            "Jean-Guillaume Dumas",
            "Thierry Gautier",
            "Jean-Louis Roch"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We propose a generic design for Chinese remainder algorithms. A Chinese\nremainder computation consists in reconstructing an integer value from its\nresidues modulo non coprime integers. We also propose an efficient linear data\nstructure, a radix ladder, for the intermediate storage and computations. Our\ndesign is structured into three main modules: a black box residue computation\nin charge of computing each residue; a Chinese remaindering controller in\ncharge of launching the computation and of the termination decision; an integer\nbuilder in charge of the reconstruction computation. We then show that this\ndesign enables many different forms of Chinese remaindering (e.g.\ndeterministic, early terminated, distributed, etc.), easy comparisons between\nthese forms and e.g. user-transparent parallelism at different parallel grains.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0830v1"
    },
    {
        "title": "Polynomial integration on regions defined by a triangle and a conic",
        "authors": [
            "David Sevilla",
            "Daniel Wachsmuth"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We present an efficient solution to the following problem, of relevance in a\nnumerical optimization scheme: calculation of integrals of the type \\[\\iint_{T\n\\cap \\{f\\ge0\\}} \\phi_1\\phi_2 \\, dx\\,dy\\] for quadratic polynomials\n$f,\\phi_1,\\phi_2$ on a plane triangle $T$. The naive approach would involve\nconsideration of the many possible shapes of $T\\cap\\{f\\geq0\\}$ (possibly after\na convenient transformation) and parameterizing its border, in order to\nintegrate the variables separately. Our solution involves partitioning the\ntriangle into smaller triangles on which integration is much simpler.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0990v1"
    },
    {
        "title": "The 1958 Pekeris-Accad-WEIZAC Ground-Breaking Collaboration that\n  Computed Ground States of Two-Electron Atoms (and its 2010 Redux)",
        "authors": [
            "Christoph Koutschan",
            "Doron Zeilberger"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  In order to appreciate how well off we mathematicians and scientists are\ntoday, with extremely fast hardware and lots and lots of memory, as well as\nwith powerful software, both for numeric and symbolic computation, it may be a\ngood idea to go back to the early days of electronic computers and compare how\nthings went then. We have chosen, as a case study, a problem that was\nconsidered a huge challenge at the time. Namely, we looked at C.L. Pekeris's\nseminal 1958 work on the ground state energies of two-electron atoms. We went\nthrough all the computations ab initio with today's software and hardware, with\na special emphasis on the symbolic computations which in 1958 had to be made by\nhand, and which nowadays can be automated and generalized.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0200v2"
    },
    {
        "title": "Efficient Characteristic Set Algorithms for Equation Solving in Finite\n  Fields and Applications in Cryptanalysis",
        "authors": [
            "Xiao-Shan Gao",
            "Zhenyu Huang"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Efficient characteristic set methods for computing solutions of polynomial\nequation systems in a finite field are proposed. The concept of proper\ntriangular sets is introduced and an explicit formula for the number of\nsolutions of a proper and monic (or regular) triangular set is given. An\nimproved zero decomposition algorithm which can be used to reduce the zero set\nof an equation system in general form to the union of zero sets of monic proper\ntriangular sets is proposed. As a consequence, we can give an explicit formula\nfor the number of solutions of an equation system. Bitsize complexity for the\nalgorithm is given in the case of Boolean polynomials. We also give a\nmultiplication free characteristic set method for Boolean polynomials, where\nthe sizes of the polynomials are effectively controlled. The algorithms are\nimplemented in the case of Boolean polynomials and extensive experiments show\nthat they are quite efficient for solving certain classes of Boolean equations.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.6505v1"
    },
    {
        "title": "Isomorphisms of Algebraic Number Fields",
        "authors": [
            "Mark van Hoeij",
            "Vivek Pal"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Let $\\mathbb{Q}(\\alpha)$ and $\\mathbb{Q}(\\beta)$ be algebraic number fields.\nWe describe a new method to find (if they exist) all isomorphisms,\n$\\mathbb{Q}(\\beta) \\rightarrow \\mathbb{Q}(\\alpha)$. The algorithm is\nparticularly efficient if the number of isomorphisms is one.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.0096v2"
    },
    {
        "title": "A new conception for computing gröbner basis and its applications",
        "authors": [
            "Lei Huang"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  This paper presents a conception for computing gr\\\"{o}bner basis. We convert\nsome of gr\\\"{o}bner-computing algorithms, e.g., F5, extended F5 and GWV\nalgorithms into a special type of algorithm. The new algorithm's finite\ntermination problem can be described by equivalent conditions, so all the above\nalgorithms can be determined when they terminate finitely. At last, a new\ncriterion is presented. It is an improvement for the Rewritten and Signature\nCriterion.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5425v2"
    },
    {
        "title": "Symbolic-manipulation constructions of Hilbert-space metrics in quantum\n  mechanics",
        "authors": [
            "Miloslav Znojil"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  The problem of the determination of the Hilbert-space metric which renders a\ngiven Hamiltonian $H$ self-adjoint is addressed from the point of view of\napplicability of computer-assisted algebraic manipulations. An exactly solvable\nexample of the so called Gegenbauerian quantum-lattice oscillator is recalled\nfor the purpose. Both the construction of suitable metric (basically, the\nsolution of the Dieudonne's operator equation) and the determination of its\ndomain of positivity are shown facilitated by the symbolic algebraic\nmanipulations and by MAPLE-supported numerics and graphics.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.4525v1"
    },
    {
        "title": "On Two-generated Non-commutative Algebras Subject to the Affine Relation",
        "authors": [
            "Christoph Koutschan",
            "Viktor Levandovskyy",
            "Oleksandr Motsak"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We consider algebras over a field K, generated by two variables x and y\nsubject to the single relation yx = qxy + ax + by + c for q in K^* and a, b, c\nin K. We prove, that among such algebras there are precisely five isomorphism\nclasses. The representatives of these classes, which are ubiquitous operator\nalgebras, are called model algebras. We derive explicit multiplication formulas\nfor y^m*x^n in terms of standard monomials x^i*y^j for many algebras of the\nconsidered type. Such formulas are used in establishing formulas of binomial\ntype and in implementing non-commutative multiplication in a computer algebra\nsystem. By using the formulas we also study centers and ring-theoretic\nproperties of the non-commutative model algebras.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.1108v1"
    },
    {
        "title": "A New Algorithmic Scheme for Computing Characteristic Sets",
        "authors": [
            "Meng Jin",
            "Xiaoliang Li",
            "Dongming Wang"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  Ritt-Wu's algorithm of characteristic sets is the most representative for\ntriangularizing sets of multivariate polynomials. Pseudo-division is the main\noperation used in this algorithm. In this paper we present a new algorithmic\nscheme for computing generalized characteristic sets by introducing other\nadmissible reductions than pseudo-division. A concrete subalgorithm is designed\nto triangularize polynomial sets using selected admissible reductions and\nseveral effective elimination strategies and to replace the algorithm of basic\nsets (used in Ritt-Wu's algorithm). The proposed algorithm has been implemented\nand experimental results show that it performs better than Ritt-Wu's algorithm\nin terms of computing time and simplicity of output for a number of non-trivial\ntest examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.1486v1"
    },
    {
        "title": "The Parametric Solution of Underdetermined linear ODEs",
        "authors": [
            "Thomas Wolf"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  The purpose of this paper is twofold. An immediate practical use of the\npresented algorithm is its applicability to the parametric solution of\nunderdetermined linear ordinary differential equations (ODEs) with coefficients\nthat are arbitrary analytic functions in the independent variable. A second\nconceptual aim is to present an algorithm that is in some sense dual to the\nfundamental Euclids algorithm, and thus an alternative to the special case of a\nGroebner basis algorithm as it is used for solving linear ODE-systems. In the\npaper Euclids algorithm and the new `dual version' are compared and their\ncomplementary strengths are analysed on the task of solving underdetermined\nODEs. An implementation of the described algorithm is interactively accessible\nunder http://lie.math.brocku.ca/crack/demo.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4487v1"
    },
    {
        "title": "Algorithms for integrals of holonomic functions over domains defined by\n  polynomial inequalities",
        "authors": [
            "Toshinori Oaku"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We present an algorithm for computing a holonomic system for a definite\nintegral of a holonomic function over a domain defined by polynomial\ninequalities. If the integrand satisfies a holonomic difference-differential\nsystem including parameters, then a holonomic difference-differential system\nfor the integral can also be computed. In the algorithm, holonomic\ndistributions (generalized functions in the sense of L. Schwartz) are\ninevitably involved even if the integrand is a usual function.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4853v2"
    },
    {
        "title": "An Oracle-based, Output-sensitive Algorithm for Projections of Resultant\n  Polytopes",
        "authors": [
            "Ioannis Z. Emiris",
            "Vissarion Fisikopoulos",
            "Christos Konaxis",
            "Luis Peñaranda"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We design an algorithm to compute the Newton polytope of the resultant, known\nas resultant polytope, or its orthogonal projection along a given direction.\nThe resultant is fundamental in algebraic elimination, optimization, and\ngeometric modeling. Our algorithm exactly computes vertex- and\nhalfspace-representations of the polytope using an oracle producing resultant\nvertices in a given direction, thus avoiding walking on the polytope whose\ndimension is alpha-n-1, where the input consists of alpha points in Z^n. Our\napproach is output-sensitive as it makes one oracle call per vertex and facet.\nIt extends to any polytope whose oracle-based definition is advantageous, such\nas the secondary and discriminant polytopes. Our publicly available\nimplementation uses the experimental CGAL package triangulation. Our method\ncomputes 5-, 6- and 7-dimensional polytopes with 35K, 23K and 500 vertices,\nrespectively, within 2hrs, and the Newton polytopes of many important surface\nequations encountered in geometric modeling in <1sec, whereas the corresponding\nsecondary polytopes are intractable. It is faster than tropical geometry\nsoftware up to dimension 5 or 6. Hashing determinantal predicates accelerates\nexecution up to 100 times. One variant computes inner and outer approximations\nwith, respectively, 90% and 105% of the true volume, up to 25 times faster.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.5985v4"
    },
    {
        "title": "Stability of Triangular Decomposition and Comprehensive Triangular\n  Decomposition",
        "authors": [
            "Xiaoxian Tang",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  A new concept, decomposition-unstable (DU) variety of a parametric polynomial\nsystem, is introduced in this paper and the stabilities of several triangular\ndecomposition methods, such as characteristic set decomposition, relatively\nsimplicial decomposition and regular chain decomposition, for parametric\npolynomial systems are discussed in detail. The concept leads to a definition\nof weakly comprehensive triangular decomposition (WCTD) and a new algorithm for\ncomputing comprehensive triangular decomposition (CTD) which was first\nintroduced in [4] for computing an analogue of comprehensive Groebner systems\nfor parametric polynomial systems. Our algorithm takes advantage of a\nhierarchical solving strategy and a self-adaptive order of parameters. The\nalgorithm has been implemented with Maple 15 and experimented with a number of\nbenchmarks from the literature. Comparison with the Maple package\nRegularChains, which contains an implementation of the algorithm in [4], is\nprovided and the results illustrate that the time costs by our program for\ncomputing CTDs of most examples are no more than those by RegularChains.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.6275v2"
    },
    {
        "title": "Sparse Differential Resultant for Laurent Differential Polynomials",
        "authors": [
            "Wei Li",
            "Chun-Ming Yuan",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  In this paper, we first introduce the concept of Laurent differentially\nessential systems and give a criterion for Laurent differentially essential\nsystems in terms of their supports. Then the sparse differential resultant for\na Laurent differentially essential system is defined and its basic properties\nare proved. In particular, order and degree bounds for the sparse differential\nresultant are given. Based on these bounds, an algorithm to compute the sparse\ndifferential resultant is proposed, which is single exponential in terms of the\nnumber of indeterminates, the Jacobi number of the system, and the size of the\nsystem.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.1084v3"
    },
    {
        "title": "Adleman-Manders-Miller Root Extraction Method Revisited",
        "authors": [
            "Zhengjun Cao",
            "Qian Sha",
            "Xiao Fan"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  In 1977, Adleman, Manders and Miller had briefly described how to extend\ntheir square root extraction method to the general $r$th root extraction over\nfinite fields, but not shown enough details. Actually, there is a dramatic\ndifference between the square root extraction and the general $r$th root\nextraction because one has to solve discrete logarithms for $r$th root\nextraction. In this paper, we clarify their method and analyze its complexity.\nOur heuristic presentation is helpful to grasp the method entirely and deeply.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.4877v1"
    },
    {
        "title": "Advanced Computer Algebra for Determinants",
        "authors": [
            "Christoph Koutschan",
            "Thotsaporn \"Aek\" Thanatipanonda"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We prove three conjectures concerning the evaluation of determinants, which\nare related to the counting of plane partitions and rhombus tilings. One of\nthem was posed by George Andrews in 1980, the other two were by Guoce Xin and\nChristian Krattenthaler. Our proofs employ computer algebra methods, namely,\nthe holonomic ansatz proposed by Doron Zeilberger and variations thereof. These\nvariations make Zeilberger's original approach even more powerful and allow for\naddressing a wider variety of determinants. Finally, we present, as a challenge\nproblem, a conjecture about a closed-form evaluation of Andrews's determinant.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.0647v3"
    },
    {
        "title": "On the Complexity of Solving Quadratic Boolean Systems",
        "authors": [
            "Magali Bardet",
            "Jean-Charles Faugère",
            "Bruno Salvy",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  A fundamental problem in computer science is to find all the common zeroes of\n$m$ quadratic polynomials in $n$ unknowns over $\\mathbb{F}_2$. The\ncryptanalysis of several modern ciphers reduces to this problem. Up to now, the\nbest complexity bound was reached by an exhaustive search in $4\\log_2 n\\,2^n$\noperations. We give an algorithm that reduces the problem to a combination of\nexhaustive search and sparse linear algebra. This algorithm has several\nvariants depending on the method used for the linear algebra step. Under\nprecise algebraic assumptions on the input system, we show that the\ndeterministic variant of our algorithm has complexity bounded by\n$O(2^{0.841n})$ when $m=n$, while a probabilistic variant of the Las Vegas type\nhas expected complexity $O(2^{0.792n})$. Experiments on random systems show\nthat the algebraic assumptions are satisfied with probability very close to~1.\nWe also give a rough estimate for the actual threshold between our method and\nexhaustive search, which is as low as~200, and thus very relevant for\ncryptographic applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.6263v2"
    },
    {
        "title": "An Algorithmic Characterization of Polynomial Functions over $Z_{p^n}$",
        "authors": [
            "Ashwin Guha",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  In this paper we consider polynomial representability of functions defined\nover $Z_{p^n}$, where $p$ is a prime and $n$ is a positive integer. Our aim is\nto provide an algorithmic characterization that (i) answers the decision\nproblem: to determine whether a given function over $Z_{p^n}$ is polynomially\nrepresentable or not, and (ii) finds the polynomial if it is polynomially\nrepresentable. The previous characterizations given by Kempner (1921) and\nCarlitz (1964) are existential in nature and only lead to an exhaustive search\nmethod, i.e., algorithm with complexity exponential in size of the input. Our\ncharacterization leads to an algorithm whose running time is linear in size of\ninput. We also extend our result to the multivariate case.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.1122v4"
    },
    {
        "title": "FORM version 4.0",
        "authors": [
            "J. Kuipers",
            "T. Ueda",
            "J. A. M. Vermaseren",
            "J. Vollinga"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We present version 4.0 of the symbolic manipulation system FORM. The most\nimportant new features are manipulation of rational polynomials and the\nfactorization of expressions. Many other new functions and commands are also\nadded; some of them are very general, while others are designed for building\nspecific high level packages, such as one for Groebner bases. New is also the\ncheckpoint facility, that allows for periodic backups during long calculations.\nLastly, FORM 4.0 has become available as open source under the GNU General\nPublic License version 3.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6543v1"
    },
    {
        "title": "Proving Inequalities and Solving Global Optimization Problems via\n  Simplified CAD Projection",
        "authors": [
            "Jingjun Han",
            "Zhi Jin",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Let $\\xx_n=(x_1,\\ldots,x_n)$ and $f\\in \\R[\\xx_n,k]$. The problem of finding\nall $k_0$ such that $f(\\xx_n,k_0)\\ge 0$ on $\\mathbb{R}^n$ is considered in this\npaper, which obviously takes as a special case the problem of computing the\nglobal infimum or proving the semi-definiteness of a polynomial.\n  For solving the problems, we propose a simplified Brown's CAD projection\noperator, \\Nproj, of which the projection scale is always no larger than that\nof Brown's. For many problems, the scale is much smaller than that of Brown's.\nAs a result, the lifting phase is also simplified. Some new algorithms based on\n\\Nproj\\ for solving those problems are designed and proved to be correct.\nComparison to some existing tools on some examples is reported to illustrate\nthe effectiveness of our new algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1223v4"
    },
    {
        "title": "Speeding up Cylindrical Algebraic Decomposition by Gröbner Bases",
        "authors": [
            "David J. Wilson",
            "Russell J. Bradford",
            "James H. Davenport"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Gr\\\"obner Bases and Cylindrical Algebraic Decomposition are generally thought\nof as two, rather different, methods of looking at systems of equations and, in\nthe case of Cylindrical Algebraic Decomposition, inequalities. However, even\nfor a mixed system of equalities and inequalities, it is possible to apply\nGr\\\"obner bases to the (conjoined) equalities before invoking CAD. We see that\nthis is, quite often but not always, a beneficial preconditioning of the CAD\nproblem.\n  It is also possible to precondition the (conjoined) inequalities with respect\nto the equalities, and this can also be useful in many cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.6285v1"
    },
    {
        "title": "First Steps Towards Radical Parametrization of Algebraic Surfaces",
        "authors": [
            "J. Rafael Sendra",
            "David Sevilla"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We introduce the notion of radical parametrization of a surface, and we\nprovide algorithms to compute such type of parametrizations for families of\nsurfaces, like: Fermat surfaces, surfaces with a high multiplicity (at least\nthe degree minus 4) singularity, all irreducible surfaces of degree at most 5,\nall irreducible singular surfaces of degree 6, and surfaces containing a pencil\nof low-genus curves. In addition, we prove that radical parametrizations are\npreserved under certain type of geometric constructions that include offset and\nconchoids.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.1456v2"
    },
    {
        "title": "Computation of Difference Groebner Bases",
        "authors": [
            "Vladimir P. Gerdt",
            "Daniel Robertz"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  To compute difference Groebner bases of ideals generated by linear\npolynomials we adopt to difference polynomial rings the involutive algorithm\nbased on Janet-like division. The algorithm has been implemented in Maple in\nthe form of the package LDA (Linear Difference Algebra) and we describe the\nmain features of the package. Its applications are illustrated by generation of\nfinite difference approximations to linear partial differential equations and\nby reduction of Feynman integrals. We also present the algorithm for an ideal\ngenerated by a finite set of nonlinear difference polynomials. If the algorithm\nterminates, then it constructs a Groebner basis of the ideal.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.3463v2"
    },
    {
        "title": "Metric Problems for Quadrics in Multidimensional Space",
        "authors": [
            "Alexei Yu. Uteshev",
            "Marina V. Yashina"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Given the equations of the first and the second order surfaces in\nmultidimensional space, our goal is to construct a univariate polynomial one of\nthe zeros of which coincides with the square of the distance between these\nsurfaces. To achieve this goal we employ Elimination Theory methods. The\nproposed approach is also extended for the case of parameter dependent\nsurfaces.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.2243v1"
    },
    {
        "title": "On the Existence of Telescopers for Mixed Hypergeometric Terms",
        "authors": [
            "Shaoshi Chen",
            "Frédéric Chyzak",
            "Ruyong Feng",
            "Guofeng Fu",
            "Ziming Li"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We present a criterion for the existence of telescopers for mixed\nhypergeometric terms, which is based on multiplicative and additive\ndecompositions. The criterion enables us to determine the termination of\nZeilberger's algorithms for mixed hypergeometric inputs.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.2430v2"
    },
    {
        "title": "How to compute the constant term of a power of a Laurent polynomial\n  efficiently",
        "authors": [
            "Pavel Metelitsyn"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We present an algorithm for efficient computation of the constant term of a\npower of a multivariate Laurent polynomial. The algorithm is based on\nunivariate interpolation, does not require the storage of intermediate data and\ncan be easily parallelized. As an application we compute the power series\nexpansion of the principal period of some toric Calabi-Yau varieties and find\npreviously unknown differential operators of Calabi-Yau type.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.3959v1"
    },
    {
        "title": "Sparse Difference Resultant",
        "authors": [
            "Wei Li",
            "Chun-Ming Yuan",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  In this paper, the concept of sparse difference resultant for a Laurent\ntransformally essential system of difference polynomials is introduced and a\nsimple criterion for the existence of sparse difference resultant is given. The\nconcept of transformally homogenous polynomial is introduced and the sparse\ndifference resultant is shown to be transformally homogenous. It is shown that\nthe vanishing of the sparse difference resultant gives a necessary condition\nfor the corresponding difference polynomial system to have non-zero solutions.\nThe order and degree bounds for sparse difference resultant are given. Based on\nthese bounds, an algorithm to compute the sparse difference resultant is\nproposed, which is single exponential in terms of the number of variables, the\nJacobi number, and the size of the Laurent transformally essential system.\nFurthermore, the precise order and degree, a determinant representation, and a\nPoisson-type product formula for the difference resultant are given.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.3090v2"
    },
    {
        "title": "Hermite Reduction and Creative Telescoping for Hyperexponential\n  Functions",
        "authors": [
            "Alin Bostan",
            "Shaoshi Chen",
            "Frédéric Chyzak",
            "Ziming Li",
            "Guoce Xin"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present a reduction algorithm that simultaneously extends Hermite's\nreduction for rational functions and the Hermite-like reduction for\nhyperexponential functions. It yields a unique additive decomposition and\nallows to decide hyperexponential integrability. Based on this reduction\nalgorithm, we design a new method to compute minimal telescopers for bivariate\nhyperexponential functions. One of its main features is that it can avoid the\ncostly computation of certificates. Its implementation outperforms Maple's\nfunction DEtools[Zeilberger]. Moreover, we derive an order bound on minimal\ntelescopers, which is more general and tighter than the known one.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5038v1"
    },
    {
        "title": "On the Structure of Compatible Rational Functions",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Guofeng Fu",
            "Ziming Li"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  A finite number of rational functions are compatible if they satisfy the\ncompatibility conditions of a first-order linear functional system involving\ndifferential, shift and q-shift operators. We present a theorem that describes\nthe structure of compatible rational functions. The theorem enables us to\ndecompose a solution of such a system as a product of a rational function,\nseveral symbolic powers, a hyperexponential function, a hypergeometric term,\nand a q-hypergeometric term. We outline an algorithm for computing this\nproduct, and present an application.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5046v2"
    },
    {
        "title": "Superfast solution of Toeplitz systems based on syzygy reduction",
        "authors": [
            "Houssam Khalil",
            "Bernard Mourrain",
            "Michelle Schatzman"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present a new superfast algorithm for solving Toeplitz systems. This\nalgorithm is based on a relation between the solution of such problems and\nsyzygies of polynomials or moving lines. We show an explicit connection between\nthe generators of a Toeplitz matrix and the generators of the corresponding\nmodule of syzygies. We show that this module is generated by two elements and\nthe solution of a Toeplitz system T u=g can be reinterpreted as the remainder\nof a vector depending on g, by these two generators. We obtain these generators\nand this remainder with computational complexity O(n log^2 n) for a Toeplitz\nmatrix of size nxn.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5798v1"
    },
    {
        "title": "Fast algorithms for ell-adic towers over finite fields",
        "authors": [
            "Luca De Feo",
            "Javad Doliskani",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Inspired by previous work of Shoup, Lenstra-De Smit and Couveignes-Lercier,\nwe give fast algorithms to compute in (the first levels of) the ell-adic\nclosure of a finite field. In many cases, our algorithms have quasi-linear\ncomplexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.6021v1"
    },
    {
        "title": "Exact Safety Verification of Interval Hybrid Systems Based on\n  Symbolic-Numeric Computation",
        "authors": [
            "Zhengfeng Yang",
            "Min Wu",
            "Wang Lin"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper, we address the problem of safety verification of interval\nhybrid systems in which the coefficients are intervals instead of explicit\nnumbers. A hybrid symbolic-numeric method, based on SOS relaxation and interval\narithmetic certification, is proposed to generate exact inequality invariants\nfor safety verification of interval hybrid systems. As an application, an\napproach is provided to verify safety properties of non-polynomial hybrid\nsystems. Experiments on the benchmark hybrid systems are given to illustrate\nthe efficiency of our method.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.5974v1"
    },
    {
        "title": "Normalization of Polynomials in Algebraic Invariants of\n  Three-Dimensional Orthogonal Geometry",
        "authors": [
            "Hongbo Li"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In classical invariant theory, the Gr\\\"obner base of the ideal of syzygies\nand the normal forms of polynomials of invariants are two core contents. To\nimprove the performance of invariant theory in symbolic computing of classical\ngeometry, advanced invariants are introduced via Clifford product. This paper\naddresses and solves the two key problems in advanced invariant theory: the\nGr\\\"obner base of the ideal of syzygies among advanced invariants, and the\nnormal forms of polynomials of advanced invariants. These results beautifully\nextend the straightening of Young tableaux to advanced invariants.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.7194v1"
    },
    {
        "title": "Domain-of-Attraction Estimation for Uncertain Non-polynomial Systems",
        "authors": [
            "Min Wu",
            "Zhengfeng Yang",
            "Wang Lin"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper, we consider the problem of computing estimates of the\ndomain-of-attraction for non-polynomial systems. A polynomial approximation\ntechnique, based on multivariate polynomial interpolation and error analysis\nfor remaining functions, is applied to compute an uncertain polynomial system,\nwhose set of trajectories contains that of the original non-polynomial system.\nExperiments on the benchmark non-polynomial systems show that our approach\ngives better estimates of the domain-of-attraction.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.0452v1"
    },
    {
        "title": "Separating linear forms for bivariate systems",
        "authors": [
            "Yacine Bouzidi",
            "Sylvain Lazard",
            "Marc Pouget",
            "Fabrice Rouillier"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present an algorithm for computing a separating linear form of a system of\nbivariate polynomials with integer coefficients, that is a linear combination\nof the variables that takes different values when evaluated at distinct\n(complex) solutions of the system. In other words, a separating linear form\ndefines a shear of the coordinate system that sends the algebraic system in\ngeneric position, in the sense that no two distinct solutions are vertically\naligned. The computation of such linear forms is at the core of most algorithms\nthat solve algebraic systems by computing rational parameterizations of the\nsolutions and, moreover, the computation a separating linear form is the\nbottleneck of these algorithms, in terms of worst-case bit complexity. Given\ntwo bivariate polynomials of total degree at most $d$ with integer coefficients\nof bitsize at most~$\\tau$, our algorithm computes a separating linear form in\n$\\sOB(d^{8}+d^7\\tau)$ bit operations in the worst case, where the previously\nknown best bit complexity for this problem was $\\sOB(d^{10}+d^9\\tau)$ (where\n$\\sO$ refers to the complexity where polylogarithmic factors are omitted and\n$O_B$ refers to the bit complexity).\n",
        "pdf_link": "http://arxiv.org/pdf/1303.5041v2"
    },
    {
        "title": "Rational Univariate Representations of Bivariate Systems and\n  Applications",
        "authors": [
            "Yacine Bouzidi",
            "Sylvain Lazard",
            "Marc Pouget",
            "Fabrice Rouillier"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We address the problem of solving systems of two bivariate polynomials of\ntotal degree at most $d$ with integer coefficients of maximum bitsize $\\tau$.\nIt is known that a linear separating form, that is a linear combination of the\nvariables that takes different values at distinct solutions of the system, can\nbe computed in $\\sOB(d^{8}+d^7\\tau)$ bit operations (where $O_B$ refers to bit\ncomplexities and $\\sO$ to complexities where polylogarithmic factors are\nomitted) and we focus here on the computation of a Rational Univariate\nRepresentation (RUR) given a linear separating form. We present an algorithm\nfor computing a RUR with worst-case bit complexity in $\\sOB(d^7+d^6\\tau)$ and\nbound the bitsize of its coefficients by $\\sO(d^2+d\\tau)$. We show in addition\nthat isolating boxes of the solutions of the system can be computed from the\nRUR with $\\sOB(d^{8}+d^7\\tau)$ bit operations. Finally, we show how a RUR can\nbe used to evaluate the sign of a bivariate polynomial (of degree at most $d$\nand bitsize at most $\\tau$) at one real solution of the system in\n$\\sOB(d^{8}+d^7\\tau)$ bit operations and at all the $\\Theta(d^2)$ {real}\nsolutions in only $O(d)$ times that for one solution.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.5042v2"
    },
    {
        "title": "Reduced Gröbner Bases and Macaulay-Buchberger Basis Theorem over\n  Noetherian Rings",
        "authors": [
            "Maria Francis",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper, we extend the characterization of $\\mathbb{Z}[x]/\\ < f \\ >$,\nwhere $f \\in \\mathbb{Z}[x]$ to be a free $\\mathbb{Z}$-module to multivariate\npolynomial rings over any commutative Noetherian ring, $A$. The\ncharacterization allows us to extend the Gr\\\"obner basis method of computing a\n$\\Bbbk$-vector space basis of residue class polynomial rings over a field\n$\\Bbbk$ (Macaulay-Buchberger Basis Theorem) to rings, i.e.\n$A[x_1,\\ldots,x_n]/\\mathfrak{a}$, where $\\mathfrak{a} \\subseteq\nA[x_1,\\ldots,x_n]$ is an ideal. We give some insights into the characterization\nfor two special cases, when $A = \\mathbb{Z}$ and $A =\n\\Bbbk[\\theta_1,\\ldots,\\theta_m]$. As an application of this characterization,\nwe show that the concept of border bases can be extended to rings when the\ncorresponding residue class ring is a finitely generated, free $A$-module.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.6889v5"
    },
    {
        "title": "Ore Polynomials in Sage",
        "authors": [
            "Manuel Kauers",
            "Maximilian Jaroschek",
            "Fredrik Johansson"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present a Sage implementation of Ore algebras. The main features for the\nmost common instances include basic arithmetic and actions; gcrd and lclm;\nD-finite closure properties; natural transformations between related algebras;\nguessing; desingularization; solvers for polynomials, rational functions and\n(generalized) power series. This paper is a tutorial on how to use the package.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.4263v1"
    },
    {
        "title": "Rigorous high-precision computation of the Hurwitz zeta function and its\n  derivatives",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We study the use of the Euler-Maclaurin formula to numerically evaluate the\nHurwitz zeta function $\\zeta(s,a)$ for $s, a \\in \\mathbb{C}$, along with an\narbitrary number of derivatives with respect to $s$, to arbitrary precision\nwith rigorous error bounds. Techniques that lead to a fast implementation are\ndiscussed. We present new record computations of Stieltjes constants, Keiper-Li\ncoefficients and the first nontrivial zero of the Riemann zeta function,\nobtained using an open source implementation of the algorithms described in\nthis paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.2877v1"
    },
    {
        "title": "Code Optimization in FORM",
        "authors": [
            "J. Kuipers",
            "T. Ueda",
            "J. A. M. Vermaseren"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We describe the implementation of output code optimization in the open source\ncomputer algebra system FORM. This implementation is based on recently\ndiscovered techniques of Monte Carlo tree search to find efficient multivariate\nHorner schemes, in combination with other optimization algorithms, such as\ncommon subexpression elimination. For systems for which no specific knowledge\nis provided it performs significantly better than other methods we could\ncompare with. Because the method has a number of free parameters, we also show\nsome methods by which to tune them to different types of problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7007v1"
    },
    {
        "title": "Computing the multilinear factors of lacunary polynomials without\n  heights",
        "authors": [
            "Arkadev Chattopadhyay",
            "Bruno Grenet",
            "Pascal Koiran",
            "Natacha Portier",
            "Yann Strozecki"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  We present a deterministic algorithm which computes the multilinear factors\nof multivariate lacunary polynomials over number fields. Its complexity is\npolynomial in $\\ell^n$ where $\\ell$ is the lacunary size of the input\npolynomial and $n$ its number of variables, that is in particular polynomial in\nthe logarithm of its degree. We also provide a randomized algorithm for the\nsame problem of complexity polynomial in $\\ell$ and $n$.\n  Over other fields of characteristic zero and finite fields of large\ncharacteristic, our algorithms compute the multilinear factors having at least\nthree monomials of multivariate polynomials. Lower bounds are provided to\nexplain the limitations of our algorithm. As a by-product, we also design\npolynomial-time deterministic polynomial identity tests for families of\npolynomials which were not known to admit any.\n  Our results are based on so-called Gap Theorem which reduce high-degree\nfactorization to repeated low-degree factorizations. While previous algorithms\nused Gap Theorems expressed in terms of the heights of the coefficients, our\nGap Theorems only depend on the exponents of the polynomials. This makes our\nalgorithms more elementary and general, and faster in most cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.5694v2"
    },
    {
        "title": "Parallel computation of echelon forms",
        "authors": [
            "Jean-Guillaume Dumas",
            "Thierry Gautier",
            "Clément Pernet",
            "Ziad Sultan"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We propose efficient parallel algorithms and implementations on shared memory\narchitectures of LU factorization over a finite field. Compared to the\ncorresponding numerical routines, we have identified three main difficulties\nspecific to linear algebra over finite fields. First, the arithmetic complexity\ncould be dominated by modular reductions. Therefore, it is mandatory to delay\nas much as possible these reductions while mixing fine-grain parallelizations\nof tiled iterative and recursive algorithms. Second, fast linear algebra\nvariants, e.g., using Strassen-Winograd algorithm, never suffer from\ninstability and can thus be widely used in cascade with the classical\nalgorithms. There, trade-offs are to be made between size of blocks well suited\nto those fast variants or to load and communication balancing. Third, many\napplications over finite fields require the rank profile of the matrix (quite\noften rank deficient) rather than the solution to a linear system. It is thus\nimportant to design parallel algorithms that preserve and compute this rank\nprofile. Moreover, as the rank profile is only discovered during the algorithm,\nblock size has then to be dynamic. We propose and compare several block\ndecomposition: tile iterative with left-looking, right-looking and Crout\nvariants, slab and tile recursive. Experiments demonstrate that the tile\nrecursive variant performs better and matches the performance of reference\nnumerical software when no rank deficiency occur. Furthermore, even in the most\nheterogeneous case, namely when all pivot blocks are rank deficient, we show\nthat it is possbile to maintain a high efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3501v1"
    },
    {
        "title": "Matrix-F5 algorithms and tropical Gröbner bases computation",
        "authors": [
            "Tristan Vaccon"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Let $K$ be a field equipped with a valuation. Tropical varieties over $K$ can\nbe defined with a theory of Gr\\\"obner bases taking into account the valuation\nof $K$. Because of the use of the valuation, this theory is promising for\nstable computations over polynomial rings over a $p$-adic fields.We design a\nstrategy to compute such tropical Gr\\\"obner bases by adapting the Matrix-F5\nalgorithm. Two variants of the Matrix-F5 algorithm, depending on how the\nMacaulay matrices are built, are available to tropical computation with\nrespective modifications. The former is more numerically stable while the\nlatter is faster.Our study is performed both over any exact field with\nvaluation and some inexact fields like $\\mathbb{Q}\\_p$ or $\\mathbb{F}\\_q\n\\llbracket t \\rrbracket.$ In the latter case, we track the loss in precision,\nand show that the numerical stability can compare very favorably to the case of\nclassical Gr\\\"obner bases when the valuation is non-trivial. Numerical examples\nare provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6675v2"
    },
    {
        "title": "Matrix-F5 algorithms over finite-precision complete discrete valuation\n  fields",
        "authors": [
            "Tristan Vaccon"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Let $(f\\_1,\\dots, f\\_s) \\in \\mathbb{Q}\\_p [X\\_1,\\dots, X\\_n]^s$ be a sequence\nof homogeneous polynomials with $p$-adic coefficients. Such system may happen,\nfor example, in arithmetic geometry. Yet, since $\\mathbb{Q}\\_p$ is not an\neffective field, classical algorithm does not apply.We provide a definition for\nan approximate Gr{\\\"o}bner basis with respect to a monomial order $w.$ We\ndesign a strategy to compute such a basis, when precision is enough and under\nthe assumption that the input sequence is regular and the ideals $\\langle\nf\\_1,\\dots,f\\_i \\rangle$ are weakly-$w$-ideals. The conjecture of Moreno-Socias\nstates that for the grevlex ordering, such sequences are generic.Two variants\nof that strategy are available, depending on whether one lean more on precision\nor time-complexity. For the analysis of these algorithms, we study the loss of\nprecision of the Gauss row-echelon algorithm, and apply it to an adapted\nMatrix-F5 algorithm. Numerical examples are provided.Moreover, the fact that\nunder such hypotheses, Gr{\\\"o}bner bases can be computed stably has many\napplications. Firstly, the mapping sending $(f\\_1,\\dots,f\\_s)$ to the reduced\nGr{\\\"o}bner basis of the ideal they span is differentiable, and its\ndifferential can be given explicitly. Secondly, these hypotheses allows to\nperform lifting on the Grobner bases, from $\\mathbb{Z}/p^k \\mathbb{Z}$ to\n$\\mathbb{Z}/p^{k+k'} \\mathbb{Z}$ or $\\mathbb{Z}.$ Finally, asking for the same\nhypotheses on the highest-degree homogeneous components of the entry\npolynomials allows to extend our strategy to the affine case.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.5464v2"
    },
    {
        "title": "Solving the \"Isomorphism of Polynomials with Two Secrets\" Problem for\n  all Pairs of Quadratic Forms",
        "authors": [
            "Jérôme Plût",
            "Pierre-Alain Fouque",
            "Gilles Macario-Rat"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We study the Isomorphism of Polynomial (IP2S) problem with m=2 homogeneous\nquadratic polynomials of n variables over a finite field of odd characteristic:\ngiven two quadratic polynomials (a, b) on n variables, we find two bijective\nlinear maps (s,t) such that b=t . a . s. We give an algorithm computing s and t\nin time complexity O~(n^4) for all instances, and O~(n^3) in a dominant set of\ninstances.\n  The IP2S problem was introduced in cryptography by Patarin back in 1996. The\nspecial case of this problem when t is the identity is called the isomorphism\nwith one secret (IP1S) problem. Generic algebraic equation solvers (for example\nusing Gr\\\"obner bases) solve quite well random instances of the IP1S problem.\nFor the particular cyclic instances of IP1S, a cubic-time algorithm was later\ngiven and explained in terms of pencils of quadratic forms over all finite\nfields; in particular, the cyclic IP1S problem in odd characteristic reduces to\nthe computation of the square root of a matrix.\n  We give here an algorithm solving all cases of the IP1S problem in odd\ncharacteristic using two new tools, the Kronecker form for a singular quadratic\npencil, and the reduction of bilinear forms over a non-commutative algebra.\nFinally, we show that the second secret in the IP2S problem may be recovered in\ncubic time.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.3163v3"
    },
    {
        "title": "An Algorithm for Deciding the Summability of Bivariate Rational\n  Functions",
        "authors": [
            "Qing-Hu Hou",
            "Rong-Hua Wang"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Let $\\Delta_x f(x,y)=f(x+1,y)-f(x,y)$ and $\\Delta_y f(x,y)=f(x,y+1)-f(x,y)$\nbe the difference operators with respect to $x$ and $y$. A rational function\n$f(x,y)$ is called summable if there exist rational functions $g(x,y)$ and\n$h(x,y)$ such that $f(x,y)=\\Delta_x g(x,y) + \\Delta_y h(x,y)$. Recently, Chen\nand Singer presented a method for deciding whether a rational function is\nsummable. To implement their method in the sense of algorithms, we need to\nsolve two problems. The first is to determine the shift equivalence of two\nbivariate polynomials. We solve this problem by presenting an algorithm for\ncomputing the dispersion sets of any two bivariate polynomials. The second is\nto solve a univariate difference equation in an algebraically closed field. By\nconsidering the irreducible factorization of the denominator of $f(x,y)$ in a\ngeneral field, we present a new criterion which requires only finding a\nrational solution of a bivariate difference equation. This goal can be achieved\nby deriving a universal denominator of the rational solutions and a degree\nbound on the numerator. Combining these two algorithms, we can decide the\nsummability of a bivariate rational function.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.2473v1"
    },
    {
        "title": "Desingularization of Ore Operators",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers",
            "Michael F. Singer"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We show that Ore operators can be desingularized by calculating a least\ncommon left multiple with a random operator of appropriate order. Our result\ngeneralizes a classical result about apparent singularities of linear\ndifferential equations, and it gives rise to a surprisingly simple\ndesingularization algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5512v1"
    },
    {
        "title": "Bounds for D-finite closure properties",
        "authors": [
            "Manuel Kauers"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We provide bounds on the size of operators obtained by algorithms for\nexecuting D-finite closure properties. For operators of small order, we give\nbounds on the degree and on the height (bit-size). For higher order operators,\nwe give degree bounds that are parameterized with respect to the order and\nreflect the phenomenon that higher order operators may have lower degrees\n(order-degree curves).\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5514v1"
    },
    {
        "title": "Real root finding for determinants of linear matrices",
        "authors": [
            "Didier Henrion",
            "Simone Naldi",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Let $\\A_0, \\A_1, \\ldots, \\A_n$ be given square matrices of size $m$ with\nrational coefficients. The paper focuses on the exact computation of one point\nin each connected component of the real determinantal variety $\\{\\X \\in\\RR^n \\:\n:\\: \\det(\\A_0+x_1\\A_1+\\cdots+x_n\\A_n)=0\\}$. Such a problem finds applications\nin many areas such as control theory, computational geometry, optimization,\netc. Using standard complexity results this problem can be solved using\n$m^{O(n)}$ arithmetic operations. Under some genericity assumptions on the\ncoefficients of the matrices, we provide an algorithm solving this problem\nwhose runtime is essentially quadratic in ${{n+m}\\choose{n}}^{3}$. We also\nreport on experiments with a computer implementation of this algorithm. Its\npractical performance illustrates the complexity estimates. In particular, we\nemphasize that for subfamilies of this problem where $m$ is fixed, the\ncomplexity is polynomial in $n$.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.5873v1"
    },
    {
        "title": "Extractions: Computable and Visible Analogues of Localizations for\n  Polynomial Ideals",
        "authors": [
            "Ye Liang"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  When studying local properties of a polynomial ideal, one usually needs a\ntheoretic technique called localization. For most cases, in spite of its\nimportance, the computation in a localized ring cannot be algorithmically\npreformed. On the other hand, the standard basis method is very effective for\nthe computation in a special kind of localized rings, but for a general\nsemigroup order the geometry of the localization of a positive-dimensional\nideal is difficult to interpret.\n  In this paper, we introduce a new ideal operation called extraction. For an\nideal $I$ in a polynomial ring $K[x_1,\\ldots,x_n]$ over a field $K$, we use\nanother ideal $J$ to control the primary components of $I$ and the result\n$\\beta(I,J)$ is called the extraction of $I$ by $J$. It is still a polynomial\nideal and has a concrete geometric meaning in $\\bar{K}^n$, i.e., we keep the\nbranches of $\\textbf{V}(I) \\subset \\bar{K}^n$ that intersect with\n$\\textbf{V}(J) \\subset \\bar{K}^n$ and delete others, where $\\bar{K}$ is the\nalgebraic closure of $K$. This is what we mean by visible. On the other hand,\nwe can use the standard basis method to compute a localized ideal corresponding\nto $\\beta(I,J)$ without a complete primary decomposition, and can do further\ncomputation in the localized ring such as determining the membership problem of\n$\\beta(I,J)$. Moreover, we prove that extractions are as powerful as\nlocalizations in the sense that for any multiplicatively closed subset $S$ of\n$K[x_1,\\ldots,x_n]$ and any polynomial ideal $I$, there always exists a\npolynomial ideal $J$ such that $\\beta(I,J)=(S^{-1}I)^c$.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.03967v1"
    },
    {
        "title": "Tropical differential equations",
        "authors": [
            "Dima Grigoriev"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Tropical differential equations are introduced and an algorithm is designed\nwhich tests solvability of a system of tropical linear differential equations\nwithin the complexity polynomial in the size of the system and in its\ncoefficients. Moreover, we show that there exists a minimal solution, and the\nalgorithm constructs it (in case of solvability). This extends a similar\ncomplexity bound established for tropical linear systems. In case of tropical\nlinear differential systems in one variable a polynomial complexity algorithm\nfor testing its solvability is designed.\n  We prove also that the problem of solvability of a system of tropical\nnon-linear differential equations in one variable is $NP$-hard, and this\nproblem for arbitrary number of variables belongs to $NP$. Similar to tropical\nalgebraic equations, a tropical differential equation expresses the (necessary)\ncondition on the dominant term in the issue of solvability of a differential\nequation in power series.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.08010v1"
    },
    {
        "title": "Polynomial complexity recognizing a tropical linear variety",
        "authors": [
            "Dima Grigoriev"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  A polynomial complexity algorithm is designed which tests whether a point\nbelongs to a given tropical linear variety.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06126v1"
    },
    {
        "title": "Recent Advances in Real Geometric Reasoning",
        "authors": [
            "James H. Davenport",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  In the 1930s Tarski showed that real quantifier elimination was possible, and\nin 1975 Collins gave a remotely practicable method, albeit with\ndoubly-exponential complexity, which was later shown to be inherent. We discuss\nsome of the recent major advances in Collins method: such as an alternative\napproach based on passing via the complexes, and advances which come closer to\n\"solving the question asked\" rather than \"solving all problems to do with these\npolynomials\".\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06484v1"
    },
    {
        "title": "Pfaffian Systems of A-Hypergeometric Systems II --- Holonomic Gradient\n  Method",
        "authors": [
            "Katsuyoshi Ohara",
            "Nobuki Takayama"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We give two efficient methods to derive Pfaffian systems for A-hypergeometric\nsystems for the application to the holonomic gradient method for statistics. We\nutilize the Hilbert driven Buchberger algorithm and Macaulay type matrices in\nthe two methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.02947v1"
    },
    {
        "title": "Multiple binomial sums",
        "authors": [
            "Alin Bostan",
            "Pierre Lairez",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Multiple binomial sums form a large class of multi-indexed sequences, closed\nunder partial summation, which contains most of the sequences obtained by\nmultiple summation of products of binomial coefficients and also all the\nsequences with algebraic generating function. We study the representation of\nthe generating functions of binomial sums by integrals of rational functions.\nThe outcome is twofold. Firstly, we show that a univariate sequence is a\nmultiple binomial sum if and only if its generating function is the diagonal of\na rational function. Secondly, we propose algorithms that decide the equality\nof multiple binomial sums and that compute recurrence relations for them. In\nconjunction with geometric simplifications of the integral representations,\nthis approach behaves well in practice. The process avoids the computation of\ncertificates and the problem of the appearance of spurious singularities that\nafflicts discrete creative telescoping, both in theory and in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.07487v2"
    },
    {
        "title": "Holonomic Tools for Basic Hypergeometric Functions",
        "authors": [
            "Christoph Koutschan",
            "Peter Paule"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  With the exception of q-hypergeometric summation, the use of computer algebra\npackages implementing Zeilberger's \"holonomic systems approach\" in a broader\nmathematical sense is less common in the field of q-series and basic\nhypergeometric functions. A major objective of this article is to popularize\nthe usage of such tools also in these domains. Concrete case studies showing\nsoftware in action introduce to the basic techniques. An application highlight\nis a new computer-assisted proof of the celebrated Ismail-Zhang formula, an\nimportant q-analog of a classical expansion formula of plane waves in terms of\nGegenbauer polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00454v1"
    },
    {
        "title": "Fast Computation of the Nth Term of an Algebraic Series over a Finite\n  Prime Field",
        "authors": [
            "Alin Bostan",
            "Gilles Christol",
            "Philippe Dumas"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We address the question of computing one selected term of an algebraic power\nseries. In characteristic zero, the best algorithm currently known for\ncomputing the $N$th coefficient of an algebraic series uses differential\nequations and has arithmetic complexity quasi-linear in $\\sqrt{N}$. We show\nthat over a prime field of positive characteristic $p$, the complexity can be\nlowered to $O(\\log N)$. The mathematical basis for this dramatic improvement is\na classical theorem stating that a formal power series with coefficients in a\nfinite field is algebraic if and only if the sequence of its coefficients can\nbe generated by an automaton. We revisit and enhance two constructive proofs of\nthis result for finite prime fields. The first proof uses Mahler equations,\nwhose sizes appear to be prohibitively large. The second proof relies on\ndiagonals of rational functions; we turn it into an efficient algorithm, of\ncomplexity linear in $\\log N$ and quasi-linear in $p$.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00545v2"
    },
    {
        "title": "On the p-adic stability of the FGLM algorithm",
        "authors": [
            "Guénaël Renault",
            "Tristan Vaccon"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Nowadays, many strategies to solve polynomial systems use the computation of\na Gr{\\\"o}bner basis for the graded reverse lexicographical ordering, followed\nby a change of ordering algorithm to obtain a Gr{\\\"o}bner basis for the\nlexicographical ordering. The change of ordering algorithm is crucial for these\nstrategies. We study the p-adic stability of the main change of ordering\nalgorithm, FGLM. We show that FGLM is stable and give explicit upper bound on\nthe loss of precision occuring in its execution. The variant of FGLM designed\nto pass from the grevlex ordering to a Gr{\\\"o}bner basis in shape position is\nalso stable. Our study relies on the application of Smith Normal Form\ncomputations for linear algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00848v1"
    },
    {
        "title": "Inverse Inequality Estimates with Symbolic Computation",
        "authors": [
            "Christoph Koutschan",
            "Martin Neumüller",
            "Cristian-Silviu Radu"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In the convergence analysis of numerical methods for solving partial\ndifferential equations (such as finite element methods) one arrives at certain\ngeneralized eigenvalue problems, whose maximal eigenvalues need to be estimated\nas accurately as possible. We apply symbolic computation methods to the\nsituation of square elements and are able to improve the previously known upper\nbound, given in \"p- and hp-finite element methods\" (Schwab, 1998), by a factor\nof 8. More precisely, we try to evaluate the corresponding determinant using\nthe holonomic ansatz, which is a powerful tool for dealing with determinants,\nproposed by Zeilberger in 2007. However, it turns out that this method does not\nsucceed on the problem at hand. As a solution we present a variation of the\noriginal holonomic ansatz that is applicable to a larger class of determinants,\nincluding the one we are dealing with here. We obtain an explicit closed form\nfor the determinant, whose special form enables us to derive new and tight\nupper resp. lower bounds on the maximal eigenvalue, as well as its asymptotic\nbehaviour.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.01304v2"
    },
    {
        "title": "Toric Difference Variety",
        "authors": [
            "Xiao-Shan Gao",
            "Zhang Huang",
            "Jie Wang",
            "Chun-Ming Yuan"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In this paper, the concept of toric difference varieties is defined and four\nequivalent descriptions for toric difference varieties are presented in terms\nof difference rational parametrization, difference coordinate rings, toric\ndifference ideals, and group actions by difference tori. Connections between\ntoric difference varieties and affine N[x]-semimodules are established by\nproving the correspondence between the irreducible invariant difference\nsubvarieties and the faces of the N[x]-submodules and the orbit-face\ncorrespondence. Finally, an algorithm is given to decide whether a binomial\ndifference ideal represented by a Z[x]-lattice defines a toric difference\nvariety.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.01958v1"
    },
    {
        "title": "New Bounds for Hypergeometric Creative Telescoping",
        "authors": [
            "Hui Huang"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Based on a modified version of Abramov-Petkov\\v{s}ek reduction, a new\nalgorithm to compute minimal telescopers for bivariate hypergeometric terms was\ndeveloped last year. We investigate further in this paper and present a new\nargument for the termination of this algorithm, which provides an independent\nproof of the existence of telescopers and even enables us to derive lower as\nwell as upper bounds for the order of telescopers for hypergeometric terms.\nCompared to the known bounds in the literature, our bounds are sometimes\nbetter, and never worse than the known ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.08059v4"
    },
    {
        "title": "On the Complexity of Solving Zero-Dimensional Polynomial Systems via\n  Projection",
        "authors": [
            "Cornelius Brand",
            "Michael Sagraloff"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Given a zero-dimensional polynomial system consisting of n integer\npolynomials in n variables, we propose a certified and complete method to\ncompute all complex solutions of the system as well as a corresponding\nseparating linear form l with coefficients of small bit size. For computing l,\nwe need to project the solutions into one dimension along O(n) distinct\ndirections but no further algebraic manipulations. The solutions are then\ndirectly reconstructed from the considered projections. The first step is\ndeterministic, whereas the second step uses randomization, thus being\nLas-Vegas.\n  The theoretical analysis of our approach shows that the overall cost for the\ntwo problems considered above is dominated by the cost of carrying out the\nprojections. We also give bounds on the bit complexity of our algorithms that\nare exclusively stated in terms of the number of variables, the total degree\nand the bitsize of the input polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.08944v1"
    },
    {
        "title": "The Complexity of Computing all Subfields of an Algebraic Number Field",
        "authors": [
            "Jonas Szutkoski",
            "Mark van Hoeij"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  For a finite separable field extension K/k, all subfields can be obtained by\nintersecting so-called principal subfields of K/k. In this work we present a\nway to quickly compute these intersections. If the number of subfields is high,\nthen this leads to faster run times and an improved complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.01140v3"
    },
    {
        "title": "Computing Hypergeometric Solutions of Second Order Linear Differential\n  Equations using Quotients of Formal Solutions and Integral Bases",
        "authors": [
            "Erdal Imamoglu",
            "Mark van Hoeij"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We present two algorithms for computing hypergeometric solutions of second\norder linear differential operators with rational function coefficients. Our\nfirst algorithm searches for solutions of the form \\[ \\exp(\\int r \\,\ndx)\\cdot{_{2}F_1}(a_1,a_2;b_1;f) \\] where $r,f \\in \\overline{\\mathbb{Q}(x)}$,\nand $a_1,a_2,b_1 \\in \\mathbb{Q}$. It uses modular reduction and Hensel lifting.\nOur second algorithm tries to find solutions in the form \\[ \\exp(\\int r \\,\ndx)\\cdot \\left( r_0 \\cdot{_{2}F_1}(a_1,a_2;b_1;f) + r_1\n\\cdot{_{2}F_1}'(a_1,a_2;b_1;f) \\right) \\] where $r_0, r_1 \\in\n\\overline{\\mathbb{Q}(x)}$, as follows: It tries to transform the input equation\nto another equation with solutions of the first type, and then uses the first\nalgorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.01576v1"
    },
    {
        "title": "Rational Solutions of Underdetermined Polynomial Equations",
        "authors": [
            "Thomas Wolf",
            "Chimaobi Amadi"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In this paper we report on an application of computer algebra in which\nmathematical puzzles are generated of a type that had been widely used in\nmathematics contests by a large number of participants worldwide.\n  The algorithmic aspect of our work provides a method to compute rational\nsolutions of single polynomial equations that are typically large with $10^2\n\\ldots 10^5$ terms and that are heavily underdetermined. This functionality was\nobtained by adding modules for a new type of splitting of equations to the\nexisting package CRACK that is normally used to solve polynomial algebraic and\ndifferential systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.00697v1"
    },
    {
        "title": "Using Machine Learning to Decide When to Precondition Cylindrical\n  Algebraic Decomposition With Groebner Bases",
        "authors": [
            "Zongyan Huang",
            "Matthew England",
            "James H. Davenport",
            "Lawrence C. Paulson"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Cylindrical Algebraic Decomposition (CAD) is a key tool in computational\nalgebraic geometry, particularly for quantifier elimination over real-closed\nfields. However, it can be expensive, with worst case complexity doubly\nexponential in the size of the input. Hence it is important to formulate the\nproblem in the best manner for the CAD algorithm. One possibility is to\nprecondition the input polynomials using Groebner Basis (GB) theory. Previous\nexperiments have shown that while this can often be very beneficial to the CAD\nalgorithm, for some problems it can significantly worsen the CAD performance.\n  In the present paper we investigate whether machine learning, specifically a\nsupport vector machine (SVM), may be used to identify those CAD problems which\nbenefit from GB preconditioning. We run experiments with over 1000 problems\n(many times larger than previous studies) and find that the machine learned\nchoice does better than the human-made heuristic.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.04219v1"
    },
    {
        "title": "On matrices with displacement structure: generalized operators and\n  faster algorithms",
        "authors": [
            "Alin Bostan",
            "Claude-Pierre Jeannerod",
            "Christophe Mouilleron",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  For matrices with displacement structure, basic operations like\nmultiplication, inversion, and linear system solving can all be expressed in\nterms of the following task: evaluate the product $\\mathsf{A}\\mathsf{B}$, where\n$\\mathsf{A}$ is a structured $n \\times n$ matrix of displacement rank $\\alpha$,\nand $\\mathsf{B}$ is an arbitrary $n\\times\\alpha$ matrix. Given $\\mathsf{B}$ and\na so-called \"generator\" of $\\mathsf{A}$, this product is classically computed\nwith a cost ranging from $O(\\alpha^2 \\mathscr{M}(n))$ to $O(\\alpha^2\n\\mathscr{M}(n)\\log(n))$ arithmetic operations, depending on the type of\nstructure of $\\mathsf{A}$; here, $\\mathscr{M}$ is a cost function for\npolynomial multiplication. In this paper, we first generalize classical\ndisplacement operators, based on block diagonal matrices with companion\ndiagonal blocks, and then design fast algorithms to perform the task above for\nthis extended class of structured matrices. The cost of these algorithms ranges\nfrom $O(\\alpha^{\\omega-1} \\mathscr{M}(n))$ to $O(\\alpha^{\\omega-1}\n\\mathscr{M}(n)\\log(n))$, with $\\omega$ such that two $n \\times n$ matrices over\na field can be multiplied using $O(n^\\omega)$ field operations. By combining\nthis result with classical randomized regularization techniques, we obtain\nfaster Las Vegas algorithms for structured inversion and linear system solving.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.03734v1"
    },
    {
        "title": "Ultimate Positivity of Diagonals of Quasi-rational Functions",
        "authors": [
            "Hui Huang"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  The problem to decide whether a given multivariate (quasi-)rational function\nhas only positive coefficients in its power series expansion has a long\nhistory. It dates back to Szego in 1933 who showed certain quasi-rational\nfunction to be positive, in the sense that all the series coefficients are\npositive, using an involved theory of special functions. In contrast to the\nsimplicity of the statement, the method was surprisingly difficult. This\ndependency motivated further research for positivity of (quasi-)rational\nfunctions. More and more (quasi-)rational functions have been proven to be\npositive, and some of the proofs are even quite simple. However, there are also\nothers whose positivity are still open conjectures. In this talk, we focus on a\nless difficult but also interesting question to decide whether the diagonal of\na given quasi-rational function is ultimately positive, especially for the one\nconjectured to be positive by Kauers in 2007. To solve this question, it\nsuffices to compute the asymptotics of the diagonal coefficients, which can be\ndone by the multivariate singularity analysis developed by Baryshnikov,\nPemantle and Wilson. Note that the ultimate positivity is a necessary condition\nfor the positivity, and therefore can be used to either exclude the nonpositive\ncases or further support the conjectural positivity.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.05580v1"
    },
    {
        "title": "CAD Adjacency Computation Using Validated Numerics",
        "authors": [
            "Adam Strzebonski"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We present an algorithm for computation of cell adjacencies for well-based\ncylindrical algebraic decomposition. Cell adjacency information can be used to\ncompute topological operations e.g. closure, boundary, connected components,\nand topological properties e.g. homology groups. Other applications include\nvisualization and path planning. Our algorithm determines cell adjacency\ninformation using validated numerical methods similar to those used in CAD\nconstruction, thus computing CAD with adjacency information in time comparable\nto that of computing CAD without adjacency information. We report on\nimplementation of the algorithm and present empirical data.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.06856v1"
    },
    {
        "title": "A Tropical F5 algorithm",
        "authors": [
            "Tristan Vaccon",
            "Kazuhiro Yokoyama"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Let K be a field equipped with a valuation. Tropical varieties over K can be\ndefined with a theory of Gr{\\\"o}bner bases taking into account the valuation of\nK. While generalizing the classical theory of Gr{\\\"o}bner bases, it is not\nclear how modern algorithms for computing Gr{\\\"o}bner bases can be adapted to\nthe tropical case. Among them, one of the most efficient is the celebrated F5\nAlgorithm of Faug{\\`e}re. In this article, we prove that, for homogeneous\nideals, it can be adapted to the tropical case. We prove termination and\ncorrectness. Because of the use of the valuation, the theory of tropical\nGr{\\\"o}b-ner bases is promising for stable computations over polynomial rings\nover a p-adic field. We provide numerical examples to illustrate\ntime-complexity and p-adic stability of this tropical F5 algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.05571v1"
    },
    {
        "title": "On Euler's inequality and automated reasoning with dynamic geometry",
        "authors": [
            "Zoltán Kovács",
            "Róbert Vajda",
            "Aaron Montag"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Euler's inequality $R\\geq 2r$ can be investigated in a novel way by using\nimplicit loci in GeoGebra. Some unavoidable side effects of the implicit locus\ncomputation introduce unexpected algebraic curves. By using a mixture of\nsymbolic and numerical methods a possible approach is sketched up to\ninvestigate the situation. By exploiting fast GPU computations, a web\napplication written in CindyJS helps in understanding the situation even\nbetter.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.02993v3"
    },
    {
        "title": "Faster Multiplication for Long Binary Polynomials",
        "authors": [
            "Ming-Shing Chen",
            "Chen-Mou Cheng",
            "Po-Chun Kuo",
            "Wen-Ding Li",
            "Bo-Yin Yang"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We set new speed records for multiplying long polynomials over finite fields\nof characteristic two. Our multiplication algorithm is based on an additive FFT\n(Fast Fourier Transform) by Lin, Chung, and Huang in 2014 comparing to\npreviously best results based on multiplicative FFTs. Both methods have similar\ncomplexity for arithmetic operations on underlying finite field; however, our\nimplementation shows that the additive FFT has less overhead. For further\noptimization, we employ a tower field construction because the multipliers in\nthe additive FFT naturally fall into small subfields, which leads to speed-ups\nusing table-lookup instructions in modern CPUs. Benchmarks show that our method\nsaves about $40 \\%$ computing time when multiplying polynomials of $2^{28}$ and\n$2^{29}$ bits comparing to previous multiplicative FFT implementations.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.09746v3"
    },
    {
        "title": "Automatic Differentiation for Tensor Algebras",
        "authors": [
            "Sebastian Urban",
            "Patrick van der Smagt"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  Kjolstad et. al. proposed a tensor algebra compiler. It takes expressions\nthat define a tensor element-wise, such as $f_{ij}(a,b,c,d) =\n\\exp\\left[-\\sum_{k=0}^4 \\left((a_{ik}+b_{jk})^2\\, c_{ii} + d_{i+k}^3 \\right)\n\\right]$, and generates the corresponding compute kernel code.\n  For machine learning, especially deep learning, it is often necessary to\ncompute the gradient of a loss function $l(a,b,c,d)=l(f(a,b,c,d))$ with respect\nto parameters $a,b,c,d$. If tensor compilers are to be applied in this field,\nit is necessary to derive expressions for the derivatives of element-wise\ndefined tensors, i.e. expressions for $(da)_{ik}=\\partial l/\\partial a_{ik}$.\n  When the mapping between function indices and argument indices is not 1:1,\nspecial attention is required. For the function $f_{ij} (x) = x_i^2$, the\nderivative of the loss is $(dx)_i=\\partial l/\\partial x_i=\\sum_j\n(df)_{ij}2x_i$; the sum is necessary because index $j$ does not appear in the\nindices of $f$. Another example is $f_{i}(x)=x_{ii}^2$, where $x$ is a matrix;\nhere we have $(dx)_{ij}=\\delta_{ij}(df)_i2x_{ii}$; the Kronecker delta is\nnecessary because the derivative is zero for off-diagonal elements. Another\nindexing scheme is used by $f_{ij}(x)=\\exp x_{i+j}$; here the correct\nderivative is $(dx)_{k}=\\sum_i (df)_{i,k-i} \\exp x_{k}$, where the range of the\nsum must be chosen appropriately.\n  In this publication we present an algorithm that can handle any case in which\nthe indices of an argument are an arbitrary linear combination of the indices\nof the function, thus all the above examples can be handled. Sums (and their\nranges) and Kronecker deltas are automatically inserted into the derivatives as\nnecessary. Additionally, the indices are transformed, if required (as in the\nlast example). The algorithm outputs a symbolic expression that can be\nsubsequently fed into a tensor algebra compiler.\n  Source code is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.01348v1"
    },
    {
        "title": "Symbolic-Numeric Integration of Rational Functions",
        "authors": [
            "Robert M. Corless",
            "Robert H. C. Moir",
            "Marc Moreno Maza",
            "Ning Xie"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We consider the problem of symbolic-numeric integration of symbolic\nfunctions, focusing on rational functions. Using a hybrid method allows the\nstable yet efficient computation of symbolic antiderivatives while avoiding\nissues of ill-conditioning to which numerical methods are susceptible. We\npropose two alternative methods for exact input that compute the rational part\nof the integral using Hermite reduction and then compute the transcendental\npart two different ways using a combination of exact integration and efficient\nnumerical computation of roots. The symbolic computation is done within BPAS,\nor Basic Polynomial Algebra Subprograms, which is a highly optimized\nenvironment for polynomial computation on parallel architectures, while the\nnumerical computation is done using the highly optimized multiprecision\nrootfinding package MPSolve. We show that both methods are forward and backward\nstable in a structured sense and away from singularities tolerance\nproportionality is achieved by adjusting the precision of the rootfinding\ntasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.01752v2"
    },
    {
        "title": "On Division Polynomial PIT and Supersingularity",
        "authors": [
            "Javad Doliskani"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  For an elliptic curve $E$ over a finite field $\\F_q$, where $q$ is a prime\npower, we propose new algorithms for testing the supersingularity of $E$. Our\nalgorithms are based on the Polynomial Identity Testing (PIT) problem for the\n$p$-th division polynomial of $E$. In particular, an efficient algorithm using\npoints of high order on $E$ is given.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.02664v2"
    },
    {
        "title": "Frobenius Additive Fast Fourier Transform",
        "authors": [
            "Wen-Ding Li",
            "Ming-Shing Chen",
            "Po-Chun Kuo",
            "Chen-Mou Cheng",
            "Bo-Yin Yang"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In ISSAC 2017, van der Hoeven and Larrieu showed that evaluating a polynomial\nP in GF(q)[x] of degree <n at all n-th roots of unity in GF($q^d$) can\nessentially be computed d-time faster than evaluating Q in GF($q^d$)[x] at all\nthese roots, assuming GF($q^d$) contains a primitive n-th root of unity. Termed\nthe Frobenius FFT, this discovery has a profound impact on polynomial\nmultiplication, especially for multiplying binary polynomials, which finds\nample application in coding theory and cryptography. In this paper, we show\nthat the theory of Frobenius FFT beautifully generalizes to a class of additive\nFFT developed by Cantor and Gao-Mateer. Furthermore, we demonstrate the power\nof Frobenius additive FFT for q=2: to multiply two binary polynomials whose\nproduct is of degree <256, the new technique requires only 29,005 bit\noperations, while the best result previously reported was 33,397. To the best\nof our knowledge, this is the first time that FFT-based multiplication\noutperforms Karatsuba and the like at such a low degree in terms of\nbit-operation count.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03932v1"
    },
    {
        "title": "Formal Analysis of Galois Field Arithmetics - Parallel Verification and\n  Reverse Engineering",
        "authors": [
            "Cunxi Yu",
            "Maciej Ciesielski"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Galois field (GF) arithmetic circuits find numerous applications in\ncommunications, signal processing, and security engineering. Formal\nverification techniques of GF circuits are scarce and limited to circuits with\nknown bit positions of the primary inputs and outputs. They also require\nknowledge of the irreducible polynomial $P(x)$, which affects final hardware\nimplementation. This paper presents a computer algebra technique that performs\nverification and reverse engineering of GF($2^m$) multipliers directly from the\ngate-level implementation. The approach is based on extracting a unique\nirreducible polynomial in a parallel fashion and proceeds in three steps: 1)\ndetermine the bit position of the output bits; 2) determine the bit position of\nthe input bits; and 3) extract the irreducible polynomial used in the design.\nWe demonstrate that this method is able to reverse engineer GF($2^m$)\nmultipliers in \\textit{m} threads. Experiments performed on synthesized\n\\textit{Mastrovito} and \\textit{Montgomery} multipliers with different $P(x)$,\nincluding NIST-recommended polynomials, demonstrate high efficiency of the\nproposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.06870v1"
    },
    {
        "title": "Simulation-Based Reachability Analysis for High-Index Large Linear\n  Differential Algebraic Equations",
        "authors": [
            "Hoang-Dung Tran",
            "Weiming Xiang",
            "Nathaniel Hamilton",
            "Taylor T. Johnson"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Reachability analysis is a fundamental problem for safety verification and\nfalsification of Cyber-Physical Systems (CPS) whose dynamics follow physical\nlaws usually represented as differential equations. In the last two decades,\nnumerous reachability analysis methods and tools have been proposed for a\ncommon class of dynamics in CPS known as ordinary differential equations (ODE).\nHowever, there is lack of methods dealing with differential algebraic equations\n(DAE) which is a more general class of dynamics that is widely used to describe\na variety of problems from engineering and science such as multibody mechanics,\nelectrical cicuit design, incompressible fluids, molecular dynamics and\nchemcial process control. Reachability analysis for DAE systems is more complex\nthan ODE systems, especially for high-index DAEs because they contain both a\ndifferential part (i.e., ODE) and algebraic constraints (AC). In this paper, we\nextend the recent scalable simulation-based reachability analysis in\ncombination with decoupling techniques for a class of high-index large linear\nDAEs. In particular, a high-index linear DAE is first decoupled into one ODE\nand one or several AC subsystems based on the well-known Marz decoupling method\nultilizing admissible projectors. Then, the discrete reachable set of the DAE,\nrepresented as a list of star-sets, is computed using simulation. Unlike ODE\nreachability analysis where the initial condition is freely defined by a user,\nin DAE cases, the consistency of the inititial condition is an essential\nrequirement to guarantee a feasible solution. Therefore, a thorough check for\nthe consistency is invoked before computing the discrete reachable set. Our\napproach sucessfully verifies (or falsifies) a wide range of practical,\nhigh-index linear DAE systems in which the number of state variables varies\nfrom several to thousands.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.03227v1"
    },
    {
        "title": "Using Machine Learning to Improve Cylindrical Algebraic Decomposition",
        "authors": [
            "Zongyan Huang",
            "Matthew England",
            "David Wilson",
            "James H. Davenport",
            "Lawrence C. Paulson"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Cylindrical Algebraic Decomposition (CAD) is a key tool in computational\nalgebraic geometry, best known as a procedure to enable Quantifier Elimination\nover real-closed fields. However, it has a worst case complexity doubly\nexponential in the size of the input, which is often encountered in practice.\nIt has been observed that for many problems a change in algorithm settings or\nproblem formulation can cause huge differences in runtime costs, changing\nproblem instances from intractable to easy. A number of heuristics have been\ndeveloped to help with such choices, but the complicated nature of the\ngeometric relationships involved means these are imperfect and can sometimes\nmake poor choices. We investigate the use of machine learning (specifically\nsupport vector machines) to make such choices instead.\n  Machine learning is the process of fitting a computer model to a complex\nfunction based on properties learned from measured data. In this paper we apply\nit in two case studies: the first to select between heuristics for choosing a\nCAD variable ordering; the second to identify when a CAD problem instance would\nbenefit from Groebner Basis preconditioning. These appear to be the first such\napplications of machine learning to Symbolic Computation. We demonstrate in\nboth cases that the machine learned choice outperforms human developed\nheuristics.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.10520v1"
    },
    {
        "title": "On Affine Tropical F5 Algorithms",
        "authors": [
            "Tristan Vaccon",
            "Thibaut Verron",
            "Kazuhiro Yokoyama"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Let $K$ be a field equipped with a valuation. Tropical varieties over $K$ can\nbe defined with a theory of Gr{\\\"o}bner bases taking into account the valuation\nof $K$.Because of the use of the valuation, the theory of tropical Gr{\\\"o}bner\nbases has proved to provide settings for computations over polynomial rings\nover a $p$-adic field that are more stable than that of classical Gr{\\\"o}bner\nbases.Beforehand, these strategies were only available for homogeneous\npolynomials. In this article, we extend the F5 strategy to a new definition of\ntropical Gr{\\\"o}bner bases in an affine setting.We provide numerical examples\nto illustrate time-complexity and $p$-adic stability of this tropical F5\nalgorithm.We also illustrate its merits as a first step before an FGLM\nalgorithm to compute (classical) lex bases over $p$-adics.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.06183v1"
    },
    {
        "title": "Algebraic number fields and the LLL algorithm",
        "authors": [
            "M. J. Uray"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this paper we analyze the computational costs of various operations and\nalgorithms in algebraic number fields using exact arithmetic. Let $K$ be an\nalgebraic number field. In the first half of the paper, we calculate the\nrunning time and the size of the output of many operations in $K$ in terms of\nthe size of the input and the parameters of $K$. We include some earlier\nresults about these, but we go further than them, e.g. we also analyze some\n$\\mathbb{R}$-specific operations in $K$ like less-than comparison. In the\nsecond half of the paper, we analyze two algorithms: the Bareiss algorithm,\nwhich is an integer-preserving version of the Gaussian elimination, and the LLL\nalgorithm, which is for lattice basis reduction. In both cases, we extend the\nalgorithm from $\\mathbb{Z}^n$ to $K^n$, and give a polynomial upper bound on\nthe running time when the computations in $K$ are performed exactly (as opposed\nto floating-point approximations).\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01634v2"
    },
    {
        "title": "Subresultants of $(x-α)^m$ and $(x-β)^n$, Jacobi polynomials\n  and complexity",
        "authors": [
            "A. Bostan",
            "T. Krick",
            "A. Szanto",
            "M. Valdettaro"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In an earlier article together with Carlos D'Andrea [BDKSV2017], we described\nexplicit expressions for the coefficients of the order-$d$ polynomial\nsubresultant of $(x-\\alpha)^m$ and $(x-\\beta)^n $ with respect to Bernstein's\nset of polynomials $\\{(x-\\alpha)^j(x-\\beta)^{d-j}, \\, 0\\le j\\le d\\}$, for $0\\le\nd<\\min\\{m, n\\}$. The current paper further develops the study of these\nstructured polynomials and shows that the coefficients of the subresultants of\n$(x-\\alpha)^m$ and $(x-\\beta)^n$ with respect to the monomial basis can be\ncomputed in linear arithmetic complexity, which is faster than for arbitrary\npolynomials. The result is obtained as a consequence of the amazing though\nseemingly unnoticed fact that these subresultants are scalar multiples of\nJacobi polynomials up to an affine change of variables.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11789v2"
    },
    {
        "title": "The PSLQ Algorithm for Empirical Data",
        "authors": [
            "Yong Feng",
            "Jingwei Chen",
            "Wenyuan Wu"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  The celebrated integer relation finding algorithm PSLQ has been successfully\nused in many applications. PSLQ was only analyzed theoretically for exact input\ndata, however, when the input data are irrational numbers, they must be\napproximate ones due to the finite precision of the computer. When the\nalgorithm takes empirical data (inexact data with error bounded) instead of\nexact real numbers as its input, how do we theoretically ensure the output of\nthe algorithm to be an exact integer relation?\n  In this paper, we investigate the PSLQ algorithm for empirical data as its\ninput. Firstly, we give a termination condition for this case. Secondly, we\nanalyze a perturbation on the hyperplane matrix constructed from the input data\nand hence disclose a relationship between the accuracy of the input data and\nthe output quality (an upper bound on the absolute value of the inner product\nof the exact data and the computed integer relation), which naturally leads to\nan error control strategy for PSLQ. Further, we analyze the complexity bound of\nthe PSLQ algorithm for empirical data. Examples on transcendental numbers and\nalgebraic numbers show the meaningfulness of our error control strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.05037v2"
    },
    {
        "title": "Efficient q-Integer Linear Decomposition of Multivariate Polynomials",
        "authors": [
            "Mark Giesbrecht",
            "Hui Huang",
            "George Labahn",
            "Eugene Zima"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We present two new algorithms for the computation of the q-integer linear\ndecomposition of a multivariate polynomial. Such a decomposition is essential\nfor the treatment of q-hypergeometric symbolic summation via creative\ntelescoping and for describing the q-counterpart of Ore-Sato theory. Both of\nour algorithms require only basic integer and polynomial arithmetic and work\nfor any unique factorization domain containing the ring of integers. Complete\ncomplexity analyses are conducted for both our algorithms and two previous\nalgorithms in the case of multivariate integer polynomials, showing that our\nalgorithms have better theoretical performances. A Maple implementation is also\nincluded which suggests that our algorithms are also much faster in practice\nthan previous algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.00124v2"
    },
    {
        "title": "Separating Variables in Bivariate Polynomial Ideals",
        "authors": [
            "Manfred Buchacher",
            "Manuel Kauers",
            "Gleb Pogudin"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We present an algorithm which for any given ideal $I\\subseteq\\mathbb{K}\n[x,y]$ finds all elements of $I$ that have the form $f(x) - g(y)$, i.e., all\nelements in which no monomial is a multiple of $xy$.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.01541v2"
    },
    {
        "title": "Integral P-Recursive Sequences",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  In an earlier paper, the notion of integrality known from algebraic number\nfields and fields of algebraic functions has been extended to D-finite\nfunctions. The aim of the present paper is to extend the notion to the case of\nP-recursive sequences. In order to do so, we formulate a general algorithm for\nfinding all integral elements for valued vector spaces and then show that this\nalgorithm includes not only the algebraic and the D-finite cases but also\ncovers the case of P-recursive sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.02783v1"
    },
    {
        "title": "First-Order Tests for Toricity",
        "authors": [
            "Hamid Rahkooy",
            "Thomas Sturm"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Motivated by problems arising with the symbolic analysis of steady state\nideals in Chemical Reaction Network Theory, we consider the problem of testing\nwhether the points in a complex or real variety with non-zero coordinates form\na coset of a multiplicative group. That property corresponds to Shifted\nToricity, a recent generalization of toricity of the corresponding polynomial\nideal. The key idea is to take a geometric view on varieties rather than an\nalgebraic view on ideals. Recently, corresponding coset tests have been\nproposed for complex and for real varieties. The former combine numerous\ntechniques from commutative algorithmic algebra with Gr\\\"obner bases as the\ncentral algorithmic tool. The latter are based on interpreted first-order logic\nin real closed fields with real quantifier elimination techniques on the\nalgorithmic side. Here we take a new logic approach to both theories, complex\nand real, and beyond. Besides alternative algorithms, our approach provides a\nunified view on theories of fields and helps to understand the relevance and\ninterconnection of the rich existing literature in the area, which has been\nfocusing on complex numbers, while from a scientific point of view the\n(positive) real numbers are clearly the relevant domain in chemical reaction\nnetwork theory. We apply prototypical implementations of our new approach to a\nset of 129 models from the BioModels repository.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03586v1"
    },
    {
        "title": "Compatible rewriting of noncommutative polynomials for proving operator\n  identities",
        "authors": [
            "Cyrille Chenavier",
            "Clemens Hofstadler",
            "Clemens G. Raab",
            "Georg Regensburger"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  The goal of this paper is to prove operator identities using equalities\nbetween noncommutative polynomials. In general, a polynomial expression is not\nvalid in terms of operators, since it may not be compatible with domains and\ncodomains of the corresponding operators. Recently, some of the authors\nintroduced a framework based on labelled quivers to rigorously translate\npolynomial identities to operator identities. In the present paper, we extend\nand adapt the framework to the context of rewriting and polynomial reduction.\nWe give a sufficient condition on the polynomials used for rewriting to ensure\nthat standard polynomial reduction automatically respects domains and codomains\nof operators. Finally, we adapt the noncommutative Buchberger procedure to\ncompute additional compatible polynomials for rewriting. In the package\nOperatorGB, we also provide an implementation of the concepts developed.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03626v1"
    },
    {
        "title": "Sparse Polynomial Interpolation Based on Diversification",
        "authors": [
            "Qiao-Long Huang"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We consider the problem of interpolating a sparse multivariate polynomial\nover a finite field, represented with a black box. Building on the algorithm of\nBen-Or and Tiwari for interpolating polynomials over rings with characteristic\nzero, we develop a new Monte Carlo algorithm over the finite field by doing\nadditional probes. To interpolate a polynomial $f\\in F_q[x_1,\\dots,x_n]$ with a\npartial degree bound $D$ and a term bound $T$, our new algorithm costs\n$O^\\thicksim(nT\\log ^2q+nT\\sqrt{D}\\log q)$ bit operations and uses $2(n+1)T$\nprobes to the black box. If $q\\geq O(nT^2D)$, it has constant success rate to\nreturn the correct polynomial. Compared with previous algorithms over general\nfinite field, our algorithm has better complexity in the parameters $n,T,D$ and\nis the first one to achieve the complexity of fractional power about $D$, while\nkeeping linear in $n,T$. A key technique is a randomization which makes all\ncoefficients of the unknown polynomial distinguishable, producing a diverse\npolynomial. This approach, called diversification, was proposed by Giesbrecht\nand Roche in 2011. Our algorithm interpolates each variable independently using\n$O(T)$ probes, and then uses the diversification to correlate terms in\ndifferent images. At last, we get the exponents by solving the discrete\nlogarithms and obtain coefficients by solving a linear system. We have\nimplemented our algorithm in Maple. Experimental results shows that our\nalgorithm can applied to sparse polynomials with large degree. We also analyze\nthe success rate of the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03706v1"
    },
    {
        "title": "Sparse Polynomial Interpolation Based on Derivative",
        "authors": [
            "Qiao-Long Huang"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  In this paper, we propose two new interpolation algorithms for sparse\nmultivariate polynomials represented by a straight-line program(SLP). Both of\nour algorithms work over any finite fields $F_q$ with large characteristic. The\nfirst one is a Monte Carlo randomized algorithm. Its arithmetic complexity is\nlinear in the number $T$ of non-zero terms of $f$, in the number $n$ of\nvariables. If $q$ is $O((nTD)^{(1)})$, where $D$ is the partial degree bound,\nthen our algorithm has better complexity than other existing algorithms. The\nsecond one is a deterministic algorithm. It has better complexity than existing\ndeterministic algorithms over a field with large characteristic. Its arithmetic\ncomplexity is quadratic in $n,T,\\log D$, i.e., quadratic in the size of the\nsparse representation. And we also show that the complexity of our\ndeterministic algorithm is the same as the one of deterministic zero-testing of\nBl\\\"{a}ser et al. for the polynomial given by an SLP over finite field (for\nlarge characteristic).\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03708v1"
    },
    {
        "title": "Fast In-place Algorithms for Polynomial Operations: Division,\n  Evaluation, Interpolation",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We consider space-saving versions of several important operations on\nunivariate polynomials, namely power series inversion and division, division\nwith remainder, multi-point evaluation, and interpolation. Now-classical\nresults show that such problems can be solved in (nearly) the same asymptotic\ntime as fast polynomial multiplication. However, these reductions, even when\napplied to an in-place variant of fast polynomial multiplication, yield\nalgorithms which require at least a linear amount of extra space for\nintermediate results. We demonstrate new in-place algorithms for the\naforementioned polynomial computations which require only constant extra space\nand achieve the same asymptotic running time as their out-of-place\ncounterparts. We also provide a precise complexity analysis so that all\nconstants are made explicit, parameterized by the space usage of the underlying\nmultiplication algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.10304v3"
    },
    {
        "title": "A Linear Algebra Approach for Detecting Binomiality of Steady State\n  Ideals of Reversible Chemical Reaction Networks",
        "authors": [
            "Hamid Rahkooy",
            "Ovidiu Radulescu",
            "Thomas Sturm"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Motivated by problems from Chemical Reaction Network Theory, we investigate\nwhether steady state ideals of reversible reaction networks are generated by\nbinomials. We take an algebraic approach considering, besides concentrations of\nspecies, also rate constants as indeterminates. This leads us to the concept of\nunconditional binomiality, meaning binomiality for all values of the rate\nconstants. This concept is different from conditional binomiality that applies\nwhen rate constant values or relations among rate constants are given. We start\nby representing the generators of a steady state ideal as sums of binomials,\nwhich yields a corresponding coefficient matrix. On these grounds we propose an\nefficient algorithm for detecting unconditional binomiality. That algorithm\nuses exclusively elementary column and row operations on the coefficient\nmatrix. We prove asymptotic worst case upper bounds on the time complexity of\nour algorithm. Furthermore, we experimentally compare its performance with\nother existing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.12693v2"
    },
    {
        "title": "Polynomial-Time Algorithms for Quadratic Isomorphism of Polynomials: The\n  Regular Case",
        "authors": [
            "Jérémy Berthomieu",
            "Jean-Charles Faugère",
            "Ludovic Perret"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Let $\\mathbf{f}=(f\\_1,\\ldots,f\\_m)$ and $\\mathbf{g}=(g\\_1,\\ldots,g\\_m)$ be\ntwo sets of $m\\geq 1$ nonlinear polynomials over $\\mathbb{K}[x\\_1,\\ldots,x\\_n]$\n($\\mathbb{K}$ being a field). We consider the computational problem of finding\n-- if any -- an invertible transformation on the variables mapping $\\mathbf{f}$\nto $\\mathbf{g}$. The corresponding equivalence problem is known as {\\tt\nIsomorphism of Polynomials with one Secret} ({\\tt IP1S}) and is a fundamental\nproblem in multivariate cryptography. The main result is a randomized\npolynomial-time algorithm for solving {\\tt IP1S} for quadratic instances, a\nparticular case of importance in cryptography and somewhat justifying {\\it a\nposteriori} the fact that {\\it Graph Isomorphism} reduces to only cubic\ninstances of {\\tt IP1S} (Agrawal and Saxena). To this end, we show that {\\tt\nIP1S} for quadratic polynomials can be reduced to a variant of the classical\nmodule isomorphism problem in representation theory, which involves to test the\northogonal simultaneous conjugacy of symmetric matrices. We show that we can\nessentially {\\it linearize} the problem by reducing quadratic-{\\tt IP1S} to\ntest the orthogonal simultaneous similarity of symmetric matrices; this latter\nproblem was shown by Chistov, Ivanyos and Karpinski to be equivalent to finding\nan invertible matrix in the linear space $\\mathbb{K}^{n \\times n}$ of $n \\times\nn$ matrices over $\\mathbb{K}$ and to compute the square root in a matrix\nalgebra. While computing square roots of matrices can be done efficiently using\nnumerical methods, it seems difficult to control the bit complexity of such\nmethods. However, we present exact and polynomial-time algorithms for computing\nthe square root in $\\mathbb{K}^{n \\times n}$ for various fields (including\nfinite fields). We then consider \\\\#{\\tt IP1S}, the counting version of {\\tt\nIP1S} for quadratic instances. In particular, we provide a (complete)\ncharacterization of the automorphism group of homogeneous quadratic\npolynomials. Finally, we also consider the more general {\\it Isomorphism of\nPolynomials} ({\\tt IP}) problem where we allow an invertible linear\ntransformation on the variables \\emph{and} on the set of polynomials. A\nrandomized polynomial-time algorithm for solving {\\tt IP} when\n\\(\\mathbf{f}=(x\\_1^d,\\ldots,x\\_n^d)\\) is presented. From an algorithmic point\nof view, the problem boils down to factoring the determinant of a linear matrix\n(\\emph{i.e.}\\ a matrix whose components are linear polynomials). This extends\nto {\\tt IP} a result of Kayal obtained for {\\tt PolyProj}.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.4974v5"
    },
    {
        "title": "Probabilistic Algorithm for Polynomial Optimization over a Real\n  Algebraic Set",
        "authors": [
            "Aurélien Greuet",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Let $f, f_1, \\ldots, f_\\nV$ be polynomials with rational coefficients in the\nindeterminates $\\bfX=X_1, \\ldots, X_n$ of maximum degree $D$ and $V$ be the set\nof common complex solutions of $\\F=(f_1,\\ldots, f_\\nV)$. We give an algorithm\nwhich, up to some regularity assumptions on $\\F$, computes an exact\nrepresentation of the global infimum $f^\\star=\\inf_{x\\in V\\cap\\R^n} f\\Par{x}$,\ni.e. a univariate polynomial vanishing at $f^\\star$ and an isolating interval\nfor $f^\\star$. Furthermore, this algorithm decides whether $f^\\star$ is reached\nand if so, it returns $x^\\star\\in V\\cap\\R^n$ such that\n$f\\Par{x^\\star}=f^\\star$. This algorithm is probabilistic. It makes use of the\nnotion of polar varieties. Its complexity is essentially cubic in $\\Par{\\nV\nD}^n$ and linear in the complexity of evaluating the input. This fits within\nthe best known deterministic complexity class $D^{O(n)}$. We report on some\npractical experiments of a first implementation that is available as a Maple\npackage. It appears that it can tackle global optimization problems that were\nunreachable by previous exact algorithms and can manage instances that are hard\nto solve with purely numeric techniques. As far as we know, even under the\nextra genericity assumptions on the input, it is the first probabilistic\nalgorithm that combines practical efficiency with good control of complexity\nfor this problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.8281v2"
    },
    {
        "title": "Computing periods of rational integrals",
        "authors": [
            "Pierre Lairez"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  A period of a rational integral is the result of integrating, with respect to\none or several variables, a rational function over a closed path. This work\nfocuses particularly on periods depending on a parameter: in this case the\nperiod under consideration satisfies a linear differential equation, the\nPicard-Fuchs equation. I give a reduction algorithm that extends the\nGriffiths-Dwork reduction and apply it to the computation of Picard-Fuchs\nequations. The resulting algorithm is elementary and has been successfully\napplied to problems that were previously out of reach.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.5069v3"
    },
    {
        "title": "Applying machine learning to the problem of choosing a heuristic to\n  select the variable ordering for cylindrical algebraic decomposition",
        "authors": [
            "Zongyan Huang",
            "Matthew England",
            "David Wilson",
            "James H. Davenport",
            "Lawrence C. Paulson",
            "James Bridge"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Cylindrical algebraic decomposition(CAD) is a key tool in computational\nalgebraic geometry, particularly for quantifier elimination over real-closed\nfields. When using CAD, there is often a choice for the ordering placed on the\nvariables. This can be important, with some problems infeasible with one\nvariable ordering but easy with another. Machine learning is the process of\nfitting a computer model to a complex function based on properties learned from\nmeasured data. In this paper we use machine learning (specifically a support\nvector machine) to select between heuristics for choosing a variable ordering,\noutperforming each of the separate heuristics.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6369v1"
    },
    {
        "title": "Parallel sparse interpolation using small primes",
        "authors": [
            "Mohamed Khochtali",
            "Daniel S. Roche",
            "Xisen Tian"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  To interpolate a supersparse polynomial with integer coefficients, two\nalternative approaches are the Prony-based \"big prime\" technique, which acts\nover a single large finite field, or the more recently-proposed \"small primes\"\ntechnique, which reduces the unknown sparse polynomial to many low-degree dense\npolynomials. While the latter technique has not yet reached the same\ntheoretical efficiency as Prony-based methods, it has an obvious potential for\nparallelization. We present a heuristic \"small primes\" interpolation algorithm\nand report on a low-level C implementation using FLINT and MPI.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.04215v1"
    },
    {
        "title": "Real root finding for low rank linear matrices",
        "authors": [
            "Didier Henrion",
            "Simone Naldi",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We consider $m \\times s$ matrices (with $m\\geq s$) in a real affine subspace\nof dimension $n$. The problem of finding elements of low rank in such spaces\nfinds many applications in information and systems theory, where low rank is\nsynonymous of structure and parsimony. We design computer algebra algorithms,\nbased on advanced methods for polynomial system solving, to solve this problem\nefficiently and exactly: the input are the rational coefficients of the\nmatrices spanning the affine subspace as well as the expected maximum rank, and\nthe output is a rational parametrization encoding a finite set of points that\nintersects each connected component of the low rank real algebraic set. The\ncomplexity of our algorithm is studied thoroughly. It is polynomial in\n$\\binom{n+m(s-r)}{n}$. It improves on the state-of-the-art in computer algebra\nand effective real algebraic geometry. Moreover, computer experiments show the\npractical efficiency of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.05897v3"
    },
    {
        "title": "A proof of Hilbert's theorem on ternary quartic forms with the ladder\n  technique",
        "authors": [
            "Jia Xu",
            "Yong Yao"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  This paper proposes a totally constructive approach for the proof of\nHilbert's theorem on ternary quartic forms. The main contribution is the ladder\ntechnique, with which the Hilbert's theorem is proved vividly.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.08294v2"
    },
    {
        "title": "Fast multiplication for skew polynomials",
        "authors": [
            "Xavier Caruso",
            "Jérémy Le Borgne"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We describe an algorithm for fast multiplication of skew polynomials. It is\nbased on fast modular multiplication of such skew polynomials, for which we\ngive an algorithm relying on evaluation and interpolation on normal bases. Our\nalgorithms improve the best known complexity for these problems, and reach the\noptimal asymptotic complexity bound for large degree. We also give an\nadaptation of our algorithm for polynomials of small degree. Finally, we use\nour methods to improve on the best known complexities for various arithmetics\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.01665v1"
    },
    {
        "title": "Faster Tensor Canonicalization",
        "authors": [
            "Benjamin E. Niehoff"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  The Butler-Portugal algorithm for obtaining the canonical form of a tensor\nexpression with respect to slot symmetries and dummy-index renaming suffers, in\ncertain cases with a high degree of symmetry, from $O(n!)$ explosion in both\ncomputation time and memory. We present a modified algorithm which alleviates\nthis problem in the most common cases---tensor expressions with subsets of\nindices which are totally symmetric or totally antisymmetric---in polynomial\ntime. We also present an implementation of the label-renaming mechanism which\nimproves upon that of the original Butler-Portugal algorithm, thus providing a\nsignificant speed increase for the average case as well as the highly-symmetric\nspecial case. The worst-case behavior remains $O(n!)$, although it occurs in\nmore limited situations unlikely to appear in actual computations. We comment\non possible strategies to take if the nature of a computation should make these\nsituations more likely.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.08114v3"
    },
    {
        "title": "Algorithmically generating new algebraic features of polynomial systems\n  for machine learning",
        "authors": [
            "Dorian Florescu",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  There are a variety of choices to be made in both computer algebra systems\n(CASs) and satisfiability modulo theory (SMT) solvers which can impact\nperformance without affecting mathematical correctness. Such choices are\ncandidates for machine learning (ML) approaches, however, there are\ndifficulties in applying standard ML techniques, such as the efficient\nidentification of ML features from input data which is typically a polynomial\nsystem. Our focus is selecting the variable ordering for cylindrical algebraic\ndecomposition (CAD), an important algorithm implemented in several CASs, and\nnow also SMT-solvers. We created a framework to describe all the previously\nidentified ML features for the problem and then enumerated all options in this\nframework to automatically generation many more features. We validate the\nusefulness of these with an experiment which shows that an ML choice for CAD\nvariable ordering is superior to those made by human created heuristics, and\nfurther improved with these additional features. We expect that this technique\nof feature generation could be useful for other choices related to CAD, or even\nchoices for other algorithms with polynomial systems for input.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.01455v1"
    },
    {
        "title": "On FGLM Algorithms with Tropical Gröbner bases",
        "authors": [
            "Yuki Ishihara",
            "Tristan Vaccon",
            "Kazuhiro Yokoyama"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Let K be a field equipped with a valuation. Tropical varieties over K can be\ndefined with a theory of Gr{\\\"o}bner bases taking into account the valuation of\nK. Because of the use of the valuation, the theory of tropical Gr{\\\"o}bner\nbases has proved to provide settings for computations over polynomial rings\nover a p-adic field that are more stable than that of classical Gr{\\\"o}bner\nbases. In this article, we investigate how the FGLM change of ordering\nalgorithm can be adapted to the tropical setting. As the valuations of the\npolynomial coefficients are taken into account, the classical FGLM algorithm's\nincremental way, monomo-mial by monomial, to compute the multiplication\nmatrices and the change of basis matrix can not be transposed at all to the\ntropical setting. We mitigate this issue by developing new linear algebra\nalgorithms and apply them to our new tropical FGLM algorithms. Motivations are\ntwofold. Firstly, to compute tropical varieties, one usually goes through the\ncomputation of many tropical Gr{\\\"o}bner bases defined for varying weights (and\nthen varying term orders). For an ideal of dimension 0, the tropical FGLM\nalgorithm provides an efficient way to go from a tropical Gr{\\\"o}bner basis\nfrom one weight to one for another weight. Secondly, the FGLM strategy can be\napplied to go from a tropical Gr{\\\"o}bner basis to a classical Gr{\\\"o}bner\nbasis. We provide tools to chain the stable computation of a tropical\nGr{\\\"o}bner basis (for weight [0,. .. , 0]) with the p-adic stabilized variants\nof FGLM of [RV16] to compute a lexicographical or shape position basis. All our\nalgorithms have been implemented into SageMath. We provide numerical examples\nto illustrate time-complexity. We then illustrate the superiority of our\nstrategy regarding to the stability of p-adic numerical computations.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.02067v1"
    },
    {
        "title": "Automatic Differentiation: a look through Tensor and Operational\n  Calculus",
        "authors": [
            "Žiga Sajovic"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In this paper we take a look at Automatic Differentiation through the eyes of\nTensor and Operational Calculus. This work is best consumed as supplementary\nmaterial for learning tensor and operational calculus by those already familiar\nwith automatic differentiation. To that purpose, we provide a simple\nimplementation of automatic differentiation, where the steps taken are\nexplained in the language tensor and operational calculus.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.02731v3"
    },
    {
        "title": "A fast algorithm for solving linearly recurrent sequences",
        "authors": [
            "Seung Gyu Hyun",
            "Stephen Melczer",
            "Catherine St-Pierre"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We present an algorithm which computes the $D^{th}$ term of a sequence\nsatisfying a linear recurrence relation of order $d$ over a field $K$ in $O(\n\\mathsf{M}(\\bar d)\\log(D) + \\mathsf{M}(d)\\log(d))$ operations in $K$, where\n$\\bar d \\leq d$ is the degree of the squarefree part of the annihilating\npolynomial of the recurrence and $\\mathsf{M}$ is the cost of polynomial\nmultiplication in $K$. This is a refinement of the previously optimal result of\n$O( \\mathsf{M}(d)\\log(D) )$ operations, due to Fiduccia.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.03554v1"
    },
    {
        "title": "Real root finding for equivariant semi-algebraic systems",
        "authors": [
            "Cordian Riener",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Let $R$ be a real closed field. We consider basic semi-algebraic sets defined\nby $n$-variate equations/inequalities of $s$ symmetric polynomials and an\nequivariant family of polynomials, all of them of degree bounded by $2d < n$.\nSuch a semi-algebraic set is invariant by the action of the symmetric group. We\nshow that such a set is either empty or it contains a point with at most $2d-1$\ndistinct coordinates. Combining this geometric result with efficient algorithms\nfor real root finding (based on the critical point method), one can decide the\nemptiness of basic semi-algebraic sets defined by $s$ polynomials of degree $d$\nin time $(sn)^{O(d)}$. This improves the state-of-the-art which is exponential\nin $n$. When the variables $x_1, \\ldots, x_n$ are quantified and the\ncoefficients of the input system depend on parameters $y_1, \\ldots, y_t$, one\nalso demonstrates that the corresponding one-block quantifier elimination\nproblem can be solved in time $(sn)^{O(dt)}$.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.08121v1"
    },
    {
        "title": "TheoryGuru: A Mathematica Package to apply Quantifier Elimination",
        "authors": [
            "C. Mulligan",
            "J. H. Davenport",
            "M. England"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We consider the use of Quantifier Elimination (QE) technology for automated\nreasoning in economics. There is a great body of work considering QE\napplications in science and engineering but we demonstrate here that it also\nhas use in the social sciences. We explain how many suggested theorems in\neconomics could either be proven, or even have their hypotheses shown to be\ninconsistent, automatically via QE.\n  However, economists who this technology could benefit are usually unfamiliar\nwith QE, and the use of mathematical software generally. This motivated the\ndevelopment of a Mathematica Package TheoryGuru, whose purpose is to lower the\ncosts of applying QE to economics. We describe the package's functionality and\ngive examples of its use.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.10925v1"
    },
    {
        "title": "Proof-of-work certificates that can be efficiently computed in the cloud",
        "authors": [
            "Jean-Guillaume Dumas"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In an emerging computing paradigm, computational capabilities, from\nprocessing power to storage capacities, are offered to users over communication\nnetworks as a cloud-based service. There, demanding computations are outsourced\nin order to limit infrastructure costs. The idea of verifiable computing is to\nassociate a data structure, a proof-of-work certificate, to the result of the\noutsourced computation. This allows a verification algorithm to prove the\nvalidity of the result, faster than by recomputing it. We talk about a Prover\n(the server performing the computations) and a Verifier. Goldwasser, Kalai and\nRothblum gave in 2008 a generic method to verify any parallelizable\ncomputation, in almost linear time in the size of the, potentially structured,\ninputs and the result. However, the extra cost of the computations for the\nProver (and therefore the extra cost to the customer), although only almost a\nconstant factor of the overall work, is nonetheless prohibitive in practice.\nDifferently, we will here present problem-specific procedures in computer\nalgebra, e.g. for exact linear algebra computations, that are Prover-optimal,\nthat is that have much less financial overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.11293v2"
    },
    {
        "title": "Generic reductions for in-place polynomial multiplication",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Daniel Roche"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The polynomial multiplication problem has attracted considerable attention\nsince the early days of computer algebra, and several algorithms have been\ndesigned to achieve the best possible time complexity. More recently, efforts\nhave been made to improve the space complexity, developing modified versions of\na few specific algorithms to use no extra space while keeping the same\nasymptotic running time. In this work, we broaden the scope in two regards.\nFirst, we ask whether an arbitrary multiplication algorithm can be performed\nin-place generically. Second, we consider two important variants which produce\nonly part of the result (and hence have less space to work with), the so-called\nmiddle and short products, and ask whether these operations can also be\nperformed in-place. To answer both questions in (mostly) the affirmative, we\nprovide a series of reductions starting with any linear-space multiplication\nalgorithm. For full and short product algorithms these reductions yield\nin-place versions with the same asymptotic time complexity as the out-of-place\nversion. For the middle product, the reduction incurs an extra logarithmic\nfactor in the time complexity only when the algorithm is quasi-linear.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.02967v1"
    },
    {
        "title": "The complexity of MinRank",
        "authors": [
            "Alessio Caminata",
            "Elisa Gorla"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In this note, we leverage some of our results from arXiv:1706.06319 to\nproduce a concise and rigorous proof for the complexity of the generalized\nMinRank Problem in the under-defined and well-defined case. Our main theorem\nrecovers and extends previous results by Faug\\`ere, Safey El Din, Spaenlehauer\n(arXiv:1112.4411).\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02682v3"
    },
    {
        "title": "Effective Coefficient Asymptotics of Multivariate Rational Functions via\n  Semi-Numerical Algorithms for Polynomial Systems",
        "authors": [
            "Stephen Melczer",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The coefficient sequences of multivariate rational functions appear in many\nareas of combinatorics. Their diagonal coefficient sequences enjoy nice\narithmetic and asymptotic properties, and the field of analytic combinatorics\nin several variables (ACSV) makes it possible to compute asymptotic expansions.\nWe consider these methods from the point of view of effectivity. In particular,\ngiven a rational function, ACSV requires one to determine a (generically)\nfinite collection of points that are called critical and minimal. Criticality\nis an algebraic condition, meaning it is well treated by classical methods in\ncomputer algebra, while minimality is a semi-algebraic condition describing\npoints on the boundary of the domain of convergence of a multivariate power\nseries. We show how to obtain dominant asymptotics for the diagonal coefficient\nsequence of multivariate rational functions under some genericity assumptions\nusing symbolic-numeric techniques. To our knowledge, this is the first\ncompletely automatic treatment and complexity analysis for the asymptotic\nenumeration of rational functions in an arbitrary number of variables.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04187v2"
    },
    {
        "title": "Reconstruction of rational ruled surfaces from their silhouettes",
        "authors": [
            "Matteo Gallet",
            "Niels Lubbes",
            "Josef Schicho",
            "Jan Vršek"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We provide algorithms to reconstruct rational ruled surfaces in\nthree-dimensional projective space from the `apparent contour' of a single\nprojection to the projective plane. We deal with the case of tangent\ndevelopables and of general projections to $\\mathbb{p}^3$ of rational normal\nscrolls. In the first case, we use the fact that every such surface is the\nprojection of the tangent developable of a rational normal curve, while in the\nsecond we start by reconstructing the rational normal scroll. In both instances\nwe then reconstruct the correct projection to $\\mathbb{p}^3$ of these surfaces\nby exploiting the information contained in the singularities of the apparent\ncontour.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11853v2"
    },
    {
        "title": "Deep Learning for Symbolic Mathematics",
        "authors": [
            "Guillaume Lample",
            "François Charton"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Neural networks have a reputation for being better at solving statistical or\napproximate problems than at performing calculations or working with symbolic\ndata. In this paper, we show that they can be surprisingly good at more\nelaborated tasks in mathematics, such as symbolic integration and solving\ndifferential equations. We propose a syntax for representing mathematical\nproblems, and methods for generating large datasets that can be used to train\nsequence-to-sequence models. We achieve results that outperform commercial\nComputer Algebra Systems such as Matlab or Mathematica.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01412v1"
    },
    {
        "title": "Visualizing Planar and Space Implicit Real Algebraic Curves with\n  Singularities",
        "authors": [
            "Changbo Chen",
            "Wenyuan Wu",
            "Yong Feng"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We present a new method for visualizing implicit real algebraic curves inside\na bounding box in the $2$-D or $3$-D ambient space based on numerical\ncontinuation and critical point methods. The underlying techniques work also\nfor tracing space curve in higher-dimensional space. Since the topology of a\ncurve near a singular point of it is not numerically stable, we trace only the\ncurve outside neighborhoods of singular points and replace each neighborhood\nsimply by a point, which produces a polygonal approximation that is\n$\\epsilon$-close to the curve. Such an approximation is more stable for\ndefining the numerical connectedness of the complement of the projection of the\ncurve in $\\mathbb{R}^2$, which is important for applications such as solving\nbi-parametric polynomial systems. The algorithm starts by computing three types\nof key points of the curve, namely the intersection of the curve with small\nspheres centered at singular points, regular critical points of every connected\ncomponents of the curve, as well as intersection points of the curve with the\ngiven bounding box. It then traces the curve starting with and in the order of\nthe above three types of points. This basic scheme is further enhanced by\nseveral optimizations, such as grouping singular points in natural clusters,\ntracing the curve by a try-and-resume strategy and handling \"pseudo singular\npoints\". The effectiveness of the algorithm is illustrated by numerous\nexamples. This manuscript extends our preliminary results that appeared in CASC\n2018.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.07507v1"
    },
    {
        "title": "Characterizing Triviality of the Exponent Lattice of A Polynomial\n  through Galois and Galois-Like Groups",
        "authors": [
            "Tao Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  The problem of computing \\emph{the exponent lattice} which consists of all\nthe multiplicative relations between the roots of a univariate polynomial has\ndrawn much attention in the field of computer algebra. As is known, almost all\nirreducible polynomials with integer coefficients have only trivial exponent\nlattices. However, the algorithms in the literature have difficulty in proving\nsuch triviality for a generic polynomial. In this paper, the relations between\nthe Galois group (respectively, \\emph{the Galois-like groups}) and the\ntriviality of the exponent lattice of a polynomial are investigated. The\n$\\bbbq$\\emph{-trivial} pairs, which are at the heart of the relations between\nthe Galois group and the triviality of the exponent lattice of a polynomial,\nare characterized. An effective algorithm is developed to recognize these\npairs. Based on this, a new algorithm is designed to prove the triviality of\nthe exponent lattice of a generic irreducible polynomial, which considerably\nimproves a state-of-the-art algorithm of the same type when the polynomial\ndegree becomes larger. In addition, the concept of the Galois-like groups of a\npolynomial is introduced. Some properties of the Galois-like groups are proved\nand, more importantly, a sufficient and necessary condition is given for a\npolynomial (which is not necessarily irreducible) to have trivial exponent\nlattice.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01963v1"
    },
    {
        "title": "Algorithmic Averaging for Studying Periodic Orbits of Planar\n  Differential Systems",
        "authors": [
            "Bo Huang"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  One of the main open problems in the qualitative theory of real planar\ndifferential systems is the study of limit cycles. In this article, we present\nan algorithmic approach for detecting how many limit cycles can bifurcate from\nthe periodic orbits of a given polynomial differential center when it is\nperturbed inside a class of polynomial differential systems via the averaging\nmethod. We propose four symbolic algorithms to implement the averaging method.\nThe first algorithm is based on the change of polar coordinates that allows one\nto transform a considered differential system to the normal form of averaging.\nThe second algorithm is used to derive the solutions of certain differential\nsystems associated to the unperturbed term of the normal of averaging. The\nthird algorithm exploits the partial Bell polynomials and allows one to compute\nthe integral formula of the averaged functions at any order. The last algorithm\nis based on the aforementioned algorithms and determines the exact expressions\nof the averaged functions for the considered differential systems. The\nimplementation of our algorithms is discussed and evaluated using several\nexamples. The experimental results have extended the existing relevant results\nfor certain classes of differential systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.03487v2"
    },
    {
        "title": "Subquadratic-Time Algorithms for Normal Bases",
        "authors": [
            "Mark Giesbrecht",
            "Armin Jamshidpey",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  For any finite Galois field extension $\\mathsf{K}/\\mathsf{F}$, with Galois\ngroup $G = \\mathrm{Gal}(\\mathsf{K}/\\mathsf{F})$, there exists an element\n$\\alpha \\in \\mathsf{K}$ whose orbit $G\\cdot\\alpha$ forms an $\\mathsf{F}$-basis\nof $\\mathsf{K}$. Such a $\\alpha$ is called a normal element and $G\\cdot\\alpha$\nis a normal basis. We introduce a probabilistic algorithm for testing whether a\ngiven $\\alpha \\in \\mathsf{K}$ is normal, when $G$ is either a finite abelian or\na metacyclic group. The algorithm is based on the fact that deciding whether\n$\\alpha$ is normal can be reduced to deciding whether $\\sum_{g \\in G}\ng(\\alpha)g \\in \\mathsf{K}[G]$ is invertible; it requires a slightly\nsubquadratic number of operations. Once we know that $\\alpha$ is normal, we\nshow how to perform conversions between the power basis of\n$\\mathsf{K}/\\mathsf{F}$ and the normal basis with the same asymptotic cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.03497v2"
    },
    {
        "title": "An Algebraic Model For Quorum Systems",
        "authors": [
            "Alex Pellegrini",
            "Luca Zanolini"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Quorum systems are a key mathematical abstraction in distributed\nfault-tolerant computing for capturing trust assumptions. A quorum system is a\ncollection of subsets of all processes, called quorums, with the property that\neach pair of quorums have a non-empty intersection. They can be found at the\ncore of many reliable distributed systems, such as cloud computing platforms,\ndistributed storage systems and blockchains. In this paper we give a new\ninterpretation of quorum systems, starting with classical majority-based quorum\nsystems and extending this to Byzantine quorum systems. We propose an algebraic\nrepresentation of the theory underlying quorum systems making use of\nmultivariate polynomial ideals, incorporating properties of these systems, and\nstudying their algebraic varieties. To achieve this goal we will exploit\nproperties of Boolean Groebner bases. The nice nature of Boolean Groebner bases\nallows us to avoid part of the combinatorial computations required to check\nconsistency and availability of quorum systems. Our results provide a novel\napproach to test quorum systems properties from both algebraic and algorithmic\nperspectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.08536v2"
    },
    {
        "title": "A machine learning based software pipeline to pick the variable ordering\n  for algorithms with polynomial inputs",
        "authors": [
            "Dorian Florescu",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We are interested in the application of Machine Learning (ML) technology to\nimprove mathematical software. It may seem that the probabilistic nature of ML\ntools would invalidate the exact results prized by such software, however, the\nalgorithms which underpin the software often come with a range of choices which\nare good candidates for ML application. We refer to choices which have no\neffect on the mathematical correctness of the software, but do impact its\nperformance.\n  In the past we experimented with one such choice: the variable ordering to\nuse when building a Cylindrical Algebraic Decomposition (CAD). We used the\nPython library Scikit-Learn (sklearn) to experiment with different ML models,\nand developed new techniques for feature generation and hyper-parameter\nselection.\n  These techniques could easily be adapted for making decisions other than our\nimmediate application of CAD variable ordering. Hence in this paper we present\na software pipeline to use sklearn to pick the variable ordering for an\nalgorithm that acts on a polynomial system. The code described is freely\navailable online.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.11251v1"
    },
    {
        "title": "A Majorization Order on Monomials and Termination of a Successive\n  Difference Substitution Algorithm",
        "authors": [
            "Jia Xu",
            "Yong Yao"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  We introduce a majorization order on monomials. With the help of this order,\nwe derive a necessary condition on the positive termination of a general\nsuccessive difference substitution algorithm (KSDS) for an input form $f$.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0686v2"
    },
    {
        "title": "Solving large linear algebraic systems in the context of integrable\n  non-abelian Laurent ODEs",
        "authors": [
            "Thomas Wolf",
            "Eberhard Schruefer",
            "Kenneth Webster"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  The paper reports on a computer algebra program LSSS (Linear Selective\nSystems Solver) for solving linear algebraic systems with rational\ncoefficients. The program is especially efficient for very large sparse systems\nthat have a solution in which many variables take the value zero. The program\nis applied to the symmetry investigation of a non-abelian Laurent ODE\nintroduced recently by M. Kontsevich. The computed symmetries confirmed that a\nLax pair found for this system earlier generates all first integrals of degree\nat least up to 14.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.2785v1"
    },
    {
        "title": "logcf: An Efficient Tool for Real Root Isolation",
        "authors": [
            "Liyun Dai",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  This paper revisits an algorithm for isolating real roots of univariate\npolynomials based on continued fractions. It follows the work of Vincent,\nUspen- sky, Collins and Akritas, Johnson and Krandick. We use some tricks,\nespecially a new algorithm for computing an upper bound of positive roots. In\nthis way, the algorithm of isolating real roots is improved. The complexity of\nour method for computing an upper bound of positive roots is O(n log(u+1))\nwhere u is the optimal upper bound satisfying Theorem 3 and n is the degree of\nthe polynomial. Our method has been implemented as a software package logcf\nusing C++ language. For many benchmarks logcf is two or three times faster than\nthe function RootIntervals of Mathematica. And it is much faster than another\ncontinued fractions based software CF, which seems to be one of the fastest\navailable open software for exact real root isolation. For those benchmarks\nwhich have only real roots, logcf is much faster than Sleeve and eigensolve\nwhich are based on numerical computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.3555v1"
    },
    {
        "title": "Fast Hermite interpolation and evaluation over finite fields of\n  characteristic two",
        "authors": [
            "Nicholas Coxon"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  This paper presents new fast algorithms for Hermite interpolation and\nevaluation over finite fields of characteristic two. The algorithms reduce the\nHermite problems to instances of the standard multipoint interpolation and\nevaluation problems, which are then solved by existing fast algorithms. The\nreductions are simple to implement and free of multiplications, allowing low\noverall multiplicative complexities to be obtained. The algorithms are suitable\nfor use in encoding and decoding algorithms for multiplicity codes.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.00645v1"
    },
    {
        "title": "Fast transforms over finite fields of characteristic two",
        "authors": [
            "Nicholas Coxon"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  An additive fast Fourier transform over a finite field of characteristic two\nefficiently evaluates polynomials at every element of an $\\mathbb{F}_2$-linear\nsubspace of the field. We view these transforms as performing a change of basis\nfrom the monomial basis to the associated Lagrange basis, and consider the\nproblem of performing the various conversions between these two bases, the\nassociated Newton basis, and the '' novel '' basis of Lin, Chung and Han (FOCS\n2014). Existing algorithms are divided between two families, those designed for\narbitrary subspaces and more efficient algorithms designed for specially\nconstructed subspaces of fields with degree equal to a power of two. We\ngeneralise techniques from both families to provide new conversion algorithms\nthat may be applied to arbitrary subspaces, but which benefit equally from the\nspecially constructed subspaces. We then construct subspaces of fields with\nsmooth degree for which our algorithms provide better performance than existing\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.07785v1"
    },
    {
        "title": "Reconstructing Rational Functions with $\\texttt{FireFly}$",
        "authors": [
            "Jonas Klappert",
            "Fabian Lange"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We present the open-source $\\texttt{C++}$ library $\\texttt{FireFly}$ for the\nreconstruction of multivariate rational functions over finite fields. We\ndiscuss the involved algorithms and their implementation. As an application, we\nuse $\\texttt{FireFly}$ in the context of integration-by-parts reductions and\ncompare runtime and memory consumption to a fully algebraic approach with the\nprogram $\\texttt{Kira}$.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.00009v2"
    },
    {
        "title": "On the Equivalence of Automatic and Symbolic Differentiation",
        "authors": [
            "Soeren Laue"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We show that reverse mode automatic differentiation and symbolic\ndifferentiation are equivalent in the sense that they both perform the same\noperations when computing derivatives. This is in stark contrast to the common\nclaim that they are substantially different. The difference is often\nillustrated by claiming that symbolic differentiation suffers from \"expression\nswell\" whereas automatic differentiation does not. Here, we show that this\nstatement is not true. \"Expression swell\" refers to the phenomenon of a much\nlarger representation of the derivative as opposed to the representation of the\noriginal function.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.02990v4"
    },
    {
        "title": "Comparing machine learning models to choose the variable ordering for\n  cylindrical algebraic decomposition",
        "authors": [
            "Matthew England",
            "Dorian Florescu"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  There has been recent interest in the use of machine learning (ML) approaches\nwithin mathematical software to make choices that impact on the computing\nperformance without affecting the mathematical correctness of the result. We\naddress the problem of selecting the variable ordering for cylindrical\nalgebraic decomposition (CAD), an important algorithm in Symbolic Computation.\nPrior work to apply ML on this problem implemented a Support Vector Machine\n(SVM) to select between three existing human-made heuristics, which did better\nthan anyone heuristic alone. The present work extends to have ML select the\nvariable ordering directly, and to try a wider variety of ML techniques.\n  We experimented with the NLSAT dataset and the Regular Chains Library CAD\nfunction for Maple 2018. For each problem, the variable ordering leading to the\nshortest computing time was selected as the target class for ML. Features were\ngenerated from the polynomial input and used to train the following ML models:\nk-nearest neighbours (KNN) classifier, multi-layer perceptron (MLP), decision\ntree (DT) and SVM, as implemented in the Python scikit-learn package. We also\ncompared these with the two leading human constructed heuristics for the\nproblem: Brown's heuristic and sotd. On this dataset all of the ML approaches\noutperformed the human made heuristics, some by a large margin.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11061v2"
    },
    {
        "title": "Improved cross-validation for classifiers that make algorithmic choices\n  to minimise runtime without compromising output correctness",
        "authors": [
            "Dorian Florescu",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Our topic is the use of machine learning to improve software by making\nchoices which do not compromise the correctness of the output, but do affect\nthe time taken to produce such output. We are particularly concerned with\ncomputer algebra systems (CASs), and in particular, our experiments are for\nselecting the variable ordering to use when performing a cylindrical algebraic\ndecomposition of $n$-dimensional real space with respect to the signs of a set\nof polynomials.\n  In our prior work we explored the different ML models that could be used, and\nhow to identify suitable features of the input polynomials. In the present\npaper we both repeat our prior experiments on problems which have more\nvariables (and thus exponentially more possible orderings), and examine the\nmetric which our ML classifiers targets. The natural metric is computational\nruntime, with classifiers trained to pick the ordering which minimises this.\nHowever, this leads to the situation were models do not distinguish between any\nof the non-optimal orderings, whose runtimes may still vary dramatically. In\nthis paper we investigate a modification to the cross-validation algorithms of\nthe classifiers so that they do distinguish these cases, leading to improved\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12672v1"
    },
    {
        "title": "Good pivots for small sparse matrices",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  For sparse matrices up to size $8 \\times 8$, we determine optimal choices for\npivot selection in Gaussian elimination. It turns out that they are slightly\nbetter than the pivots chosen by a popular pivot selection strategy, so there\nis some room for improvement. We then create a pivot selection strategy using\nmachine learning and find that it indeed leads to a small improvement compared\nto the classical strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.01623v2"
    },
    {
        "title": "A variant of van Hoeij's algorithm to compute hypergeometric term\n  solutions of holonomic recurrence equations",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Linear homogeneous recurrence equations with polynomial coefficients are said\nto be holonomic. Such equations have been introduced in the last century for\nproving and discovering combinatorial and hypergeometric identities. Given a\nfield K of characteristic zero, a term a(n) is called hypergeometric with\nrespect to K, if the ratio a(n+1)/a(n) is a rational function over K. The\nsolutions space of holonomic recurrence equations gained more interest in the\n1990s from the well known Zeilberger's algorithm. In particular, algorithms\ncomputing the subspace of hypergeometric term solutions which covers\npolynomial, rational, and some algebraic solutions of these equations were\ninvestigated by Marko Petkov\\v{s}ek (1993) and Mark van Hoeij (1999). The\nalgorithm proposed by the latter is characterized by a much better efficiency\nthan that of the other; it computes, in Gamma representations, a basis of the\nsubspace of hypergeometric term solutions of any given holonomic recurrence\nequation, and is considered as the current state of the art in this area. Mark\nvan Hoeij implemented his algorithm in the Computer Algebra System (CAS) Maple\nthrough the command $LREtools[hypergeomsols]$.\n  We propose a variant of van Hoeij's algorithm that performs the same\nefficiency and gives outputs in terms of factorials and shifted factorials,\nwithout considering certain recommendations of the original version. We have\nimplementations of our algorithm for the CASs Maxima and Maple. Such an\nimplementation is new for Maxima which is therefore used for general-purpose\nexamples. Our Maxima code is currently available as a third-party package for\nMaxima. A comparison between van Hoeij's implementation and ours is presented\nfor Maple 2020. It appears that both have the same efficiency, and moreover,\nfor some particular cases, our code finds results where\n$LREtools[hypergeomsols]$ fails.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.11513v1"
    },
    {
        "title": "On Two Signature Variants Of Buchberger's Algorithm Over Principal Ideal\n  Domains",
        "authors": [
            "Maria Francis",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Signature-based algorithms have brought large improvements in the\nperformances of Gr\\\"obner bases algorithms for polynomial systems over fields.\nFurthermore, they yield additional data which can be used, for example, to\ncompute the module of syzygies of an ideal or to compute coefficients in terms\nof the input generators.\n  In this paper, we examine two variants of Buchberger's algorithm to compute\nGr\\\"obner bases over principal ideal domains, with the addition of signatures.\nThe first one is adapted from Kandri-Rody and Kapur's algorithm, whereas the\nsecond one uses the ideas developed in the algorithms by L. Pan (1989) and D.\nLichtblau (2012). The differences in constructions between the algorithms\nentail differences in the operations which are compatible with the signatures,\nand in the criteria which can be used to discard elements.\n  We prove that both algorithms are correct and discuss their relative\nperformances in a prototype implementation in Magma.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03339v2"
    },
    {
        "title": "Separability Problems in Creative Telescoping",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Pingchuan Ma",
            "Michael F. Singer"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  For given multivariate functions specified by algebraic, differential or\ndifference equations, the separability problem is to decide whether they\nsatisfy linear differential or difference equations in one variable. In this\npaper, we will explain how separability problems arise naturally in creative\ntelescoping and present some criteria for testing the separability for several\nclasses of special functions, including rational functions, hyperexponential\nfunctions, hypergeometric terms, and algebraic functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03693v1"
    },
    {
        "title": "An algorithm to recognize regular singular Mahler systems",
        "authors": [
            "Colin Faverjon",
            "Marina Poulet"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  This paper is devoted to the study of the analytic properties of Mahler\nsystems at 0. We give an effective characterisation of Mahler systems that are\nregular singular at 0, that is, systems which are equivalent to constant ones.\nSimilar characterisations already exist for differential and (q-)difference\nsystems but they do not apply in the Mahler case. This work fills in the gap by\ngiving an algorithm which decides whether or not a Mahler system is regular\nsingular at 0. In particular, it gives an effective characterisation of Mahler\nsystems to which an analog of Schlesinger's density theorem applies.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.10842v2"
    },
    {
        "title": "Faster One Block Quantifier Elimination for Regular Polynomial Systems\n  of Equations",
        "authors": [
            "Huu Phuoc Le",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Quantifier elimination over the reals is a central problem in computational\nreal algebraic geometry, polynomial system solving and symbolic computation.\nGiven a semi-algebraic formula (whose atoms are polynomial constraints) with\nquantifiers on some variables, it consists in computing a logically equivalent\nformula involving only unquantified variables. When there is no alternation of\nquantifiers, one has a one block quantifier elimination problem.\n  This paper studies a variant of the one block quantifier elimination in which\nwe compute an almost equivalent formula of the input. We design a new\nprobabilistic efficient algorithm for solving this variant when the input is a\nsystem of polynomial equations satisfying some regularity assumptions. When the\ninput is generic, involves $s$ polynomials of degree bounded by $D$ with $n$\nquantified variables and $t$ unquantified ones, we prove that this algorithm\noutputs semi-algebraic formulas of degree bounded by $\\mathcal{D}$ using $O\\\n{\\widetilde{~}}\\left ((n-s+1)\\ 8^{t}\\ \\mathcal{D}^{3t+2}\n\\binom{t+\\mathcal{D}}{t} \\right )$ arithmetic operations in the ground field\nwhere $\\mathcal{D} = 2(n+s)\\ D^s(D-1)^{n-s+1}\\ \\binom{n}{s}$. In practice, it\nallows us to solve quantifier elimination problems which are out of reach of\nthe state-of-the-art (up to $8$ variables).\n",
        "pdf_link": "http://arxiv.org/pdf/2103.13735v3"
    },
    {
        "title": "Parametric \"Non-nested\" Discriminants for Multiplicities of Univariate\n  Polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We consider the problem of complex root classification, i.e., finding the\nconditions on the coefficients of a univariate polynomial for all possible\nmultiplicity structures on its complex roots. It is well known that such\nconditions can be written as conjunctions of several polynomial equations and\none inequation in the coefficients. Those polynomials in the coefficients are\ncalled discriminants for multiplicities. It is well known that discriminants\ncan be obtained by using repeated parametric gcd's. The resulting discriminants\nare usually nested determinants, that is, determinants of matrices whose\nentries are determinants, and so son. In this paper, we give a new type of\ndiscriminants which are not based on repeated gcd's. The new discriminants are\nsimpler in that they are non-nested determinants and have smaller maximum\ndegrees.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00315v3"
    },
    {
        "title": "Computing square roots in quaternion algebras",
        "authors": [
            "Przemysław Koprowski"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We present an explicit algorithmic method for computing square roots in\nquaternion algebras over global fields of characteristic different from 2.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00743v4"
    },
    {
        "title": "An algorithm to compute the differential equations for the logarithm of\n  a polynomial",
        "authors": [
            "Toshinori Oaku"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We present an algorithm to compute the annihilator of (i.e., the linear\ndifferential equations for) the logarithm of a polynomial in the ring of\ndifferential operators with polynomial coefficients. The algorithm consists of\ndifferentiation with respect to the parameter s of the annihilator of f^s for a\npolynomial f and quotient computation. More generally, the annihilator of\nf^s(log f)^m for a complex number s and a positive integer m can be computed,\nwhich constitutes what is called a holonomic system in D-module theory. This\nenables us to compute a holonomic system for the integral of a function\ninvolving the logarithm of a polynomial by using integration algorithm for\nD-modules.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3198v1"
    },
    {
        "title": "Fast Computation of Smith Forms of Sparse Matrices Over Local Rings",
        "authors": [
            "Mustafa Elsheikh",
            "Mark Giesbrecht",
            "Andy Novocin",
            "B. David Saunders"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We present algorithms to compute the Smith Normal Form of matrices over two\nfamilies of local rings.\n  The algorithms use the \\emph{black-box} model which is suitable for sparse\nand structured matrices. The algorithms depend on a number of tools, such as\nmatrix rank computation over finite fields, for which the best-known time- and\nmemory-efficient algorithms are probabilistic.\n  For an $\\nxn$ matrix $A$ over the ring $\\Fzfe$, where $f^e$ is a power of an\nirreducible polynomial $f \\in \\Fz$ of degree $d$, our algorithm requires\n$\\bigO(\\eta de^2n)$ operations in $\\F$, where our black-box is assumed to\nrequire $\\bigO(\\eta)$ operations in $\\F$ to compute a matrix-vector product by\na vector over $\\Fzfe$ (and $\\eta$ is assumed greater than $\\Pden$). The\nalgorithm only requires additional storage for $\\bigO(\\Pden)$ elements of $\\F$.\nIn particular, if $\\eta=\\softO(\\Pden)$, then our algorithm requires only\n$\\softO(n^2d^2e^3)$ operations in $\\F$, which is an improvement on known dense\nmethods for small $d$ and $e$.\n  For the ring $\\ZZ/p^e\\ZZ$, where $p$ is a prime, we give an algorithm which\nis time- and memory-efficient when the number of nontrivial invariant factors\nis small. We describe a method for dimension reduction while preserving the\ninvariant factors. The time complexity is essentially linear in $\\mu n r e \\log\np,$ where $\\mu$ is the number of operations in $\\ZZ/p\\ZZ$ to evaluate the\nblack-box (assumed greater than $n$) and $r$ is the total number of non-zero\ninvariant factors.\n  To avoid the practical cost of conditioning, we give a Monte Carlo\ncertificate, which at low cost, provides either a high probability of success\nor a proof of failure. The quest for a time- and memory-efficient solution\nwithout restrictions on the number of nontrivial invariant factors remains\nopen. We offer a conjecture which may contribute toward that end.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.5365v2"
    },
    {
        "title": "Cylindrical Algebraic Sub-Decompositions",
        "authors": [
            "D. J. Wilson",
            "R. J. Bradford",
            "J. H. Davenport",
            "M. England"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Cylindrical algebraic decompositions (CADs) are a key tool in real algebraic\ngeometry, used primarily for eliminating quantifiers over the reals and\nstudying semi-algebraic sets. In this paper we introduce cylindrical algebraic\nsub-decompositions (sub-CADs), which are subsets of CADs containing all the\ninformation needed to specify a solution for a given problem.\n  We define two new types of sub-CAD: variety sub-CADs which are those cells in\na CAD lying on a designated variety; and layered sub-CADs which have only those\ncells of dimension higher than a specified value. We present algorithms to\nproduce these and describe how the two approaches may be combined with each\nother and the recent theory of truth-table invariant CAD.\n  We give a complexity analysis showing that these techniques can offer\nsubstantial theoretical savings, which is supported by experimentation using an\nimplementation in Maple.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.0647v2"
    },
    {
        "title": "Parallel Telescoping and Parameterized Picard--Vessiot Theory",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Ziming Li",
            "Michael F. Singer"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Parallel telescoping is a natural generalization of differential\ncreative-telescoping for single integrals to line integrals. It computes a\nlinear ordinary differential operator $L$, called a parallel telescoper, for\nseveral multivariate functions, such that the applications of $L$ to the\nfunctions yield antiderivatives of a single function. We present a necessary\nand sufficient condition guaranteeing the existence of parallel telescopers for\ndifferentially finite functions, and develop an algorithm to compute minimal\nones for compatible hyperexponential functions. Besides computing annihilators\nof parametric line integrals, we use the parallel telescoping for determining\nGalois groups of parameterized partial differential systems of first order.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4666v1"
    },
    {
        "title": "Over-constrained Weierstrass iteration and the nearest consistent system",
        "authors": [
            "Olivier Ruatta",
            "Mark Sciabica",
            "Agnes Szanto"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We propose a generalization of the Weierstrass iteration for over-constrained\nsystems of equations and we prove that the proposed method is the Gauss-Newton\niteration to find the nearest system which has at least $k$ common roots and\nwhich is obtained via a perturbation of prescribed structure. In the univariate\ncase we show the connection of our method to the optimization problem\nformulated by Karmarkar and Lakshman for the nearest GCD. In the multivariate\ncase we generalize the expressions of Karmarkar and Lakshman, and give\nexplicitly several iteration functions to compute the optimum.\n  The arithmetic complexity of the iterations is detailed.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5086v1"
    },
    {
        "title": "Truth Table Invariant Cylindrical Algebraic Decomposition by Regular\n  Chains",
        "authors": [
            "R. Bradford",
            "C. Chen",
            "J. H. Davenport",
            "M. England",
            "M. Moreno Maza",
            "D. Wilson"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  A new algorithm to compute cylindrical algebraic decompositions (CADs) is\npresented, building on two recent advances. Firstly, the output is truth table\ninvariant (a TTICAD) meaning given formulae have constant truth value on each\ncell of the decomposition. Secondly, the computation uses regular chains theory\nto first build a cylindrical decomposition of complex space (CCD) incrementally\nby polynomial. Significant modification of the regular chains technology was\nused to achieve the more sophisticated invariance criteria. Experimental\nresults on an implementation in the RegularChains Library for Maple verify that\ncombining these advances gives an algorithm superior to its individual\ncomponents and competitive with the state of the art.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.6310v3"
    },
    {
        "title": "Border Bases for Polynomial Rings over Noetherian Rings",
        "authors": [
            "Ambedkar Dukkipati",
            "Nithish Pai",
            "Maria Francis"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  The theory of border bases for zero-dimensional ideals has attracted several\nresearchers in symbolic computation due to their numerical stability and\nmathematical elegance. As shown in (Francis & Dukkipati, J. Symb. Comp., 2014),\none can extend the concept of border bases over Noetherian rings whenever the\ncorresponding residue class ring is finitely generated and free. In this paper\nwe address the following problem: Can the concept of border basis over\nNoetherian rings exists for ideals when the corresponding residue class rings\nare finitely generated but need not necessarily be free modules? We present a\nborder division algorithm and prove the termination of the algorithm for a\nspecial class of border bases. We show the existence of such border bases over\nNoetherian rings and present some characterizations in this regard. We also\nshow that certain reduced Gr\\\"{o}bner bases over Noetherian rings are contained\nin this class of border bases.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.0472v5"
    },
    {
        "title": "On the design of an expert help system for computer algebra systems",
        "authors": [
            "Renato P. dos Santos",
            "Waldir L. Roque"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  It is our intention here only to discuss the nature, complexity and tools\nconcerning the design of Smart Help, an expert help facility for aiding users\nof Computer Algebra Systems. Although the expert help system presented here has\nbeen particularly oriented to REDUCE (as a consequence of our former experience\nwith this system), we point out that the concept of Smart Help can be extended\nto other Computer Algebra Systems. Technically, Smart Help is a Production\nSystem on the top of a particular implementation of MANTRA, a hybrid knowledge\nrepresentation system, which has REDUCE integrated as an additional knowledge\nrepresentation module. Since the heuristic level of MANTRA has not yet been\nimplemented, being presently represented by the Lisp language itself, Smart\nHelp is coded in Lisp and resides in the same Lisp session of MANTRA. A\nprototype of Smart Help is now running on a SUN work-station on an experimental\nbasis.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6885v2"
    },
    {
        "title": "The package HarmonicSums: Computer Algebra and Analytic aspects of\n  Nested Sums",
        "authors": [
            "Jakob Ablinger"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  This paper summarizes the essential functionality of the computer algebra\npackage HarmonicSums. On the one hand HarmonicSums can work with nested sums\nsuch as harmonic sums and their generalizations and on the other hand it can\ntreat iterated integrals of the Poincare and Chen-type, such as harmonic\npolylogarithms and their generalizations. The interplay of these\nrepresentations and the analytic aspects are illustrated by concrete examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6180v1"
    },
    {
        "title": "On Ideal Lattices, Gröbner Bases and Generalized Hash Functions",
        "authors": [
            "Maria Francis",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  In this paper, we draw connections between ideal lattices and multivariate\npolynomial rings over integers using Gr\\\"obner bases. Ideal lattices are ideals\nin the residue class ring, $\\mathbb{Z}[x]/\\langle f \\rangle$ (here $f$ is a\nmonic polynomial), and cryptographic primitives have been built based on these\nobjects. As ideal lattices in the univariate case are generalizations of cyclic\nlattices, we introduce the notion of multivariate cyclic lattices and show that\nmultivariate ideal lattices are indeed a generalization of them. Based on\nmultivariate ideal lattices, we establish the existence of collision resistant\nhash functions using Gr\\\"obner basis techniques. For the construction of hash\nfunctions, we define a worst case problem, shortest substitution problem w.r.t.\nan ideal in $\\mathbb{Z}[x_1,\\ldots, x_n]$, and establish hardness results using\nfunctional fields.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.2011v3"
    },
    {
        "title": "Recognizing implicitly given rational canal surfaces",
        "authors": [
            "Jan Vršek",
            "Miroslav Lávička"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  It is still a challenging task of today to recognize the type of a given\nalgebraic surface which is described only by its implicit representation.\nIn~this paper we will investigate in more detail the case of canal surfaces\nthat are often used in geometric modelling, Computer-Aided Design and technical\npractice (e.g. as blending surfaces smoothly joining two parts with circular\nends). It is known that if the squared medial axis transform is a rational\ncurve then so is also the corresponding surface. However, starting from a\npolynomial it is not known how to decide if the corresponding algebraic surface\nis rational canal surface or not. Our goal is to formulate a simple and\nefficient algorithm whose input is a~polynomial with the coefficients from some\nsubfield of real numbers and the output is the answer whether the surface is a\nrational canal surface. In the affirmative case we also compute a rational\nparameterization of the squared medial axis transform which can be then used\nfor finding a rational parameterization of the implicitly given canal surface.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.3628v1"
    },
    {
        "title": "Integral D-Finite Functions",
        "authors": [
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We propose a differential analog of the notion of integral closure of\nalgebraic function fields. We present an algorithm for computing the integral\nclosure of the algebra defined by a linear differential operator. Our algorithm\nis a direct analog of van Hoeij's algorithm for computing integral bases of\nalgebraic function fields.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.03691v2"
    },
    {
        "title": "A Modified Abramov-Petkovsek Reduction and Creative Telescoping for\n  Hypergeometric Terms",
        "authors": [
            "Shaoshi Chen",
            "Hui Huang",
            "Manuel Kauers",
            "Ziming Li"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  The Abramov-Petkovsek reduction computes an additive decomposition of a\nhypergeometric term, which extends the functionality of the Gosper algorithm\nfor indefinite hypergeometric summation. We modify the Abramov-Petkovsek\nreduction so as to decompose a hypergeometric term as the sum of a summable\nterm and a non-summable one. The outputs of the Abramov-Petkovsek reduction and\nour modified version share the same required properties. The modified reduction\ndoes not solve any auxiliary linear difference equation explicitly. It is also\nmore efficient than the original reduction according to computational\nexperiments. Based on this reduction, we design a new algorithm to compute\nminimal telescopers for bivariate hypergeometric terms. The new algorithm can\navoid the costly computation of certificates.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.04668v2"
    },
    {
        "title": "A Polynomial-time Algorithm to Compute Generalized Hermite Normal Form\n  of Matrices over Z[x]",
        "authors": [
            "Rui-Juan Jing",
            "Chun-Ming Yuan",
            "Xiao-Shan Gao"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In this paper, a polynomial-time algorithm is given to compute the\ngeneralized Hermite normal form for a matrix F over Z[x], or equivalently, the\nreduced Groebner basis of the Z[x]-module generated by the column vectors of F.\nThe algorithm is also shown to be practically more efficient than existing\nalgorithms. The algorithm is based on three key ingredients. First, an F4 style\nalgorithm to compute the Groebner basis is adopted, where a novel prolongation\nis designed such that the coefficient matrices under consideration have\npolynomial sizes. Second, fast algorithms to compute Hermite normal forms of\nmatrices over Z are used. Third, the complexity of the algorithm are guaranteed\nby a nice estimation for the degree and height bounds of the polynomials in the\ngeneralized Hermite normal form.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.01067v2"
    },
    {
        "title": "Existence Problem of Telescopers: Beyond the Bivariate Case",
        "authors": [
            "Shaoshi Chen",
            "Qing-Hu Hou",
            "George Labahn",
            "Rong-Hua Wang"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In this paper, we solve the existence problem of telescopers for rational\nfunctions in three discrete variables. We reduce the problem to that of\ndeciding the summability of bivariate rational functions, which has been solved\nrecently. The existence criteria we present is needed for detecting the\ntermination of Zeilberger's algorithm to the function classes studied in this\npaper.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.03080v1"
    },
    {
        "title": "Binomial Difference Ideals",
        "authors": [
            "Xiao-Shan Gao",
            "Zhang Huang",
            "Chun-Ming Yuan"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In this paper, binomial difference ideals are studied. Three canonical\nrepresentations for Laurent binomial difference ideals are given in terms of\nthe reduced Groebner basis of Z[x]-lattices, regular and coherent difference\nascending chains, and partial characters over Z[x]-lattices, respectively.\nCriteria for a Laurent binomial difference ideal to be reflexive, prime,\nwell-mixed, and perfect are given in terms of their support lattices. The\nreflexive, well-mixed, and perfect closures of a Laurent binomial difference\nideal are shown to be binomial. Most of the properties of Laurent binomial\ndifference ideals are extended to the case of difference binomial ideals.\nFinally, algorithms are given to check whether a given Laurent binomial\ndifference ideal I is reflexive, prime, well-mixed, or perfect, and in the\nnegative case, to compute the reflexive, well-mixed, and perfect closures of I.\nAn algorithm is given to decompose a finitely generated perfect binomial\ndifference ideal as the intersection of reflexive prime binomial difference\nideals.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.03987v1"
    },
    {
        "title": "Symbolic-Numeric Tools for Analytic Combinatorics in Several Variables",
        "authors": [
            "Stephen Melczer",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Analytic combinatorics studies the asymptotic behaviour of sequences through\nthe analytic properties of their generating functions. This article provides\neffective algorithms required for the study of analytic combinatorics in\nseveral variables, together with their complexity analyses. Given a\nmultivariate rational function we show how to compute its smooth isolated\ncritical points, with respect to a polynomial map encoding asymptotic\nbehaviour, in complexity singly exponential in the degree of its denominator.\nWe introduce a numerical Kronecker representation for solutions of polynomial\nsystems with rational coefficients and show that it can be used to decide\nseveral properties (0 coordinate, equal coordinates, sign conditions for real\nsolutions, and vanishing of a polynomial) in good bit complexity. Among the\ncritical points, those that are minimal---a property governed by inequalities\non the moduli of the coordinates---typically determine the dominant asymptotics\nof the diagonal coefficient sequence. When the Taylor expansion at the origin\nhas all non-negative coefficients (known as the `combinatorial case') and under\nregularity conditions, we utilize this Kronecker representation to determine\nprobabilistically the minimal critical points in complexity singly exponential\nin the degree of the denominator, with good control over the exponent in the\nbit complexity estimate. Generically in the combinatorial case, this allows one\nto automatically and rigorously determine asymptotics for the diagonal\ncoefficient sequence. Examples obtained with a preliminary implementation show\nthe wide applicability of this approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00402v1"
    },
    {
        "title": "Refined Holonomic Summation Algorithms in Particle Physics",
        "authors": [
            "Johannes Blümlein",
            "Mark Round",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  An improved multi-summation approach is introduced and discussed that enables\none to simultaneously handle indefinite nested sums and products in the setting\nof difference rings and holonomic sequences. Relevant mathematics is reviewed\nand the underlying advanced difference ring machinery is elaborated upon. The\nflexibility of this new toolbox contributed substantially to evaluating\ncomplicated multi-sums coming from particle physics. Illustrative examples of\nthe functionality of the new software package RhoSum are given.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.03677v2"
    },
    {
        "title": "Towards a symbolic summation theory for unspecified sequences",
        "authors": [
            "Peter Paule",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  The article addresses the problem whether indefinite double sums involving a\ngeneric sequence can be simplified in terms of indefinite single sums.\nDepending on the structure of the double sum, the proposed summation machinery\nmay provide such a simplification without exceptions. If it fails, it may\nsuggest a more advanced simplification introducing in addition a single nested\nsum where the summand has to satisfy a particular constraint. More precisely,\nan explicitly given parameterized telescoping equation must hold. Restricting\nto the case that the arising unspecified sequences are specialized to the class\nof indefinite nested sums defined over hypergeometric, multi-basic or mixed\nhypergeometric products, it can be shown that this constraint is not only\nsufficient but also necessary.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06578v1"
    },
    {
        "title": "An efficient reduction strategy for signature-based algorithms to\n  compute Groebner basis",
        "authors": [
            "Kosuke Sakata"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  This paper introduces a strategy for signature-based algorithms to compute\nGroebner basis. The signature-based algorithms generate S-pairs instead of\nS-polynomials, and use s-reduction instead of the usual reduction used in the\nBuchberger algorithm. There are two strategies for s-reduction: one is the\nonly-top reduction strategy which is the way that only leading monomials are\ns-reduced. The other is the full reduction strategy which is the way that all\nmonomials are s-reduced. A new strategy, which we call selective-full strategy,\nfor s-reduction of S-pairs is introduced in this paper. In the experiment, this\nstrategy is efficient for computing the reduced Groebner basis. For computing a\nsignature Groebner basis, it is the most efficient or not the worst of the\nthree strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.12663v1"
    },
    {
        "title": "On the Existence of Telescopers for Rational Functions in Three\n  Variables",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Rong-Hua Wang",
            "Chaochao Zhu"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Zeilberger's method of creative telescoping is crucial for the\ncomputer-generated proofs of combinatorial and special-function identities.\nTelescopers are linear differential or ($q$-)recurrence operators computed by\nalgorithms for creative telescoping. For a given class of inputs, when\ntelescopers exist and how to construct telescopers efficiently if they exist\nare two fundamental problems related to creative telescoping. In this paper, we\nsolve the existence problem of telescopers for rational functions in three\nvariables including 18 cases. We reduce the existence problem from the\ntrivariate case to the bivariate case and some related problems. The existence\ncriteria given in this paper enable us to determine the termination of\nalgorithms for creative telescoping with trivariate rational inputs.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.09377v2"
    },
    {
        "title": "Resultants over principal Artinian rings",
        "authors": [
            "Claus Fieker",
            "Tommy Hofmann",
            "Carlo Sircana"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  The resultant of two univariate polynomials is an invariant of great\nimportance in commutative algebra and vastly used in computer algebra systems.\nHere we present an algorithm to compute it over Artinian principal rings with a\nmodified version of the Euclidean algorithm. Using the same strategy, we show\nhow the reduced resultant and a pair of B\\'ezout coefficient can be computed.\nParticular attention is devoted to the special case of\n$\\mathbf{Z}/n\\mathbf{Z}$, where we perform a detailed analysis of the\nasymptotic cost of the algorithm. Finally, we illustrate how the algorithms can\nbe exploited to improve ideal arithmetic in number fields and polynomial\narithmetic over $p$-adic fields.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.03341v1"
    },
    {
        "title": "On Algorithmic Estimation of Analytic Complexity for Polynomial\n  Solutions to Hypergeometric Systems",
        "authors": [
            "Vitaly A. Krasikov"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  The paper deals with the analytic complexity of solutions to bivariate\nholonomic hypergeometric systems of the Horn type. We obtain estimates on the\nanalytic complexity of Puiseux polynomial solutions to the hypergeometric\nsystems defined by zonotopes. We also propose algorithms of the analytic\ncomplexity estimation for polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09407v1"
    },
    {
        "title": "Formal Power Series on Algebraic Cryptanalysis",
        "authors": [
            "Shuhei Nakamura"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  In the complexity estimation for an attack that reduces a cryptosystem to\nsolving a system of polynomial equations, the degree of regularity and an upper\nbound of the first fall degree are often used in cryptanalysis. While the\ndegree of regularity can be easily computed using a univariate formal power\nseries under the semi-regularity assumption, determining an upper bound of the\nfirst fall degree requires investigating the concrete syzygies of an input\nsystem. In this paper, we investigate an upper bound of the first fall degree\nfor a polynomial system over a sufficiently large field. In this case, we prove\nthat the first fall degree of a non-semi-regular system is bounded above by the\ndegree of regularity, and that the first fall degree of a multi-graded\npolynomial system is bounded above by a certain value determined from a\nmultivariate formal power series. Moreover, we provide a theoretical assumption\nfor computing the first fall degree of a polynomial system over a sufficiently\nlarge field.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.14729v3"
    },
    {
        "title": "Deterministic computation of the characteristic polynomial in the time\n  of matrix multiplication",
        "authors": [
            "Vincent Neiger",
            "Clément Pernet"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  This paper describes an algorithm which computes the characteristic\npolynomial of a matrix over a field within the same asymptotic complexity, up\nto constant factors, as the multiplication of two square matrices. Previously,\nthis was only achieved by resorting to genericity assumptions or randomization\ntechniques, while the best known complexity bound with a general deterministic\nalgorithm was obtained by Keller-Gehrig in 1985 and involves logarithmic\nfactors. Our algorithm computes more generally the determinant of a univariate\npolynomial matrix in reduced form, and relies on new subroutines for\ntransforming shifted reduced matrices into shifted weak Popov matrices, and\nshifted weak Popov matrices into shifted Popov matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.04662v2"
    },
    {
        "title": "A Graph Theoretical Approach for Testing Binomiality of Reversible\n  Chemical Reaction Networks",
        "authors": [
            "Hamid Rahkooy",
            "Cristian Vargas Montero"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We study binomiality of the steady state ideals of chemical reaction\nnetworks. Considering rate constants as indeterminates, the concept of\nunconditional binomiality has been introduced and an algorithm based on linear\nalgebra has been proposed in a recent work for reversible chemical reaction\nnetworks, which has a polynomial time complexity upper bound on the number of\nspecies and reactions. In this article, using a modified version of\nspecies--reaction graphs, we present an algorithm based on graph theory which\nperforms by adding and deleting edges and changing the labels of the edges in\norder to test unconditional binomiality. We have implemented our graph\ntheoretical algorithm as well as the linear algebra one in Maple and made\nexperiments on biochemical models. Our experiments show that the performance of\nthe graph theoretical approach is similar to or better than the linear algebra\napproach, while it is drastically faster than Groebner basis and quantifier\nelimination methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.12615v2"
    },
    {
        "title": "An effective method for computing Grothendieck point residue mappings",
        "authors": [
            "Shinichi Tajima",
            "Katsusuke Nabeshima"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Grothendieck point residue is considered in the context of computational\ncomplex analysis. A new effective method is proposed for computing Grothendieck\npoint residues mappings and residues. Basic ideas of our approach are the use\nof Grothendieck local duality and a transformation law for local cohomology\nclasses. A new tool is devised for efficiency to solve the extended ideal\nmembership problems in local rings. The resulting algorithms are described with\nan example to illustrate them. An extension of the proposed method to\nparametric cases is also discussed as an application.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.09092v1"
    },
    {
        "title": "A new algorithm for computing $μ$-bases of the univariate polynomial\n  vector",
        "authors": [
            "Dingkang Wang",
            "Hesong Wang",
            "Fanghui Xiao"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  In this paper, we characterized the relationship between Groebner bases and\nu-bases: any minimal Groebner basis of the syzygy module for n univariate\npolynomials with respect to the term-over-position monomial order is its\nu-basis. Moreover, based on the gcd computation, we construct a free basis of\nthe syzygy module by the recursive way. According to this relationship and the\nconstructed free basis, a new algorithm for computing u-bases of the syzygy\nmodule is presented. The theoretical complexity of the algorithm is O(n^3d^2)\nunder a reasonable assumption, where d is the maximum degree of the input n\npolynomials. We have implemented this algorithm (MinGb) in Maple. Experimental\ndata and performance comparison with the existing algorithms developed by Song\nand Goldman (2009) (SG algorithm) and Hong et al. (2017) (HHK algorithm) show\nthat MinGb algorithm is more efficient than SG algorithm when n and d are\nsufficiently large, while MinGb algorithm and HHK algorithm both have their own\nadvantages.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10924v2"
    },
    {
        "title": "Solving parametric systems of polynomial equations over the reals\n  through Hermite matrices",
        "authors": [
            "Huu Phuoc Le",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We design a new algorithm for solving parametric systems having finitely many\ncomplex solutions for generic values of the parameters. More precisely, let $f\n= (f_1, \\ldots, f_m)\\subset \\mathbb{Q}[y][x]$ with $y = (y_1, \\ldots, y_t)$ and\n$x = (x_1, \\ldots, x_n)$, $V\\subset \\mathbb{C}^{t+n}$ be the algebraic set\ndefined by $f$ and $\\pi$ be the projection $(y, x) \\to y$. Under the\nassumptions that $f$ admits finitely many complex roots for generic values of\n$y$ and that the ideal generated by $f$ is radical, we solve the following\nproblem. On input $f$, we compute semi-algebraic formulas defining\nsemi-algebraic subsets $S_1, \\ldots, S_l$ of the $y$-space such that\n$\\cup_{i=1}^l S_i$ is dense in $\\mathbb{R}^t$ and the number of real points in\n$V\\cap \\pi^{-1}(\\eta)$ is invariant when $\\eta$ varies over each $S_i$.\n  This algorithm exploits properties of some well chosen monomial bases in the\nalgebra $\\mathbb{Q}(y)[x]/I$ where $I$ is the ideal generated by $f$ in\n$\\mathbb{Q}(y)[x]$ and the specialization property of the so-called Hermite\nmatrices. This allows us to obtain compact representations of the sets $S_i$ by\nmeans of semi-algebraic formulas encoding the signature of a symmetric matrix.\nWhen $f$ satisfies extra genericity assumptions, we derive complexity bounds on\nthe number of arithmetic operations in $\\mathbb{Q}$ and the degree of the\noutput polynomials. Let $d$ be the maximal degree of the $f_i$'s and $D =\nn(d-1)d^n$, we prove that, on a generic $f=(f_1,\\ldots,f_n)$, one can compute\nthose semi-algebraic formulas with $O^~( \\binom{t+D}{t}2^{3t}n^{2t+1}\nd^{3nt+2(n+t)+1})$ operations in $\\mathbb{Q}$ and that the polynomials involved\nhave degree bounded by $D$.\n  We report on practical experiments which illustrate the efficiency of our\nalgorithm on generic systems and systems from applications. It allows us to\nsolve problems which are out of reach of the state-of-the-art.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.14136v2"
    },
    {
        "title": "Monomial-agnostic computation of vanishing ideals",
        "authors": [
            "Hiroshi Kera",
            "Yoshihiko Hasegawa"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  In the last decade, the approximate basis computation of vanishing ideals has\nbeen studied extensively in computational algebra and data-driven applications\nsuch as machine learning. However, symbolic computation and the dependency on\nterm order remain essential gaps between the two fields. In this study, we\npresent the first $\\textit{monomial-agnostic}$ basis computation, which works\nfully numerically with proper normalization and without term order. This is\nrealized by gradient normalization, a newly proposed data-dependent\nnormalization that normalizes a polynomial with the magnitude of gradients at\ngiven points. The data-dependent nature of gradient normalization brings\nvarious significant advantages: i) efficient resolution of the spurious\nvanishing problem, the scale-variance issue of approximately vanishing\npolynomials, without accessing coefficients of terms, ii) scaling-consistent\nbasis computation, ensuring that input scaling does not lead to an essential\nchange in the output, and iii) robustness against input perturbations, where\nthe upper bound of error is determined only by the magnitude of the\nperturbations. Existing studies did not achieve any of these. As further\napplications of gradient information, we propose a monomial-agnostic basis\nreduction method and a regularization method to manage positive-dimensional\nideals.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00243v6"
    },
    {
        "title": "Polynomial modular product verification and its implications",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Polynomial multiplication is known to have quasi-linear complexity in both\nthe dense and the sparse cases. Yet no truly linear algorithm has been given in\nany case for the problem, and it is not clear whether it is even possible. This\nleaves room for a better algorithm for the simpler problem of verifying a\npolynomial product. While finding deterministic methods seems out of reach,\nthere exist probabilistic algorithms for the problem that are optimal in number\nof algebraic operations.\n  We study the generalization of the problem to the verification of a\npolynomial product modulo a sparse divisor. We investigate its bit complexity\nfor both dense and sparse multiplicands. In particular, we are able to show the\nprimacy of the verification over modular multiplication when the divisor has a\nconstant sparsity and a second highest-degree monomial that is not too large.\nWe use these results to obtain new bounds on the bit complexity of the standard\npolynomial multiplication verification. In particular, we provide optimal\nalgorithms in the bit complexity model in the dense case by improving a result\nof Kaminski and develop the first quasi-optimal algorithm for verifying sparse\npolynomial product.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.02142v1"
    },
    {
        "title": "Complexity Analysis of Root Clustering for a Complex Polynomial",
        "authors": [
            "Ruben Becker",
            "Michael Sagraloff",
            "Vikram Sharma",
            "Juan Xu",
            "Chee Yap"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Let $F(z)$ be an arbitrary complex polynomial. We introduce the local root\nclustering problem, to compute a set of natural $\\varepsilon$-clusters of roots\nof $F(z)$ in some box region $B_0$ in the complex plane. This may be viewed as\nan extension of the classical root isolation problem. Our contribution is\ntwo-fold: we provide an efficient certified subdivision algorithm for this\nproblem, and we provide a bit-complexity analysis based on the local geometry\nof the root clusters.\n  Our computational model assumes that arbitrarily good approximations of the\ncoefficients of $F$ are provided by means of an oracle at the cost of reading\nthe coefficients. Our algorithmic techniques come from a companion paper\n(Becker et al., 2018) and are based on the Pellet test, Graeffe and Newton\niterations, and are independent of Sch\\\"onhage's splitting circle method. Our\nalgorithm is relatively simple and promises to be efficient in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.05183v1"
    },
    {
        "title": "Fast evaluation of some p-adic transcendental functions",
        "authors": [
            "Xavier Caruso",
            "Marc Mezzarobba",
            "Nobuki Takayama",
            "Tristan Vaccon"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We design algorithms for computing values of many p-adic elementary and\nspecial functions, including logarithms, exponentials, polylogarithms, and\nhypergeometric functions. All our algorithms feature a quasi-linear complexity\nwith respect to the target precision and most of them are based on an\nadaptation to the-adic setting of the binary splitting and bit-burst\nstrategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.09315v1"
    },
    {
        "title": "Computing Characteristic Polynomials of p-Curvatures in Average\n  Polynomial Time",
        "authors": [
            "Raphaël Pagès"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We design a fast algorithm that computes, for a given linear differential\noperator with coefficients in $Z[x ]$, all the characteristic polynomials of\nits p-curvatures, for all primes $p < N$ , in asymptotically quasi-linear bit\ncomplexity in N. We discuss implementations and applications of our algorithm.\nWe shall see in particular that the good performances of our algorithm are\nquickly visible.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.14637v2"
    },
    {
        "title": "Sum of Squares Decompositions of Polynomials over their Gradient Ideals\n  with Rational Coefficients",
        "authors": [
            "Victor Magron",
            "Mohab Safey El Din",
            "Trung-Hieu Vu"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Assessing non-negativity of multivariate polynomials over the reals, through\nthe computation of {\\em certificates of non-negativity}, is a topical issue in\npolynomial optimization. This is usually tackled through the computation of\n{\\em sums-of-squares decompositions} which rely on efficient numerical solvers\nfor semi-definite programming. This method faces two difficulties. The first\none is that the certificates obtained this way are {\\em approximate} and then\nnon-exact. The second one is due to the fact that not all non-negative\npolynomials are sums-of-squares. In this paper, we build on previous works by\nParrilo, Nie, Demmel and Sturmfels who introduced certificates of\nnon-negativity modulo {\\em gradient ideals}. We prove that, actually, such\ncertificates can be obtained {\\em exactly}, over the rationals if the\npolynomial under consideration has rational coefficients and we provide {\\em\nexact} algorithms to compute them. We analyze the bit complexity of these\nalgorithms and deduce bit size bounds of such certificates.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11825v1"
    },
    {
        "title": "Signature Gröbner bases, bases of syzygies and cofactor reconstruction\n  in the free algebra",
        "authors": [
            "Clemens Hofstadler",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Signature-based algorithms have become a standard approach for computing\nGr\\\"obner bases in commutative polynomial rings. However, so far, it was not\nclear how to extend this concept to the setting of noncommutative polynomials\nin the free algebra. In this paper, we present a signature-based algorithm for\ncomputing Gr\\\"obner bases in precisely this setting. The algorithm is an\nadaptation of Buchberger's algorithm including signatures. We prove that our\nalgorithm correctly enumerates a signature Gr\\\"obner basis as well as a\nGr\\\"obner basis of the module generated by the leading terms of the generators'\nsyzygies, and that it terminates whenever the ideal admits a finite signature\nGr\\\"obner basis. Additionally, we adapt well-known signature-based criteria\neliminating redundant reductions, such as the syzygy criterion, the F5\ncriterion and the singular criterion, to the case of noncommutative\npolynomials. We also generalize reconstruction methods from the commutative\nsetting that allow to recover, from partial information about signatures, the\ncoordinates of elements of a Gr\\\"obner basis in terms of the input polynomials,\nas well as a basis of the syzygy module of the generators. We have written a\ntoy implementation of all the algorithms in the Mathematica package OperatorGB\nand we compare our signature-based algorithm to the classical Buchberger\nalgorithm for noncommutative polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.14675v3"
    },
    {
        "title": "Faster Modular Composition",
        "authors": [
            "Vincent Neiger",
            "Bruno Salvy",
            "Éric Schost",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  A new Las Vegas algorithm is presented for the composition of two polynomials\nmodulo a third one, over an arbitrary field. When the degrees of these\npolynomials are bounded by $n$, the algorithm uses $O(n^{1.43})$ field\noperations, breaking through the $3/2$ barrier in the exponent for the first\ntime. The previous fastest algebraic algorithms, due to Brent and Kung in 1978,\nrequire $O(n^{1.63})$ field operations in general, and ${n^{3/2+o(1)}}$ field\noperations in the special case of power series over a field of large enough\ncharacteristic. If cubic-time matrix multiplication is used, the new algorithm\nruns in ${n^{5/3+o(1)}}$ operations, while previous ones run in $O(n^2)$\noperations.\n  Our approach relies on the computation of a matrix of algebraic relations\nthat is typically of small size. Randomization is used to reduce arbitrary\ninput to this favorable situation.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08354v2"
    },
    {
        "title": "Towards a Theory of Domains for Harmonic Functions and its Symbolic\n  Counterpart",
        "authors": [
            "van Chiên Bui",
            "Gérard Duchamp",
            "Quoc Hoàn Ngo",
            "Vincel Hoang Ngoc Minh",
            "Vu Nguyen Dinh"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  In this paper, we begin by reviewing the calculus induced by the framework of\n[10]. In there, we extended Polylogarithm functions over a subalgebra of\nnoncommutative rational power series, recognizable by finite state\n(multiplicity) automata over the alphabet X = {x 0 , x 1 }. The stability of\nthis calculus under shuffle products relies on the nuclearity of the target\nspace [31]. We also concentrated on algebraic and analytic aspects of this\nextension allowing to index polylogarithms, at non positive multi-indices, by\nrational series and also allowing to regularize divergent polyzetas, at non\npositive multi-indices [10]. As a continuation of works in [10] and in order to\nunderstand the bridge between the extension of this \"polylogarithmic calculus\"\nand the world of harmonic sums, we propose a local theory, adapted to a full\ncalculus on indices of Harmonic Sums based on the Taylor expansions, around\nzero, of polylogarithms with index x 1 on the rightmost end. This theory is not\nonly compatible with Stuffle products but also with the Analytic Model. In this\nrespect, it provides a stable and fully algorithmic model for Harmonic\ncalculus. Examples by computer are also provided 6 .\n",
        "pdf_link": "http://arxiv.org/pdf/2110.13743v1"
    },
    {
        "title": "DFORMPY: A Python Library for visualising and zooming on differential\n  forms",
        "authors": [
            "Moustafa Gharamti",
            "Maciej Jarema",
            "Samuel Kirwin-Jones"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We present the v1.0.1 release of DFormPy, the first Python library providing\nan interactive visualisation of differential forms. DFormPy is also capable of\nexterior algebra and vector calculus, building on the capabilities of NumPy and\nmatplotlib. This short paper will demonstrate the functionalities of the\nlibrary, briefly outlining the mathematics involved with our objects and the\nmethods available to the user. DFormPy is an open source library with\ninteractive GUI released under MIT license at\nhttps://github.com/MostaphaG/Summer_project-df\n",
        "pdf_link": "http://arxiv.org/pdf/2201.10517v1"
    },
    {
        "title": "Resultant Tools for Parametric Polynomial Systems with Application to\n  Population Models",
        "authors": [
            "AmirHosein Sadeghimanesh",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We are concerned with the problem of decomposing the parameter space of a\nparametric system of polynomial equations, and possibly some polynomial\ninequality constraints, with respect to the number of real solutions that the\nsystem attains. Previous studies apply a two step approach to this problem,\nwhere first the discriminant variety of the system is computed via a Groebner\nBasis (GB), and then a Cylindrical Algebraic Decomposition (CAD) of this is\nproduced to give the desired computation. However, even on some reasonably\nsmall applied examples this process is too expensive, with computation of the\ndiscriminant variety alone infeasible. In this paper we develop new approaches\nto build the discriminant variety using resultant methods (the Dixon resultant\nand a new method using iterated univariate resultants). This reduces the\ncomplexity compared to GB and allows for a previous infeasible example to be\ntackled. We demonstrate the benefit by giving a symbolic solution to a problem\nfrom population dynamics -- the analysis of the steady states of three\nconnected populations which exhibit Allee effects - which previously could only\nbe tackled numerically.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.13189v2"
    },
    {
        "title": "Exact SOHS decompositions of trigonometric univariate polynomials with\n  Gaussian coefficients",
        "authors": [
            "Victor Magron",
            "Mohab Safey El Din",
            "Markus Schweighofer",
            "Trung Hieu Vu"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Certifying the positivity of trigonometric polynomials is of first importance\nfor design problems in discrete-time signal processing. It is well known from\nthe Riesz-Fej\\'ez spectral factorization theorem that any trigonometric\nunivariate polynomial positive on the unit circle can be decomposed as a\nHermitian square with complex coefficients. Here we focus on the case of\npolynomials with Gaussian integer coefficients, i.e., with real and imaginary\nparts being integers. We design, analyze and compare, theoretically and\npractically,three hybrid numeric-symbolic algorithms computing weighted sums of\nHermitian squares decompositions for trigonometric univariate polynomials\npositive on the unit circle with Gaussian coefficients. The numerical steps the\nfirst and second algorithm rely on are complex root isolation and semidefinite\nprogramming, respectively. An exact sum of Hermitian squares decomposition is\nobtained thanks to compensation techniques. The third algorithm, also based on\ncomplex semidefinite programming, is an adaptation of the rounding and\nprojection algorithm by Peyrl and Parrilo. For all three algorithms, we prove\nbit complexity and output size estimates that are polynomial in the degree of\nthe input and linear in the maximum bitsize of its coefficients. We compare\ntheir performance on randomly chosen benchmarks, and further design a certified\nfinite impulse filter.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06544v2"
    },
    {
        "title": "Bohemian Matrix Geometry",
        "authors": [
            "Robert M. Corless",
            "George Labahn",
            "Dan Piponi",
            "Leili Rafiee Sevyeri"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  A Bohemian matrix family is a set of matrices all of whose entries are drawn\nfrom a fixed, usually discrete and hence bounded, subset of a field of\ncharacteristic zero. Originally these were integers -- hence the name, from the\nacronym BOunded HEight Matrix of Integers (BOHEMI) -- but other kinds of\nentries are also interesting. Some kinds of questions about Bohemian matrices\ncan be answered by numerical computation, but sometimes exact computation is\nbetter. In this paper we explore some Bohemian families (symmetric, upper\nHessenberg, or Toeplitz) computationally, and answer some open questions posed\nabout the distributions of eigenvalue densities.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07769v2"
    },
    {
        "title": "Sparse Polynomial Interpolation and Division in Soft-linear Time",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray",
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Given a way to evaluate an unknown polynomial with integer coefficients, we\npresent new algorithms to recover its nonzero coefficients and corresponding\nexponents. As an application, we adapt this interpolation algorithm to the\nproblem of computing the exact quotient of two given polynomials. These methods\nare efficient in terms of the bit-length of the sparse representation, that is,\nthe number of nonzero terms, the size of coefficients, the number of variables,\nand the logarithm of the degree. At the core of our results is a new Monte\nCarlo randomized algorithm to recover a polynomial $f(x)$ with integer\ncoefficients given a way to evaluate $f(\\theta) \\bmod m$ for any chosen\nintegers $\\theta$ and $m$. This algorithm has nearly-optimal bit complexity,\nmeaning that the total bit-length of the probes, as well as the computational\nrunning time, is softly linear (ignoring logarithmic factors) in the bit-length\nof the resulting sparse polynomial. To our knowledge, this is the first sparse\ninterpolation algorithm with soft-linear bit complexity in the total output\nsize. For polynomials with integer coefficients, the best previously known\nresults have at least a cubic dependency on the bit-length of the exponents.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.08106v2"
    },
    {
        "title": "Faster change of order algorithm for Gröbner bases under shape and\n  stability assumptions",
        "authors": [
            "Jérémy Berthomieu",
            "Vincent Neiger",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Solving zero-dimensional polynomial systems using Gr\\\"obner bases is usually\ndone by, first, computing a Gr\\\"obner basis for the degree reverse\nlexicographic order, and next computing the lexicographic Gr\\\"obner basis with\na change of order algorithm. Currently, the change of order now takes a\nsignificant part of the whole solving time for many generic instances.\n  Like the fastest known change of order algorithms, this work focuses on the\nsituation where the ideal defined by the system satisfies natural properties\nwhich can be recovered in generic coordinates. First, the ideal has a\n\\emph{shape} lexicographic Gr\\\"obner basis. Second, the set of leading terms\nwith respect to the degree reverse lexicographic order has a \\emph{stability}\nproperty; in particular, the multiplication matrix can be read on the input\nGr\\\"obner basis.\n  The current fastest algorithms rely on the sparsity of this matrix. Actually,\nthis sparsity is a consequence of an algebraic structure, which can be\nexploited to represent the matrix concisely as a univariate polynomial matrix.\nWe show that the Hermite normal form of that matrix yields the sought\nlexicographic Gr\\\"obner basis, under assumptions which cover the shape position\ncase. Under some mild assumption implying $n \\le t$, the arithmetic complexity\nof our algorithm is $O\\tilde{~}(t^{\\omega-1}D)$, where $n$ is the number of\nvariables, $t$ is a sparsity indicator of the aforementioned matrix, $D$ is the\ndegree of the zero-dimensional ideal under consideration, and $\\omega$ is the\nexponent of matrix multiplication. This improves upon both state-of-the-art\ncomplexity bounds $O\\tilde{~}(tD^2)$ and $O\\tilde{~}(D^\\omega)$, since $\\omega\n< 3$ and $t\\le D$. Practical experiments, based on the libraries msolve and\nPML, confirm the high practical benefit.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09226v2"
    },
    {
        "title": "Rank-Sensitive Computation of the Rank Profile of a Polynomial Matrix",
        "authors": [
            "George Labahn",
            "Vincent Neiger",
            "Thi Xuan Vu",
            "Wei Zhou"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Consider a matrix $\\mathbf{F} \\in \\mathbb{K}[x]^{m \\times n}$ of univariate\npolynomials over a field $\\mathbb{K}$. We study the problem of computing the\ncolumn rank profile of $\\mathbf{F}$. To this end we first give an algorithm\nwhich improves the minimal kernel basis algorithm of Zhou, Labahn, and\nStorjohann (Proceedings ISSAC 2012). We then provide a second algorithm which\ncomputes the column rank profile of $\\mathbf{F}$ with a rank-sensitive\ncomplexity of $O\\tilde{~}(r^{\\omega-2} n (m+D))$ operations in $\\mathbb{K}$.\nHere, $D$ is the sum of row degrees of $\\mathbf{F}$, $\\omega$ is the exponent\nof matrix multiplication, and $O\\tilde{~}(\\cdot)$ hides logarithmic factors.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09329v2"
    },
    {
        "title": "Random primes without primality testing",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray",
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Numerous algorithms call for computation over the integers modulo a\nrandomly-chosen large prime. In some cases, the quasi-cubic complexity of\nselecting a random prime can dominate the total running time. We propose a new\nvariant of the classic D5 algorithm for \"dynamic evaluation\", applied to a\nrandomly-chosen (composite) integer. Unlike the D5 principle which has been\nused in the past to compute over a direct product of fields, our method is\nsimpler as it only requires following a single path after any modulus splits.\nThe transformation we propose can apply to any algorithm in the algebraic RAM\nmodel, even allowing randomization. The resulting transformed algorithm avoids\nany primality tests and will, with constant positive probability, have the same\nresult as the original computation modulo a randomly-chosen prime. As an\napplication, we demonstrate how to compute the exact number of nonzero terms in\nan unknown integer polynomial in quasi-linear time. We also show how the same\nalgorithmic transformation technique can be used for computing modulo random\nirreducible polynomials over a finite field.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.12073v1"
    },
    {
        "title": "New efficient algorithms for computing Gröbner bases of saturation\n  ideals (F4SAT) and colon ideals (Sparse-FGLM-colon)",
        "authors": [
            "Jérémy Berthomieu",
            "Christian Eder",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  This paper is concerned with linear algebra based methods for solving exactly\npolynomial systems through so-called Gr\\\"obner bases, which allow one to\ncompute modulo the polynomial ideal generated by the input equations. This is a\ntopical issue in non-linear algebra and more broadly in computational\nmathematics because of its numerous applications in engineering and computing\nsciences. Such applications often require geometric computing features such as\nrepresenting the closure of the set difference of two solution sets to given\npolynomial systems. Algebraically, this boils down to computing Gr\\\"obner bases\nof colon and/or saturation polynomial ideals. In this paper, we describe and\nanalyze new Gr\\\"obner bases algorithms for this task and present\nimplementations which are more efficient by several orders of magnitude than\nthe state-of-the-art software.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13387v2"
    },
    {
        "title": "Computing roadmaps in unbounded smooth real algebraic sets I:\n  connectivity results",
        "authors": [
            "Rémi Prébet",
            "Mohab Safey El Din",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Answering connectivity queries in real algebraic sets is a fundamental\nproblem in effective real algebraic geometry that finds many applications in\ne.g. robotics where motion planning issues are topical. This computational\nproblem is tackled through the computation of so-called roadmaps which are real\nalgebraic subsets of the set V under study, of dimension at most one, and which\nhave a connected intersection with all semi-algebraically connected components\nof V. Algorithms for computing roadmaps rely on statements establishing\nconnectivity properties of some well-chosen subsets of V , assuming that V is\nbounded.\n  In this paper, we extend such connectivity statements by dropping the\nboundedness assumption on V. This exploits properties of so-called generalized\npolar varieties, which are critical loci of V for some well-chosen polynomial\nmaps.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.03961v2"
    },
    {
        "title": "Solving sparse polynomial systems using Groebner bases and resultants",
        "authors": [
            "Matías R. Bender"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Solving systems of polynomial equations is a central problem in nonlinear and\ncomputational algebra. Since Buchberger's algorithm for computing Gr\\\"obner\nbases in the 60s, there has been a lot of progress in this domain. Moreover,\nthese equations have been employed to model and solve problems from diverse\ndisciplines such as biology, cryptography, and robotics. Currently, we have a\ngood understanding of how to solve generic systems from a theoretical and\nalgorithmic point of view. However, polynomial equations encountered in\npractice are usually structured, and so many properties and results about\ngeneric systems do not apply to them. For this reason, a common trend in the\nlast decades has been to develop mathematical and algorithmic frameworks to\nexploit specific structures of systems of polynomials.\n  Arguably, the most common structure is sparsity; that is, the polynomials of\nthe systems only involve a few monomials. Since Bernstein, Khovanskii, and\nKushnirenko's work on the expected number of solutions of sparse systems, toric\ngeometry has been the default mathematical framework to employ sparsity. In\nparticular, it is the crux of the matter behind the extension of classical\ntools to systems, such as resultant computations, homotopy continuation\nmethods, and most recently, Gr\\\"obner bases. In this work, we will review these\nclassical tools, their extensions, and recent progress in exploiting sparsity\nfor solving polynomial systems.\n  This manuscript complements its homonymous tutorial presented at the\nconference ISSAC 2022.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.09888v1"
    },
    {
        "title": "Elementary remarks about Pisano periods",
        "authors": [
            "Gérard Henry Edmond Duchamp",
            "Pierre Simonnet"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this short note, we reprove in a very elementary way some known facts\nabout Pisano periods as well as some considerations about the link between\nPisano periods and the order of roots of the characteristic equation. The\ntechnics only requires a small background in ring theory (merely the definition\nof a commutative ring). The tools set here can be reused for all linear\nrecurrences with quadratic non-constant characteristic equation.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.07095v2"
    },
    {
        "title": "FPS In Action: An Easy Way To Find Explicit Formulas For Interlaced\n  Hypergeometric Sequences",
        "authors": [
            "Bertrand Teguia Tabuguia",
            "Wolfram Koepf"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Linear recurrence equations with constant coefficients define the power\nseries coefficients of rational functions. However, one usually prefers to have\nan explicit formula for the sequence of coefficients, provided that such a\nformula is \"simple\" enough. Simplicity is related to the compactness of the\nformula due to the presence of algebraic numbers: \"the smaller, the simpler\".\nThis poster showcases the capacity of recent updates on the Formal Power Series\n(FPS) algorithm, implemented in Maxima and Maple (convert/FormalPowerSeries),\nto find simple formulas for sequences like those from https://oeis.org/A307717,\nhttps://oeis.org/A226782, or https://oeis.org/A226784 by computing power series\nrepresentations of their correctly guessed generating functions. We designed\nthe algorithm for the more general context of univariate $P$-recursive\nsequences. Our implementations are available at\nhttp://www.mathematik.uni-kassel.de/~bteguia/FPS_webpage/FPS.htm\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01031v1"
    },
    {
        "title": "Sturm's Theorem with Endpoints",
        "authors": [
            "Philippe Pébay",
            "J. Maurice Rojas",
            "David C. Thompson"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Sturm's Theorem is a fundamental 19th century result relating the number of\nreal roots of a polynomial $f$ in an interval to the number of sign\nalternations in a sequence of polynomial division-like calculations. We provide\na short direct proof of Sturm's Theorem, including the numerically vexing case\n(ignored in many published accounts) where an interval endpoint is a root of\n$f$.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07904v1"
    },
    {
        "title": "Factoring differential operators over algebraic curves in positive\n  characteristic",
        "authors": [
            "Raphaël Pagès"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We present an algorithm for factoring linear differential operators with\ncoefficients in a finite separable extension of F p (x). Our methods rely on\nspecific tools arising in positive characteristic: p-curvature, structure of\nsimple central algebras and p-Riccati equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.11365v1"
    },
    {
        "title": "Minimization of differential equations and algebraic values of\n  $E$-functions",
        "authors": [
            "Alin Bostan",
            "Tanguy Rivoal",
            "Bruno Salvy"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  A power series being given as the solution of a linear differential equation\nwith appropriate initial conditions, minimization consists in finding a\nnon-trivial linear differential equation of minimal order having this power\nseries as a solution. This problem exists in both homogeneous and inhomogeneous\nvariants; it is distinct from, but related to, the classical problem of\nfactorization of differential operators. Recently, minimization has found\napplications in Transcendental Number Theory, more specifically in the\ncomputation of non-zero algebraic points where Siegel's $E$-functions take\nalgebraic values. We present algorithms and implementations for these\nquestions, and discuss examples and experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01827v3"
    },
    {
        "title": "SC-Square: Future Progress with Machine Learning?",
        "authors": [
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  The algorithms employed by our communities are often underspecified, and thus\nhave multiple implementation choices, which do not effect the correctness of\nthe output, but do impact the efficiency or even tractability of its\nproduction. In this extended abstract, to accompany a keynote talk at the 2021\nSC-Square Workshop, we survey recent work (both the author's and from the\nliterature) on the use of Machine Learning technology to improve algorithms of\ninterest to SC-Square.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04361v1"
    },
    {
        "title": "Computing groups of Hecke characters",
        "authors": [
            "Pascal Molin",
            "Aurel Page"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We describe algorithms to represent and compute groups of Hecke characters.\nWe make use of an id{\\`e}lic point of view and obtain the whole family of such\ncharacters, including transcendental ones. We also show how to isolate the\nalgebraic characters, which are of particular interest in number theory. This\nwork has been implemented in Pari/GP, and we illustrate our work with a variety\nof explicit examples using our implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.02716v1"
    },
    {
        "title": "The FBHHRBNRSSSHK-Algorithm for Multiplication in\n  $\\mathbb{Z}_2^{5\\times5}$ is still not the end of the story",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In response to a recent Nature article which announced an algorithm for\nmultiplying $5\\times5$-matrices over $\\mathbb{Z}_2$ with only 96\nmultiplications, two fewer than the previous record, we present an algorithm\nthat does the job with only 95 multiplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.04045v3"
    },
    {
        "title": "Axioms for a theory of signature bases",
        "authors": [
            "Pierre Lairez"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Twenty years after the discovery of the F5 algorithm, Gr\\\"obner bases with\nsignatures are still challenging to understand and to adapt to different\nsettings. This contrasts with Buchberger's algorithm, which we can bend in many\ndirections keeping correctness and termination obvious. I propose an axiomatic\napproach to Gr\\\"obner bases with signatures with the purpose of uncoupling the\ntheory and the algorithms, and giving general results applicable in many\ndifferent settings (e.g. Gr\\\"obner for submodules, F4-style reduction,\nnoncommutative rings, non-Noetherian settings, etc.).\n",
        "pdf_link": "http://arxiv.org/pdf/2210.13788v3"
    },
    {
        "title": "Analysis and object oriented implementation of the Kovacic algorithm",
        "authors": [
            "Nasser M. Abbasi"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  This paper gives a detailed overview and a number of worked out examples\nillustrating the Kovacic \\cite{Kovacic86} algorithm for solving second order\nlinear differential equation ${A(x) y\"+ B(x) y' + C(x) y=0}$ where $A,B,C$ are\nrational functions with complex coefficients in the independent variable $x$.\nAll three cases of the algorithm were implemented in a software package based\non an object oriented design and complete source code listing given in the\nappendix with usage examples. Implementation used the Maple computer algebra\nlanguage. The complete Kovacic package in one mpl file accompany the arXiv\nversion of this paper. This package was then used to analyze the distribution\nof Kovacic algorithm cases on $3000$ differential equations\n",
        "pdf_link": "http://arxiv.org/pdf/2211.00804v1"
    },
    {
        "title": "Subresultants of Several Univariate Polynomials in Newton Basis",
        "authors": [
            "Weidong Wang",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this paper, we consider the problem of formulating the subresultant\npolynomials for several univariate polynomials in Newton basis. It is required\nthat the resulting subresultant polynomials be expressed in the same Newton\nbasis as that used in the input polynomials. To solve the problem, we devise a\nparticular matrix with the help of the companion matrix of a polynomial in\nNewton basis. Meanwhile, the concept of determinantal polynomial in power basis\nfor formulating subresultant polynomials is extended to that in Newton basis.\nIt is proved that the generalized determinantal polynomial of the specially\ndesigned matrix provides a new formula for the subresultant polynomial in\nNewton basis, which is equivalent to the subresultant polynomial in power\nbasis. Furthermore, we show an application of the new formula in devising a\nbasis-preserving method for computing the gcd of several Newton polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.03422v2"
    },
    {
        "title": "Computing error bounds for asymptotic expansions of regular P-recursive\n  sequences",
        "authors": [
            "Ruiwen Dong",
            "Stephen Melczer",
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Over the last several decades, improvements in the fields of analytic\ncombinatorics and computer algebra have made determining the asymptotic\nbehaviour of sequences satisfying linear recurrence relations with polynomial\ncoefficients largely a matter of routine, under assumptions that hold often in\npractice. The algorithms involved typically take a sequence, encoded by a\nrecurrence relation and initial terms, and return the leading terms in an\nasymptotic expansion up to a big-O error term. Less studied, however, are\neffective techniques giving an explicit bound on asymptotic error terms. Among\nother things, such explicit bounds typically allow the user to automatically\nprove sequence positivity (an active area of enumerative and algebraic\ncombinatorics) by exhibiting an index when positive leading asymptotic\nbehaviour dominates any error terms. In this article, we present a practical\nalgorithm for computing such asymptotic approximations with rigorous error\nbounds, under the assumption that the generating series of the sequence is a\nsolution of a differential equation with regular (Fuchsian) dominant\nsingularities. Our algorithm approximately follows the singularity analysis\nmethod of Flajolet and Odlyzko, except that all big-O terms involved in the\nderivation of the asymptotic expansion are replaced by explicit error terms.\nThe computation of the error terms combines analytic bounds from the literature\nwith effective techniques from rigorous numerics and computer algebra. We\nimplement our algorithm in the SageMath computer algebra system and exhibit its\nuse on a variety of applications (including our original motivating example,\nsolution uniqueness in the Canham model for the shape of genus one\nbiomembranes).\n",
        "pdf_link": "http://arxiv.org/pdf/2212.11742v2"
    },
    {
        "title": "A Unified Approach to Unimodality of Gaussian Polynomials",
        "authors": [
            "Christoph Koutschan",
            "Ali K. Uncu",
            "Elaine Wong"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In 2013, Pak and Panova proved the strict unimodality property of\n$q$-binomial coefficients $\\binom{\\ell+m}{m}_q$ (as polynomials in $q$) based\non the combinatorics of Young tableaux and the semigroup property of Kronecker\ncoefficients. They showed it to be true for all $\\ell,m\\geq 8$ and a few other\ncases. We propose a different approach to this problem based on computer\nalgebra, where we establish a closed form for the coefficients of these\npolynomials and then use cylindrical algebraic decomposition to identify\nexactly the range of coefficients where strict unimodality holds. This strategy\nallows us to tackle generalizations of the problem, e.g., to show unimodality\nwith larger gaps or unimodality of related sequences. In particular, we present\nproofs of two additional cases of a conjecture by Stanley and Zanello.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04067v2"
    },
    {
        "title": "Refined $F_5$ Algorithms for Ideals of Minors of Square Matrices",
        "authors": [
            "Sriram Gopalakrishnan",
            "Vincent Neiger",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We consider the problem of computing a grevlex Gr\\\"obner basis for the set\n$F_r(M)$ of minors of size $r$ of an $n\\times n$ matrix $M$ of generic linear\nforms over a field of characteristic zero or large enough. Such sets are not\nregular sequences; in fact, the ideal $\\langle F_r(M) \\rangle$ cannot be\ngenerated by a regular sequence. As such, when using the general-purpose\nalgorithm $F_5$ to find the sought Gr\\\"obner basis, some computing time is\nwasted on reductions to zero. We use known results about the first syzygy\nmodule of $F_r(M)$ to refine the $F_5$ algorithm in order to detect more\nreductions to zero. In practice, our approach avoids a significant number of\nreductions to zero. In particular, in the case $r=n-2$, we prove that our new\nalgorithm avoids all reductions to zero, and we provide a corresponding\ncomplexity analysis which improves upon the previously known estimates.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05375v2"
    },
    {
        "title": "A Direttissimo Algorithm for Equidimensional Decomposition",
        "authors": [
            "Christian Eder",
            "Pierre Lairez",
            "Rafael Mohr",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We describe a recursive algorithm that decomposes an algebraic set into\nlocally closed equidimensional sets, i.e. sets which each have irreducible\ncomponents of the same dimension. At the core of this algorithm, we combine\nideas from the theory of triangular sets, a.k.a. regular chains, with Gr\\\"obner\nbases to encode and work with locally closed algebraic sets. Equipped with\nthis, our algorithm avoids projections of the algebraic sets that are\ndecomposed and certain genericity assumptions frequently made when decomposing\npolynomial systems, such as assumptions about Noether position. This makes it\nproduce fine decompositions on more structured systems where ensuring\ngenericity assumptions often destroys the structure of the system at hand.\nPractical experiments demonstrate its efficiency compared to state-of-the-art\nimplementations.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.08174v2"
    },
    {
        "title": "Algorithm for connectivity queries on real algebraic curves",
        "authors": [
            "Md Nazrul Islam",
            "Adrien Poteaux",
            "Rémi Prébet"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We consider the problem of answering connectivity queries on a real algebraic\ncurve. The curve is given as the real trace of an algebraic curve, assumed to\nbe in generic position, and being defined by some rational parametrizations.\nThe query points are given by a zero-dimensional parametrization. We design an\nalgorithm which counts the number of connected components of the real curve\nunder study, and decides which query point lie in which connected component, in\ntime log-linear in $N^6$, where $N$ is the maximum of the degrees and\ncoefficient bit-sizes of the polynomials given as input. This matches the\ncurrently best-known bound for computing the topology of real plane curves. The\nmain novelty of this algorithm is the avoidance of the computation of the\ncomplete topology of the curve.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.11347v3"
    },
    {
        "title": "Some D-finite and Some Possibly D-finite Sequences in the OEIS",
        "authors": [
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In an automatic search, we found conjectural recurrences for some sequences\nin the OEIS that were not previously recognized as being D-finite. In some\ncases, we are able to prove the conjectured recurrence. In some cases, we are\nnot able to prove the conjectured recurrence, but we can prove that a\nrecurrence exists. In some remaining cases, we do not know where the recurrence\nmight come from.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.02793v2"
    },
    {
        "title": "Computer-assisted proofs of \"Kariya's theorem\" with computer algebra",
        "authors": [
            "Ayane Ito",
            "Takefumi Kasai",
            "Akira Terui"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We demonstrate computer-assisted proofs of \"Kariya's theorem,\" a theorem in\nelementary geometry, with computer algebra. In the proof of geometry theorem\nwith computer algebra, vertices of geometric figures that are subjects for the\nproof are expressed as variables. The variables are classified into two\nclasses: arbitrarily given points and the points defined from the former points\nby constraints. We show proofs of Kariya's theorem with two formulations\naccording to two ways for giving the arbitrary points: one is called \"vertex\nformulation,\" and the other is called \"incenter formulation,\" with two methods:\none is Gr\\\"obner basis computation, and the other is Wu's method. Furthermore,\nwe show computer-assisted proofs of the property that the point so-called\n\"Kariya point\" is located on the hyperbola so-called \"Feuerbach's hyperbola\",\nwith two formulations and two methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.07491v1"
    },
    {
        "title": "Explainable AI Insights for Symbolic Computation: A case study on\n  selecting the variable ordering for cylindrical algebraic decomposition",
        "authors": [
            "Lynn Pickering",
            "Tereso Del Rio Almajano",
            "Matthew England",
            "Kelly Cohen"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In recent years there has been increased use of machine learning (ML)\ntechniques within mathematics, including symbolic computation where it may be\napplied safely to optimise or select algorithms. This paper explores whether\nusing explainable AI (XAI) techniques on such ML models can offer new insight\nfor symbolic computation, inspiring new implementations within computer algebra\nsystems that do not directly call upon AI tools. We present a case study on the\nuse of ML to select the variable ordering for cylindrical algebraic\ndecomposition. It has already been demonstrated that ML can make the choice\nwell, but here we show how the SHAP tool for explainability can be used to\ninform new heuristics of a size and complexity similar to those human-designed\nheuristics currently commonly used in symbolic computation.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12154v2"
    },
    {
        "title": "Drinfeld modules in SageMath",
        "authors": [
            "David Ayotte",
            "Xavier Caruso",
            "Antoine Leudière",
            "Joseph Musleh"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We present the first implementation of Drinfeld modules fully integrated in\nthe SageMath ecosystem. First features will be released with SageMath 10.0.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00422v1"
    },
    {
        "title": "Arithmetic of D-Algebraic Functions",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We are concerned with the arithmetic of solutions to ordinary or partial\nnonlinear differential equations which are algebraic in the indeterminates and\ntheir derivatives. We call these solutions D-algebraic functions, and their\nequations are algebraic (ordinary or partial) differential equations (ADEs).\nThe general purpose is to find ADEs whose solutions contain specified rational\nexpressions of solutions to given ADEs. For univariate D-algebraic functions,\nwe show how to derive an ADE of smallest possible order. In the multivariate\ncase, we introduce a general algorithm for these computations and derive\nconclusions on the order bound of the resulting algebraic PDE. Using our\naccompanying Maple software, we discuss applications in physics, statistics,\nand symbolic integration.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00702v3"
    },
    {
        "title": "Factorization and root-finding for polynomials over division quaternion\n  algebras",
        "authors": [
            "Przemysław Koprowski"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Polynomial factorization and root finding are among the most standard themes\nof computational mathematics. Yet still, little has been done for polynomials\nover quaternion algebras, with the single exception of Hamiltonian quaternions\nfor which there are known numerical methods for polynomial root approximation.\nThe sole purpose of the present paper is to present a polynomial factorization\nalgorithm for division quaternion algebras over number fields, together with\nits adaptation for root finding.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.02072v1"
    },
    {
        "title": "Dimension Results for Extremal-Generic Polynomial Systems over Complete\n  Toric Varieties",
        "authors": [
            "Matías Bender",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We study polynomial systems with prescribed monomial supports in the Cox\nrings of toric varieties built from complete polyhedral fans. We present\ncombinatorial formulas for the dimensions of their associated subvarieties\nunder genericity assumptions on the coefficients of the polynomials. Using\nthese formulas, we identify at which degrees generic systems in polytopal\nalgebras form regular sequences. Our motivation comes from sparse elimination\ntheory, where knowing the expected dimension of these subvarieties leads to\nspecialized algorithms and to large speed-ups for solving sparse polynomial\nsystems. As a special case, we classify the degrees at which regular sequences\ndefined by weighted homogeneous polynomials can be found, answering an open\nquestion in the Gr\\\"obner bases literature. We also show that deciding whether\na sparse system is generically a regular sequence in a polytopal algebra is\nhard from the point of view of theoretical computational complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07439v3"
    },
    {
        "title": "Bézout identities and control of the heat equation",
        "authors": [
            "François Ollivier"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Computing analytic B\\'ezout identities remains a difficult task, which has\nmany applications in control theory. Flat PDE systems have cast a new light on\nthis problem. We consider here a simple case of special interest: a rod of\nlength $a+b$, insulated at both ends and heated at point $x=a$. The case $a=0$\nis classical, the temperature of the other end $\\theta(b,t)$ being then a flat\noutput, with parametrization $\\theta(x,t)=\\cosh((b-x)(\\partial/\\partial\nt)^{1/2}\\theta(b,t)$.\n  When $a$ and $b$ are integers, with $a$ odd and $b$ even, the system is flat\nand the flat output is obtained from the B\\'ezout identity\n$f(x)\\cosh(ax)+g(x)\\cosh(bx)=1$, the omputation of which boils down to a\nB\\'ezout identity of Chebyshev polynomials. But this form is not the most\nefficient and a smaller expression $f(x)=\\sum_{k=1}^{n} c_{k}\\cosh(kx)$ may be\ncomputed in linear time.\n  These results are compared with an approximations by a finite system, using a\nclassical discretization.\n  We provide experimental computations, approximating a non rational value $r$\nby a sequence of fractions $b/a$, showing that the power series for the\nB\\'ezout relation seems to converge.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.09340v1"
    },
    {
        "title": "Using Symbolic Computation to Analyze Zero-Hopf Bifurcations of\n  Polynomial Differential Systems",
        "authors": [
            "Bo Huang"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper is devoted to the study of infinitesimal limit cycles that can\nbifurcate from zero-Hopf equilibria of differential systems based on the\naveraging method. We develop an efficient symbolic program using Maple for\ncomputing the averaged functions of any order for continuous differential\nsystems in arbitrary dimension. The program allows us to systematically analyze\nzero-Hopf bifurcations of polynomial differential systems using symbolic\ncomputation methods. We show that for the first-order averaging,\n$\\ell\\in\\{0,1,\\ldots,2^{n-3}\\}$ limit cycles can bifurcate from the zero-Hopf\nequilibrium for the general class of perturbed differential systems and up to\nthe second-order averaging, the maximum number of limit cycles can be\ndetermined by computing the mixed volume of a polynomial system obtained from\nthe averaged functions. A number of examples are presented to demonstrate the\neffectiveness of the proposed algorithmic approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11109v1"
    },
    {
        "title": "Faster real root decision algorithm for symmetric polynomials",
        "authors": [
            "George Labahn",
            "Cordian Riener",
            "Mohab Safey El Din",
            "Éric Schost",
            "Thi Xuan Vu"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper, we consider the problem of deciding the existence of real\nsolutions to a system of polynomial equations having real coefficients, and\nwhich are invariant under the action of the symmetric group. We construct and\nanalyze a Monte Carlo probabilistic algorithm which solves this problem, under\nsome regularity assumptions on the input, by taking advantage of the symmetry\ninvariance property. The complexity of our algorithm is polynomial in $d^s,\n{{n+d} \\choose d}$, and ${{n} \\choose {s+1}}$, where $n$ is the number of\nvariables and $d$ is the maximal degree of $s$ input polynomials defining the\nreal algebraic set under study. In particular, this complexity is polynomial in\n$n$ when $d$ and $s$ are fixed and is equal to $n^{O(1)}2^n$ when $d=n$.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.03855v1"
    },
    {
        "title": "Generating Elementary Integrable Expressions",
        "authors": [
            "Rashid Barket",
            "Matthew England",
            "Jürgen Gerhard"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  There has been an increasing number of applications of machine learning to\nthe field of Computer Algebra in recent years, including to the prominent\nsub-field of Symbolic Integration. However, machine learning models require an\nabundance of data for them to be successful and there exist few benchmarks on\nthe scale required. While methods to generate new data already exist, they are\nflawed in several ways which may lead to bias in machine learning models\ntrained upon them. In this paper, we describe how to use the Risch Algorithm\nfor symbolic integration to create a dataset of elementary integrable\nexpressions. Further, we show that data generated this way alleviates some of\nthe flaws found in earlier methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.15572v1"
    },
    {
        "title": "Discovering Asymptotic Expansions Using Symbolic Regression",
        "authors": [
            "Rasul Abdusalamov",
            "Julius Kaplunov",
            "Mikhail Itskov"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Recently, symbolic regression (SR) has demonstrated its efficiency for\ndiscovering basic governing relations in physical systems. A major impact can\nbe potentially achieved by coupling symbolic regression with asymptotic\nmethodology. The main advantage of asymptotic approach involves the robust\napproximation to the sought for solution bringing a clear idea of the effect of\nproblem parameters. However, the analytic derivation of the asymptotic series\nis often highly nontrivial especially, when the exact solution is not\navailable. In this paper, we adapt SR methodology to discover asymptotic\nseries. As an illustration we consider three problem in mechanics, including\ntwo-mass collision, viscoelastic behavior of a Kelvin-Voigt solid and\npropagation of Rayleigh-Lamb waves. The training data is generated from the\nexplicit exact solutions of these problems. The obtained SR results are\ncompared to the benchmark asymptotic expansions of the above mentioned exact\nsolutions. Both convergent and divergent asymptotic series are considered. A\ngood agreement between SR expansions and analytical results is observed. It is\ndemonstrated that the proposed approach can be used to identify material\nparameters, e.g. Poisson's ratio, and has high prospects for utilizing\nexperimental and numerical data.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.01876v1"
    },
    {
        "title": "Algorithms for computing norms and characteristic polynomials on general\n  Drinfeld modules",
        "authors": [
            "Xavier Caruso",
            "Antoine Leudière"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We provide two families of algorithms to compute characteristic polynomials\nof endomorphisms and norms of isogenies of Drinfeld modules. Our algorithms\nwork for Drinfeld modules of any rank, defined over any base curve. When the\nbase curve is $\\mathbb P^1_{\\mathbb F_q}$, we do a thorough study of the\ncomplexity, demonstrating that our algorithms are, in many cases, the most\nasymptotically performant. The first family of algorithms relies on the\ncorrespondence between Drinfeld modules and Anderson motives, reducing the\ncomputation to linear algebra over a polynomial ring. The second family,\navailable only for the Frobenius endomorphism, is based on a formula expressing\nthe characteristic polynomial of the Frobenius as a reduced norm in a central\nsimple algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.02879v4"
    },
    {
        "title": "Data Augmentation for Mathematical Objects",
        "authors": [
            "Tereso del Rio",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper discusses and evaluates ideas of data balancing and data\naugmentation in the context of mathematical objects: an important topic for\nboth the symbolic computation and satisfiability checking communities, when\nthey are making use of machine learning techniques to optimise their tools. We\nconsider a dataset of non-linear polynomial problems and the problem of\nselecting a variable ordering for cylindrical algebraic decomposition to tackle\nthese with. By swapping the variable names in already labelled problems, we\ngenerate new problem instances that do not require any further labelling when\nviewing the selection as a classification problem. We find this augmentation\nincreases the accuracy of ML models by 63% on average. We study what part of\nthis improvement is due to the balancing of the dataset and what is achieved\nthanks to further increasing the size of the dataset, concluding that both have\na very significant effect. We finish the paper by reflecting on how this idea\ncould be applied in other uses of machine learning in mathematics.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06984v1"
    },
    {
        "title": "Deciding One to One property of Boolean maps: Condition and algorithm in\n  terms of implicants",
        "authors": [
            "Virendra Sule"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper addresses the computational problem of deciding invertibility (or\none to one-ness) of a Boolean map $F$ in $n$-Boolean variables. This problem\nhas a special case of deciding invertibilty of a map\n$F:\\mathbb{F}_{2}^n\\rightarrow\\mathbb{F}_{2}^n$ over the binary field\n$\\mathbb{F}_2$. Further the problem can be extended and stated over a finite\nfield $\\mathbb{F}$ instead of $\\mathbb{F}_2$. Algebraic condition for\ninvertibility of $F$ in this special case over a finite field is well known to\nbe equivalent to invertibility of the Koopman operator of $F$ as shown in\n\\cite{RamSule}. In this paper a condition for invertibility is derived in the\nspecial case of Boolean maps $F:B_0^n\\rightarrow B_0^n$ where $B_0$ is the two\nelement Boolean algebra in terms of \\emph{implicants} of Boolean equations.\nThis condition is then extended to the case of general maps in $n$ variables.\nHence this condition answers the special case of invertibility of the map $F$\ndefined over the binary field $\\mathbb{F}_2$ alternatively, in terms of\nimplicants instead of the Koopman operator. The problem of deciding\ninvertibility of a map $F$ (or that of finding its $GOE$) over finite fields\nappears to be distinct from the satisfiability problem (SAT) or the problem of\ndeciding consistency of polynomial equations over finite fields. Hence the well\nknown algorithms for deciding SAT or of solvability using Grobner basis for\nchecking membership in an ideal generated by polynomials is not known to answer\nthe question of invertibility of a map. Similarly it appears that algorithms\nfor satisfiability or polynomial solvability are not useful for computation of\n$GOE(F)$ even for maps over the binary field $\\mathbb{F}_2$.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07788v3"
    },
    {
        "title": "Partial Proof of a Conjecture with Implications for Spectral\n  Majorization",
        "authors": [
            "Jeffrey Uhlmann"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper we report on new results relating to a conjecture regarding\nproperties of $n\\times n$, $n\\leq 6$, positive definite matrices. The\nconjecture has been proven for $n\\leq 4$ using computer-assisted sum of squares\n(SoS) methods for proving polynomial nonnegativity. Based on these proven\ncases, we report on the recent identification of a new family of matrices with\nthe property that their diagonals majorize their spectrum. We then present new\nresults showing that this family can extended via Kronecker composition to\n$n>6$ while retaining the special majorization property. We conclude with\ngeneral considerations on the future of computer-assisted and AI-based proofs.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01302v1"
    },
    {
        "title": "HIVE: Scalable Hardware-Firmware Co-Verification using Scenario-based\n  Decomposition and Automated Hint Extraction",
        "authors": [
            "Aruna Jayasena",
            "Prabhat Mishra"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Hardware-firmware co-verification is critical to design trustworthy systems.\nWhile formal methods can provide verification guarantees, due to the complexity\nof firmware and hardware, it can lead to state space explosion. There are\npromising avenues to reduce the state space during firmware verification\nthrough manual abstraction of hardware or manual generation of hints. Manual\ndevelopment of abstraction or hints requires domain expertise and can be\ntime-consuming and error-prone, leading to incorrect proofs or inaccurate\nresults. In this paper, we effectively combine the scalability of\nsimulation-based validation and the completeness of formal verification. Our\nproposed approach is applicable to actual firmware and hardware implementations\nwithout requiring any manual intervention during formal model generation or\nhint extraction. To reduce the state space complexity, we utilize both static\nmodule-level analysis and dynamic execution of verification scenarios to\nautomatically generate system-level hints. These hints guide the underlying\nsolver to perform scalable equivalence checking using proofs. The extracted\nhints are validated against the implementation before using them in the proofs.\nExperimental evaluation on RISC-V based systems demonstrates that our proposed\nframework is scalable due to scenario-based decomposition and automated hint\nextraction. Moreover, our fully automated framework can identify complex bugs\nin actual firmware-hardware implementations.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.08002v2"
    },
    {
        "title": "An F5 Algorithm for Tropical Gröbner Bases in the Weyl Algebras",
        "authors": [
            "Ari Dwi Hartanto",
            "Katsuyoshi Ohara"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  A Gr\\\"obner basis computation for the Weyl algebra with respect to a tropical\nterm order and by using a homogenization-dehomogenization technique is\nsufficiently sluggish. A significant number of reductions to zero occur. To\nimprove the computation, a tropical F5 algorithm is developed for this context.\nAs a member of the family of signature-based algorithms, this algorithm keeps\ntrack of where Weyl algebra elements come from to anticipate reductions to\nzero. The total order for ordering module monomials or signatures in this paper\nis designed as close as possible to the definition of the tropical term order.\nAs in Vaccon et al. (2021), this total order is not compatible with the\ntropical term order.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14419v1"
    },
    {
        "title": "Iterated Resultants and Rational Functions in Real Quantifier\n  Elimination",
        "authors": [
            "James H. Davenport",
            "Matthew England",
            "Scott McCallum",
            "Ali K. Uncu"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper builds and extends on the authors' previous work related to the\nalgorithmic tool, Cylindrical Algebraic Decomposition (CAD), and one of its\ncore applications, Real Quantifier Elimination (QE). These topics are at the\nheart of symbolic computation and were first implemented in computer algebra\nsystems decades ago, but have recently received renewed interest as part of the\nongoing development of SMT solvers for non-linear real arithmetic.\n  First, we consider the use of iterated univariate resultants in traditional\nCAD, and how this leads to inefficiencies, especially in the case of an input\nwith multiple equational constraints. We reproduce the workshop paper\n[Davenport and England, 2023], adding important clarifications to our\nsuggestions first made there to make use of multivariate resultants in the\nprojection phase of CAD. We then consider an alternative approach to this\nproblem first documented in [McCallum and Brown, 2009] which redefines the\nactual object under construction, albeit only in the case of two equational\nconstraints. We correct an unhelpful typo and provide a proof missing from that\npaper.\n  We finish by revising the topic of how to deal with SMT or Real QE problems\nexpressed using rational functions (as opposed to the usual polynomial ones)\nnoting that these are often found in industrial applications. We revisit a\nproposal made in [Uncu, Davenport and England, 2023] for doing this in the case\nof satisfiability, explaining why such an approach does not trivially extend to\nmore complicated quantification structure and giving a suitable alternative.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.16210v2"
    },
    {
        "title": "Factoring sparse polynomials fast",
        "authors": [
            "Alexander Demin",
            "Joris van der Hoeven"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Consider a sparse polynomial in several variables given explicitly as a sum\nof non-zero terms with coefficients in an effective field. In this paper, we\npresent several algorithms for factoring such polynomials and related tasks\n(such as gcd computation, square-free factorization, content-free\nfactorization, and root extraction). Our methods are all based on sparse\ninterpolation, but follow two main lines of attack: iteration on the number of\nvariables and more direct reductions to the univariate or bivariate case. We\npresent detailed probabilistic complexity bounds in terms of the complexity of\nsparse interpolation and evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.17380v1"
    },
    {
        "title": "Fast interpolation of sparse multivariate polynomials",
        "authors": [
            "Joris van der Hoeven",
            "Grégoire Lecerf"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Consider a sparse multivariate polynomial f with integer coefficients. Assume\nthat f is represented as a \"modular black box polynomial\", e.g. via an\nalgorithm to evaluate f at arbitrary integer points, modulo arbitrary positive\nintegers. The problem of sparse interpolation is to recover f in its usual\nsparse representation, as a sum of coefficients times monomials. For the first\ntime we present a quasi-optimal algorithm for this task.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.17664v1"
    },
    {
        "title": "Persistent components in Canny's Generalized Characteristic Polynomial",
        "authors": [
            "Gleb Pogudin"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  When using resultants for elimination, one standard issue is that the\nresultant vanishes if the variety contains components of dimension larger than\nthe expected dimension. J. Canny proposed an elegant construction, generalized\ncharacteristic polynomial, to address this issue by symbolically perturbing the\nsystem before the resultant computation. Such perturbed resultant would\ntypically involve artefact components only loosely related to the geometry of\nthe variety of interest. For removing these components, J.M. Rojas proposed to\ntake the greatest common divisor of the results of two different perturbations.\nIn this paper, we investigate this construction, and show that the extra\ncomponents persistent under taking different perturbations must come either\nfrom singularities or from positive-dimensional fibers.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.01948v2"
    },
    {
        "title": "Computation of classical and $v$-adic $L$-series of $t$-motives",
        "authors": [
            "Xavier Caruso",
            "Quentin Gazda"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We design an algorithm for computing the $L$-series associated to an Anderson\n$t$-motives, exhibiting quasilinear complexity with respect to the target\nprecision. Based on experiments, we conjecture that the order of vanishing at\n$T=1$ of the $v$-adic $L$-series of a given Anderson $t$-motive with good\nreduction does not depend on the finite place $v$.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12618v1"
    },
    {
        "title": "Lessons on Datasets and Paradigms in Machine Learning for Symbolic\n  Computation: A Case Study on CAD",
        "authors": [
            "Tereso del Río",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Symbolic Computation algorithms and their implementation in computer algebra\nsystems often contain choices which do not affect the correctness of the output\nbut can significantly impact the resources required: such choices can benefit\nfrom having them made separately for each problem via a machine learning model.\nThis study reports lessons on such use of machine learning in symbolic\ncomputation, in particular on the importance of analysing datasets prior to\nmachine learning and on the different machine learning paradigms that may be\nutilised. We present results for a particular case study, the selection of\nvariable ordering for cylindrical algebraic decomposition, but expect that the\nlessons learned are applicable to other decisions in symbolic computation.\n  We utilise an existing dataset of examples derived from applications which\nwas found to be imbalanced with respect to the variable ordering decision. We\nintroduce an augmentation technique for polynomial systems problems that allows\nus to balance and further augment the dataset, improving the machine learning\nresults by 28\\% and 38\\% on average, respectively. We then demonstrate how the\nexisting machine learning methodology used for the problem $-$ classification\n$-$ might be recast into the regression paradigm. While this does not have a\nradical change on the performance, it does widen the scope in which the\nmethodology can be applied to make choices.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.13343v2"
    },
    {
        "title": "Computing roadmaps in unbounded smooth real algebraic sets II: algorithm\n  and complexity",
        "authors": [
            "Rémi Prébet",
            "Mohab Safey El Din",
            "Éric Schost"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  A roadmap for an algebraic set $V$ defined by polynomials with coefficients\nin some real field, say $\\mathbb{R}$, is an algebraic curve contained in $V$\nwhose intersection with all connected components of $V\\cap\\mathbb{R}^{n}$ is\nconnected. These objects, introduced by Canny, can be used to answer\nconnectivity queries over $V\\cap \\mathbb{R}^{n}$ provided that they are\nrequired to contain the finite set of query points $\\mathcal{P}\\subset V$; in\nthis case,we say that the roadmap is associated to $(V, \\mathcal{P})$.\n  In this paper, we make effective a connectivity result we previously proved,\nto design a Monte Carlo algorithm which, on input (i) a finite sequence of\npolynomials defining $V$ (and satisfying some regularity assumptions) and (ii)\nan algebraic representation of finitely many query points $\\mathcal{P}$ in $V$,\ncomputes a roadmap for $(V, \\mathcal{P})$. This algorithm generalizes the\nnearly optimal one introduced by the last two authors by dropping a boundedness\nassumption on the real trace of $V$.\n  The output size and running times of our algorithm are both polynomial in\n$(nD)^{n\\log d}$, where $D$ is the maximal degree of the input equations and\n$d$ is the dimension of $V$. As far as we know, the best previously known\nalgorithm dealing with such sets has an output size and running time polynomial\nin $(nD)^{n\\log^2 n}$.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.03111v1"
    },
    {
        "title": "Computing Generic Fibers of Polynomial Ideals with FGLM and Hensel\n  Lifting",
        "authors": [
            "Jérémy Berthomieu",
            "Rafael Mohr"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We describe a version of the FGLM algorithm that can be used to compute\ngeneric fibers of positive-dimensional polynomial ideals. It combines the FGLM\nalgorithm with a Hensel lifting strategy. In analogy with Hensel lifting, we\nshow that this algorithm has a complexity quasi-linear in the number of terms\nof certain $\\mathfrak{m}$-adic expansions we compute. Some provided\nexperimental data also demonstrates the practical efficacy of our algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.03144v2"
    },
    {
        "title": "Factorial Basis Method for q-Series Applications",
        "authors": [
            "Antonio Jiménez-Pastor",
            "Ali Kemal Uncu"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  The Factorial Basis method, initially designed for quasi-triangular,\nshift-compatible factorial bases, provides solutions to linear recurrence\nequations in the form of definite-sums. This paper extends the Factorial Basis\nmethod to its q-analog, enabling its application in q-calculus. We demonstrate\nthe adaptation of the method to q-sequences and its utility in the realm of\nq-combinatorics. The extended technique is employed to automatically prove\nestablished identities and unveil novel ones, particularly some associated with\nthe Rogers-Ramanujan identities.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.04392v1"
    },
    {
        "title": "Reading Rational Univariate Representations on lexicographic Groebner\n  bases",
        "authors": [
            "Alexander Demin",
            "Fabrice Rouillier",
            "Joao Ruiz"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In this contribution, we consider a zero-dimensional polynomial system in $n$\nvariables defined over a field $\\mathbb{K}$. In the context of computing a\nRational Univariate Representation (RUR) of its solutions, we address the\nproblem of certifying a separating linear form and, once certified, calculating\nthe RUR that comes from it, without any condition on the ideal else than being\nzero-dimensional. Our key result is that the RUR can be read (closed formula)\nfrom lexicographic Groebner bases of bivariate elimination ideals, even in the\ncase where the original ideal that is not in shape position, so that one can\nuse the same core as the well known FGLM method to propose a simple algorithm.\nOur first experiments, either with a very short code (300 lines) written in\nMaple or with a Julia code using straightforward implementations performing\nonly classical Gaussian reductions in addition to Groebner bases for the degree\nreverse lexicographic ordering, show that this new method is already\ncompetitive with sophisticated state of the art implementations which do not\ncertify the parameterizations.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07141v1"
    },
    {
        "title": "Optimized Gröbner basis algorithms for maximal determinantal ideals\n  and critical point computations",
        "authors": [
            "Sriram Gopalakrishnan",
            "Vincent Neiger",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Given polynomials $g$ and $f_1,\\dots,f_p$, all in $\\Bbbk[x_1,\\dots,x_n]$ for\nsome field $\\Bbbk$, we consider the problem of computing the critical points of\nthe restriction of $g$ to the variety defined by $f_1=\\cdots=f_p=0$. These are\ndefined by the simultaneous vanishing of the $f_i$'s and all maximal minors of\nthe Jacobian matrix associated to $(g,f_1, \\ldots, f_p)$. We use the\nEagon-Northcott complex associated to the ideal generated by these maximal\nminors to gain insight into the syzygy module of the system defining these\ncritical points. We devise new $F_5$-type criteria to predict and avoid more\nreductions to zero when computing a Gr\\\"obner basis for the defining system of\nthis critical locus. We give a bound for the arithmetic complexity of this\nenhanced $F_5$ algorithm and compare it to the best previously known bound for\ncomputing critical points using Gr\\\"obner bases.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07353v1"
    },
    {
        "title": "Solving parameter-dependent semi-algebraic systems",
        "authors": [
            "Louis Gaillard",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We consider systems of polynomial equations and inequalities in\n$\\mathbb{Q}[\\boldsymbol{y}][\\boldsymbol{x}]$ where $\\boldsymbol{x} = (x_1,\n\\ldots, x_n)$ and $\\boldsymbol{y} = (y_1, \\ldots,y_t)$. The $\\boldsymbol{y}$\nindeterminates are considered as parameters and we assume that when\nspecialising them generically, the set of common complex solutions, to the\nobtained equations, is finite. We consider the problem of real root\nclassification for such parameter-dependent problems, i.e. identifying the\npossible number of real solutions depending on the values of the parameters and\ncomputing a description of the regions of the space of parameters over which\nthe number of real roots remains invariant.\n  We design an algorithm for solving this problem. The formulas it outputs\nenjoy a determinantal structure. Under genericity assumptions, we show that its\narithmetic complexity is polynomial in both the maximum degree $d$ and the\nnumber $s$ of the input inequalities and exponential in $nt+t^2$. The output\nformulas consist of polynomials of degree bounded by $(2s+n)d^{n+1}$. This is\nthe first algorithm with such a singly exponential complexity. We report on\npractical experiments showing that a first implementation of this algorithm can\ntackle examples which were previously out of reach.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07782v1"
    },
    {
        "title": "Fast interpolation and multiplication of unbalanced polynomials",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray",
            "Daniel S. Roche"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We consider the classical problems of interpolating a polynomial given a\nblack box for evaluation, and of multiplying two polynomials, in the setting\nwhere the bit-lengths of the coefficients may vary widely, so-called unbalanced\npolynomials. Writing s for the total bit-length and D for the degree, our new\nalgorithms have expected running time $\\tilde{O}(s \\log D)$, whereas previous\nmethods for (resp.) dense or sparse arithmetic have at least $\\tilde{O}(sD)$ or\n$\\tilde{O}(s^2)$ bit complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.10139v2"
    },
    {
        "title": "On the arithmetic complexity of computing Gröbner bases of comaximal\n  determinantal ideals",
        "authors": [
            "Sriram Gopalakrishnan"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Let $M$ be an $n\\times n$ matrix of homogeneous linear forms over a field\n$\\Bbbk$. If the ideal $\\mathcal{I}_{n-2}(M)$ generated by minors of size $n-1$\nis Cohen-Macaulay, then the Gulliksen-Neg{\\aa}rd complex is a free resolution\nof $\\mathcal{I}_{n-2}(M)$. It has recently been shown that by taking into\naccount the syzygy modules for $\\mathcal{I}_{n-2}(M)$ which can be obtained\nfrom this complex, one can derive a refined signature-based Gr\\\"obner basis\nalgorithm DetGB which avoids reductions to zero when computing a grevlex\nGr\\\"obner basis for $\\mathcal{I}_{n-2}(M)$. In this paper, we establish sharp\ncomplexity bounds on DetGB. To accomplish this, we prove several results on the\nsizes of reduced grevlex Gr\\\"obner bases of reverse lexicographic ideals,\nthanks to which we obtain two main complexity results which rely on conjectures\nsimilar to that of Fr\\\"oberg. The first one states that, in the\nzero-dimensional case, the size of the reduced grevlex Gr\\\"obner basis of\n$\\mathcal{I}_{n-2}(M)$ is bounded from below by $n^{6}$ asymptotically. The\nsecond, also in the zero-dimensional case, states that the complexity of DetGB\nis bounded from above by $n^{2\\omega+3}$ asymptotically, where $2\\le\\omega\\le\n3$ is any complexity exponent for matrix multiplication over $\\Bbbk$.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.02160v2"
    },
    {
        "title": "Constrained Neural Networks for Interpretable Heuristic Creation to\n  Optimise Computer Algebra Systems",
        "authors": [
            "Dorian Florescu",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We present a new methodology for utilising machine learning technology in\nsymbolic computation research. We explain how a well known human-designed\nheuristic to make the choice of variable ordering in cylindrical algebraic\ndecomposition may be represented as a constrained neural network. This allows\nus to then use machine learning methods to further optimise the heuristic,\nleading to new networks of similar size, representing new heuristics of similar\ncomplexity as the original human-designed one. We present this as a form of\nante-hoc explainability for use in computer algebra development.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17508v1"
    },
    {
        "title": "The Liouville Generator for Producing Integrable Expressions",
        "authors": [
            "Rashid Barket",
            "Matthew England",
            "Jürgen Gerhard"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  There has been a growing need to devise processes that can create\ncomprehensive datasets in the world of Computer Algebra, both for accurate\nbenchmarking and for new intersections with machine learning technology. We\npresent here a method to generate integrands that are guaranteed to be\nintegrable, dubbed the LIOUVILLE method. It is based on Liouville's theorem and\nthe Parallel Risch Algorithm for symbolic integration.\n  We show that this data generation method retains the best qualities of\nprevious data generation methods, while overcoming some of the issues built\ninto that prior work. The LIOUVILLE generator is able to generate sufficiently\ncomplex and realistic integrands, and could be used for benchmarking or machine\nlearning training tasks related to symbolic integration.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11631v1"
    },
    {
        "title": "On the equivalence problem of Smith forms for multivariate polynomial\n  matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao",
            "Xiaopeng Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  This paper delves into the equivalence problem of Smith forms for\nmultivariate polynomial matrices. Generally speaking, multivariate ($n \\geq 2$)\npolynomial matrices and their Smith forms may not be equivalent. However, under\ncertain specific condition, we derive the necessary and sufficient condition\nfor their equivalence. Let $F\\in K[x_1,\\ldots,x_n]^{l\\times m}$ be of rank $r$,\n$d_r(F)\\in K[x_1]$ be the greatest common divisor of all the $r\\times r$ minors\nof $F$, where $K$ is a field, $x_1,\\ldots,x_n$ are variables and $1 \\leq r \\leq\n\\min\\{l,m\\}$. Our key findings reveal the result: $F$ is equivalent to its\nSmith form if and only if all the $i\\times i$ reduced minors of $F$ generate\n$K[x_1,\\ldots,x_n]$ for $i=1,\\ldots,r$.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.06649v1"
    },
    {
        "title": "A SageMath Package for Elementary and Sign Vectors with Applications to\n  Chemical Reaction Networks",
        "authors": [
            "Marcus S. Aichmayr",
            "Stefan Müller",
            "Georg Regensburger"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We present our SageMath package elementary_vectors for computing elementary\nand sign vectors of real subspaces. In this setting, elementary vectors are\nsupport-minimal vectors that can be determined from maximal minors of a real\nmatrix representing a subspace. By applying the sign function, we obtain the\ncocircuits of the corresponding oriented matroid, which in turn allow the\ncomputation of all sign vectors of a real subspace.\n  As an application, we discuss sign vector conditions for existence and\nuniqueness of complex-balanced equilibria of chemical reaction networks with\ngeneralized mass-action kinetics. The conditions are formulated in terms of\nsign vectors of two subspaces arising from the stoichiometric coefficients and\nthe kinetic orders of the reactions. We discuss how these conditions can be\nchecked algorithmically, and we demonstrate the functionality of our package\nsign_vector_conditions in several examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.12660v1"
    },
    {
        "title": "Comprehensive Systems for Primary Decompositions of Parametric Ideals",
        "authors": [
            "Yuki Ishihara",
            "Kazuhiro Yokoyama"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We present an effective method for computing parametric primary decomposition\nvia comprehensive Gr\\\"obner systems. In general, it is very difficult to\ncompute a parametric primary decomposition of a given ideal in the polynomial\nring with rational coefficients $\\mathbb{Q}[A,X]$ where $A$ is the set of\nparameters and $X$ is the set of ordinary variables. One cause of the\ndifficulty is related to the irreducibility of the specialized polynomial.\nThus, we introduce a new notion of ``feasibility'' on the stability of the\nstructure of the ideal in terms of its primary decomposition, and we give a new\nalgorithm for computing a so-called comprehensive system consisting of pairs\n$(C, \\mathcal{Q})$, where for each parameter value in $C$, the ideal has the\nstable decomposition $\\mathcal{Q}$. We may call this comprehensive system a\nparametric primary decomposition of the ideal. Also, one can also compute a\ndense set $\\mathcal{O}$ such that $\\varphi_\\alpha(\\mathcal{Q})$ is a primary\ndecomposition for any $\\alpha\\in C\\cap \\mathcal{O}$ via irreducible\npolynomials. In addition, we give several computational examples to examine the\neffectiveness of our new decomposition.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.15917v1"
    },
    {
        "title": "Integer Polynomial Factorization by Recombination of Real Factors:\n  Re-evaluating an Old Technique in Modern Era",
        "authors": [
            "Shahriar Iravanian"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Polynomial factorization over $ZZ$ is of great historical and practical\nimportance. Currently, the standard technique is to factor the polynomial over\nfinite fields first and then to lift to integers. Factorization over finite\nfields can be done in polynomial time using Berlekamp or Cantor-Zassenhaus\nalgorithms. Lifting from the finite field to $ZZ$ requires a combinatorial\nalgorithm. The van Hoeij algorithm casts the combinatorial problem as a\nknapsack-equivalent problem, which is then solved using lattice-reduction (the\nLLL algorithm) in polynomial time, which is implemented in many computer\nalgebra systems (CAS).\n  In this paper, we revisit the old idea of starting with factorization over\n$RR$ instead of a finite field, followed by recombination of the resulting\nlinear and quadratic factors. We transform the problem into an integer subset\nsum problem, which is then solved using the Horowizt-Sinha algorithm. This\nalgorithm can factor a random integer polynomial of degree $d$ in a time\ncomplexity of $O(2^(d slash 4))$.\n  While the resulting algorithm is exponential, consistent with the integer\nsubset sum problem being in NP, it has a few advantages. First, it is simple\nand easy to implement. Second, it is almost embarrassingly parallelizable. We\ndemonstrate this by implementing the algorithm in a Graphic Processing Unit\n(GPU). The resulting code can factor a degree 100 polynomial is a few tenths of\na second, comparable to some standard CAS. This shows that it is possible to\nuse current hardware, especially massively parallel systems like GPU, to the\nbenefit of symbolic algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.15880v1"
    },
    {
        "title": "On Recurrence Relations of Multi-dimensional Sequences",
        "authors": [
            "Hamid Rahkooy"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In this paper, we present a new algorithm for computing the linear recurrence\nrelations of multi-dimensional sequences. Existing algorithms for computing\nthese relations arise in computational algebra and include constructing\nstructured matrices and computing their kernels. The challenging problem is to\nreduce the size of the corresponding matrices. In this paper, we show how to\nconvert the problem of computing recurrence relations of multi-dimensional\nsequences into computing the orthogonal of certain ideals as subvector spaces\nof the dual module of polynomials. We propose an algorithm using efficient dual\nmodule computation algorithms. We present a complexity bound for this\nalgorithm, carry on experiments using Maple implementation, and discuss the\ncases when using this algorithm is much faster than the existing approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.17208v1"
    },
    {
        "title": "Hahn series and Mahler equations: Algorithmic aspects",
        "authors": [
            "C. Faverjon",
            "Julien Roques"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Many articles have recently been devoted to Mahler equations, partly because\nof their links with other branches of mathematics such as automata theory. Hahn\nseries (a generalization of the Puiseux series allowing arbitrary exponents of\nthe indeterminate as long as the set that supports them is well-ordered) play a\ncentral role in the theory of Mahler equations. In this paper, we address the\nfollowing fundamental question: is there an algorithm to calculate the Hahn\nseries solutions of a given linear Mahler equation? What makes this question\ninteresting is the fact that the Hahn series appearing in this context can have\ncomplicated supports with infinitely many accumulation points. Our (positive)\nanswer to the above question involves among other things the construction of a\ncomputable well-ordered receptacle for the supports of the potential Hahn\nseries solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.04928v1"
    },
    {
        "title": "A semi-algebraic model for automatic loop parallelization",
        "authors": [
            "Changbo Chen"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In this work, we introduce a semi-algebraic model for automatic\nparallelization of perfectly nested polynomial loops, which generalizes the\nclassical polyhedral model. This model supports the basic tasks for automatic\nloop parallelization, such as the representation of the nested loop, the\ndependence analysis, the computation of valid schedules, as well as the\ntransformation of the loop program with a valid schedule.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.19287v1"
    },
    {
        "title": "Factorization of linear partial differential operators and Darboux\n  integrability of nonlinear PDEs",
        "authors": [
            "Serguei P. Tsarev"
        ],
        "category": "cs.SC",
        "published_year": "1998",
        "summary": "  Using a new definition of generalized divisors we prove that the lattice of\nsuch divisors for a given linear partial differential operator is modular and\nobtain analogues of the well-known theorems of the Loewy-Ore theory of\nfactorization of linear ordinary differential operators. Possible applications\nto factorized Groebner bases computations in the commutative and\nnon-commutative cases are discussed, an application to finding criterions of\nDarboux integrability of nonlinear PDEs is given.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9811002v1"
    },
    {
        "title": "Introduction to the GiNaC Framework for Symbolic Computation within the\n  C++ Programming Language",
        "authors": [
            "Christian Bauer",
            "Alexander Frink",
            "Richard Kreckel"
        ],
        "category": "cs.SC",
        "published_year": "2000",
        "summary": "  The traditional split-up into a low level language and a high level language\nin the design of computer algebra systems may become obsolete with the advent\nof more versatile computer languages. We describe GiNaC, a special-purpose\nsystem that deliberately denies the need for such a distinction. It is entirely\nwritten in C++ and the user can interact with it directly in that language. It\nwas designed to provide efficient handling of multivariate polynomials,\nalgebras and special functions that are needed for loop calculations in\ntheoretical quantum field theory. It also bears some potential to become a more\ngeneral purpose symbolic package.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0004015v2"
    },
    {
        "title": "A comparison of four approaches to the calculation of conservation laws",
        "authors": [
            "Thomas Wolf"
        ],
        "category": "cs.SC",
        "published_year": "2003",
        "summary": "  The paper compares computational aspects of four approaches to compute\nconservation laws of single differential equations (DEs) or systems of them,\nODEs and PDEs. The only restriction, required by two of the four corresponding\ncomputer algebra programs, is that each DE has to be solvable for a leading\nderivative. Extra constraints for the conservation laws can be specified.\nExamples include new conservation laws that are non-polynomial in the\nfunctions, that have an explicit variable dependence and families of\nconservation laws involving arbitrary functions. The following equations are\ninvestigated in examples: Ito, Liouville, Burgers, Kadomtsev-Petviashvili,\nKarney-Sen-Chu-Verheest, Boussinesq, Tzetzeica, Benney.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0301027v2"
    },
    {
        "title": "Polynomial-time computing over quadratic maps I: sampling in real\n  algebraic sets",
        "authors": [
            "Dima Grigoriev",
            "Dmitrii V. Pasechnik"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  Given a quadratic map Q : K^n -> K^k defined over a computable subring D of a\nreal closed field K, and a polynomial p(Y_1,...,Y_k) of degree d, we consider\nthe zero set Z=Z(p(Q(X)),K^n) of the polynomial p(Q(X_1,...,X_n)). We present a\nprocedure that computes, in (dn)^O(k) arithmetic operations in D, a set S of\n(real univariate representations of) sampling points in K^n that intersects\nnontrivially each connected component of Z. As soon as k=o(n), this is faster\nthan the standard methods that all have exponential dependence on n in the\ncomplexity. In particular, our procedure is polynomial-time for constant k. In\ncontrast, the best previously known procedure (due to A.Barvinok) is only\ncapable of deciding in n^O(k^2) operations the nonemptiness (rather than\nconstructing sampling points) of the set Z in the case of p(Y)=sum_i Y_i^2 and\nhomogeneous Q.\n  A by-product of our procedure is a bound (dn)^O(k) on the number of connected\ncomponents of Z.\n  The procedure consists of exact symbolic computations in D and outputs\nvectors of algebraic numbers. It involves extending K by infinitesimals and\nsubsequent limit computation by a novel procedure that utilizes knowledge of an\nexplicit isomorphism between real algebraic sets.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0403008v3"
    },
    {
        "title": "ParFORM: Parallel Version of the Symbolic Manipulation Program FORM",
        "authors": [
            "M. Tentyukov",
            "D. Fliegner",
            "M. Frank",
            "A. Onischenko",
            "A. Retey",
            "H. M. Staudenmaier",
            "J. A. M. Vermaseren"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  After an introduction to the sequential version of FORM and the mechanisms\nbehind, we report on the status of our project of parallelization. We have now\na parallel version of FORM running on Cluster- and SMP-architectures. This\nversion can be used to run arbitrary FORM programs in parallel.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0407066v1"
    },
    {
        "title": "Free quasi-symmetric functions, product actions and quantum field theory\n  of partitions",
        "authors": [
            "Gerard Henry Edmond Duchamp",
            "Jean-Gabriel Luque",
            "Karol A. Penson",
            "Christophe Tollu"
        ],
        "category": "cs.SC",
        "published_year": "2004",
        "summary": "  We examine two associative products over the ring of symmetric functions\nrelated to the intransitive and Cartesian products of permutation groups. As an\napplication, we give an enumeration of some Feynman type diagrams arising in\nBender's QFT of partitions. We end by exploring possibilities to construct\nnoncommutative analogues.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0412061v1"
    },
    {
        "title": "Generalized Laplace transformations and integration of hyperbolic\n  systems of linear partial differential equations",
        "authors": [
            "Sergey P. Tsarev"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  We give a new procedure for generalized factorization and construction of the\ncomplete solution of strictly hyperbolic linear partial differential equations\nor strictly hyperbolic systems of such equations in the plane. This procedure\ngeneralizes the classical theory of Laplace transformations of second-order\nequations in the plane.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0501030v1"
    },
    {
        "title": "Approximation of dynamical systems using S-systems theory : application\n  to biological systems",
        "authors": [
            "Laurent Tournier"
        ],
        "category": "cs.SC",
        "published_year": "2005",
        "summary": "  In this paper we propose a new symbolic-numeric algorithm to find positive\nequilibria of a n-dimensional dynamical system. This algorithm implies a\nsymbolic manipulation of ODE in order to give a local approximation of\ndifferential equations with power-law dynamics (S-systems). A numerical\ncalculus is then needed to converge towards an equilibrium, giving at the same\ntime a S-system approximating the initial system around this equilibrium. This\nalgorithm is applied to a real biological example in 14 dimensions which is a\nsubsystem of a metabolic pathway in Arabidopsis Thaliana.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0503008v1"
    },
    {
        "title": "A field-theory motivated approach to symbolic computer algebra",
        "authors": [
            "Kasper Peeters"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  Field theory is an area in physics with a deceptively compact notation.\nAlthough general purpose computer algebra systems, built around generic\nlist-based data structures, can be used to represent and manipulate\nfield-theory expressions, this often leads to cumbersome input formats,\nunexpected side-effects, or the need for a lot of special-purpose code. This\nmakes a direct translation of problems from paper to computer and back\nneedlessly time-consuming and error-prone. A prototype computer algebra system\nis presented which features TeX-like input, graph data structures, lists with\nYoung-tableaux symmetries and a multiple-inheritance property system. The\nusefulness of this approach is illustrated with a number of explicit\nfield-theory problems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0608005v2"
    },
    {
        "title": "Explicit factors of some iterated resultants and discriminants",
        "authors": [
            "Laurent Busé",
            "Bernard Mourrain"
        ],
        "category": "cs.SC",
        "published_year": "2006",
        "summary": "  In this paper, the result of applying iterative univariate resultant\nconstructions to multivariate polynomials is analyzed. We consider the input\npolynomials as generic polynomials of a given degree and exhibit explicit\ndecompositions into irreducible factors of several constructions involving two\ntimes iterated univariate resultants and discriminants over the integer\nuniversal ring of coefficients of the entry polynomials. Cases involving from\ntwo to four generic polynomials and resultants or discriminants in one of their\nvariables are treated. The decompositions into irreducible factors we get are\nobtained by exploiting fundamental properties of the univariate resultants and\ndiscriminants and induction on the degree of the polynomials. As a consequence,\neach irreducible factor can be separately and explicitly computed in terms of a\ncertain multivariate resultant. With this approach, we also obtain as direct\ncorollaries some results conjectured by Collins and McCallum which correspond\nto the case of polynomials whose coefficients are themselves generic\npolynomials in other variables. Finally, a geometric interpretation of the\nalgebraic factorization of the iterated discriminant of a single polynomial is\ndetailled.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0612050v2"
    },
    {
        "title": "The Invar Tensor Package",
        "authors": [
            "Jose M. Martin-Garcia",
            "Renato Portugal",
            "Leon R. U. Manssur"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  The Invar package is introduced, a fast manipulator of generic scalar\npolynomial expressions formed from the Riemann tensor of a four-dimensional\nmetric-compatible connection. The package can maximally simplify any polynomial\ncontaining tensor products of up to seven Riemann tensors within seconds. It\nhas been implemented both in Mathematica and Maple algebraic systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.1756v1"
    },
    {
        "title": "Tropical Implicitization and Mixed Fiber Polytopes",
        "authors": [
            "Bernd Sturmfels",
            "Josephine Yu"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  The software TrIm offers implementations of tropical implicitization and\ntropical elimination, as developed by Tevelev and the authors. Given a\npolynomial map with generic coefficients, TrIm computes the tropical variety of\nthe image. When the image is a hypersurface, the output is the Newton polytope\nof the defining polynomial. TrIm can thus be used to compute mixed fiber\npolytopes, including secondary polytopes.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.0564v2"
    },
    {
        "title": "Computer algebra in systems biology",
        "authors": [
            "Reinhard Laubenbacher",
            "Bernd Sturmfels"
        ],
        "category": "cs.SC",
        "published_year": "2007",
        "summary": "  Systems biology focuses on the study of entire biological systems rather than\non their individual components. With the emergence of high-throughput data\ngeneration technologies for molecular biology and the development of advanced\nmathematical modeling techniques, this field promises to provide important new\ninsights. At the same time, with the availability of increasingly powerful\ncomputers, computer algebra has developed into a useful tool for many\napplications. This article illustrates the use of computer algebra in systems\nbiology by way of a well-known gene regulatory network, the Lac Operon in the\nbacterium E. coli.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.4248v2"
    },
    {
        "title": "The Invar tensor package: Differential invariants of Riemann",
        "authors": [
            "Jose M. Martin-Garcia",
            "David Yllanes",
            "Renato Portugal"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  The long standing problem of the relations among the scalar invariants of the\nRiemann tensor is computationally solved for all 6x10^23 objects with up to 12\nderivatives of the metric. This covers cases ranging from products of up to 6\nundifferentiated Riemann tensors to cases with up to 10 covariant derivatives\nof a single Riemann. We extend our computer algebra system Invar to produce\nwithin seconds a canonical form for any of those objects in terms of a basis.\nThe process is as follows: (1) an invariant is converted in real time into a\ncanonical form with respect to the permutation symmetries of the Riemann\ntensor; (2) Invar reads a database of more than 6x10^5 relations and applies\nthose coming from the cyclic symmetry of the Riemann tensor; (3) then applies\nthe relations coming from the Bianchi identity, (4) the relations coming from\ncommutations of covariant derivatives, (5) the dimensionally-dependent\nidentities for dimension 4, and finally (6) simplifies invariants that can be\nexpressed as product of dual invariants. Invar runs on top of the tensor\ncomputer algebra systems xTensor (for Mathematica) and Canon (for Maple).\n",
        "pdf_link": "http://arxiv.org/pdf/0802.1274v1"
    },
    {
        "title": "xPerm: fast index canonicalization for tensor computer algebra",
        "authors": [
            "Jose M. Martin-Garcia"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We present a very fast implementation of the Butler-Portugal algorithm for\nindex canonicalization with respect to permutation symmetries. It is called\nxPerm, and has been written as a combination of a Mathematica package and a C\nsubroutine. The latter performs the most demanding parts of the computations\nand can be linked from any other program or computer algebra system. We\ndemonstrate with tests and timings the effectively polynomial performance of\nthe Butler-Portugal algorithm with respect to the number of indices, though we\nalso show a case in which it is exponential. Our implementation handles generic\ntensorial expressions with several dozen indices in hundredths of a second, or\none hundred indices in a few seconds, clearly outperforming all other current\ncanonicalizers. The code has been already under intensive testing for several\nyears and has been essential in recent investigations in large-scale tensor\ncomputer algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.0862v1"
    },
    {
        "title": "A Refined Difference Field Theory for Symbolic Summation",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  In this article we present a refined summation theory based on Karr's\ndifference field approach. The resulting algorithms find sum representations\nwith optimal nested depth. For instance, the algorithms have been applied\nsuccessively to evaluate Feynman integrals from Perturbative Quantum Field\nTheory.\n",
        "pdf_link": "http://arxiv.org/pdf/0808.2543v1"
    },
    {
        "title": "Parameterized Telescoping Proves Algebraic Independence of Sums",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  Usually creative telescoping is used to derive recurrences for sums. In this\narticle we show that the non-existence of a creative telescoping solution, and\nmore generally, of a parameterized telescoping solution, proves algebraic\nindependence of certain types of sums. Combining this fact with\nsummation-theory shows transcendence of whole classes of sums. Moreover, this\nresult throws new light on the question why, e.g., Zeilberger's algorithm fails\nto find a recurrence with minimal order.\n",
        "pdf_link": "http://arxiv.org/pdf/0808.2596v1"
    },
    {
        "title": "Rational Hadamard products via Quantum Diagonal Operators",
        "authors": [
            "Gérard Henry Edmond Duchamp",
            "Silvia Goodenough",
            "Karol A. Penson"
        ],
        "category": "cs.SC",
        "published_year": "2008",
        "summary": "  We use the remark that, through Bargmann-Fock representation, diagonal\noperators of the Heisenberg-Weyl algebra are scalars for the Hadamard product\nto give some properties (like the stability of periodic fonctions) of the\nHadamard product by a rational fraction. In particular, we provide through this\nway explicit formulas for the multiplication table of the Hadamard product in\nthe algebra of rational functions in $\\C[[z]]$.\n",
        "pdf_link": "http://arxiv.org/pdf/0810.3641v1"
    },
    {
        "title": "Some Open Problems in Combinatorial Physics",
        "authors": [
            "Gérard Henry Edmond Duchamp",
            "H. Cheballah"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We point out four problems which have arisen during the recent research in\nthe domain of Combinatorial Physics.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.2612v1"
    },
    {
        "title": "The acoustic wave equation in the expanding universe. Sachs-Wolfe\n  theorem",
        "authors": [
            "Wojciech Czaja",
            "Zdzislaw A. Golda",
            "Andrzej Woszczyna"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  In this paper the acoustic field propagating in the early hot ($p=\\epsilon/$)\nuniverse of arbitrary space curvature ($K=0, \\pm 1$) is considered. The field\nequations are reduced to the d'Alembert equation in an auxiliary static\nRoberson-Walker space-time. Symbolic computation in {\\em Mathematica} is\napplied.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.0239v3"
    },
    {
        "title": "Combinatorial Deformations of Algebras: Twisting and Perturbations",
        "authors": [
            "Gérard Henry Edmond Duchamp",
            "Christophe Tollu",
            "K. A. Penson",
            "Gleb Koshevoy"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  The framework used to prove the multiplicative law deformation of the algebra\nof Feynman-Bender diagrams is a \\textit{twisted shifted dual law} (in fact,\ntwice). We give here a clear interpretation of its two parameters. The crossing\nparameter is a deformation of the tensor structure whereas the superposition\nparameters is a perturbation of the shuffle coproduct of Hoffman type which, in\nturn, can be interpreted as the diagonal restriction of a superproduct. Here,\nwe systematically detail these constructions.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.2101v2"
    },
    {
        "title": "A Symbolic Summation Approach to Find Optimal Nested Sum Representations",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2009",
        "summary": "  We consider the following problem: Given a nested sum expression, find a sum\nrepresentation such that the nested depth is minimal. We obtain a symbolic\nsummation framework that solves this problem for sums defined, e.g., over\nhypergeometric, $q$-hypergeometric or mixed hypergeometric expressions.\nRecently, our methods have found applications in quantum field theory.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.2323v1"
    },
    {
        "title": "Holonomic Gradient Descent and its Application to Fisher-Bingham\n  Integral",
        "authors": [
            "Tomonari Sei",
            "Nobuki Takayama",
            "Akimichi Takemura",
            "Hiromasa Nakayama",
            "Kenta Nishiyama",
            "Masayuki Noro",
            "Katsuyoshi Ohara"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We give a new algorithm to find local maximum and minimum of a holonomic\nfunction and apply it for the Fisher-Bingham integral on the sphere $S^n$,\nwhich is used in the directional statistics. The method utilizes the theory and\nalgorithms of holonomic systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.5273v2"
    },
    {
        "title": "Pattern Classification In Symbolic Streams via Semantic Annihilation of\n  Information",
        "authors": [
            "Ishanu Chattopadhyay",
            "Yicheng Wen",
            "Asok Ray"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  We propose a technique for pattern classification in symbolic streams via\nselective erasure of observed symbols, in cases where the patterns of interest\nare represented as Probabilistic Finite State Automata (PFSA). We define an\nadditive abelian group for a slightly restricted subset of probabilistic finite\nstate automata (PFSA), and the group sum is used to formulate pattern-specific\nsemantic annihilators. The annihilators attempt to identify pre-specified\npatterns via removal of essentially all inter-symbol correlations from observed\nsequences, thereby turning them into symbolic white noise. Thus a perfect\nannihilation corresponds to a perfect pattern match. This approach of\nclassification via information annihilation is shown to be strictly\nadvantageous, with theoretical guarantees, for a large class of PFSA models.\nThe results are supported by simulation experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.3667v1"
    },
    {
        "title": "Detecting Simultaneous Integer Relations for Several Real Vectors",
        "authors": [
            "Jingwei Chen",
            "Yong Feng",
            "Xiaolin Qin",
            "Jingzhong Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  An algorithm which either finds an nonzero integer vector ${\\mathbf m}$ for\ngiven $t$ real $n$-dimensional vectors ${\\mathbf x}_1,...,{\\mathbf x}_t$ such\nthat ${\\mathbf x}_i^T{\\mathbf m}=0$ or proves that no such integer vector with\nnorm less than a given bound exists is presented in this paper. The cost of the\nalgorithm is at most ${\\mathcal O}(n^4 + n^3 \\log \\lambda(X))$ exact arithmetic\noperations in dimension $n$ and the least Euclidean norm $\\lambda(X)$ of such\ninteger vectors. It matches the best complexity upper bound known for this\nproblem. Experimental data show that the algorithm is better than an already\nexisting algorithm in the literature. In application, the algorithm is used to\nget a complete method for finding the minimal polynomial of an unknown complex\nalgebraic number from its approximation, which runs even faster than the\ncorresponding \\emph{Maple} built-in function.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.1982v1"
    },
    {
        "title": "Methods in Mathematica for Solving Ordinary Differential Equations",
        "authors": [
            "Ünal Göktaş",
            "Devendra Kapadia"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  An overview of the solution methods for ordinary differential equations in\nthe Mathematica function DSolve is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.4025v1"
    },
    {
        "title": "Symbolic Computation of Recursion Operators for Nonlinear\n  Differential-Difference equations",
        "authors": [
            "Ünal Göktaş",
            "Willy Hereman"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  An algorithm for the symbolic computation of recursion operators for systems\nof nonlinear differential-difference equations (DDEs) is presented. Recursion\noperators allow one to generate an infinite sequence of generalized symmetries.\nThe existence of a recursion operator therefore guarantees the complete\nintegrability of the DDE. The algo-rithm is based in part on the concept of\ndilation invariance and uses our earlier algorithms for the symbolic\ncomputation of conservation laws and generalized symmetries.\n  The algorithm has been applied to a number of well-known DDEs, including the\nKac-van Moerbeke (Volterra), Toda, and Ablowitz-Ladik lattices, for which\nrecursion opera-tors are shown. The algorithm has been implemented in\nMathematica, a leading com-puter algebra system. The package\nDDERecursionOperator.m is briefly discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.4026v1"
    },
    {
        "title": "A New General-Purpose Method to Multiply 3x3 Matrices Using Only 23\n  Multiplications",
        "authors": [
            "Nicolas T. Courtois",
            "Gregory V. Bard",
            "Daniel Hulme"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  One of the most famous conjectures in computer algebra is that matrix\nmultiplication might be feasible in not much more than quadratic time. The best\nknown exponent is 2.376, due to Coppersmith and Winograd. Many attempts to\nsolve this problems in the literature work by solving, fixed-size problems and\nthen apply the solution recursively. This leads to pure combinatorial\noptimisation problems with fixed size. These problems are unlikely to be\nsolvable in polynomial time.\n  In 1976 Laderman published a method to multiply two 3x3 matrices using only\n23 multiplications. This result is non-commutative, and therefore can be\napplied recursively to smaller sub-matrices. In 35 years nobody was able to do\nbetter and it remains an open problem if this can be done with 22\nmultiplications. We proceed by solving the so called Brent equations [7]. We\nhave implemented a method to converting this very hard problem to a SAT\nproblem, and we have attempted to solve it, with our portfolio of some 500 SAT\nsolvers. With this new method we were able to produce new solutions to the\nLaderman's problem. We present a new fully general non-commutative solution\nwith 23 multiplications and show that this solution is new and is NOT an\nequivalent variant of the Laderman's original solution. This result\ndemonstrates that the space of solutions to Laderman's problem is larger than\nexpected, and therefore it becomes now more plausible that a solution with 22\nmultiplications exists. If it exists, we might be able to find it soon just by\nrunning our algorithms longer, or due to further improvements in the SAT solver\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.2830v3"
    },
    {
        "title": "Improvement Of Barreto-Voloch Algorithm For Computing $r$th Roots Over\n  Finite Fields",
        "authors": [
            "Zhengjun Cao",
            "Xiao Fan"
        ],
        "category": "cs.SC",
        "published_year": "2011",
        "summary": "  Root extraction is a classical problem in computers algebra. It plays an\nessential role in cryptosystems based on elliptic curves. In 2006, Barreto and\nVoloch proposed an algorithm to compute $r$th roots in ${F}_{q^m} $ for certain\nchoices of $m$ and $q$. If $r\\,||\\,q-1$ and $ (m, r)=1, $ they proved that the\ncomplexity of their method is $\\widetilde{\\mathcal {O}}(r(\\log m+\\log\\log\nq)m\\log q) $. In this paper, we extend the Barreto-Voloch algorithm to the\ngeneral case that $r\\,||\\,q^m-1$, without the restrictions $r\\,||\\,q-1$ and\n$(m, r)=1 $. We also specify the conditions that the Barreto-Voloch algorithm\ncan be preferably applied.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.4801v1"
    },
    {
        "title": "A polynomial time algorithm for computing the HNF of a module over the\n  integers of a number field",
        "authors": [
            "Jean-François Biasse",
            "Claus Fieker"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We present a variation of the modular algorithm for computing the Hermite\nNormal Form of an $\\OK$-module presented by Cohen, where $\\OK$ is the ring of\nintegers of a number field K. The modular strategy was conjectured to run in\npolynomial time by Cohen, but so far, no such proof was available in the\nliterature. In this paper, we provide a new method to prevent the coefficient\nexplosion and we rigorously assess its complexity with respect to the size of\nthe input and the invariants of the field K.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.1298v1"
    },
    {
        "title": "An efficient implementation of the algorithm computing the Borel-fixed\n  points of a Hilbert scheme",
        "authors": [
            "Paolo Lella"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Borel-fixed ideals play a key role in the study of Hilbert schemes. Indeed\neach component and each intersection of components of a Hilbert scheme contains\nat least one Borel-fixed point, i.e. a point corresponding to a subscheme\ndefined by a Borel-fixed ideal. Moreover Borel-fixed ideals have good\ncombinatorial properties, which make them very interesting in an algorithmic\nperspective. In this paper, we propose an implementation of the algorithm\ncomputing all the saturated Borel-fixed ideals with number of variables and\nHilbert polynomial assigned, introduced from a theoretical point of view in the\npaper \"Segment ideals and Hilbert schemes of points\", Discrete Mathematics 311\n(2011).\n",
        "pdf_link": "http://arxiv.org/pdf/1205.0456v1"
    },
    {
        "title": "Quasi-Stability versus Genericity",
        "authors": [
            "Amir Hashemi",
            "Michael Schweinfurter",
            "Werner M. Seiler"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Quasi-stable ideals appear as leading ideals in the theory of Pommaret bases.\nWe show that quasi-stable leading ideals share many of the properties of the\ngeneric initial ideal. In contrast to genericity, quasi-stability is a\ncharacteristic independent property that can be effectively verified. We also\nrelate Pommaret bases to some invariants associated with local cohomology,\nexhibit the existence of linear quotients in Pommaret bases and prove some\nresults on componentwise linear ideals.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.6671v1"
    },
    {
        "title": "Comprehensive Involutive Systems",
        "authors": [
            "Vladimir Gerdt",
            "Amir Hashemi"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  In this paper, we consider parametric ideals and introduce a notion of\ncomprehensive involutive system. This notion plays the same role in theory of\ninvolutive bases as the notion of comprehensive Groebner system in theory of\nGroebner bases. Given a parametric ideal, the space of parameters is decomposed\ninto a finite set of cells. Each cell yields the corresponding involutive basis\nof the ideal for the values of parameters in that cell. Using the Gerdt-Blinkov\nalgorithm for computing involutive bases and also the Montes algorithm for\ncomputing comprehensive Groebner systems, we present an algorithm for\nconstruction of comprehensive involutive systems. The proposed algorithm has\nbeen implemented in Maple, and we provide an illustrative example showing the\nstep-by-step construction of comprehensive involutive system by our algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0181v2"
    },
    {
        "title": "Improving multivariate Horner schemes with Monte Carlo tree search",
        "authors": [
            "J. Kuipers",
            "J. A. M. Vermaseren",
            "A. Plaat",
            "H. J. van den Herik"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Optimizing the cost of evaluating a polynomial is a classic problem in\ncomputer science. For polynomials in one variable, Horner's method provides a\nscheme for producing a computationally efficient form. For multivariate\npolynomials it is possible to generalize Horner's method, but this leaves\nfreedom in the order of the variables. Traditionally, greedy schemes like\nmost-occurring variable first are used. This simple textbook algorithm has\ngiven remarkably efficient results. Finding better algorithms has proved\ndifficult. In trying to improve upon the greedy scheme we have implemented\nMonte Carlo tree search, a recent search method from the field of artificial\nintelligence. This results in better Horner schemes and reduces the cost of\nevaluating polynomials, sometimes by factors up to two.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.7079v1"
    },
    {
        "title": "Generic Regular Decompositions for Parametric Polynomial Systems",
        "authors": [
            "Zhenghong Chen",
            "Xiaoxian Tang",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  This paper presents a generalization of our earlier work in [19]. In this\npaper, the two concepts, generic regular decomposition (GRD) and\nregular-decomposition-unstable (RDU) variety introduced in [19] for generic\nzero-dimensional systems, are extended to the case where the parametric systems\nare not necessarily zero-dimensional. An algorithm is provided to compute GRDs\nand the associated RDU varieties of parametric systems simultaneously on the\nbasis of the algorithm for generic zero-dimensional systems proposed in [19].\nThen the solutions of any parametric system can be represented by the solutions\nof finitely many regular systems and the decomposition is stable at any\nparameter value in the complement of the associated RDU variety of the\nparameter space. The related definitions and the results presented in [19] are\nalso generalized and a further discussion on RDU varieties is given from an\nexperimental point of view. The new algorithm has been implemented on the basis\nof DISCOVERER with Maple 16 and experimented with a number of benchmarks from\nthe literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.3991v1"
    },
    {
        "title": "Introduction to Redberry: a computer algebra system designed for tensor\n  manipulation",
        "authors": [
            "D. A. Bolotin",
            "S. V. Poslavsky"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this paper we introduce Redberry --- an open source computer algebra\nsystem with native support of tensorial expressions. It provides basic computer\nalgebra tools (algebraic manipulations, substitutions, basic simplifications\netc.) which are aware of specific features of indexed expressions: contractions\nof indices, permutational symmetries, multiple index types etc. Redberry\nsupports conventional \\LaTeX-style input notation for tensorial expressions.\nThe high energy physics package includes tools for Feynman diagrams\ncalculation: Dirac and SU(N) algebra, Levi-Civita simplifications and tools for\none-loop calculations in quantum field theory. In the paper we give detailed\noverview of Redberry features: from basic manipulations with tensors to real\nFeynman diagrams calculation, accompanied by many examples. Redberry is written\nin Java 7 and provides convenient Groovy-based user interface inside the\nhigh-level general purpose programming language environment. Redberry is\navailable from http://redberry.cc\n",
        "pdf_link": "http://arxiv.org/pdf/1302.1219v2"
    },
    {
        "title": "Simplifying Multiple Sums in Difference Fields",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  In this survey article we present difference field algorithms for symbolic\nsummation. Special emphasize is put on new aspects in how the summation\nproblems are rephrased in terms of difference fields, how the problems are\nsolved there, and how the derived results in the given difference field can be\nreinterpreted as solutions of the input problem. The algorithms are illustrated\nwith the Mathematica package \\SigmaP\\ by discovering and proving new harmonic\nnumber identities extending those from (Paule and Schneider, 2003). In\naddition, the newly developed package \\texttt{EvaluateMultiSums} is introduced\nthat combines the presented tools. In this way, large scale summation problems\nfor the evaluation of Feynman diagrams in QCD (Quantum ChromoDynamics) can be\nsolved completely automatically.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4134v1"
    },
    {
        "title": "Modern Summation Methods for Loop Integrals in Quantum Field Theory: The\n  Packages Sigma, EvaluateMultiSums and SumProduction",
        "authors": [
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  A large class of Feynman integrals, like e.g., two-point parameter integrals\nwith at most one mass and containing local operator insertions, can be\ntransformed to multi-sums over hypergeometric expressions. In this survey\narticle we present a difference field approach for symbolic summation that\nenables one to simplify such definite nested sums to indefinite nested sums. In\nparticular, the simplification is given -if possible- in terms of harmonic\nsums, generalized harmonic sums, cyclotomic harmonic sums or binomial sums.\nSpecial emphasis is put on the developed packages Sigma, EvaluateMultiSums and\nSumProduction that assist in the task to perform these simplifications\ncompletely automatically for huge input expressions.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.0160v1"
    },
    {
        "title": "A Polyhedral Method to Compute All Affine Solution Sets of Sparse\n  Polynomial Systems",
        "authors": [
            "Danko Adrovic",
            "Jan Verschelde"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  To compute solutions of sparse polynomial systems efficiently we have to\nexploit the structure of their Newton polytopes. While the application of\npolyhedral methods naturally excludes solutions with zero components, an\nirreducible decomposition of a variety is typically understood in affine space,\nincluding also those components with zero coordinates. We present a polyhedral\nmethod to compute all affine solution sets of a polynomial system. The method\nenumerates all factors contributing to a generalized permanent. Toric solution\nsets are recovered as a special case of this enumeration. For sparse systems as\nadjacent 2-by-2 minors our methods scale much better than the techniques from\nnumerical algebraic geometry.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.4128v1"
    },
    {
        "title": "Sparse Polynomial Interpolation Codes and their decoding beyond half the\n  minimal distance",
        "authors": [
            "Erich L. Kaltofen",
            "Clément Pernet"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We present algorithms performing sparse univariate polynomial interpolation\nwith errors in the evaluations of the polynomial. Based on the initial work by\nComer, Kaltofen and Pernet [Proc. ISSAC 2012], we define the sparse polynomial\ninterpolation codes and state that their minimal distance is precisely the\nlength divided by twice the sparsity. At ISSAC 2012, we have given a decoding\nalgorithm for as much as half the minimal distance and a list decoding\nalgorithm up to the minimal distance. Our new polynomial-time list decoding\nalgorithm uses sub-sequences of the received evaluations indexed by a linear\nprogression, allowing the decoding for a larger radius, that is, more errors in\nthe evaluations while returning a list of candidate sparse polynomials. We\nquantify this improvement for all typically small values of number of terms and\nnumber of errors, and provide a worst case asymptotic analysis of this\nimprovement. For instance, for sparsity T = 5 with up to 10 errors we can list\ndecode in polynomial-time from 74 values of the polynomial with unknown terms,\nwhereas our earlier algorithm required 2T (E + 1) = 110 evaluations. We then\npropose two variations of these codes in characteristic zero, where appropriate\nchoices of values for the variable yield a much larger minimal distance: the\nlength minus twice the sparsity.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.3594v3"
    },
    {
        "title": "Gröbner Bases for Linearized Polynomials",
        "authors": [
            "Margreta Kuijper",
            "Anna-Lena Trautmann"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  In this work we develop the theory of Gr\\\"obner bases for modules over the\nring of univariate linearized polynomials with coefficients from a finite\nfield.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.4600v1"
    },
    {
        "title": "Certifying solutions to overdetermined and singular polynomial systems\n  over Q",
        "authors": [
            "Tulay Ayyildiz Akoglu",
            "Jonathan D. Hauenstein",
            "Agnes Szanto"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  This paper is concerned with certifying that a given point is near an exact\nroot of an overdetermined or singular polynomial system with rational\ncoefficients. The difficulty lies in the fact that consistency of\noverdetermined systems is not a continuous property. Our certification is based\non hybrid symbolic-numeric methods to compute the exact \"rational univariate\nrepresentation\" (RUR) of a component of the input system from approximate\nroots. For overdetermined polynomial systems with simple roots, we compute an\ninitial RUR from approximate roots. The accuracy of the RUR is increased via\nNewton iterations until the exact RUR is found, which we certify using exact\narithmetic. Since the RUR is well-constrained, we can use it to certify the\ngiven approximate roots using alpha-theory. To certify isolated singular roots,\nwe use a determinantal form of the \"isosingular deflation\", which adds new\npolynomials to the original system without introducing new variables. The\nresulting polynomial system is overdetermined, but the roots are now simple,\nthereby reducing the problem to the overdetermined case. We prove that our\nalgorithms have complexity that are polynomial in the input plus the output\nsize upon successful convergence, and we use worst case upper bounds for\ntermination when our iteration does not converge to an exact RUR. Examples are\nincluded to demonstrate the approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.2721v1"
    },
    {
        "title": "Exploiting chordal structure in polynomial ideals: a Gröbner bases\n  approach",
        "authors": [
            "Diego Cifuentes",
            "Pablo Parrilo"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  Chordal structure and bounded treewidth allow for efficient computation in\nnumerical linear algebra, graphical models, constraint satisfaction and many\nother areas. In this paper, we begin the study of how to exploit chordal\nstructure in computational algebraic geometry, and in particular, for solving\npolynomial systems. The structure of a system of polynomial equations can be\ndescribed in terms of a graph. By carefully exploiting the properties of this\ngraph (in particular, its chordal completions), more efficient algorithms can\nbe developed. To this end, we develop a new technique, which we refer to as\nchordal elimination, that relies on elimination theory and Gr\\\"obner bases. By\nmaintaining graph structure throughout the process, chordal elimination can\noutperform standard Gr\\\"obner basis algorithms in many cases. The reason is\nthat all computations are done on \"smaller\" rings, of size equal to the\ntreewidth of the graph. In particular, for a restricted class of ideals, the\ncomputational complexity is linear in the number of variables. Chordal\nstructure arises in many relevant applications. We demonstrate the suitability\nof our methods in examples from graph colorings, cryptography, sensor\nlocalization and differential equations.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.1745v2"
    },
    {
        "title": "Generalization of Gabidulin Codes over Fields of Rational Functions",
        "authors": [
            "Daniel Augot"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We transpose the theory of rank metric and Gabidulin codes to the case of\nfields which are not finite fields. The Frobenius automorphism is replaced by\nany element of the Galois group of a cyclic algebraic extension of a base\nfield. We use our framework to define Gabidulin codes over the field of\nrational functions using algebraic function fields with a cyclic Galois group.\nThis gives a linear subspace of matrices whose coefficients are rational\nfunction, such that the rank of each of this matrix is lower bounded, where the\nrank is comprised in term of linear combination with rational functions. We\nprovide two examples based on Kummer and Artin-Schreier extensions.The matrices\nthat we obtain may be interpreted as generating matrices of convolutional\ncodes.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.6080v1"
    },
    {
        "title": "Automatic differentiation in machine learning: a survey",
        "authors": [
            "Atilim Gunes Baydin",
            "Barak A. Pearlmutter",
            "Alexey Andreyevich Radul",
            "Jeffrey Mark Siskind"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in\nmachine learning. Automatic differentiation (AD), also called algorithmic\ndifferentiation or simply \"autodiff\", is a family of techniques similar to but\nmore general than backpropagation for efficiently and accurately evaluating\nderivatives of numeric functions expressed as computer programs. AD is a small\nbut established field with applications in areas including computational fluid\ndynamics, atmospheric sciences, and engineering design optimization. Until very\nrecently, the fields of machine learning and AD have largely been unaware of\neach other and, in some cases, have independently discovered each other's\nresults. Despite its relevance, general-purpose AD has been missing from the\nmachine learning toolbox, a situation slowly changing with its ongoing adoption\nunder the names \"dynamic computational graphs\" and \"differentiable\nprogramming\". We survey the intersection of AD and machine learning, cover\napplications where AD has direct relevance, and address the main implementation\ntechniques. By precisely defining the main differentiation techniques and their\ninterrelationships, we aim to bring clarity to the usage of the terms\n\"autodiff\", \"automatic differentiation\", and \"symbolic differentiation\" as\nthese are encountered more and more in machine learning settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05767v4"
    },
    {
        "title": "Interactive certificate for the verification of Wiedemann's Krylov\n  sequence: application to the certification of the determinant, the minimal\n  and the characteristic polynomials of sparse matrices",
        "authors": [
            "Jean-Guillaume Dumas",
            "Erich Kaltofen",
            "Emmanuel Thomé"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Certificates to a linear algebra computation are additional data structures\nfor each output, which can be used by a-possibly randomized- verification\nalgorithm that proves the correctness of each output. Wiede-mann's algorithm\nprojects the Krylov sequence obtained by repeatedly multiplying a vector by a\nmatrix to obtain a linearly recurrent sequence. The minimal polynomial of this\nsequence divides the minimal polynomial of the matrix. For instance, if the\n$n\\times n$ input matrix is sparse with n 1+o(1) non-zero entries, the\ncomputation of the sequence is quadratic in the dimension of the matrix while\nthe computation of the minimal polynomial is n 1+o(1), once that projected\nKrylov sequence is obtained. In this paper we give algorithms that compute\ncertificates for the Krylov sequence of sparse or structured $n\\times n$\nmatrices over an abstract field, whose Monte Carlo verification complexity can\nbe made essentially linear. As an application this gives certificates for the\ndeterminant, the minimal and characteristic polynomials of sparse or structured\nmatrices at the same cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.01083v1"
    },
    {
        "title": "Algebraic independence of sequences generated by (cyclotomic) harmonic\n  sums",
        "authors": [
            "Jakob Ablinger",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  An expression in terms of (cyclotomic) harmonic sums can be simplified by the\nquasi-shuffle algebra in terms of the so-called basis sums. By construction,\nthese sums are algebraically independent within the quasi-shuffle algebra. In\nthis article we show that the basis sums can be represented within a tower of\ndifference ring extensions where the constants remain unchanged. This property\nenables one to embed this difference ring for the (cyclotomic) harmonic sums\ninto the ring of sequences. This construction implies that the sequences\nproduced by the basis sums are algebraically independent over the rational\nsequences adjoined with the alternating sequence.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.03692v2"
    },
    {
        "title": "Chordal networks of polynomial ideals",
        "authors": [
            "Diego Cifuentes",
            "Pablo A. Parrilo"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We introduce a novel representation of structured polynomial ideals, which we\nrefer to as chordal networks. The sparsity structure of a polynomial system is\noften described by a graph that captures the interactions among the variables.\nChordal networks provide a computationally convenient decomposition into\nsimpler (triangular) polynomial sets, while preserving the underlying graphical\nstructure. We show that many interesting families of polynomial ideals admit\ncompact chordal network representations (of size linear in the number of\nvariables), even though the number of components is exponentially large.\nChordal networks can be computed for arbitrary polynomial systems using a\nrefinement of the chordal elimination algorithm from [Cifuentes-Parrilo-2016].\nFurthermore, they can be effectively used to obtain several properties of the\nvariety, such as its dimension, cardinality, and equidimensional components, as\nwell as an efficient probabilistic test for radical ideal membership. We apply\nour methods to examples from algebraic statistics and vector addition systems;\nfor these instances, algorithms based on chordal networks outperform existing\ntechniques by orders of magnitude.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02618v2"
    },
    {
        "title": "Inverse Mellin Transform of Holonomic Sequences",
        "authors": [
            "Jakob Ablinger"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We describe a method to compute the inverse Mellin transform of holonomic\nsequences, that is based on a method to compute the Mellin transform of\nholonomic functions. Both methods are implemented in the computer algebra\npackage HarmonicSums.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.02845v1"
    },
    {
        "title": "Algorithms to solve coupled systems of differential equations in terms\n  of power series",
        "authors": [
            "Jakob Ablinger",
            "Arnd Behring",
            "Johannes Bluemlein",
            "Abilio de Freitas",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Using integration by parts relations, Feynman integrals can be represented in\nterms of coupled systems of differential equations. In the following we suppose\nthat the unknown Feynman integrals can be given in power series\nrepresentations, and that sufficiently many initial values of the integrals are\ngiven. Then there exist algorithms that decide constructively if the\ncoefficients of their power series representations can be given within the\nclass of nested sums over hypergeometric products. In this article we will work\nout the calculation steps that solve this problem. First, we will present a\nsuccessful tactic that has been applied recently to challenging problems coming\nfrom massive 3-loop Feynman integrals. Here our main tool is to solve scalar\nlinear recurrences within the class of nested sums over hypergeometric\nproducts. Second, we will present a new variation of this tactic which relies\non more involved summation technologies but succeeds in reducing the problem to\nsolve scalar recurrences with lower recurrence orders. The article will work\nout the different challenges of this new tactic and demonstrates how they can\nbe treated efficiently with our existing summation technologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.05376v1"
    },
    {
        "title": "Lopsided Approximation of Amoebas",
        "authors": [
            "Jens Forsgård",
            "Laura Felicia Matusevich",
            "Nathan Mehlhop",
            "Timo de Wolff"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  The amoeba of a Laurent polynomial is the image of the corresponding\nhypersurface under the coordinatewise log absolute value map. In this article,\nwe demonstrate that a theoretical amoeba approximation method due to Purbhoo\ncan be used efficiently in practice. To do this, we resolve the main bottleneck\nin Purbhoo's method by exploiting relations between cyclic resultants. We use\nthe same approach to give an approximation of the Log preimage of the amoeba of\na Laurent polynomial using semi-algebraic sets. We also provide a SINGULAR/SAGE\nimplementation of these algorithms, which shows a significant speedup when our\nspecialized cyclic resultant computation is used, versus a general purpose\nresultant algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.08663v3"
    },
    {
        "title": "A Special Homotopy Continuation Method For A Class of Polynomial Systems",
        "authors": [
            "Yu Wang",
            "Wenyuan Wu",
            "Bican Xia"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  A special homotopy continuation method, as a combination of the polyhedral\nhomotopy and the linear product homotopy, is proposed for computing all the\nisolated solutions to a special class of polynomial systems. The root number\nbound of this method is between the total degree bound and the mixed volume\nbound and can be easily computed. The new algorithm has been implemented as a\nprogram called LPH using C++. Our experiments show its efficiency compared to\nthe polyhedral or other homotopies on such systems. As an application, the\nalgorithm can be used to find witness points on each connected component of a\nreal variety.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.07536v1"
    },
    {
        "title": "Dimension-Dependent Upper Bounds for Grobner Bases",
        "authors": [
            "Amir Hashemi",
            "Werner M. Seiler"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We improve certain degree bounds for Grobner bases of polynomial ideals in\ngeneric position. We work exclusively in deterministically verifiable and\nachievable generic positions of a combinatorial nature, namely either strongly\nstable position or quasi stable position. Furthermore, we exhibit new\ndimension- (and depth-)dependent upper bounds for the Castelnuovo-Mumford\nregularity and the degrees of the elements of the reduced Grobner basis (w.r.t.\nthe degree reverse lexicographical ordering) of a homogeneous ideal in these\npositions.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.02776v1"
    },
    {
        "title": "Deterministic Genericity for Polynomial Ideals",
        "authors": [
            "Amir Hashemi",
            "Michael Schweinfurter",
            "Werner M. Seiler"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We consider several notions of genericity appearing in algebraic geometry and\ncommutative algebra. Special emphasis is put on various stability notions which\nare defined in a combinatorial manner and for which a number of equivalent\nalgebraic characterisations are provided. It is shown that in characteristic\nzero the corresponding generic positions can be obtained with a simple\ndeterministic algorithm. In positive characteristic, only adapted stable\npositions are reachable except for quasi-stability which is obtainable in any\ncharacteristic.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.02797v1"
    },
    {
        "title": "Improved Computation of Involutive Bases",
        "authors": [
            "Bentolhoda Binaei",
            "Amir Hashemi",
            "Werner M. Seiler"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we describe improved algorithms to compute Janet and Pommaret\nbases. To this end, based on the method proposed by Moller et al., we present a\nmore efficient variant of Gerdt's algorithm (than the algorithm presented by\nGerdt-Hashemi-M.Alizadeh) to compute minimal involutive bases. Further, by\nusing the involutive version of Hilbert driven technique, along with the new\nvariant of Gerdt's algorithm, we modify the algorithm, given by Seiler, to\ncompute a linear change of coordinates for a given homogeneous ideal so that\nthe new ideal (after performing this change) possesses a finite Pommaret basis.\nAll the proposed algorithms have been implemented in Maple and their efficiency\nis discussed via a set of benchmark polynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03441v1"
    },
    {
        "title": "Power series expansions for the planar monomer-dimer problem",
        "authors": [
            "Gleb Pogudin"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We compute the free energy of the planar monomer-dimer model. Unlike the\nclassical planar dimer model, an exact solution is not known in this case. Even\nthe computation of the low-density power series expansion requires heavy and\nnontrivial computations. Despite of the exponential computational complexity,\nwe compute almost three times more terms than were previously known. Such an\nexpansion provides both lower and upper bound for the free energy, and allows\nto obtain more accurate numerical values than previously possible. We expect\nthat our methods can be applied to other similar problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.10121v3"
    },
    {
        "title": "Root Separation for Trinomials",
        "authors": [
            "Pascal Koiran"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We give a separation bound for the complex roots of a trinomial $f \\in\n\\mathbb{Z}[X]$. The logarithm of the inverse of our separation bound is\npolynomial in the size of the sparse encoding of $f$; in particular, it is\npolynomial in $\\log (\\deg f)$. It is known that no such bound is possible for\n4-nomials (polynomials with 4 monomials). For trinomials, the classical results\n(which are based on the degree of $f$ rather than the number of monomials) give\nseparation bounds that are exponentially worse.As an algorithmic application,\nwe show that the number of real roots of a trinomial $f$ can be computed in\ntime polynomial in the size of the sparse encoding of~$f$. The same problem is\nopen for 4-nomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.03294v3"
    },
    {
        "title": "Automatic Generation of Bounds for Polynomial Systems with Application\n  to the Lorenz System",
        "authors": [
            "Klaus Röbenack",
            "Rick Voßwinkel",
            "Hendrik Richter"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  This study covers an analytical approach to calculate positively invariant\nsets of dynamical systems. Using Lyapunov techniques and quantifier elimination\nmethods, an automatic procedure for determining bounds in the state space as an\nenclosure of attractors is proposed. The available software tools permit an\nalgorithmizable process, which normally requires a good insight into the\nsystems dynamics and experience. As a result we get an estimation of the\nattractor, whose conservatism only results from the initial choice of the\nLyapunov candidate function. The proposed approach is illustrated on the\nwell-known Lorenz system.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.08228v2"
    },
    {
        "title": "Computing the Inverse Mellin Transform of Holonomic Sequences using\n  Kovacic's Algorithm",
        "authors": [
            "Jakob Ablinger"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We describe how the extension of a solver for linear differential equations\nby Kovacic's algorithm helps to improve a method to compute the inverse Mellin\ntransform of holonomic sequences. The method is implemented in the computer\nalgebra package HarmonicSums.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.01039v1"
    },
    {
        "title": "Quantum Algorithm for Optimization and Polynomial System Solving over\n  Finite Field and Application to Cryptanalysis",
        "authors": [
            "Yu-Ao Chen",
            "Xiao-Shan Gao",
            "Chun-Ming Yuan"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this paper, we give quantum algorithms for two fundamental computation\nproblems: solving polynomial systems over finite fields and optimization where\nthe arguments of the objective function and constraints take values from a\nfinite field or a bounded interval of integers. The quantum algorithms can\nsolve these problems with any given success probability and have polynomial\nruntime complexities in the size of the input, the degree of the inequality\nconstraints, and the condition number of certain matrices derived from the\nproblem. So, we achieved exponential speedup for these problems when their\ncondition numbers are small. As applications, quantum algorithms are given to\nthree basic computational problems in cryptography: the polynomial system with\nnoise problem, the short integer solution problem, the shortest vector problem,\nas well as the cryptanalysis for the lattice based NTRU cryptosystem. It is\nshown that these problems and NTRU can against quantum computer attacks only if\ntheir condition numbers are large, so the condition number could be used as a\nnew criterion for the lattice based post-quantum cryptosystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03856v2"
    },
    {
        "title": "Groebner bases of reaction networks with intermediate species",
        "authors": [
            "AmirHosein Sadeghimanesh",
            "Elisenda Feliu"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In this work we consider the computation of Groebner bases of the steady\nstate ideal of reaction networks equipped with mass-action kinetics.\nSpecifically, we focus on the role of intermediate species and the relation\nbetween the extended network (with intermediate species) and the core network\n(without intermediate species).\n  We show that a Groebner basis of the steady state ideal of the core network\nalways lifts to a Groebner basis of the steady state ideal of the extended\nnetwork by means of linear algebra, with a suitable choice of monomial order.\nAs illustrated with examples, this contributes to a substantial reduction of\nthe computation time, due mainly to the reduction in the number of variables\nand polynomials. We further show that if the steady state ideal of the core\nnetwork is binomial, then so is the case for the extended network, as long as\nan extra condition is fulfilled. For standard networks, this extra condition\ncan be visually explored from the network structure alone.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.01381v1"
    },
    {
        "title": "Implementing a Method for Stochastization of One-Step Processes in a\n  Computer Algebra System",
        "authors": [
            "D. S. Kulyabov",
            "M. N. Gevorkyan",
            "A. V. Demidova",
            "T. R. Velieva",
            "A. V. Korolkova",
            "L. A. Sevastianov"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  When modeling such phenomena as population dynamics, controllable ows, etc.,\na problem arises of adapting the existing models to a phenomenon under study.\nFor this purpose, we propose to derive new models from the rst principles by\nstochastization of one-step processes. Research can be represented as an\niterative process that consists in obtaining a model and its further re nement.\nThe number of such iterations can be extremely large. This work is aimed at\nsoftware implementation (by means of computer algebra) of a method for\nstochastization of one-step processes. As a basis of the software\nimplementation, we use the SymPy computer algebra system. Based on a developed\nalgorithm, we derive stochastic di erential equations and their interaction\nschemes. The operation of the program is demonstrated on the Verhulst and\nLotka-Volterra models.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03190v1"
    },
    {
        "title": "Towards Incremental Cylindrical Algebraic Decomposition in Maple",
        "authors": [
            "Alexander Imani Cowen-Rivers",
            "Matthew England"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Cylindrical Algebraic Decomposition (CAD) is an important tool within\ncomputational real algebraic geometry, capable of solving many problems for\npolynomial systems over the reals. It has long been studied by the Symbolic\nComputation community and has found recent interest in the Satisfiability\nChecking community. The present report describes a proof of concept\nimplementation of an Incremental CAD algorithm in Maple, where CADs are built\nand then refined as additional polynomial constraints are added. The aim is to\nmake CAD suitable for use as a theory solver for SMT tools who search for\nsolutions by continually reformulating logical formula and querying whether a\nlogical solution is admissible. We describe experiments for the proof of\nconcept, which clearly display the computational advantages compared to\niterated re-computation. In addition, the project implemented this work under\nthe recently verified Lazard projection scheme (with corresponding Lazard\nvaluation).\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10136v1"
    },
    {
        "title": "Monodromy Solver: Sequential and Parallel",
        "authors": [
            "Nathan Bliss",
            "Timothy Duff",
            "Anton Leykin",
            "Jeff Sommars"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We describe, study, and experiment with an algorithm for finding all\nsolutions of systems of polynomial equations using homotopy continuation and\nmonodromy. This algorithm follows a framework developed in previous work and\ncan operate in the presence of a large number of failures of the homotopy\ncontinuation subroutine. We give special attention to parallelization and\nprobabilistic analysis of a model adapted to parallelization and failures.\nApart from theoretical results, we developed a simulator that allows us to run\na large number of experiments without recomputing the outcomes of the\ncontinuation subroutine.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.12212v1"
    },
    {
        "title": "Computing Elimination Ideals and Discriminants of Likelihood Equations",
        "authors": [
            "Xiaoxian Tang",
            "Timo De Wolff",
            "Rukai Zhao"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We develop a probabilistic algorithm for computing elimination ideals of\nlikelihood equations, which is for larger models by far more efficient than\ndirectly computing Groebner bases or the interpolation method proposed in the\nfirst author's previous work. The efficiency is improved by a theoretical\nresult showing that the sum of data variables appears in most coefficients of\nthe generator polynomial of elimination ideal. Furthermore, applying the known\nstructures of Newton polytopes of discriminants, we can also efficiently deduce\ndiscriminants of the elimination ideals. For instance, the discriminants of 3\nby 3 matrix model and one Jukes-Cantor model in phylogenetics (with sizes over\n30 GB and 8 GB text files, respectively) can be computed by our methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.05620v1"
    },
    {
        "title": "SIAN: software for structural identifiability analysis of ODE models",
        "authors": [
            "Hoon Hong",
            "Alexey Ovchinnikov",
            "Gleb Pogudin",
            "Chee Yap"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Biological processes are often modeled by ordinary differential equations\nwith unknown parameters. The unknown parameters are usually estimated from\nexperimental data. In some cases, due to the structure of the model, this\nestimation problem does not have a unique solution even in the case of\ncontinuous noise-free data. It is therefore desirable to check the uniqueness a\npriori before carrying out actual experiments. We present a new software SIAN\n(Structural Identifiability ANalyser) that does this. Our software can tackle\nproblems that could not be tackled by previously developed packages.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.10180v1"
    },
    {
        "title": "Recursive Matrix Algorithms in Commutative Domain for Cluster with\n  Distributed Memory",
        "authors": [
            "Gennadi Malaschonok",
            "Evgeni Ilchenko"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We give an overview of the theoretical results for matrix block-recursive\nalgorithms in commutative domains and present the results of experiments that\nwe conducted with new parallel programs based on these algorithms on a\nsupercomputer MVS-10P at the Joint Supercomputer Center of the Russian Academy\nof Science. To demonstrate a scalability of these programs we measure the\nrunning time of the program for a different number of processors and plot the\ngraphs of efficiency factor. Also we present the main application areas in\nwhich such parallel algorithms are used. It is concluded that this class of\nalgorithms allows to obtain efficient parallel programs on clusters with\ndistributed memory.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.04394v1"
    },
    {
        "title": "Factoring Differential Operators in n Variables",
        "authors": [
            "Mark Giesbrecht",
            "Albert Heinle",
            "Viktor Levandovskyy"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  In this paper, we present a new algorithm and an experimental implementation\nfor factoring elements in the polynomial n'th Weyl algebra, the polynomial n'th\nshift algebra, and ZZ^n-graded polynomials in the n'th q-Weyl algebra.\n  The most unexpected result is that this noncommutative problem of factoring\npartial differential operators can be approached effectively by reducing it to\nthe problem of solving systems of polynomial equations over a commutative ring.\nIn the case where a given polynomial is ZZ^n-graded, we can reduce the problem\ncompletely to factoring an element in a commutative multivariate polynomial\nring.\n  The implementation in Singular is effective on a broad range of polynomials\nand increases the ability of computer algebra systems to address this important\nproblem. We compare the performance and output of our algorithm with other\nimplementations in commodity computer algebra systems on nontrivial examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.0002v1"
    },
    {
        "title": "Symbolic Derivation of Mean-Field PDEs from Lattice-Based Models",
        "authors": [
            "Christoph Koutschan",
            "Helene Ranetbauer",
            "Georg Regensburger",
            "Marie-Therese Wolfram"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Transportation processes, which play a prominent role in the life and social\nsciences, are typically described by discrete models on lattices. For studying\ntheir dynamics a continuous formulation of the problem via partial differential\nequations (PDE) is employed. In this paper we propose a symbolic computation\napproach to derive mean-field PDEs from a lattice-based model. We start with\nthe microscopic equations, which state the probability to find a particle at a\ngiven lattice site. Then the PDEs are formally derived by Taylor expansions of\nthe probability densities and by passing to an appropriate limit as the time\nsteps and the distances between lattice sites tend to zero. We present an\nimplementation in a computer algebra system that performs this transition for a\ngeneral class of models. In order to rewrite the mean-field PDEs in a\nconservative formulation, we adapt and implement symbolic integration methods\nthat can handle unspecified functions in several variables. To illustrate our\napproach, we consider an application in crowd motion analysis where the\ndynamics of bidirectional flows are studied. However, the presented approach\ncan be applied to various transportation processes of multiple species with\nvariable size in any dimension, for example, to confirm several proposed\nmean-field models for cell motility.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.08527v3"
    },
    {
        "title": "Computing minimal interpolation bases",
        "authors": [
            "Claude-Pierre Jeannerod",
            "Vincent Neiger",
            "Éric Schost",
            "Gilles Villard"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  We consider the problem of computing univariate polynomial matrices over a\nfield that represent minimal solution bases for a general interpolation\nproblem, some forms of which are the vector M-Pad\\'e approximation problem in\n[Van Barel and Bultheel, Numerical Algorithms 3, 1992] and the rational\ninterpolation problem in [Beckermann and Labahn, SIAM J. Matrix Anal. Appl. 22,\n2000]. Particular instances of this problem include the bivariate interpolation\nsteps of Guruswami-Sudan hard-decision and K\\\"otter-Vardy soft-decision\ndecodings of Reed-Solomon codes, the multivariate interpolation step of\nlist-decoding of folded Reed-Solomon codes, and Hermite-Pad\\'e approximation.\n  In the mentioned references, the problem is solved using iterative algorithms\nbased on recurrence relations. Here, we discuss a fast, divide-and-conquer\nversion of this recurrence, taking advantage of fast matrix computations over\nthe scalars and over the polynomials. This new algorithm is deterministic, and\nfor computing shifted minimal bases of relations between $m$ vectors of size\n$\\sigma$ it uses $O~( m^{\\omega-1} (\\sigma + |s|) )$ field operations, where\n$\\omega$ is the exponent of matrix multiplication, and $|s|$ is the sum of the\nentries of the input shift $s$, with $\\min(s) = 0$. This complexity bound\nimproves in particular on earlier algorithms in the case of bivariate\ninterpolation for soft decoding, while matching fastest existing algorithms for\nsimultaneous Hermite-Pad\\'e approximation.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.03503v2"
    },
    {
        "title": "Fast Operations on Linearized Polynomials and their Applications in\n  Coding Theory",
        "authors": [
            "Sven Puchinger",
            "Antonia Wachter-Zeh"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  This paper considers fast algorithms for operations on linearized\npolynomials. We propose a new multiplication algorithm for skew polynomials (a\ngeneralization of linearized polynomials) which has sub-quadratic complexity in\nthe polynomial degree $s$, independent of the underlying field extension\ndegree~$m$. We show that our multiplication algorithm is faster than all known\nones when $s \\leq m$. Using a result by Caruso and Le Borgne (2017), this\nimmediately implies a sub-quadratic division algorithm for linearized\npolynomials for arbitrary polynomial degree $s$. Also, we propose algorithms\nwith sub-quadratic complexity for the $q$-transform, multi-point evaluation,\ncomputing minimal subspace polynomials, and interpolation, whose\nimplementations were at least quadratic before. Using the new fast algorithm\nfor the $q$-transform, we show how matrix multiplication over a finite field\ncan be implemented by multiplying linearized polynomials of degrees at most\n$s=m$ if an elliptic normal basis of extension degree $m$ exists, providing a\nlower bound on the cost of the latter problem. Finally, it is shown how the new\nfast operations on linearized polynomials lead to the first error and erasure\ndecoding algorithm for Gabidulin codes with sub-quadratic complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.06520v3"
    },
    {
        "title": "On Bezout Inequalities for non-homogeneous Polynomial Ideals",
        "authors": [
            "Amir Hashemi",
            "Joos Heintz",
            "Luis Miguel Pardo",
            "Pablo Solernó"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  We introduce a \"workable\" notion of degree for non-homogeneous polynomial\nideals and formulate and prove ideal theoretic B\\'ezout Inequalities for the\nsum of two ideals in terms of this notion of degree and the degree of\ngenerators. We compute probabilistically the degree of an equidimensional\nideal.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.04341v1"
    },
    {
        "title": "Discriminants of complete intersection space curves",
        "authors": [
            "Laurent Busé",
            "Ibrahim Nonkané"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this paper, we develop a new approach to the discrimi-nant of a complete\nintersection curve in the 3-dimensional projective space. By relying on the\nresultant theory, we first prove a new formula that allows us to define this\ndiscrimi-nant without ambiguity and over any commutative ring, in particular in\nany characteristic. This formula also provides a new method for evaluating and\ncomputing this discrimi-nant efficiently, without the need to introduce new\nvariables as with the well-known Cayley trick. Then, we obtain new properties\nand computational rules such as the covariance and the invariance formulas.\nFinally, we show that our definition of the discriminant satisfies to the\nexpected geometric property and hence yields an effective smoothness criterion\nfor complete intersection space curves. Actually, we show that in the generic\nsetting, it is the defining equation of the discriminant scheme if the ground\nring is assumed to be a unique factorization domain.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.01694v1"
    },
    {
        "title": "Generalization of Risch's Algorithm to Special Functions",
        "authors": [
            "C. G. Raab"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  Symbolic integration deals with the evaluation of integrals in closed form.\nWe present an overview of Risch's algorithm including recent developments. The\nalgorithms discussed are suited for both indefinite and definite integration.\nThey can also be used to compute linear relations among integrals and to find\nidentities for special functions given by parameter integrals. The aim of this\npresentation is twofold: to introduce the reader to some basic ideas of\ndifferential algebra in the context of integration and to raise awareness in\nthe physics community of computer algebra algorithms for indefinite and\ndefinite integration.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.1481v1"
    },
    {
        "title": "Characterization of Rational Ruled Surfaces",
        "authors": [
            "Sonia Perez-Diaza",
            "Liyong Shen"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  The ruled surface is a typical modeling surface in computer aided geometric\ndesign. It is usually given in the standard parametric form. However, it can\nalso be in the forms than the standard one. For these forms, it is necessary to\ndetermine and find the standard form. In this paper, we present algorithms to\ndetermine whether a given implicit surface is a rational ruled surface. A\nparametrization of the surface is computed for the affirmative case. We also\nconsider the parametric situation. More precisely, after a given rational\nparametric surface is determined as a ruled one, we reparameterize it to the\nstandard form.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.2462v2"
    },
    {
        "title": "Determination and (re)parametrization of rational developable surfaces",
        "authors": [
            "Sonia Perez-Diaz",
            "Li-Yong Shen"
        ],
        "category": "cs.SC",
        "published_year": "2013",
        "summary": "  The developable surface is an important surface in computer aided design,\ngeometric modeling and industrial manufactory. It is often given in the stan-\ndard parametric form, but it can also be in the implicit form which is commonly\nused in algebraic geometry. Not all algebraic developable surfaces have\nrational parametrizations. In this paper, we focus on the rational developable\nsurfaces. For a given algebraic surface, we first determine whether it is\ndevelopable by geometric inspection, and we give a rational proper\nparametrization for the af- firmative case. For a rational parametric surface,\nwe can also determine the developability and give a proper reparametrization\nfor the developable surface.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.2463v1"
    },
    {
        "title": "Faster integer multiplication using plain vanilla FFT primes",
        "authors": [
            "David Harvey",
            "Joris van der Hoeven"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  Assuming a conjectural upper bound for the least prime in an arithmetic\nprogression, we show that n-bit integers may be multiplied in O(n log n\n4^(log^* n)) bit operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.07144v2"
    },
    {
        "title": "On the Complexity of Toric Ideals",
        "authors": [
            "Diego Cifuentes",
            "Shmuel Onn"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We investigate the computational complexity of problems on toric ideals such\nas normal forms, Gr\\\"obner bases, and Graver bases. We show that all these\nproblems are strongly NP-hard in the general case. Nonetheless, we can derive\nefficient algorithms by taking advantage of the sparsity pattern of the matrix.\nWe describe this sparsity pattern with a graph, and study the parameterized\ncomplexity of toric ideals in terms of graph parameters such as treewidth and\ntreedepth. In particular, we show that the normal form problem can be solved in\nparameter-tractable time in terms of the treedepth. An important application of\nthis result is in multiway ideals arising in algebraic statistics. We also give\na parameter-tractable membership test to the reduced Gr\\\"obner basis. This test\nleads to an efficient procedure for computing the reduced Gr\\\"obner basis.\nSimilar results hold for Graver bases computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.01484v1"
    },
    {
        "title": "Exact Optimization via Sums of Nonnegative Circuits and Sums of AM/GM\n  Exponentials",
        "authors": [
            "Victor Magron",
            "Henning Seidler",
            "Timo de Wolff"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We provide two hybrid numeric-symbolic optimization algorithms, computing\nexact sums of nonnegative circuits (SONC) and sums of\narithmetic-geometric-exponentials (SAGE) decompositions. Moreover, we provide a\nhybrid numeric-symbolic decision algorithm for polynomials lying in the\ninterior of the SAGE cone. Each framework, inspired by previous contributions\nof Parrilo and Peyrl, is a rounding-projection procedure.\n  For a polynomial lying in the interior of the SAGE cone, we prove that the\ndecision algorithm terminates within a number of arithmetic operations, which\nis polynomial in the number of terms of the input, and linear in the distance\nto the boundary of the cone. We also provide experimental comparisons regarding\nthe implementation of the two optimization algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.02123v2"
    },
    {
        "title": "A refined machinery to calculate large moments from coupled systems of\n  linear differential equations",
        "authors": [
            "Johannes Blümlein",
            "Peter Marquard",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  The large moment method can be used to compute a large number of moments of\nphysical quantities that are described by coupled systems of linear\ndifferential equations. Besides these systems the algorithm requires a certain\nnumber of initial values as input, that are often hard to derive in a\npreprocessing step.Thus a major challenge is to keep the number of initial\nvalues as small as possible. We present the basic ideas of the underlying large\nmoment method and present refined versions that reduce significantly the number\nof required initial values.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.04390v1"
    },
    {
        "title": "Sparse Interpolation in Terms of Multivariate Chebyshev Polynomials",
        "authors": [
            "Evelyne Hubert",
            "Michael F. Singer"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Sparse interpolation} refers to the exact recovery of a function as a short\nlinear combination of basis functions from a limited number of evaluations. For\nmultivariate functions, the case of the monomial basis is well studied, as is\nnow the basis of exponential functions. Beyond the multivariate Chebyshev\npolynomial obtained as tensor products of univariate Chebyshev polynomials, the\ntheory of root systems allows to define a variety of generalized multivariate\nChebyshev polynomials that have connections to topics such as Fourier analysis\nand representations of Lie algebras. We present a deterministic algorithm to\nrecover a function that is the linear combination of at most r such polynomials\nfrom the knowledge of r and an explicitly bounded number of evaluations of this\nfunction.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.09144v1"
    },
    {
        "title": "On the complexity of computing integral bases of function fields",
        "authors": [
            "Simon Abelard"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Let $\\mathcal{C}$ be a plane curve given by an equation $f(x,y)=0$ with $f\\in\nK[x][y]$ a monic squarefree polynomial. We study the problem of computing an\nintegral basis of the algebraic function field $K(\\mathcal{C})$ and give new\ncomplexity bounds for three known algorithms dealing with this problem. For\neach algorithm, we study its subroutines and, when it is possible, we modify or\nreplace them so as to take advantage of faster primitives. Then, we combine\ncomplexity results to derive an overall complexity estimate for each algorithm.\nIn particular, we modify an algorithm due to B\\\"ohm et al. and achieve a\nquasi-optimal runtime.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.03964v1"
    },
    {
        "title": "A proposal to first principles electronic structure calculation:\n  Symbolic-Numeric method",
        "authors": [
            "Akihito Kikuchi"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  This study proposes an approach toward the first principles electronic\nstructure calculation with the aid of symbolic-numeric solving. The symbolic\ncomputation enables us to express the Hartree-Fock-Roothaan equation and the\nmolecular integrals in analytic forms and approximate them as a set of\npolynomial equations. By use of the Grobner bases technique, the polynomial\nequations are transformed into other ones which have identical roots. The\nconverted equations take more convenient forms which will simplify numerical\nprocedures, from which we can derive necessary physical properties in order, in\nan a la carte way. This method enables us to solve the electronic structure\ncalculation, the optimization of any kind, or the inverse problem as a forward\nproblem in a unified way, in which there is no need for iterative\nself-consistent procedures with trials and errors.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5127v4"
    },
    {
        "title": "Toward an Optimal Quantum Algorithm for Polynomial Factorization over\n  Finite Fields",
        "authors": [
            "Javad Doliskani"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We present a randomized quantum algorithm for polynomial factorization over\nfinite fields. For polynomials of degree $n$ over a finite field $\\F_q$, the\naverage-case complexity of our algorithm is an expected $O(n^{1 + o(1)} \\log^{2\n+ o(1)}q)$ bit operations. Only for a negligible subset of polynomials of\ndegree $n$ our algorithm has a higher complexity of $O(n^{4 / 3 + o(1)} \\log^{2\n+ o(1)}q)$ bit operations. This breaks the classical $3/2$-exponent barrier for\npolynomial factorization over finite fields \\cite{guo2016alg}.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.09675v1"
    },
    {
        "title": "Constructing minimal telescopers for rational functions in three\n  discrete variables",
        "authors": [
            "Shaoshi Chen",
            "Qing-Hu Hou",
            "Hui Huang",
            "George Labahn",
            "Rong-Hua Wang"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We present a new algorithm for constructing minimal telescopers for rational\nfunctions in three discrete variables. This is the first discrete\nreduction-based algorithm that goes beyond the bivariate case. The termination\nof the algorithm is guaranteed by a known existence criterion of telescopers.\nOur approach has the important feature that it avoids the potentially costly\ncomputation of certificates. Computational experiments are also provided so as\nto illustrate the efficiency of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11614v3"
    },
    {
        "title": "Algorithmic approach to strong consistency analysis of finite difference\n  approximations to PDE systems",
        "authors": [
            "Vladimir P. Gerdt",
            "Daniel Robertz"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  For a wide class of polynomially nonlinear systems of partial differential\nequations we suggest an algorithmic approach to the s(trong)-consistency\nanalysis of their finite difference approximations on Cartesian grids. First we\napply the differential Thomas decomposition to the input system, resulting in a\npartition of the solution set. We consider the output simple subsystem that\ncontains a solution of interest. Then, for this subsystem, we suggest an\nalgorithm for verification of s-consistency for its finite difference\napproximation. For this purpose we develop a difference analogue of the\ndifferential Thomas decomposition, both of which jointly allow to verify the\ns-consistency of the approximation. As an application of our approach, we show\nhow to produce s-consistent difference approximations to the incompressible\nNavier-Stokes equations including the pressure Poisson equation.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12912v1"
    },
    {
        "title": "A localized version of the basic triangle theorem",
        "authors": [
            "Gérard Duchamp",
            "Nihar Gargava",
            "Hoang Ngoc Minh",
            "Pierre Simonnet"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  In this short note, we give a localized version of the basic triangle\ntheorem, first published in 2011 (see [4]) in order to prove the independence\nof hyperlogarithms over various function fields. This version provides direct\naccess to rings of scalars and avoids the recourse to fraction fields as that\nof meromorphic functions for instance.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.03327v3"
    },
    {
        "title": "Efficient Rational Creative Telescoping",
        "authors": [
            "Mark Giesbrecht",
            "Hui Huang",
            "George Labahn",
            "Eugene Zima"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We present a new algorithm to compute minimal telescopers for rational\nfunctions in two discrete variables. As with recent reduction-based approaches,\nour algorithm has the important feature that the computation of a telescoper is\nindependent of its certificate. In addition, our algorithm uses a compact\nrepresentation of the certificate, which allows it to be easily manipulated and\nanalyzed without knowing the precise expanded form. This representation hides\npotential expression swell until the final (and optional) expansion, which can\nbe accomplished in time polynomial in the size of the expanded certificate. A\ncomplexity analysis, along with a Maple implementation, indicates that our\nalgorithm has better theoretical and practical performance than the\nreduction-based approach in the rational case.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.06898v2"
    },
    {
        "title": "Certified evaluations of Hölder continuous functions at roots of\n  polynomials",
        "authors": [
            "Parker B. Edwards",
            "Jonathan D. Hauenstein",
            "Clifford D. Smyth"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Various methods can obtain certified estimates for roots of polynomials. Many\napplications in science and engineering additionally utilize the value of\nfunctions evaluated at roots. For example, critical values are obtained by\nevaluating an objective function at critical points. For analytic evaluation\nfunctions, Newton's method naturally applies to yield certified estimates.\nThese estimates no longer apply, however, for H\\\"older continuous functions,\nwhich are a generalization of Lipschitz continuous functions where continuous\nderivatives need not exist. This work develops and analyzes an alternative\napproach for certified estimates of evaluating locally H\\\"older continuous\nfunctions at roots of polynomials. An implementation of the method in Maple\ndemonstrates efficacy and efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00115v1"
    },
    {
        "title": "Polynomial Linear System Solving with Random Errors: new bounds and\n  early termination technique",
        "authors": [
            "Guerrini Eleonora",
            "Lebreton Romain",
            "Zappatore Ilaria"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  This paper deals with the polynomial linear system solving with errors\n(PLSwE) problem. Specifically, we focus on the evaluation-interpolation\ntechnique for solving polynomial linear systems and we assume that errors can\noccur in the evaluation step. In this framework, the number of evaluations\nneeded to recover the solution of the linear system is crucial since it affects\nthe number of computations. It depends on the parameters of the linear system\n(degrees, size) and on a bound on the number of errors.\n  Our work is part of a series of papers about PLSwE aiming to reduce this\nnumber of evaluations. We proved in [Guerrini et al., Proc. ISIT'19] that if\nerrors are randomly distributed, the bound of the number of evaluations can be\nlowered for large error rate.\n  In this paper, following the approach of [Kaltofen et al., Proc. ISSAC'17],\nwe improve the results of [Guerrini et al., Proc. ISIT'19] in two directions.\nFirst, we propose a new bound of the number of evaluations, lowering the\ndependency on the parameters of the linear system, based on work of [Cabay,\nProc. SYMSAC'71]. Second, we introduce an early termination strategy in order\nto handle the unnecessary increase of the number of evaluations due to\noverestimation of the parameters of the system and on the bound on the number\nof errors.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04182v1"
    },
    {
        "title": "How to hunt wild constants",
        "authors": [
            "David R. Stoutemyer"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  There are now several comprehensive web applications, stand-alone computer\nprograms and computer algebra functions that, given a floating point number\nsuch as 6.518670730718491, can return concise nonfloat constants such as 3\narctan 2 + ln 9 + 1, that closely approximate the float. Examples include\nAskConstants, Inverse Symbolic Calculator, the Maple identify function,\nMESearch, OEIS, RIES, and WolframAlpha. Usefully often such a result is the\nexact limit as the float is computed with increasing precision. Therefore these\nprogram results are candidates for proving an exact result that you could not\notherwise compute or conjecture without the program. Moreover, candidates that\nare not the exact limit can be provable bounds, or convey qualitative insight,\nor suggest series that they truncate, or provide sufficiently close efficient\napproximations for subsequent computation. This article describes some of these\nprograms, how they work, and how best to use each of them. Almost everyone who\nuses or should use mathematical software can benefit from acquaintance with\nseveral such programs, because these programs differ in the sets of constants\nthat they can return.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.16720v3"
    },
    {
        "title": "Fast Approximation of Polynomial Zeros and Matrix Eigenvalues",
        "authors": [
            "Victor Y. Pan",
            "Soo Go",
            "Qi Luan",
            "Liang Zhao"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We approximate the d complex zeros of a univariate polynomial p(x) of a\ndegree d or those zeros that lie in a fixed region of interest on the complex\nplane such as a disc or a square. Our divide and conquer algorithm of STOC 1995\nsupports solution of this problem in optimal Boolean time (up to a\npoly-logarithmic factor), that is, runs nearly as fast as one can access the\ncoefficients of p with the precision necessary to support required accuracy of\nthe output. That record complexity has not been matched by any other algorithm\nyet, but our root-finder of 1995 is quite involved and has never been\nimplemented. We present alternative nearly optimal root-finders based on our\nnovel variants of the classical subdivision iterations. Unlike our predecessor\nof 1995, we require randomization of Las Vegas type, allowing us to detect any\noutput error at a dominated computational cost, but our new root-finders are\nmuch simpler to implement than their predecessor of 1995. According to the\nresults of extensive test with standard test polynomials for their preliminary\nversion, which incorporates only a part of our novel techniques, the new\nroot-finders compete and for a large class of inputs significantly supersedes\nthe package of root-finding subroutines MPSolve, which for decades has been\nuser's choice package. Unlike our predecessor of 1995 and all known fast\nalgorithms for the cited tasks of polynomial root-finding, our new algorithms\ncan be also applied to a polynomial given by a black box oracle for its\nevaluation rather than by its coefficients. This makes our root-finders\nparticularly efficient for polynomials p(x) that can be evaluated fast such as\nthe Mandelbrot polynomials or those given by the sum of a small number of\nshifted monomials. Our algorithm can be readily extended to fast approximation\nof the eigenvalues of a matrix or a matrix polynomial.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.11268v4"
    },
    {
        "title": "The Automated Discovery of Kinetic Rate Models -- Methodological\n  Frameworks",
        "authors": [
            "Miguel Ángel de Carvalho Servia",
            "Ilya Orson Sandoval",
            "Klaus Hellgardt",
            "King Kuok",
            " Hii",
            "Dongda Zhang",
            "Ehecatl Antonio del Rio Chanona"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  The industrialization of catalytic processes requires reliable kinetic models\nfor their design, optimization and control. Mechanistic models require\nsignificant domain knowledge, while data-driven and hybrid models lack\ninterpretability. Automated knowledge discovery methods, such as ALAMO\n(Automated Learning of Algebraic Models for Optimization), SINDy (Sparse\nIdentification of Nonlinear Dynamics), and genetic programming, have gained\npopularity but suffer from limitations such as needing model structure\nassumptions, exhibiting poor scalability, and displaying sensitivity to noise.\nTo overcome these challenges, we propose two methodological frameworks, ADoK-S\nand ADoK-W (Automated Discovery of Kinetic rate models using a Strong/Weak\nformulation of symbolic regression), for the automated generation of catalytic\nkinetic models using a robust criterion for model selection. We leverage\ngenetic programming for model generation and a sequential optimization routine\nfor model refinement. The frameworks are tested against three case studies of\nincreasing complexity, demonstrating their ability to retrieve the underlying\nkinetic rate model with limited noisy data from the catalytic systems,\nshowcasing their potential for chemical reaction engineering applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.11356v2"
    },
    {
        "title": "Telescopers for Rational and Algebraic Functions via Residues",
        "authors": [
            "Shaoshi Chen",
            "Manuel Kauers",
            "Michael F. Singer"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  We show that the problem of constructing telescopers for functions of m\nvariables is equivalent to the problem of constructing telescopers for\nalgebraic functions of m -1 variables and present a new algorithm to construct\ntelescopers for algebraic functions of two variables. These considerations are\nbased on analyzing the residues of the input. According to experiments, the\nresulting algorithm for rational functions of three variables is faster than\nknown algorithms, at least in some examples of combinatorial interest. The\nalgorithm for algebraic functions implies a new bound on the order of the\ntelescopers.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1954v2"
    },
    {
        "title": "Computing Puiseux Series for Algebraic Surfaces",
        "authors": [
            "Danko Adrovic",
            "Jan Verschelde"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  In this paper we outline an algorithmic approach to compute Puiseux series\nexpansions for algebraic surfaces. The series expansions originate at the\nintersection of the surface with as many coordinate planes as the dimension of\nthe surface. Our approach starts with a polyhedral method to compute cones of\nnormal vectors to the Newton polytopes of the given polynomial system that\ndefines the surface. If as many vectors in the cone as the dimension of the\nsurface define an initial form system that has isolated solutions, then those\nvectors are potential tropisms for the initial term of the Puiseux series\nexpansion. Our preliminary methods produce exact representations for solution\nsets of the cyclic $n$-roots problem, for $n = m^2$, corresponding to a result\nof Backelin.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3401v2"
    },
    {
        "title": "A General Solver Based on Sparse Resultants",
        "authors": [
            "Ioannis Z. Emiris"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Sparse (or toric) elimination exploits the structure of polynomials by\nmeasuring their complexity in terms of Newton polytopes instead of total\ndegree. The sparse, or Newton, resultant generalizes the classical homogeneous\nresultant and its degree is a function of the mixed volumes of the Newton\npolytopes. We sketch the sparse resultant constructions of Canny and Emiris and\nshow how they reduce the problem of root-finding to an eigenproblem. A novel\nmethod for achieving this reduction is presented which does not increase the\ndimension of the problem. Together with an implementation of the sparse\nresultant construction, it provides a general solver for polynomial systems. We\ndiscuss the overall implementation and illustrate its use by applying it to\nconcrete problems from vision, robotics and structural biology. The high\nefficiency and accuracy of the solutions suggest that sparse elimination may be\nthe method of choice for systems of moderate size.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.5810v1"
    },
    {
        "title": "Recent Symbolic Summation Methods to Solve Coupled Systems of\n  Differential and Difference Equations",
        "authors": [
            "Johannes Bluemlein",
            "Abilio De Freitas",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We outline a new algorithm to solve coupled systems of differential equations\nin one continuous variable $x$ (resp. coupled difference equations in one\ndiscrete variable $N$) depending on a small parameter $\\epsilon$: given such a\nsystem and given sufficiently many initial values, we can determine the first\ncoefficients of the Laurent-series solutions in $\\epsilon$ if they are\nexpressible in terms of indefinite nested sums and products. This systematic\napproach is based on symbolic summation algorithms in the context of difference\nrings/fields and uncoupling algorithms. The proposed method gives rise to new\ninteresting applications in connection with integration by parts (IBP) methods.\nAs an illustrative example, we will demonstrate how one can calculate the\n$\\epsilon$-expansion of a ladder graph with 6 massive fermion lines.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2537v1"
    },
    {
        "title": "Symbolic Tensor Calculus -- Functional and Dynamic Approach",
        "authors": [
            "A. Woszczyna",
            "P. Plaszczyk",
            "W. Czaja",
            "Z. A. Golda"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  In this paper, we briefly discuss the dynamic and functional approach to\ncomputer symbolic tensor analysis. The ccgrg package for Wolfram\nLanguage/Mathematica is used to illustrate this approach. Some examples of\napplications are attached.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.05819v1"
    },
    {
        "title": "ATENSOR - REDUCE program for tensor simplification",
        "authors": [
            "V. A. Ilyin",
            "A. P. Kryukov"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  The paper presents a REDUCE program for the simplification of tensor\nexpressions that are considered as formal indexed objects. The proposed\nalgorithm is based on the consideration of tensor expressions as vectors in\nsome linear space. This linear space is formed by all the elements of the group\nalgebra of the corresponding tensor expression. Such approach permits us to\nsimplify the tensor expressions possessing symmetry properties, summation\n(dummy) indices and multiterm identities by unify manner. The canonical element\nfor the tensor expression is defined in terms of the basic vectors of this\nlinear space. The main restriction of the algorithm is the dimension of the\nlinear space that is equal to N!, where N is a number of indices of the tensor\nexpression. The program uses REDUCE as user interface.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05409v1"
    },
    {
        "title": "Simplification of tensor expressions in computer algebra",
        "authors": [
            "A. Kryukov",
            "G. Shpiz"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  Computer algebra is widely used in various fields of mathematics, physics and\nother sciences. The simplification of tensor expressions is an important\nspecial case of computer algebra. In this paper, we consider the reduction of\ntensor polynomials to canonical form, taking into account the properties of\nsymmetry under permutations of indices, the symmetries associated with the\nrenaming of summation indices, and also linear relations between tensors of a\ngeneral form. We give a definition of the canonical representation for\npolynomial (multiplicative) expressions of variables with abstract indices,\nwhich is the result of averaging of the original expression by the action of\nsome finite group (the signature stabilizer). In practice, the proposed\nalgorithms demonstrate high efficiency for expressions made of Riemann\ncurvature tensors.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07701v1"
    },
    {
        "title": "A Fast Randomized Geometric Algorithm for Computing Riemann-Roch Spaces",
        "authors": [
            "Aude Le Gluher",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  We propose a probabilistic variant of Brill-Noether's algorithm for computing\na basis of the Riemann-Roch space $L(D)$ associated to a divisor $D$ on a\nprojective nodal plane curve $\\mathcal C$ over a sufficiently large perfect\nfield $k$. Our main result shows that this algorithm requires at most\n$O(\\max(\\mathrm{deg}(\\mathcal C)^{2\\omega}, \\mathrm{deg}(D_+)^\\omega))$\narithmetic operations in $k$, where $\\omega$ is a feasible exponent for matrix\nmultiplication and $D_+$ is the smallest effective divisor such that $D_+\\geq\nD$. This improves the best known upper bounds on the complexity of computing\nRiemann-Roch spaces. Our algorithm may fail, but we show that provided that a\nfew mild assumptions are satisfied, the failure probability is bounded by\n$O(\\max(\\mathrm{deg}(\\mathcal C)^4, \\mathrm{deg}(D_+)^2)/\\lvert \\mathcal\nE\\rvert)$, where $\\mathcal E$ is a finite subset of $k$ in which we pick\nelements uniformly at random. We provide a freely available C++/NTL\nimplementation of the proposed algorithm and we present experimental data. In\nparticular, our implementation enjoys a speedup larger than 6 on many examples\n(and larger than 200 on some instances over large finite fields) compared to\nthe reference implementation in the Magma computer algebra system. As a\nby-product, our algorithm also yields a method for computing the group law on\nthe Jacobian of a smooth plane curve of genus $g$ within $O(g^\\omega)$\noperations in $k$, which equals the best known complexity for this problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08237v8"
    },
    {
        "title": "LU factorization with errors *",
        "authors": [
            "Jean-Guillaume Dumas",
            "Joris Van Der Hoeven",
            "Clément Pernet",
            "Daniel Roche"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We present new algorithms to detect and correct errors in the lower-upper\nfactorization of a matrix, or the triangular linear system solution, over an\narbitrary field. Our main algorithms do not require any additional information\nor encoding other than the original inputs and the erroneous output. Their\nrunning time is softly linear in the dimension times the number of errors when\nthere are few errors, smoothly growing to the cost of fast matrix\nmultiplication as the number of errors increases. We also present applications\nto general linear system solving.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.10730v1"
    },
    {
        "title": "Rational Solutions of First-Order Algebraic Ordinary Difference\n  Equations",
        "authors": [
            "Thieu N. Vo",
            "Yi Zhang"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We propose an algebraic geometric approach for studying rational solutions of\nfirst-order algebraic ordinary difference equations. For an autonomous\nfirst-order algebraic ordinary difference equations, we give an upper bound for\nthe degrees of its rational solutions, and thus derive a complete algorithm for\ncomputing corresponding rational solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11048v2"
    },
    {
        "title": "Improved Structural Methods for Nonlinear Differential-Algebraic\n  Equations via Combinatorial Relaxation",
        "authors": [
            "Taihei Oki"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  Differential-algebraic equations (DAEs) are widely used for modeling of\ndynamical systems. In numerical analysis of DAEs, consistent initialization and\nindex reduction are important preprocessing prior to numerical integration.\nExisting DAE solvers commonly adopt structural preprocessing methods based on\ncombinatorial optimization. Unfortunately, the structural methods fail if the\nDAE has numerical or symbolic cancellations. For such DAEs, methods have been\nproposed to modify them to other DAEs to which the structural methods are\napplicable, based on the combinatorial relaxation technique. Existing\nmodification methods, however, work only for a class of DAEs that are linear or\nclose to linear.\n  This paper presents two new modification methods for nonlinear DAEs: the\nsubstitution method and the augmentation method. Both methods are based on the\ncombinatorial relaxation approach and are applicable to a large class of\nnonlinear DAEs. The substitution method symbolically solves equations for some\nderivatives based on the implicit function theorem and substitutes the solution\nback into the system. Instead of solving equations, the augmentation method\nmodifies DAEs by appending new variables and equations. The augmentation method\nhas advantages that the equation solving is not needed and the sparsity of DAEs\nis retained. It is shown in numerical experiments that both methods, especially\nthe augmentation method, successfully modify high-index DAEs that the DAE\nsolver in MATLAB cannot handle.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04511v1"
    },
    {
        "title": "Upper Hessenberg and Toeplitz Bohemians",
        "authors": [
            "Eunice Y. S. Chan",
            "Robert M. Corless",
            "Laureano Gonzalez-Vega",
            "J. Rafael Sendra",
            "Juana Sendra"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We look at Bohemians, specifically those with population $\\{-1, 0, {+1}\\}$\nand sometimes $\\{0,1,i,-1,-i\\}$. More, we specialize the matrices to be upper\nHessenberg Bohemian. From there, focusing on only those matrices whose\ncharacteristic polynomials have maximal height allows us to explicitly identify\nthese polynomials and give useful bounds on their height, and conjecture an\naccurate asymptotic formula. The lower bound for the maximal characteristic\nheight is exponential in the order of the matrix; in contrast, the height of\nthe matrices remains constant. We give theorems about the numbers of normal\nmatrices and the numbers of stable matrices in these families.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10677v1"
    },
    {
        "title": "qFunctions -- A Mathematica package for $q$-series and partition theory\n  applications",
        "authors": [
            "Jakob Ablinger",
            "Ali K. Uncu"
        ],
        "category": "cs.SC",
        "published_year": "2019",
        "summary": "  We describe the qFunctions Mathematica package for $q$-series and partition\ntheory applications. This package includes both experimental and symbolic\ntools. The experimental set of elements includes guessers for $q$-shift\nequations and recurrences for given $q$-series and fitting/finding explicit\nexpressions for sequences of polynomials. This package can symbolically handle\nformal manipulations on $q$-differential, $q$-shift equations and recurrences,\nsuch as switching between these forms, finding the greatest common divisor of\nrecurrences, and formal substitutions. Here, we also extend the classical\nmethod of the weighted words approach. Moreover, qFunctions has implementations\nthat automate the recurrence system creation of the weighted words approach as\nwell as a scheme on cylindric partitions.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.12410v1"
    },
    {
        "title": "Maximum Absolute Determinants of Upper Hessenberg Bohemian Matrices",
        "authors": [
            "Jonathan P. Keating",
            "Ahmet Abdullah Keleş"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  A matrix is called Bohemian if its entries are sampled from a finite set of\nintegers. We determine the maximum absolute determinant of upper Hessenberg\nBohemian Matrices for which the subdiagonal entries are fixed to be $1$ and\nupper triangular entries are sampled from $\\{0,1,\\cdots,n\\}$, extending\nprevious results for $n=1$ and $n=2$ and proving a recent conjecture of Fasi &\nNegri Porzio [8]. Furthermore, we generalize the problem to non-integer-valued\nentries.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.00454v2"
    },
    {
        "title": "A Simple Method for Computing Some Pseudo-Elliptic Integrals in Terms of\n  Elementary Functions",
        "authors": [
            "Sam Blake"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We introduce a method for computing some pseudo-elliptic integrals in terms\nof elementary functions. The method is simple and fast in comparison to the\nalgebraic case of the Risch-Trager-Bronstein algorithm. This method can quickly\nsolve many pseudo-elliptic integrals, which other well-known computer algebra\nsystems either fail, return an answer in terms of special functions, or require\nmore than 20 seconds of computing time. Randomised tests showed our method\nsolved 73.4% of the integrals that could be solved with the best implementation\nof the Risch-Trager-Bronstein algorithm. Unlike the symbolic integration\nalgorithms of Risch, Davenport, Trager, Bronstein and Miller; our method is not\na decision process. The implementation of this method is less than 200 lines of\nMathematica code and can be easily ported to other CAS that can solve systems\nof polynomial equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.04910v3"
    },
    {
        "title": "Groebner basis structure of ideal interpolation",
        "authors": [
            "Yihe Gong",
            "Xue Jiang"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  We study the relationship between certain Groebner bases for zero dimensional\nideals, and the interpolation condition functionals of ideal interpolation.\nIdeal interpolation is defined by a linear idempotent projector whose kernel is\na polynomial ideal. In this paper, we propose the notion of \"reverse\" complete\nreduced basis. Based on the notion, we present a fast algorithm to compute the\nreduced Groebner basis for the kernel of ideal projector under an arbitrary\ncompatible ordering. As an application, we show that knowing the affine variety\nmakes available information concerning the reduced Groebner basis.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11830v2"
    },
    {
        "title": "Border basis computation with gradient-weighted normalization",
        "authors": [
            "Hiroshi Kera"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Normalization of polynomials plays a vital role in the approximate basis\ncomputation of vanishing ideals. Coefficient normalization, which normalizes a\npolynomial with its coefficient norm, is the most common method in computer\nalgebra. This study proposes the gradient-weighted normalization method for the\napproximate border basis computation of vanishing ideals, inspired by recent\ndevelopments in machine learning. The data-dependent nature of\ngradient-weighted normalization leads to better stability against perturbation\nand consistency in the scaling of input points, which cannot be attained by\ncoefficient normalization. Only a subtle change is needed to introduce gradient\nnormalization in the existing algorithms with coefficient normalization. The\nanalysis of algorithms still works with a small modification, and the order of\nmagnitude of time complexity of algorithms remains unchanged. We also prove\nthat, with coefficient normalization, which does not provide the scaling\nconsistency property, scaling of points (e.g., as a preprocessing) can cause an\napproximate basis computation to fail. This study is the first to theoretically\nhighlight the crucial effect of scaling in approximate basis computation and\npresents the utility of data-dependent normalization.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00401v4"
    },
    {
        "title": "MultivariateApart: Generalized Partial Fractions",
        "authors": [
            "Matthias Heller",
            "Andreas von Manteuffel"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We present a package to perform partial fraction decompositions of\nmultivariate rational functions. The algorithm allows to systematically avoid\nspurious denominator factors and is capable of producing unique results also\nwhen being applied to terms of a sum separately. The package is designed to\nwork in Mathematica, but also provides interfaces to the Form and Singular\ncomputer algebra systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.08283v1"
    },
    {
        "title": "Extensions of the AZ-algorithm and the Package MultiIntegrate",
        "authors": [
            "Jakob Ablinger"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  We extend the (continuous) multivariate Almkvist-Zeilberger algorithm in\norder to apply it for instance to special Feynman integrals emerging in\nrenormalizable Quantum field Theories. We will consider multidimensional\nintegrals over hyperexponential integrands and try to find closed form\nrepresentations in terms of nested sums and products or iterated integrals. In\naddition, if we fail to compute a closed form solution in full generality, we\nmay succeed in computing the first coefficients of the Laurent series\nexpansions of such integrals in terms of indefinite nested sums and products or\niterated integrals. In this article we present the corresponding methods and\nalgorithms. Our Mathematica package MultiIntegrate, can be considered as an\nenhanced implementation of the (continuous) multivariate Almkvist Zeilberger\nalgorithm to compute recurrences or differential equations for hyperexponential\nintegrands and integrals. Together with the summation package Sigma and the\npackage HarmonicSums our package provides methods to compute closed form\nrepresentations (or coefficients of the Laurent series expansions) of\nmultidimensional integrals over hyperexponential integrands in terms of nested\nsums or iterated integrals.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.11385v1"
    },
    {
        "title": "Proceedings of the 9th International Workshop on Verification and\n  Program Transformation",
        "authors": [
            "Alexei Lisitsa",
            "Andrei P. Nemytykh"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  The previous VPT 2020 workshop was organized in honour of Professor Alberto\nPettorossi on the occasion of his academic retirement from Universit\\`a di Roma\nTor Vergata. Due to the pandemic the VPT 2020 meeting was cancelled but its\nproceeding have already appeared in the EPTCS 320 volume. The joint VPT-20-21\nevent has subsumed the original programme of VPT 2020 and provided an\nopportunity to meet and celebrate the achievements of Professor Alberto\nPettorossi; its programme was further expanded with the newly submitted\npresentations for VPT 2021. The aim of the VPT workshop series is to provide a\nforum where people from the areas of program transformation and program\nverification can fruitfully exchange ideas and gain a deeper understanding of\nthe interactions between those two fields.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.02001v1"
    },
    {
        "title": "Symbolic Computation in Software Science: My Personal View",
        "authors": [
            "Bruno Buchberger"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  In this note, I develop my personal view on the scope and relevance of\nsymbolic computation in software science. For this, I discuss the interaction\nand differences between symbolic computation, software science, automatic\nprogramming, mathematical knowledge management, artificial intelligence,\nalgorithmic intelligence, numerical computation, and machine learning. In the\ndiscussion of these notions, I allow myself to refer also to papers (1982,\n1985, 2001, 2003, 2013) of mine in which I expressed my views on these areas at\nearly stages of some of these fields.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.02806v1"
    },
    {
        "title": "Polynomial XL: A Variant of the XL Algorithm Using Macaulay Matrices\n  over Polynomial Rings",
        "authors": [
            "Hiroki Furue",
            "Momonari Kudo"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Solving a system of $m$ multivariate quadratic equations in $n$ variables\nover finite fields (the MQ problem) is one of the important problems in the\ntheory of computer science. The XL algorithm (XL for short) is a major approach\nfor solving the MQ problem with linearization over a coefficient field.\nFurthermore, the hybrid approach with XL (h-XL) is a variant of XL guessing\nsome variables beforehand. In this paper, we present a variant of h-XL, which\nwe call the \\textit{polynomial XL (PXL)}. In PXL, the whole $n$ variables are\ndivided into $k$ variables to be fixed and the remaining $n-k$ variables as\n``main variables'', and we generate a Macaulay matrix with respect to the $n-k$\nmain variables over a polynomial ring of the $k$ (sub-)variables. By\neliminating some columns of the Macaulay matrix over the polynomial ring before\nguessing $k$ variables, the amount of operations required for each guessed\nvalue can be reduced compared with h-XL. Our complexity analysis of PXL (under\nsome practical assumptions and heuristics) gives a new theoretical bound, and\nit indicates that PXL could be more efficient than other algorithms in theory\non the random system with $n=m$, which is the case of general multivariate\nsignatures. For example, on systems over the finite field with ${2^8}$ elements\nwith $n=m=80$, the numbers of operations deduced from the theoretical bounds of\nthe hybrid approaches with XL and Wiedemann XL, Crossbred, and PXL with optimal\n$k$ are estimated as $2^{252}$, $2^{234}$, $2^{237}$, and $2^{220}$,\nrespectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.05023v2"
    },
    {
        "title": "Stability of Cournot duopoly games with isoelastic demands and quadratic\n  costs",
        "authors": [
            "Xiaoliang Li",
            "Li Su"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  In this discussion draft, we explore different duopoly games of players with\nquadratic costs, where the market is supposed to have the isoelastic demand.\nDifferent from the usual approaches based on numerical computations, the\nmethods used in the present work are built on symbolic computations, which can\nproduce analytical and rigorous results. Our investigations show that the\nstability regions are enlarged for the games considered in this work compared\nto their counterparts with linear costs, which generalizes the classical\nresults of \"F. M. Fisher. The stability of the Cournot oligopoly solution: The\neffects of speeds of adjustment and increasing marginal costs. The Review of\nEconomic Studies, 28(2):125--135, 1961.\".\n",
        "pdf_link": "http://arxiv.org/pdf/2112.05948v2"
    },
    {
        "title": "Subresultant of several univariate polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "category": "cs.SC",
        "published_year": "2021",
        "summary": "  Subresultant of two univariate polynomials is a fundamental object in\ncomputational algebra and geometry with many applications (for instance,\nparametric GCD and parametric multiplicity of roots). In this paper, we\ngeneralize the theory of subresultants of two polynomials to arbitrary number\nof polynomials, resulting in multi-polynomial subresultants. Specifically,\n  1. we propose a definition of multi-polynomial subresultants, which is an\nexpression in terms of roots;\n  2. we illustrate the usefulness of the proposed definition via the following\ntwo fundamental applications:\n  - parametric GCD of multi-polynomials, and\n  - parametric multiplicity of roots of a polynomial;\n  3. we provide several expressions for the multi-polynomials subresultants in\nterms of coefficients, for computation.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.15370v4"
    },
    {
        "title": "Stability Problems in Symbolic Integration",
        "authors": [
            "Shaoshi Chen"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  This paper aims to initialize a dynamical aspect of symbolic integration by\nstudying stability problems in differential fields. We present some basic\nproperties of stable elementary functions and D-finite power series that enable\nus to characterize three special families of stable elementary functions\ninvolving rational functions, logarithmic functions, and exponential functions.\nSome problems for future studies are proposed towards deeper dynamical studies\nin differential and difference algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.06305v1"
    },
    {
        "title": "On Polynomial Ideals And Overconvergence In Tate Algebras",
        "authors": [
            "Xavier Caruso",
            "Tristan Vaccon",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In this paper, we study ideals spanned by polynomials or overconvergent\nseries in a Tate algebra. With state-of-the-art algorithms for computing Tate\nGr{\\\"o}bner bases, even if the input is polynomials, the size of the output\ngrows with the required precision, both in terms of the size of the\ncoefficients and the size of the support of the series. We prove that ideals\nwhich are spanned by polynomials admit a Tate Gr{\\\"o}bner basis made of\npolynomials, and we propose an algorithm, leveraging Mora's weak normal form\nalgorithm, for computing it. As a result, the size of the output of this\nalgorithm grows linearly with the precision. Following the same ideas, we\npropose an algorithm which computes an overconvergent basis for an ideal\nspanned by overconvergent series. Finally, we prove the existence of a\nuniversal analytic Gr{\\\"o}bner basis for polynomial ideals in Tate algebras,\ncompatible with all convergence radii.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07509v1"
    },
    {
        "title": "Extending Flat Motion Planning to Non-flat Systems. Experiments on\n  Aircraft Models Using Maple",
        "authors": [
            "François Ollivier"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Aircraft models may be considered as flat if one neglects some terms\nassociated to aerodynamics. Computational experiments in Maple show that in\nsome cases a suitably designed feed-back allows to follow such trajectories,\nwhen applied to the non-flat model. However some maneuvers may be hard or even\nimpossible to achieve with this flat approximation. In this paper, we propose\nan iterated process to compute a more achievable trajectory, starting from the\nflat reference trajectory. More precisely, the unknown neglected terms in the\nflat model are iteratively re-evaluated using the values obtained at the\nprevious step. This process may be interpreted as a new trajectory\nparametrization, using an infinite number of derivatives, a property that may\nbe called \\emph{generalized flatness}. We illustrate the pertinence of this\napproach in flight conditions of increasing difficulties, from single engine\nflight, to aileron roll.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09921v3"
    },
    {
        "title": "On realizing differential-algebraic equations by rational dynamical\n  systems",
        "authors": [
            "Dmitrii Pavlov",
            "Gleb Pogudin"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Real-world phenomena can often be conveniently described by dynamical systems\n(that is, ODE systems in the state-space form). However, if one observes the\nstate of the system only partially, the observed quantities (outputs) and the\ninputs of the system can typically be related by more complicated\ndifferential-algebraic equations (DAEs). Therefore, a natural question\n(referred to as the realizability problem) is: given a differential-algebraic\nequation (say, fitted from data), does it come from a partially observed\ndynamical system? A special case in which the functions involved in the\ndynamical system are rational is of particular interest. For a single\ndifferential-algebraic equation in a single output variable, Forsman has shown\nthat it is realizable by a rational dynamical system if and only if the\ncorresponding hypersurface is unirational, and he turned this into an algorithm\nin the first-order case.\n  In this paper, we study a more general case of single-input-single-output\nequations. We show that if a realization by a rational dynamical system exists,\nthe system can be taken to have the dimension equal to the order of the DAE. We\nprovide a complete algorithm for first-order DAEs. We also show that the same\napproach can be used for higher-order DAEs using several examples from the\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.03555v2"
    },
    {
        "title": "Deciding Cuspidality of Manipulators through Computer Algebra and\n  Algorithms in Real Algebraic Geometry",
        "authors": [
            "Damien Chablat",
            "Rémi Prébet",
            "Mohab Safey El Din",
            "Durgesh Salunkhe",
            "Philippe Wenger"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Cuspidal robots are robots with at least two inverse kinematic solutions that\ncan be connected by a singularity-free path. Deciding the cuspidality of\ngeneric 3R robots has been studied in the past, but extending the study to\nsix-degree-of-freedom robots can be a challenging problem. Many robots can be\nmodeled as a polynomial map together with a real algebraic set so that the\nnotion of cuspidality can be extended to these data. In this paper we design an\nalgorithm that, on input a polynomial map in $n$ indeterminates, and $s$\npolynomials in the same indeterminates describing a real algebraic set of\ndimension $d$, decides the cuspidality of the restriction of the map to the\nreal algebraic set under consideration. Moreover, if $D$ and $\\tau$ are,\nrespectively the maximum degree and the bound on the bit size of the\ncoefficients of the input polynomials, this algorithm runs in time log-linear\nin $\\tau$ and polynomial in $((s+d)D)^{O(n^2)}$. It relies on many high-level\nalgorithms in computer algebra which use advanced methods on real algebraic\nsets and critical loci of polynomial maps. As far as we know, this is the first\nalgorithm that tackles the cuspidality problem from a general point of view.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04578v2"
    },
    {
        "title": "Computing a Group Action from the Class Field Theory of Imaginary\n  Hyperelliptic Function Fields",
        "authors": [
            "Antoine Leudière",
            "Pierre-Jean Spaenlehauer"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  We explore algorithmic aspects of a simply transitive commutative group\naction coming from the class field theory of imaginary hyperelliptic function\nfields. Namely, the Jacobian of an imaginary hyperelliptic curve defined over\n$\\mathbb F_q$ acts on a subset of isomorphism classes of Drinfeld modules. We\ndescribe an algorithm to compute the group action efficiently. This is a\nfunction field analog of the Couveignes-Rostovtsev-Stolbunov group action. We\nreport on an explicit computation done with our proof-of-concept C++/NTL\nimplementation; it took a fraction of a second on a standard computer. We prove\nthat the problem of inverting the group action reduces to the problem of\nfinding isogenies of fixed $\\tau$-degree between Drinfeld $\\mathbb\nF_q[X]$-modules, which is solvable in polynomial time thanks to an algorithm by\nWesolowski. We give asymptotic complexity bounds for all algorithms presented\nin this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06970v6"
    },
    {
        "title": "More Efficient Identifiability Verification in ODE Models by Reducing\n  Non-Identifiability",
        "authors": [
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Gleb Pogudin",
            "Pedro Soto"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Structural global parameter identifiability indicates whether one can\ndetermine a parameter's value from given inputs and outputs in the absence of\nnoise. If a given model has parameters for which there may be infinitely many\nvalues, such parameters are called non-identifiable. We present a procedure for\naccelerating a global identifiability query by eliminating algebraically\nindependent non-identifiable parameters. Our proposed approach significantly\nimproves performance across different computer algebra frameworks.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.01623v1"
    },
    {
        "title": "Shift Equivalence Testing of Polynomials and Symbolic Summation of\n  Multivariate Rational Functions",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Hanqian Fang"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  The Shift Equivalence Testing (SET) of polynomials is deciding whether two\npolynomials $p(x_1, \\ldots, x_m)$ and $q(x_1, \\ldots, x_m)$ satisfy the\nrelation $p(x_1 + a_1, \\ldots, x_m + a_m) = q(x_1, \\ldots, x_m)$ for some $a_1,\n\\ldots, a_m$ in the coefficient field. The SET problem is one of basic\ncomputational problems in computer algebra and algebraic complexity theory,\nwhich was reduced by Dvir, Oliveira and Shpilka in 2014 to the Polynomial\nIdentity Testing (PIT) problem. This paper presents a general scheme for\ndesigning algorithms to solve the SET problem which includes\nDvir-Oliveira-Shpilka's algorithm as a special case. With the algorithms for\nthe SET problem over integers, we give complete solutions to two challenging\nproblems in symbolic summation of multivariate rational functions, namely the\nrational summability problem and the existence problem of telescopers for\nmultivariate rational functions. Our approach is based on the structure of\nisotropy groups of polynomials introduced by Sato in 1960s. Our results can be\nused to detect the applicability of the Wilf-Zeilberger method to multivariate\nrational functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.06968v2"
    },
    {
        "title": "Gluing Neural Networks Symbolically Through Hyperdimensional Computing",
        "authors": [
            "Peter Sutor",
            "Dehao Yuan",
            "Douglas Summers-Stay",
            "Cornelia Fermuller",
            "Yiannis Aloimonos"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Hyperdimensional Computing affords simple, yet powerful operations to create\nlong Hyperdimensional Vectors (hypervectors) that can efficiently encode\ninformation, be used for learning, and are dynamic enough to be modified on the\nfly. In this paper, we explore the notion of using binary hypervectors to\ndirectly encode the final, classifying output signals of neural networks in\norder to fuse differing networks together at the symbolic level. This allows\nmultiple neural networks to work together to solve a problem, with little\nadditional overhead. Output signals just before classification are encoded as\nhypervectors and bundled together through consensus summation to train a\nclassification hypervector. This process can be performed iteratively and even\non single neural networks by instead making a consensus of multiple\nclassification hypervectors. We find that this outperforms the state of the\nart, or is on a par with it, while using very little overhead, as hypervector\noperations are extremely fast and efficient in comparison to the neural\nnetworks. This consensus process can learn online and even grow or lose models\nin real time. Hypervectors act as memories that can be stored, and even further\nbundled together over time, affording life long learning capabilities.\nAdditionally, this consensus structure inherits the benefits of\nHyperdimensional Computing, without sacrificing the performance of modern\nMachine Learning. This technique can be extrapolated to virtually any neural\nmodel, and requires little modification to employ - one simply requires\nrecording the output signals of networks when presented with a testing example.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.15534v1"
    },
    {
        "title": "Hiding canonicalisation in tensor computer algebra",
        "authors": [
            "Dominic Price",
            "Kasper Peeters",
            "Marija Zamaklar"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Simplification of expressions in computer algebra systems often involves a\nstep known as \"canonicalisation\", which reduces equivalent expressions to the\nsame form. However, such forms may not be natural from the perspective of a\npen-and-paper computation, or may be unwieldy, or both. This is, for example,\nthe case for expressions involving tensor multi-term symmetries. We propose an\nalternative strategy to handle such tensor expressions, which hides canonical\nforms from the user entirely, and present an implementation of this idea in the\nCadabra computer algebra system.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.11946v1"
    },
    {
        "title": "AI-Assisted Discovery of Quantitative and Formal Models in Social\n  Science",
        "authors": [
            "Julia Balla",
            "Sihao Huang",
            "Owen Dugan",
            "Rumen Dangovski",
            "Marin Soljacic"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  In social science, formal and quantitative models, such as ones describing\neconomic growth and collective action, are used to formulate mechanistic\nexplanations, provide predictions, and uncover questions about observed\nphenomena. Here, we demonstrate the use of a machine learning system to aid the\ndiscovery of symbolic models that capture nonlinear and dynamical relationships\nin social science datasets. By extending neuro-symbolic methods to find compact\nfunctions and differential equations in noisy and longitudinal data, we show\nthat our system can be used to discover interpretable models from real-world\ndata in economics and sociology. Augmenting existing workflows with symbolic\nregression can help uncover novel relationships and explore counterfactual\nmodels during the scientific process. We propose that this AI-assisted\nframework can bridge parametric and non-parametric models commonly employed in\nsocial science research by systematically exploring the space of nonlinear\nmodels and enabling fine-grained control over expressivity and\ninterpretability.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00563v3"
    },
    {
        "title": "Gosper's algorithm and Bell numbers",
        "authors": [
            "Robert Dougherty-Bliss"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Computers are good at evaluating finite sums in closed form, but there are\nfinite sums which do not have closed forms. Summands which do not produce a\nclosed form can often be ``fixed'' by multiplying them by a suitable\npolynomial. We provide an explicit description of a class of such polynomials\nfor simple hypergeometric summands in terms of the Bell numbers.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.13520v1"
    },
    {
        "title": "Anticipation of Method Execution in Mixed Consistency Systems --\n  Technical Report",
        "authors": [
            "Marco Giunti",
            "Hervé Paulino",
            "António Ravara"
        ],
        "category": "cs.SC",
        "published_year": "2022",
        "summary": "  Distributed applications often deal with data with different consistency\nrequirements: while a post in a social network only requires weak consistency,\nthe user balance in turn has strong correctness requirements, demanding\nmutations to be synchronised. To deal efficiently with sequences of operations\non different replicas of the distributed application, it is useful to know\nwhich operations commute with others and thus, when can an operation not\nrequiring synchronisation be anticipated wrt other requiring it, thus avoiding\nunnecessary waits. Herein we present a language-based static analysis to\nextract at compile-time from code information on which operations can commute\nwith which other operations and thus get information that can be used by the\nrun-time support to decide on call anticipations of operations in replicas\nwithout compromising consistency. We illustrate the formal analysis on several\nparadigmatic examples and briefly present a proof-of-concept implementation in\nJava.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.14651v1"
    },
    {
        "title": "Fast Algorithms for Discrete Differential Equations",
        "authors": [
            "Alin Bostan",
            "Hadrien Notarantonio",
            "Mohab Safey El Din"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Discrete Differential Equations (DDEs) are functional equations that relate\npolynomially a power series $F(t,u)$ in $t$ with polynomial coefficients in a\n\"catalytic\" variable $u$ and the specializations, say at $u=1$, of $F(t,u)$ and\nof some of its partial derivatives in $u$. DDEs occur frequently in\ncombinatorics, especially in map enumeration. If a DDE is of fixed-point type\nthen its solution $F(t,u)$ is unique, and a general result by Popescu (1986)\nimplies that $F(t,u)$ is an algebraic power series. Constructive proofs of\nalgebraicity for solutions of fixed-point type DDEs were proposed by\nBousquet-M\\'elou and Jehanne (2006). Bostan et. al (2022) initiated a\nsystematic algorithmic study of such DDEs of order 1.\n  We generalize this study to DDEs of arbitrary order. First, we propose\nnontrivial extensions of algorithms based on polynomial elimination and on the\nguess-and-prove paradigm. Second, we design two brand-new algorithms that\nexploit the special structure of the underlying polynomial systems. Last, but\nnot least, we report on implementations that are able to solve highly\nchallenging DDEs with a combinatorial origin.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06203v2"
    },
    {
        "title": "On real and observable realizations of input-output equations",
        "authors": [
            "Sebastian Falkensteiner",
            "Dmitrii Pavlov",
            "Rafael Sendra"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  Given a single algebraic input-output equation, we present a method for\nfinding different representations of the associated system in the form of\nrational realizations; these are dynamical systems with rational right-hand\nsides. It has been shown that in the case where the input-output equation is of\norder one, rational realizations can be computed, if they exist. In this work,\nwe focus first on the existence and actual computation of the so-called\nobservable rational realizations, and secondly on rational realizations with\nreal coefficients. The study of observable realizations allows to find every\nrational realization of a given first order input-output equation, and the\nnecessary field extensions in this process. We show that for first order\ninput-output equations the existence of a rational realization is equivalent to\nthe existence of an observable rational realization. Moreover, we give a\ncriterion to decide the existence of real rational realizations. The\ncomputation of observable and real realizations of first order input-output\nequations is fully algorithmic. We also present partial results for the case of\nhigher order input-output equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16799v1"
    },
    {
        "title": "A multistep strategy for polynomial system solving over finite fields\n  and a new algebraic attack on the stream cipher Trivium",
        "authors": [
            "Roberto La Scala",
            "Federico Pintore",
            "Sharwan K. Tiwari",
            "Andrea Visconti"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  In this paper we introduce a multistep generalization of the\nguess-and-determine or hybrid strategy for solving a system of multivariate\npolynomial equations over a finite field. In particular, we propose performing\nthe exhaustive evaluation of a subset of variables stepwise, that is, by\nincrementing the size of such subset each time that an evaluation leads to a\npolynomial system which is possibly unfeasible to solve. The decision about\nwhich evaluation to extend is based on a preprocessing consisting in computing\nan incomplete Grobner basis after the current evaluation, which possibly\ngenerates linear polynomials that are used to eliminate further variables. If\nthe number of remaining variables in the system is deemed still too high, the\nevaluation is extended and the preprocessing is iterated. Otherwise, we solve\nthe system by a complete Grobner basis computation.\n  Having in mind cryptanalytic applications, we present an implementation of\nthis strategy in an algorithm called MultiSolve which is designed for\npolynomial systems having at most one solution. We prove explicit formulas for\nits complexity which are based on probability distributions that can be easily\nestimated by performing the proposed preprocessing on a testset of evaluations\nfor different subsets of variables. We prove that an optimal complexity of\nMultiSolve is achieved by using a full multistep strategy with a maximum number\nof steps and in turn the standard guess-and-determine strategy, which\nessentially is a strategy consisting of a single step, is the worst choice.\nFinally, we extensively study the behaviour of MultiSolve when performing an\nalgebraic attack on the well-known stream cipher Trivium.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.07820v2"
    },
    {
        "title": "New Bounds on Quotient Polynomials with Applications to Exact\n  Divisibility and Divisibility Testing of Sparse Polynomials",
        "authors": [
            "Ido Nahshon",
            "Amir Shpilka"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We prove that for monic polynomials $f, g \\in \\mathbb{C}[x]$ such that $g$\ndivides $f$, the $\\ell_2$-norm of the quotient polynomial $f/g$ is bounded by\n$\\lVert f \\rVert_1 \\cdot \\tilde{O}(\\lVert{g}\\rVert_0^3\\text{deg}^2{\nf})^{\\lVert{g}\\rVert_0 - 1}$. This improves upon the previously known\nexponential (in $\\text{deg}{ f}$) bounds for general polynomials. Our results\nimplies that the trivial long division algorithm runs in quasi-linear time\nrelative to the input size and number of terms of the quotient polynomial\n$f/g$, thus solving a long-standing problem on exact divisibility of sparse\npolynomials.\n  We also study the problem of bounding the number of terms of $f/g$ in some\nspecial cases. When $f, g \\in \\mathbb{Z}[x]$ and $g$ is a cyclotomic-free\n(i.e., it has no cyclotomic factors) trinomial, we prove that\n$\\lVert{f/g}\\rVert_0 \\leq O(\\lVert{f}\\rVert_0 \\text{size}({f})^2 \\cdot\n\\log^6{\\text{deg}{ g}})$. When $g$ is a cyclotomic-free binomial, we prove that\nthe sparsity is at most $O(\\lVert{f}\\rVert_0 ( \\log{\\lVert{f}\\rVert_0} +\n\\log{\\lVert{f}\\rVert_{\\infty}}))$. Both upper bounds are polynomial in the\ninput-size. We leverage these results and give a polynomial time algorithm for\ndeciding whether a cyclotomic-free trinomial divides a sparse polynomial over\nthe integers.\n  As our last result, we present a polynomial time algorithm for testing\ndivisibility by pentanomials over small finite fields when $\\text{deg}{ f} =\n\\tilde{O}(\\text{deg}{ g})$.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.03885v3"
    },
    {
        "title": "Field theory with the Maxima computer algebra system",
        "authors": [
            "Viktor T. Toth"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  The Maxima computer algebra system, the open-source successor to MACSYMA, the\nfirst general-purpose computer algebra system that was initially developed at\nthe Massachusetts Institute of Technology in the late 1960s and later\ndistributed by the United States Department of Energy, has some remarkable\ncapabilities, some of which are implemented in the form of add-on, \"share\"\npackages that are distributed along with the core Maxima system. One such share\npackage is itensor, for indicial tensor manipulation. One of the more\nremarkable features of itensor is functional differentiation. Through this, it\nis possible to use itensor to develop a Lagrangian field theory and derive the\ncorresponding field equations. In the present note, we demonstrate this\ncapability by deriving Maxwell's equations from the Maxwell Lagrangian, and\nexploring the properties of the system, including current conservation.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09837v1"
    },
    {
        "title": "Three Paths to Rational Curves with Rational Arc Length",
        "authors": [
            "Hans-Peter Schröcker",
            "Zbyněk Šìr"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We solve the so far open problem of constructing all spatial rational curves\nwith rational arc length functions. More precisely, we present three different\nmethods for this construction. The first method adapts a recent approach of\n(Kalkan et al. 2022) to rational PH curves and requires solving a modestly\nsized system of linear equations. The second constructs the curve by imposing\nzero-residue conditions, thus extending ideas of previous papers by (Farouki\nand Sakkalis 2019) and the authors themselves (Schr\\\"ocker and \\v{S}\\'ir 2023).\nThe third method generalizes the dual approach of (Pottmann 1995) from planar\nto spatial curves. The three methods share the same quaternion based\nrepresentation in which not only the PH curve but also its arc length function\nare compactly expressed. We also present a new proof based on the quaternion\npolynomial factorization theory of the well known characterization of the\nPythagorean quadruples.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.08047v2"
    },
    {
        "title": "Stability Problems on D-finite Functions",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Zewang Guo",
            "Wei Lu"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  This paper continues the studies of symbolic integration by focusing on the\nstability problems on D-finite functions. We introduce the notion of stability\nindex in order to investigate the order growth of the differential operators\nsatisfied by iterated integrals of D-finite functions and determine bounds and\nexact formula for stability indices of several special classes of differential\noperators. With the basic properties of stability index, we completely solve\nthe stability problem on general hyperexponential functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.05897v1"
    },
    {
        "title": "Nested Integrals and Rationalizing Transformations",
        "authors": [
            "Clemens G. Raab"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  A brief overview of some computer algebra methods for computations with\nnested integrals is given. The focus is on nested integrals over integrands\ninvolving square roots. Rewrite rules for conversion to and from associated\nnested sums are discussed. We also include a short discussion comparing the\nholonomic systems approach and the differential field approach. For\nsimplification to rational integrands, we give a comprehensive list of\nunivariate rationalizing transformations, including transformations tuned to\nmap the interval $[0,1]$ bijectively to itself.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.16992v1"
    },
    {
        "title": "Finite Expression Method for Learning Dynamics on Complex Networks",
        "authors": [
            "Zezheng Song",
            "Chunmei Wang",
            "Haizhao Yang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Complex network data pervades various real-world domains, including physical,\ntechnological, and biological systems. Despite the prevalence of such data,\npredicting trends and understanding behavioral patterns in complex systems\nremains challenging due to poorly understood underlying mechanisms. While\ndata-driven methods have made strides in uncovering governing equations from\ntime series data, efforts to extract physical laws from network data are\nlimited and often struggle with incomplete or noisy data. To address these\nchallenges, we introduce a novel approach called the Finite Expression Method\n(FEX) and its fast algorithm for this learning problem on complex networks. FEX\nrepresents dynamics on complex networks using binary trees composed of finite\nmathematical operators. The nodes within these trees are trained through a\ncombinatorial optimization process guided by reinforcement learning techniques.\nThis unique configuration allows FEX to capture complex dynamics with minimal\nprior knowledge of the system and a small dictionary of mathematical operators.\nOur extensive numerical experiments demonstrate that FEX excels in accurately\nidentifying dynamics across diverse network topologies and dynamic behaviors.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03092v2"
    },
    {
        "title": "Universal Analytic Gr{ö}bner Bases and Tropical Geometry",
        "authors": [
            "Tristan Vaccon",
            "Thibaut Verron"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  A universal analytic Gr{\\\"o}bner basis (UAGB) of an ideal of a Tate algebra\nis a set containing a local Gr{\\\"o}bner basis for all suitable convergence\nradii. In a previous article, the authors proved the existence of finite UAGB's\nfor polynomial ideals, leaving open the question of how to compute them. In\nthis paper, we provide an algorithm computing a UAGB for a given polynomial\nideal, by traversing the Gr{\\\"o}bner fan of the ideal. As an application, it\noffers a new point of view on algorithms for computing tropical varieties of\nhomogeneous polynomial ideals, which typically rely on lifting the computations\nto an algebra of power series. Motivated by effective computations in tropical\nanalytic geometry, we also examine local bases for more general convergence\nconditions, constraining the radii to a convex polyhedron. In this setting, we\nprovide an algorithm to compute local Gr{\\\"o}bner bases and discuss obstacles\ntowards proving the existence of finite UAGBs. CCS CONCEPTS $\\bullet$ Computing\nmethodologies $\\rightarrow$ Algebraic algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.05759v1"
    },
    {
        "title": "On Hilbert-Poincaré series of affine semi-regular polynomial\n  sequences and related Gröbner bases",
        "authors": [
            "Momonari Kudo",
            "Kazuhiro Yokoyama"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Gr\\\"{o}bner bases are nowadays central tools for solving various problems in\ncommutative algebra and algebraic geometry. A typical use of Gr\\\"{o}bner bases\nis the multivariate polynomial system solving, which enables us to construct\nalgebraic attacks against post-quantum cryptographic protocols. Therefore, the\ndetermination of the complexity of computing Gr\\\"{o}bner bases is very\nimportant both in theory and in practice: One of the most important cases is\nthe case where input polynomials compose an (overdetermined) affine\nsemi-regular sequence. The first part of this paper aims to present a survey on\nGr\\\"{o}bner basis computation and its complexity. In the second part, we shall\ngive an explicit formula on the (truncated) Hilbert-Poincar\\'{e} series\nassociated to the homogenization of an affine semi-regular sequence. Based on\nthe formula, we also study (reduced) Gr\\\"{o}bner bases of the ideals generated\nby an affine semi-regular sequence and its homogenization. Some of our results\nare considered to give mathematically rigorous proofs of the correctness of\nmethods for computing Gr\\\"{o}bner bases of the ideal generated by an affine\nsemi-regular sequence.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07768v2"
    },
    {
        "title": "Bootstrapping OTS-Funcimg Pre-training Model (Botfip) -- A Comprehensive\n  Symbolic Regression Framework",
        "authors": [
            "Tianhao Chen",
            "Pengbo Xu",
            "Haibiao Zheng"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In the field of scientific computing, many problem-solving approaches tend to\nfocus only on the process and final outcome, even in AI for science, there is a\nlack of deep multimodal information mining behind the data, missing a\nmultimodal framework akin to that in the image-text domain. In this paper, we\ntake Symbolic Regression(SR) as our focal point and, drawing inspiration from\nthe BLIP model in the image-text domain, propose a scientific computing\nmultimodal framework based on Function Images (Funcimg) and Operation Tree\nSequence (OTS), named Bootstrapping OTS-Funcimg Pre-training Model (Botfip). In\nSR experiments, we validate the advantages of Botfip in low-complexity SR\nproblems, showcasing its potential. As a MED framework, Botfip holds promise\nfor future applications in a broader range of scientific computing problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.09748v1"
    },
    {
        "title": "Showing Proofs, Assessing Difficulty with GeoGebra Discovery",
        "authors": [
            "Zoltán Kovács",
            "Tomás Recio",
            "M. Pilar Vélez"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In our contribution we describe some on-going improvements concerning the\nAutomated Reasoning Tools developed in GeoGebra Discovery, providing different\nexamples of the performance of these new features. We describe the new\nShowProof command, that outputs both the sequence of the different steps\nperformed by GeoGebra Discovery to confirm a certain statement, as well as a\nnumber intending to grade the difficulty or interest of the assertion. The\nproposal of this assessment measure, involving the comparison of the expression\nof the thesis (or conclusion) as a combination of the hypotheses, will be\ndeveloped.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11900v1"
    },
    {
        "title": "Solving with GeoGebra Discovery an Austrian Mathematics Olympiad\n  problem: Lessons Learned",
        "authors": [
            "Belén Ariño-Morera",
            "Zoltán Kovács",
            "Tomás Recio",
            "Piedad Tolmos"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We address, through the automated reasoning tools in GeoGebra Discovery, a\nproblem from a regional phase of the Austrian Mathematics Olympiad 2023. Trying\nto solve this problem gives rise to four different kind of feedback: the almost\ninstantaneous, automated solution of the proposed problem; the measure of its\ncomplexity, according to some recent proposals; the automated discovery of a\ngeneralization of the given assertion, showing that the same statement is true\nover more general polygons than those mentioned in the problem; and the\ndifficulties associated to the analysis of the surprising and involved high\nnumber of degenerate cases that appear when using the LocusEquation command in\nthis problem. In our communication we will describe and reflect on these\ndiverse issues, enhancing its exemplar role for showing some of the advantages,\nproblems, and current fields of development of GeoGebra Discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11906v1"
    },
    {
        "title": "On the Algorithmic Verification of Nonlinear Superposition for Systems\n  of First Order Ordinary Differential Equations",
        "authors": [
            "Veronika Treumova",
            "Dmitry A. Lyakhov",
            "Dominik L. Michels"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  This paper belongs to a group of work in the intersection of symbolic\ncomputation and group analysis aiming for the symbolic analysis of differential\nequations. The goal is to extract important properties without finding the\nexplicit general solution. In this contribution, we introduce the algorithmic\nverification of nonlinear superposition properties and its implementation. More\nexactly, for a system of nonlinear ordinary differential equations of first\norder with a polynomial right-hand side, we check if the differential system\nadmits a general solution by means of a superposition rule and a certain number\nof particular solutions. It is based on the theory of Newton polytopes and\nassociated symbolic computation. The developed method provides the basis for\nthe identification of nonlinear superpositions within a given system and for\nthe construction of numerical methods which preserve important algebraic\nproperties at the numerical level.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.17012v1"
    },
    {
        "title": "Automated Data-Driven Discovery of Material Models Based on Symbolic\n  Regression: A Case Study on Human Brain Cortex",
        "authors": [
            "Jixin Hou",
            "Xianyan Chen",
            "Taotao Wu",
            "Ellen Kuhl",
            "Xianqiao Wang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We introduce a data-driven framework to automatically identify interpretable\nand physically meaningful hyperelastic constitutive models from sparse data.\nLeveraging symbolic regression, an algorithm based on genetic programming, our\napproach generates elegant hyperelastic models that achieve accurate data\nfitting through parsimonious mathematic formulae, while strictly adhering to\nhyperelasticity constraints such as polyconvexity. Our investigation spans\nthree distinct hyperelastic models -- invariant-based, principal stretch-based,\nand normal strain-based -- and highlights the versatility of symbolic\nregression. We validate our new approach using synthetic data from five classic\nhyperelastic models and experimental data from the human brain to demonstrate\nalgorithmic efficacy. Our results suggest that our symbolic regression robustly\ndiscovers accurate models with succinct mathematic expressions in\ninvariant-based, stretch-based, and strain-based scenarios. Strikingly, the\nstrain-based model exhibits superior accuracy, while both stretch- and\nstrain-based models effectively capture the nonlinearity and\ntension-compression asymmetry inherent to human brain tissue. Polyconvexity\nexaminations affirm the rigor of convexity within the training regime and\ndemonstrate excellent extrapolation capabilities beyond this regime for all\nthree models. However, the stretch-based models raise concerns regarding\npotential convexity loss under large deformations. Finally, robustness tests on\nnoise-embedded data underscore the reliability of our symbolic regression\nalgorithms. Our study confirms the applicability and accuracy of symbolic\nregression in the automated discovery of hyperelastic models for the human\nbrain and gives rise to a wide variety of applications in other soft matter\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.05238v1"
    },
    {
        "title": "Computing discrete residues of rational functions",
        "authors": [
            "Carlos E. Arreche",
            "Hari P. Sitaula"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  In 2012 Chen and Singer introduced the notion of discrete residues for\nrational functions as a complete obstruction to rational summability. More\nexplicitly, for a given rational function f(x), there exists a rational\nfunction g(x) such that f(x) = g(x+1) - g(x) if and only if every discrete\nresidue of f(x) is zero. Discrete residues have many important further\napplications beyond summability: to creative telescoping problems, thence to\nthe determination of (differential-)algebraic relations among hypergeometric\nsequences, and subsequently to the computation of (differential) Galois groups\nof difference equations. However, the discrete residues of a rational function\nare defined in terms of its complete partial fraction decomposition, which\nmakes their direct computation impractical due to the high complexity of\ncompletely factoring arbitrary denominator polynomials into linear factors. We\ndevelop a factorization-free algorithm to compute discrete residues of rational\nfunctions, relying only on gcd computations and linear algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07328v1"
    },
    {
        "title": "Solving the p-Riccati Equations and Applications to the Factorisation of\n  Differential Operators",
        "authors": [
            "Raphaël Pagès"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  The solutions of the equation f^{ (p--1) }+ f^p = h^p in the unknown function\nf overan algebraic function field of characteristic p are very closely linked\nto the structure and fac-torisations of linear differential operators with\ncoefficients in function fields of characteristic p.However, while being able\nto solve this equation over general algebraic function fields is necessaryeven\nfor operators with rational coefficients, no general resolution method has been\ndeveloped.We present an algorithm for testing the existence of solutions in\npolynomial time in the ``size''of h and an algorithm based on the computation\nof Riemann-Roch spaces and the selection ofelements in the divisor class group,\nfor computing solutions of size polynomial in the ``size'' of hin polynomial\ntime in the size of h and linear in the characteristic p, and discuss its\napplicationsto the factorisation of linear differential operators in positive\ncharacteristic p.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06542v2"
    },
    {
        "title": "Structural Preprocessing Method for Nonlinear Differential-Algebraic\n  Equations Using Linear Symbolic Matrices",
        "authors": [
            "Taihei Oki",
            "Yujin Song"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Differential-algebraic equations (DAEs) have been used in modeling various\ndynamical systems in science and engineering. Several preprocessing methods for\nDAEs, such as consistent initialization and index reduction, use structural\ninformation on DAEs. Unfortunately, these methods may fail when the system\nJacobian, which is a functional matrix, derived from the DAE is singular.\n  To transform a DAE with a singular system Jacobian into a nonsingular system,\nseveral regularization methods have been proposed. Most of all existing\nregularization methods rely on symbolic computation to eliminate the system\nJacobian for finding a certificate of singularity, resulting in much\ncomputational time. Iwata--Oki--Takamatsu (2019) proposed a method (IOT-method)\nto find a certificate without symbolic computations. The IOT method\napproximates the system Jacobian by a simpler symbolic matrix, called a layered\nmixed matrix, which admits a fast combinatorial algorithm for singularity\ntesting. However, it often overlooks the singularity of the system Jacobian\nsince the approximation largely discards algebraic relationships among entries\nin the original system Jacobian.\n  In this study, we propose a new regularization method extending the idea of\nthe IOT method. Instead of layered mixed matrices, our method approximates the\nsystem Jacobian by more expressive symbolic matrices, called rank-1 coefficient\nmixed (1CM) matrices. This makes our method more widely applicable. We give a\nfast combinatorial algorithm for finding a singularity certificate of\n1CM-matrices, which is free from symbolic elimination. Our method is also\nadvantageous in that it globally preserves the solution set to the DAE. Through\nnumerical experiments, we confirmed that our method runs fast for large-scale\nDAEs from real instances.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.10260v1"
    },
    {
        "title": "First-order factors of linear Mahler operators",
        "authors": [
            "Frédéric Chyzak",
            "Thomas Dreyfus",
            "Philippe Dumas",
            "Marc Mezzarobba"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We develop and compare two algorithms for computing first-order right-hand\nfactors in the ring of linear Mahler operators$\\ell_r M^r + \\dots + \\ell_1 M +\n\\ell_0$where $\\ell_0, \\dots, \\ell_r$ are polynomials in~$x$ and $Mx = x^b M$\nfor some integer $b \\geq 2$. In other words, we give algorithms for finding all\nformal infinite product solutions of linear functional equations$\\ell_r(x)\nf(x^{b^r}) + \\dots + \\ell_1(x) f(x^b) + \\ell_0(x) f(x) = 0$. The first of our\nalgorithms is adapted from Petkov\\v{s}ek's classical algorithm forthe analogous\nproblem in the case of linear recurrences. The second one proceeds by computing\na basis of generalized power series solutions of the functional equation and by\nusing Hermite-Pad{\\'e} approximants to detect those linear combinations of the\nsolutions that correspond to first-order factors. We present implementations of\nboth algorithms and discuss their use in combination with criteria from the\nliterature to prove the differential transcendence of power series solutions of\nMahler equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.11545v2"
    },
    {
        "title": "Gr{ö}bner bases over polytopal affinoid algebras",
        "authors": [
            "Moulay A. Barkatou",
            "Lucas Legrand",
            "Tristan Vaccon"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Polyhedral affinoid algebras have been introduced by Einsiedler, Kapranov and\nLind to connect rigid analytic geometry (analytic geometry over non-archimedean\nfields) and tropical geometry.In this article, we present a theory of\nGr{\\\"o}bner bases for polytopal affinoid algebras that extends both Caruso et\nal.'s theory of Gr{\\\"o}bner bases on Tate algebras and Pauer et al.'s theory of\nGr{\\\"o}bner bases on Laurent polynomials.We provide effective algorithms to\ncompute Gr{\\\"o}bner bases for both ideals of Laurent polynomials and ideals in\npolytopal affinoid algebras. Experiments with a Sagemath implementation are\nprovided.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13382v1"
    },
    {
        "title": "On the Algorithmic Recovering of Coefficients in Linearizable\n  Differential Equations",
        "authors": [
            "Dmitry A. Lyakhov",
            "Dominik L. Michels"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We investigate the problem of recovering coefficients in scalar nonlinear\nordinary differential equations that can be exactly linearized. This\ncontribution builds upon prior work by Lyakhov, Gerdt, and Michels, which\nfocused on obtaining a linearizability certificate through point\ntransformations. Our focus is on quasi-linear equations, specifically those\nsolved for the highest derivative with a rational dependence on the variables\ninvolved. Our novel algorithm for coefficient recovery relies on basic\noperations on Lie algebras, such as computing the derived algebra and the\ndimension of the symmetry algebra. This algorithmic approach is efficient,\nalthough finding the linearization transformation necessitates computing at\nleast one solution of the corresponding Bluman-Kumei equation system.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01798v1"
    },
    {
        "title": "A Basis-preserving Algorithm for Computing the Bezout Matrix of Newton\n  Polynomials",
        "authors": [
            "Jing Yang",
            "Wei Yang"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  This paper tackles the problem of constructing Bezout matrices for Newton\npolynomials in a basis-preserving approach that operates directly with the\ngiven Newton basis, thus avoiding the need for transformation from Newton basis\nto monomial basis. This approach significantly reduces the computational cost\nand also mitigates numerical instability caused by basis transformation. For\nthis purpose, we investigate the internal structure of Bezout matrices in\nNewton basis and design a basis-preserving algorithm that generates the Bezout\nmatrix in the specified basis used to formulate the input polynomials.\nFurthermore, we show an application of the proposed algorithm on constructing\nconfederate resultant matrices for Newton polynomials. Experimental results\ndemonstrate that the proposed methods perform superior to the\nbasis-transformation-based ones.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.18117v1"
    },
    {
        "title": "Effective alpha theory certification using interval arithmetic: alpha\n  theory over regions",
        "authors": [
            "Kisun Lee"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We reexamine Smale's alpha theory as a way to certify a numerical solution to\nan analytic system. For a given point and a system, Smale's alpha theory\ndetermines whether Newton's method applied to this point shows the quadratic\nconvergence to an exact solution. We introduce the alpha theory computation\nusing interval arithmetic to avoid costly exact arithmetic. As a\nstraightforward variation of the alpha theory, our work improves computational\nefficiency compared to software employing the traditional alpha theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04842v1"
    },
    {
        "title": "LinApart: optimizing the univariate partial fraction decomposition",
        "authors": [
            "Bakar Chargeishvili",
            "Levente Fekésházy",
            "Gábor Somogyi",
            "Sam Van Thurenhout"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  We present LinApart, a routine designed for efficiently performing the\nunivariate partial fraction decomposition of large symbolic expressions. Our\nmethod is based on an explicit closed formula for the decomposition of rational\nfunctions with fully factorized denominators. We provide implementations in\nboth the Wolfram Mathematica and C languages, made available at\nhttps://github.com/fekeshazy/LinApart . The routine can provide very\nsignificant performance gains over available tools such as the Apart command in\nMathematica.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.20130v1"
    },
    {
        "title": "Computing Clipped Products",
        "authors": [
            "Arthur C. Norman",
            "Stephen M. Watt"
        ],
        "category": "cs.SC",
        "published_year": "2024",
        "summary": "  Sometimes only some digits of a numerical product or some terms of a\npolynomial or series product are required. Frequently these constitute the most\nsignificant or least significant part of the value, for example when computing\ninitial values or refinement steps in iterative approximation schemes. Other\nsituations require the middle portion. In this paper we provide algorithms for\nthe general problem of computing a given span of coefficients within a product,\nthat is the terms within a range of degrees for univariate polynomials or range\ndigits of an integer. This generalizes the \"middle product\" concept of Hanrot,\nQuercia and Zimmerman. We are primarily interested in problems of modest size\nwhere constant speed up factors can improve overall system performance, and\ntherefore focus the discussion on classical and Karatsuba multiplication and\nhow methods may be combined.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.04133v1"
    },
    {
        "title": "A Symbolic Summation Approach to Feynman Integral Calculus",
        "authors": [
            "Johannes Bluemlein",
            "Sebastian Klein",
            "Carsten Schneider",
            "Flavia Stan"
        ],
        "category": "cs.SC",
        "published_year": "2010",
        "summary": "  Given a Feynman parameter integral, depending on a single discrete variable\n$N$ and a real parameter $\\epsilon$, we discuss a new algorithmic framework to\ncompute the first coefficients of its Laurent series expansion in $\\epsilon$.\nIn a first step, the integrals are expressed by hypergeometric multi-sums by\nmeans of symbolic transformations. Given this sum format, we develop new\nsummation tools to extract the first coefficients of its series expansion\nwhenever they are expressible in terms of indefinite nested product-sum\nexpressions. In particular, we enhance the known multi-sum algorithms to derive\nrecurrences for sums with complicated boundary conditions, and we present new\nalgorithms to find formal Laurent series solutions of a given recurrence\nrelation.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.2656v2"
    },
    {
        "title": "Advanced Computer Algebra Algorithms for the Expansion of Feynman\n  Integrals",
        "authors": [
            "J. Ablinger",
            "S. Blümlein",
            "M. Round",
            "C. Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2012",
        "summary": "  Two-point Feynman parameter integrals, with at most one mass and containing\nlocal operator insertions in $4+\\ep$-dimensional Minkowski space, can be\ntransformed to multi-integrals or multi-sums over hyperexponential and/or\nhypergeometric functions depending on a discrete parameter $n$. Given such a\nspecific representation, we utilize an enhanced version of the multivariate\nAlmkvist--Zeilberger algorithm (for multi-integrals) and a common summation\nframework of the holonomic and difference field approach (for multi-sums) to\ncalculate recurrence relations in $n$. Finally, solving the recurrence we can\ndecide efficiently if the first coefficients of the Laurent series expansion of\na given Feynman integral can be expressed in terms of indefinite nested sums\nand products; if yes, the all $n$ solution is returned in compact\nrepresentations, i.e., no algebraic relations exist among the occurring sums\nand products.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.1685v1"
    },
    {
        "title": "Planar Linkages Following a Prescribed Motion",
        "authors": [
            "Matteo Gallet",
            "Christoph Koutschan",
            "Zijia Li",
            "Georg Regensburger",
            "Josef Schicho",
            "Nelly Villamizar"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Designing mechanical devices, called linkages, that draw a given plane curve\nhas been a topic that interested engineers and mathematicians for hundreds of\nyears, and recently also computer scientists. Already in 1876, Kempe proposed a\nprocedure for solving the problem in full generality, but his constructions\ntend to be extremely complicated. We provide a novel algorithm that produces\nmuch simpler linkages, but works only for parametric curves. Our approach is to\ntransform the problem into a factorization task over some noncommutative\nalgebra. We show how to compute such a factorization, and how to use it to\nconstruct a linkage tracing a given curve.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05623v2"
    },
    {
        "title": "(Pure) transcendence bases in $φ$-deformed shuffle bialgebras",
        "authors": [
            "Van Chiên Bui",
            "Gérard H. E. Duchamp",
            "Quoc Hoan Ngô",
            "Vincel Hoang Ngoc Minh",
            "Christophe Tollu"
        ],
        "category": "cs.SC",
        "published_year": "2015",
        "summary": "  Computations with integro-differential operators are often carried out in an\nassociative algebra with unit, and they are essentially non-commutative\ncomputations. By adjoining a cocommutative co-product, one can have those\noperators perform act on a bialgebra isomorphic to an enveloping algebra. That\ngives an adequate framework for a computer-algebra implementation via monoidal\nfactorization, (pure) transcendence bases and Poincar\\'e--Birkhoff--Witt bases.\nIn this paper, we systematically study these deformations, obtaining necessary\nand sufficient conditions for the operators to exist, and we give the most\ngeneral cocommutative deformations of the shuffle co-product and an effective\nconstruction of pairs of bases in duality. The paper ends by the combinatorial\nsetting of local systems of coordinates on the group of group-like series.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.01089v2"
    },
    {
        "title": "Symbolic Computations of First Integrals for Polynomial Vector Fields",
        "authors": [
            "Guillaume Chèze",
            "Thierry Combot"
        ],
        "category": "cs.SC",
        "published_year": "2017",
        "summary": "  In this article we show how to generalize to the Darbouxian, Liouvillian and\nRiccati case the extactic curve introduced by J. Pereira. With this approach,\nwe get new algorithms for computing, if it exists, a rational, Darbouxian,\nLiouvillian or Riccati first integral with bounded degree of a polynomial\nplanar vector field. We give probabilistic and deterministic algorithms. The\narithmetic complexity of our probabilistic algorithm is in\n$\\tilde{\\mathcal{O}}(N^{\\omega+1})$, where $N$ is the bound on the degree of a\nrepresentation of the first integral and $\\omega \\in [2;3]$ is the exponent of\nlinear algebra. This result improves previous algorithms. Our algorithms have\nbeen implemented in Maple and are available on authors' websites. In the last\nsection, we give some examples showing the efficiency of these algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08225v2"
    },
    {
        "title": "Computer Algebra in Physics: The hidden SO(4) symmetry of the hydrogen\n  atom",
        "authors": [
            "Pascal Szriftgiser",
            "Edgardo S. Cheb-Terrab"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Pauli first noticed the hidden SO(4) symmetry for the Hydrogen atom in the\nearly stages of quantum mechanics [1]. Departing from that symmetry, one can\nrecover the spectrum of a spinless hydrogen atom and the degeneracy of its\nstates without explicitly solving Schr\\\"odinger's equation [2]. In this paper,\nwe derive that SO(4) symmetry and spectrum using a computer algebra system\n(CAS). While this problem is well known [3, 4], its solution involves several\nsteps of manipulating expressions with tensorial quantum operators, simplifying\nthem by taking into account a combination of commutator rules and Einstein's\nsum rule for repeated indices. Therefore, it is an excellent model to test the\ncurrent status of CAS concerning this kind of quantum-and-tensor-algebra\ncomputations. Generally speaking, when capable, CAS can significantly help with\nmanipulations that, like non-commutative tensor calculus subject to algebra\nrules, are tedious, time-consuming and error-prone. The presentation also shows\na pattern of computer algebra operations that can be useful for systematically\ntackling more complicated symbolic problems of this kind.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.12498v2"
    },
    {
        "title": "On the Complexity of Computing with Planar Algebraic Curves",
        "authors": [
            "Alexander Kobel",
            "Michael Sagraloff"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  In this paper, we give improved bounds for the computational complexity of\ncomputing with planar algebraic curves. More specifically, for arbitrary\ncoprime polynomials $f$, $g \\in \\mathbb{Z}[x,y]$ and an arbitrary polynomial $h\n\\in \\mathbb{Z}[x,y]$, each of total degree less than $n$ and with integer\ncoefficients of absolute value less than $2^\\tau$, we show that each of the\nfollowing problems can be solved in a deterministic way with a number of bit\noperations bounded by $\\tilde{O}(n^6+n^5\\tau)$, where we ignore polylogarithmic\nfactors in $n$ and $\\tau$:\n  (1) The computation of isolating regions in $\\mathbb{C}^2$ for all complex\nsolutions of the system $f = g = 0$,\n  (2) the computation of a separating form for the solutions of $f = g = 0$,\n  (3) the computation of the sign of $h$ at all real valued solutions of $f = g\n= 0$, and\n  (4) the computation of the topology of the planar algebraic curve\n$\\mathcal{C}$ defined as the real valued vanishing set of the polynomial $f$.\n  Our bound improves upon the best currently known bounds for the first three\nproblems by a factor of $n^2$ or more and closes the gap to the\nstate-of-the-art randomized complexity for the last problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5690v2"
    },
    {
        "title": "Gröbner Bases and Nullstellensätze for Graph-Coloring Ideals",
        "authors": [
            "Jesús A. De Loera",
            "Susan Margulies",
            "Michael Pernpeintner",
            "Eric Riedl",
            "David Rolnick",
            "Gwen Spencer",
            "Despina Stasi",
            "Jon Swenson"
        ],
        "category": "cs.SC",
        "published_year": "2014",
        "summary": "  We revisit a well-known family of polynomial ideals encoding the problem of\ngraph-$k$-colorability. Our paper describes how the inherent combinatorial\nstructure of the ideals implies several interesting algebraic properties.\nSpecifically, we provide lower bounds on the difficulty of computing Gr\\\"obner\nbases and Nullstellensatz certificates for the coloring ideals of general\ngraphs. For chordal graphs, however, we explicitly describe a Gr\\\"obner basis\nfor the coloring ideal, and provide a polynomial-time algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.6806v1"
    },
    {
        "title": "A toolbox to solve coupled systems of differential and difference\n  equations",
        "authors": [
            "Jakob Ablinger",
            "Johannes Bluemlein",
            "Abilio de Freitas",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2016",
        "summary": "  We present algorithms to solve coupled systems of linear differential\nequations, arising in the calculation of massive Feynman diagrams with local\noperator insertions at 3-loop order, which do {\\it not} request special choices\nof bases. Here we assume that the desired solution has a power series\nrepresentation and we seek for the coefficients in closed form. In particular,\nif the coefficients depend on a small parameter $\\ep$ (the dimensional\nparameter), we assume that the coefficients themselves can be expanded in\nformal Laurent series w.r.t.\\ $\\ep$ and we try to compute the first terms in\nclosed form. More precisely, we have a decision algorithm which solves the\nfollowing problem: if the terms can be represented by an indefinite nested\nhypergeometric sum expression (covering as special cases the harmonic sums,\ncyclotomic sums, generalized harmonic sums or nested binomial sums), then we\ncan calculate them. If the algorithm fails, we obtain a proof that the terms\ncannot be represented by the class of indefinite nested hypergeometric sum\nexpressions. Internally, this problem is reduced by holonomic closure\nproperties to solving a coupled system of linear difference equations. The\nunderlying method in this setting relies on decoupling algorithms, difference\nring algorithms and recurrence solving. We demonstrate by a concrete example\nhow this algorithm can be applied with the new Mathematica package\n\\texttt{SolveCoupledSystem} which is based on the packages \\texttt{Sigma},\n\\texttt{HarmonicSums} and \\texttt{OreSys}. In all applications the\nrepresentation in $x$-space is obtained as an iterated integral representation\nover general alphabets, generalizing Poincar\\'{e} iterated integrals.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.01856v1"
    },
    {
        "title": "Computer algebra tools for Feynman integrals and related multi-sums",
        "authors": [
            "Johannes Blümlein",
            "Carsten Schneider"
        ],
        "category": "cs.SC",
        "published_year": "2018",
        "summary": "  In perturbative calculations, e.g., in the setting of Quantum Chromodynamics\n(QCD) one aims at the evaluation of Feynman integrals. Here one is often faced\nwith the problem to simplify multiple nested integrals or sums to expressions\nin terms of indefinite nested integrals or sums. Furthermore, one seeks for\nsolutions of coupled systems of linear differential equations, that can be\nrepresented in terms of indefinite nested sums (or integrals). In this article\nwe elaborate the main tools and the corresponding packages, that we have\ndeveloped and intensively used within the last 10 years in the course of our\nQCD-calculations.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06168v1"
    },
    {
        "title": "Epistemic Phase Transitions in Mathematical Proofs",
        "authors": [
            "Scott Viteri",
            "Simon DeDeo"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  Mathematical proofs are both paradigms of certainty and some of the most\nexplicitly-justified arguments that we have in the cultural record. Their very\nexplicitness, however, leads to a paradox, because the probability of error\ngrows exponentially as the argument expands. When a mathematician encounters a\nproof, how does she come to believe it? Here we show that, under a\ncognitively-plausible belief formation mechanism combining deductive and\nabductive reasoning, belief in mathematical arguments can undergo what we call\nan epistemic phase transition: a dramatic and rapidly-propagating jump from\nuncertainty to near-complete confidence at reasonable levels of claim-to-claim\nerror rates. To show this, we analyze an unusual dataset of forty-eight\nmachine-aided proofs from the formalized reasoning system Coq, including major\ntheorems ranging from ancient to 21st Century mathematics, along with five\nhand-constructed cases including Euclid, Apollonius, Hernstein's Topics in\nAlgebra, and Andrew Wiles's proof of Fermat's Last Theorem. Our results bear\nboth on recent work in the history and philosophy of mathematics on how we\nunderstand proofs, and on a question, basic to cognitive science, of how we\njustify complex beliefs.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.00055v2"
    },
    {
        "title": "The Complexity of Diagonalization",
        "authors": [
            "Nikhil Srivastava"
        ],
        "category": "cs.SC",
        "published_year": "2023",
        "summary": "  We survey recent progress on efficient algorithms for approximately\ndiagonalizing a square complex matrix in the models of rational (variable\nprecision) and finite (floating point) arithmetic. This question has been\nstudied across several research communities for decades, but many mysteries\nremain. We present several open problems which we hope will be of broad\ninterest.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10575v1"
    },
    {
        "title": "Strong Consistency and Thomas Decomposition of Finite Difference\n  Approximations to Systems of Partial Differential Equations",
        "authors": [
            "Vladimir P. Gerdt",
            "Daniel Robertz",
            "Yuri A. Blinkov"
        ],
        "category": "cs.SC",
        "published_year": "2020",
        "summary": "  For a wide class of polynomially nonlinear systems of partial differential\nequations we suggest an algorithmic approach that combines differential and\ndifference algebra to analyze s(trong)-consistency of finite difference\napproximations. Our approach is applicable to regular solution grids. For the\ngrids of this type we give a new definition of s-consistency for finite\ndifference approximations which generalizes our definition given earlier for\nCartesian grids. The algorithmic verification of s-consistency presented in the\npaper is based on the use of both differential and difference Thomas\ndecomposition. First, we apply the differential decomposition to the input\nsystem, resulting in a partition of its solution space. Then, to the output\nsubsystem that contains a solution of interest we apply a difference analogue\nof the differential Thomas decomposition which allows to check the\ns-consistency. For linear and some quasi-linear differential systems one can\nalso apply difference \\Gr bases for the s-consistency analysis. We illustrate\nour methods and algorithms by a number of examples, which include Navier-Stokes\nequations for viscous incompressible flow.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.01731v1"
    }
]