[
    {
        "title": "Human housekeeping genes are compact",
        "authors": [
            "Eli Eisenberg",
            "Erez Y. Levanon"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  We identify a set of 575 human genes that are expressed in all conditions\ntested in a publicly available database of microarray results. Based on this\ncommon occurrence, the set is expected to be rich in \"housekeeping\" genes,\nshowing constitutive expression in all tissues. We compare selected aspects of\ntheir genomic structure with a set of background genes. We find that the\nintrons, untranslated regions and coding sequences of the housekeeping genes\nare shorter, indicating a selection for compactness in these genes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0309020v1"
    },
    {
        "title": "A covariance kernel for proteins",
        "authors": [
            "Marco Cuturi",
            "Jean-Philippe Vert"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  We propose a new kernel for biological sequences which borrows ideas and\ntechniques from information theory and data compression. This kernel can be\nused in combination with any kernel method, in particular Support Vector\nMachines for protein classification. By incorporating prior biological\nassumptions on the properties of amino-acid sequences and using a Bayesian\naveraging framework, we compute the value of this kernel in linear time and\nspace, benefiting from previous achievements proposed in the field of universal\ncoding. Encouraging classification results are reported on a standard protein\nhomology detection experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0310022v1"
    },
    {
        "title": "Random model for RNA interference yields scale free network",
        "authors": [
            "Duygu Balcan",
            "Ayse Erzan"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  We introduce a random bit-string model of post-transcriptional genetic\nregulation based on sequence matching. The model spontaneously yields a scale\nfree network with power law scaling with $ \\gamma=-1$ and also exhibits\nlog-periodic behaviour. The in-degree distribution is much narrower, and\nexhibits a pronounced peak followed by a Gaussian distribution. The network is\nof the smallest world type, with the average minimum path length independent of\nthe size of the network, as long as the network consists of one giant cluster.\nThe percolation threshold depends on the system size.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0310027v1"
    },
    {
        "title": "Computational identification of transcription factor binding sites by\n  functional analysis of sets of genes sharing overrepresented upstream motifs",
        "authors": [
            "Davide Cora'",
            "Ferdinando Di Cunto",
            "Paolo Provero",
            "Lorenzo Silengo",
            "Michele Caselle"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  BACKGROUND: Transcriptional regulation is a key mechanism in the functioning\nof the cell, and is mostly effected through transcription factors binding to\nspecific recognition motifs located upstream of the coding region of the\nregulated gene. The computational identification of such motifs is made easier\nby the fact that they often appear several times in the upstream region of the\nregulated genes, so that the number of occurrences of relevant motifs is often\nsignificantly larger than expected by pure chance. RESULTS: To exploit this\nfact, we construct sets of genes characterized by the statistical\noverrepresentation of a certain motif in their upstream regions. Then we study\nthe functional characterization of these sets by analyzing their annotation to\nGene Ontology terms. For the sets showing a statistically significant specific\nfunctional characterization, we conjecture that the upstream motif\ncharacterizing the set is a binding site for a transcription factor involved in\nthe regulation of the genes in the set. CONCLUSIONS: The method we propose is\nable to identify many known binding sites in S. cerevisiae and new candidate\ntargets of regulation by known transcription factors. Its application to less\nwell studied organisms is likely to be valuable in the exploration of their\nregulatory interaction network.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0310040v2"
    },
    {
        "title": "MAVID: Constrained ancestral alignment of multiple sequences",
        "authors": [
            "Nicolas Bray",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  We describe a new global multiple alignment program capable of aligning a\nlarge number of genomic regions. Our progressive alignment approach\nincorporates the following ideas: maximum-likelihood inference of ancestral\nsequences, automatic guide-tree construction, protein based anchoring of\nab-initio gene predictions, and constraints derived from a global homology map\nof the sequences. We have implemented these ideas in the MAVID program, which\nis able to accurately align multiple genomic regions up to megabases long.\nMAVID is able to effectively align divergent sequences, as well as incomplete\nunfinished sequences. We demonstrate the capabilities of the program on the\nbenchmark CFTR region which consists of 1.8Mb of human sequence and 20\northologous regions in marsupials, birds, fish, and mammals. Finally, we\ndescribe two large MAVID alignments: an alignment of all the available HIV\ngenomes and a multiple alignment of the entire human, mouse and rat genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0311018v1"
    },
    {
        "title": "Relevance Vector Machines for classifying points and regions in\n  biological sequences",
        "authors": [
            "Thomas A. Down",
            "Tim J. P. Hubbard"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  The Relevance Vector Machine (RVM) is a recently developed machine learning\nframework capable of building simple models from large sets of candidate\nfeatures. Here, we describe a protocol for using the RVM to explore very large\nnumbers of candidate features, and a family of models which apply the power of\nthe RVM to classifying and detecting interesting points and regions in\nbiological sequence data. The models described here have been used successfully\nfor predicting transcription start sites and other features in genome\nsequences.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0312006v1"
    },
    {
        "title": "What can we learn from noncoding regions of similarity between genomes?",
        "authors": [
            "Thomas A. Down",
            "Tim J. P. Hubbard"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  Background: In addition to known protein-coding genes, large amount of\napparently non-coding sequence are conserved between the human and mouse\ngenomes. It seems reasonable to assume that these conserved regions are more\nlikely to contain functional elements than less-conserved portions of the\ngenome. Here we used a motif-oriented machine learning method to extract the\nstrongest signal from a set of non-coding conserved sequences.\n  Results: We successfully fitted models to reflect the non-coding sequences,\nand showed that the results were quite consistent for repeated training runs.\nUsing the learned model to scan genomic sequence, we found that it often made\npredictions close to the start of annotated genes. We compared this method with\nother published promoter-prediction systems, and show that the set of promoters\nwhich are detected by this method seems to be substantially similar to that\ndetected by existing methods.\n  Conclusions: The results presented here indicate that the promoter signal is\nthe strongest single motif-based signal in the non-coding functional fraction\nof the genome. They also lend support to the belief that there exists a\nsubstantial subset of promoter regions which share common features and are\ndetectable by a variety of computational methods.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0312007v1"
    },
    {
        "title": "Clone-array pooled shotgun mapping and sequencing: design and analysis\n  of experiments",
        "authors": [
            "Miklós Csürös",
            "Bingshan Li",
            "Aleksandar Milosavljevic"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  This paper studies sequencing and mapping methods that rely solely on pooling\nand shotgun sequencing of clones. First, we scrutinize and improve the recently\nproposed Clone-Array Pooled Shotgun Sequencing (CAPSS) method, which delivers a\nBAC-linked assembly of a whole genome sequence. Secondly, we introduce a novel\nphysical mapping method, called Clone-Array Pooled Shotgun Mapping (CAPS-MAP),\nwhich computes the physical ordering of BACs in a random library. Both CAPSS\nand CAPS-MAP construct subclone libraries from pooled genomic BAC clones.\n  We propose algorithmic and experimental improvements that make CAPSS a viable\noption for sequencing a set of BACs. We provide the first probabilistic model\nof CAPSS sequencing progress. The model leads to theoretical results supporting\nprevious, less formal arguments on the practicality of CAPSS. We demonstrate\nthe usefulness of CAPS-MAP for clone overlap detection with a probabilistic\nanalysis, and a simulated assembly of the Drosophila melanogaster genome. Our\nanalysis indicates that CAPS-MAP is well-suited for detecting BAC overlaps in a\nhighly redundant library, relying on a low amount of shotgun sequence\ninformation. Consequently, it is a practical method for computing the physical\nordering of clones in a random library, without requiring additional clone\nfingerprinting. Since CAPS-MAP requires only shotgun sequence reads, it can be\nseamlessly incorporated into a sequencing project with almost no experimental\noverhead.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0312017v1"
    },
    {
        "title": "Genetic Paralog Analysis and Simulations",
        "authors": [
            "Stanislaw Cebrat",
            "Jan P. Radomski",
            "Dietrich Stauffer"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  Using Monte Carlo methods, we simulated the effects of bias in generation and\nelimination of paralogs on the size distribution of paralog groups. It was\nfound that the function describing the decay of the number of paralog groups\nwith their size depends on the ratio between the probability of duplications of\ngenes and their deletions, which corresponds to different selection pressures\non the genome size. Slightly different slopes of curves describing the decay of\nthe number of paralog groups with their size were also observed when the\nthreshold of homology between paralogous sequences was changed.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0312027v1"
    },
    {
        "title": "RNA Binding Density on X-chromosome Differing from that on 22 Autosomes\n  in Human",
        "authors": [
            "Zhanjun Lu",
            "Ying Lu",
            "Shuxia Song",
            "Zhai Yu",
            "Xiufang Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  To test whether X-chromosome has unique genomic characteristics, X-chromosome\nand 22 autosomes were compared for RNA binding density. Nucleotide sequences on\nthe chromosomes were divided into 50kb per segment that was recoded as a set of\nfrequency values of 7-nucleotide (7nt) strings using all possible 7nt strings\n(47=16384). 120 genes highly expressed in tonsil germinal center B cells were\nselected for calculating 7nt string frequency values of all introns (RNAs). The\nbinding density of DNA segments and RNAs was determined by the amount of\ncomplement sequences. It was shown for the first time that gene-poor and low\ngene expression X-chromosome had the lowest percentage of the DNA segments that\ncan highly bind RNAs, whereas gene-rich and high gene expression chromosome 19\nhad the highest percentage of the segments. On the basis of these results, it\nis proposed that the nonrandom properties of distribution of RNA highly binding\nDNA segments on the chromosomes provide strong evidence that lack of RNA highly\nbinding segments may be a cause of X-chromosome inactivation\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0312039v1"
    },
    {
        "title": "Solution of the Quasispecies Model for an Arbitrary Gene Network",
        "authors": [
            "Emmanuel Tannenbaum",
            "Eugene I. Shakhnovich"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  In this paper, we study the equilibrium behavior of Eigen's quasispecies\nequations for an arbitrary gene network. We consider a genome consisting of $ N\n$ genes, so that each gene sequence $ \\sigma $ may be written as $ \\sigma =\n\\sigma_1 \\sigma_2 ... \\sigma_N $. We assume a single fitness peak (SFP) model\nfor each gene, so that gene $ i $ has some ``master'' sequence $ \\sigma_{i, 0}\n$ for which it is functioning. The fitness landscape is then determined by\nwhich genes in the genome are functioning, and which are not. The equilibrium\nbehavior of this model may be solved in the limit of infinite sequence length.\nThe central result is that, instead of a single error catastrophe, the model\nexhibits a series of localization to delocalization transitions, which we term\nan ``error cascade.'' As the mutation rate is increased, the selective\nadvantage for maintaining functional copies of certain genes in the network\ndisappears, and the population distribution delocalizes over the corresponding\nsequence spaces. The network goes through a series of such transitions, as more\nand more genes become inactivated, until eventually delocalization occurs over\nthe entire genome space, resulting in a final error catastrophe. This model\nprovides a criterion for determining the conditions under which certain genes\nin a genome will lose functionality due to genetic drift. It also provides\ninsight into the response of gene networks to mutagens. In particular, it\nsuggests an approach for determining the relative importance of various genes\nto the fitness of an organism, in a more accurate manner than the standard\n``deletion set'' method. The results in this paper also have implications for\nmutational robustness and what C.O. Wilke termed ``survival of the flattest.''\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0402044v1"
    },
    {
        "title": "A Machine Learning Strategy to Identity Exonic Splice Enhancers in Human\n  Protein-coding Sequence",
        "authors": [
            "Thomas A. Down",
            "Bernard Leong",
            "Tim J. P. Hubbard"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Background: Exonic splice enhancers are sequences embedded within exons which\npromote and regulate the splicing of the transcript in which they are located.\nA class of exonic splice enhancers are the SR proteins, which are thought to\nmediate interactions between splicing factors bound to the 5' and 3' splice\nsites. Method and results: We present a novel strategy for analysing\nprotein-coding sequence by first randomizing the codons used at each position\nwithin the coding sequence, then applying a motif-based machine learning\nalgorithm to compare the true and randomized sequences. This strategy\nidentified a collection of motifs which can successfully discriminate between\nreal and randomized coding sequence, including -- but not restricted to --\nseveral previously reported splice enhancer elements. As well as successfully\ndistinguishing coding exons from randomized sequences, we show that our model\nis able to recognize non-coding exons. Conclusions: Our strategy succeeded in\ndetecting signals in coding exons which seem to be orthogonal to the sequences'\nprimary function of coding for proteins. We believe that many of the motifs\ndetected here may represent binding sites for previously unrecognized proteins\nwhich influence RNA splicing. We hope that this development will lead to\nimproved knowledge of exonic splice enhancers, and new developments in the\nfield of computational gene prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0403024v1"
    },
    {
        "title": "Statistical analysis of the distribution of amino acids in Borrelia\n  burgdorferi genome under different genetic codes",
        "authors": [
            "Jose A Garcia",
            "Samantha Alvarez",
            "Alejandro Flores",
            "Tzipe Govezensky",
            "Juan R. Bobadilla",
            "Marco V. Jose"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  The genetic code is considered to be universal. In order to test if some\nstatistical properties of the coding bacterial genome were due to inherent\nproperties of the genetic code, we compared the autocorrelation function, the\nscaling properties and the maximum entropy of the distribution of distances of\namino acids in sequences obtained by translating protein-coding regions from\nthe genome of Borrelia burgdorferi, under different genetic codes. Overall our\nresults indicate that these properties are very stable to perturbations made by\naltering the genetic code. We also discuss the evolutionary likely implications\nof the present results.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0403032v1"
    },
    {
        "title": "Statistical analysis of Gene and Intergenic DNA Sequences",
        "authors": [
            "D. Kugiumtzis",
            "A. Provata"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Much of the on-going statistical analysis of DNA sequences is focused on the\nestimation of characteristics of coding and non-coding regions that would\npossibly allow discrimination of these regions. In the current approach, we\nconcentrate specifically on genes and intergenic regions. To estimate the level\nand type of correlation in these regions we apply various statistical methods\ninspired from nonlinear time series analysis, namely the probability\ndistribution of tuplets, the Mutual Information and the Identical Neighbour\nFit. The methods are suitably modified to work on symbolic sequences and they\nare first tested for validity on sequences obtained from well--known simple\ndeterministic and stochastic models. Then they are applied to the DNA sequence\nof chromosome 1 of {\\em arabidopsis thaliana}. The results suggest that\ncorrelations do exist in the DNA sequence but they are weak and that intergenic\nsequences tend to be more correlated than gene sequences. The use of\nstatistical tests with surrogate data establish these findings in a rigorous\nstatistical manner.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0404024v1"
    },
    {
        "title": "Statistical properties of DNA sequences revisited: the role of inverse\n  bilateral symmetry in bacterial chromosomes",
        "authors": [
            "Marco V. Jose",
            "Tzipe Govezensky",
            "Juan R. Bobadilla"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Herein it is shown that in order to study the statistical properties of DNA\nsequences in bacterial chromosomes it suffices to consider only one half of the\nchromosome because they are similar to its corresponding complementary sequence\nin the other half. This is due to the inverse bilateral symmetry of bacterial\nchromosomes. Contrary to the classical result that DNA coding regions of\nbacterial genomes are purely uncorrelated random sequences, here it is shown,\nvia a renormalization group approach, that DNA random fluctuations of single\nbases are modulated by log-periodic variations. Distance series of triplets\ndisplay long-range correlations in each half of the intact chromosome and in\nintronless protein-coding sequences, or both long-range correlations and\nlog-periodic modulations along the whole chromosome. Hence scaling analyses of\ndistance series of DNA sequences have to consider the functional units of\nbacterial chromosomes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0408014v1"
    },
    {
        "title": "Monte Carlo Simulation and Statistical Analysis of Genetic Information\n  Coding",
        "authors": [
            "E. Gultepe",
            "M. L. Kurnaz"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  The rules that specify how the information contained in DNA codes amino\nacids, is called \"the genetic code\". Using a simplified version of the Penna\nnodel, we are using computer simulations to investigate the importance of the\ngenetic code and the number of amino acids in Nature on population dynamics. We\nfind that the genetic code is not a random pairing of codons to amino acids and\nthe number of amino acids in Nature is an optimum under mutations.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0408017v1"
    },
    {
        "title": "SUMO Substrates and Sites Prediction Combining Pattern Recognition and\n  Phylogenetic Conservation",
        "authors": [
            "Yu Xue",
            "Fengfeng Zhou",
            "Hualei Lu",
            "Guoliang Chen",
            "Xuebiao Yao"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Small Ubiquitin-related modifier (SUMO) proteins are widely expressed in\neukaryotic cells, which are reversibly coupled to their substrates by motif\nrecognition, called sumoylation. Two interesting questions are 1) how many\npotential SUMO substrates may be included in mammalian proteomes, such as human\nand mouse, 2) and given a SUMO substrate, can we recognize its sumoylation\nsites? To answer these two questions, previous prediction systems of SUMO\nsubstrates mainly adopted the pattern recognition methods, which could get high\nsensitivity with relatively too many potential false positives. So we use\nphylogenetic conservation between mouse and human to reduce the number of\npotential false positives.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0409011v1"
    },
    {
        "title": "Needed for completion of the human genome: hypothesis driven experiments\n  and biologically realistic mathematical models",
        "authors": [
            "Roderic Guigo",
            "Ewan Birney",
            "Michael Brent",
            "Emmanouil Dermitzakis",
            "Lior Pachter",
            "Hugues Roest Crollius",
            "Victor Solovyev",
            "Michael Q. Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  With the sponsorship of ``Fundacio La Caixa'' we met in Barcelona, November\n21st and 22nd, to analyze the reasons why, after the completion of the human\ngenome sequence, the identification all protein coding genes and their variants\nremains a distant goal. Here we report on our discussions and summarize some of\nthe major challenges that need to be overcome in order to complete the human\ngene catalog.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0410008v1"
    },
    {
        "title": "Gene splice sites correlate with nucleosome positions",
        "authors": [
            "Simon Kogan",
            "Edward N. Trifonov"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Gene sequences in the vicinity of splice sites are found to possess\ndinucleotide periodicities, especially RR and YY, with the period close to the\npitch of nucleosome DNA. This confirms previously reported finding about\npreferential positioning of splice junctions within the nucleosomes. The RR and\nYY dinucleotides oscillate counterphase, i.e., their respective preferred\npositions are shifted about half-period one from another, as it was observed\nearlier for AA and TT dinucleotides. Species specificity of nucleosome\npositioning DNA pattern is indicated by predominant use of the periodical\nGG(CC) dinucleotides in human and mouse genes, as opposed to predominant AA(TT)\ndinucleotides in Arabidopsis and C.elegans.\n  Keywords: chromatin; gene splicing; intron; exon; dinucleotide; periodical\npattern\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0411024v1"
    },
    {
        "title": "Systematic identification of abundant A-to-I editing sites in the human\n  transcriptome",
        "authors": [
            "Erez Y. Levanon",
            "Eli Eisenberg",
            "Rodrigo Yelin",
            "Sergey Nemzer",
            "Martina Hallegger",
            "Ronen Shemesh",
            "Zipora Y. Fligelman",
            "Avi Shoshan",
            "Sarah R. Pollock",
            "Dan Sztybel",
            "Moshe Olshansky",
            "Gideon Rechavi",
            "Michael F. Jantsch"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  RNA editing by members of the double-stranded RNA-specific ADAR family leads\nto site-specific conversion of adenosine to inosine (A-to-I) in precursor\nmessenger RNAs. Editing by ADARs is believed to occur in all metazoa, and is\nessential for mammalian development. Currently, only a limited number of human\nADAR substrates are known, while indirect evidence suggests a substantial\nfraction of all pre-mRNAs being affected. Here we describe a computational\nsearch for ADAR editing sites in the human transcriptome, using millions of\navailable expressed sequences. 12,723 A-to-I editing sites were mapped in 1,637\ndifferent genes, with an estimated accuracy of 95%, raising the number of known\nediting sites by two orders of magnitude. We experimentally validated our\nmethod by verifying the occurrence of editing in 26 novel substrates. A-to-I\nediting in humans primarily occurs in non-coding regions of the RNA, typically\nin Alu repeats. Analysis of the large set of editing sites indicates the role\nof editing in controlling dsRNA stability.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0411045v1"
    },
    {
        "title": "Divergence and Shannon information in genomes",
        "authors": [
            "Hong-Da Chen",
            "Chang-Heng Chang",
            "Li-Ching Hsieh",
            "Hoong-Chien Lee"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Shannon information (SI) and its special case, divergence, are defined for a\nDNA sequence in terms of probabilities of chemical words in the sequence and\nare computed for a set of complete genomes highly diverse in length and\ncomposition. We find the following: SI (but not divergence) is inversely\nproportional to sequence length for a random sequence but is length-independent\nfor genomes; the genomic SI is always greater and, for shorter words and longer\nsequences, hundreds to thousands times greater than the SI in a random sequence\nwhose length and composition match those of the genome; genomic SIs appear to\nhave word-length dependent universal values. The universality is inferred to be\nan evolution footprint of a universal mode for genome growth.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0412037v1"
    },
    {
        "title": "Is abundant A-to-I RNA editing primate-specific?",
        "authors": [
            "Eli Eisenberg",
            "Sergey Nemzer",
            "Yaron Kinar",
            "Rotem Sorek",
            "Gideon Rechavi",
            "Erez Y. Levanon"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  A-To-I RNA editing is common to all eukaryotes, associated with various\nneurological functions. Recently, A-to-I editing was found to occur abundantly\nin the human transcriptome. Here we show that the frequency of A-to-I editing\nin humans is at least an order of magnitude higher as that of mouse, rat,\nchicken or fly. The extraordinary frequency of RNA editing in human is\nexplained by the dominance of the primate-specific Alu element in the human\ntranscriptome, which increases the number of double-stranded RNA substrates.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0412043v1"
    },
    {
        "title": "A New Simulated Annealing Algorithm for the Multiple Sequence Alignment\n  Problem: The approach of Polymers in a Random Media",
        "authors": [
            "M. Hernández-Guía",
            "R. Mulet",
            "S. Rodríguez-Pérez"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We proposed a probabilistic algorithm to solve the Multiple Sequence\nAlignment problem. The algorithm is a Simulated Annealing (SA) that exploits\nthe representation of the Multiple Alignment between $D$ sequences as a\ndirected polymer in $D$ dimensions. Within this representation we can easily\ntrack the evolution in the configuration space of the alignment through local\nmoves of low computational cost. At variance with other probabilistic\nalgorithms proposed to solve this problem, our approach allows for the creation\nand deletion of gaps without extra computational cost. The algorithm was tested\naligning proteins from the kinases family. When D=3 the results are consistent\nwith those obtained using a complete algorithm. For $D>3$ where the complete\nalgorithm fails, we show that our algorithm still converges to reasonable\nalignments. Moreover, we study the space of solutions obtained and show that\ndepending on the number of sequences aligned the solutions are organized in\ndifferent ways, suggesting a possible source of errors for progressive\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501012v1"
    },
    {
        "title": "Identification and Measurement of Neighbor Dependent Nucleotide\n  Substitution Processes",
        "authors": [
            "Peter F. Arndt",
            "Terence Hwa"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The presence of neighbor dependencies generated a specific pattern of\ndinucleotide frequencies in all organisms. Especially, the\nCpG-methylation-deamination process is the predominant substitution process in\nvertebrates and needs to be incorporated into a more realistic model for\nnucleotide substitutions. Based on a general framework of nucleotide\nsubstitutions we develop a method that is able to identify the most relevant\nneighbor dependent substitution processes, measure their strength, and judge\ntheir importance to be included into the modeling. Starting from a model for\nneighbor independent nucleotide substitution we successively add neighbor\ndependent substitution processes in the order of their ability to increase the\nlikelihood of the model describing given data. The analysis of neighbor\ndependent nucleotide substitutions in human, zebrafish and fruit fly is\npresented. A web server to perform the presented analysis is publicly\navailable.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501018v1"
    },
    {
        "title": "Substantial regional variation in substitution rates in the human\n  genome: importance of GC content, gene density and telomere-specific effects",
        "authors": [
            "Peter F Arndt",
            "Terence Hwa",
            "Dmitri A Petrov"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  This study presents the first global, 1 Mbp level analysis of patterns of\nnucleotide substitutions along the human lineage. The study is based on the\nanalysis of a large amount of repetitive elements deposited into the human\ngenome since the mammalian radiation, yielding a number of results that would\nhave been difficult to obtain using the more conventional comparative method of\nanalysis. This analysis revealed substantial and consistent variability of\nrates of substitution, with the variability ranging up to 2-fold among\ndifferent regions. The rates of substitutions of C or G nucleotides with A or T\nnucleotides vary much more sharply than the reverse rates suggesting that much\nof that variation is due to differences in mutation rates rather than in the\nprobabilities of fixation of C/G vs. A/T nucleotides across the genome. For all\ntypes of substitution we observe substantially more hotspots than coldspots,\nwith hotspots showing substantial clustering over tens of Mbp's. Our analysis\nrevealed that GC-content of surrounding sequences is the best predictor of the\nrates of substitution. The pattern of substitution appears very different near\ntelomeres compared to the rest of the genome and cannot be explained by the\ngenome-wide correlations of the substitution rates with GC content or exon\ndensity. The telomere pattern of substitution is consistent with natural\nselection or biased gene conversion acting to increase the GC-content of the\nsequences that are within 10-15 Mbp away from the telomere.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501020v1"
    },
    {
        "title": "Molecular Phylogenetic Analyses and Real Life Data",
        "authors": [
            "Kerstin Hoef-Emden"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  In molecular phylogeny, relationships among organisms are reconstructed using\nDNA or protein sequences and are displayed as trees. A linear increase in the\nnumber of sequences results in an exponential increase of possible trees. Thus,\ninferring trees from molecular data was shown to be NP-hard. This causes\nproblems, if large data sets are used. This review gives an introduction to\nmolecular phylogenetic methods and to the problems biologists are facing in\nmolecular phylogenetic analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501030v2"
    },
    {
        "title": "Global divergence of microbial genome sequences mediated by propagating\n  fronts",
        "authors": [
            "Kalin Vetsigian",
            "Nigel Goldenfeld"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We model the competition between recombination and point mutation in\nmicrobial genomes, and present evidence for two distinct phases, one uniform,\nthe other genetically diverse. Depending on the specifics of homologous\nrecombination, we find that global sequence divergence can be mediated by\nfronts propagating along the genome, whose characteristic signature on genome\nstructure is elucidated, and apparently observed in closely-related {\\it\nBacillus} strains. Front propagation provides an emergent, generic mechanism\nfor microbial \"speciation\", and suggests a classification of microorganisms on\nthe basis of their propensity to support propagating fronts.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501033v3"
    },
    {
        "title": "Statistical analysis of simple repeats in the human genome",
        "authors": [
            "Francesco Piazza",
            "Pietro Lio"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The human genome contains repetitive DNA at different level of sequence\nlength, number and dispersion. Highly repetitive DNA is particularly rich in\nhomo-- and di--nucleotide repeats, while middle repetitive DNA is rich of\nfamilies of interspersed, mobile elements hundreds of base pairs (bp) long,\namong which the Alu families. A link between homo- and di-polymeric tracts and\nmobile elements has been recently highlighted. In particular, the mobility of\nAlu repeats, which form 10% of the human genome, has been correlated with the\nlength of poly(A) tracts located at one end of the Alu. These tracts have a\nrigid and non-bendable structure and have an inhibitory effect on nucleosomes,\nwhich normally compact the DNA. We performed a statistical analysis of the\ngenome-wide distribution of lengths and inter--tract separations of poly(X) and\npoly(XY) tracts in the human genome. Our study shows that in humans the length\ndistributions of these sequences reflect the dynamics of their expansion and\nDNA replication. By means of general tools from linguistics, we show that the\nlatter play the role of highly-significant content-bearing terms in the DNA\ntext. Furthermore, we find that such tracts are positioned in a non-random\nfashion, with an apparent periodicity of 150 bases. This allows us to extend\nthe link between repetitive, highly mobile elements such as Alus and\nlow-complexity words in human DNA. More precisely, we show that Alus are\nsources of poly(X) tracts, which in turn affect in a subtle way the combination\nand diversification of gene expression and the fixation of multigene families.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0502009v1"
    },
    {
        "title": "Evolutionarily conserved human targets of adenosine to inosine RNA\n  editing",
        "authors": [
            "Erez Y. Levanon",
            "Martina Hallegger",
            "Yaron Kinar",
            "Ronen Shemesh",
            "Kristina Djinovic-Carugo",
            "Gideon Rechavi",
            "Michael F. Jantsch",
            "Eli Eisenberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  A-to-I RNA editing by ADARs is a post-transcriptional mechanism for expanding\nthe proteomic repertoire. Genetic recoding by editing was so far observed for\nonly a few mammalian RNAs that are predominantly expressed in nervous tissues.\nHowever, as these editing targets fail to explain the broad and severe\nphenotypes of ADAR1 knockout mice, additional targets for editing by ADARs were\nalways expected. Using comparative genomics and expressed sequence analysis, we\nidentified and experimentally verified four additional candidate human\nsubstrates for ADAR-mediated editing: FLNA, BLCAP, CYFIP2 and IGFBP7.\nAdditionally, editing of three of these substrates was verified in the mouse\nwhile two of them were validated in chicken. Interestingly, none of these\nsubstrates encodes a receptor protein but two of them are strongly expressed in\nthe CNS and seem important for proper nervous system function. The editing\npattern observed suggests that some of the affected proteins might have altered\nphysiological properties leaving the possibility that they can be related to\nthe phenotypes of ADAR1 knockout mice.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0502045v1"
    },
    {
        "title": "Mimivirus Gene Promoters Exhibit an Unprecedented Conservation among all\n  Eukaryotes",
        "authors": [
            "Karsten Suhre",
            "Stéphane Audic",
            "Jean-Michel Claverie"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The initial analysis of the recently sequenced genome of Acanthamoeba\npolyphaga Mimivirus, the largest known double-stranded DNA virus, predicted a\nproteome of size and complexity more akin to small parasitic bacteria than to\nother nucleo-cytoplasmic large DNA viruses, and identified numerous functions\nnever before described in a virus. It has been proposed that the Mimivirus\nlineage could have emerged before the individualization of cellular organisms\nfrom the 3 domains of life. An exhaustive in silico analysis of the non-coding\nmoiety of all known viral genomes, now uncovers the unprecedented perfect\nconservation of a AAAATTGA motif in close to 50% of the Mimivirus genes. This\nmotif preferentially occurs in genes transcribed from the predicted leading\nstrand and is associated with functions required early in the viral infectious\ncycle, such as transcription and protein translation. A comparison with the\nknown promoter of unicellular eukaryotes, in particular amoebal protists,\nstrongly suggests that the AAAATTGA motif is the structural equivalent of the\nTATA box core promoter element. This element is specific to the Mimivirus\nlineage, and may correspond to an ancestral promoter structure predating the\nradiation of the eukaryotic kingdoms. This unprecedented conservation of core\npromoter regions is another exceptional features of Mimivirus, that again\nraises the question of its evolutionary origin.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0504012v2"
    },
    {
        "title": "Ab initio identification of putative human transcription factor binding\n  sites by comparative genomics",
        "authors": [
            "Davide Cora'",
            "Carl Herrmann",
            "Christoph Dieterich",
            "Ferdinando Di Cunto",
            "Paolo Provero",
            "Michele Caselle"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We discuss a simple and powerful approach for the ab initio identification of\ncis-regulatory motifs involved in transcriptional regulation. The method we\npresent integrates several elements: human-mouse comparison, statistical\nanalysis of genomic sequences and the concept of coregulation. We apply it to a\ncomplete scan of the human genome. By using the catalogue of conserved upstream\nsequences collected in the CORG database we construct sets of genes sharing the\nsame overrepresented motif (short DNA sequence) in their upstream regions both\nin human and in mouse. We perform this construction for all possible motifs\nfrom 5 to 8 nucleotides in length and then filter the resulting sets looking\nfor two types of evidence of coregulation: first, we analyze the Gene Ontology\nannotation of the genes in the set, searching for statistically significant\ncommon annotations; second, we analyze the expression profiles of the genes in\nthe set as measured by microarray experiments, searching for evidence of\ncoexpression. The sets which pass one or both filters are conjectured to\ncontain a significant fraction of coregulated genes, and the upstream motifs\ncharacterizing the sets are thus good candidates to be the binding sites of the\nTF's involved in such regulation. In this way we find various known motifs and\nalso some new candidate binding sites.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0505005v1"
    },
    {
        "title": "On the Complexity of Several Haplotyping Problems",
        "authors": [
            "Rudi Cilibrasi",
            "Leo van Iersel",
            "Steven Kelk",
            "John Tromp"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  In this paper we present a collection of results pertaining to haplotyping.\nThe first set of results concerns the combinatorial problem of reconstructing\nhaplotypes from incomplete and/or imperfectly sequenced haplotype data. More\nspecifically, we show that an interesting, restricted case of Minimum Error\nCorrection (MEC) is NP-hard, point out problems in earlier claims about a\nrelated problem, and present a polynomial-time algorithm for the ungapped case\nof Longest Haplotype Reconstruction (LHR). Secondly, we present a polynomial\ntime algorithm for the problem of resolving genotype data using as few\nhaplotypes as possible (the Pure Parsimony Haplotyping Problem, PPH) where each\ngenotype has at most two ambiguous positions, thus solving an open problem\nposed by Lancia et al in \"Haplotyping Populations by Pure Parsimony: Complexity\nof Exact and Approximation Algorithms.\"\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0505023v1"
    },
    {
        "title": "Gene & Genome Duplication in Acanthamoeba Polyphaga Mimivirus",
        "authors": [
            "Karsten Suhre"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Gene duplication is key to molecular evolution in all three domains of life\nand may be the first step in the emergence of new gene function. It is a well\nrecognized feature in large DNA viruses, but has not been studied extensively\nin the largest known virus to date, the recently discovered Acanthamoeba\nPolyphaga Mimivirus. Here we present a systematic analysis of gene and genome\nduplication events in the Mimivirus genome. We find that one third of the\nMimivirus genes are related to at least one other gene in the Mimivirus genome,\neither through a large segmental genome duplication event that occurred in the\nmore remote past, either through more recent gene duplication events, which\noften occur in tandem. This shows that gene and genome duplication played a\nmajor role in shaping the Mimivirus genome. Using multiple alignments together\nwith remote homology detection methods based on Hidden Markov Model comparison,\nwe assign putative functions to some of the paralogous gene families. We\nsuggest that a large part of the duplicated Mimivirus gene families are likely\nto interfere with important host cell processes, such as transcription control,\nprotein degradation, and cell regulatory processes. Our findings support the\nview that large DNA viruses are complex evolving organisms, possibly deeply\nrooted within the tree of life, and oppose the paradigm that viral evolution is\ndominated by lateral gene acquisition, at least in what concerns large DNA\nviruses.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0505049v3"
    },
    {
        "title": "Identity Elements of Archaeal tRNA",
        "authors": [
            "Bibekanand Mallick",
            "Jayprokas Chakrabarti",
            "Satyabrata Sahoo",
            "Zhumur Ghosh",
            "Smarajit Das"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Features unique to a transfer-RNA are recognized by the corresponding\ntRNA-synthetase. Keeping this in view we isolate the discriminating features of\nall archaeal tRNA. These are our identity elements. Further, we investigate\ntRNA-characteristics that delineate the different orders of archaea.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0506020v2"
    },
    {
        "title": "Evidence for abundant transcription of non-coding regions in the\n  Saccharomyces cerevisiae genome",
        "authors": [
            "Moshe Havilio",
            "Erez Y. Levanon",
            "Galia Lerman",
            "Martin Kupiec",
            "Eli Eisenberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Background: Recent studies in a growing number of organisms have yielded\naccumulating evidence that a significant portion of the non-coding region in\nthe genome is transcribed. We address this issue in the yeast Saccharomyces\ncerevisiae.\n  Results: Taking into account the absence of a significantly large yeast EST\ndatabase, we use microarray expression data collected for genomic regions\nerroneously believed to be coding to study the expression pattern of non-coding\nregions in the Saccharomyces cerevisiae genome. We find that at least 164 out\nof 589 (28%) such regions are expressed under specific biological conditions.\nIn particular, looking at the probes that are located opposing other known\ngenes at the same genomic locus, we find that 88 out of 341 (26%) of these\ngenes support antisense transcription. The expression patterns of these\nantisense genes are positively correlated. We validate these results using\nRT-PCR on a sample of 6 non-coding transcripts.\n  Conclusions: 1. The yeast genome is transcribed on a scale larger than\npreviously assumed. 2. Correlated transcription of antisense genes is abundant\nin the yeast genome. 3. Antisense genes in yeast are non-coding.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0506021v1"
    },
    {
        "title": "Is there any sense in antisense editing?",
        "authors": [
            "Yossef Neeman",
            "Dvir Dahary",
            "Erez Y. Levanon",
            "Rotem Sorek",
            "Eli Eisenberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  A number of recent studies have hypothesized that sense-antisense RNA\ntranscript pairs create dsRNA duplexes that undergo extensive A-to-I RNA\nediting. Here we studied human and mouse genomic antisense regions, and found\nthat the editing level in these areas is negligible. This observation puts in\nquestion the scope of sense-antisense duplexes formation in-vivo, which is the\nbasis for a number of proposed regulatory mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0506022v1"
    },
    {
        "title": "Introns Restructure tRNA Genes of Archaea",
        "authors": [
            "Zhumur Ghosh",
            "Smarajit Das",
            "Jayprokas Chakrabarti",
            "Bibekanand Mallick",
            "Satyabrata Sahoo"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  This paper has been withdrawn by the author.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0507008v2"
    },
    {
        "title": "Conspiracy in bacterial genomes",
        "authors": [
            "Luc Frappat",
            "Antonino Sciarrino"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The rank ordered distribution of the codon usage frequencies for 123\nbacteriae is best fitted by a three parameters function that is the sum of a\nconstant, an exponential and a linear term in the rank n. The parameters depend\n(two parabolically) from the total GC content. The rank ordered distribution of\nthe amino acids is fitted by a straight line. The Shannon entropy computed over\nall the codons is well fitted by a parabola in the GC content, while the\npartial entropies computed over subsets of the codons show peculiar different\nbehavior, exhibiting therefore a first conspiracy effect. Moreover the sum of\nthe codon usage frequencies over particular sets, e.g. with C and A\n(respectively G and U) as i-th nucleotide, shows a clear linear dependence from\nthe GC content, exhibiting another conspiracy effect.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0507030v2"
    },
    {
        "title": "Positioning Crenarchaeal tRNA-Introns",
        "authors": [
            "Smarajit Das",
            "Zhumur Ghosh",
            "Jayprokas Chakrabarti",
            "Bibekanand Mallick",
            "Satyabrata Sahoo"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We precisely position a noncanonical intron in the odd second copy of\ntRNAAsp(GTC) gene in the newly sequenced crenarchaea S.acidocaldarius. The\nuniform assortment of some features from normal aspartate tDNA and some from\nthose corresponding to non-standard amino acids conduce us to conjecture it to\nbe a novel tRNA gene, probably coding for a modified aspartate residue. Further\nwe reposition intron in tRNAHis(GUG) gene in P.aerophilum.The BHB motif at the\nexon-intron boundaries are re-analyzed and found to support our conjectures.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0508019v1"
    },
    {
        "title": "Universality of Long-Range Correlations in Expansion-Randomization\n  Systems",
        "authors": [
            "Philipp W. Messer",
            "Michael Lassig",
            "Peter F. Arndt"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We study the stochastic dynamics of sequences evolving by single site\nmutations, segmental duplications, deletions, and random insertions. These\nprocesses are relevant for the evolution of genomic DNA. They define a\nuniversality class of non-equilibrium 1D expansion-randomization systems with\ngeneric stationary long-range correlations in a regime of growing sequence\nlength. We obtain explicitly the two-point correlation function of the sequence\ncomposition and the distribution function of the composition bias in sequences\nof finite length. The characteristic exponent $\\chi$ of these quantities is\ndetermined by the ratio of two effective rates, which are explicitly calculated\nfor several specific sequence evolution dynamics of the universality class.\nDepending on the value of $\\chi$, we find two different scaling regimes, which\nare distinguished by the detectability of the initial composition bias. All\nanalytic results are accurately verified by numerical simulations. We also\ndiscuss the non-stationary build-up and decay of correlations, as well as more\ncomplex evolutionary scenarios, where the rates of the processes vary in time.\nOur findings provide a possible example for the emergence of universality in\nmolecular biology.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0509027v1"
    },
    {
        "title": "Domesticated P elements in the Drosophila montium species subgroup have\n  a new function related to a DNA binding property",
        "authors": [
            "Daphné Reiss",
            "Danielle Nouaud",
            "Stéphane Ronsseray",
            "Dominique Anxolabéhère"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Molecular domestication of a transposable element is defined as its\nfunctional recruitment by the host genome. To date, two independent events of\nmolecular domestication of the P transposable element have been described: in\nthe Drosophila obscura species group and in the Drosophila montium species\nsubgroup. These P neogenes consist to stationary, non repeated sequences,\npotentially encoding 66 kDa repressor-like proteins (RLs). Here we investigate\nthe function of the montium P neogenes. We provide evidence for the presence of\nRLs proteins in two montium species (D. tsacasi and D. bocqueti) specifically\nexpressed in adult and larval brain and gonads. We tested the hypothesis that\nthe montium P neogenes function is related to the repression of the\ntransposition of distant related mobile P elements which coexist in the genome.\nOur results strongly suggest that the montium P neogenes are not recruited to\ndown regulate the P element transposition. Given that all the proteins encoded\nby mobile or stationary P homologous sequences show a strong conservation of\nthe DNA Binding Domain, we tested the capacity of the RLs proteins to bind DNA\nin vivo. Immunstaining of polytene chromosomes in D. melanogaster transgenic\nlines strongly suggest that montium P neogenes encode proteins that bind DNA in\nvivo. RLs proteins show multiple binding to the chromosomes. We suggest that\nthe property recruited in the case of the montium P neoproteins is their DNA\nbinding property. The possible functions of these neogenes are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0509030v1"
    },
    {
        "title": "Statistical Indicators of Collective Behavior and Functional Clusters in\n  Gene Networks of Yeast",
        "authors": [
            "Jelena Zivkovic",
            "Bosiljka Tadic",
            "Nikolaus Wick",
            "Stefan Thurner"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We analyze gene expression time-series data of yeast S. cerevisiae measured\nalong two full cell-cycles. We quantify these data by using q-exponentials,\ngene expression ranking and a temporal mean-variance analysis. We construct\ngene interaction networks based on correlation coefficients and study the\nformation of the corresponding giant components and minimum spanning trees. By\ncoloring genes according to their cell function we find functional clusters in\nthe correlation networks and functional branches in the associated trees. Our\nresults suggest that a percolation point of functional clusters can be\nidentified on these gene expression correlation networks.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0509043v1"
    },
    {
        "title": "The protein map of Synechococcus sp. PCC 7942 - the first overlook",
        "authors": [
            "Olga A. Koksharova",
            "Johan Klint",
            "Ulla Rasmussen"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The unicellular cyanobacterium Synechococcus PCC 7942 has been used as a\nmodel organism for studies of prokaryotic circadian rhythms,\ncarbon-concentrating mechanisms, response to a variety of nutrient and\nenvironmental stresses, and cell division. This paper presents the results of\nthe first proteomic exploratory study of Synechococcus PCC 7942. The proteome\nwas analyzed using two-dimensional gel electrophoresis followed by MALDI-TOF\nmass spectroscopy, and database searching. Of 140 analyzed protein spots, 110\nwere successfully identified as 62 different proteins, many of which occurred\nas multiple spots on the gel. The identified proteins were organized into 18\ndifferent functional categories reflecting the major metabolic and cellular\nprocesses occurring in the cyanobacterial cells in the exponential growth\nphase. Among the identified proteins, 14 previously unknown or considered to be\nhypothetical are here shown to be true gene products in Synechococcus sp. PCC\n7942, and may be helpful for annotation of the newly sequenced genome.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0510013v1"
    },
    {
        "title": "Non-extensive Trends in the Size Distribution of Coding and Non-coding\n  DNA Sequences in the Human Genome",
        "authors": [
            "Th. Oikonomou",
            "A. Provata"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We study the primary DNA structure of four of the most completely sequenced\nhuman chromosomes (including chromosome 19 which is the most dense in coding),\nusing Non-extensive Statistics. We show that the exponents governing the decay\nof the coding size distributions vary between $5.2 \\le r \\le 5.7$ for the short\nscales and $1.45 \\le q \\le 1.50$ for the large scales. On the contrary, the\nexponents governing the decay of the non-coding size distributions in these\nfour chromosomes, take the values $2.4 \\le r \\le 3.2$ for the short scales and\n$1.50 \\le q \\le 1.72$ for the large scales. This quantitative difference, in\nparticular in the tail exponent $q$, indicates that the non-coding (coding)\nsize distributions have long (short) range correlations. This non-trivial\ndifference in the DNA statistics is attributed to the non-conservative\n(conservative) evolution dynamics acting on the non-coding (coding) DNA\nsequences.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0510021v1"
    },
    {
        "title": "tRNA-isoleucine-tryptophan Composite Gene",
        "authors": [
            "Zhumur Ghosh",
            "Jayprokas Chakrabarti",
            "Bibekanand Mallick",
            "Smarajit Das",
            "Satyabrata Sahoo",
            "Harmeet Singh Sethi"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Transfer-RNA genes in archaea often have introns intervening between exon\nsequences. The structural motif at the boundary between exon and intron is the\nbulge-helix-bulge. Computational investigations of these boundary structures in\nH. marismortui lead us to propose that tRNA-isoleucine and tRNA-tryptophan\ngenes are co-located. Precise insilico identification of the splice-sites on\nthe bulges at the exon-intron boundaries conduce us to infer that a single\nintron-containing composite tRNA-gene can give rise to more than one gene\nproduc.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0510053v1"
    },
    {
        "title": "Quantitative modeling and data analysis of SELEX experiments",
        "authors": [
            "Marko Djordjevic",
            "Anirvan M. Sengupta"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  SELEX (Systematic Evolution of Ligands by Exponential Enrichment) is an\nexperimental procedure that allows extracting, from an initially random pool of\nDNA, those oligomers with high affinity for a given DNA-binding protein. We\naddress what is a suitable experimental and computational procedure to infer\nparameters of transcription factor-DNA interaction from SELEX experiments. To\nanswer this, we use a biophysical model of transcription factor-DNA\ninteractions to quantitatively model SELEX. We show that a standard procedure\nis unsuitable for obtaining accurate interaction parameters. However, we\ntheoretically show that a modified experiment in which chemical potential is\nfixed through different rounds of the experiment allows robust generation of an\nappropriate data set. Based on our quantitative model, we propose a novel\nbioinformatic method of data analysis for such modified experiment and apply it\nto extract the interaction parameters for a mammalian transcription factor\nCTF/NFI. From a practical point of view, our method results in a significantly\nimproved false positive/false negative trade-off, as compared to both the\nstandard information theory based method and a widely used empirically\nformulated procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0512001v1"
    },
    {
        "title": "Cloning, expression and purification of the general stress protein Yhbo\n  from Escherichia coli",
        "authors": [
            "Jad Abdallah",
            "Renee Kern",
            "Abderrahim Malki",
            "Viola Eckey",
            "Gilbert Richarme"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We cloned, expressed and purified the Escherichia coli yhbO gene product,\nwhich is homolog to the Bacillus subtilis general stress protein 18 (the yfkM\ngene product), the Pyrococcus furiosus intracellular protease PfpI, and the\nhuman Parkinson disease protein DJ-1. The gene coding for YhbO was generated by\namplifying the yhbO gene from E. coli by polymerase chain reaction. It was\ninserted in the expression plasmid pET-21a, under the transcriptional control\nof the bacteriophage T7 promoter and lac operator. A BL21(DE3) E. coli strain\ntransformed with the YhbO-expression vector pET-21a-yhbO, accumulates large\namounts of a soluble protein of 20 kDa in SDS-PAGE that matches the expected\nYhbO molecular weight. YhbO was purified to homogeneity by HPLC DEAE ion\nexchange chromatography and hydroxylapatite chromatography and its identity was\nconfirmed by N-terminal sequencing and mass spectrometry analysis. The native\nprotein exists in monomeric, trimeric and hexameric forms.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0512028v1"
    },
    {
        "title": "Regularization Strategies for Hyperplane Classifiers: Application to\n  Cancer Classification with Gene Expression Data",
        "authors": [
            "Erik Andries",
            "Thomas Hagstrom",
            "Susan R. Atlas",
            "Cheryl Willman"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Linear discrimination, from the point of view of numerical linear algebra,\ncan be treated as solving an ill-posed system of linear equations. In order to\ngenerate a solution that is robust in the presence of noise, these problems\nrequire regularization. Here, we examine the ill-posedness involved in the\nlinear discrimination of cancer gene expression data with respect to outcome\nand tumor subclasses. We show that a filter factor representation, based upon\nSingular Value Decomposition, yields insight into the numerical ill-posedness\nof the hyperplane-based separation when applied to gene expression data. We\nalso show that this representation yields useful diagnostic tools for guiding\nthe selection of classifier parameters, thus leading to improved performance.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0601002v1"
    },
    {
        "title": "Qualitative Assessment of Gene Expression in Affymetrix Genechip Arrays",
        "authors": [
            "Radhakrishnan Nagarajan",
            "Meenakshi Upreti"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Affymetrix Genechip microarrays are used widely to determine the simultaneous\nexpression of genes in a given biological paradigm. Probes on the Genechip\narray are atomic entities which by definition are randomly distributed across\nthe array and in turn govern the gene expression. In the present study, we make\nseveral interesting observations. We show that there is considerable\ncorrelation between the probe intensities across the array which defy the\nindependence assumption. While the mechanism behind such correlations is\nunclear, we show that scaling behavior and the profiles of perfect match (PM)\nas well as mismatch (MM) probes are similar and immune to background\nsubtraction. We believe that the observed correlations are possibly an outcome\nof inherent non-stationarities or patchiness in the array devoid of biological\nsignificance. This is demonstrated by inspecting their scaling behavior and\nprofiles of the PM and MM probe intensities obtained from publicly available\nGenechip arrays from three eukaryotic genomes, namely: Drosophila Melanogaster,\nHomo Sapiens and Mus musculus across distinct biological paradigms and across\nlaboratories, with and without background subtraction. The fluctuation\nfunctions were estimated using detrended fluctuation analysis (DFA) with fourth\norder polynomial detrending. The results presented in this study provide new\ninsights into correlation signatures of PM and MM probe intensities and\nsuggests the choice of DFA as a tool for qualitative assessment of Affymetrix\nGenechip microarrays prior to their analysis. A more detailed investigation is\nnecessary in order to understand the source of these correlations.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0604015v2"
    },
    {
        "title": "Effects of Growth on Dinitrogen on the Transcriptome and Predicted\n  Proteome of Nostoc PCC 7120",
        "authors": [
            "R. Wunschiers",
            "R. Axelsson",
            "P. Lindblad"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Upon growth on dinitrogen, the filamentous cyanobacterium Nostoc PCC 7120\ninitiates metabolic and morphological changes. We analyzed the expression of\n1249 genes from major metabolic categories under nitrogen fixing and\nnon-nitrogen fixing growth. The expression data were correlated with potential\ntarget secondary structures, probe GC-content, predicted operon structures, and\nnitrogen content of gene products. Of the selected genes, 494 show a more than\n2-fold difference in the two conditions analyzed. Under nitrogen-fixing\nconditions 465 genes, mainly involved in energy metabolism, photosynthesis,\nrespiration and nitrogen-fixation, were found to be stronger expressed, whereas\n29 genes showed a stronger expression under non-nitrogen fixing conditions.\nAnalysis of the nitrogen content of regulated genes shows that Nostoc PCC 7120\ngrowing on dinitrogen is freed from any constraints to save nitrogen. For the\nfirst time the expression of high light-induced stress proteins (HLIP-family)\nis shown to be linked to the nitrogen availability.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0604031v1"
    },
    {
        "title": "Microarray Data Management. An Enterprise Information Approach:\n  Implementations and Challenges",
        "authors": [
            "Willy Valdivia-Granda",
            "Christopher Dwan"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  The extraction of information form high-throughput experiments is a key\naspect of modern biology. Early in the development of microarray technology,\nresearchers recognized that the size of the datasets and the limitations of\nboth computational and visualization techniques restricted their ability to\nfind the biological meaning hidden in the data. In addition, most researchers\nwanted to make their datasets accessible to others. This resulted in the\ndevelopment of new and advanced data storage, analysis, and visualization tools\nenabling the cross-platform validation of the experiments and the\nidentification of previously undetected patterns. In order to reap the benefits\nof this microarray data, researchers have needed to implement database\nmanagement systems providing integration of different experiments and data\ntypes. Moreover, it was necessary to standardize the basic data structure and\nexperimental techniques for the standardization of microarray platforms. In\nthis chapter, we introduce the reader to the major concepts related to the use\nof controlled vocabularies (ontologies), the definition of Minimum Information\nAbout a Microarray Experiment (MIAME) and provide an overview of different\nmicroarray data management strategies in use today. We summarize the main\ncharacteristics of microarray data storage and sharing strategies including\nwarehouses, datamarts, and federations. The fundamental challenges involved in\nthe distribution, and retrieval of microarray data are presented, along with an\noverview of some emerging technologies.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0605005v1"
    },
    {
        "title": "Gene Function Classification Using Bayesian Models with Hierarchy-Based\n  Priors",
        "authors": [
            "Babak Shahbaba",
            "Radford M. Neal"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  We investigate the application of hierarchical classification schemes to the\nannotation of gene function based on several characteristics of protein\nsequences including phylogenic descriptors, sequence based attributes, and\npredicted secondary structure. We discuss three Bayesian models and compare\ntheir performance in terms of predictive accuracy. These models are the\nordinary multinomial logit (MNL) model, a hierarchical model based on a set of\nnested MNL models, and a MNL model with a prior that introduces correlations\nbetween the parameters for classes that are nearby in the hierarchy. We also\nprovide a new scheme for combining different sources of information. We use\nthese models to predict the functional class of Open Reading Frames (ORFs) from\nthe E. coli genome. The results from all three models show substantial\nimprovement over previous methods, which were based on the C5 algorithm. The\nMNL model using a prior based on the hierarchy outperforms both the\nnon-hierarchical MNL model and the nested MNL model. In contrast to previous\nattempts at combining these sources of information, our approach results in a\nhigher accuracy rate when compared to models that use each data source alone.\nTogether, these results show that gene function can be predicted with higher\naccuracy than previously achieved, using Bayesian models that incorporate\nsuitable prior information.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0605015v1"
    },
    {
        "title": "Large-scale Oscillation of Structure-Related DNA Sequence Features in\n  Human Chromosome 21",
        "authors": [
            "Wentian Li",
            "Pedro Miramontes"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Human chromosome 21 is the only chromosome in human genome that exhibits\noscillation of (G+C)-content of cycle length of hundreds kilobases (500 kb near\nthe right telomere). We aim at establishing the existence of similar\nperiodicity in structure-related sequence features in order to relate this\n(G+C)% oscillation to other biological phenomena. The following quantities are\nshown to oscillate with the same 500kb periodicity in human chromosome 21:\nbinding energy calculated by two sets of dinucleotide-based thermodynamic\nparameters, AA/TT and AAA/TTT bi-/tri-nucleotide density, 5'-TA-3' dinucleotide\ndensity, and signal for 10/11-base periodicity of AA/TT or AAA/TTT. These\nintrinsic quantities are related to structural features of the double helix of\nDNA molecules, such as base-pair binding, untwisting/unwinding, stiffness, and\na putative tendency for nucleosome formation.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0606016v1"
    },
    {
        "title": "Modeling gene's length distribution in genomes",
        "authors": [
            "S. Cebrat",
            "M. R. Dudek",
            "P. Mackiewicz"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  We show, that the specific distribution of gene's length, which is observed\nin natural genomes, might be a result of a growth process, in which a single\nlength scale $L(t)$ develops that grows with time as $t^{1/3}$. This length\nscale could be associated with the length of the longest gene in an evolving\ngenome. The growth kinetics of the genes resembles the one observed in physical\nsystems with conserved ordered parameter. We show, that in genome this\nconservation is guaranteed by compositional compensation along DNA strands of\nthe purine-like trends introduced by genes. The presented mathematical model is\nthe modified Bak-Sneppen model of critical self-organization applied to the\none-dimensional system of $N$ spins. The spins take discrete values, which\nrepresent gene's length.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0607029v1"
    },
    {
        "title": "Mathematic principles underlying genetic structures",
        "authors": [
            "Matthew J. Berryman"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Many people are familiar with the physico-chemical properties of gene\nsequences. In this paper I present a mathematical perspective: how do\nmathematical principles such as information theory, coding theory, and\ncombinatorics influence the beginnings of life and the formation of the genetic\ncodes we observe today? What constraints on possible life forms are imposed by\ninformation-theoretical concepts? Further, I detail how mathematical principles\ncan help us to analyse the genetic sequences we observe in the world today.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0607039v1"
    },
    {
        "title": "Invertibility of the TKF model of sequence evolution",
        "authors": [
            "Bhalchandra D. Thatte"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  We consider character sequences evolving on a phylogenetic tree under the\nTKF91 model. We show that as the sequence lengths tend to infinity the the\ntopology of the phylogenetic tree and the edge lengths are determined by any\none of (a) the alignment of sequences (b) the collection of sequence lengths.\nWe also show that the probability of any homology structure on a collection of\nsequences related by a TKF91 process on a tree is independent of the root\nlocation.\n  Keywords: phylogenetics, DNA sequence evolution models, identifiability,\nalignment\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0608017v1"
    },
    {
        "title": "Maximum-frequency gene tree: a simplified genome-scale approach to\n  overcoming incongruence in molecular phylogenies",
        "authors": [
            "Yunfeng Shan",
            "Xiu-Qing Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Genomes and genes diversify during evolution; however, it is unclear to what\nextent genes still retain the relationship among species. Model species for\nmolecular phylogenetic studies include yeasts and viruses whose genomes were\nsequenced as well as plants that have the fossil-supported true phylogenetic\ntrees available. In this study, we generated single gene trees of seven yeast\nspecies as well as single gene trees of nine baculovirus species using all the\northologous genes among the species compared. Homologous genes among seven\nknown plants were used for validation of the fi nding. Four algorithms: maximum\nparsimony, minimum evolution, maximum likelihood, and neighbor-joining, were\nused. Trees were reconstructed before and after weighting the DNA and protein\nsequence lengths among genes. Rarely a gene can always generate the \"true tree\"\nby all the four algorithms. However, the most frequent gene tree, termed\n\"maximum gene-support tree\" (MGS tree, or WMGS tree for the weighted one), in\nyeasts, baculoviruses, or plants was consistently found to be the \"true tree\"\namong the species. The results provide insights into the overall degree of\ndivergence of orthologous genes of the genomes analyzed and suggest the\nfollowing: 1) The true tree relationship among the species studied is still\nmaintained by the largest group of orthologous genes; 2) There are usually more\northologous genes with higher similarities between genetically closer species\nthan between genetically more distant ones; and 3) The maximum gene-support\ntree refl ects the phylogenetic relationship among species in comparison.\n  Keywords: genome, gene evolution, molecular phylogeny, true tree\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0609003v3"
    },
    {
        "title": "Genome-wide EST data mining approaches to resolving incongruence of\n  molecular phylogenies",
        "authors": [
            "Yunfeng Shan"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  36 single genes of six plants inferred 18 unique trees using maximum\nparsimony. Such incongruence is an important issue and how to reconstruct the\ncongruent tree still is one of the most challenges in molecular phylogenetics.\nFor resolving this problem, a genome-wide EST data mining approach was\nsystematically investigated by retrieving a large size of EST data of 144\nshared genes of six green plants from GenBank. The results show that the\nconcatenated alignments approach overcame incongruence among single-gene\nphylogenies and successfully reconstructed the congruent tree of six species\nwith 100% jackknife support across each branch when 144 genes was used.\nJackknife supports of correct branches increased with number of genes linearly,\nbut those of wrong branches also increased linearly. For inferring the\ncongruent tree, the minimum 30 genes were required. This approach may provide\npotential power in resolving conflictions of phylogenies.\n  Keywords: Genome-wide; Data mining; EST; Phylogeny; Congruent tree; Jackknife\nsupport; Plants.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0609004v2"
    },
    {
        "title": "Expression of MHC II genes",
        "authors": [
            "G. Drozina",
            "J. Kohoutek",
            "N. Jabrane-Ferrat",
            "B. M. Peterlin"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Innate and adaptive immunity are connected via antigen processing and\npresentation (APP), which results in the presentation of antigenic peptides to\nT cells in the complex with the major histocompatibility (MHC) determinants.\nMHC class II (MHC II) determinants present antigens to CD4+ T cells, which are\nthe main regulators of the immune response. Their genes are transcribed from\ncompact promoters that form first the MHC II enhanceosome, which contains\nDNA-bound activators and then the MHC II transcriptosome with the addition of\nthe class II transactivator (CIITA). CIITA is the master regulator of MHC II\ntranscription. It is expressed constitutively in dendritic cells (DC) and\nmature B cells and is inducible in most other cell types. Three isoforms of\nCIITA exist, depending on cell type and inducing signals. CIITA is regulated at\nthe levels of transcription and post-translational modifications, which are\nstill not very clear. Inappropriate immune responses are found in several\ndiseases, including cancer and autoimmunity. Since CIITA regulates the\nexpression of MHC II genes, it is involved directly in the regulation of the\nimmune response. The knowledge of CIITA will facilitate the manipulation of the\nimmune response and might contribute to the treatment of these diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0609017v1"
    },
    {
        "title": "Reconsidering the significance of genomic word frequency",
        "authors": [
            "Miklós Csűrös",
            "Laurent Noé",
            "Gregory Kucherov"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  We propose that the distribution of DNA words in genomic sequences can be\nprimarily characterized by a double Pareto-lognormal distribution, which\nexplains lognormal and power-law features found across all known genomes. Such\na distribution may be the result of completely random sequence evolution by\nduplication processes. The parametrization of genomic word frequencies allows\nfor an assessment of significance for frequent or rare sequence motifs.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0609022v1"
    },
    {
        "title": "Cell wall proteins: a new insight through proteomics",
        "authors": [
            "Elisabeth Jamet",
            "Hervé Canut",
            "Georges Boudart",
            "Rafael F Pont-Lezica"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Cell wall proteins are essential constituents of plant cell walls; they are\ninvolved in modifications of cell wall components, wall structure, signaling\nand interactions with plasma membrane proteins at the cell surface. The\napplication of proteomic approaches to the cell wall compartment raises\nimportant questions: are there technical problems specific to cell wall\nproteomics? What kinds of proteins can be found in Arabidopsis walls? Are some\nof them unexpected? What sort of post-translational modifications have been\ncharacterized in cell wall proteins to date? The purpose of this review is to\ndiscuss the experimental results obtained to date using proteomics, as well as\nsome of the new questions challenging future research.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0610021v1"
    },
    {
        "title": "Evaluation of cell wall preparations for proteomics: a new procedure for\n  purifying cell walls from Arabidopsis hypocotyls",
        "authors": [
            "Leila Feiz",
            "Muhammad Irshad",
            "Rafael F Pont-Lezica",
            "Hervé Canut",
            "Elisabeth Jamet"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  The ultimate goal of proteomic analysis of a cell compartment should be the\nexhaustive identification of resident proteins; excluding proteins from other\ncell compartments. Plant cell walls possess specific difficulties. Several\nreported procedures to isolate cell walls for proteomic analyses led to the\nisolation of a high proportion (more than 50%) of predicted intracellular\nproteins. The rationales of several published procedures to isolate cell walls\nfor proteomics were analyzed, with regard to the bioinformatic-predicted\nsubcellular localization of the identified proteins. A new procedure was\ndeveloped to prepare cell walls from etiolated hypocotyls of Arabidopsis\nthaliana. After salt extraction, a high proportion of proteins predicted to be\nsecreted was released (73%), belonging to the same functional classes as\nproteins identified using previously described protocols. The new cell wall\npreparation described in this paper gives the lowest proportion of proteins\npredicted to be intracellular when compared to available protocols. The\napplication of its principles should lead to a more realistic view of the cell\nwall proteome, at least for the weakly bound CWP extractable by salts. In\naddition, it offers a clean cell wall preparation for subsequent extraction of\nstrongly bound CWP.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0610022v2"
    },
    {
        "title": "The riddle of the plant vacuolar sorting receptors",
        "authors": [
            "F. G. Masclaux",
            "J. -P. Galaud",
            "R. Pont-Lezica"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Proteins synthesized on membrane-bound ribosomes are sorted at the Golgi\napparatus level for delivery to various cellular destinations: the plasma\nmembrane or the extracellular space, and the lytic vacuole or lysosome. Sorting\ninvolves the assembly of vesicles, which preferentially package soluble\nproteins with a common destination. The selection of proteins for a particular\nvesicle type involves the recognition of proteins by specific receptors, such\nas the vacuolar sorting receptors for vacuolar targeting. Most eukaryotic\norganisms have one or two receptors to target proteins to the lytic vacuole.\nSurprisingly, plants have several members of the same family, seven in\nArabidopsis thaliana. Why do plants have so many proteins to sort soluble\nproteins to their respective destinations? The presence of at least two types\nof vacuoles, lytic and storage, seems to be a partial answer. In this review we\nanalyze the last experimental evidence supporting the presence of different\nsubfamilies of plant vacuolar sorting receptors.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0610035v1"
    },
    {
        "title": "Correlated fragile site expression allows the identification of\n  candidate fragile genes involved in immunity and associated with\n  carcinogenesis",
        "authors": [
            "A. Re",
            "D. Cora",
            "A. M. Puliti",
            "M. Caselle",
            "I. Sbrana"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Common fragile sites (cfs) are specific regions in the human genome that are\nparticularly prone to genomic instability under conditions of replicative\nstress. Several investigations support the view that common fragile sites play\na role in carcinogenesis. We discuss a genome-wide approach based on graph\ntheory and Gene Ontology vocabulary for the functional characterization of\ncommon fragile sites and for the identification of genes that contribute to\ntumour cell biology. CFS were assembled in a network based on a simple measure\nof correlation among common fragile site patterns of expression. By applying\nrobust measurements to capture in quantitative terms the non triviality of the\nnetwork, we identified several topological features clearly indicating\ndeparture from the Erdos-Renyi random graph model. The most important outcome\nwas the presence of an unexpected large connected component far below the\npercolation threshold. Most of the best characterized common fragile sites\nbelonged to this connected component. By filtering this connected component\nwith Gene Ontology, statistically significant shared functional features were\ndetected. Common fragile sites were found to be enriched for genes associated\nto the immune response and to mechanisms involved in tumour progression such as\nextracellular space remodeling and angiogenesis. Our results support the\nhypothesis that fragile sites serve a function; we propose that fragility is\nlinked to a coordinated regulation of fragile genes expression.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0610047v1"
    },
    {
        "title": "Proteomic nonlinear waves in networks of transcriptional regulators",
        "authors": [
            "A. S. Carstea"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  A chain of connected genes with activation-repression links is analysed. It\nis shown that for various promoter activity functions (parametrised by Hill\ncoefficient) the equations describing the concentrations of transcription\nfactors, are differential-difference KdV-type with perturbations. In the case\nof large Hill coefficient the proteomic signal along the gene network is given\nby a superposition of perturbed dark solitons of defocusing\ndifferential-difference mKdV equation. Biological implications are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611042v1"
    },
    {
        "title": "Networks from gene expression time series: characterization of\n  correlation patterns",
        "authors": [
            "D. Remondini",
            "N. Neretti",
            "J. M. Sedivy",
            "C. Franceschi",
            "L. Milanesi",
            "P. Tieri",
            "G. C. Castellani"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  This paper describes characteristic features of networks reconstructed from\ngene expression time series data. Several null models are considered in order\nto discriminate between informations embedded in the network that are related\nto real data, and features that are due to the method used for network\nreconstruction (time correlation).\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611043v1"
    },
    {
        "title": "How much non-coding DNA do eukaryotes require?",
        "authors": [
            "Sebastian Ahnert",
            "Thomas Fink",
            "Andrei Zinovyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Despite tremendous advances in the field of genomics, the amount and function\nof the large non-coding part of the genome in higher organisms remains poorly\nunderstood. Here we report an observation, made for 37 fully sequenced\neukaryotic genomes, which indicates that eukaryotes require a certain minimum\namount of non-coding DNA (ncDNA). This minimum increases quadratically with the\namount of DNA located in exons. Based on a simple model of the growth of\nregulatory networks, we derive a theoretical prediction of the required\nquantity of ncDNA and find it to be in excellent agreement with the data. The\namount of additional ncDNA (in basepairs) which eukaryotes require obeys Ndef =\n1/2 (Nc / Np) (Nc - Np), where Nc is the amount of exonic DNA, and Np is a\nconstant of about 10Mb. This value Ndef corresponds to a few percent of the\ngenome in Homo sapiens and other mammals, and up to half the genome in simpler\neukaryotes. Thus our findings confirm that eukaryotic life depends on a\nsubstantial fraction of ncDNA and also make a prediction of the size of this\nfraction, which matches the data closely.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611047v4"
    },
    {
        "title": "Di-nucleotide Entropy as a Measure of Genomic Sequence Functionality",
        "authors": [
            "Dmitri Parkhomchuk"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Considering vast amounts of genomic sequences of mostly unknown\nfunctionality, in-silico prediction of functional regions is an important\nenterprise. Many genomic browsers employ GC content, which was observed to be\nelevated in gene-rich functional regions. This report shows that the entropy of\ndi- and tri-nucleotides distributions provides a superior measure of genomic\nsequence functionality, and proposes an explanation on why the GC content must\nbe elevated (closer to 50%) in functional regions. Regions with high entropy\nstrongly co-localize with exons and provide genome-wide evidences of purifying\nselection acting on non-coding regions, such as decreased SNPs density. The\nobservations suggest that functional non-coding regions are optimised for\nmutation load in a way, that transition mutations have less impact on\nfunctionality than transversions, leading to the decrease in transversions to\ntransitions ratio in functional regions.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611059v3"
    },
    {
        "title": "Genetic Variability of Splicing Sites",
        "authors": [
            "Dmitri Parkhomchuk"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Splicing sites provide unique statistics in human genome due to their large\nnumber and reasonably complete annotation. Analyses of the cumulative SNPs\ndistribution in splicing sites reveal a few interesting observations. While a\ndegree of the nucleotide conservation reflects on the SNPs density\nmonotonically, no detectable changes in the SNPs frequencies spectrum were\nfound. Semi-conserved nucleotide sites harbor transition mutations\npredominantly. We propose that such transition preference is caused by\nco-evolution of a site with corresponding binding agents. Since transitions in\nhumans and similarly in other organisms are almost twice as frequent as\ntransversions, this adaptation significantly lowers the mutation load.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611060v2"
    },
    {
        "title": "Progress in the definition of a reference human mitochondrial proteome",
        "authors": [
            "Pierre Lescuyer",
            "Jean-Marc Strub",
            "Sylvie Luche",
            "Hélène Diemer",
            "Pascal Martinez",
            "Alain Van Dorsselaer",
            "Joël Lunardi",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Owing to the complexity of higher eukaryotic cells, a complete proteome is\nlikely to be very difficult to achieve. However, advantage can be taken of the\ncell compartmentalization to build organelle proteomes, which can moreover be\nviewed as specialized tools to study specifically the biology and \"physiology\"\nof the target organelle. Within this frame, we report here the construction of\nthe human mitochondrial proteome, using placenta as the source tissue. Protein\nidentification was carried out mainly by peptide mass fingerprinting. The\noptimization steps in two-dimensional electrophoresis needed for proteome\nresearch are discussed. However, the relative paucity of data concerning\nmitochondrial proteins is still the major limiting factor in building the\ncorresponding proteome, which should be a useful tool for researchers working\non human mitochondria and their deficiencies.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611075v1"
    },
    {
        "title": "Evaluation of nonionic and zwitterionic detergents as membrane protein\n  solubilizers in two-dimensional electrophoresis",
        "authors": [
            "Sylvie Luche",
            "Véronique Santoni",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  The solubilizing power of various nonionic and zwitterionic detergents as\nmembrane protein solubilizers for two-dimensional electrophoresis was\ninvestigated. Human red blood cell ghosts and Arabidopsis thaliana leaf\nmembrane proteins were used as model systems. Efficient detergents could be\nfound in each class, i.e. with oligooxyethylene, sugar or sulfobetaine polar\nheads. Among the commercially available nonionic detergents, dodecyl maltoside\nand decaethylene glycol mono hexadecyl ether proved most efficient. They\ncomplement the more classical sulfobetaine detergents to widen the scope of\nuseful detergents for the solubilization of membrane proteins in proteomics.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611076v1"
    },
    {
        "title": "Detergents and Chaotropes for Protein Solubilization before\n  Two-Dimensional Electrophoresis",
        "authors": [
            "Thierry Rabilloud",
            "Sylvie Luche",
            "Véronique Santoni",
            "Mireille Chevallet"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Because of the outstanding separating capabilities of two-dimensional\nelectrophoresis for complete proteins, it would be advantageous to be able to\napply it to all types of proteins. Unfortunately, severe solubility problems\nhamper the analysis of many classes of proteins, but especially membrane\nproteins. These problems arise mainly in the extraction and isoelectric\nfocusing steps, and solutions are sought to improve protein solubility under\nthe conditions prevailing during isoelectric focusing. These solutions deal\nmainly with chaotropes and new detergents, which are both able to enhance\nprotein solubility. The input of these compounds in proteomics analysis of\nmembrane proteins is discussed, as well as future directions.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611077v1"
    },
    {
        "title": "About thiol derivatization and resolution of basic proteins in\n  two-dimensional electrophoresis",
        "authors": [
            "Sylvie Luche",
            "Hélène Diemer",
            "Chistophe Tastet",
            "Mireille Chevallet",
            "Alain Van Dorsselaer",
            "Emmanuelle Leize-Wagner",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  The influence of thiol blocking on the resolution of basic proteins by\ntwo-dimensional electrophoresis was investigated. Cysteine blocking greatly\nincreased resolution and decreased streaking, especially in the basic region of\nthe gels. Two strategies for cysteine blocking were found to be efficient:\nclassical alkylation with maleimide derivatives and mixed disulfide exchange\nwith an excess of a low molecular weight disulfide. The effect on resolution\nwas significant enough to allow correct resolution of basic proteins with\nin-gel rehydration on wide gradients (e.g. 3-10 and 4-12), but anodic\ncup-loading was still required for basic gradients (e.g. 6-12 or 8-12). These\nresults demonstrate that thiol-related problems are not solely responsible for\nstreaking of basic proteins on two-dimensional gels.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611079v1"
    },
    {
        "title": "Alterations of the mitochondrial proteome caused by the absence of\n  mitochondrial DNA: A proteomic view",
        "authors": [
            "Mireille Chevallet",
            "Pierre Lescuyer",
            "Hélène Diemer",
            "Alain van Dorsselaer",
            "Emmanuelle Leize-Wagner",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  The proper functioning of mitochondria requires that both the mitochondrial\nand the nuclear genome are functional. To investigate the importance of the\nmitochondrial genome, which encodes only 13 subunits of the respiratory\ncomplexes, the mitochondrial rRNAs and a few tRNAs, we performed a comparative\nstudy on the 143B cell line and on its Rho-0 counterpart, i.e., devoid of\nmitochondrial DNA. Quantitative differences were found, of course in the\nrespiratory complexes subunits, but also in the mitochondrial translation\napparatus, mainly mitochondrial ribosomal proteins, and in the ion and protein\nimport system, i.e., including membrane proteins. Various mitochondrial\nmetabolic processes were also altered, especially electron transfer proteins\nand some dehydrogenases, but quite often on a few proteins for each pathway.\nThis study also showed variations in some hypothetical or poorly characterized\nproteins, suggesting a mitochondrial localization for these proteins. Examples\ninclude a stomatin-like protein and a protein sharing homologies with bacterial\nproteins implicated in tyrosine catabolism. Proteins involved in apoptosis\ncontrol are also found modulated in Rho-0 mitochondria.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611081v1"
    },
    {
        "title": "High expression of antioxidant proteins in dendritic cells: possible\n  implications in atherosclerosis",
        "authors": [
            "Aymeric Rivollier",
            "Laure Perrin-Cocon",
            "Sylvie Luche",
            "Hélène Diemer",
            "Jean-Marc Strub",
            "Daniel Hanau",
            "Alain van Dorsselaer",
            "Vincent Lotteau",
            "Chantal Rabourdin-Combe",
            "Thierry Rabilloud",
            "Christine Servet-Delprat"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Dendritic cells (DCs) display the unique ability to activate naive T cells\nand to initiate primary T cell responses revealed in DC-T cell alloreactions.\nDCs frequently operate under stress conditions. Oxidative stress enhances the\nproduction of inflammatory cytokines by DCs. We performed a proteomic analysis\nto see which major changes occur, at the protein expression level, during DC\ndifferentiation and maturation. Comparative two-dimensional gel analysis of the\nmonocyte, immature DC, and mature DC stages was performed. Manganese superoxide\ndismutase (Mn-SOD) reached 0.7% of the gel-displayed proteins at the mature DC\nstage. This important amount of Mn-SOD is a primary antioxidant defense system\nagainst superoxide radicals, but its product, H(2)O(2), is also deleterious for\ncells. Peroxiredoxin (Prx) enzymes play an important role in eliminating such\nperoxide. Prx1 expression level continuously increased during DC\ndifferentiation and maturation, whereas Prx6 continuously decreased, and Prx2\npeaked at the immature DC stage. As a consequence, DCs were more resistant than\nmonocytes to apoptosis induced by high amounts of oxidized low density\nlipoproteins containing toxic organic peroxides and hydrogen peroxide.\nFurthermore DC-stimulated T cells produced high levels of receptor activator of\nnuclear factor kappaB ligand, a chemotactic and survival factor for monocytes\nand DCs. This study provides insights into the original ability of DCs to\nexpress very high levels of antioxidant enzymes such as Mn-SOD and Prx1, to\ndetoxify oxidized low density lipoproteins, and to induce high levels of\nreceptor activator of nuclear factor kappaB ligand by the T cells they activate\nand further emphasizes the role that DCs might play in atherosclerosis, a\npathology recognized as a chronic inflammatory disorder.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611082v1"
    },
    {
        "title": "Improved mass spectrometry compatibility is afforded by ammoniacal\n  silver staining",
        "authors": [
            "Mireille Chevallet",
            "Hélène Diemer",
            "Sylvie Luche",
            "Alain van Dorsselaer",
            "Thierry Rabilloud",
            "Emmanuelle Leize-Wagner"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Sequence coverage in MS analysis of protein digestion-derived peptides is a\nkey issue for detailed characterization of proteins or identification at low\nquantities. In gel-based proteomics studies, the sequence coverage greatly\ndepends on the protein detection method. It is shown here that ammoniacal\nsilver detection methods offer improved sequence coverage over standard silver\nnitrate methods, while keeping the high sensitivity of silver staining. With\nthe development of 2D-PAGE-based proteomics, another burden is placed on the\ndetection methods used for protein detection on 2-D-gels. Besides the classical\nrequirements of linearity, sensitivity, and homogeneity from one protein to\nanother, detection methods must now take into account another aspect, namely\ntheir compatibility with MS. This compatibility is evidenced by two different\nand complementary aspects, which are (i) the absence of adducts and artefactual\nmodifications on the peptides obtained after protease digestion of a protein\ndetected and digested in - gel, and (ii) the quantitative yield of peptides\nrecovered after digestion and analyzed by the mass spectrometer. While this\nquantitative yield is not very important per se, it is however a crucial\nparameter as it strongly influences the S/N of the mass spectrum and thus the\nnumber of peptides that can be detected from a given protein input, especially\nat low protein amounts. This influences in turn the sequence coverage and thus\nthe detail of the analysis provided by the mass spectrometer.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611083v1"
    },
    {
        "title": "A versatile electrophoresis system for the analysis of high- and\n  low-molecular-weight proteins",
        "authors": [
            "Christophe Tastet",
            "Pierre Lescuyer",
            "Hélène Diemer",
            "Sylvie Luche",
            "Alain van Dorsselaer",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  A new, versatile, multiphasic buffer system for high-resolution sodium\ndodecyl sulfate-polyacrylamide gel electrophoresis of proteins in the relative\nmolecular weight range of 300 000-3000 Da is described. The system, based on\nthe theory of multiphasic zone electrophoresis, allows complete stacking and\ndestacking of proteins in the above M(r) range. The buffer system uses taurine\nand chloride as trailing and leading ion, respectively, and Tris, at a pH close\nto its pK(a), as the buffering counterion. Coupled with limited variation in\nthe acrylamide concentration, this electrophoresis system allows to tailor the\nresolution in the 6-200 kDa M(r) range, with minimal difficulties in the post\nelectrophoretic identification processes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611088v1"
    },
    {
        "title": "Improvement of the solubilization of proteins in two-dimensional\n  electrophoresis with immobilized pH gradients",
        "authors": [
            "T. Rabilloud",
            "C. Adessi",
            "A. Giraudel",
            "J. Lunardi"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Membrane and nuclear proteins of poor solubility have been separated by high\nresolution two-dimensional (2-D) gel electrophoresis. Isoelectric focusing with\nimmobilized pH gradients leads to severe quantitative losses of proteins in the\nresulting 2-D map, although the resolution is usually high. Protein solubility\ncould be improved by using denaturing solutions containing various detergents\nand chaotropes. Best results were obtained with a denaturing solution\ncontaining urea, thiourea, and detergents (both nonionic and zwitterionic). The\nusefulness of thiourea-containing denaturing mixtures is shown for microsomal\nand nuclear proteins as well as for tubulin, a protein highly prone to\naggregation.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0612002v1"
    },
    {
        "title": "Gene induction during differentiation of human monocytes into dendritic\n  cells: an integrated study at the RNA and protein levels",
        "authors": [
            "C. Angénieux",
            "D. Fricker",
            "J. M. Strub",
            "S. Luche",
            "H. Bausinger",
            "J. P. Cazenave",
            "A. Van Dorsselaer",
            "D. Hanau",
            "H. de la Salle",
            "T. Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Changes in gene expression occurring during differentiation of human\nmonocytes into dendritic cells were studied at the RNA and protein levels.\nThese studies showed the induction of several gene classes corresponding to\nvarious biological functions. These functions encompass antigen processing and\npresentation, cytoskeleton, cell signalling and signal transduction, but also\nan increase in mitochondrial function and in the protein synthesis machinery,\nincluding some, but not all, chaperones. These changes put in perspective the\nevents occurring during this differentiation process. On a more technical\npoint, it appears that the studies carried out at the RNA and protein levels\nare highly complementary.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0612006v1"
    },
    {
        "title": "Linguistic mechanism of the evolution of amino acid frequencies and\n  genomic GC content",
        "authors": [
            "Dirson Jian Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Much information is stored in amino acid composition of protein and base\ncomposition of DNA. We simulated the evolution of amino acid frequencies and\ngenomic GC content by a linguistic model. It is showed that the evolution of\ngenetic code determines the evolution of amino acid frequencies and genomic GC\ncontent. We explained the relationships among amino acid frequencies, genomic\nGC content and protein length distribution in a unified theoretical framework.\nEspecially, the simulations of the evolution of amino acid frequencies and the\ncodon position GC content agree dramatically with the results based on the data\nof all known genomes so far. Furthermore, we found that the space of average\nprotein length in proteome and ratio of amino acid frequencies is useful to\ndescribe the phylogeny and evolution. Amazingly, the dots of all the species in\nthis space form an evolutionary flow. We believe that the amino acid gain and\nloss is motivated by the established pattern of the variation of amino acid\nfrequencies. The linguistic mechanism is helpful to unveil the origin of the\ngenetic code.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0612010v1"
    },
    {
        "title": "Motif Discovery through Predictive Modeling of Gene Regulation",
        "authors": [
            "Manuel Middendorf",
            "Anshul Kundaje",
            "Mihir Shah",
            "Yoav Freund",
            "Chris H. Wiggins",
            "Christina Leslie"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We present MEDUSA, an integrative method for learning motif models of\ntranscription factor binding sites by incorporating promoter sequence and gene\nexpression data. We use a modern large-margin machine learning approach, based\non boosting, to enable feature selection from the high-dimensional search space\nof candidate binding sequences while avoiding overfitting. At each iteration of\nthe algorithm, MEDUSA builds a motif model whose presence in the promoter\nregion of a gene, coupled with activity of a regulator in an experiment, is\npredictive of differential expression. In this way, we learn motifs that are\nfunctional and predictive of regulatory response rather than motifs that are\nsimply overrepresented in promoter sequences. Moreover, MEDUSA produces a model\nof the transcriptional control logic that can predict the expression of any\ngene in the organism, given the sequence of the promoter region of the target\ngene and the expression state of a set of known or putative transcription\nfactors and signaling molecules. Each motif model is either a $k$-length\nsequence, a dimer, or a PSSM that is built by agglomerative probabilistic\nclustering of sequences with similar boosting loss. By applying MEDUSA to a set\nof environmental stress response expression data in yeast, we learn motifs\nwhose ability to predict differential expression of target genes outperforms\nmotifs from the TRANSFAC dataset and from a previously published candidate set\nof PSSMs. We also show that MEDUSA retrieves many experimentally confirmed\nbinding sites associated with environmental stress response from the\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0701021v1"
    },
    {
        "title": "Marker enzyme phenotype ratios in agamospermous sugarbeet progenies as a\n  demonstration of multidimensional encoding of inherited information in plants",
        "authors": [
            "Evgenii V. Levites"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  It has been demonstrated that the observed ratio of phenotypes of marker\nenzymes in some sugarbeet plants produced by mitotic agamospermy can be\nexplained by different degrees of endoreduplication of chromosomes carrying\ndifferent alleles of the enzyme loci. In these plants, different patterns of\nvariability of the enzymes controlled by the linked loci suggest different\ndegrees of endoreduplication of different chromosomal regions. A concept of\nmultidimensional encoding of inherited information in eukaryotes has been\nproposed.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0701027v1"
    },
    {
        "title": "Finding Sequence Features in Tissue-specific Sequences",
        "authors": [
            "Arvind Rao",
            "Alfred O. Hero III",
            "David J. States",
            "James Douglas Engel"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  The discovery of motifs underlying gene expression is a challenging one. Some\nof these motifs are known transcription factors, but sequence inspection often\nprovides valuable clues, even discovery of novel motifs with uncharacterized\nfunction in gene expression. Coupled with the complexity underlying\ntissue-specific gene expression, there are several motifs that are putatively\nresponsible for expression in a certain cell type. This has important\nimplications in understanding fundamental biological processes, such as\ndevelopment and disease progression. In this work, we present an approach to\nthe principled selection of motifs (not necessarily transcription factor sites)\nand examine its application to several questions in current bioinformatics\nresearch.\n  There are two main contributions of this work: Firstly, we introduce a new\nmetric for variable selection during classification, and secondly, we\ninvestigate a problem of finding specific sequence motifs that underlie tissue\nspecific gene expression. In conjunction with the SVM classifier we find these\nmotifs and discover several novel motifs which have not yet been attributed\nwith any particular functional role (eg: TFBS binding motifs). We hypothesize\nthat the discovery of these motifs would enable the large-scale investigation\nfor the tissue specific regulatory potential of any conserved sequence element\nidentified from genome-wide studies.\n  Finally, we propose the utility of this developed framework to not only aid\ndiscovery of discriminatory motifs, but also to examine the role of any motif\nof choice in co-regulation or co-expression of gene groups.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0702022v1"
    },
    {
        "title": "Bacteria are not Lamarckian",
        "authors": [
            "Antoine Danchin"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Instructive influence of environment on heredity has been a debated topic for\ncenturies. Darwin's identification of natural selection coupled to chance\nvariation as the driving force for evolution, against a formal interpretation\nproposed by Lamarck, convinced most scientists that environment does not\nspecifically instruct evolution in an oriented direction. This is true for\nmulticellular organisms. In contrast, bacteria were long thought of as prone to\nreceive oriented influences from their environment, although much was in favour\nof the Darwinian route (1). In this context Cairns et al. raised a passionate\ndebate by suggesting that bacteria generate mutations oriented by the\nenvironmental conditions (2). Several independent pieces of work subsequently\ndemonstrated that mutations overcoming specific defects arised as a consequence\nof cultivation on specific media (3-7). Two diametrically opposed\ninterpretations were proposed to explain these observations : either induction\nof mutations instructed by the environment (e.g. by a process involving a\nputative reverse transcription) or selection of variants among a large set of\nmutant bacteria generated when stress conditions are present. The experiments\npresented below indicate that the Darwinian paradigm is the most plausible.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0702032v1"
    },
    {
        "title": "Nucleotide Distribution Patterns in Insect Genomes",
        "authors": [
            "Manoj Pratim Samanta"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  This work analyzed genome-wide nucleotide distribution patterns in ten insect\ngenomes. Two internal measures were applied: (i) GC variation and (ii) third\ncodon nucleotide preference. Although the genome size and overall GC level did\nnot show any correlation with insect order, the internal measures usually\ndisplayed higher levels of consistency. GC variations in genomes of\nhymenopteran insects, honeybee and wasp, ranked highest among all eukaryotic\ngenomes analyzed by us. Genomes of honeybee and beetle, insects of different\norders with similar overall GC levels, showed significant internal differences.\nHoneybee genome stood out as unusual due to its high GC variation and\n'left-handed' gene locations.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0702036v1"
    },
    {
        "title": "Ultraconserved Sequences in the Honeybee Genome - Are GC-rich Regions\n  Preferred?",
        "authors": [
            "Manoj Pratim Samanta"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Among all insect genomes, honeybee displays one of the most unusual patterns\nwith interspersed long AT and GC-rich segments. Nearly 75% of the\nprotein-coding genes are located in the AT-rich segments of the genome, but the\nbiological significance of the GC-rich regions is not well understood. Based on\nan observation that the bee miRNAs, actins and tubulins are located in the\nGC-rich segments, this work investigated whether other highly conserved genomic\nregions show similar preferences. Sequences ultraconserved between the genomes\nof honeybee and Nasonia, another hymenopteran insect, were determined. They\nshowed strong preferences towards locating in the GC-rich regions of the bee\ngenome.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0702037v1"
    },
    {
        "title": "Toward a better analysis of secreted proteins: the example of the\n  myeloid cells secretome",
        "authors": [
            "Mireille Chevallet",
            "Hélène Diemer",
            "Alain van Dorsselaer",
            "Christian Villiers",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  The analysis of secreted proteins represents a challenge for current\nproteomics techniques. Proteins are usually secreted at low concentrations in\nthe culture media, which makes their recovery difficult. In addition, culture\nmedia are rich in salts and other compounds interfering with most proteomics\ntechniques, which makes selective precipitation of proteins almost mandatory\nfor a correct subsequent proteomics analysis. Last but not least, the\nnon-secreted proteins liberated in the culture medium upon lysis of a few dead\ncells heavily contaminate the so-called secreted proteins preparations. Several\ntechniques have been used in the past for concentration of proteins secreted in\nculture media. These techniques present several drawbacks, such as\ncoprecipitation of salts or poor yields at low protein concentrations. Improved\ntechniques based on carrier-assisted trichloroacetic acid precipitation are\ndescribed and discussed in this paper. These techniques have been used to\nanalyse the secretome of myeloid cells (macrophages, dendritic cells) and\nenabled to analyze proteins secreted at concentrations close to 1 ng/ml,\nthereby allowing to detect some of the cytokines (TNF, IL-12) secreted by the\nmyeloid cells upon activation by bacterial products.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0703006v1"
    },
    {
        "title": "Noise-filtering features of transcription regulation in the yeast S.\n  cerevisiae",
        "authors": [
            "Erik Aurell",
            "Aymeric Fouquier d'Herouel",
            "Claes Malmnas",
            "Massimo Vergassola"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Transcription regulation is largely governed by the profile and the dynamics\nof transcription factors' binding to DNA. Stochastic effects are intrinsic to\nthis dynamics and the binding to functional sites must be controled with a\ncertain specificity for living organisms to be able to elicit specific cellular\nresponses. Specificity stems here from the interplay between binding affinity\nand cellular abundancy of transcription factor proteins and the binding of such\nproteins to DNA is thus controlled by their chemical potential.\n  We combine large-scale protein abundance data in the budding yeast with\nbinding affinities for all transcription factors with known DNA binding site\nsequences to assess the behavior of their chemical potentials. A sizable\nfraction of transcription factors is apparently bound non-specifically to DNA\nand the observed abundances are marginally sufficient to ensure high\noccupations of the functional sites. We argue that a biological cause of this\nfeature is related to its noise-filtering consequences: abundances below\nphysiological levels do not yield significant binding of functional targets and\nmis-expressions of regulated genes are thus tamed.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0703063v1"
    },
    {
        "title": "Mismatch Repair Error Implies Chargaff's Second Parity Rule",
        "authors": [
            "Bo Deng"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Chargaff's second parity rule holds empirically for most types of DNA that\nalong single strands of DNA the base contents are equal for complimentary\nbases, A = T, G = C. A Markov chain model is constructed to track the evolution\nof any single base position along single strands of genomes whose organisms are\nequipped with replication mismatch repair. Under the key assumptions that\nmismatch error rates primarily depend the number of hydrogen bonds of\nnucleotides and that the mismatch repairing process itself makes strand\nrecognition error, the model shows that the steady state probabilities for any\nbase position to take on one of the 4 nucleotide bases are equal for\ncomplimentary bases. As a result, Chargaff's second parity rule is the\nmanifestation of the Law of Large Number acting on the steady state\nprobabilities. More importantly, because the model pinpoints mismatch repair as\na basis of the rule, it is suitable for experimental verification.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.2191v2"
    },
    {
        "title": "Chromatin Folding in Relation to Human Genome Function",
        "authors": [
            "Julio Mateos-Langerak",
            "Osdilly Giromus",
            "Wim de Leeuw",
            "Manfred Bohn",
            "Pernette J. Verschure",
            "Gregor Kreth",
            "Dieter W. Heermann",
            "Roel van Driel",
            "Sandra Goetze"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Three-dimensional (3D) chromatin structure is closely related to genome\nfunction, in particular transcription. However, the folding path of the\nchromatin fiber in the interphase nucleus is unknown. Here, we systematically\nmeasured the 3D physical distance between pairwise labeled genomic positions in\ngene-dense, highly transcribed domains and gene-poor less active areas on\nchromosomes 1 and 11 in G1 nuclei of human primary fibroblasts, using\nfluorescence in situ hybridization. Interpretation of our results and those\npublished by others, based on polymer physics, shows that the folding of the\nchromatin fiber can be described as a polymer in a globular state (GS),\nmaintained by intra-polymer attractive interactions that counteract\nself-avoidance forces. The GS polymer model is able to describe chromatin\nfolding in as well the highly expressed domains as the lowly expressed ones,\nindicating that they differ in Kuhn length and chromatin compaction. Each type\nof genomic domain constitutes an ensemble of relatively compact globular\nfolding states, resulting in a considerable cellto- cell variation between\notherwise identical cells. We present evidence for different polymer folding\nregimes of the chromatin fiber on the length scale of a few mega base pairs and\non that of complete chromosome arms (several tens of Mb). Our results present a\nnovel view on the folding of the chromatin fiber in interphase and open the\npossibility to explore the nature of the intra-chromatin fiber interactions.\n",
        "pdf_link": "http://arxiv.org/pdf/0705.1656v1"
    },
    {
        "title": "Reciprocal best hits are not a logically sufficient condition for\n  orthology",
        "authors": [
            "Toby Johnson"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  It is common to use reciprocal best hits, also known as a boomerang\ncriterion, for determining orthology between sequences. The best hits may be\nfound by blast, or by other more recently developed algorithms. Previous work\nseems to have assumed that reciprocal best hits is a sufficient but not\nnecessary condition for orthology. In this article, I explain why reciprocal\nbest hits cannot logically be a sufficient condition for orthology. If\nreciprocal best hits is neither sufficient nor necessary for orthology, it\nwould seem worthwhile to examine further the logical foundations of some\nunsupervised algorithms that are used to identify orthologs.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.0117v1"
    },
    {
        "title": "Codon Usage Bias Measured Through Entropy Approach",
        "authors": [
            "Michael G. Sadovsky",
            "Julia A. Putintzeva"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Codon usage bias measure is defined through the mutual entropy calculation of\nreal codon frequency distribution against the quasi-equilibrium one. This\nlatter is defined in three manners: (1) the frequency of synonymous codons is\nsupposed to be equal (i.e., the arithmetic mean of their frequencies); (2) it\ncoincides to the frequency distribution of triplets; and, finally, (3) the\nquasi-equilibrium frequency distribution is defined as the expected frequency\nof codons derived from the dinucleotide frequency distribution. The measure of\nbias in codon usage is calculated for 125 bacterial genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.2077v1"
    },
    {
        "title": "OrfMapper: A Web-Based Application for Visualizing Gene Clusters on\n  Metabolic Pathway Maps",
        "authors": [
            "Robbe Wunschiers",
            "Martin Vellguth"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Computational analyses of, e.g., genomic, proteomic, or metabolomic data,\ncommonly result in one or more sets of candidate genes, proteins, or enzymes.\nThese sets are often the outcome of clustering algorithms. Subsequently, it has\nto be tested if, e.g., the candidate gene-products are members of known\nmetabolic processes. With OrfMapper we provide a powerful but easy-to-use,\nweb-based database application, that supports such analyses. All services\nprovided by OrfMapper are freely available at http://www.orfmapper.com\n",
        "pdf_link": "http://arxiv.org/pdf/0706.3477v1"
    },
    {
        "title": "Silver staining of proteins in polyacrylamide gels",
        "authors": [
            "Mireille Chevallet",
            "Sylvie Luche",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Silver staining is used to detect proteins after electrophoretic separation\non polyacrylamide gels. It combines excellent sensitivity (in the low nanogram\nrange) with the use of very simple and cheap equipment and chemicals. It is\ncompatible with downstream processing, such as mass spectrometry analysis after\nprotein digestion. The sequential phases of silver staining are protein\nfixation, then sensitization, then silver impregnation and finally image\ndevelopment. Several variants of silver staining are described here, which can\nbe completed in a time range from 2 h to 1 d after the end of the\nelectrophoretic separation. Once completed, the stain is stable for several\nweeks.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.4396v1"
    },
    {
        "title": "Genomes: at the edge of chaos with maximum information capacity",
        "authors": [
            "Sing-Guan Kong",
            "Hong-Da Chen",
            "Wen-Lang Fan",
            "Jan Wigger",
            "Andrew Torda",
            "HC Lee"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We propose an order index, phi, which quantifies the notion of ``life at the\nedge of chaos'' when applied to genome sequences. It maps genomes to a number\nfrom 0 (random and of infinite length) to 1 (fully ordered) and applies\nregardless of sequence length. The 786 complete genomic sequences in GenBank\nwere found to have phi values in a very narrow range, 0.037+/-0.027. We show\nthis implies that genomes are halfway towards being completely random, namely,\nat the edge of chaos. We argue that this narrow range represents the\nneighborhood of a fixed-point in the space of sequences, and genomes are driven\nthere by the dynamics of a robust, predominantly neutral evolution process.\n",
        "pdf_link": "http://arxiv.org/pdf/0708.1598v1"
    },
    {
        "title": "Genome landscapes and bacteriophage codon usage",
        "authors": [
            "Julius B. Lucks",
            "David R. Nelson",
            "Grzegorz Kudla",
            "Joshua B. Plotkin"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Across all kingdoms of biological life, protein-coding genes exhibit unequal\nusage of synonmous codons. Although alternative theories abound, translational\nselection has been accepted as an important mechanism that shapes the patterns\nof codon usage in prokaryotes and simple eukaryotes. Here we analyze patterns\nof codon usage across 74 diverse bacteriophages that infect E. coli, P.\naeruginosa and L. lactis as their primary host. We introduce the concept of a\n`genome landscape,' which helps reveal non-trivial, long-range patterns in\ncodon usage across a genome. We develop a series of randomization tests that\nallow us to interrogate the significance of one aspect of codon usage, such a\nGC content, while controlling for another aspect, such as adaptation to\nhost-preferred codons. We find that 33 phage genomes exhibit highly non-random\npatterns in their GC3-content, use of host-preferred codons, or both. We show\nthat the head and tail proteins of these phages exhibit significant bias\ntowards host-preferred codons, relative to the non-structural phage proteins.\nOur results support the hypothesis of translational selection on viral genes\nfor host-preferred codons, over a broad range of bacteriophages.\n",
        "pdf_link": "http://arxiv.org/pdf/0708.2038v1"
    },
    {
        "title": "CompostBin: A DNA composition-based algorithm for binning environmental\n  shotgun reads",
        "authors": [
            "Sourav Chatterji",
            "Ichitaro Yamazaki",
            "Zhaojun Bai",
            "Jonathan Eisen"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  A major hindrance to studies of microbial diversity has been that the vast\nmajority of microbes cannot be cultured in the laboratory and thus are not\namenable to traditional methods of characterization. Environmental shotgun\nsequencing (ESS) overcomes this hurdle by sequencing the DNA from the organisms\npresent in a microbial community. The interpretation of this metagenomic data\ncan be greatly facilitated by associating every sequence read with its source\norganism. We report the development of CompostBin, a DNA composition-based\nalgorithm for analyzing metagenomic sequence reads and distributing them into\ntaxon-specific bins. Unlike previous methods that seek to bin assembled contigs\nand often require training on known reference genomes, CompostBin has the\nability to accurately bin raw sequence reads without need for assembly or\ntraining. It applies principal component analysis to project the data into an\ninformative lower-dimensional space, and then uses the normalized cut\nclustering algorithm on this filtered data set to classify sequences into\ntaxon-specific bins. We demonstrate the algorithm's accuracy on a variety of\nsimulated data sets and on one metagenomic data set with known species\nassignments. CompostBin is a work in progress, with several refinements of the\nalgorithm planned for the future.\n",
        "pdf_link": "http://arxiv.org/pdf/0708.3098v1"
    },
    {
        "title": "Ultrafast coelectrophoretic fluorescent staining of proteins with\n  carbocyanines",
        "authors": [
            "Sylvie Luche",
            "Cécile Lelong",
            "Hélène Diemer",
            "Alain Van Dorsselaer",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Protein detection on SDS gels or on 2-D gels must combine several features,\nsuch as sensitivity, homogeneity from one protein to another, speed, low cost,\nand user-friendliness. For some applications, it is also interesting to have a\nnonfixing stain, so that proteins can be mobilized from the gel for further use\n(electroelution, blotting). We show here that coelectrophoretic staining by\nfluorophores of the oxacarbocyanine family, and especially\ndiheptyloxacarbocyanine, offers several positive features. The sensitivity is\nintermediate between the one of colloidal CBB and the one of fluroescent\nruthenium complexes. Detection is achieved within 1 h after the end of the\nelectrophoretic process and does not use any fixing or toxic agent. The\nfluorescent SDS-carbocyanine-protein complexes can be detected either with a\nlaser scanner with an excitation wavelength of 488 nm or with a UV table\noperating at 302 nm. Excellent sequence coverage in subsequent MS analysis of\nproteolytic peptides is also achieved with this detection method.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.0717v1"
    },
    {
        "title": "DrosOCB: a high resolution map of conserved non coding sequences in\n  Drosophila",
        "authors": [
            "L. Martignetti",
            "M. Caselle",
            "B. Jacq",
            "C. Herrmann"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Comparative genomics methods are widely used to aid the functional annotation\nof non coding DNA regions. However, aligning non coding sequences requires new\nalgorithms and strategies, in order to take into account extensive\nrearrangements and turnover during evolution. Here we present a novel large\nscale alignment strategy which aims at drawing a precise map of conserved non\ncoding regions between genomes, even when these regions have undergone small\nscale rearrangments events and a certain degree of sequence variability. We\napplied our alignment approach to obtain a genome-wide catalogue of conserved\nnon coding blocks (CNBs) between Drosophila melanogaster and 11 other\nDrosophila species. Interestingly, we observe numerous small scale\nrearrangement events, such as local inversions, duplications and\ntranslocations, which are not observable in the whole genome alignments\ncurrently available. The high rate of observed low scale reshuffling show that\nthis database of CNBs can constitute the starting point for several\ninvestigations, related to the evolution of regulatory DNA in Drosophila and\nthe in silico identification of unannotated functional elements.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.1570v1"
    },
    {
        "title": "Electric Transport Properties of the p53 Gene and the Effects of Point\n  Mutations",
        "authors": [
            "Chi-Tin Shih",
            "Rudolf A. Römer",
            "Stephan Roche"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  In this work, charge transport (CT) properties of the p53 gene are\nnumerically studied by the transfer matrix method, and using either single or\ndouble strand effective tight-binding models. A statistical analysis of the\nconsequences of known p53 point mutations on CT features is performed. It is\nfound that in contrast to other kind of mutation defects, cancerous mutations\nresult in much weaker changes of CT efficiency. Given the envisioned role\nplayed by CT in the DNA-repairing mechanism, our theoretical results suggest an\nunderlying physical explanation at the origin of carcinogenesis.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.1676v1"
    },
    {
        "title": "Understanding Transcriptional Regulation Using De-novo Sequence Motif\n  Discovery, Network Inference and Interactome Data",
        "authors": [
            "Arvind Rao",
            "Alfred O. Hero",
            "David J. States",
            "James Douglas Engel"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Gene regulation is a complex process involving the role of several genomic\nelements which work in concert to drive spatio-temporal expression. The\nexperimental characterization of gene regulatory elements is a very complex and\nresource-intensive process. One of the major goals in computational biology is\nthe \\textit{in-silico} annotation of previously uncharacterized elements using\nresults from the subset of known, previously annotated, regulatory elements.\n  The recent results of the ENCODE project (\\emph{http://encode.nih.gov})\npresented in-depth analysis of such functional (regulatory) non-coding elements\nfor 1% of the human genome. It is hoped that the results obtained on this\nsubset can be scaled to the rest of the genome. This is an extremely important\neffort which will enable faster dissection of other functional elements in key\nbiological processes such as disease progression and organ development\n(\\cite{Kleinjan2005},\\cite{Lieb2006}. The computational annotation of these\nhitherto uncharacterized regions would require an identification of features\nthat have good predictive value.\n  In this work, we study transcriptional regulation as a problem in\nheterogeneous data integration, across sequence, expression and interactome\nlevel attributes. Using the example of the \\textit{Gata2} gene and its recently\ndiscovered urogenital enhancers \\cite{Khandekar2004} as a case study, we\nexamine the predictive value of various high throughput functional genomic\nassays (from projects like ENCODE and SymAtlas) in characterizing these\nenhancers and their regulatory role. Observing results from the application of\nmodern statistical learning methodologies for each of these data modalities, we\npropose a set of features that are most discriminatory to find these enhancers.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.1889v1"
    },
    {
        "title": "From DNA sequence analysis to modeling replication in the human genome",
        "authors": [
            "Edward-Benedict Brodie",
            "Samuel Nicolay",
            "Marie Touchon",
            "Benjamin Audit",
            "Yves D'Aubenton-Carafa",
            "Claude Thermes",
            "Alain Arneodo"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We explore the large-scale behavior of nucleotide compositional strand\nasymmetries along human chromosomes. As we observe for 7 of 9 origins of\nreplication experimentally identified so far, the (TA+GC) skew displays rather\nsharp upward jumps, with a linear decreasing profile in between two successive\njumps. We present a model of replication with well positioned replication\norigins and random terminations that accounts for the observed characteristic\nserrated skew profiles. We succeed in identifying 287 pairs of putative\nadjacent replication origins with an origin spacing approximately 1-2 Mbp that\nare likely to correspond to replication foci observed in interphase nuclei and\nrecognized as stable structures that persist throughout subsequent cell\ngenerations.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4030v1"
    },
    {
        "title": "A mechanistic model for +1 frameshifts in eubacteria",
        "authors": [
            "Lalit Ponnala",
            "Donald Bitzer",
            "Anne Stomp",
            "Mladen Vouk"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  This work applies the methods of signal processing and the concepts of\ncontrol system design to model the maintenance and modulation of reading frame\nin the process of protein synthesis. The model shows how translational speed\ncan modulate translational accuracy to accomplish programmed +1 frameshifts and\ncould have implications for the regulation of translational efficiency. A\nseries of free energy estimates were calculated from the ribosome's interaction\nwith mRNA sequences during the process of translation elongation in eubacteria.\nA sinusoidal pattern of roughly constant phase was detected in these free\nenergy signals. Signal phase was identified as a useful parameter for locating\nprogrammed +1 frameshifts encoded in bacterial genes for release factor 2. A\ndisplacement model was developed that captures the mechanism of frameshift\nbased on the information content of the signal parameters and the relative\nabundance of tRNA in the bacterial cell. Results are presented using\nexperimentally verified frameshift genes across eubacteria.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.2068v1"
    },
    {
        "title": "Zinc adaptation and resistance to cadmium toxicity in mammalian cells.\n  Molecular insight by proteomic analysis",
        "authors": [
            "Estelle Rousselet",
            "Alain Martelli",
            "Mireille Chevallet",
            "Hélène Diemer",
            "Alain Van Dorssealer",
            "Thierry Rabilloud",
            "Jean-Marc Moulis"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  To identify proteins involved in cellular adaptive responses to zinc, a\ncomparative proteome analysis between a previously developed high zinc- and\ncadmium- resistant human epithelial cell line (HZR) and the parental HeLa cells\nhas been carried out. Differentially produced proteins included co-chaperones,\nproteins associated with oxido-reductase activities, and ubiquitin. Biochemical\npathways to which these proteins belong were probed for their involvement in\nthe resistance of both cell lines against cadmium toxicity. Among endoplasmic\nreticulum stressors, thapsigargin sensitized HZR cells, but not HeLa cells, to\ncadmium toxicity more acutely than tunicamycin, implying that these cells\nheavily relied on proper intracellular calcium distribution. The similar\nsensitivity of both HeLa and HZR cells to inhibitors of the proteasome, such as\nMG-132 or lactacystin, excluded improved proteasome activity as a mechanism\nassociated with zinc adaptation of HZR cells. The enzyme\n4-hydroxyphenylpyruvate dioxygenase was overproduced in HZR cells as compared\nto HeLa cells. It transforms 4-hydroxyphenylpyruvate to homogentisate in the\nsecond step of tyrosine catabolism. Inhibition of 4-hydroxyphenylpyruvate\ndioxygenase decreased the resistance of HZR cells against cadmium, but not that\nof HeLa cells, suggesting that adaptation to zinc overload and increased\n4-hydroxyphenylpyruvate removal are linked in HZR cells\n",
        "pdf_link": "http://arxiv.org/pdf/0803.0850v1"
    },
    {
        "title": "Interchromatidal central ridge and transversal symmetry in early\n  metaphasic human chromosome one",
        "authors": [
            "O. Argüello-Miranda",
            "G. Sáenz-Arce"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The topographic structure of Giemsa banded (G-banded) early metaphase human\nchromosomes adsorbed on glass was analyzed by atomic force microscope using\namplitude modulation mode [AM-AFM]. Longitudinal height measurements for early\nmetaphasic human chromosomes showed a central ridge that was further\ncharacterized by transversal height measurements. The heterochromatic regions\ndisplayed a high level of transversal symmetry, while the euchromatic ones\npresented several peaks across the transversal height measurements. We suggest\nthat this central ridge and symmetry patterns point out a transitional\narrangement of the early metaphase chromosome and support evidence for\ninterchromatidal interactions prior to disjunction.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.0964v1"
    },
    {
        "title": "Chance and necessity in chromosomal gene distributions",
        "authors": [
            "Rutger Hermsen",
            "Pieter Rein ten Wolde",
            "Sarah Teichmann"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  By analyzing the spacing of genes on chromosomes, we find that\ntranscriptional and RNA-processing regulatory sequences outside coding regions\nleave footprints on the distribution of intergenic distances. Using analogies\nbetween genes on chromosomes and one-dimensional gases, we constructed a\nstatistical null model. We have used this to estimate typical upstream and\ndownstream regulatory sequence sizes in various species. Deviations from this\nmodel reveal bi-directional transcriptional regulatory regions in S. cerevisiae\nand bi-directional terminators in E. coli.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.1261v1"
    },
    {
        "title": "Identifying short motifs by means of extreme value analysis",
        "authors": [
            "Daniela Bianchi",
            "Brunello Tirozzi"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The problem of detecting a binding site -- a substring of DNA where\ntranscription factors attach -- on a long DNA sequence requires the recognition\nof a small pattern in a large background. For short binding sites, the matching\nprobability can display large fluctuations from one putative binding site to\nanother. Here we use a self-consistent statistical procedure that accounts\ncorrectly for the large deviations of the matching probability to predict the\nlocation of short binding sites. We apply it in two distinct situations: (a)\nthe detection of the binding sites for three specific transcription factors on\na set of 134 estrogen-regulated genes; (b) the identification, in a set of 138\npossible transcription factors, of the ones binding a specific set of nine\ngenes. In both instances, experimental findings are reproduced (when available)\nand the number of false positives is significantly reduced with respect to the\nother methods commonly employed.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.4277v2"
    },
    {
        "title": "A limiting rule for the variability of coding sequence length in\n  microbial genomes",
        "authors": [
            "Vasile V. Morariu"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The mean length and the variability of coding sequences for 48 genomes of\nbacteria and archaea were analyzed. It was found that the plotted data can be\ndescribed by an angular area. This suggests the followings: a) The variability\nof a genome increases as the mean length increases; b) There is an upper and a\nlower limit for variability for a given mean length; c) Extrapolation of the\nupper and lower limits to lower mean values converges to a single point which\nmight be assimilated to a primordial cell. The whole picture is reminding of a\nprocess which starts from a single cell and evolves into more and more species\nwhich, in turn, show more and more variability.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.1289v1"
    },
    {
        "title": "Microbial genome as a fluctuating system: Distribution and correlation\n  of coding sequence lengths",
        "authors": [
            "V. V. Morariu"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The length of coding sequence series in microbial genomes were regarded as a\nfluctuating system and characterized by the methods of statistical physics. The\ndistribution and the correlatin properties of 50 genomes including bacteria and\nseveral archaea were investigated. The distribution was investigated by\nrank-size analysis (Zipf's law. We found that coding sequence lengths series do\nnot obey Zipf's law contrary to natural languages. The distribution was found\nto be more closely to an exponential distribution. The correlation appeared to\nbe similar to natural languages. Segmentation analysis of the series showed to\nbe short range memory systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.4315v1"
    },
    {
        "title": "A standalone version of IsoFinder for the computational prediction of\n  isochores in genome sequences",
        "authors": [
            "Pedro Bernaola-Galván",
            "Pedro Carpena",
            "José L. Oliver"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Isochores are long genome segments relatively homogeneous in G+C. A heuristic\nalgorithm based on entropic segmentation has been developed by our group, and a\nweb server implementing all the required components is available. However, a\nresearcher may want to perform batch processing of many sequences\nsimultaneously in its local machine, instead of analyzing them on one by one\nbasis through the web. To this end, standalone versions are required. We report\nhere the implementation of two standalone programs, able to predict isochores\nat the sequence level: 1) a command-line version (IsoFinder) for Windows and\nLinux systems; and 2) a user-friendly version (IsoFinderWin) running under\nWindows.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.1292v1"
    },
    {
        "title": "Comment of Global dynamics of biological systems",
        "authors": [
            "Radhakrishnan Nagarajan"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  In a recent study, (Grigorov, 2006) analyzed temporal gene expression\nprofiles (Arbeitman et al., 2002) generated in a Drosophila experiment using\nSSA in conjunction with Monte-Carlo SSA. The author (Grigorov, 2006) makes\nthree important claims in his article, namely:\n  Claim1: A new method based on the theory of nonlinear time series analysis is\nused to capture the global dynamics of the fruit-fly cycle temporal gene\nexpression profiles.\n  Claim 2: Flattening of a significant part of the eigen-spectrum confirms the\nhypothesis about an underly-ing high-dimensional chaotic generating process.\n  Claim 3: Monte-Carlo SSA can be used to establish whether a given time series\nis distinguishable from any well-defined process including deterministic chaos.\n  In this report we present fundamental concerns with respect to the above\nclaims (Grigorov, 2006) in a systematic manner with simple examples. The\ndiscussion provided especially discourages the choice of SSA for inferring\nnonlinear dynamical structure form time series obtained in any biological\nparadigm.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.3479v1"
    },
    {
        "title": "Keynotes on membrane proteomics",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  This review article deals with the specificities of the proteomics analysis\nof membrane proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1039v1"
    },
    {
        "title": "Oxidative stress response: a proteomic view",
        "authors": [
            "Thierry Rabilloud",
            "Mireille Chevallet",
            "Sylvie Luche",
            "Emmanuelle Leize-Wagner"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The oxidative stress response is characterized by various effects on a range\nof biologic molecules. When examined at the protein level, both expression\nlevels and protein modifications are altered by oxidative stress. While these\neffects have been studied in the past by classic biochemical methods, the\nrecent onset of proteomics methods has allowed the oxidative stress response to\nbe studied on a much wider scale. The input of proteomics in the study of\noxidative stress response and in the evidence of an oxidative stress component\nin biologic phenomena is reviewed in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1041v1"
    },
    {
        "title": "How shall we use the proteomics toolbox for biomarker discovery?",
        "authors": [
            "Pierre Lescuyer",
            "Denis Hochstrasser",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Biomarker discovery for clinical purposes is one of the major areas in which\nproteomics is used. However, despite considerable effort, the successes have\nbeen relatively scarce. In this perspective paper, we try to highlight and\nanalyze the main causes for this limited success, and to suggest alternate\nstrategies, which will avoid them, without eluding the foreseeable weak points\nof these strategies. Two major strategies are analyzed, namely, the switch from\nbody fluids to cell and tissues for the initial biomarker discovery step or, if\nbody fluids must be analyzed, the implementation of highly selective protein\nselection strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1206v1"
    },
    {
        "title": "Mitochondrial proteomics: analysis of a whole mitochondrial extract with\n  two-dimensional electrophoresis",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Mitochondria are complex organelles, and their proteomics analysis requires a\ncombination of techniques. The emphasis in this chapter is made first on\nmitochondria preparation from cultured mammalian cells, then on the separation\nof the mitochondrial proteins with two-dimensional electrophoresis (2DE),\nshowing some adjustment over the classical techniques to improve resolution of\nthe mitochondrial proteins. This covers both the protein solubilization, the\nelectrophoretic part per se, and the protein detection on the gels, which makes\nthe interface with the protein identification part relying on mass\nspectrometry.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1276v1"
    },
    {
        "title": "Genetic code evolution as an initial driving force for molecular\n  evolution",
        "authors": [
            "Dirson Jian Li",
            "Shengli Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  There is an intrinsic relationship between the molecular evolution in\nprimordial period and the properties of genomes and proteomes of contemporary\nspecies. The genomic data may help us understand the driving force of evolution\nof life at molecular level. In absence of evidence, numerous problems in\nmolecular evolution had to fall into a twilight zone of speculation and\ncontroversy in the past. Here we show that delicate structures of variations of\ngenomic base compositions and amino acid frequencies resulted from the genetic\ncode evolution. And the driving force of evolution of life also originated in\nthe genetic code evolution. The theoretical results on the variations of amino\nacid frequencies and genomic base compositions agree with the experimental\nobservations very well, not only in the variation trends but also in some fine\nstructures. Inversely, the genomic data of contemporary species can help\nreconstruct the genetic code chronology and amino acid chronology in primordial\nperiod. Our results may shed light on the intrinsic mechanism of molecular\nevolution and the genetic code evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1762v2"
    },
    {
        "title": "Computation of Maximal Resolution of Copy Number Variation on a\n  Nanofluidic Device using Digital PCR",
        "authors": [
            "Simant Dube",
            "Alain Mir",
            "Robert C. Jones",
            "Ramesh Ramakrishnan",
            "Gang Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Copy Number Variations (CNVs) of regions of the human genome are important in\ndisease association studies.The digital array is a nanofluidic biochip which\nutilizes integrated channels and valves that partition mixtures of sample and\nreagents into 765 nanovolume reaction chambers. It was recently shown how one\ncan perform statistical analysis of CNV in a DNA sample the digital array. In\nparticular, it was shown how one can accurately estimate the true concentration\nof the molecules in the DNA sample and then determine the ratios of different\nsequences along with statistical confidence intervals on these estimations. In\nthis paper we perform computation of maximum number of copies which can be\ndistinguished using the digital array which gives its resolution in terms of\nits ability to determine CNV. Then, we demonstrate the usefulness of the\nmathematical analysis to solve an important real-world problem of determination\nof the copy number of X chromosome as our example application.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.1460v2"
    },
    {
        "title": "Sequence alignment and mutual information",
        "authors": [
            "Orion Penner",
            "Peter Grassberger",
            "Maya Paczuski"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Background: Alignment of biological sequences such as DNA, RNA or proteins is\none of the most widely used tools in computational bioscience. All existing\nalignment algorithms rely on heuristic scoring schemes based on biological\nexpertise. Therefore, these algorithms do not provide model independent and\nobjective measures for how similar two (or more) sequences actually are.\nAlthough information theory provides such a similarity measure -- the mutual\ninformation (MI) -- previous attempts to connect sequence alignment and\ninformation theory have not produced realistic estimates for the MI from a\ngiven alignment.\n  Results: Here we describe a simple and flexible approach to get robust\nestimates of MI from {\\it global} alignments. For mammalian mitochondrial DNA,\nour approach gives pairwise MI estimates for commonly used global alignment\nalgorithms that are strikingly close to estimates obtained by an entirely\nunrelated approach -- concatenating and zipping the sequences.\n  Conclusions: This remarkable consistency may help establish MI as a reliable\ntool for evaluating the quality of global alignments, judging the relative\nmerits of different alignment algorithms, and estimating the significance of\nspecific alignments. We expect that our approach can be extended to establish\nfurther connections between information theory and sequence alignment,\nincluding applications to local and multiple alignment procedures.\n",
        "pdf_link": "http://arxiv.org/pdf/0810.4355v1"
    },
    {
        "title": "SERpredict: Detection of tissue- or tumor-specific isoforms generated\n  through exonization of transposable elements",
        "authors": [
            "Britta Mersch",
            "Noa Sela",
            "Gil Ast",
            "Sandor Suhai",
            "Agnes Hotz- Wagenblatt"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Background: Transposed elements (TEs) are known to affect transcriptomes,\nbecause either new exons are generated from intronic transposed elements (this\nis called exonization), or the element inserts into the exon, leading to a new\ntranscript. Several examples in the literature show that isoforms generated by\nan exonization are specific to a certain tissue (for example the heart muscle)\nor inflict a disease. Thus, exonizations can have negative effects for the\ntranscriptome of an organism. Results: As we aimed at detecting other tissue-\nor tumor-specific isoforms in human and mouse genomes which were generated\nthrough exonization of a transposed element, we designed the automated analysis\npipeline SERpredict (SER = Specific Exonized Retroelement) making use of\nBayesian Statistics. With this pipeline, we found several genes in which a\ntransposed element formed a tissue- or tumor-specific isoform. Conclusion: Our\nresults show that SERpredict produces relevant results, demonstrating the\nimportance of transposed elements in shaping both the human and the mouse\ntranscriptomes. The effect of transposed elements on the human transcriptome is\nseveral times higher than the effect on the mouse transcriptome, due to the\ncontribution of the primate-specific Alu elements\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3502v1"
    },
    {
        "title": "Combining chromosomal arm status and significantly aberrant genomic\n  locations reveals new cancer subtypes",
        "authors": [
            "Tal Shay",
            "Wanyu L. Lambiv",
            "Anat Reiner",
            "Monika E. Hegi",
            "Eytan Domany"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Many types of tumors exhibit chromosomal losses or gains, as well as local\namplifications and deletions. Within any given tumor type, sample specific\namplifications and deletionsare also observed. Typically, a region that is\naberrant in more tumors,or whose copy number change is stronger, would be\nconsidered as a more promising candidate to be biologically relevant to cancer.\nWe sought for an intuitive method to define such aberrations and prioritize\nthem. We define V, the volume associated with an aberration, as the product of\nthree factors: a. fraction of patients with the aberration, b. the aberrations\nlength and c. its amplitude. Our algorithm compares the values of V derived\nfrom real data to a null distribution obtained by permutations, and yields the\nstatistical significance, p value, of the measured value of V. We detected\ngenetic locations that were significantly aberrant and combined them with\nchromosomal arm status to create a succint fingerprint of the tumor genome.\nThis genomic fingerprint is used to visualize the tumors, highlighting events\nthat are co ocurring or mutually exclusive. We allpy the method on three\ndifferent public array CGH datasets of Medulloblastoma and Neuroblastoma, and\ndemonstrate its ability to detect chromosomal regions that were known to be\naltered in the tested cancer types, as well as to suggest new genomic locations\nto be tested. We identified a potential new subtype of Medulloblastoma, which\nis analogous to Neuroblastoma type 1.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.1656v1"
    },
    {
        "title": "Sweet silver: A formaldehyde-free silver staining using aldoses as\n  developing agents, with enhanced compatibility with mass spectrometry",
        "authors": [
            "Mireille Chevallet",
            "Sylvie Luche",
            "Hélène Diemer",
            "Jean-Marc Strub",
            "Alain Van Dorsselaer",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Protein detection methods after electrophoresis have to be sensitive,\nhomogeneous, and not to impair downstream analysis of proteins by MS. Speed,\nlow cost, and user friendliness are also favored features. Silver staining\ncombines many of these features, but its compatibility with MS is limited. We\ndescribe here, a new variant of silver staining that is completely\nformaldehyde-free. Reducing sugars in alkaline borate buffer are used as\ndevelopers. While keeping the benefits of silver staining, this method is shown\nto afford a much better performance in terms of compatibility with MS, both in\nPMF by MALDI and in LC/ESI/MS/MS.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.3988v1"
    },
    {
        "title": "Fully denaturing two-dimensional electrophoresis of membrane proteins: a\n  critical update",
        "authors": [
            "Thierry Rabilloud",
            "Mireille Chevallet",
            "Sylvie Luche",
            "Cécile Lelong"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The quality and ease of proteomics analysis depends on the performance of the\nanalytical tools used, and thus of the performances of the protein separation\ntools used to deconvolute complex protein samples. Among protein samples,\nmembrane proteins are one of the most difficult sample classes, because of\ntheir hydrophobicity and embedment in the lipid bilayers. This review deals\nwith the recent progresses and advances made in the separation of membrane\nproteins by 2-DE separating only denatured proteins. Traditional 2-D methods,\ni.e., methods using IEF in the first dimension are compared to methods using\nonly zone electrophoresis in both dimensions, i.e., electrophoresis in the\npresence of cationic or anionic detergents. The overall performances and fields\nof application of both types of method is critically examined, as are future\nprospects for this field.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.4736v1"
    },
    {
        "title": "Multiple Sequence Alignment System for Pyrosequencing Reads",
        "authors": [
            "Fahad Saeed",
            "Ashfaq Khokhar",
            "Osvaldo Zagordi",
            "Niko Beerenwinkel"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Pyrosequencing is among the emerging sequencing techniques, capable of\ngenerating upto 100,000 overlapping reads in a single run. This technique is\nmuch faster and cheaper than the existing state of the art sequencing technique\nsuch as Sanger. However, the reads generated by pyrosequencing are short in\nsize and contain numerous errors. Furthermore, each read has a specific\nposition in the reference genome. In order to use these reads for any\nsubsequent analysis, the reads must be aligned . Existing multiple sequence\nalignment methods cannot be used as they do not take into account the specific\npositions of the sequences with respect to the genome, and are highly\ninefficient for large number of sequences. Therefore, the common practice has\nbeen to use either simple pairwise alignment despite its poor accuracy for\nerror prone pyroreads, or use computationally expensive techniques based on\nsequential gap propagation. In this paper, we develop a computationally\nefficient method based on domain decomposition, referred to as pyro-align, to\nalign such large number of reads. The proposed alignment algorithm accurately\naligns the erroneous reads in a short period of time, which is orders of\nmagnitude faster than any existing method. The accuracy of the alignment is\nconfirmed from the consensus obtained from the multiple alignments.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.2753v1"
    },
    {
        "title": "p-Adic numbers in bioinformatics: from genetic code to PAM-matrix",
        "authors": [
            "A. Yu. Khrennikov",
            "S. V. Kozyrev"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  In this paper we denonstrate that the use of the system of 2-adic numbers\nprovides a new insight to some problems of genetics, in particular, generacy of\nthe genetic code and the structure of the PAM matrix in bioinformatics. The\n2-adic distance is an ultrametric and applications of ultrametrics in\nbioinformatics are not surprising. However, by using the 2-adic numbers we\nmatch ultrametric with a number theoretic structure. In this way we find new\napplications of an ultrametric which differ from known up to now in\nbioinformatics.\n  We obtain the following results. We show that the PAM matrix A allows the\nexpansion into the sum of the two matrices A=A^{(2)}+A^{(\\infty)}, where the\nmatrix A^{(2)} is 2-adically regular (i.e. matrix elements of this matrix are\nclose to locally constant with respect to the discussed earlier by the authors\n2-adic parametrization of the genetic code), and the matrix A^{(\\infty)} is\nsparse. We discuss the structure of the matrix A^{(\\infty)} in relation to the\nside chain properties of the corresponding amino acids.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.0137v3"
    },
    {
        "title": "Organelle proteomics",
        "authors": [
            "Pierre Lescuyer",
            "Mireille Chevallet",
            "Sylvie Luche",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  This unit describes strategies for studying the proteomes of organelles,\nwhich is one example of targeted proteomics. It relies heavily on previously\npublished units dealing with organelle preparation, protein solubilization, and\nproteomics techniques. A specific commentary for organelle proteomics is\nprovided. Specific protocols for the isolation of nuclei from various sources\n(cell cultures, tissues) are also provided.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.0636v1"
    },
    {
        "title": "Non-equilibrium thermodynamics of gene expression and transcriptional\n  regulation",
        "authors": [
            "Enrique Hernandez-Lemus"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  In recent times whole-genome gene expression analysis has turned out to be a\nhighly important tool to study the coordinated function of a very large number\nof genes within their corresponding cellular environment, especially in\nrelation to phenotypic diversity and disease. A wide variety of methods of\nquantitative analysis have been developed to cope with high throughput data\nsets generated by gene expression profiling experiments. Due to the complexity\nassociated with transcriptomics, specially in the case of gene regulation\nphenomena, most of these methods are of a probabilistic or statistical nature.\nEven if these methods have reached a central status in the development of an\nintegrative, systematic understanding of the associated biological processes,\nthey very rarely constitute a concrete guide to the actual physicochemical\nmechanisms behind biological function and the role of these methods is more on\na hypotheses generating line. An important improvement could be done with the\ndevelopment of a thermodynamic theory for gene expression and transcriptional\nregulation that will build the foundations for a proper integration of the vast\namount of molecular biophysical data and could lead, in the future, to a\nsystemic view of genetic transcription and regulation.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.0662v2"
    },
    {
        "title": "Detergents and chaotropes for protein solubilization before\n  two-dimensional electrophoresis",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Because of the outstanding ability of two-dimensional electrophoresis to\nseparate complex mixtures of intact proteins, it would be advantageous to apply\nit to all types of proteins, including hydrophobic and membrane proteins.\nUnfortunately, poor solubility hampers the analysis of these molecules. As\nthese problems arise mainly in the extraction and isoelectric focusing steps,\nthe solution is to improve protein solubility under the conditions prevailing\nduring isoelectric focusing. This chapter describes the use of chaotropes and\nnovel detergents to enhance protein solubility during sample extraction and\nisoelectric focussing, and discusses the contribution of these compounds to\nimproving proteomic analysis of membrane proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.0685v1"
    },
    {
        "title": "Guidelines for reporting the use of gel electrophoresis in proteomics",
        "authors": [
            "Frank Gibson",
            "Leigh Anderson",
            "Gyorgy Babnigg",
            "Mark Baker",
            "Matthias Berth",
            "Pierre-Alain Binz",
            "Andy Borthwick",
            "Phil Cash",
            "Billy W Day",
            "David B Friedman",
            "Donita Garland",
            "Howard B Gutstein",
            "Christine Hoogland",
            "Neil A Jones",
            "Alamgir Khan",
            "Joachim Klose",
            "Angus I Lamond",
            "Peter F Lemkin",
            "Kathryn S Lilley",
            "Jonathan Minden",
            "Nicholas J Morris",
            "Norman W Paton",
            "Michael R Pisano",
            "John E Prime",
            "Thierry Rabilloud",
            "David A Stead",
            "Chris F Taylor",
            "Hans Voshol",
            "Anil Wipat",
            "Andrew R Jones"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  the MIAPE Gel Electrophoresis (MIAPE-GE) guidelines specify the minimum\ninformation that should be provided when reporting the use of n-dimensional gel\nelectrophoresis in a proteomics experiment. Developed through a joint effort\nbetween the gel-based analysis working group of the Human Proteome\nOrganisation's Proteomics Standards Initiative (HUPO-PSI;\nhttp://www.psidev.info/) and the wider proteomics community, they constitute\none part of the overall Minimum Information about a Proteomics Experiment\n(MIAPE) documentation system published last August in Nature Biotechnology\n",
        "pdf_link": "http://arxiv.org/pdf/0904.0694v1"
    },
    {
        "title": "Guidelines for the next 10 years of proteomics",
        "authors": [
            "Marc R Wilkins",
            "Ron D Appel",
            "Jennifer E Van Eyk",
            "Maxey C M Chung",
            "Angelika Görg",
            "Michael Hecker",
            "Lukas A Huber",
            "Hanno Langen",
            "Andrew J Link",
            "Young-Ki Paik",
            "Scott D Patterson",
            "Stephen R Pennington",
            "Thierry Rabilloud",
            "Richard J Simpson",
            "Walter Weiss",
            "Michael J Dunn"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  In the last ten years, the field of proteomics has expanded at a rapid rate.\nA range of exciting new technology has been developed and enthusiastically\napplied to an enormous variety of biological questions. However, the degree of\nstringency required in proteomic data generation and analysis appears to have\nbeen underestimated. As a result, there are likely to be numerous published\nfindings that are of questionable quality, requiring further confirmation\nand/or validation. This manuscript outlines a number of key issues in proteomic\nresearch, including those associated with experimental design, differential\ndisplay and biomarker discovery, protein identification and analytical\nincompleteness. In an effort to set a standard that reflects current thinking\non the necessary and desirable characteristics of publishable manuscripts in\nthe field, a minimal set of guidelines for proteomics research is then\ndescribed. These guidelines will serve as a set of criteria which editors of\nPROTEOMICS will use for assessment of future submissions to the Journal.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.0788v1"
    },
    {
        "title": "Extending the Recursive Jensen-Shannon Segmentation of Biological\n  Sequences",
        "authors": [
            "Siew-Ann Cheong",
            "Paul Stodghill",
            "David J. Schneider",
            "Samuel W. Cartinhour",
            "Christopher R. Myers"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  In this paper, we extend a previously developed recursive entropic\nsegmentation scheme for applications to biological sequences. Instead of\nBernoulli chains, we model the statistically stationary segments in a\nbiological sequence as Markov chains, and define a generalized Jensen-Shannon\ndivergence for distinguishing between two Markov chains. We then undertake a\nmean-field analysis, based on which we identify pitfalls associated with the\nrecursive Jensen-Shannon segmentation scheme. Following this, we explain the\nneed for segmentation optimization, and describe two local optimization schemes\nfor improving the positions of domain walls discovered at each recursion stage.\nWe also develop a new termination criterion for recursive Jensen-Shannon\nsegmentation based on the strength of statistical fluctuations up to a minimum\nstatistically reliable segment length, avoiding the need for unrealistic null\nand alternative segment models of the target sequence. Finally, we compare the\nextended scheme against the original scheme by recursively segmenting the\nEscherichia coli K-12 MG1655 genome.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.2466v1"
    },
    {
        "title": "The Context Sensitivity Problem in Biological Sequence Segmentation",
        "authors": [
            "Siew-Ann Cheong",
            "Paul Stodghill",
            "David J. Schneider",
            "Samuel W. Cartinhour",
            "Christopher R. Myers"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  In this paper, we describe the context sensitivity problem encountered in\npartitioning a heterogeneous biological sequence into statistically homogeneous\nsegments. After showing signatures of the problem in the bacterial genomes of\nEscherichia coli K-12 MG1655 and Pseudomonas syringae DC3000, when these are\nsegmented using two entropic segmentation schemes, we clarify the contextual\norigins of these signatures through mean-field analyses of the segmentation\nschemes. Finally, we explain why we believe all sequence segmentation schems\nare plagued by the context sensitivity problem.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.2668v1"
    },
    {
        "title": "Solubilization of Proteins in 2DE: An Outline",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Protein solubilization for two-dimensional electrophoresis (2DE) has to break\nmolecular interactions to separate the biological contents of the material of\ninterest into isolated and intact polypeptides. This must be carried out in\nconditions compatible with the first dimension of 2DE, namely isoelectric\nfocusing. In addition, the extraction process must enable easy removal of any\nnonprotein component interfering with the isoelectric focusing. The constraints\nbrought in this process by the peculiar features of isoelectric focusing are\ndiscussed, as well as their consequences in terms of possible solutions and\nlimits for the solubilization process.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3534v1"
    },
    {
        "title": "Silver Staining of Proteins in 2DE Gels",
        "authors": [
            "Cécile Lelong",
            "Mireille Chevallet",
            "Sylvie Luche",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Silver staining detects proteins after electrophoretic separation on\npolyacrylamide gels. Its main positive features are its excellent sensitivity\n(in the low nanogram range) and the use of very simple and cheap equipment and\nchemicals. The sequential phases of silver staining are protein fixation, then\nsensitization, then silver impregnation, and finally image development. Several\nvariants of silver staining are described here, which can be completed in a\ntime range from 2 h to 1 day after the end of the electrophoretic separation.\nOnce completed, the stain is stable for several weeks.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3535v1"
    },
    {
        "title": "Membrane proteins and proteomics: Love is possible, but so difficult",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Despite decades of extensive research, the large-scale analysis of membrane\nproteins remains a difficult task. This is due to the fact that membrane\nproteins require a carefully balanced hydrophilic and lipophilic environment,\nwhich optimum varies with different proteins, while most protein chemistry\nmethods work mainly, if not only, in water-based media. Taking this review\n[Santoni, Molloy and Rabilloud, Membrane proteins and proteomics: un amour\nimpossible? Electrophoresis 2000, 21, 1054-1070] as a pivotal paper, the\ncurrent paper analyzes how the field of membrane proteomics exacerbated the\ntrend in proteomics, i.e. developing alternate methods to the historical\ntwo-dimensional electrophoresis, and thus putting more and more pressure on the\nmass spectrometry side. However, in the case of membrane proteins, the\nincentive in doing so is due to the poor solubility of membrane proteins. This\nreview also shows that in some situations, where this solubility problem is\nless acute, two-dimensional electrophoresis remains a method of choice. Last\nbut not least, this review also critically examines the alternate approaches\nthat have been used for the proteomic analysis of membrane proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.2281v1"
    },
    {
        "title": "From secretome analysis to immunology: chitosan induces major\n  alterations in the activation of dendritic cells via a TLR4-dependent\n  mechanism",
        "authors": [
            "Christian Villiers",
            "Mireille Chevallet",
            "Hélène Diemer",
            "Rachel Couderc",
            "Heidi Freitas",
            "Alain Van Dorsselaer",
            "Patrice N Marche",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Dendritic cells are known to be activated by a wide range of microbial\nproducts, leading to cytokine production and increased levels of membrane\nmarkers such as major histocompatibility complex class II molecules. Such\nactivated dendritic cells possess the capacity to activate na\\\"ive T cells. In\nthe present study we demonstrated that immature dendritic cells secrete both\nthe YM1 lectin and lipocalin-2. By testing the ligands of these two proteins,\nchitosan and siderophores, respectively, we also demonstrated that chitosan, a\ndegradation product of various fungal and protozoal cell walls, induces an\nactivation of dendritic cells at the membrane level, as shown by the\nup-regulation of membrane proteins such as class II molecules, CD80 and CD86\nvia a TLR4-dependent mechanism, but is not able to induce cytokine production.\nThis led to the production of activated dendritic cells unable to stimulate T\ncells. However, costimulation with other microbial products overcame this\npartial activation and restored the capacity of these activated dendritic cells\nto stimulate T cells. In addition, successive stimulation with chitosan and\nthen by lipopolysaccharide induced a dose-dependent change in the cytokinic\nIL-12/IL-10 balance produced by the dendritic cells.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.2872v1"
    },
    {
        "title": "Autoregressive Modeling of Coding Sequence Lengths in Bacterial Genome",
        "authors": [
            "Vasile V. Morariu",
            "Luiza Buimaga-Iarinca"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Previous investigation of coding sequence lengths (CDS) in the bacterial\ncircular chromosome revealed short range correlation in the series of these\ndata. We have further analyzed the averaged periodograms of these series and we\nfound that the organization of CDS can be well described by first order\nautoregressive processes. This involves interaction between the neighboring\nterms. The autoregressive analysis may have great potential in modeling various\nphysical and biological processes like light emission of galaxies, protein\norganization, cell flickering, cognitive processes and perhaps others.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.1159v1"
    },
    {
        "title": "Compressed Genotyping",
        "authors": [
            "Yaniv Erlich",
            "Assaf Gordon",
            "Michael Brand",
            "Gregory J. Hannon",
            "Partha P. Mitra"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Significant volumes of knowledge have been accumulated in recent years\nlinking subtle genetic variations to a wide variety of medical disorders from\nCystic Fibrosis to mental retardation. Nevertheless, there are still great\nchallenges in applying this knowledge routinely in the clinic, largely due to\nthe relatively tedious and expensive process of DNA sequencing. Since the\ngenetic polymorphisms that underlie these disorders are relatively rare in the\nhuman population, the presence or absence of a disease-linked polymorphism can\nbe thought of as a sparse signal. Using methods and ideas from compressed\nsensing and group testing, we have developed a cost-effective genotyping\nprotocol. In particular, we have adapted our scheme to a recently developed\nclass of high throughput DNA sequencing technologies, and assembled a\nmathematical framework that has some important distinctions from 'traditional'\ncompressed sensing ideas in order to address different biological and technical\nconstraints.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.3691v1"
    },
    {
        "title": "Power and limitations of electrophoretic separations in proteomics\n  strategies",
        "authors": [
            "Thierry Rabilloud",
            "Ali R Vaezzadeh",
            "Noelle Potier",
            "Cécile Lelong",
            "Emmanuelle Leize-Wagner",
            "Mireille Chevallet"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Proteomics can be defined as the large-scale analysis of proteins. Due to the\ncomplexity of biological systems, it is required to concatenate various\nseparation techniques prior to mass spectrometry. These techniques, dealing\nwith proteins or peptides, can rely on chromatography or electrophoresis. In\nthis review, the electrophoretic techniques are under scrutiny. Their\nprinciples are recalled, and their applications for peptide and protein\nseparations are presented and critically discussed. In addition, the features\nthat are specific to gel electrophoresis and that interplay with mass\nspectrometry (i.e., protein detection after electrophoresis, and the process\nleading from a gel piece to a solution of peptides) are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.4158v1"
    },
    {
        "title": "Identification of possible differences in coding and non-coding\n  fragments of DNA sequences by using the method of the Recurrence\n  Quantification Analysis",
        "authors": [
            "Sergio Conte",
            "Alessandro Giuliani"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Starting with the results of Li et al. in 1992 there is valuable interest in\nfinding long range correlations in dna sequences since it raises questions\nabout the role of introns and intron-containing genes. In the present paper we\nstudied two sequences. We applied the method of the recurrence quantification\nanalysis (rqa) that was introduced by Zbilut and Webber in 1994. The\nsignificant result that we have here is that both Lmax and Laminarity exhibit\nvery large values in non coding respect to coding sequences. Therefore we\nsuggest that there the claimed higher long range correlations of introns\nrespect to exons from many authors may be explained here in reason of such\nfound higher values of Lmax and of Laminarity.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.3516v1"
    },
    {
        "title": "Age, Sex, and Genetic Architecture of Human Gene Expression in EBV\n  Transformed Cell Lines",
        "authors": [
            "Manuel A. Rivas",
            "Mark J. Daly",
            "Itsik Pe'er"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Individual expression profiles from EBV transformed cell lines are an\nemerging resource for genomic investigation. In this study we characterize the\neffects of age, sex, and genetic variation on gene expression by surveying\npublic datasets of such profiles. We establish that the expression space of\ncell lines maintains genetic as well as non-germline information, in an\nindividual-specific and cross-tissue manner. Age of donor is associated with\nthe expression of 949 genes in the derived cell line. Age-associated genes\ninclude over-representation of immune-related genes, specifically MHC Class I\ngenes, a phenomenon that replicates across tissues and organisms. Sex\nassociated genes in these cell lines include likely candidates, such as genes\nthat escape X-inactivation,testis specific expressed genes, androgen and\nestrogen specific genes, but also gene families previously unknown to be sex\nassociated such as common microRNA targets (MIR-490, V_ARP1_01, MIR-489).\nFinally, we report 494 transcripts whose expression levels are associated with\na genetic variant in cis, overlapping and validating previous reports.\nIncorporating age in analysis of association facilitates additional discovery\nof trans-acting regulatory genetic variants. Our findings promote expression\nprofiling of transformed cell lines as a vehicle for understanding cellular\nsystems beyond the specific lines.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0215v1"
    },
    {
        "title": "Silver-staining of proteins in polyacrylamide gels: a general overview",
        "authors": [
            "Thierry Rabilloud",
            "L. Vuillard",
            "C. Gilly",
            "J. J. Lawrence"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  On the basis of the physico-chemical principles underlying silver-staining of\nproteins, which are recalled in this paper, several methods of silver-staining\nof proteins after SDS electrophoresis in polyacrylamide gels or isoelectric\nfocusing were tested. The most valuable protocols are presented in this report,\nincluding standard methods for unsupported gels and new methods devised for\nthin (0.5 mm) supported gels for SDS electrophoresis or isoelectric focusing\nand for staining of small peptides. Generally speaking, the most rapid methods\nwere found to be less sensitive and less reproducible than more time-consuming\nones. Among the long methods, those using silver-diammine complex gave the most\nuniform sensitivity. They require however special home-made gels and cannot be\napplied to several electrophoretic systems (e.g. systems using tricine or\nbicine as the trailing ion, or isoelectric focusing in immobilized pH\ngradients). For these reasons, protocols based on silver nitrate are of a more\ngeneral use and might be favored. Future trends for silver-staining will also\nbe discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.4458v1"
    },
    {
        "title": "Information-theoretic View of Sequence Organization in a Genome",
        "authors": [
            "Liaofu Luo",
            "Yang Gao",
            "Jun Lu"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Sequence organizations are viewed from two points: one is from informational\nredundancy or informational correlation (IC) and another is from k-mer\nfrequency statistics. Two problems are investigated. The first is how the ICs\nexceed the fluctuation bound and the order emerges from fluctuation in a genome\nwhen the sequence length attains some critical value. We demonstrated that the\ntransition from fluctuation to order takes place at about sequence length\n200-300 thousands bases for human and E coli genome. It means that the life\nemerges from a region between macroscopic and microscopic. The second is about\nthe statistical law of the k-mer organization in a genome under the\nevolutionary pressure and functional selection. We deduced a sum rule Q(k,N) on\nthe k-mer frequency deviations from the randomness in a N-long sequence of\ngenome and deduced the relations of Q(k,N) with k and N. We found that Q(k,N)\nincreases with length N at a constant rate for most genome sequences and\ndemonstrated that when the functional selection of k-mers is accumulated to\nsome critical value the ordering takes place. An important finding is the sum\nrule correlated with the evolutionary complexity of the genome.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3843v1"
    },
    {
        "title": "Shape-based peak identification for ChIP-Seq",
        "authors": [
            "Valerie Hower",
            "Steven N. Evans",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  We present a new algorithm for the identification of bound regions from\nChIP-seq experiments. Our method for identifying statistically significant\npeaks from read coverage is inspired by the notion of persistence in\ntopological data analysis and provides a non-parametric approach that is robust\nto noise in experiments. Specifically, our method reduces the peak calling\nproblem to the study of tree-based statistics derived from the data. We\ndemonstrate the accuracy of our method on existing datasets, and we show that\nit can discover previously missed regions and can more clearly discriminate\nbetween multiple binding events. The software T-PIC (Tree shape Peak\nIdentification for ChIP-Seq) is available at\nhttp://math.berkeley.edu/~vhower/tpic.html\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0793v1"
    },
    {
        "title": "Variations on a theme: Changes to electrophoretic separations that can\n  make a difference",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Electrophoretic separations of proteins are widely used in proteomic\nanalyses, and rely heavily on SDS electrophoresis. This mode of separation is\nalmost exclusively used when a single dimension separation is performed, and\ngenerally represents the second dimension of two-dimensional separations.\nElectrophoretic separations for proteomics use robust, well-established\nprotocols. However, many variations in almost all possible parameters have been\ndescribed in the literature over the years, and they may bring a decisive\nadvantage when the limits of the classical protocols are reached. The purpose\nof this article is to review the most important of these variations, so that\nthe readers can be aware of how they can improve or tune protein separations\naccording to their needs. The chemical variations reviewed in this paper\nencompass gel structure, buffer systems and detergents for SDS electrophoresis,\ntwo-dimensional electrophoresis based on isoelectric focusing and\ntwo-dimensional electrophoresis based on cationic zone electrophoresis.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0899v1"
    },
    {
        "title": "PIntron: a Fast Method for Gene Structure Prediction via Maximal\n  Pairings of a Pattern and a Text",
        "authors": [
            "Paola Bonizzoni",
            "Gianluca Della Vedova",
            "Yuri Pirola",
            "Raffaella Rizzi"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Current computational methods for exon-intron structure prediction from a\ncluster of transcript (EST, mRNA) data do not exhibit the time and space\nefficiency necessary to process large clusters of over than 20,000 ESTs and\ngenes longer than 1Mb. Guaranteeing both accuracy and efficiency seems to be a\ncomputational goal quite far to be achieved, since accuracy is strictly related\nto exploiting the inherent redundancy of information present in a large\ncluster. We propose a fast method for the problem that combines two ideas: a\nnovel algorithm of proved small time complexity for computing spliced\nalignments of a transcript against a genome, and an efficient algorithm that\nexploits the inherent redundancy of information in a cluster of transcripts to\nselect, among all possible factorizations of EST sequences, those allowing to\ninfer splice site junctions that are highly confirmed by the input data. The\nEST alignment procedure is based on the construction of maximal embeddings that\nare sequences obtained from paths of a graph structure, called Embedding Graph,\nwhose vertices are the maximal pairings of a genomic sequence T and an EST P.\nThe procedure runs in time linear in the size of P, T and of the output.\nPIntron, the software tool implementing our methodology, is able to process in\na few seconds some critical genes that are not manageable by other gene\nstructure prediction tools. At the same time, PIntron exhibits high accuracy\n(sensitivity and specificity) when compared with ENCODE data. Detailed\nexperimental data, additional results and PIntron software are available at\nhttp://www.algolab.eu/PIntron.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.1514v1"
    },
    {
        "title": "The role of transposable elements in the evolution of non-mammalian\n  vertebrates and invertebrates",
        "authors": [
            "Noa Sela",
            "Eddo Kim",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Background: Transposable elements (TEs) have played an important role in the\ndiversification and enrichment of mammalian transcriptomes through various\nmechanisms such as exonization and intronization (the birth of new\nexons/introns from previously intronic/exonic sequences, respectively), and\ninsertion into first and last exons. However, no extensive analysis has\ncompared the effects of TEs on the transcriptomes of mammalian, non-mammalian\nvertebrates and invertebrates. Results: We analyzed the influence of TEs on the\ntranscriptomes of five species, three invertebrates and two non-mammalian\nvertebrates. Compared to previously analyzed mammals, there were lower levels\nof TE introduction into introns, significantly lower numbers of exonizations\noriginating from TEs and a lower percentage of TE insertion within the first\nand last exons. Although the transcriptomes of vertebrates exhibit a\nsignificant level of exonizations of TEs, only anecdotal cases were found in\ninvertebrates. In vertebrates, as in mammals, the exonized TEs are mostly\nalternatively spliced, indicating selective pressure maintains the original\nmRNA product generated from such genes. Conclusions: Exonization of TEs is\nwide-spread in mammals, less so in non- mammalian vertebrates, and very low in\ninvertebrates. We assume that the exonization process depends on the length of\nintrons. Vertebrates, unlike invertebrates, are characterized by long introns\nand short internal exons. Our results suggest that there is a direct link\nbetween the length of introns and exonization of TEs and that this process\nbecame more prevalent following the appearance of mammals.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.3171v1"
    },
    {
        "title": "Characteristics of transposable element exonization within human and\n  mouse",
        "authors": [
            "Noa Sela",
            "Britta Mersch",
            "Agnes Hotz-Wagenblatt",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Insertion of transposed elements within mammalian genes is thought to be an\nimportant contributor to mammalian evolution and speciation. Insertion of\ntransposed elements into introns can lead to their activation as alternatively\nspliced cassette exons, an event called exonization. Elucidation of the\nevolutionary constraints that have shaped fixation of transposed elements\nwithin human and mouse protein coding genes and subsequent exonization is\nimportant for understanding of how the exonization process has affected\ntranscriptome and proteome complexities. Here we show that exonization of\ntransposed elements is biased towards the beginning of the coding sequence in\nboth human and mouse genes. Analysis of single nucleotide polymorphisms (SNPs)\nrevealed that exonization of transposed elements can be population-specific,\nimplying that exonizations may enhance divergence and lead to speciation. SNP\ndensity analysis revealed differences between Alu and other transposed\nelements. Finally, we identified cases of primate-specific Alu elements that\ndepend on RNA editing for their exonization. These results shed light on TE\nfixation and the exonization process within human and mouse genes.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.3172v1"
    },
    {
        "title": "Is a gene-centric human proteome project the best way for proteomics to\n  serve biology?",
        "authors": [
            "Thierry Rabilloud",
            "Denis Hochstrasser",
            "Richard J Simpson"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  With the recent developments in proteomic technologies, a complete human\nproteome project (HPP) appears feasible for the first time. However, there is\nstill debate as to how it should be designed and what it should encompass. In\n\"proteomics speak\", the debate revolves around the central question as to\nwhether a gene-centric or a protein-centric proteomics approach is the most\nappropriate way forward. In this paper, we try to shed light on what these\ndefinitions mean, how large-scale proteomics such as a HPP can insert into the\nlarger omics chorus, and what we can reasonably expect from a HPP in the way it\nhas been proposed so far.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.5378v1"
    },
    {
        "title": "Two-dimensional gel electrophoresis in proteomics: past, present and\n  future",
        "authors": [
            "Thierry Rabilloud",
            "Mireille Chevallet",
            "Sylvie Luche",
            "Cécile Lelong"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Two-dimensional gel electrophoresis has been instrumental in the birth and\ndevelopments of proteomics, although it is no longer the exclusive separation\ntool used in the field of proteomics. In this review, a historical perspective\nis made, starting from the days where two-dimensional gels were used and the\nword proteomics did not even exist. The events that have led to the birth of\nproteomics are also recalled, ending with a description of the now well-known\nlimitations of two-dimensional gels in proteomics. However, the\noften-underestimated advantages of two-dimensional gels are also underlined,\nleading to a description of how and when to use two-dimensional gels for the\nbest in a proteomics approach. Taking support of these advantages (robustness,\nresolution, and ability to separate entire, intact proteins), possible future\napplications of this technique in proteomics are also mentioned.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.2591v1"
    },
    {
        "title": "Sequence alignment, mutual information, and dissimilarity measures for\n  constructing phylogenies",
        "authors": [
            "Orion Penner",
            "Peter Grassberger",
            "Maya Paczuski"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Existing sequence alignment algorithms use heuristic scoring schemes which\ncannot be used as objective distance metrics. Therefore one relies on measures\nlike the p- or log-det distances, or makes explicit, and often simplistic,\nassumptions about sequence evolution. Information theory provides an\nalternative, in the form of mutual information (MI) which is, in principle, an\nobjective and model independent similarity measure. MI can be estimated by\nconcatenating and zipping sequences, yielding thereby the \"normalized\ncompression distance\". So far this has produced promising results, but with\nuncontrolled errors. We describe a simple approach to get robust estimates of\nMI from global pairwise alignments. Using standard alignment algorithms, this\ngives for animal mitochondrial DNA estimates that are strikingly close to\nestimates obtained from the alignment free methods mentioned above. Our main\nresult uses algorithmic (Kolmogorov) information theory, but we show that\nsimilar results can also be obtained from Shannon theory. Due to the fact that\nit is not additive, normalized compression distance is not an optimal metric\nfor phylogenetics, but we propose a simple modification that overcomes the\nissue of additivity. We test several versions of our MI based distance measures\non a large number of randomly chosen quartets and demonstrate that they all\nperform better than traditional measures like the Kimura or log-det (resp.\nparalinear) distances. Even a simplified version based on single letter Shannon\nentropies, which can be easily incorporated in existing software packages, gave\nsuperior results throughout the entire animal kingdom. But we see the main\nvirtue of our approach in a more general way. For example, it can also help to\njudge the relative merits of different alignment algorithms, by estimating the\nsignificance of specific alignments.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.3358v1"
    },
    {
        "title": "Identification of 11 potential malaria vaccine candidates using\n  Bioinformatics",
        "authors": [
            "Raul Isea"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  In this paper, we suggested eleven protein targets to be used as possible\nvaccines against Plasmodium falciparum causative agent of almost two to three\nmillion deaths per year. A comprehensive analysis of protein target have been\nselected from the small experimental fragment of antigen in the P. falciparum\ngenome, all of them common to the four stages of the parasite life cycle (i.e.,\nsporozoites, merozoites, trophozoites and gametocytes). The potential vaccine\ncandidates should be analyzed in silico technique using various bioinformatics\ntools. Finally, the possible protein target according to PlasmoDB gene ID are\nPFC0975c, PFE0660c, PF08_0071, PF10_0084, PFI0180w, MAL13P1.56, PF14_0192,\nPF13_0141, PF14_0425, PF13_0322, y PF14_0598.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.5956v1"
    },
    {
        "title": "Classification of Saccharomyces cerevisiae promoter regions into\n  distinct chromatin classes reveals the existence of nucleosome-depleted\n  hotspots of transcription factor occupancy",
        "authors": [
            "Junbai Wang",
            "Lucas D. Ward",
            "Harmen J. Bussemaker"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Transcription factors (TF) play an essential role in the cell as locus- and\ncondition-specific recruiters of transcriptional machinery or\nchromatin-modifying complexes. However, predicting the in vivo profile of TF\noccupancy along the genome, which depends on complex interactions with other\nchromatin-associated proteins, from the DNA sequence remains a major challenge.\nThrough careful reanalysis of ChIP-chip data for 138 TFs obtained in rich\nmedia, we were able to classify the upstream promoter regions of S. cerevisiae\ninto 15 distinct chromatin types. One of these encompasses 5% of all promoters\nand is unique in that it is highly occupied by (essentially) all TFs expressed\nin rich media. These \"hotspots\" of TF occupancy are strongly\nnucleosome-depleted and preferentially targeted by chromatin-remodeling\ncomplexes and the origin-of-replication complex (ORC). They are also the only\nchromatin type enriched for predicted Rap1p and Pdr1p binding sites, which we\nfound to work cooperatively with AAA/TTT motifs, known to affect local DNA\nstructure, to reduce nucleosome occupancy. Taken together, our results reveal\nand characterize a new type of local chromatin structure in yeast.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.0713v2"
    },
    {
        "title": "Stochastic modeling of gene activation and application to cell\n  regulation",
        "authors": [
            "Godefroy Malherbe",
            "David Holcman"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Transcription factors (TFs) are key regulators of gene expression. Based on\nthe classical scenario in which the TF search process switches between\none-dimensional motion along the DNA molecule and free Brownian motion in the\nnucleus, we study the arrival time of several TFs to multiple binding sites and\nderive, in the presence of competitive binding ligands, the probability that\nseveral target sites are bound. We then apply our results to the hunchback\nregulation by bicoid in the fly embryo and we propose a general mechanism that\nallows cells to read a morphogenetic gradient and specialize according to their\nposition in the embryo.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.3001v1"
    },
    {
        "title": "Mapping Dynamic Histone Acetylation Patterns to Gene Expression in\n  Nanog-depleted Murine Embryonic Stem Cells",
        "authors": [
            "Florian Markowetz",
            "Klaas W Mulder",
            "Edoardo M Airoldi",
            "Ihor R Lemischka",
            "Olga G Troyanskaya"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Embryonic stem cells (ESC) have the potential to self-renew indefinitely and\nto differentiate into any of the three germ layers. The molecular mechanisms\nfor self-renewal, maintenance of pluripotency and lineage specification are\npoorly understood, but recent results point to a key role for epigenetic\nmechanisms. In this study, we focus on quantifying the impact of histone 3\nacetylation (H3K9,14ac) on gene expression in murine embryonic stem cells. We\nanalyze genome-wide histone acetylation patterns and gene expression profiles\nmeasured over the first five days of cell differentiation triggered by\nsilencing Nanog, a key transcription factor in ESC regulation. We explore the\ntemporal and spatial dynamics of histone acetylation data and its correlation\nwith gene expression using supervised and unsupervised statistical models. On a\ngenome-wide scale, changes in acetylation are significantly correlated to\nchanges in mRNA expression and, surprisingly, this coherence increases over\ntime. We quantify the predictive power of histone acetylation for gene\nexpression changes in a balanced cross-validation procedure. In an in-depth\nstudy we focus on genes central to the regulatory network of Mouse ESC,\nincluding those identified in a recent genome-wide RNAi screen and in the\nPluriNet, a computationally derived stem cell signature. We find that compared\nto the rest of the genome, ESC-specific genes show significantly more\nacetylation signal and a much stronger decrease in acetylation over time, which\nis often not reflected in an concordant expression change. These results shed\nlight on the complexity of the relationship between histone acetylation and\ngene expression and are a step forward to dissect the multilayer regulatory\nmechanisms that determine stem cell fate.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.3268v1"
    },
    {
        "title": "Large Tandem, Higher Order Repeats and Regularly Dispersed Repeat Units\n  Contribute Substantially to Divergence Between Human and Chimpanzee Y\n  Chromosomes",
        "authors": [
            "Vladimir Paar",
            "Matko Glunčić",
            "Ivan Basar",
            "Marija Rosandić",
            "Petar Paar",
            "Mislav Cvitković"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Comparison of human and chimpanzee genomes has received much attention,\nbecause of paramount role for understanding evolutionary step distinguishing us\nfrom our closest living relative. In order to contribute to insight into Y\nchromosome evolutionary history, we study and compare tandems, higher order\nrepeats (HORs), and regularly dispersed repeats in human and chimpanzee Y\nchromosome contigs, using robust Global Repeat Map algorithm. We find a new\ntype of long-range acceleration, human-accelerated HOR regions. In peripheral\ndomains of 35mer human alphoid HORs, we find riddled features with ten\nadditional repeat monomers. In chimpanzee, we identify 30mer alphoid HOR. We\nconstruct alphoid HOR schemes showing significant human-chimpanzee difference,\nrevealing rapid evolution after human-chimpanzee separation. We identify and\nanalyze over 20 large repeat units, most of them reported here for the first\ntime as: chimpanzee and human ~1.6 kb 3mer secondary repeat unit (SRU) and\n~23.5 kb tertiary repeat unit (~0.55 kb primary repeat unit, PRU); human 10848,\n15775, 20309, 60910, and 72140 bp PRUs; human 3mer SRU (~2.4 kb PRU); 715mer\nand 1123mer SRUs (5mer PRU); chimpanzee 5096, 10762, 10853, 60523 bp PRUs; and\nchimpanzee 64624 bp SRU (10853 bp PRU). We show that substantial\nhuman-chimpanzee differences are concentrated in large repeat structures, at\nthe level of as much as ~70% divergence, sizably exceeding previous numerical\nestimates for some selected noncoding sequences. Smeared over the whole\nsequenced assembly (25 Mb) this gives ~14% human--chimpanzee divergence. This\nis significantly higher estimate of divergence between human and chimpanzee\nthan previous estimates.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.4093v2"
    },
    {
        "title": "Towards a theoretical understanding of false positives in DNA motif\n  finding",
        "authors": [
            "Amin Zia",
            "Alan M. Moses"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Detection of false-positive motifs is one of the main causes of low\nperformance in motif finding methods. It is generally assumed that\nfalse-positives are mostly due to algorithmic weakness of motif-finders. Here,\nhowever, we derive the theoretical dependence of false positives on dataset\nsize and find that false positives can arise as a result of large dataset size,\nirrespective of the algorithm used. Interestingly, the false-positive strength\ndepends more on the number of sequences in the dataset than it does on the\nsequence length. As expected, false-positives can be reduced by decreasing the\nsequence length or by adding more sequences to the dataset. The dependence on\nnumber of sequences, however, diminishes and reaches a plateau after which\nadding more sequences to the dataset does not reduce the false-positive rate\nsignificantly. Based on the theoretical results presented here, we provide a\nnumber of intuitive rules of thumb that may be used to enhance motif-finding\nresults in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5011v1"
    },
    {
        "title": "Is the unfoldome widespread in proteomes?",
        "authors": [
            "Antonio Deiana",
            "Andrea Giansanti"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The term unfoldome has been recently used to indicate the universe of\nintrinsically disordered proteins. These proteins are characterized by an\nensemble of high-flexible interchangeable conformations and therefore they can\ninteract with many targets without requiring pre-existing stereo-chemical\ncomplementarity. It has been suggested that intrinsically disordered proteins\nare frequent in proteomes and disorder is widespread also in structured\nproteins. However, several studies raise some doubt about these views. It this\npaper we estimate the frequency of intrinsically disordered proteins in several\nliving organisms by using the ratio S between the likelihood, for a protein\nsequence, of being composed mainly by order-promoting or disorder-promoting\nresidues. We scan several proteomes from Archaea, Bacteria and Eukarya. We find\nthe following figures: 1.63% for Archaea, 3.91% for Bacteria, 16.35% for\nEukarya. The frequencies we found can be considered an upper bound to the real\nfrequency of intrinsically disordered proteins in proteomes. Our estimates are\nlower than those previously reported in several studies. A scanning of proteins\nin the Protein Data Bank (PDB) searching for segments of non-observed residues\nreveals that segments of non-observed residues longer than 30 amino acids, are\nrare. Our observations support the idea that the spread of the unfoldome has\nbeen often overestimated. If we exclude some exceptions, the structure-function\nparadigm is generally valid and pre-existing stereo-chemical complementarity\namong structures remains an important requisite for interactions between\nbiological macromolecules.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5909v1"
    },
    {
        "title": "Amino acid composition and thermal stability of protein structures: the\n  free energy geography of the Protein Data Bank",
        "authors": [
            "Antonio Deiana",
            "Kana Shimizu",
            "Andrea Giansanti"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  We study the combined influence of amino acid composition and chain length on\nthe thermal stability of protein structures. A new parameterization of the\ninternal free energy is considered, as the sum of hydrophobic effect,\nhydrogen-bond and de-hydration energy terms. We divided a non-redundant\nselection of protein structures from the Protein Data Bank into three groups:\ni) rich in order-promoting residues (OPR proteins); ii) rich in\ndisorder-promoting residues (DPR proteins); iii) belonging to a twilight zone\n(TZ proteins). We observe a partition of PDB in several groups with different\ninternal free energies, amino acid compositions and protein lengths. Internal\nfree energy of 96% of the proteins analyzed ranges from -2 to -6.5 kJ/mol/res.\nWe found many DPR and OPR proteins with the same relative thermal stability.\nOnly OPR proteins with internal energy between -4 and -6.5 kJ/mol/res are\nobserved to have chains longer than 200 residues, with a high de-hydration\nenergy compensated by the hydrophobic effect. DPR and TZ proteins are shorter\nthan 200 residues and they have an internal energy above -4 kJ/mol/res, with a\nfew exceptions among TZ proteins. Hydrogen-bonds play an important role in the\nstabilization of these DPR folds, often higher than contact energy. The new\nparameterization of internal free energy let emerge a geography of thermal\nstabilities of PDB structures. Amino acid composition per se is not sufficient\nto determine the stability of protein folds, since. DPR and TZ proteins\ngenerally have a relatively high internal free energy, and they are stabilized\nby hydrogen-bonds. Long DPR proteins are not observed in the PDB, because their\nlow hydrophobicity cannot compensate the high de-hydration energy necessary to\naccommodate residues within a highly packed globular fold.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5916v2"
    },
    {
        "title": "Relationships among the nucleotide content of human genome sequence,\n  gene structure, and gene expression features (PhD synopsis)",
        "authors": [
            "Diana Duplij"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The Dissertation is focused on the studies of associations between functional\nelements in human genome and their nucleotide structure. The asymmetry in\nnucleotide content (skew, bias) was chosen as the main feature for nucleotide\nstructure. A significant difference in nucleotide content asymmetry was found\nfor human exons vs. introns. Specifically, exon sequences display bias for\npurines (i.e., excess of A and G over C and T), while introns exhibit\nketo-amino skew (i.e. excess of G and T over A and C). The extents of these\nbiases depend upon gene expression patterns. The highest intronic keto-amino\nskew is found in the introns of housekeeping genes. In the case of introns,\nwhose sequences are under weak repair system, the AT->GC and CG->TA\nsubstitutions are preferentially accumulated. A comparative analysis of gene\nsequences encoding cytochrome P450 2E1 of Homo sapiens and representative\nmammals was done. The cladistic tree on the basis of coding sequences\nsimilarity of the gene Cyp2e1 was constructed. A new programming tools of NCBI\ndatabase sequence mining and analysis was developed, resulting in construction\nof a own database.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.0100v1"
    },
    {
        "title": "The Genomic HyperBrowser: inferential genomics at the sequence level",
        "authors": [
            "Geir K. Sandve",
            "Sveinung Gundersen",
            "Halfdan Rydbeck",
            "Ingrid K. Glad",
            "Lars Holden",
            "Marit Holden",
            "Knut Liestøl",
            "Trevor Clancy",
            "Egil Ferkingstad",
            "Morten Johansen",
            "Vegard Nygaard",
            "Eivind Tøstesen",
            "Arnoldo Frigessi",
            "Eivind Hovig"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  The immense increase in the generation of genomic scale data poses an unmet\nanalytical challenge, due to a lack of established methodology with the\nrequired flexibility and power. We propose a first principled approach to\nstatistical analysis of sequence-level genomic information. We provide a\ngrowing collection of generic biological investigations that query pairwise\nrelations between tracks, represented as mathematical objects, along the\ngenome. The Genomic HyperBrowser implements the approach and is available at\nhttp://hyperbrowser.uio.no.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.4898v1"
    },
    {
        "title": "Beyond the consensus: dissecting within-host viral population diversity\n  of foot-and-mouth disease virus using next-generation genome sequencing",
        "authors": [
            "Marco J. Morelli",
            "Caroline F. Wright",
            "Gaël Thébaud",
            "Nick J. Knowles",
            "Pawel Herzyk",
            "David J. Paton",
            "Daniel T. Haydon",
            "Donald P. King"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  The sequence diversity of viral populations within individual hosts is the\nstarting material for selection and subsequent evolution of RNA viruses such as\nfoot-and-mouth disease virus (FMDV). Using next-generation sequencing (NGS)\nperformed on a Genome Analyzer platform (Illumina), this study compared the\nviral populations within two bovine epithelial samples (foot lesions) from a\nsingle animal with the Inoculum used to initiate experimental infection.\nGenomic sequences were determined in duplicate sequencing runs, and the\nconsensus sequence determined by NGS, for the Inoculum, was identical to that\npreviously determined using the Sanger method. However, NGS reveals the fine\npolymorphic sub-structure of the viral population, from nucleotide variants\npresent at just below 50% frequency to those present at fractions of 1%. Some\nof the higher frequency polymorphisms identified encoded changes within codons\nassociated with heparan sulphate binding and were present in both feet lesions\nrevealing intermediate stages in the evolution of a tissue-culture adapted\nvirus replicating within a mammalian host. We identified 2,622, 1,434 and 1,703\npolymorphisms in the Inoculum, and in the two foot lesions respectively: most\nof the substitutions occurred only in a small fraction of the population and\nrepresent the progeny from recent cellular replication prior to onset of any\nselective pressures. We estimated an upper limit for the genome-wide mutation\nrate of the virus within a cell to be 7.8 x 10-4 per nt. The greater depth of\ndetection, achieved by NGS, demonstrates that this method is a powerful and\nvaluable tool for the dissection of FMDV populations within-hosts.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.5371v1"
    },
    {
        "title": "Improvements and simplifications in in-gel fluorescent detection of\n  proteins using ruthenium II tris-(bathophenanthroline disulfonate): the poor\n  man's fluorescent detection method",
        "authors": [
            "Catherine Aude-Garcia",
            "Véronique Collin-Faure",
            "Sylvie Luche",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Fluorescent detection of proteins is a popular method of detection allying\nsensitivity, linearity and compatibility with mass spectrometry. Among the\nnumerous methods described in the literature, staining with ruthenium II\ntris(bathophenanthroline disulfonate) is particularly cost-effective, but\nslightly cumbersome owing to difficulties in the preparation of the complex and\ncomplexity of staining protocols. We describe here the modifications on both\naspects that allow to perform a higher contrast staining and offer a more\nrobust method of complex preparation, thereby maximizing the advantages of the\nmethod.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.2632v1"
    },
    {
        "title": "Low-pass Genomewide Sequencing and Variant Imputation Using\n  Identity-by-descent in an Isolated Human Population",
        "authors": [
            "A Gusev",
            "MJ Shah",
            "EE Kenny",
            "A Ramachandran",
            "JK Lowe",
            "J Salit",
            "CC Lee",
            "EC Levandowsky",
            "TN Weaver",
            "QC Doan",
            "HE Peckham",
            "SF McLaughlin",
            "MR Lyons",
            "VN Sheth",
            "M Stoffel",
            "FM De La Vega",
            "JM Friedman",
            "JL Breslow",
            "I Pe'er"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Whole-genome sequencing in an isolated population with few founders directly\nascertains variants from the population bottleneck that may be rare elsewhere.\nIn such populations, shared haplotypes allow imputation of variants in\nunsequenced samples without resorting to statistical methods, as in studies of\noutbred cohorts. We focus on an isolated population cohort from the Pacific\nIsland of Kosrae, Micronesia, where we previously collected SNP array and rich\nphenotype data for the majority of the population. We report identification of\nlong regions with haplotypes co-inherited between pairs of individuals and\nmethodology to leverage such shared genetic content for imputation. Our\nestimates show that sequencing as few as 40 personal genomes allows for\nimputation in up to 60% of the 3,000-person cohort at the average locus. We\nascertained a pilot data-set of whole-genome sequences from seven Kosraean\nindividuals, with average 5X coverage. This dataset identified 5,735,306 unique\nsites of which 1,212,831 were previously unknown. Additionally, these Kosraen\nvariants are unusually enriched for alleles that are rare in other populations\nwhen compared to geographic neighbors. We were able to use the presence of\nshared haplotypes between the seven individuals to estimate imputation accuracy\nof known and novel variants and achieved levels of 99.6% and 97.3%,\nrespectively. This study presents the first whole-genome analysis of a\nhomogenous isolate population with emphasis on rare variant inference.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.3720v1"
    },
    {
        "title": "dMotifGreedy: a novel tool for de novo discovery of DNA motifs with\n  enhanced power of reporting distinct motifs",
        "authors": [
            "Yupeng Wang",
            "Xinyu Liu",
            "Michael Kelley",
            "Romdhane Rekaya"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  De novo discovery of over-represented DNA motifs is one of the major\nchallenges in computational biology. Although numerous tools have been\navailable for de novo motif discovery, many of these tools are subject to local\noptima phenomena, which may hinder detection of multiple distinct motifs. A\ngreedy algorithm based tool named dMotifGreedy was developed. dMotifGreedy\nbegins by searching for candidate motifs from pair-wise local alignments of\ninput sequences and then computes an optimal global solution for each candidate\nmotif through a greedy algorithm. dMotifGreedy has competitive performance in\ndetecting a true motif and greatly enhanced performance in detecting multiple\ndistinct true motifs. dMotifGreedy is freely available via a stand-alone\nprogram at http://lambchop.ads.uga.edu/dmotifgreedy/download.php.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.4015v1"
    },
    {
        "title": "Matrix eQTL: Ultra fast eQTL analysis via large matrix operations",
        "authors": [
            "Andrey A. Shabalin"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Expression quantitative trait loci (eQTL) mapping aims to determine genomic\nregions that regulate gene transcription. Expression QTL is used to study the\nregulatory structure of normal tissues and to search for genetic factors in\ncomplex diseases such as cancer, diabetes, and cystic fibrosis. A modern eQTL\ndataset contains millions of SNPs and thousands of transcripts measured for\nhundreds of samples. This makes the analysis computationally complex as it\ninvolves independent testing for association for every transcript-SNP pair. The\nheavy computational burden makes eQTL analysis less popular, often forces\nanalysts to restrict their attention to just a subset of transcripts and SNPs.\nAs larger genotype and gene expression datasets become available, the demand\nfor fast tools for eQTL analysis increases. We present a new method for fast\neQTL analysis via linear models, called Matrix eQTL. Matrix eQTL can model and\ntest for association using both linear regression and ANOVA models. The models\ncan include covariates to account for such factors as population structure,\ngender, and clinical variables. It also supports testing of heteroscedastic\nmodels and models with correlated errors. In our experiment on large datasets\nMatrix eQTL was thousands of times faster than the existing popular software\nfor QTL/eQTL analysis. Matrix eQTL is implemented as both Matlab and R packages\nand thus can easily be run on Windows, Mac OS, and Linux systems. The software\nis freely available at the following address:\nhttp://www.bios.unc.edu/research/genomic_software/Matrix_eQTL\n",
        "pdf_link": "http://arxiv.org/pdf/1105.5764v1"
    },
    {
        "title": "More Mouldy Data: Another mycoplasma gene jumps the silicon barrier into\n  the human genome",
        "authors": [
            "W. B. Langdon",
            "M. J. Arno"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  The human genome sequence database contains DNA sequences very like those of\nmycoplasma molds. It appears such moulds infect not only molecular Biology\nlaboratories but were picked up by experimenters from contaminated samples and\ninserted into GenBank as if they were human. At least one mouldy EST (Expressed\nSequence Tag) has transferred from public databases to commercial tools\n(Affymetrix HG-U133 plus 2.0 microarrays). We report a second example\n(DA466599) and suggest there is a need to clean up genomic databases but fear\ncurrent tools will be inadequate to catch genes which have jumped the silicon\nbarrier.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.4192v1"
    },
    {
        "title": "Effects of nanoparticles on murine macrophages",
        "authors": [
            "Mireille Chevallet",
            "Catherine Aude-Garcia",
            "Cécile Lelong",
            "Serge M. Candéias",
            "Sylvie Luche",
            "Véronique Collin-Faure",
            "Sarah Triboulet",
            "Dévy Diallo",
            "Hélène Diemer",
            "Alain van Dorsselaer",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Metallic nanoparticles are more and more widely used in an increasing number\nof applications. Consequently, they are more and more present in the\nenvironment, and the risk that they may represent for human health must be\nevaluated. This requires to increase our knowledge of the cellular responses to\nnanoparticles. In this context, macrophages appear as an attractive system.\nThey play a major role in eliminating foreign matter, e.g. pathogens or\ninfectious agents, by phagocytosis and inflammatory responses, and are thus\nhighly likely to react to nanoparticles. We have decided to study their\nresponses to nanoparticles by a combination of classical and wide-scope\napproaches such as proteomics. The long term goal of this study is the better\nunderstanding of the responses of macrophages to nanoparticles, and thus to\nhelp to assess their possible impact on human health. We chose as a model\nsystem bone marrow-derived macrophages and studied the effect of commonly used\nnanoparticles such as TiO2 and Cu. Classical responses of macrophage were\ncharacterized and proteomic approaches based on 2D gels of whole cell extracts\nwere used. Preliminary proteomic data resulting from whole cell extracts showed\ndifferent effects for TiO2-NPs and Cu-NPs. Modifications of the expression of\nseveral proteins involved in different pathways such as, for example, signal\ntransduction, endosome-lysosome pathway, Krebs cycle, oxidative stress response\nhave been underscored. These first results validate our proteomics approach and\nopen a new wide field of investigation for NPs impact on macrophages\n",
        "pdf_link": "http://arxiv.org/pdf/1107.1577v1"
    },
    {
        "title": "Non-alignment comparison of human and high primate genomes",
        "authors": [
            "V. M. Kirzhner",
            "S. Frenkel",
            "A. B. Korol"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Compositional spectra (CS) analysis based on k-mer scoring of DNA sequences\nwas employed in this study for dot-plot comparison of human and primate\ngenomes. The detection of extended conserved synteny regions was based on\ncontinuous fuzzy similarity rather than on chains of discrete anchors (genes or\nhighly conserved noncoding elements). In addition to the high correspondence\nfound in the comparisons of whole-genome sequences, a good similarity was also\nfound after masking gene sequences, indicating that CS analysis manages to\nreveal phylogenetic signal in the organization of noncoding part of the genome\nsequences, including repetitive DNA and the genome \"dark matter\". Obviously,\nthe possibility to reveal parallel ordering depends on the signal of common\nancestor sequence organization varying locally along the corresponding segments\nof the compared genomes. We explored two sources contributing to this signal:\nsequence composition (GC content) and sequence organization (abundances of\nk-mers in the usual A,T,G,C or purine-pyrimidine alphabets). Whole-genome\ncomparisons based on GC distribution along the analyzed sequences indeed gives\nreasonable results, but combining it with k-mer abundances dramatically\nimproves the ordering quality, indicating that compositional and organizational\nheterogeneity comprise complementary sources of information on evolutionary\nconserved similarity of genome sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6172v1"
    },
    {
        "title": "RNASEQR - A streamlined and accurate RNA-seq sequence analysis program",
        "authors": [
            "Abner C. -Y. Huang",
            "Leslie Y Chen",
            "Kuo-Chen Wei",
            "Kai Wang",
            "Chiung-Yin Huang",
            "Danielle Yi",
            "Chuan Yi Tang",
            "David J. Galas",
            "Leroy E. Hood"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  The paper has been withdrawn by the authors.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.3544v2"
    },
    {
        "title": "Scaling metagenome sequence assembly with probabilistic de Bruijn graphs",
        "authors": [
            "Jason Pell",
            "Arend Hintze",
            "Rosangela Canino-Koning",
            "Adina Howe",
            "James M. Tiedje",
            "C. Titus Brown"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Deep sequencing has enabled the investigation of a wide range of\nenvironmental microbial ecosystems, but the high memory requirements for {\\em\nde novo} assembly of short-read shotgun sequencing data from these complex\npopulations are an increasingly large practical barrier. Here we introduce a\nmemory-efficient graph representation with which we can analyze the k-mer\nconnectivity of metagenomic samples. The graph representation is based on a\nprobabilistic data structure, a Bloom filter, that allows us to efficiently\nstore assembly graphs in as little as 4 bits per k-mer, albeit inexactly. We\nshow that this data structure accurately represents DNA assembly graphs in low\nmemory. We apply this data structure to the problem of partitioning assembly\ngraphs into components as a prelude to assembly, and show that this reduces the\noverall memory requirements for {\\em de novo} assembly of metagenomes. On one\nsoil metagenome assembly, this approach achieves a nearly 40-fold decrease in\nthe maximum memory requirements for assembly. This probabilistic graph\nrepresentation is a significant theoretical advance in storing assembly graphs\nand also yields immediate leverage on metagenomic assembly.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.4193v3"
    },
    {
        "title": "Bayesian hierarchical reconstruction of protein profiles including a\n  digestion model",
        "authors": [
            "Pierre Grangeat",
            "Pascal Szacherski",
            "Laurent Gerfault",
            "Jean-François Giovannelli"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Introduction : Mass spectrometry approaches are very attractive to detect\nprotein panels in a sensitive and high speed way. MS can be coupled to many\nproteomic separation techniques. However, controlling technological variability\non these analytical chains is a critical point. Adequate information processing\nis mandatory for data analysis to take into account the complexity of the\nanalysed mixture, to improve the measurement reliability and to make the\ntechnology user friendly. Therefore we develop a hierarchical parametric\nprobabilistic model of the LC-MS analytical chain including the technological\nvariability. We introduce a Bayesian reconstruction methodology to recover the\nprotein biomarkers content in a robust way. We will focus on the digestion step\nsince it brings a major contribution to technological variability. Method : In\nthis communication, we introduce a hierarchical model of the LC-MS analytical\nchain. Such a chain is a cascade of molecular events depicted by a graph\nstructure, each node being associated to a molecular state such as protein,\npeptide and ion and each branch to a molecular processing such as digestion,\nionisation and LC-MS separation. This molecular graph defines a hierarchical\nmixture model. We extend the Bayesian statistical framework we have introduced\npreviously [1] to this hierarchical description. As an example, we will\nconsider the digestion step. We describe the digestion process on a pair of\npeptides within the targeted protein as a Bernoulli random process associated\nwith a cleavage probability controlled by the digestion kinetic law.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.4868v1"
    },
    {
        "title": "In Silico Genome-Genome Hybridization Values Accurately and Precisely\n  Predict Empirical DNA-DNA Hybridization Values for Classifying Prokaryotes",
        "authors": [
            "Paul A. Muller Jr.",
            "Slava S. Epstein"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  For nearly 50 years microbiologists have been determining prokaryotic genome\nrelatedness by means of nucleic acid reassociation kinetics. These methods,\nhowever, are technically challenging, difficult to reproduce, and - given the\ntime and resources it takes to generate a single data-point - not cost\neffective. In the post genomic era, with the cost of sequencing whole\nprokaryotic genomes no longer a limiting factor, we believed that\ncomputationally predicting the output value from a traditional DNA-DNA\nhybridization experiment using pair-wise comparisons of whole genome sequences\nto be of value. While other computational whole-genome classification methods\nexist, they predict values on widely different scales than DNA-DNA\nhybridization, introducing yet another metric into the polyphasic approach of\ndefining microbial species. Our goal was to develop an in silico BLAST based\npipeline that would predict with a high level of certainty the value of the wet\nlab-based DNA-DNA hybridization values. Here we report on one such method that\nproduces estimates that are both accurate and precise with respect to the\nDNA-DNA hybridization values they are designed to emulate.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.5211v1"
    },
    {
        "title": "Evaluation of the Genome Mixture Contents by Means of the Compositional\n  Spectra Method",
        "authors": [
            "Valery Kirzhner",
            "Zeev Volkovich"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  In this research, we consider a mixture of genome fragments of a certain\nbacteria set. The problem of mixture separation is studied under the assumption\nthat all the genomes present in the mixture are completely sequenced or are\nclose to those already sequenced. Such assumption is relevant, e.g., in regular\nobservations of ecological or biomedical objects, where the possible set of\nmicroorganisms is known and it is only necessary to follow their\nconcentrations.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2178v1"
    },
    {
        "title": "GC3 Biology in Eukaryotes and Prokaryotes",
        "authors": [
            "Eran Elhaik",
            "Tatiana Tatarinova"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  We describe the distribution of Guanine and Cytosine (GC) content in the\nthird codon position (GC3) distributions in different species, analyze\nevolutionary trends and discuss differences between genes and organisms with\ndistinct GC3 levels. We scrutinize previously published theoretical frameworks\nand construct a unified view of GC3 biology in eukaryotes and prokaryotes.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3929v1"
    },
    {
        "title": "A Reference-Free Algorithm for Computational Normalization of Shotgun\n  Sequencing Data",
        "authors": [
            "C. Titus Brown",
            "Adina Howe",
            "Qingpeng Zhang",
            "Alexis B. Pyrkosz",
            "Timothy H. Brom"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Deep shotgun sequencing and analysis of genomes, transcriptomes, amplified\nsingle-cell genomes, and metagenomes has enabled investigation of a wide range\nof organisms and ecosystems. However, sampling variation in short-read data\nsets and high sequencing error rates of modern sequencers present many new\ncomputational challenges in data interpretation. These challenges have led to\nthe development of new classes of mapping tools and {\\em de novo} assemblers.\nThese algorithms are challenged by the continued improvement in sequencing\nthroughput. We here describe digital normalization, a single-pass computational\nalgorithm that systematizes coverage in shotgun sequencing data sets, thereby\ndecreasing sampling variation, discarding redundant data, and removing the\nmajority of errors. Digital normalization substantially reduces the size of\nshotgun data sets and decreases the memory and time requirements for {\\em de\nnovo} sequence assembly, all without significantly impacting content of the\ngenerated contigs. We apply digital normalization to the assembly of microbial\ngenomic data, amplified single-cell genomic data, and transcriptomic data. Our\nimplementation is freely available for use and modification.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.4802v2"
    },
    {
        "title": "Exploring single-sample SNP and INDEL calling with whole-genome de novo\n  assembly",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Motivation: Eugene Myers in his string graph paper (Myers, 2005) suggested\nthat in a string graph or equivalently a unitig graph, any path spells a valid\nassembly. As a string/unitig graph also encodes every valid assembly of reads,\nsuch a graph, provided that it can be constructed correctly, is in fact a\nlossless representation of reads. In principle, every analysis based on\nwhole-genome shotgun sequencing (WGS) data, such as SNP and insertion/deletion\n(INDEL) calling, can also be achieved with unitigs.\n  Results: To explore the feasibility of using de novo assembly in the context\nof resequencing, we developed a de novo assembler, fermi, that assembles\nIllumina short reads into unitigs while preserving most of information of the\ninput reads. SNPs and INDELs can be called by mapping the unitigs against a\nreference genome. By applying the method on 35-fold human resequencing data, we\nshowed that in comparison to the standard pipeline, our approach yields similar\naccuracy for SNP calling and better results for INDEL calling. It has higher\nsensitivity than other de novo assembly based methods for variant calling. Our\nwork suggests that variant calling with de novo assembly be a beneficial\ncomplement to the standard variant calling pipeline for whole-genome\nresequencing. In the methodological aspects, we proposed FMD-index for\nforward-backward extension of DNA sequences, a fast algorithm for finding all\nsuper-maximal exact matches and one-pass construction of unitigs from an\nFMD-index.\n  Availability: http://github.com/lh3/fermi\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6364v2"
    },
    {
        "title": "A statistical framework for SNP calling, mutation discovery, association\n  mapping and population genetical parameter estimation from sequencing data",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Motivation: Most existing methods for DNA sequence analysis rely on accurate\nsequences or genotypes. However, in applications of the next-generation\nsequencing (NGS), accurate genotypes may not be easily obtained (e.g.\nmulti-sample low-coverage sequencing or somatic mutation discovery). These\napplications press for the development of new methods for analyzing sequence\ndata with uncertainty.\n  Results: We present a statistical framework for calling SNPs, discovering\nsomatic mutations, inferring population genetical parameters and performing\nassociation tests directly based on sequencing data without explicit genotyping\nor linkage-based imputation. On real data, we demonstrate that our method\nachieves comparable accuracy to alternative methods for estimating site allele\ncount, for inferring allele frequency spectrum and for association mapping. We\nalso highlight the necessity of using symmetric datasets for finding somatic\nmutations and confirm that for discovering rare events, mismapping is\nfrequently the leading source of errors.\n  Availability: http://samtools.sourceforge.net.\n  Contact: hengli@broadinstitute.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6372v3"
    },
    {
        "title": "Phenomenon of irreducible genetic markers for TATAAA motifs in human\n  chromosome 1",
        "authors": [
            "Sergey V. Chesnokov",
            "Lina G. Chesnokov",
            "Viktor Wixler"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  It is well known that the general transcription factors (GTF) specifically\nrecognize correct TATA boxes, distinguishing them from many others. Employing\nthe principles of determinacy analysis (mathematical theory of rules) we\nanalyzed a fragment of human chromosome 1 DNA sequence and identified specific\ngenetic markers (IG-markers = Irreducible Genetic markers) in the nearest\nproximity to TATAAA motifs. The IG-markers enable determining the exact\nlocation of any TATAAA motif within the investigated DNA fragment. Based on our\ndata we hypothesize that the GTF recognize the\n{\\guillemotleft}true{\\guillemotright} transcriptional start TATA box by means\nof IG-markers. The math method described here is universal and can be used to\nfind IG-markers that will provide, like a global navigation satellite system,\nfor the specific location of any distinct sequence motif within larger DNA\nsequence content.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6465v1"
    },
    {
        "title": "The Whereabouts of 2D Gels in Quantitative Proteomics",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Two-dimensional gel electrophoresis has been instrumental in the development\nof proteomics. Although it is no longer the exclusive scheme used for\nproteomics, its unique features make it a still highly valuable tool,\nespecially when multiple quantitative comparisons of samples must be made, and\neven for large samples series. However, quantitative proteomics using 2D gels\nis critically dependent on the performances of the protein detection methods\nused after the electrophoretic separations. This chapter therefore examines\ncritically the various detection methods (radioactivity, dyes, fluorescence,\nand silver) as well as the data analysis issues that must be taken into account\nwhen quantitative comparative analysis of 2D gels is performed.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.3003v1"
    },
    {
        "title": "Silver Staining of 2D Electrophoresis Gels",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Silver staining is used to detect proteins after electrophoretic separation\non polyacrylamide gels. It -combines excellent sensitivity (in the low nanogram\nrange) with the use of very simple and cheap equipment and chemicals. For its\nuse in proteomics, two important additional features must be considered,\ncompatibility with mass spectrometry and quantitative response. Both features\nare discussed in this chapter, and optimized silver staining protocols are\nproposed.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.3004v1"
    },
    {
        "title": "About the mechanism of interference of silver staining with peptide mass\n  spectrometry",
        "authors": [
            "Sophie Richert",
            "Sylvie Luche",
            "Mireille Chevallet",
            "Alain Van Dorsselaer",
            "Emmanuelle Leize-Wagner",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The mechanism by which silver staining of proteins in polyacrylamide gels\ninterferes with mass spectrometry of peptides produced by proteolysis has been\ninvestigated. It was demonstrated that this interference increases with time\nbetween silver staining and gel processing, although the silver image is\nconstant. This suggested an important role of the formaldehyde used in silver\nstaining development in this interference process. Consequently, a\nformaldehyde-free staining protocol has been devised, using carbohydrazide as\nthe developing agent. This protocol showed much increased peptide coverage and\nretained the sensitivity of silver staining. These results were however\nobtained at the expense of an increased background in the stained gels and of a\nreduced staining homogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.1957v1"
    },
    {
        "title": "Hidden breakpoints in genome alignments",
        "authors": [
            "Birte Kehr",
            "Knut Reinert",
            "Aaron E. Darling"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  During the course of evolution, an organism's genome can undergo changes that\naffect the large-scale structure of the genome. These changes include gene\ngain, loss, duplication, chromosome fusion, fission, and rearrangement. When\ngene gain and loss occurs in addition to other types of rearrangement,\nbreakpoints of rearrangement can exist that are only detectable by comparison\nof three or more genomes. An arbitrarily large number of these \"hidden\"\nbreakpoints can exist among genomes that exhibit no rearrangements in pairwise\ncomparisons.\n  We present an extension of the multichromosomal breakpoint median problem to\ngenomes that have undergone gene gain and loss. We then demonstrate that the\nmedian distance among three genomes can be used to calculate a lower bound on\nthe number of hidden breakpoints present. We provide an implementation of this\ncalculation including the median distance, along with some practical\nimprovements on the time complexity of the underlying algorithm.\n  We apply our approach to measure the abundance of hidden breakpoints in\nsimulated data sets under a wide range of evolutionary scenarios. We\ndemonstrate that in simulations the hidden breakpoint counts depend strongly on\nrelative rates of inversion and gene gain/loss. Finally we apply current\nmultiple genome aligners to the simulated genomes, and show that all aligners\nintroduce a high degree of error in hidden breakpoint counts, and that this\nerror grows with evolutionary distance in the simulation. Our results suggest\nthat hidden breakpoint error may be pervasive in genome alignments.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.6964v1"
    },
    {
        "title": "Context-specific transcriptional regulatory network inference from\n  global gene expression maps using double two-way t-tests",
        "authors": [
            "Jianlong Qi",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Transcriptional regulatory network inference methods have been studied for\nyears. Most of them relie on complex mathematical and algorithmic concepts,\nmaking them hard to adapt, re-implement or integrate with other methods. To\naddress this problem, we introduce a novel method based on a minimal\nstatistical model for observing transcriptional regulatory interactions in\nnoisy expression data, which assumes that transcription factors (TFs) and their\ntargets are both differentially expressed in a gene-specific, critical sample\ncontrast, as measured by repeated two-way t-tests. This method is conceptually\nsimple and easy to implement and integrate in any statistical software\nenvironment. Benchmarking on standard E. coli and yeast reference datasets\nshowed that it performs equally well as the best existing methods. Analysis of\nthe predicted interactions suggested that it works best to infer\ncontext-specific TF-target interactions which only co-express locally. We\nconfirmed this hypothesis on a dataset of more than 1,000 normal human tissue\nsamples, where we found that our method predicts highly tissue-specific and\nfunctionally relevant interactions, whereas a global co-expression method only\nassociates general TFs to non-specific biological processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.0537v1"
    },
    {
        "title": "Finding the sources of missing heritability in a yeast cross",
        "authors": [
            "Joshua S. Bloom",
            "Ian M. Ehrenreich",
            "Wesley Loo",
            "Thúy-Lan Võ Lite",
            "Leonid Kruglyak"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  For many traits, including susceptibility to common diseases in humans,\ncausal loci uncovered by genetic mapping studies explain only a minority of the\nheritable contribution to trait variation. Multiple explanations for this\n\"missing heritability\" have been proposed. Here we use a large cross between\ntwo yeast strains to accurately estimate different sources of heritable\nvariation for 46 quantitative traits and to detect underlying loci with high\nstatistical power. We find that the detected loci explain nearly the entire\nadditive contribution to heritable variation for the traits studied. We also\nshow that the contribution to heritability of gene-gene interactions varies\namong traits, from near zero to 50%. Detected two-locus interactions explain\nonly a minority of this contribution. These results substantially advance our\nunderstanding of the missing heritability problem and have important\nimplications for future studies of complex and quantitative traits.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.2865v1"
    },
    {
        "title": "Binary Interval Search (BITS): A Scalable Algorithm for Counting\n  Interval Intersections",
        "authors": [
            "Ryan M. Layer",
            "Kevin Skadron",
            "Gabriel Robins",
            "Ira M. Hall",
            "Aaron R. Quinlan"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Motivation: The comparison of diverse genomic datasets is fundamental to\nunderstanding genome biology. Researchers must explore many large datasets of\ngenome intervals (e.g., genes, sequence alignments) to place their experimental\nresults in a broader context and to make new discoveries. Relationships between\ngenomic datasets are typically measured by identifying intervals that\nintersect: that is, they overlap and thus share a common genome interval. Given\nthe continued advances in DNA sequencing technologies, efficient methods for\nmeasuring statistically significant relationships between many sets of genomic\nfeatures is crucial for future discovery.\n  Results: We introduce the Binary Interval Search (BITS) algorithm, a novel\nand scalable approach to interval set intersection. We demonstrate that BITS\noutperforms existing methods at counting interval intersections. Moreover, we\nshow that BITS is intrinsically suited to parallel computing architectures such\nas Graphics Processing Units (GPUs) by illustrating its utility for efficient\nMonte-Carlo simulations measuring the significance of relationships between\nsets of genomic intervals.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.3407v2"
    },
    {
        "title": "Differential Expression Analysis for A Mouse p53KO Microarray Dataset",
        "authors": [
            "Wanting Xu"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Affymetrix GeneChip technology is used to detect gene expression levels in\nsamples of cells under different conditions. In this project, we analyzed the\ngene expression profiling data for mouse induced pluripotent stem cell (iPSCs)\n(Takahashi, 2006) on Affymetrix Mouse 430 2.0 GeneChip. Three biological\nconditions were present: p53KO, microRNA mir34aKO, and wild type, each with\nthree biological replicates. The first part was devoted to identifying\ndifferentially expressed genes from around 45,000 of them, and looking into\ntheir biological meanings by pathway analysis. The second part dealt with\nrepetitive elements represented in the pool of mRNAs. We identified repetitive\nelements that show a significant difference between two biological conditions.\nBoth the comparison of p53KO versus WT and mir34aKO versus WT were done.\nHowever, the emphasis was on the former. Laboratory validation with qPCR\nconfirmed our findings. This work was done under the Overseas Research\nFellowship (ORF) Scheme 2012 for Science Students by the Faculty of Science,\nThe University of Hong Kong. Many thanks are due to the University for the\nfellowship, and to Professors Terry Speed and Lin He and Drs Chao-po Lin and\nAnne Biton of the University of California at Berkeley for their supervision\nand generous support.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.4065v3"
    },
    {
        "title": "SSW Library: An SIMD Smith-Waterman C/C++ Library for Use in Genomic\n  Applications",
        "authors": [
            "Mengyao Zhao",
            "Wan-Ping Lee",
            "Erik Garrison",
            "Gabor T. Marth"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Summary: The Smith Waterman (SW) algorithm, which produces the optimal\npairwise alignment between two sequences, is frequently used as a key component\nof fast heuristic read mapping and variation detection tools, but current\nimplementations are either designed as monolithic protein database searching\ntools or are embedded into other tools. To facilitate easy integration of the\nfast Single Instruction Multiple Data (SIMD) SW algorithm into third party\nsoftware, we wrote a C/C++ library, which extends Farrars Striped SW (SSW) to\nreturn alignment information in addition to the optimal SW score. Availability:\nSSW is available both as a C/C++ software library, as well as a stand alone\nalignment tool wrapping the librarys functionality at\nhttps://github.com/mengyao/Complete- Striped-Smith-Waterman-Library Contact:\nmarth@bc.edu\n",
        "pdf_link": "http://arxiv.org/pdf/1208.6350v2"
    },
    {
        "title": "LUMPY: A probabilistic framework for structural variant discovery",
        "authors": [
            "Ryan M. Layer",
            "Ira M. Hall",
            "Aaron R. Quinlan"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Comprehensive discovery of structural variation (SV) in human genomes from\nDNA sequencing requires the integration of multiple alignment signals including\nread-pair, split-read and read-depth. However, owing to inherent technical\nchallenges, most existing SV discovery approaches utilize only one signal and\nconsequently suffer from reduced sensitivity, especially at low sequence\ncoverage and for smaller SVs. We present a novel and extremely flexible\nprobabilistic SV discovery framework that is capable of integrating any number\nof SV detection signals including those generated from read alignments or prior\nevidence. We demonstrate improved sensitivity over extant methods by combining\npaired-end and split-read alignments and emphasize the utility of our framework\nfor comprehensive studies of structural variation in heterogeneous tumor\ngenomes. We further discuss the broader utility of this approach for\nprobabilistic integration of diverse genomic interval datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2342v2"
    },
    {
        "title": "Integrative modeling of eQTLs and cis-regulatory elements suggest\n  mechanisms underlying cell type specificity of eQTLs",
        "authors": [
            "Christopher D Brown",
            "Lara M Mangravite",
            "Barbara E Engelhardt"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Genetic variants in cis-regulatory elements or trans-acting regulators\ncommonly influence the quantity and spatiotemporal distribution of gene\ntranscription. Recent interest in expression quantitative trait locus (eQTL)\nmapping has paralleled the adoption of genome-wide association studies (GWAS)\nfor the analysis of complex traits and disease in humans. Under the hypothesis\nthat many GWAS associations tag non-coding SNPs with small effects, and that\nthese SNPs exert phenotypic control by modifying gene expression, it has become\ncommon to interpret GWAS associations using eQTL data. To exploit the\nmechanistic interpretability of eQTL-GWAS comparisons, an improved\nunderstanding of the genetic architecture and cell type specificity of eQTLs is\nrequired. We address this need by performing an eQTL analysis in four parts:\nfirst we identified eQTLs from eleven studies on seven cell types; next we\nquantified cell type specific eQTLs across the studies; then we integrated eQTL\ndata with cis-regulatory element (CRE) data sets from the ENCODE project;\nfinally we built a classifier to predict cell type specific eQTLs. Consistent\nwith prior studies, we demonstrate that allelic heterogeneity is pervasive at\ncis-eQTLs and that cis-eQTLs are often cell type specific. Within and between\ncell type eQTL replication is associated with eQTL SNP overlap with hundreds of\ncell type specific CRE element classes, including enhancer, promoter, and\nrepressive chromatin marks, regions of open chromatin, and many classes of DNA\nbinding proteins. Using a random forest classifier including 526 CRE data sets\nas features, we successfully predict the cell type specificity of eQTL SNPs in\nthe absence of gene expression data from the cell type of interest. We\nanticipate that such integrative, predictive modeling will improve our ability\nto understand the mechanistic basis of human complex phenotypic variation.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.3294v1"
    },
    {
        "title": "Species Identification and Profiling of Complex Microbial Communities\n  Using Shotgun Illumina Sequencing of 16S rRNA Amplicon Sequences",
        "authors": [
            "Swee Hoe Ong",
            "Vinutha Uppoor Kukkillaya",
            "Andreas Wilm",
            "Christophe Lay",
            "Eliza Xin Pei Ho",
            "Louie Low",
            "Martin Lloyd Hibberd",
            "Niranjan Nagarajan"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The high throughput and cost-effectiveness afforded by short-read sequencing\ntechnologies, in principle, enable researchers to perform 16S rRNA profiling of\ncomplex microbial communities at unprecedented depth and resolution. Existing\nIllumina sequencing protocols are, however, limited by the fraction of the 16S\nrRNA gene that is interrogated and therefore limit the resolution and quality\nof the profiling. To address this, we present the design of a novel protocol\nfor shotgun Illumina sequencing of the bacterial 16S rRNA gene, optimized to\ncapture more than 90% of sequences in the Greengenes database and with nearly\ntwice the resolution of existing protocols. Using several in silico and\nexperimental datasets, we demonstrate that despite the presence of multiple\nvariable and conserved regions, the resulting shotgun sequences can be used to\naccurately quantify the diversity of complex microbial communities. The\nreconstruction of a significant fraction of the 16S rRNA gene also enabled high\nprecision (>90%) in species-level identification thereby opening up potential\napplication of this approach for clinical microbial characterization.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.3464v2"
    },
    {
        "title": "Structural attributes of nucleotide sequences in promoter regions of\n  supercoiling-sensitive genes: how to relate microarray expression data with\n  genomic sequences",
        "authors": [
            "Galina I. Kravatskaya",
            "Vladimir R. Chechetkin",
            "Yury V. Kravatsky",
            "Vladimir G. Tumanyan"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The level of supercoiling in the chromosome can affect gene expression. To\nclarify the basis of supercoiling sensitivity, we analyzed the structural\nfeatures of nucleotide sequences in the vicinity of promoters for the genes\nwith expression enhanced and decreased in response to loss of chromosomal\nsupercoiling in E. coli. Fourier analysis of promoter sequences for\nsupercoiling-sensitive genes reveals the tendency in selection of sequences\nwith helical periodicities close to 10 nt for relaxation-induced genes and to\n11 nt for relaxation-repressed genes. The helical periodicities in the subsets\nof promoters recognized by RNA polymerase with different sigma factors were\nalso studied. A special procedure was developed for study of correlations\nbetween the intensities of periodicities in promoter sequences and the\nexpression levels of corresponding genes. Significant correlations of\nexpression with the AT content and with AT periodicities about 10, 11, and 50\nnt indicate their role in regulation of supercoiling-sensitive genes.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4313v1"
    },
    {
        "title": "Improved proteomic analysis of nuclear proteins, as exemplified by the\n  comparison of two myeloïd cell lines nuclear proteomes",
        "authors": [
            "Cécile Lelong",
            "Mireille Chevallet",
            "Hélène Diemer",
            "Sylvie Luche",
            "Alain Van Dorsselaer",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  One of the challenges of the proteomic analysis by 2D-gel is to visualize the\nlow abundance proteins, particularly those localized in organelles. An\nadditional problem with nuclear proteins lies in their strong interaction with\nnuclear acids. Several experimental procedures have been tested to increase, in\nthe nuclear extract, the ratio of nuclear proteins compared to contaminant\nproteins, and also to obtain reproducible conditions compatible with 2D-gel\nelectrophoresis. The NaCl procedure has been chosen. To test the interest of\nthis procedure, the nuclear protein expression profiles of macrophages and\ndendritic cells have been compared with a proteomic approach by 2D-gel\nelectrophoresis. Delta 2D software and mass spectrometry analyses have allowed\npointing out some proteins of interest. We have chosen some of them, involved\nin transcriptional regulation and/or chromatin structure for further\nvalidations. The immunoblotting experiments have shown that most of observed\nchanges are due to post-translational modifications, thereby a exemplifying the\ninterest of the 2D gel approach. Finally, this approach allowed us to reach not\nonly high abundance nuclear proteins but also lower abundance proteins, such as\nthe HP1 proteins and reinforces the interest of using 2DE-gel in proteomics\nbecause of its ability to visualize intact proteins with their modifications.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4938v1"
    },
    {
        "title": "De novo genomic analyses for non-model organisms: an evaluation of\n  methods across a multi-species data set",
        "authors": [
            "Sonal Singhal"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  High-throughput sequencing (HTS) is revolutionizing biological research by\nenabling scientists to quickly and cheaply query variation at a genomic scale.\nDespite the increasing ease of obtaining such data, using these data\neffectively still poses notable challenges, especially for those working with\norganisms without a high-quality reference genome. For every stage of analysis\n- from assembly to annotation to variant discovery - researchers have to\ndistinguish technical artifacts from the biological realities of their data\nbefore they can make inference. In this work, I explore these challenges by\ngenerating a large de novo comparative transcriptomic dataset data for a clade\nof lizards and constructing a pipeline to analyze these data. Then, using a\ncombination of novel metrics and an externally validated variant data set, I\ntest the efficacy of my approach, identify areas of improvement, and propose\nways to minimize these errors. I find that with careful data curation, HTS can\nbe a powerful tool for generating genomic data for non-model organisms.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.1737v1"
    },
    {
        "title": "Genome and transcriptome studies of the protozoan parasites Trypanosoma\n  cruzi and Giardia intestinalis",
        "authors": [
            "Oscar Franzén"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Trypanosoma cruzi and Giardia intestinalis are two human pathogens and\nprotozoan parasites responsible for the diseases Chagas disease and giardiasis,\nrespectively. Both diseases cause suffering and illness in several million\nindividuals. The former disease occurs primarily in South America and Central\nAmerica, and the latter disease occurs worldwide. Current therapeutics are\ntoxic and lack efficacy, and potential vaccines are far from the market.\nIncreased knowledge about the biology of these parasites is essential for drug\nand vaccine development, and new diagnostic tests. In this thesis,\nhigh-throughput sequencing was applied together with extensive bioinformatic\nanalyses to yield insights into the biology and evolution of Trypanosoma cruzi\nand Giardia intestinalis. Bioinformatics analysis of DNA and RNA sequences was\nperformed to identify features that may be of importance for parasite biology\nand functional characterization. This thesis is based on five papers (i-v).\nPaper i and ii describe comparative genome studies of three distinct genotypes\nof Giardia intestinalis (A, B and E). Paper iii describes a genome comparison\nof the human infecting Trypanosoma cruzi with the bat-restricted subspecies\nTrypanosoma cruzi marinkellei. Paper iv describes the repertoire of small\nnon-coding RNAs in Trypanosoma cruzi epimastigotes. Paper v describes\ntranscriptome analysis using paired-end RNA-Seq of three distinct genotypes of\nGiardia intestinalis (A, B and E).\n",
        "pdf_link": "http://arxiv.org/pdf/1211.4210v1"
    },
    {
        "title": "Utilizing RNA-Seq Data for Cancer Network Inference",
        "authors": [
            "Ying Cai",
            "Bernard Fendler",
            "Gurinder S. Atwal"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  An important challenge in cancer systems biology is to uncover the complex\nnetwork of interactions between genes (tumor suppressor genes and oncogenes)\nimplicated in cancer. Next generation sequencing provides unparalleled ability\nto probe the expression levels of the entire set of cancer genes and their\ntranscript isoforms. However, there are onerous statistical and computational\nissues in interpreting high-dimensional sequencing data and inferring the\nunderlying genetic network. In this study, we analyzed RNA-Seq data from\nlymphoblastoid cell lines derived from a population of 69 human individuals and\nimplemented a probabilistic framework to construct biologically-relevant\ngenetic networks. In particular, we employed a graphical lasso analysis,\nmotivated by considerations of the maximum entropy formalism, to estimate the\nsparse inverse covariance matrix of RNA-Seq data. Gene ontology, pathway\nenrichment and protein-protein path length analysis were all carried out to\nvalidate the biological context of the predicted network of interacting cancer\ngene isoforms.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.4543v2"
    },
    {
        "title": "Illumina Sequencing Artifacts Revealed by Connectivity Analysis of\n  Metagenomic Datasets",
        "authors": [
            "Adina Chuang Howe",
            "Jason Pell",
            "Rosangela Canino-Koning",
            "Rachel Mackelprang",
            "Susannah Tringe",
            "Janet Jansson",
            "James M. Tiedje",
            "C. Titus Brown"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Sequencing errors and biases in metagenomic datasets affect coverage-based\nassemblies and are often ignored during analysis. Here, we analyze read\nconnectivity in metagenomes and identify the presence of problematic and likely\na-biological connectivity within metagenome assembly graphs. Specifically, we\nidentify highly connected sequences which join a large proportion of reads\nwithin each real metagenome. These sequences show position-specific bias in\nshotgun reads, suggestive of sequencing artifacts, and are only minimally\nincorporated into contigs by assembly. The removal of these sequences prior to\nassembly results in similar assembly content for most metagenomes and enables\nthe use of graph partitioning to decrease assembly memory and time\nrequirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0159v1"
    },
    {
        "title": "Biological Database of Images and Genomes: tools for community\n  annotations linking image and genomic information",
        "authors": [
            "Andrew T. Oberlin",
            "Dominika A. Jurkovic",
            "Mitchell F. Balish",
            "Iddo Friedberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Genomic data and biomedical imaging data are undergoing exponential growth.\nHowever, our understanding of the phenotype-genotype connection linking the two\ntypes of data is lagging behind. While there are many types of software that\nenable the manipulation and analysis of image data and genomic data as separate\nentities, there is no framework established for linking the two. We present a\ngeneric set of software tools, BioDIG, that allows linking of image data to\ngenomic data. BioDIG tools can be applied to a wide range of research problems\nthat require linking images to genomes. BioDIG features the following: rapid\nconstruction of web-based workbenches, community-based annotation, user\nmanagement, and web-services. By using BioDIG to create websites, researchers\nand curators can rapidly annotate large number of images with genomic\ninformation. Here we present the BioDIG software tools that include an image\nmodule, a genome module and a user management module. We also introduce a\nBioDIG-based website, MyDIG, which is being used to annotate images of\nMycoplasma.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0447v1"
    },
    {
        "title": "System Wide Analyses have Underestimated Protein Abundances and the\n  Importance of Transcription in Mammals",
        "authors": [
            "Jingyi Jessica Li",
            "Peter J. Bickel",
            "Mark D. Biggin"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Large scale surveys in mammalian tissue culture cells suggest that the\nprotein expressed at the median abundance is present at 8,000 - 16,000\nmolecules per cell and that differences in mRNA expression between genes\nexplain only 10-40% of the differences in protein levels. We find, however,\nthat these surveys have significantly underestimated protein abundances and the\nrelative importance of transcription. Using individual measurements for 61\nhousekeeping proteins to rescale whole proteome data from Schwanhausser et al.,\nwe find that the median protein detected is expressed at 170,000 molecules per\ncell and that our corrected protein abundance estimates show a higher\ncorrelation with mRNA abundances than do the uncorrected protein data. In\naddition, we estimated the impact of further errors in mRNA and protein\nabundances, showing that mRNA levels explain at least 56% of the differences in\nprotein abundance for the genes detected by Schwanhausser et al., though\nbecause one major source of error could not be estimated the true percent\ncontribution could be higher. We also employed a second, independent strategy\nto determine the contribution of mRNA levels to protein expression. We show\nthat the variance in translation rates directly measured by ribosome profiling\nis only 12% of that inferred by Schwanhausser et al. and that the measured and\ninferred translation rates correlate only poorly (R2=0.13). Based on this, our\nsecond strategy suggests that mRNA levels explain ~81% of the variance in\nprotein levels. We also determined the percent contributions of transcription,\nRNA degradation, translation and protein degradation to the variance in protein\nabundances using both of our strategies. While the magnitudes of the two\nestimates vary, they both suggest that transcription plays a more important\nrole than the earlier studies implied and translation a much smaller role.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0587v7"
    },
    {
        "title": "Assembling large, complex environmental metagenomes",
        "authors": [
            "Adina Chuang Howe",
            "Janet Jansson",
            "Stephanie A. Malfatti",
            "Susannah G. Tringe",
            "James M. Tiedje",
            "C. Titus Brown"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The large volumes of sequencing data required to sample complex environments\ndeeply pose new challenges to sequence analysis approaches. De novo metagenomic\nassembly effectively reduces the total amount of data to be analyzed but\nrequires significant computational resources. We apply two pre-assembly\nfiltering approaches, digital normalization and partitioning, to make large\nmetagenome assemblies more comput\\ ationaly tractable. Using a human gut mock\ncommunity dataset, we demonstrate that these methods result in assemblies\nnearly identical to assemblies from unprocessed data. We then assemble two\nlarge soil metagenomes from matched Iowa corn and native prairie soils. The\npredicted functional content and phylogenetic origin of the assembled contigs\nindicate significant taxonomic differences despite similar function. The\nassembly strategies presented are generic and can be extended to any\nmetagenome; full source code is freely available under a BSD license.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.2832v2"
    },
    {
        "title": "Zygotic combinatorial process in plants",
        "authors": [
            "Evgenii Vladimirovich Levites",
            "Svetlana Sergeevna Kirikovich"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Experimental data that prove the existence of the zygotic combinatorial\nprocess occurring in an embryogenesis-entering zygote are presented in the\npaper. The zygotic combinatorial process is found when analyzing F1 hybrid\nplants obtained from crossing homozygous forms different, minimum, in two\nmarker enzymes, and it is found in that hybrid plant which, with one marker\nenzyme heterozygous spectrum, has a homozygous spectrum of the other. The\nzygotic combinatorial process leads to F1 hybrids uniformity aberration. The\nzygotic combinatory process revealed in the study is supposed to be conditioned\nby chromosome polyteny in mother plant cells and diminution of chromatin excess\nfrom the embryogenesis-entering zygote. An obligatory condition for\ncombinatorial process is the presence of free exchange of cromatides among\nhomological chromosomes in an embryogenesis-entering cell, i.e. the presence of\ncrossing-over analogous to the one proceeding at meiosis. The found\ncombinatorial process and the earlier-obtained data confirm the hypothesis on\nmulti-dimensionality of inherited information coding. Differential polyteny of\ncertain chromosome regions can lead to differences among homozygous plants\nhaving the same alleles in genes located in polytenized regions and controlling\nmorpho-physiological traits.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.3120v1"
    },
    {
        "title": "A comparative analysis of transcription factor expression during\n  metazoan embryonic development",
        "authors": [
            "Alicia Schep",
            "Boris Adryan"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  During embryonic development, a complex organism is formed from a single\nstarting cell. These processes of growth and differentiation are driven by\nlarge transcriptional changes, which are following the expression and activity\nof transcription factors (TFs). This study sought to compare TF expression\nduring embryonic development in a diverse group of metazoan animals:\nrepresentatives of vertebrates (Danio rerio, Xenopus tropicalis), a chordate\n(Ciona intestinalis) and invertebrate phyla such as insects (Drosophila\nmelanogaster, Anopheles gambiae) and nematodes (Caenorhabditis elegans) were\nsampled, The different species showed overall very similar TF expression\npatterns, with TF expression increasing during the initial stages of\ndevelopment. C2H2 zinc finger TFs were over-represented and Homeobox TFs were\nunder-represented in the early stages in all species. We further clustered TFs\nfor each species based on their quantitative temporal expression profiles. This\nshowed very similar TF expression trends in development in vertebrate and\ninsect species. However, analysis of the expression of orthologous pairs\nbetween more closely related species showed that expression of most individual\nTFs is not conserved, following the general model of duplication and\ndiversification. The degree of similarity between TF expression between Xenopus\ntropicalis and Danio rerio followed the hourglass model, with the greatest\nsimilarity occuring during the early tailbud stage in Xenopus tropicalis and\nthe late segmentation stage in Danio rerio. However, for Drosophila\nmelanogaster and Anopheles gambiae there were two periods of high TF\ntranscriptome similarity, one during the Arthropod phylotypic stage at 8-10\nhours into Drosophila development and the other later at 16-18 hours into\nDrosophila development.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.1565v1"
    },
    {
        "title": "TrAp: a Tree Approach for Fingerprinting Subclonal Tumor Composition",
        "authors": [
            "Francesco Strino",
            "Fabio Parisi",
            "Mariann Micsinai",
            "Yuval Kluger"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Revealing the clonal composition of a single tumor is essential for\nidentifying cell subpopulations with metastatic potential in primary tumors or\nwith resistance to therapies in metastatic tumors. Sequencing technologies\nprovide an overview of an aggregate of numerous cells, rather than\nsubclonal-specific quantification of aberrations such as single nucleotide\nvariants (SNVs). Computational approaches to de-mix a single collective signal\nfrom the mixed cell population of a tumor sample into its individual components\nare currently not available. Herein we propose a framework for deconvolving\ndata from a single genome-wide experiment to infer the composition, abundance\nand evolutionary paths of the underlying cell subpopulations of a tumor. The\nmethod is based on the plausible biological assumption that tumor progression\nis an evolutionary process where each individual aberration event stems from a\nunique subclone and is present in all its descendants subclones. We have\ndeveloped an efficient algorithm (TrAp) for solving this mixture problem. In\nsilico analyses show that TrAp correctly deconvolves mixed subpopulations when\nthe number of subpopulations and the measurement errors are moderate. We\ndemonstrate the applicability of the method using tumor karyotypes and somatic\nhypermutation datasets. We applied TrAp to SNV frequency profile from Exome-Seq\nexperiment of a renal cell carcinoma tumor sample and compared the mutational\nprofile of the inferred subpopulations to the mutational profiles of twenty\nsingle cells of the same tumor. Despite the large experimental noise, specific\nco-occurring mutations found in clones inferred by TrAp are also present in\nsome of these single cells. Finally, we deconvolve Exome-Seq data from three\ndistinct metastases from different body compartments of one melanoma patient\nand exhibit the evolutionary relationships of their subpopulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.1966v1"
    },
    {
        "title": "Kerfuffle: a web tool for multi-species gene colocalization analysis",
        "authors": [
            "Robert Aboukhalil",
            "Bernard Fendler",
            "Gurinder S. Atwal"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The evolutionary pressures that underlie the large-scale functional\norganization of the genome are not well understood in eukaryotes. Recent\nevidence suggests that functionally similar genes may colocalize (cluster) in\nthe eukaryotic genome, suggesting the role of chromatin-level gene regulation\nin shaping the physical distribution of coordinated genes. However, few of the\nbioinformatic tools currently available allow for a systematic study of gene\ncolocalization across several, evolutionarily distant species. Kerfuffle is a\nweb tool designed to help discover, visualize, and quantify the physical\norganization of genomes by identifying significant gene colocalization and\nconservation across the assembled genomes of available species (currently up to\n47, from humans to worms). Kerfuffle only requires the user to specify a list\nof human genes and the names of other species of interest. Without further\ninput from the user, the software queries the e!Ensembl BioMart server to\nobtain positional information and discovers homology relations in all genes and\nspecies specified. Using this information, Kerfuffle performs a multi-species\nclustering analysis, presents downloadable lists of clustered genes, performs\nMonte Carlo statistical significance calculations, estimates how conserved gene\nclusters are across species, plots histograms and interactive graphs, allows\nusers to save their queries, and generates a downloadable visualization of the\nclusters using the Circos software. These analyses may be used to further\nexplore the functional roles of gene clusters by interrogating the enriched\nmolecular pathways associated with each cluster.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.3077v1"
    },
    {
        "title": "Which is faster: Bowtie2GP > Bowtie > Bowtie2 > BWA",
        "authors": [
            "W. B. Langdon"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We have recently used genetic programming to automatically generate an\nimproved version of Langmead's DNA read alignment tool Bowtie2 Sect.5.3\nRN/12/09. We find it runs more than four times faster than the Bioinformatics\nsequencing tool (BWA) currently used with short next generation paired end DNA\nsequences by the Cancer Institute, takes less memory and yet finds similar\nmatches in the human genome.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5187v1"
    },
    {
        "title": "Assemblathon 2: evaluating de novo methods of genome assembly in three\n  vertebrate species",
        "authors": [
            "Keith R. Bradnam",
            "Joseph N. Fass",
            "Anton Alexandrov",
            "Paul Baranay",
            "Michael Bechner",
            "İnanç Birol",
            "Sébastien Boisvert",
            "Jarrod A. Chapman",
            "Guillaume Chapuis",
            "Rayan Chikhi",
            "Hamidreza Chitsaz",
            "Wen-Chi Chou",
            "Jacques Corbeil",
            "Cristian Del Fabbro",
            "T. Roderick Docking",
            "Richard Durbin",
            "Dent Earl",
            "Scott Emrich",
            "Pavel Fedotov",
            "Nuno A. Fonseca",
            "Ganeshkumar Ganapathy",
            "Richard A. Gibbs",
            "Sante Gnerre",
            "Élénie Godzaridis",
            "Steve Goldstein",
            "Matthias Haimel",
            "Giles Hall",
            "David Haussler",
            "Joseph B. Hiatt",
            "Isaac Y. Ho",
            "Jason Howard",
            "Martin Hunt",
            "Shaun D. Jackman",
            "David B Jaffe",
            "Erich Jarvis",
            "Huaiyang Jiang",
            "Sergey Kazakov",
            "Paul J. Kersey",
            "Jacob O. Kitzman",
            "James R. Knight",
            "Sergey Koren",
            "Tak-Wah Lam",
            "Dominique Lavenier",
            "François Laviolette",
            "Yingrui Li",
            "Zhenyu Li",
            "Binghang Liu",
            "Yue Liu",
            "Ruibang Luo",
            "Iain MacCallum",
            "Matthew D MacManes",
            "Nicolas Maillet",
            "Sergey Melnikov",
            "Bruno Miguel Vieira",
            "Delphine Naquin",
            "Zemin Ning",
            "Thomas D. Otto",
            "Benedict Paten",
            "Octávio S. Paulo",
            "Adam M. Phillippy",
            "Francisco Pina-Martins",
            "Michael Place",
            "Dariusz Przybylski",
            "Xiang Qin",
            "Carson Qu",
            "Filipe J Ribeiro",
            "Stephen Richards",
            "Daniel S. Rokhsar",
            "J. Graham Ruby",
            "Simone Scalabrin",
            "Michael C. Schatz",
            "David C. Schwartz",
            "Alexey Sergushichev",
            "Ted Sharpe",
            "Timothy I. Shaw",
            "Jay Shendure",
            "Yujian Shi",
            "Jared T. Simpson",
            "Henry Song",
            "Fedor Tsarev",
            "Francesco Vezzi",
            "Riccardo Vicedomini",
            "Jun Wang",
            "Kim C. Worley",
            "Shuangye Yin",
            "Siu-Ming Yiu",
            "Jianying Yuan",
            "Guojie Zhang",
            "Hao Zhang",
            "Shiguo Zhou",
            "Ian F. Korf"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background - The process of generating raw genome sequence data continues to\nbecome cheaper, faster, and more accurate. However, assembly of such data into\nhigh-quality, finished genome sequences remains challenging. Many genome\nassembly tools are available, but they differ greatly in terms of their\nperformance (speed, scalability, hardware requirements, acceptance of newer\nread technologies) and in their final output (composition of assembled\nsequence). More importantly, it remains largely unclear how to best assess the\nquality of assembled genome sequences. The Assemblathon competitions are\nintended to assess current state-of-the-art methods in genome assembly. Results\n- In Assemblathon 2, we provided a variety of sequence data to be assembled for\nthree vertebrate species (a bird, a fish, and snake). This resulted in a total\nof 43 submitted assemblies from 21 participating teams. We evaluated these\nassemblies using a combination of optical map data, Fosmid sequences, and\nseveral statistical methods. From over 100 different metrics, we chose ten key\nmeasures by which to assess the overall quality of the assemblies. Conclusions\n- Many current genome assemblers produced useful assemblies, containing a\nsignificant representation of their genes, regulatory sequences, and overall\ngenome structure. However, the high degree of variability between the entries\nsuggests that there is still much room for improvement in the field of genome\nassembly and that approaches which work well in assembling the genome of one\nspecies may not necessarily work well for another.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5406v3"
    },
    {
        "title": "CG-content log-ratio distributions of Caenorhabditis elegans and\n  Drosophila melanogaster mirtrons",
        "authors": [
            "Denise Fagundes-Lima",
            "Gerald Weber"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Mirtrons are a special type of pre-miRNA which originate from intronic\nregions and are spliced directly from the transcript instead of being processed\nby Drosha. The splicing mechanism is better understood for the processing of\nmRNA for which was established that there is a characteristic CG content around\nsplice sites. Here we analyse the CG-content ratio of pre-miRNAs and mirtrons\nand compare them with their genomic neighbourhood in an attempt to establish\nkey properties which are easy to evaluate and to understand their biogenesis.\nWe propose a simple log-ratio of the CG-content comparing the precursor\nsequence and is flanking region. We discovered that Caenorhabditis elegans and\nDrosophila melanogaster mirtrons, so far without exception, have smaller\nCG-content than their genomic neighbourhood. This is markedly different from\nusual pre-miRNAs which mostly have larger CG-content when compared to their\ngenomic neighbourhood. We also analysed some mammalian and primate mirtrons\nwhich, in contrast the invertebrate mirtrons, have higher CG-content ratio.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.6099v1"
    },
    {
        "title": "Pattern Analysis of Tandem Repeats in Nlrp1",
        "authors": [
            "Sim-Hui Tee"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Pattern analysis of tandem repeats in gene is an indispensable computational\napproach to the understanding of the gene expression and pathogenesis of\ndiseases. This research applied a computational motif model and database\ntechniques to study the distribution of tandem repeats in Nlrp1 gene, which is\na critical gene to detect the invading pathogens in the immunologic mechanisms.\nThe frequency of tandem repeats in Nlrp1 gene was studied for mono-, di-, tri-,\nand tetranucleotides. Mutations of Nlrp1 gene were analyzed to identify the\ninsertion,deletion, and substitution of nucleotides. The results of this\nresearch provide a basis for future work in computational drug design and\nbiomedical engineering in tackling diseases associated with immune system.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.2041v1"
    },
    {
        "title": "In Silico Analysis of Tandem Repeats in GIF of Gastric Parietal Cells",
        "authors": [
            "Sim-Hui Tee"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Tandem repeats are ubiquitous in the genome of organisms and their mutated\nforms play a vital role in pathogenesis. In this study, tandem repeats in\nGastric Intrinsic Factor (GIF) of gastric parietal cells have been investigated\nusing an in silico approach. Six types of the nucleotide tandem repeat motifs\nhave been investigated, including mono-, di-, tri-, tetra-, penta- and\nhexanucleotide. The distribution of the repeat motifs in the gene was analyzed.\nThe results of this study provide an insight into the biomolecular mechanisms\nand pathogenesis implicated by the GIF of gastric parietal cells. Based on the\nfindings of the tandem repeats in GIF of gastric parietal cells, therapeutic\nstrategies and disease markers may be developed accordingly by the biomedical\nscientists.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.2047v1"
    },
    {
        "title": "Slow Evolution of rag1 and pomc Genes in Vertebrates with Large Genomes",
        "authors": [
            "Bianca Sclavi",
            "John Herrick"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Growing evidence suggests that many vertebrate lineages are evolving at\nsignificantly different rates. As a first approximation of evolutionary rates,\nwe assessed the amount of neutral (dS) and non-neutral (dN) substitutions that\nhave accumulated within and across sister clades since the time of their\ndivergence. We found that in fish, tetraodontiformes (pufferfish) are evolving\nat faster rates than cypriniformes (fresh water teleosts), while cypriniformes\nare evolving faster than elasmobranchs (sharks, skates and rays). A similar\nrate variation was observed in salamanders: plethodontidae were found to evolve\nat a rate nearly two fold faster than the hydromantes lineage. We discuss\npossible explanations for this striking variation in substitution rates among\ndifferent vertebrate lineages that occupy widely diverse habitats and niches.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.2182v1"
    },
    {
        "title": "Count-based differential expression analysis of RNA sequencing data\n  using R and Bioconductor",
        "authors": [
            "Simon Anders",
            "Davis J. McCarthy",
            "Yunshen Chen",
            "Michal Okoniewski",
            "Gordon K. Smyth",
            "Wolfgang Huber",
            "Mark D. Robinson"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  RNA sequencing (RNA-seq) has been rapidly adopted for the profiling of\ntranscriptomes in many areas of biology, including studies into gene\nregulation, development and disease. Of particular interest is the discovery of\ndifferentially expressed genes across different conditions (e.g., tissues,\nperturbations), while optionally adjusting for other systematic factors that\naffect the data collection process. There are a number of subtle yet critical\naspects of these analyses, such as read counting, appropriate treatment of\nbiological variability, quality control checks and appropriate setup of\nstatistical modeling. Several variations have been presented in the literature,\nand there is a need for guidance on current best practices. This protocol\npresents a \"state-of-the-art\" computational and statistical RNA-seq\ndifferential expression analysis workflow largely based on the free open-source\nR language and Bioconductor software and in particular, two widely-used tools\nDESeq and edgeR. Hands-on time for typical small experiments (e.g., 4-10\nsamples) can be <1 hour, with computation time <1 day using a standard desktop\nPC.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.3685v3"
    },
    {
        "title": "Virtual in situs: Sequencing mRNA from cryo-sliced Drosophila embryos to\n  determine genome-wide spatial patterns of gene expression",
        "authors": [
            "Peter A. Combs",
            "Michael B. Eisen"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Complex spatial and temporal patterns of gene expression underlie embryo\ndifferentiation, yet methods do not yet exist for the efficient genome-wide\ndetermination of spatial expression patterns during development. In situ\nimaging of transcripts and proteins is the gold-standard, but it is difficult\nand time consuming to apply to an entire genome, even when highly automated.\nSequencing, in contrast, is fast and genome-wide, but is generally applied to\nhomogenized tissues, thereby discarding spatial information. It is likely that\nthese methods will ultimately converge, and we will be able to sequence RNAs in\nsitu, simultaneously determining their identity and location. As a step along\nthis path, we developed methods to cryosection individual blastoderm stage\nDrosophila melanogaster embryos along the anterior-posterior axis and sequence\nthe mRNA isolated from each 25 micron slice. The spatial patterns of gene\nexpression we infer closely match patterns previously determined by in situ\nhybridization and microscopy. We applied this method to generate a genome-wide\ntimecourse of spatial gene expression from shortly after fertilization through\ngastrulation. We identify numerous genes with spatial patterns that have not\nyet been described in the several ongoing systematic in situ based projects.\nThis simple experiment demonstrates the potential for combining careful\nanatomical dissection with high-throughput sequencing to obtain spatially\nresolved gene expression on a genome-wide scale.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.4693v4"
    },
    {
        "title": "SOAP3-dp: Fast, Accurate and Sensitive GPU-based Short Read Aligner",
        "authors": [
            "Ruibang Luo",
            "Thomas Wong",
            "Jianqiao Zhu",
            "Chi-Man Liu",
            "Edward Wu",
            "Lap-Kei Lee",
            "Haoxiang Lin",
            "Wenjuan Zhu",
            "David W. Cheung",
            "Hing-Fung Ting",
            "Siu-Ming Yiu",
            "Chang Yu",
            "Yingrui Li",
            "Ruiqiang Li",
            "Tak-Wah Lam"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  To tackle the exponentially increasing throughput of Next-Generation\nSequencing (NGS), most of the existing short-read aligners can be configured to\nfavor speed in trade of accuracy and sensitivity. SOAP3-dp, through leveraging\nthe computational power of both CPU and GPU with optimized algorithms, delivers\nhigh speed and sensitivity simultaneously. Compared with widely adopted\naligners including BWA, Bowtie2, SeqAlto, GEM and GPU-based aligners including\nBarraCUDA and CUSHAW, SOAP3-dp is two to tens of times faster, while\nmaintaining the highest sensitivity and lowest false discovery rate (FDR) on\nIllumina reads with different lengths. Transcending its predecessor SOAP3,\nwhich does not allow gapped alignment, SOAP3-dp by default tolerates alignment\nsimilarity as low as 60 percent. Real data evaluation using human genome\ndemonstrates SOAP3-dp's power to enable more authentic variants and longer\nIndels to be discovered. Fosmid sequencing shows a 9.1 percent FDR on newly\ndiscovered deletions. SOAP3-dp natively supports BAM file format and provides a\nscoring scheme same as BWA, which enables it to be integrated into existing\nanalysis pipelines. SOAP3-dp has been deployed on Amazon-EC2, NIH-Biowulf and\nTianhe-1A.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.5507v2"
    },
    {
        "title": "Correlation Between GC-content and Palindromes in Randomly Generated\n  Sequences and Viral Genomes",
        "authors": [
            "Andrew Ninh"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  GC-content, the ratio of guanine and cytosine bases in an entire nucleotide\nsequence, and palindromic sequences are unique for every organism due to\ngenomic evolution. The goals of our research was to establish a correlation\nbetween GC-content and palindromic densities in wild-type viral and\nrandomly-generated genomes. Forty viral genomes were downloaded from GenBank\nand their GC-ratios and palindromic densities were calculated and plotted using\nMathematica. The palindromic densities-by-GC-ratios plot of randomly generated\nsequences (palindromic density curve) exhibited a quadratic relationship and\nwas superimposed over the viral genome plot. It was observed that the viral\nplots followed the curvature of the random sequences' quadratic curve,\nsignifying a directly proportional relationship between GC-content and\npalindrome density in viral genomes. However, because viral genomes require\ncertain non-palindromic sequences to function, the palindromic densities of\nmost wild-type genomes were under the palindromic density curve. The variance\nin palindrome densities of wild-type genomes in respect to the random\nsequences' quadratic curve may be examined to determine evolutionary traits in\ngenomes. A better understanding of viral palindromic densities and GC-ratios\nwould help in understanding conserved secondary RNA structures in viral genomes\nand future drug discovery. In addition, certain viral genomes were found to be\nviable recombinant viruses, which are used in gene therapy.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.5869v1"
    },
    {
        "title": "Utilizing Protein Structure to Identify Non-Random Somatic Mutations",
        "authors": [
            "Gregory Ryslik",
            "Yuwei Cheng",
            "Kei-Hoi Cheung",
            "Yorgo Modis",
            "Hongyu Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation: Human cancer is caused by the accumulation of somatic mutations\nin tumor suppressors and oncogenes within the genome. In the case of oncogenes,\nrecent theory suggests that there are only a few key \"driver\" mutations\nresponsible for tumorigenesis. As there have been significant pharmacological\nsuccesses in developing drugs that treat cancers that carry these driver\nmutations, several methods that rely on mutational clustering have been\ndeveloped to identify them. However, these methods consider proteins as a\nsingle strand without taking their spatial structures into account. We propose\na new methodology that incorporates protein tertiary structure in order to\nincrease our power when identifying mutation clustering.\n  Results: We have developed a novel algorithm, iPAC: identification of Protein\nAmino acid Clustering, for the identification of non-random somatic mutations\nin proteins that takes into account the three dimensional protein structure. By\nusing the tertiary information, we are able to detect both novel clusters in\nproteins that are known to exhibit mutation clustering as well as identify\nclusters in proteins without evidence of clustering based on existing methods.\nFor example, by combining the data in the Protein Data Bank (PDB) and the\nCatalogue of Somatic Mutations in Cancer, our algorithm identifies new\nmutational clusters in well known cancer proteins such as KRAS and PI3KCa.\nFurther, by utilizing the tertiary structure, our algorithm also identifies\nclusters in EGFR, EIF2AK2, and other proteins that are not identified by\ncurrent methodology.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6977v1"
    },
    {
        "title": "Periodic correlation structures in bacterial and archaeal complete\n  genomes",
        "authors": [
            "Zuo-Bing Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The periodic transference of nucleotide strings in bacterial and archaeal\ncomplete genomes is investigated by using the metric representation and the\nrecurrence plot method. The generated periodic correlation structures exhibit\nfour kinds of fundamental transferring characteristics: a single increasing\nperiod, several increasing periods, an increasing quasi-period and almost\nnoincreasing period. The mechanism of the periodic transference is further\nanalyzed by determining all long periodic nucleotide strings in the bacterial\nand archaeal complete genomes and is explained as follows: both the repetition\nof basic periodic nucleotide strings and the transference of non-periodic\nnucleotide strings would form the periodic correlation structures with\napproximately the same increasing periods.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.7102v1"
    },
    {
        "title": "Extensive divergence of transcription factor binding in Drosophila\n  embryos with highly conserved gene expression",
        "authors": [
            "Mathilde Paris",
            "Tommy Kaplan",
            "Xiao Yong Li",
            "Jacqueline E. Villalta",
            "Susan E. Lott",
            "Michael B. Eisen"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Extensive divergence of transcription factor binding in Drosophila embryos\nwith highly conserved gene expression\n",
        "pdf_link": "http://arxiv.org/pdf/1303.0216v2"
    },
    {
        "title": "A Unifying Model of Genome Evolution Under Parsimony",
        "authors": [
            "Benedict Paten",
            "Daniel R. Zerbino",
            "Glenn Hickey",
            "David Haussler"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We present a data structure called a history graph that offers a practical\nbasis for the analysis of genome evolution. It conceptually simplifies the\nstudy of parsimonious evolutionary histories by representing both substitutions\nand double cut and join (DCJ) rearrangements in the presence of duplications.\nThe problem of constructing parsimonious history graphs thus subsumes related\nmaximum parsimony problems in the fields of phylogenetic reconstruction and\ngenome rearrangement. We show that tractable functions can be used to define\nupper and lower bounds on the minimum number of substitutions and DCJ\nrearrangements needed to explain any history graph. These bounds become tight\nfor a special type of unambiguous history graph called an ancestral variation\ngraph (AVG), which constrains in its combinatorial structure the number of\noperations required. We finally demonstrate that for a given history graph $G$,\na finite set of AVGs describe all parsimonious interpretations of $G$, and this\nset can be explored with a few sampling moves.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.2246v5"
    },
    {
        "title": "RNA-Seq Mapping Errors When Using Incomplete Reference Transcriptomes of\n  Vertebrates",
        "authors": [
            "Alexis Black Pyrkosz",
            "Hans Cheng",
            "C. Titus Brown"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Whole transcriptome sequencing is increasingly being used as a functional\ngenomics tool to study non- model organisms. However, when the reference\ntranscriptome used to calculate differential expression is incomplete,\nsignificant error in the inferred expression levels can result. In this study,\nwe use simulated reads generated from real transcriptomes to determine the\naccuracy of read mapping, and measure the error resulting from using an\nincomplete transcriptome. We show that the two primary sources of count- ing\nerror are 1) alternative splice variants that share reads and 2) missing\ntranscripts from the reference. Alternative splice variants increase the false\npositive rate of mapping while incomplete reference tran- scriptomes decrease\nthe true positive rate, leading to inaccurate transcript expression levels.\nGrouping transcripts by gene or read sharing (similar to mapping to a reference\ngenome) significantly decreases false positives, but only by improving the\nreference transcriptome itself can the missing transcript problem be addressed.\nWe also demonstrate that employing different mapping software does not yield\nsubstantial increases in accuracy on simulated data. Finally, we show that read\nlengths or insert sizes must increase past 1kb to resolve mapping ambiguity.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.2411v1"
    },
    {
        "title": "CruzDB: software for annotation of genomic intervals with UCSC\n  genome-browser data",
        "authors": [
            "Brent S Pedersen",
            "Ivana V Yang",
            "Subhajyoti De"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The biological significance of genomic features is often context-dependent.\nWe present CruzDB, a fast and intuitive programmatic interface to the UCSC\ngenome browser that facilitates integrative analyses of diverse local and\nremotely hosted datasets. We showcase the syntax of CruzDB using miRNA-binding\nsites as examples, and further demonstrate its utility with 3 novel biological\ndiscoveries. First, we find that while exons replicate early, introns tend to\nreplicate late, suggesting a complex replication pattern in gene regions.\nSecond, variants associated with cognitive functions map to lincRNA transcripts\nof relevant function. Third, lamina-associated domains are highly enriched in\nolfaction-related genes. CruzDB is available at\nhttps://github.com/brentp/cruzdb\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3332v2"
    },
    {
        "title": "Sensitive Long-Indel-Aware Alignment of Sequencing Reads",
        "authors": [
            "Tobias Marschall",
            "Alexander Schönhuth"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The tremdendous advances in high-throughput sequencing technologies have made\npopulation-scale sequencing as performed in the 1000 Genomes project and the\nGenome of the Netherlands project possible. Next-generation sequencing has\nallowed genom-wide discovery of variations beyond single-nucleotide\npolymorphisms (SNPs), in particular of structural variations (SVs) like\ndeletions, insertions, duplications, translocations, inversions, and even more\ncomplex rearrangements. Here, we design a read aligner with special emphasis on\nthe following properties: (1) high sensitivity, i.e. find all (reasonable)\nalignments; (2) ability to find (long) indels; (3) statistically sound\nalignment scores; and (4) runtime fast enough to be applied to whole genome\ndata. We compare performance to BWA, bowtie2, stampy and find that our methods\nis especially advantageous on reads containing larger indels.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3520v1"
    },
    {
        "title": "Aligning sequence reads, clone sequences and assembly contigs with\n  BWA-MEM",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or\nlong query sequences against a large reference genome such as human. It\nautomatically chooses between local and end-to-end alignments, supports\npaired-end reads and performs chimeric alignment. The algorithm is robust to\nsequencing errors and applicable to a wide range of sequence lengths from 70bp\nto a few megabases. For mapping 100bp sequences, BWA-MEM shows better\nperformance than several state-of-art read aligners to date.\n  Availability and implementation: BWA-MEM is implemented as a component of\nBWA, which is available at http://github.com/lh3/bwa.\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3997v2"
    },
    {
        "title": "Major changes in the core developmental pathways of nematodes:\n  Romanomermis culicivorax reveals the derived status of the Caenorhabditis\n  elegans model",
        "authors": [
            "Philipp H. Schiffer",
            "Michael Kroiher",
            "Christopher Kraus",
            "Georgios D. Koutsovoulos",
            "Sujai Kumar",
            "Julia I. R. Camps",
            "Ndifon A. Nsah",
            "Dominik Stappert",
            "Krystalynne Morris",
            "Peter Heger",
            "Janine Altmüller",
            "Peter Frommolt",
            "Peter Nürnberg",
            "W. Kelley Thomas",
            "Mark L. Blaxter",
            "Einhard Schierenberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background Despite its status as a model organism, the development of\nCaenorhabditis elegans is not necessarily archetypical for nematodes. The\nphylum Nematoda is divided into the Chromadorea (indcludes C. elegans) and the\nEnoplea. Compared to C. elegans, enoplean nematodes have very different\npatterns of cell division and determination. Embryogenesis of the enoplean\nRomanomermis culicivorax has been studied in great detail, but the genetic\ncircuitry underpinning development in this species is unknown. Results We\ncreated a draft genome of R. culicivorax and compared its developmental gene\ncontent with that of two nematodes, C. elegans and Trichinella spiralis\n(another enoplean), and a representative arthropod Tribolium castaneum. This\ngenome evidence shows that R. culicivorax retains components of the conserved\nmetazoan developmental toolkit lost in C. elegans. T. spiralis has\nindependently lost even more of the toolkit than has C. elegans. However, the\nC. elegans toolkit is not simply depauperate, as many genes essential for\nembryogenesis in C. elegans are unique to this lineage, or have only extremely\ndivergent homologues in R. culicivorax and T. spiralis. These data imply\nfundamental differences in the genetic programmes for early cell specification,\ninductive interactions, vulva formation and sex determination. Conclusions Thus\nnematodes, despite their apparent phylum-wide morphological conservatism, have\nevolved major differences in the molecular logic of their development. R.\nculicivorax serves as a tractable, contrasting model to C. elegans for\nunderstanding how divergent genomic and thus regulatory backgrounds can\ngenerate a conserved phenotype. The availability of the draft genome will\npromote use of R. culicivorax as a research model.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4053v1"
    },
    {
        "title": "Lognormality and oscillations in the coverage of high-throughput\n  transcriptomic data towards gene ends",
        "authors": [
            "Nicolas Innocenti",
            "Erik Aurell"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  High-throughput transcriptomics experiments have reached the stage where the\ncount of the number of reads alignable to a given position can be treated as an\nalmost-continuous signal. This allows to ask questions of\nbiophysical/biotechnical nature, but which may still have biological\nimplications. Here we show that when sequencing RNA fragments from one end, as\nit is the case on most platforms, an oscillation in the read count is observed\nat the other end. We further show that these oscillations can be well described\nby Kolmogorov's 1941 broken stick model. We investigate how the model can be\nused to improve predictions of gene ends (3' transcript ends) but conclude that\nwith present data the improvement is only marginal. The results highlight\nsubtle effects in high-throughput transcriptomics experiments which do not have\na biological origin, but which may still be used to obtain biological\ninformation.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4229v3"
    },
    {
        "title": "Representing and decomposing genomic structural variants as balanced\n  integer flows on sequence graphs",
        "authors": [
            "Daniel R. Zerbino",
            "Tracy Ballinger",
            "Benedict Paten",
            "Glenn Hickey",
            "David Haussler"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The study of genomic variation has provided key insights into the functional\nrole of mutations. Predominantly, studies have focused on single nucleotide\nvariants (SNV), which are relatively easy to detect and can be described with\nrich mathematical models. However, it has been observed that genomes are highly\nplastic, and that whole regions can be moved, removed or duplicated in bulk.\nThese structural variants (SV) have been shown to have significant impact on\nthe phenotype, but their study has been held back by the combinatorial\ncomplexity of the underlying models. We describe here a general model of\nstructural variation that encompasses both balanced rearrangements and\narbitrary copy-numbers variants (CNV). In this model, we show that the space of\npossible evolutionary histories that explain the structural differences between\nany two genomes can be sampled ergodically.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.5569v2"
    },
    {
        "title": "SICLE: A high-throughput tool for extracting evolutionary relationships\n  from phylogenetic trees",
        "authors": [
            "Dan DeBlasio",
            "Jennifer Wiscaver"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We present the phylogeny analysis software SICLE (Sister Clade Extractor), an\neasy-to-use, high- throughput tool to describe the nearest neighbors to a node\nof interest in a phylogenetic tree as well as the support value for the\nrelationship. The application is a command line utility that can be embedded\ninto a phylogenetic analysis pipeline or can be used as a subroutine within\nanother C++ program. As a test case, we applied this new tool to the published\nphylome of Salinibacter ruber, a species of halophilic Bacteriodetes,\nidentifying 13 unique sister relationships to S. ruber across the 4589 gene\nphylogenies. S. ruber grouped with bacteria, most often other Bacteriodetes, in\nthe majority of phylogenies, but 91 phylogenies showed a branch-supported\nsister association between S. ruber and Archaea, an evolutionarily intriguing\nrelationship indicative of horizontal gene transfer. This test case\ndemonstrates how SICLE makes it possible to summarize the phylogenetic\ninformation produced by automated phylogenetic pipelines to rapidly identify\nand quantify the possible evolutionary relationships that merit further\ninvestigation. SICLE is available for free for noncommercial use at\nhttp://eebweb.arizona.edu/sicle/.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.5785v3"
    },
    {
        "title": "A Graph Theoretic Approach to Utilizing Protein Structure to Identify\n  Non-Random Somatic Mutations",
        "authors": [
            "Gregory Ryslik",
            "Yuwei Cheng",
            "Kei-Hoi Cheung",
            "Yorgo Modis",
            "Hongyu Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background: It is well known that the development of cancer is caused by the\naccumulation of somatic mutations within the genome. For oncogenes\nspecifically, current research suggests that there is a small set of \"driver\"\nmutations that are primarily responsible for tumorigenesis. Further, due to\nsome recent pharmacological successes in treating these driver mutations and\ntheir resulting tumors, a variety of methods have been developed to identify\npotential driver mutations using methods such as machine learning and\nmutational clustering. We propose a novel methodology that increases our power\nto identify mutational clusters by taking into account protein tertiary\nstructure via a graph theoretical approach.\n  Results: We have designed and implemented GraphPAC (Graph Protein Amino Acid\nClustering) to identify mutational clustering while considering protein spatial\nstructure. Using GraphPAC, we are able to detect novel clusters in proteins\nthat are known to exhibit mutation clustering as well as identify clusters in\nproteins without evidence of prior clustering based on current methods.\nSpecifically, by utilizing the spatial information available in the Protein\nData Bank (PDB) along with the mutational data in the Catalogue of Somatic\nMutations in Cancer (COSMIC), GraphPAC identifies new mutational clusters in\nwell known oncogenes such as EGFR and KRAS. Further, by utilizing graph theory\nto account for the tertiary structure, GraphPAC identifies clusters in DPP4,\nNRP1 and other proteins not identified by existing methods. The R package is\navailable at: http://bioconductor.org/packages/release/bioc/html/GraphPAC.html\n  Conclusion: GraphPAC provides an alternative to iPAC and an extension to\ncurrent methodology when identifying potential activating driver mutations by\nutilizing a graph theoretic approach when considering protein tertiary\nstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.5889v2"
    },
    {
        "title": "The Convergence of eQTL Mapping, Heritability Estimation and Polygenic\n  Modeling: Emerging Spectrum of Risk Variation in Bipolar Disorder",
        "authors": [
            "Eric R. Gamazon",
            "Hae Kyung Im",
            "Chunyu Liu",
            "Members of the Bipolar Disorder Genome Study",
            " Consortium",
            "Dan L. Nicolae",
            "Nancy J. Cox"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  It is widely held that a substantial genetic component underlies Bipolar\nDisorder (BD) and other neuropsychiatric disease traits. Recent efforts have\nbeen aimed at understanding the genetic basis of disease susceptibility, with\ngenome-wide association studies (GWAS) unveiling some promising associations.\nNevertheless, the genetic etiology of BD remains elusive with a substantial\nproportion of the heritability - which has been estimated to be 80% based on\ntwin and family studies - unaccounted for by the specific genetic variants\nidentified by large-scale GWAS. Furthermore, functional understanding of\nassociated loci generally lags discovery. Studies we report here provide\nconsiderable support to the claim that substantially more remains to be gained\nfrom GWAS on the genetic mechanisms underlying BD susceptibility, and that a\nlarge proportion of the variation in disease risk may be uncovered through\nintegrative functional genomic approaches. We combine recent analytic advances\nin heritability estimation and polygenic modeling and leverage recent\ntechnological advances in the generation of -omics data to evaluate the nature\nand scale of the contribution of functional classes of genetic variation to a\nrelatively intractable disorder. We identified cis eQTLs in cerebellum and\nparietal cortex that capture more than half of the total heritability\nattributable to SNPs interrogated through GWAS and showed that eQTL-based\nheritability estimation is highly tissue-dependent. Our findings show that a\nmuch greater resolution may be attained than has been reported thus far on the\nnumber of common loci that capture a substantial proportion of the heritability\nto disease risk and that the functional nature of contributory loci may be\nclarified en masse.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.6227v2"
    },
    {
        "title": "Improving transcriptome assembly through error correction of\n  high-throughput sequence reads",
        "authors": [
            "Matthew D MacManes",
            "Michael B Eisen"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The study of functional genomics--particularly in non-model organisms has\nbeen dramatically improved over the last few years by use of transcriptomes and\nRNAseq. While these studies are potentially extremely powerful, a\ncomputationally intensive procedure--the de novo construction of a reference\ntranscriptome must be completed as a prerequisite to further analyses. The\naccurate reference is critically important as all downstream steps, including\nestimating transcript abundance are critically dependent on the construction of\nan accurate reference. Though a substantial amount of research has been done on\nassembly, only recently have the pre-assembly procedures been studied in\ndetail. Specifically, several stand-alone error correction modules have been\nreported on, and while they have shown to be effective in reducing errors at\nthe level of sequencing reads, how error correction impacts assembly accuracy\nis largely unknown. Here, we show via use of a simulated dataset, that applying\nerror correction to sequencing reads has significant positive effects on\nassembly accuracy, by reducing assembly error by nearly 50%, and therefore\nshould be applied to all datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.0817v3"
    },
    {
        "title": "Reducing assembly complexity of microbial genomes with single-molecule\n  sequencing",
        "authors": [
            "Sergey Koren",
            "Gregory P Harhay",
            "Timothy PL Smith",
            "James L Bono",
            "Dayna M Harhay",
            "D. Scott Mcvey",
            "Diana Radune",
            "Nicholas H Bergman",
            "Adam M Phillippy"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background: The short reads output by first- and second-generation DNA\nsequencing instruments cannot completely reconstruct microbial chromosomes.\nTherefore, most genomes have been left unfinished due to the significant\nresources required to manually close gaps in draft assemblies.\nThird-generation, single-molecule sequencing addresses this problem by greatly\nincreasing sequencing read length, which simplifies the assembly problem.\n  Results: To measure the benefit of single-molecule sequencing on microbial\ngenome assembly, we sequenced and assembled the genomes of six bacteria and\nanalyzed the repeat complexity of 2,267 complete bacteria and archaea. Our\nresults indicate that the majority of known bacterial and archaeal genomes can\nbe assembled without gaps, at finished-grade quality, using a single PacBio RS\nsequencing library. These single-library assemblies are also more accurate than\ntypical short-read assemblies and hybrid assemblies of short and long reads.\n  Conclusions: Automated assembly of long, single-molecule sequencing data\nreduces the cost of microbial finishing to $1,000 for most genomes, and future\nadvances in this technology are expected to drive the cost lower. This is\nexpected to increase the number of completed genomes, improve the quality of\nmicrobial genome databases, and enable high-fidelity, population-scale studies\nof pan-genomes and chromosomal organization.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.3752v5"
    },
    {
        "title": "High-speed and accurate color-space short-read alignment with CUSHAW2",
        "authors": [
            "Yongchao Liu",
            "Bernt Popp",
            "Bertil Schmidt"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Summary: We present an extension of CUSHAW2 for fast and accurate alignments\nof SOLiD color-space short-reads. Our extension introduces a double-seeding\napproach to improve mapping sensitivity, by combining maximal exact match seeds\nand variable-length seeds derived from local alignments. We have compared the\nperformance of CUSHAW2 to SHRiMP2 and BFAST by aligning both simulated and real\ncolor-space mate-paired reads to the human genome. The results show that\nCUSHAW2 achieves comparable or better alignment quality compared to SHRiMP2 and\nBFAST at an order-of-magnitude faster speed and significantly smaller peak\nresident memory size. Availability: CUSHAW2 and all simulated datasets are\navailable at http://cushaw2.sourceforge.net. Contact: liuy@uni-mainz.de;\nbertil.schmidt@uni-mainz.de\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4766v1"
    },
    {
        "title": "GEMINI: integrative exploration of genetic variation and genome\n  annotations",
        "authors": [
            "Uma Paila",
            "Brad Chapman",
            "Rory Kirchner",
            "Aaron Quinlan"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Modern DNA sequencing technologies enable geneticists to rapidly identify\ngenetic variation among many human genomes. However, isolating the minority of\nvariants underlying disease remains an important, yet formidable challenge for\nmedical genetics. We have developed GEMINI (GEnome MINIng), a flexible software\npackage for exploring all forms of human genetic variation. Unlike existing\ntools, GEMINI integrates genetic variation with a diverse and flexible set of\ngenome annotations (e.g., dbSNP, ENCODE, UCSC, ClinVar, KEGG) into a unified\ndatabase to facilitate interpretation and data exploration. Whereas other\nmethods provide an inflexible set of variant filters or variant prioritization\nmethods, GEMINI allows researchers to compose complex queries based on sample\ngenotypes, inheritance patterns, and both pre-installed and custom genome\nannotations. GEMINI also provides methods for ad hoc queries and data\nexploration, a simple programming interface for custom analyses that leverage\nthe underlying database, and both command line and graphical tools for common\nanalyses. We demonstrate the utility of GEMINI for exploring variation in\npersonal genomes and family based genetic studies, and illustrate its ability\nto scale to studies involving thousands of human samples. GEMINI is designed\nfor reproducibility and flexibility and our goal is to will provide researchers\nwith a standard framework for medical genomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4860v2"
    },
    {
        "title": "Comparing DNA sequence collections by direct comparison of compressed\n  text indexes",
        "authors": [
            "Anthony J. Cox",
            "Tobias Jakobi",
            "Giovanna Rosone",
            "Ole B. Schulz-Trieglaff"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Popular sequence alignment tools such as BWA convert a reference genome to an\nindexing data structure based on the Burrows-Wheeler Transform (BWT), from\nwhich matches to individual query sequences can be rapidly determined. However\nthe utility of also indexing the query sequences themselves remains relatively\nunexplored.\n  Here we show that an all-against-all comparison of two sequence collections\ncan be computed from the BWT of each collection with the BWTs held entirely in\nexternal memory, i.e. on disk and not in RAM. As an application of this\ntechnique, we show that BWTs of transcriptomic and genomic reads can be\ncompared to obtain reference-free predictions of splice junctions that have\nhigh overlap with results from more standard reference-based methods.\n  Code to construct and compare the BWT of large genomic data sets is available\nat http://beetl.github.com/BEETL/ as part of the BEETL library.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5535v1"
    },
    {
        "title": "Informed and Automated k-Mer Size Selection for Genome Assembly",
        "authors": [
            "Rayan Chikhi",
            "Paul Medvedev"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Genome assembly tools based on the de Bruijn graph framework rely on a\nparameter k, which represents a trade-off between several competing effects\nthat are difficult to quantify. There is currently a lack of tools that would\nautomatically estimate the best k to use and/or quickly generate histograms of\nk-mer abundances that would allow the user to make an informed decision.\n  We develop a fast and accurate sampling method that constructs approximate\nabundance histograms with a several orders of magnitude performance improvement\nover traditional methods. We then present a fast heuristic that uses the\ngenerated abundance histograms for putative k values to estimate the best\npossible value of k. We test the effectiveness of our tool using diverse\nsequencing datasets and find that its choice of k leads to some of the best\nassemblies.\n  Our tool KmerGenie is freely available at: http://kmergenie.bx.psu.edu/\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5665v1"
    },
    {
        "title": "Methods to study splicing from high-throughput RNA Sequencing data",
        "authors": [
            "Gael P. Alamancos",
            "Eneritz Agirre",
            "Eduardo Eyras"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The development of novel high-throughput sequencing (HTS) methods for RNA\n(RNA-Seq) has provided a very powerful mean to study splicing under multiple\nconditions at unprecedented depth. However, the complexity of the information\nto be analyzed has turned this into a challenging task. In the last few years,\na plethora of tools have been developed, allowing researchers to process\nRNA-Seq data to study the expression of isoforms and splicing events, and their\nrelative changes under different conditions. We provide an overview of the\nmethods available to study splicing from short RNA-Seq data. We group the\nmethods according to the different questions they address: 1) Assignment of the\nsequencing reads to their likely gene of origin. This is addressed by methods\nthat map reads to the genome and/or to the available gene annotations. 2)\nRecovering the sequence of splicing events and isoforms. This is addressed by\ntranscript reconstruction and de novo assembly methods. 3) Quantification of\nevents and isoforms. Either after reconstructing transcripts or using an\nannotation, many methods estimate the expression level or the relative usage of\nisoforms and/or events. 4) Providing an isoform or event view of differential\nsplicing or expression. These include methods that compare relative\nevent/isoform abundance or isoform expression across two or more conditions. 5)\nVisualizing splicing regulation. Various tools facilitate the visualization of\nthe RNA-Seq data in the context of alternative splicing. In this review, we do\nnot describe the specific mathematical models behind each method. Our aim is\nrather to provide an overview that could serve as an entry point for users who\nneed to decide on a suitable tool for a specific analysis. We also attempt to\npropose a classification of the tools according to the operations they do, to\nfacilitate the comparison and choice of methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5952v3"
    },
    {
        "title": "biobambam: tools for read pair collation based algorithms on BAM files",
        "authors": [
            "German Tischler",
            "Steven Leonard"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Sequence alignment data is often ordered by coordinate (id of the reference\nsequence plus position on the sequence where the fragment was mapped) when\nstored in BAM files, as this simplifies the extraction of variants between the\nmapped data and the reference or of variants within the mapped data. In this\norder paired reads are usually separated in the file, which complicates some\nother applications like duplicate marking or conversion to the FastQ format\nwhich require to access the full information of the pairs. In this paper we\nintroduce biobambam, an API for efficient BAM file reading supporting the\nefficient collation of alignments by read name without performing a complete\nresorting of the input file and some tools based on this API performing tasks\nlike marking duplicate reads and conversion to the FastQ format. In comparison\nwith previous approaches to problems involving the collation of alignments by\nread name like the BAM to FastQ or duplication marking utilities in the Picard\nsuite the approach of biobambam can often perform an equivalent task more\nefficiently in terms of the required main memory and run-time.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.0836v1"
    },
    {
        "title": "Low-bandwidth and non-compute intensive remote identification of\n  microbes from raw sequencing reads",
        "authors": [
            "Laurent Gautier",
            "Ole Lund"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Cheap high-throughput DNA sequencing may soon become routine not only for\nhuman genomes but also for practically anything requiring the identification of\nliving organisms from their DNA: tracking of infectious agents, control of food\nproducts, bioreactors, or environmental samples.\n  We propose a novel general approach to the analysis of sequencing data in\nwhich the reference genome does not have to be specified. Using a distributed\narchitecture we are able to query a remote server for hints about what the\nreference might be, transferring a relatively small amount of data, and the\nhints can be used for more computationally-demanding work.\n  Our system consists of a server with known reference DNA indexed, and a\nclient with raw sequencing reads. The client sends a sample of unidentified\nreads, and in return receives a list of matching references known to the\nserver. Sequences for the references can be retrieved and used for exhaustive\ncomputation on the reads, such as alignment.\n  To demonstrate this approach we have implemented a web server, indexing tens\nof thousands of publicly available genomes and genomic regions from various\norganisms and returning lists of matching hits from query sequencing reads. We\nhave also implemented two clients, one of them running in a web browser, in\norder to demonstrate that gigabytes of raw sequencing reads of unknown origin\ncould be identified without the need to transfer a very large volume of data,\nand on modestly powered computing devices.\n  A web access is available at http://tapir.cbs.dtu.dk. The source code for a\npython command-line client, a server, and supplementary data is available at\nhttp://bit.ly/1aURxkc.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.1569v2"
    },
    {
        "title": "mendelFix: a Perl script for checking Mendelian errors in high density\n  SNP data of trio designs",
        "authors": [
            "Yuri Tani Utsunomiya",
            "Rodrigo Vitorio Alonso",
            "Adriana Santana do Carmo",
            "Francine Campagnari",
            "José Antonio Vinsintin",
            "José Fernando Garcia"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Here we present mendelFix, a Perl script for checking Mendelian errors in\ngenome-wide SNP data of trio designs. The program takes 12-recoded PLINK PED\nand MAP files as input to calculate a series of summary statistics for\nMendelian errors, sets missing offspring genotypes that present Mendelian\ninconsistencies, and implements a simplistic procedure to infer missing\ngenotypes using parent information. The program can be easily incorporated in\nany pipeline for family-based SNP data analysis, and is distributed as free\nsoftware under the GNU General Public License.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.2243v1"
    },
    {
        "title": "Modeling the dynamics of bivalent histone modifications",
        "authors": [
            "Wai Lim Ku",
            "Michelle Girvan",
            "Guo-Cheng Yuan",
            "Francesco Sorrentino",
            "Edward Ott"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Epigenetic modifications to histones may promote either activation or\nrepression of the transcription of nearby genes. Recent experimental studies\nshow that the promoters of many lineage-control genes in stem cells have\n\"bivalent domains\" in which the nucleosomes contain both active (H3K4me3) and\nrepressive (H3K27me3) marks. It is generally agreed that bivalent domains play\nan important role in stem cell differentiation, but the underlying mechanisms\nremain unclear. Here we formulate a mathematical model to investigate the\ndynamic properties of histone modification patterns. We then illustrate that\nour modeling framework can be used to capture key features of experimentally\nobserved combinatorial chromatin states.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.2353v1"
    },
    {
        "title": "Sashimi plots: Quantitative visualization of RNA sequencing read\n  alignments",
        "authors": [
            "Yarden Katz",
            "Eric T. Wang",
            "Jacob Silterra",
            "Schraga Schwartz",
            "Bang Wong",
            "Jill P. Mesirov",
            "Edoardo M. Airoldi",
            "Christopher B. Burge"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We introduce Sashimi plots, a quantitative multi-sample visualization of mRNA\nsequencing reads aligned to gene annotations. Sashimi plots are made using\nalignments (stored in the SAM/BAM format) and gene model annotations (in GFF\nformat), which can be custom-made by the user or obtained from databases such\nas Ensembl or UCSC. We describe two implementations of Sashimi plots: (1) a\nstand-alone command line implementation aimed at making customizable\npublication quality figures, and (2) an implementation built into the\nIntegrated Genome Viewer (IGV) browser, which enables rapid and dynamic\ncreation of Sashimi plots for any genomic region of interest, suitable for\nexploratory analysis of alternatively spliced regions of the transcriptome.\nIsoform expression estimates outputted by the MISO program can be optionally\nplotted along with Sashimi plots. Sashimi plots can be used to quickly screen\ndifferentially spliced exons along genomic regions of interest and can be used\nin publication quality figures. The Sashimi plot software and documentation is\navailable from: http://genes.mit.edu/burgelab/miso/docs/sashimi.html\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3466v1"
    },
    {
        "title": "Bound to succeed: Transcription factor binding site prediction and its\n  contribution to understanding virulence and environmental adaptation in\n  bacterial plant pathogens",
        "authors": [
            "Surya Saha",
            "Magdalen Lindeberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Bacterial plant pathogens rely on a battalion of transcription factors to\nfine-tune their response to changing environmental conditions and marshal the\ngenetic resources required for successful pathogenesis. Prediction of\ntranscription factor binding sites represents an important tool for elucidating\nregulatory networks, and has been conducted in multiple genera of plant\npathogenic bacteria for the purpose of better understanding mechanisms of\nsurvival and pathogenesis. The major categories of transcription factor binding\nsites that have been characterized are reviewed here with emphasis on in silico\nmethods used for site identification and challenges therein, their\napplicability to different types of sequence datasets, and insights into\nmechanisms of virulence and survival that have been gained through binding site\nmapping. An improved strategy for establishing E value cutoffs when using\nexisting models to screen uncharacterized genomes is also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.6124v1"
    },
    {
        "title": "Bayesian genome assembly and assessment by Markov Chain Monte Carlo\n  sampling",
        "authors": [
            "Mark Howison",
            "Felipe Zapata",
            "Erika J. Edwards",
            "Casey W. Dunn"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Most genome assemblers construct point estimates, choosing a genome sequence\nfrom among many alternative hypotheses that are supported by the data. We\npresent a Markov Chain Monte Carlo approach to sequence assembly that instead\ngenerates distributions of assembly hypotheses with posterior probabilities,\nproviding an explicit statistical framework for evaluating alternative\nhypotheses and assessing assembly uncertainty. We implement this approach in a\nprototype assembler and illustrate its application to the bacteriophage\nPhiX174.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.1388v2"
    },
    {
        "title": "MicroRNAs Implicated in Dysregulation of Gene Expression Following Human\n  Lung Transplantation",
        "authors": [
            "Wei Zhang",
            "Tong Zhou",
            "Shwu-Fan Ma",
            "Robert F. Machado",
            "Sangeeta M. Bhorade",
            "Joe G. N. Garcia"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Lung transplantation remains the only viable treatment option for the\nmajority of patients with advanced lung diseases. However, 5-year\npost-transplant survival rates remain low primarily secondary to chronic\nrejection. Novel insights from global gene expression profiles may provide\nmolecular phenotypes and therapeutic targets to improve outcomes after lung\ntransplantation. We showed the presence of a significant number of dysregulated\ngenes, particularly those genes involved in pathways and biological processes\nsuch as immune response and defense, in the PBMCs derived from a cohort of\npatients after lung transplantation. The contribution of miRNAs in regulating\nthese differential genes was also demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.2007v1"
    },
    {
        "title": "Estimation of genomic characteristics by analyzing k-mer frequency in de\n  novo genome projects",
        "authors": [
            "Binghang Liu",
            "Yujian Shi",
            "Jianying Yuan",
            "Xuesong Hu",
            "Hao Zhang",
            "Nan Li",
            "Zhenyu Li",
            "Yanxiang Chen",
            "Desheng Mu",
            "Wei Fan"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background: With the fast development of next generation sequencing\ntechnologies, increasing numbers of genomes are being de novo sequenced and\nassembled. However, most are in fragmental and incomplete draft status, and\nthus it is often difficult to know the accurate genome size and repeat content.\nFurthermore, many genomes are highly repetitive or heterozygous, posing\nproblems to current assemblers utilizing short reads. Therefore, it is\nnecessary to develop efficient assembly-independent methods for accurate\nestimation of these genomic characteristics. Results: Here we present a\nframework for modeling the distribution of k-mer frequency from sequencing data\nand estimating the genomic characteristics such as genome size, repeat\nstructure and heterozygous rate. By introducing novel techniques of k-mer\nindividuals, float precision estimation, and proper treatment of sequencing\nerror and coverage bias, the estimation accuracy of our method is significantly\nimproved over existing methods. We also studied how the various genomic and\nsequencing characteristics affect the estimation accuracy using simulated\nsequencing data, and discussed the limitations on applying our method to real\nsequencing data. Conclusion: Based on this research, we show that the k-mer\nfrequency analysis can be used as a general and assembly-independent method for\nestimating genomic characteristics, which can improve our understanding of a\nspecies genome, help design the sequencing strategy of genome projects, and\nguide the development of assembly algorithms. The programs developed in this\nresearch are written using C/C++, and freely accessible at Github URL\n(https://github.com/fanagislab/GCE) or BGI ftp (\nftp://ftp.genomics.org.cn/pub/gce).\n",
        "pdf_link": "http://arxiv.org/pdf/1308.2012v2"
    },
    {
        "title": "Predicting genome-wide DNA methylation using methylation marks, genomic\n  position, and DNA regulatory elements",
        "authors": [
            "Weiwei Zhang",
            "Tim D Spector",
            "Panos Deloukas",
            "Jordana T Bell",
            "Barbara E Engelhardt"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background: Recent assays for individual-specific genome-wide DNA methylation\nprofiles have enabled epigenome-wide association studies to identify specific\nCpG sites associated with a phenotype. Computational prediction of CpG\nsite-specific methylation levels is important, but current approaches tackle\naverage methylation within a genomic locus and are often limited to specific\ngenomic regions. Results: We characterize genome-wide DNA methylation patterns,\nand show that correlation among CpG sites decays rapidly, making predictions\nsolely based on neighboring sites challenging. We built a random forest\nclassifier to predict CpG site methylation levels using as features neighboring\nCpG site methylation levels and genomic distance, and co-localization with\ncoding regions, CGIs, and regulatory elements from the ENCODE project, among\nothers. Our approach achieves 91% -- 94% prediction accuracy of genome-wide\nmethylation levels at single CpG site precision. The accuracy increases to 98%\nwhen restricted to CpG sites within CGIs. Our classifier outperforms\nstate-of-the-art methylation classifiers and identifies features that\ncontribute to prediction accuracy: neighboring CpG site methylation status, CpG\nisland status, co-localized DNase I hypersensitive sites, and specific\ntranscription factor binding sites were found to be most predictive of\nmethylation levels. Conclusions: Our observations of DNA methylation patterns\nled us to develop a classifier to predict site-specific methylation levels that\nachieves the best DNA methylation predictive accuracy to date. Furthermore, our\nmethod identified genomic features that interact with DNA methylation,\nelucidating mechanisms involved in DNA methylation modification and regulation,\nand linking different epigenetic processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.2134v1"
    },
    {
        "title": "Realistic simulations reveal extensive sample-specificity of RNA-seq\n  biases",
        "authors": [
            "Botond Sipos",
            "Greg Slodkowicz",
            "Tim Massingham",
            "Nick Goldman"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  In line with the importance of RNA-seq, the bioinformatics community has\nproduced numerous data analysis tools incorporating methods to correct\nsample-specific biases. However, few advanced simulation tools exist to enable\nbenchmarking of competing correction methods. We introduce the first framework\nto reproduce the properties of individual RNA-seq runs and, by applying it on\nseveral datasets, we demonstrate the importance of accounting for\nsample-specificity in realistic simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.3172v1"
    },
    {
        "title": "Friendship and Natural Selection",
        "authors": [
            "Nicholas A. Christakis",
            "James H. Fowler"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  More than any other species, humans form social ties to individuals who are\nneither kin nor mates, and these ties tend to be with similar people. Here, we\nshow that this similarity extends to genotypes. Across the whole genome,\nfriends' genotypes at the SNP level tend to be positively correlated\n(homophilic); however, certain genotypes are negatively correlated\n(heterophilic). A focused gene set analysis suggests that some of the overall\ncorrelation can be explained by specific systems; for example, an olfactory\ngene set is homophilic and an immune system gene set is heterophilic. Finally,\nhomophilic genotypes exhibit significantly higher measures of positive\nselection, suggesting that, on average, they may yield a synergistic fitness\nadvantage that has been helping to drive recent human evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.5257v2"
    },
    {
        "title": "Diminishing Return for Increased Mappability with Longer Sequencing\n  Reads: Implications of the k-mer Distributions in the Human Genome",
        "authors": [
            "Wentian Li",
            "Jan Freudenberg",
            "Pedro Miramontes"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The amount of non-unique sequence (non-singletons) in a genome directly\naffects the difficulty of read alignment to a reference assembly for high\nthroughput-sequencing data. Although a greater length increases the chance for\nreads being uniquely mapped to the reference genome, a quantitative analysis of\nthe influence of read lengths on mappability has been lacking. To address this\nquestion, we evaluate the k-mer distribution of the human reference genome. The\nk-mer frequency is determined for k ranging from 20 to 1000 basepairs. We use\nthe proportion of non-singleton k-mers to evaluate the mappability of reads for\na corresponding read length. We observe that the proportion of non-singletons\ndecreases slowly with increasing k, and can be fitted by piecewise power-law\nfunctions with different exponents at different k ranges. A faster decay at\nsmaller values for k indicates more limited gains for read lengths > 200\nbasepairs. The frequency distributions of k-mers exhibit long tails in a\npower-law-like trend, and rank frequency plots exhibit a concave Zipf's curve.\nThe location of the most frequent 1000-mers comprises 172 kilobase-ranged\nregions, including four large stretches on chromosomes 1 and X, containing\ngenes with biomedical implications. Even the read length 1000 would be\ninsufficient to reliably sequence these specific regions.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.6240v1"
    },
    {
        "title": "TreeOTU: Operational Taxonomic Unit Classification Based on Phylogenetic\n  Trees",
        "authors": [
            "Dongying Wu",
            "Ladan Doroud",
            "Jonathan A. Eisen"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Our current understanding of the taxonomic and phylogenetic diversity of\ncellular organisms, especially the bacteria and archaea, is mostly based upon\nstudies of sequences of the small- subunit rRNAs (ssu-rRNAs). To address the\nlimitation of ssu-rRNA as a phylogenetic marker, such as copy number variation\namong organisms and complications introduced by horizontal gene transfer,\nconvergent evolution, or evolution rate variations, we have identified protein-\ncoding gene families as alternative Phylogenetic and Phylogenetic Ecology\nmarkers (PhyEco). Current nucleotide sequence similarity based Operational\nTaxonomic Unit (OTU) classification methods are not readily applicable to amino\nacid sequences of PhyEco markers. We report here the development of TreeOTU, a\nphylogenetic tree structure based OTU classification method that takes into\naccount of differences in rates of evolution between taxa and between genes.\nOTU sets built by TreeOTU are more faithful to phylogenetic tree structures\nthan sequence clustering (non phylogenetic) methods for ssu-rRNAs. OTUs built\nfrom phylogenetic trees of protein coding PhyEco markers are comparable to our\ncurrent taxonomic classification at different levels. With the included OTU\ncomparing tools, the TreeOTU is robust in phylogenetic referencing with\ndifferent phylogenetic markers and trees.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.6333v1"
    },
    {
        "title": "Baa.pl: A tool to evaluate de novo genome assemblies with RNA\n  transcripts",
        "authors": [
            "Joseph F. Ryan"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Assessing the correctness of genome assemblies is an important step in any\ngenome project. Several methods exist, but most are computationally intensive\nand, in some cases, inappropriate. Here I present baa.pl, a fast and\neasy-to-use program that uses transcript data to evaluate genomic assemblies.\nThrough simulations using human chromosome 22, I show that baa.pl excels at\ndetecting levels of missing sequence and contiguity. The program is freely\navailable at: https://github.com/josephryan/baa.pl\n",
        "pdf_link": "http://arxiv.org/pdf/1309.2087v2"
    },
    {
        "title": "Two-dimensional SDS-PAGE fractionation of biological samples for\n  biomarker discovery",
        "authors": [
            "Thierry Rabilloud",
            "Sarah Triboulet"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Two-dimensional electrophoresis is still a very valuable tool in proteomics,\ndue to its reproducibility and its ability to analyze complete proteins.\nHowever, due to its sensitivity to dynamic range issues, its most suitable use\nin the frame of biomarker discovery is not on very complex fluids such as\nplasma, but rather on more proximal, simpler fluids such as CSF, urine, or\nsecretome samples. Here, we describe the complete workflow for the analysis of\nsuch dilute samples by two-dimensional electrophoresis, starting from sample\nconcentration, then the two-dimensional electrophoresis step per se, ending\nwith the protein detection by fluorescence.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.2428v1"
    },
    {
        "title": "These are not the k-mers you are looking for: efficient online k-mer\n  counting using a probabilistic data structure",
        "authors": [
            "Qingpeng Zhang",
            "Jason Pell",
            "Rosangela Canino-Koning",
            "Adina Chuang Howe",
            "C. Titus Brown"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  K-mer abundance analysis is widely used for many purposes in nucleotide\nsequence analysis, including data preprocessing for de novo assembly, repeat\ndetection, and sequencing coverage estimation. We present the khmer software\npackage for fast and memory efficient online counting of k-mers in sequencing\ndata sets. Unlike previous methods based on data structures such as hash\ntables, suffix arrays, and trie structures, khmer relies entirely on a simple\nprobabilistic data structure, a Count-Min Sketch. The Count-Min Sketch permits\nonline updating and retrieval of k-mer counts in memory which is necessary to\nsupport online k-mer analysis algorithms. On sparse data sets this data\nstructure is considerably more memory efficient than any exact data structure.\nIn exchange, the use of a Count-Min Sketch introduces a systematic overcount\nfor k-mers; moreover, only the counts, and not the k-mers, are stored. Here we\nanalyze the speed, the memory usage, and the miscount rate of khmer for\ngenerating k-mer frequency distributions and retrieving k-mer counts for\nindividual k-mers. We also compare the performance of khmer to several other\nk-mer counting packages, including Tallymer, Jellyfish, BFCounter, DSK, KMC,\nTurtle and KAnalyze. Finally, we examine the effectiveness of profiling\nsequencing error, k-mer abundance trimming, and digital normalization of reads\nin the context of high khmer false positive rates. khmer is implemented in C++\nwrapped in a Python interface, offers a tested and robust API, and is freely\navailable under the BSD license at github.com/ged-lab/khmer.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.2975v4"
    },
    {
        "title": "Characterizing the infection-induced transcriptome of Nasonia\n  vitripennis reveals a preponderance of taxonomically-restricted immune genes",
        "authors": [
            "Timothy B. Sackton",
            "John H. Werren",
            "Andrew G. Clark"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The innate immune system in insects consists of a conserved core signaling\nnetwork and rapidly diversifying effector and recognition components, often\ncontaining a high proportion of taxonomically-restricted genes. In the absence\nof functional annotation, genes encoding immune system proteins can thus be\ndifficult to identify, as homology-based approaches generally cannot detect\nlineage-specific genes. Here, we use RNA-seq to compare the uninfected and\ninfection-induced transcriptome in the parasitoid wasp Nasonia vitripennis to\nidentify genes regulated by infection. We identify 183 genes significantly\nup-regulated by infection and 61 genes significantly down-regulated by\ninfection. We also produce a new homology-based immune catalog in N.\nvitripennis, and show that most infection-induced genes are not assigned an\nimmune function from homology alone, suggesting the potential for substantial\nnovel immune components in less-well-studied systems. Finally, we show that a\nhigh proportion of these novel induced genes are taxonomically-restricted,\nhighlighting the rapid evolution of immune gene content. The combination of\nfunctional annotation using RNA-seq and homology-based annotation provides a\nrobust method to characterize the innate immune response across a wide variety\nof insects, and reveals significant novel features of the Nasonia immune\nresponse.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5932v2"
    },
    {
        "title": "Integrating diverse datasets improves developmental enhancer prediction",
        "authors": [
            "Genevieve D. Erwin",
            "Rebecca M. Truty",
            "Dennis Kostka",
            "Katherine S. Pollard",
            "John A. Capra"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Gene-regulatory enhancers have been identified by many lines of evidence,\nincluding evolutionary conservation, regulatory protein binding, chromatin\nmodifications, and DNA sequence motifs. To integrate these different\napproaches, we developed EnhancerFinder, a novel method for predicting\ndevelopmental enhancers and their tissue specificity. EnhancerFinder uses a\ntwo-step multiple-kernel learning approach to integrate DNA sequence motifs,\nevolutionary patterns, and thousands of diverse functional genomics datasets\nfrom a variety of cell types and developmental stages. We trained\nEnhancerFinder on hundreds of experimentally verified human developmental\nenhancers from the VISTA Enhancer Browser, in contrast to histone mark or\nsequence-based enhancer definitions commonly used. We comprehensively evaluated\nEnhancerFinder, and found that our integrative approach improves enhancer\nprediction accuracy over previous approaches that consider a single type of\ndata. Our evaluation highlights the importance of considering information from\nmany tissues when predicting specific types of enhancers. We find that VISTA\nenhancers active in embryonic heart are easier to predict than enhancers active\nin several other tissues due to their uniquely high GC content. We applied\nEnhancerFinder to the entire human genome and predicted 84,301 developmental\nenhancers and their tissue specificity. These predictions provide specific\nfunctional annotations for large amounts of human non-coding DNA, and are\nsignificantly enriched near genes with annotated roles in their predicted\ntissues and hits from genome-wide association studies. We demonstrate the\nutility of our enhancer predictions by identifying and validating a novel\ncranial nerve enhancer in the ZEB2 locus. Our genome-wide developmental\nenhancer predictions will be freely available as a UCSC Genome Browser track.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.7382v1"
    },
    {
        "title": "Joint assembly and genetic mapping of the Atlantic horseshoe crab genome\n  reveals ancient whole genome duplication",
        "authors": [
            "Carlos Nossa",
            "Paul Havlak",
            "Jia-Xing Yue",
            "Jie Lv",
            "Kim Vincent",
            "H Jane Brockmann",
            "Nicholas H Putnam"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Horseshoe crabs are marine arthropods with a fossil record extending back\napproximately 450 million years. They exhibit remarkable morphological\nstability over their long evolutionary history, retaining a number of ancestral\narthropod traits, and are often cited as examples of \"living fossils.\" As\narthropods, they belong to the Ecdysozoa}, an ancient super-phylum whose\nsequenced genomes (including insects and nematodes) have thus far shown more\ndivergence from the ancestral pattern of eumetazoan genome organization than\ncnidarians, deuterostomes, and lophotrochozoans. However, much of ecdysozoan\ndiversity remains unrepresented in comparative genomic analyses. Here we use a\nnew strategy of combined de novo assembly and genetic mapping to examine the\nchromosome-scale genome organization of the Atlantic horseshoe crab Limulus\npolyphemus. We constructed a genetic linkage map of this 2.7 Gbp genome by\nsequencing the nuclear DNA of 34 wild-collected, full-sibling embryos and their\nparents at a mean redundancy of 1.1x per sample. The map includes 84,307\nsequence markers and 5,775 candidate conserved protein coding genes. Comparison\nto other metazoan genomes shows that the L. polyphemus genome preserves\nancestral bilaterian linkage groups, and that a common ancestor of modern\nhorseshoe crabs underwent one or more ancient whole genome duplications (WGDs)\n~ 300 MYA, followed by extensive chromosome fusion.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.7402v1"
    },
    {
        "title": "Theoretical Bounds on Mate-Pair Information for Accurate Genome Assembly",
        "authors": [
            "Henry Lin"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Over the past two decades, a series of works have aimed at studying the\nproblem of genome assembly: the process of reconstructing a genome from\nsequence reads. An early formulation of the genome assembly problem showed that\ngenome reconstruction is NP-hard when framed as finding the shortest sequence\nthat contains all observed reads. Although this original formulation is very\nsimplistic and does not allow for mate-pair information, subsequent\nformulations have also proven to be NP-hard, and/or may not be guaranteed to\nreturn a correct assembly.\n  In this paper, we provide an alternate perspective on the genome assembly\nproblem by showing genome assembly is easy when provided with sufficient\nmate-pair information. Moreover, we quantify the number of mate-pair libraries\nnecessary and sufficient for accurate genome assembly, in terms of the length\nof the longest repetitive region within a genome. In our analysis, we consider\nan idealized sequencing model where each mate-pair library generates pairs of\nerror free reads with a fixed and known insert size at each position in the\ngenome.\n  Even in this idealized model, we show that accurate genome reconstruction\ncannot be guaranteed in the worst case unless at least roughly R/2L mate-pair\nlibraries are produced, where R is the length of the longest repetitive region\nin the genome and L is the length of each read. On the other hand, if (R/L)+1\nmate-pair libraries are provided, then a simple algorithm can be used to find a\ncorrect genome assembly easily in polynomial time. Although (R/L)+1 mate-pair\nlibraries can be too much to produce in practice, the previous bounds only hold\nin the worst case. In our last result, we show that if additional conditions\nhold on a genome, a correct assembly can be guaranteed with only O(log (R/L))\nmate-pair libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.1653v3"
    },
    {
        "title": "IQRray, a new method for Affymetrix microarray quality control, and the\n  homologous organ conservation score, a new benchmark method for quality\n  control metrics",
        "authors": [
            "Marta Rosikiewicz",
            "Marc Robinson-Rechavi"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation: Microarray results accumulated in public repositories are widely\nre-used in meta-analytical studies and secondary databases. The quality of the\ndata obtained with this technology varies from experiment to experiment and\nefficient method for quality assessment is neces-sary to ensure their\nreliability. Results: The lack of a good benchmark has hampered evaluation of\nexisting methods for quality control. In this study we propose a new\ninde-pendent quality metric that is based on evolutionary conservation of\nexpression profiles. We show, using 11 large organ-specific datasets, that\nIQRray, a new quality metrics developed by us, exhibits the highest correlation\nwith this reference metric, among 14 metrics tested. IQRray outperforms other\nmethods in identification of poor quality arrays in dataset composed of arrays\nfrom many independent experiments. In con-trast, the performance of methods\ndesigned for detecting outliers in a single experiment like NUSE and RLE was\nlow because of the inability of these method to detect datasets containing only\nlow quality arrays, and the fact that the scores cannot be directly compared\nbetween ex-periments. Availability: The R implementation of IQRray is available\nat: ftp://lausanne.isb-sib.ch/pub/databases/Bgee/general/IQRray.R\n",
        "pdf_link": "http://arxiv.org/pdf/1310.2129v1"
    },
    {
        "title": "Identification of cromosomal translocation hotspots via scan statistics",
        "authors": [
            "Israel T. Silva",
            "Rafael A. Rosales",
            "Adriano J. Holanda",
            "Michel C. Nussenzweig",
            "Mila Jankovic"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The detection of genomic regions unusually rich in a given pattern is an\nimportant undertaking in the analysis of next generation sequencing data.\nRecent studies of chromosomal translocations in activated B lymphocytes have\nidentified regions that are frequently translocated to c-myc oncogene. A\nquantitative method for the identification of translocation hotspots was\ncrucial to this study. Here we improve this analysis by using a simple\nprobabilistic model and the framework provided by scan statistics to define the\nnumber and location of translocation breakpoint hotspots. A key feature of our\nmethod is that it provides a global chromosome-wide significance level to\nclustering, as opposed to previous methods based on local criteria. Whilst\nbeing motivated by a specific application, the detection of unusual clusters is\na widespread problem in bioinformatics. We expect our method to be useful in\nthe analysis of data from other experimental approaches such as of ChIP-seq and\n4C-seq.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3291v1"
    },
    {
        "title": "The Functional Consequences of Variation in Transcription Factor Binding",
        "authors": [
            "Darren A. Cusanovich",
            "Bryan Pavlovic",
            "Jonathan K. Pritchard",
            "Yoav Gilad"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  One goal of human genetics is to understand how the information for precise\nand dynamic gene expression programs is encoded in the genome. The interactions\nof transcription factors (TFs) with DNA regulatory elements clearly play an\nimportant role in determining gene expression outputs, yet the regulatory logic\nunderlying functional transcription factor binding is poorly understood. Many\nstudies have focused on characterizing the genomic locations of TF binding, yet\nit is unclear to what extent TF binding at any specific locus has functional\nconsequences with respect to gene expression output. To evaluate the context of\nfunctional TF binding we knocked down 59 TFs and chromatin modifiers in one\nHapMap lymphoblastoid cell line. We then identified genes whose expression was\naffected by the knockdowns. We intersected the gene expression data with\ntranscription factor binding data (based on ChIP-seq and DNase-seq) within 10\nkb of the transcription start sites of expressed genes. This combination of\ndata allowed us to infer functional TF binding. On average, 14.7% of genes\nbound by a factor were differentially expressed following the knockdown of that\nfactor, suggesting that most interactions between TF and chromatin do not\nresult in measurable changes in gene expression levels of putative target\ngenes. We found that functional TF binding is enriched in regulatory elements\nthat harbor a large number of TF binding sites, at sites with predicted higher\nbinding affinity, and at sites that are enriched in genomic regions annotated\nas active enhancers.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.5166v1"
    },
    {
        "title": "Ensemble Analysis of Adaptive Compressed Genome Sequencing Strategies",
        "authors": [
            "Zeinab Taghavi"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Acquiring genomes at single-cell resolution has many applications such as in\nthe study of microbiota. However, deep sequencing and assembly of all of\nmillions of cells in a sample is prohibitively costly. A property that can come\nto rescue is that deep sequencing of every cell should not be necessary to\ncapture all distinct genomes, as the majority of cells are biological\nreplicates. Biologically important samples are often sparse in that sense. In\nthis paper, we propose an adaptive compressed method, also known as distilled\nsensing, to capture all distinct genomes in a sparse microbial community with\nreduced sequencing effort. As opposed to group testing in which the number of\ndistinct events is often constant and sparsity is equivalent to rarity of an\nevent, sparsity in our case means scarcity of distinct events in comparison to\nthe data size. Previously, we introduced the problem and proposed a distilled\nsensing solution based on the breadth first search strategy. We simulated the\nwhole process which constrained our ability to study the behavior of the\nalgorithm for the entire ensemble due to its computational intensity. In this\npaper, we modify our previous breadth first search strategy and introduce the\ndepth first search strategy. Instead of simulating the entire process, which is\nintractable for a large number of experiments, we provide a dynamic programming\nalgorithm to analyze the behavior of the method for the entire ensemble. The\nensemble analysis algorithm recursively calculates the probability of capturing\nevery distinct genome and also the expected total sequenced nucleotides for a\ngiven population profile. Our results suggest that the expected total sequenced\nnucleotides grows proportional to $\\log$ of the number of cells and\nproportional linearly with the number of distinct genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.6401v2"
    },
    {
        "title": "A Spatial Simulation Approach to Account for Protein Structure When\n  Identifying Non-Random Somatic Mutations",
        "authors": [
            "Gregory Ryslik",
            "Yuwei Cheng",
            "Kei-Hoi Cheung",
            "Robert Bjornson",
            "Daniel Zelterman",
            "Yorgo Modis",
            "Hongyu Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background: Current research suggests that a small set of \"driver\" mutations\nare responsible for tumorigenesis while a larger body of \"passenger\" mutations\noccurs in the tumor but does not progress the disease. Due to recent\npharmacological successes in treating cancers caused by driver mutations, a\nvariety of of methodologies that attempt to identify such mutations have been\ndeveloped. Based on the hypothesis that driver mutations tend to cluster in key\nregions of the protein, the development of cluster identification algorithms\nhas become critical.\n  Results: We have developed a novel methodology, SpacePAC (Spatial Protein\nAmino acid Clustering), that identifies mutational clustering by considering\nthe protein tertiary structure directly in 3D space. By combining the\nmutational data in the Catalogue of Somatic Mutations in Cancer (COSMIC) and\nthe spatial information in the Protein Data Bank (PDB), SpacePAC is able to\nidentify novel mutation clusters in many proteins such as FGFR3 and CHRM2. In\naddition, SpacePAC is better able to localize the most significant mutational\nhotspots as demonstrated in the cases of BRAF and ALK. The R package is\navailable on Bioconductor at:\nhttp://www.bioconductor.org/packages/release/bioc/html/SpacePAC.html\n  Conclusion: SpacePAC adds a valuable tool to the identification of mutational\nclusters while considering protein tertiary structure\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7249v2"
    },
    {
        "title": "A feasible roadmap to identifying significant intercellular genomic\n  heterogeneity in deep sequencing data",
        "authors": [
            "Guoqiang Yu",
            "Roger R. Wang",
            "Sean S. Wang",
            "Niya Wang",
            "Yue Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Intercellular heterogeneity serves as both a confounding factor in studying\nindividual clones and an information source in characterizing any heterogeneous\ntissues, such as blood, tumor systems. Due to inevitable sequencing errors and\nother sample preparation artifacts such as PCR errors, systematic efforts to\ncharacterize intercellular genomic heterogeneity must effectively distinguish\ngenuine clonal sequences from fake derivatives. We developed a novel approach\n(SIGH) for identifying significant genuine clonal sequences directly from mixed\nsequencing reads that can improve genomic analyses in many biological contexts.\nThis method offers several attractive features: (1) it automatically estimates\nthe error rate from raw sequence reads and identifies genuine clonal sequences;\n(2) it is robust to the large variety of error rate due to the various\nexperimental conditions; (3) it is supported by a well grounded statistical\nframework that exploits probabilistic characteristics of sequencing errors; (4)\nits unbiased strategy allows detecting rare clone(s) despite that clone\nrelative abundance; and (5) it estimates constituent proportions in each\nsample. Extensive realistic simulation studies show that our method can\nreliably estimate the error rates and faithfully distinguish the genuine clones\nfrom fake derivatives, paving the way for follow up analysis that is otherwise\nruined by the often dominant fake clones.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7631v2"
    },
    {
        "title": "Can we predict the mutation rate at the single nucleotide scale in the\n  human genome?",
        "authors": [
            "Adam Eyre-Walker",
            "Ying Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  It has been recently claimed that it is possible to predict the rate of de\nnovo mutation of each site in the human genome with almost perfect accuracy\n(Michaelson et al. (2012) Cell, 151, 1431-1442). We show that this claim is\nunwarranted. By considering the correlation between the rate of de novo\nmutation and the predictions from the model of Michaelson et al., we show that\nthere could be substantial unexplained variance in the mutation rate. We also\ndemonstrate that the model of Michaelson et al. fails to capture a major\ncomponent of the variation in the mutation rate, that which is local but not\nassociated with simple context.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7802v1"
    },
    {
        "title": "BACOM 2.0 facilitates absolute normalization and quantification of\n  somatic copy number alterations in heterogeneous tumor",
        "authors": [
            "Yi Fu",
            "Guoqiang Yu",
            "Douglas A. Levine",
            "Niya Wang",
            "Ie-Ming Shih",
            "Zhen Zhang",
            "Robert Clarke",
            "Yue Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  BACOM is a statistically principled and unsupervised method that detects copy\nnumber deletion types (homozygous versus heterozygous), estimates normal cell\nfraction, and recovers cancer specific copy number profiles, using allele\nspecific copy number signals. In a subsequent analysis of TCGA ovarian cancer\ndataset, the average normal cell fraction estimated by BACOM was found higher\nthan expected. In this letter, we first discuss the advantages of the BACOM in\nrelation to alternative approaches. Then, we show that this elevated estimate\nof normal cell fraction is the combined result of inaccurate signal modeling\nand normalization. Lastly, we describe an allele specific signal modeling and\nnormalization scheme that can enhance BACOM applications in many biological\ncontexts. An open source MATLAB program was developed to implement our extended\nmethod and it is publically available.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7865v2"
    },
    {
        "title": "Molecular responses of mouse macrophages to copper and copper oxide\n  nanoparticles inferred from proteomic analyses",
        "authors": [
            "Sarah Triboulet",
            "Catherine Aude-Garcia",
            "Marie Carrière",
            "Hélène Diemer",
            "Fabienne Proamer",
            "Aurélie Habert",
            "Mireille Chevallet",
            "Véronique Collin-Faure",
            "Jean-Marc Strub",
            "Daniel Hanau",
            "Alain Van Dorsselaer",
            "Nathalie Herlin-Boime",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The molecular responses of macrophages to copper-based nanoparticles have\nbeen investigated via a combination of proteomic and biochemical approaches,\nusing the RAW264.7 cell line as a model. Both metallic copper and copper oxide\nnanoparticles have been tested, with copper ion and zirconium oxide\nnanoparticles used as controls. Proteomic analysis highlighted changes in\nproteins implicated in oxidative stress responses (superoxide dismutases and\nperoxiredoxins), glutathione biosynthesis, the actomyosin cytoskeleton, and\nmitochondrial proteins (especially oxidative phosphorylation complex subunits).\nValidation studies employing functional analyses showed that the increases in\nglutathione biosynthesis and in mitochondrial complexes observed in the\nproteomic screen were critical to cell survival upon stress with copper-based\nnanoparticles; pharmacological inhibition of these two pathways enhanced cell\nvulnerability to copper-based nanoparticles, but not to copper ions.\nFurthermore, functional analyses using primary macrophages derived from bone\nmarrow showed a decrease in reduced glutathione levels, a decrease in the\nmitochondrial transmembrane potential, and inhibition of phagocytosis and of\nlipopolysaccharide-induced nitric oxide production. However, only a fraction of\nthese effects could be obtained with copper ions. In conclusion, this study\nshowed that macrophage functions are significantly altered by copper-based\nnanoparticles. Also highlighted are the cellular pathways modulated by cells\nfor survival and the exemplified cross-toxicities that can occur between\ncopper-based nanoparticles and pharmacological agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.0802v1"
    },
    {
        "title": "Comparative Assembly Hubs: Web Accessible Browsers for Comparative\n  Genomics",
        "authors": [
            "Ngan Nguyen",
            "Glenn Hickey",
            "Brian J. Raney",
            "Joel Armstrong",
            "Hiram Clawson",
            "Ann Zweig",
            "Jim Kent",
            "David Haussler",
            "Benedict Paten"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We introduce a pipeline to easily generate collections of web accessible UCSC\ngenome browsers interrelated by an alignment. Using the alignment, all\nannotations and the alignment itself can be efficiently viewed with reference\nto any genome in the collection, symmetrically. A new, intelligently scaled\nalignment display makes it simple to view all changes between the genomes at\nall levels of resolution, from substitutions to complex structural\nrearrangements, including duplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1241v1"
    },
    {
        "title": "Sequencing and characterisation of rearrangements in three S.\n  pastorianus strains reveals the presence of chimeric genes and gives evidence\n  of breakpoint reuse",
        "authors": [
            "Sarah K. Hewitt",
            "Ian Donaldson",
            "Simon C. Lovell",
            "Daniela Delneri"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Gross chromosomal rearrangements have the potential to be evolutionarily\nadvantageous to an adapting organism. The generation of a hybrid species\nincreases opportunity for recombination by bringing together two homologous\ngenomes. We sought to define the location of genomic rearrangements in three\nstrains of Saccharomyces pastorianus, a natural lager-brewing yeast hybrid of\nSaccharomyces cerevisiae and Saccharomyces eubayanus, using whole genome\nshotgun sequencing. Each strain of S. pastorianus has lost species-specific\nportions of its genome and has undergone extensive recombination, producing\nchimeric chromosomes. We predicted 30 breakpoints that we confirmed at the\nsingle nucleotide level by designing species-specific primers that flank each\nbreakpoint, and then sequencing the PCR product. These rearrangements are the\nresult of recombination between areas of homology between the two subgenomes,\nrather than repetitive elements such as transposons or tRNAs. Interestingly,\n28/30 S. cerevisiae- S. eubayanus recombination breakpoints are located within\ngenic regions, generating chimeric genes. Furthermore we show evidence for the\nreuse of two breakpoints, located in HSP82 and KEM1, in strains of proposed\nindependent origin.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1992v1"
    },
    {
        "title": "Improved annotation of 3-prime untranslated regions and complex loci by\n  combination of strand-specific Direct RNA Sequencing, RNA-seq and ESTs",
        "authors": [
            "Nick Schurch",
            "Christian Cole",
            "Alexander Sherstnev",
            "Junfang Song",
            "Céline Duc",
            "Kate G. Storey",
            "W. H. Irwin McLean",
            "Sara J. Brown",
            "Gordon G. Simpson",
            "Geoffrey J. Barton"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The reference annotations made for a genome sequence provide the framework\nfor all subsequent analyses of the genome. Correct annotation is particularly\nimportant when interpreting the results of RNA-seq experiments where short\nsequence reads are mapped against the genome and assigned to genes according to\nthe annotation. Inconsistencies in annotations between the reference and the\nexperimental system can lead to incorrect interpretation of the effect on RNA\nexpression of an experimental treatment or mutation in the system under study.\nUntil recently, the genome-wide annotation of 3-prime untranslated regions\nreceived less attention than coding regions and the delineation of intron/exon\nboundaries. In this paper, data produced for samples in Human, Chicken and A.\nthaliana by the novel single-molecule, strand-specific, Direct RNA Sequencing\ntechnology from Helicos Biosciences which locates 3-prime polyadenylation sites\nto within +/- 2 nt, were combined with archival EST and RNA-Seq data. Nine\nexamples are illustrated where this combination of data allowed: (1) gene and\n3-prime UTR re-annotation (including extension of one 3-prime UTR by 5.9 kb);\n(2) disentangling of gene expression in complex regions; (3) clearer\ninterpretation of small RNA expression and (4) identification of novel genes.\nWhile the specific examples displayed here may become obsolete as genome\nsequences and their annotations are refined, the principles laid out in this\npaper will be of general use both to those annotating genomes and those seeking\nto interpret existing publically available annotations in the context of their\nown experimental data\n",
        "pdf_link": "http://arxiv.org/pdf/1311.2494v1"
    },
    {
        "title": "Progenetix: 12 years of oncogenomic data curation",
        "authors": [
            "Haoyang Cai",
            "Nitin Kumar",
            "Ni Ai",
            "Saumya Gupta",
            "Prisni Rath",
            "Michael Baudis"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  DNA copy number aberrations (CNAs) can be found in the majority of cancer\ngenomes, and are crucial for understanding the potential mechanisms underlying\ntumor initiation and progression. Since the first release in 2001, the\nProgenetix project (http://www.progenetix.org) has provided a reference\nresource dedicated to provide the most comprehensive collection of genome-wide\nCNA profiles. Reflecting the application of comparative genomic hybridization\n(CGH) techniques to tens of thousands of cancer genomes, over the past 12 years\nour data curation efforts have resulted in a more than 60-fold increase in the\nnumber of cancer samples presented through Progenetix. In addition, new data\nexploration tools and visualization options have been added. In particular, the\ngene specific CNA frequency analysis should facilitate the assignment of cancer\ngenes to related cancer types. Additionally, the new user file processing\ninterface allows users to take advantage of the online tools, including various\ndata representation options for proprietary data pre-publication. In this\nupdate article, we report recent improvements of the database in terms of\ncontent, user interface and online tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.2757v1"
    },
    {
        "title": "The genomic landscape of meiotic crossovers and gene conversions in\n  Arabidopsis thaliana",
        "authors": [
            "Erik Wijnker",
            "Geo Velikkakam James",
            "Jia Ding",
            "Frank Becker",
            "Jonas R. Klasen",
            "Vimal Rawat",
            "Beth A. Rowan",
            "Daniel F. de Jong",
            "C. Bastiaan de Snoo",
            "Luis Zapata",
            "Bruno Huettel",
            "Hans de Jong",
            "Stephan Ossowski",
            "Detlef Weigel",
            "Maarten Koornneef",
            "Joost J. B. Keurentjes",
            "Korbinian Schneeberger"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Knowledge of the exact distribution of meiotic crossovers (COs) and gene\nconversions (GCs) is essential for understanding many aspects of population\ngenetics and evolution, from haplotype structure and long-distance genetic\nlinkage to the generation of new allelic variants of genes. To this end, we\nresequenced the four products of 13 meiotic tetrads along with 10 doubled\nhaploids derived from Arabidopsis thaliana hybrids. GC detection through short\nreads has previously been confounded by genomic rearrangements. Rigid filtering\nfor misaligned reads allowed GC identification at high accuracy and revealed an\n~80-kb transposition, which undergoes copy-number changes mediated by meiotic\nrecombination. Non-crossover associated GCs were extremely rare most likely due\nto their short average length of ~25-50 bp, which is significantly shorter than\nthe length of CO associated GCs. Overall, recombination preferentially targeted\nnon-methylated nucleosome-free regions at gene promoters, which showed\nsignificant enrichment of two sequence motifs.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3236v1"
    },
    {
        "title": "MCUIUC -- A New Framework for Metagenomic Read Compression",
        "authors": [
            "Jonathan G. Ligo",
            "Minji Kim",
            "Amin Emad",
            "Olgica Milenkovic",
            "Venugopal V. Veeravalli"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Metagenomics is an emerging field of molecular biology concerned with\nanalyzing the genomes of environmental samples comprising many different\ndiverse organisms. Given the nature of metagenomic data, one usually has to\nsequence the genomic material of all organisms in a batch, leading to a mix of\nreads coming from different DNA sequences. In deep high-throughput sequencing\nexperiments, the volume of the raw reads is extremely high, frequently\nexceeding 600 Gb. With an ever increasing demand for storing such reads for\nfuture studies, the issue of efficient metagenomic compression becomes of\nparamount importance. We present the first known approach to metagenome read\ncompression, termed MCUIUC (Metagenomic Compression at UIUC). The gist of the\nproposed algorithm is to perform classification of reads based on unique\norganism identifiers, followed by reference-based alignment of reads for\nindividually identified organisms, and metagenomic assembly of unclassified\nreads. Once assembly and classification are completed, lossless reference based\ncompression is performed via positional encoding. We evaluate the performance\nof the algorithm on moderate sized synthetic metagenomic samples involving 15\nrandomly selected organisms and describe future directions for improving the\nproposed compression method.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3717v1"
    },
    {
        "title": "When 2D is not enough, go for an extra dimension",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The use of an extra SDS separation in a different buffer system provide a\ntechnique for deconvoluting 2D gel spots made of several proteins (Colignon et\nal. Proteomics, 2013, 13, 2077-2082). This technique keeps the quantitative\nanalysis of the protein amounts and combines it with a strongly improved\nidentification process by mass spectrometry, removing identification\nambiguities in most cases. In some favorable cases, posttranslational variants\ncan be separated by this procedure. This versatile and easy to use technique is\nanticipated to be a very valuable addition to the toolbox used in 2D gel-based\nproteomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3769v1"
    },
    {
        "title": "Multidimensional separation prior to mass spectrometry: Getting closer\n  to the bottom of the iceberg",
        "authors": [
            "Manuel Mayr",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  While prefractionation has previously been shown to improve results in MS\nanalysis, a novel combination provides an additional dimension of separation:\nprotein fractionation by SDS-PAGE followed by IEF of tryptic peptides before\nseparation by RP-LC [Atanassov and Urlaub, Proteomics 2013, 13, 2947-2955].\nThis three-step separation procedure prior to MS/MS substantially increases\nproteome coverage and represents a further step toward a more comprehensive\nanalysis of complex proteomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3770v1"
    },
    {
        "title": "Joint analysis of functional genomic data and genome-wide association\n  studies of 18 human traits",
        "authors": [
            "Joseph K. Pickrell"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Annotations of gene structures and regulatory elements can inform genome-wide\nassociation studies (GWAS). However, choosing the relevant annotations for\ninterpreting an association study of a given trait remains challenging. We\ndescribe a statistical model that uses association statistics computed across\nthe genome to identify classes of genomic element that are enriched or depleted\nfor loci that influence a trait. The model naturally incorporates multiple\ntypes of annotations. We applied the model to GWAS of 18 human traits,\nincluding red blood cell traits, platelet traits, glucose levels, lipid levels,\nheight, BMI, and Crohn's disease. For each trait, we evaluated the relevance of\n450 different genomic annotations, including protein-coding genes, enhancers,\nand DNase-I hypersensitive sites in over a hundred tissues and cell lines. We\nshow that the fraction of phenotype-associated SNPs that influence protein\nsequence ranges from around 2% (for platelet volume) up to around 20% (for LDL\ncholesterol); that repressed chromatin is significantly depleted for SNPs\nassociated with several traits; and that cell type-specific DNase-I\nhypersensitive sites are enriched for SNPs associated with several traits (for\nexample, the spleen in platelet volume). Finally, by re-weighting each GWAS\nusing information from functional genomics, we increase the number of loci with\nhigh-confidence associations by around 5%.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.4843v4"
    },
    {
        "title": "H3K4 mono- and di-methyltransferase MLL4 is required for enhancer\n  activation during cell differentiation",
        "authors": [
            "Ji-Eun Lee",
            "Chaochen Wang",
            "Shiliyang Xu",
            "Young-Wook Cho",
            "Lifeng Wang",
            "Xuesong Feng",
            "Vittorio Sartorelli",
            "Anne Baldridge",
            "Weiqun Peng",
            "Kai Ge"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Enhancers play a central role in cell-type-specific gene expression and are\nmarked by H3K4me1/2. Active enhancers are further marked by H3K27ac. However,\nthe methyltransferases responsible for H3K4me1/2 on enhancers remain elusive.\nFurthermore, how these enzymes function on enhancers to regulate\ncell-type-specific gene expression is unclear. Here we identify MLL4 (KMT2D) as\na major mammalian H3K4 mono- and di-methyltransferase with partial functional\nredundancy with MLL3 (KMT2C). Using adipogenesis and myogenesis as model\nsystems, we show that MLL4 exhibits cell-type- and\ndifferentiation-stage-specific genomic binding and is predominantly localized\non enhancers. MLL4 co-localizes with lineage-determining transcription factors\n(TFs) on active enhancers during differentiation. Deletion of MLL4 markedly\ndecreases H3K4me1/2, H3K27ac, Polymerase II and Mediator levels on enhancers\nand leads to severe defects in cell-type-specific gene expression and cell\ndifferentiation. Together, these findings identify MLL4 as a major mammalian\nH3K4 mono- and di-methyltransferase essential for enhancer activation during\ncell differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.7328v1"
    },
    {
        "title": "How to use 2D gel electrophoresis in plant proteomics",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Two-dimensional electrophoresis has nurtured the birth of proteomics. It is\nhowever no longer the exclusive setup used in proteomics, with the development\nof shotgun proteomics techniques that appear more fancy and fashionable\nnowadays.Nevertheless, 2D gel-based proteomics still has valuable features, and\nsometimes unique ones, which make it often an attractive choice when a\nproteomics strategy must be selected. These features are detailed in this\nchapter, as is the rationale for selecting or not 2D gel-based proteomics as a\nproteomic strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.1057v1"
    },
    {
        "title": "Ribosome profiling reveals post-transcriptional buffering of divergent\n  gene expression in yeast",
        "authors": [
            "Joel McManus",
            "Gemma May",
            "Pieter Spealman",
            "Alan Shteyman"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Understanding the patterns and causes of phenotypic divergence is a central\ngoal in evolutionary biology. Much work has shown that mRNA abundance is highly\nvariable between closely related species. However, the extent and mechanisms of\npost-transcriptional gene regulatory evolution are largely unknown. Here we\nused ribosome profiling to compare transcript abundance and translation\nefficiency in two closely related yeast species (S. cerevisiae and S.\nparadoxus). By comparing translation regulatory divergence to interspecies\ndifferences in mRNA sequence features, we show that differences in transcript\nleaders and codon bias substantially contribute to divergent translation.\nGlobally, we find that translation regulatory divergence often buffers\nspecies-differences in mRNA abundance, such that ribosome occupancy is more\nconserved than transcript abundance. We used allele-specific ribosome profiling\nin interspecies hybrids to compare the relative contributions of cis- and\ntrans-regulatory divergence to species differences in mRNA abundance and\ntranslation efficiency. The mode of gene regulatory divergence differs for\nthese processes, as trans-regulatory changes play a greater role in divergent\nmRNA abundance than in divergent translation efficiency. Strikingly, most genes\nwith aberrant transcript abundance in F1 hybrids (either over- or\nunder-expressed compared to both parent species) did not exhibit aberrant\nribosome occupancy. Our results show that interspecies differences in\ntranslation contribute substantially to the evolution of gene expression.\nCompensatory differences in transcript abundance and translation efficiency may\nincrease the robustness of gene regulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.1765v1"
    },
    {
        "title": "Expanding the Grammar of Biology",
        "authors": [
            "Michel Eduardo Beleza Yamagishi",
            "Roberto Hirochi Herai"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We metaphorically call \"Grammar of Biology\" a small field of genomic\nresearch, whose main objective is to search for intrinsic DNA sequence\nproperties. Erwin Chargaff inaugurated it back in 50s, but since then little\nprogress has been made. It remained almost neglected until early 90s, when\nVinayakumar V. Prabhu made a major contribution determining the Symmetry\nPrinciple. Remarkably, different sciences have contributed for its development,\nfor instance, Chargaff used his Chemistry background to discover the so-called\nChargaff's rules; taking advantage of several publicly available genomic\nsequences, and through Computational and Statistical analyses, Prabhu\nidentified the Symmetry Principle and, recently, using a Mathematical approach,\nwe have discovered four new Generalized Chargaff's rules. Our work has expanded\nthe \"Grammar of Biology\", and created the conceptual and theoretical framework\nnecessary to further developments.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3350v1"
    },
    {
        "title": "FPCB : a simple and swift strategy for mirror repeat identification",
        "authors": [
            "Bhardwaj Vikash",
            "Gupta Swapni",
            "Meena Sitaram",
            "Sharma Kulbhushan"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  After the recent advancement of sequencing strategies, mirror repeats have\nbeen found to be present in the gene sequence of many organisms and species.\nThis presence of mirror repeats in most of the sequences indicates towards some\nimportant functional role of these repeats. However, a simple and quick\nstrategy to search these repeats in a given sequence is not available. We in\nthis manuscript have proposed a simple and swift strategy named as FPCB\nstrategy to identify mirror repeats in a give sequence. The strategy includes\nthree simple steps of downloading sequencing in FASTA format (F), making its\nparallel complement (PC) and finally performing a homology search with the\noriginal sequence (B). At least twenty genes were analyzed using the proposed\nstudy. A number and types of mirror repeats were observed. We have also tried\nto give nomenclature to these repeats. We hope that the proposed FPCB strategy\nwill be quite helpful for the identification of mirror repeats in DNA or mRNA\nsequence. Also the strategy may help in unraveling the functional role of\nmirror repeats in various processes including evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3869v1"
    },
    {
        "title": "CONCOCT: Clustering cONtigs on COverage and ComposiTion",
        "authors": [
            "Johannes Alneberg",
            "Brynjar Smari Bjarnason",
            "Ino de Bruijn",
            "Melanie Schirmer",
            "Joshua Quick",
            "Umer Z. Ijaz",
            "Nicholas J. Loman",
            "Anders F. Andersson",
            "Christopher Quince"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Metagenomics enables the reconstruction of microbial genomes in complex\nmicrobial communities without the need for culturing. Since assembly typically\nresults in fragmented genomes the grouping of genome fragments (contigs)\nbelonging to the same genome, a process referred to as binning, remains a major\ninformatics challenge. Here we present CONCOCT, a computer program that\ncombines three types of information - sequence composition, coverage across\nmultiple sample, and read-pair linkage - to automatically bin contigs into\ngenomes. We demonstrate high recall and precision rates of the program on\nartificial as well as real human gut metagenome datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.4038v1"
    },
    {
        "title": "An Intuitive Graphical Webserver for Multiple-Choice Protein Sequence\n  Search",
        "authors": [
            "Dániel Bánky",
            "Balázs Szalkai",
            "Vince Grolmusz"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Every day tens of thousands of sequence searches and sequence alignment\nqueries are submitted to webservers. The capitalized word \"BLAST\" become a\nverb, describing the act of performing sequence search and alignment. However,\nif one needs to search for sequences that contain, for example, two hydrophobic\nand three polar residues at five given positions, the query formation on the\nmost frequently used webservers will be difficult. Some servers support the\nformation of queries with regular expressions, but most of the users are\nunfamiliar with their syntax. Here we present an intuitive, easily applicable\nwebserver, the Protein Sequence Analysis server, that allows the formation of\nmultiple choice queries by simply drawing the residues to their positions; if\nmore than one residue are drawn to the same position, then they will be nicely\nstacked on the user interface, indicating the multiple choice at he given\nposition. This computer-game like interface is natural and intuitive, and the\ncoloring of the residues makes possible to form queries requiring not just\ncertain amino acids in the given positions, but also small nonpolar, negatively\ncharged, hydrophobic, positively charged, or polar ones. The webserver is\navailable at http://psa.pitgroup.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.4660v1"
    },
    {
        "title": "Sequence Capture Versus Restriction Site Associated DNA Sequencing for\n  Phylogeography",
        "authors": [
            "Michael G. Harvey",
            "Brian Tilston Smith",
            "Travis C. Glenn",
            "Brant C. Faircloth",
            "Robb T. Brumfield"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Genomic datasets generated with massively parallel sequencing methods have\nthe potential to propel systematics in new and exciting directions, but\nselecting appropriate markers and methods is not straightforward. We applied\ntwo approaches with particular promise for systematics, restriction site\nassociated DNA sequencing (RAD-Seq) and sequence capture (Seq-cap) of\nultraconserved elements (UCEs), to the same set of samples from a non-model,\nNeotropical bird. We found that both RAD-Seq and Seq-cap produced genomic\ndatasets containing thousands of loci and SNPs and that the inferred population\nassignments and species trees were concordant between datasets. However,\nmodel-based estimates of demographic parameters differed between datasets,\nparticularly when we estimated the parameters using a method based on allele\nfrequency spectra. The differences we observed may result from differences in\nassembly, alignment, and filtering of sequence data between methods, and our\nfindings suggest that caution is warranted when using allele frequencies to\nestimate parameters from low-coverage sequencing data. We further explored the\ndifferences between methods using simulated Seq-cap- and RAD-Seq-like datasets.\nAnalyses of simulated data suggest that increasing the number of loci from 500\nto 5000 increased phylogenetic concordance factors and the accuracy and\nprecision of demographic parameter estimates, but increasing the number of loci\npast 5000 resulted in minimal gains. Increasing locus length from 64 bp to 500\nbp improved phylogenetic concordance factors and minimal gains were observed\nwith loci longer than 500 bp, but locus length did not influence the accuracy\nand precision of demographic parameter estimates. We discuss our results\nrelative to the diversity of data collection methods available, and we provide\nadvice for harnessing next-generation sequencing for systematics research.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.6439v1"
    },
    {
        "title": "motifDiverge: a model for assessing the statistical significance of gene\n  regulatory motif divergence between two DNA sequences",
        "authors": [
            "Dennis Kostka",
            "Tara Friedrich",
            "Alisha K. Holloway",
            "Katherine S. Pollard"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Next-generation sequencing technology enables the identification of thousands\nof gene regulatory sequences in many cell types and organisms. We consider the\nproblem of testing if two such sequences differ in their number of binding site\nmotifs for a given transcription factor (TF) protein. Binding site motifs\nimpart regulatory function by providing TFs the opportunity to bind to genomic\nelements and thereby affect the expression of nearby genes. Evolutionary\nchanges to such functional DNA are hypothesized to be major contributors to\nphenotypic diversity within and between species; but despite the importance of\nTF motifs for gene expression, no method exists to test for motif loss or gain.\nAssuming that motif counts are Binomially distributed, and allowing for\ndependencies between motif instances in evolutionarily related sequences, we\nderive the probability mass function of the difference in motif counts between\ntwo nucleotide sequences. We provide a method to numerically estimate this\ndistribution from genomic data and show through simulations that our estimator\nis accurate. Finally, we introduce the R package {\\tt motifDiverge} that\nimplements our methodology and illustrate its application to gene regulatory\nenhancers identified by a mouse developmental time course experiment. While\nthis study was motivated by analysis of regulatory motifs, our results can be\napplied to any problem involving two correlated Bernoulli trials.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.0042v1"
    },
    {
        "title": "MUSIC: A Hybrid Computing Environment for Burrows-Wheeler Alignment for\n  Massive Amount of Short Read Sequence Data",
        "authors": [
            "Saurabh Gupta",
            "Sanjoy Chaudhury 'and' Binay Panda"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  High-throughput DNA sequencers are becoming indispensable in our\nunderstanding of diseases at molecular level, in marker-assisted selection in\nagriculture and in microbial genetics research. These sequencing instruments\nproduce enormous amount of data (often terabytes of raw data in a month) that\nrequires efficient analysis, management and interpretation. The commonly used\nsequencing instrument today produces billions of short reads (upto 150 bases)\nfrom each run. The first step in the data analysis step is alignment of these\nshort reads to the reference genome of choice. There are different open source\nalgorithms available for sequence alignment to the reference genome. These\ntools normally have a high computational overhead, both in terms of number of\nprocessors and memory. Here, we propose a hybrid-computing environment called\nMUSIC (Mapping USIng hybrid Computing) for one of the most popular open source\nsequence alignment algorithm, BWA, using accelerators that show significant\nimprovement in speed over the serial code.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.0632v1"
    },
    {
        "title": "Alignment-free comparison of next-generation sequencing data using\n  compression-based distance measures",
        "authors": [
            "Ngoc Hieu Tran",
            "Xin Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Enormous volumes of short reads data from next-generation sequencing (NGS)\ntechnologies have posed new challenges to the area of genomic sequence\ncomparison.\n  The multiple sequence alignment approach is hardly applicable to NGS data due\nto the challenging problem of short read assembly.\n  Thus alignment-free methods need to be developed for the comparison of NGS\nsamples of short reads.\n  Recently, new $k$-mer based distance measures such as {\\it CVTree},\n$d_{2}^{S}$, {\\it co-phylog} have been proposed to address this problem.\n  However, those distances depend considerably on the parameter $k$, and how to\nchoose the optimal $k$ is not trivial since it may depend on different aspects\nof the sequence data.\n  Hence, in this paper we consider an alternative parameter-free approach:\ncompression-based distance measures.\n  These measures have shown impressive performance on long genome sequences in\nprevious studies, but they have not been tested on NGS short reads.\n  In this study we perform extensive validation and show that the\ncompression-based distances are highly consistent with those distances obtained\nfrom the $k$-mer based methods, from the alignment-based approach, and from\nexisting benchmarks in the literature.\n  Moreover, as these measures are parameter-free, no optimization is required\nand they still perform consistently well on multiple types of sequence data,\nfor different kinds of species and taxonomy levels.\n  The compression-based distance measures are assembly-free, alignment-free,\nparameter-free, and thus represent useful tools for the comparison of long\ngenome sequences and NGS samples of short reads.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.0640v1"
    },
    {
        "title": "RADIA: RNA and DNA Integrated Analysis for Somatic Mutation Detection",
        "authors": [
            "Amie J. Radenbaugh",
            "Singer Ma",
            "Adam Ewing",
            "Joshua Stuart",
            "Eric Collisson",
            "Jingchun Zhu",
            "David Haussler"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  The detection of somatic single nucleotide variants is a crucial component to\nthe characterization of the cancer genome. Mutation calling algorithms thus far\nhave focused on comparing the normal and tumor genomes from the same\nindividual. In recent years, it has become routine for projects like The Cancer\nGenome Atlas (TCGA) to also sequence the tumor RNA. Here we present RADIA (RNA\nand DNA Integrated Analysis), a method that combines the patient-matched normal\nand tumor DNA with the tumor RNA to detect somatic mutations. The inclusion of\nthe RNA increases the power to detect somatic mutations, especially at low DNA\nallelic frequencies. By integrating the DNA and RNA, we are able to rescue back\ncalls that would be missed by traditional mutation calling algorithms that only\nexamine the DNA.\n  RADIA was developed for the identification of somatic mutations using both\nDNA and RNA from the same individual. We demonstrate high sensitivity (84%) and\nvery high specificity (98% and 99%) in real data from endometrial carcinoma and\nlung adenocarcinoma from TCGA. Mutations with both high DNA and RNA read\nsupport have the highest validation rate of over 99%. We also introduce a\nsimulation package that spikes in artificial mutations to real data, rather\nthan simulating sequencing data from a reference genome. We evaluate\nsensitivity on the simulation data and demonstrate our ability to rescue back\ncalls at low DNA allelic frequencies by including the RNA. Finally, we\nhighlight mutations in important cancer genes that were rescued back due to the\nincorporation of the RNA.\n  Software available at https://github.com/aradenbaugh/radia/\n",
        "pdf_link": "http://arxiv.org/pdf/1402.0850v1"
    },
    {
        "title": "Cross-phenotype meta-analysis reveals large-scale trans-eQTLs mediating\n  patterns of transcriptional co-regulation",
        "authors": [
            "Boel Brynedal",
            "Towfique Raj",
            "Barbara E Stranger",
            "Robert Bjornson",
            "Benjamin M Neale",
            "Benjamin F Voight",
            "Chris Cotsapas"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Genetic variation affecting gene regulation is a central driver of phenotypic\ndifferences between individuals and can be used to uncover how biological\nprocesses are organized in a cell. Although detecting cis-eQTLs is now routine,\ntrans-eQTLs have proven more challenging to find due to the modest variance\nexplained and the multiple tests burden of testing millions of SNPs for\nassociation to thousands of transcripts. Here, we successfully map trans-eQTLs\nwith the complementary approach of looking for SNPs associated to the\nexpression of multiple genes simultaneously. We find 732 trans- eQTLs that\nreplicate across two continental populations; each trans-eQTL controls large\ngroups of target transcripts (regulons), which are part of interacting networks\ncontrolled by transcription factors. We are thus able to uncover co-regulated\ngene sets and begin describing the cell circuitry of gene regulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1728v1"
    },
    {
        "title": "The mathematics of the genetic code reveal that frequency degeneracy\n  leads to exponential scaling in the DNA codon distribution of Homo sapiens",
        "authors": [
            "Bohdan B. Khomtchouk"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  The nature of the quantitative distribution of the 64 DNA codons in the human\ngenome has been an issue of debate for over a decade. Some groups have proposed\nthat the quantitative distribution of the DNA codons ordered as a\nrank-frequency plot follows a well-known power law called Zipf's law. Others\nhave shown that the DNA codon distribution is best fitted to an exponential\nfunction. However, the reason for such scaling behavior has not yet been\naddressed. In the present study, we demonstrate that the nonlinearity of the\nDNA codon distribution is a direct consequence of the frequency recurrence of\nthe codon usage (i.e., the repetitiveness of codon usage frequencies at the\nwhole genome level). We discover that if frequency recurrence is absent from\nthe human genome, the frequency of occurrence of codons scales linearly with\nthe codon rank. We also show that DNA codons of both low and high frequency of\noccurrence in the genome are best fitted by an exponential function and provide\nstrong evidence to suggest that the coding region of the human genome does not\nfollow Zipf's law. Information-theoretic methods and entropy calculations are\napplied to the DNA codon distribution and a new approach, called the lariat\nmethod, is proposed to quantitatively analyze the DNA codon distribution in\nHomo sapiens.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.4095v3"
    },
    {
        "title": "Near-optimal Assembly for Shotgun Sequencing with Noisy Reads",
        "authors": [
            "Ka-Kit Lam",
            "Asif Khalak",
            "David Tse"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Recent work identified the fundamental limits on the information requirements\nin terms of read length and coverage depth required for successful de novo\ngenome reconstruction from shotgun sequencing data, based on the idealistic\nassumption of no errors in the reads (noiseless reads). In this work, we show\nthat even when there is noise in the reads, one can successfully reconstruct\nwith information requirements close to the noiseless fundamental limit. A new\nassembly algorithm, X-phased Multibridging, is designed based on a\nprobabilistic model of the genome. It is shown through analysis to perform well\non the model, and through simulations to perform well on real genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6971v1"
    },
    {
        "title": "MaxSSmap: A GPU program for mapping divergent short reads to genomes\n  with the maximum scoring subsequence",
        "authors": [
            "Turki Turki",
            "Usman Roshan"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Programs based on hash tables and Burrows-Wheeler are very fast for mapping\nshort reads to genomes but have low accuracy in the presence of mismatches and\ngaps. Such reads can be aligned accurately with the Smith-Waterman algorithm\nbut it can take hours and days to map millions of reads even for bacteria\ngenomes. We introduce a GPU program called MaxSSmap with the aim of achieving\ncomparable accuracy to Smith-Waterman but with faster runtimes. Similar to most\nprograms MaxSSmap identifies a local region of the genome followed by exact\nalignment. Instead of using hash tables or Burrows-Wheeler in the first part,\nMaxSSmap calculates maximum scoring subsequence score between the read and\ndisjoint fragments of the genome in parallel on a GPU and selects the highest\nscoring fragment for exact alignment. We evaluate MaxSSmap's accuracy and\nruntime when mapping simulated Illumina E.coli and human chromosome one reads\nof different lengths and 10\\% to 30\\% mismatches with gaps to the E.coli genome\nand human chromosome one. We also demonstrate applications on real data by\nmapping ancient horse DNA reads to modern genomes and unmapped paired reads\nfrom NA12878 in 1000 genomes. We show that MaxSSmap attains comparable high\naccuracy and low error to fast Smith-Waterman programs yet has much lower\nruntimes. We show that MaxSSmap can map reads rejected by BWA and NextGenMap\nwith high accuracy and low error much faster than if Smith-Waterman were used.\nOn short read lengths of 36 and 51 both MaxSSmap and Smith-Waterman have lower\naccuracy compared to at higher lengths. On real data MaxSSmap produces many\nalignments with high score and mapping quality that are not given by NextGenMap\nand BWA. The MaxSSmap source code is freely available from\nhttp://www.cs.njit.edu/usman/MaxSSmap.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.2136v3"
    },
    {
        "title": "Genetic influences on translation in yeast",
        "authors": [
            "Frank W. Albert",
            "Dale Muzzey",
            "Jonathan Weissman",
            "Leonid Kruglyak"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Heritable differences in gene expression between individuals are an important\nsource of phenotypic variation. The question of how closely the effects of\ngenetic variation on protein levels mirror those on mRNA levels remains open.\nHere, we addressed this question by using ribosome profiling to examine how\ngenetic differences between two strains of the yeast S. cerevisiae affect\ntranslation. Strain differences in translation were observed for hundreds of\ngenes. Allele specific measurements in the diploid hybrid between the two\nstrains revealed roughly half as many cis-acting effects on translation as were\nobserved for mRNA levels. In both the parents and the hybrid, most effects on\ntranslation were of small magnitude, such that the direction of an mRNA\ndifference was typically reflected in a concordant footprint difference. The\nrelative importance of cis and trans acting variation on footprint levels was\nsimilar to that for mRNA levels. There was a tendency for translation to cause\nlarger footprint differences than expected given the respective mRNA\ndifferences. This is in contrast to translational differences between yeast\nspecies that have been reported to more often oppose than reinforce mRNA\ndifferences. Finally, we catalogued instances of premature translation\ntermination in the two yeast strains and also found several instances where\nerroneous reference gene annotations lead to apparent nonsense mutations that\nin fact reside outside of the translated gene body. Overall, genetic influences\non translation subtly modulate gene expression differences, and translation\ndoes not create strong discrepancies between genetic influences on mRNA and\nprotein levels.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.3449v2"
    },
    {
        "title": "The proteomic to biology inference, a frequently overlooked concern in\n  the interpretation of proteomic data: A plea for functional validation",
        "authors": [
            "Thierry Rabilloud",
            "Pierre Lescuyer"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Proteomics will celebrate its 20th year in 2014. In this relatively short\nperiod of time, it has invaded most areas of biology and its use will probably\ncontinue to spread in the future. These two decades have seen a considerable\nincrease in the speed and sensitivity of protein identification and\ncharacterization, even from complex samples. Indeed, what was a challenge\ntwenty years ago is now little more than a daily routine. Although not\ncompletely over, the technological challenge now makes room to another\nchallenge, which is the best possible appraisal and exploitation of proteomic\ndata to draw the best possible conclusions from a biological point of view. The\npoint developed in this paper is that proteomic data are almost always\nfragmentary. This means in turn that although better than an mRNA level, a\nprotein level is often insufficient to draw a valid conclusion from a\nbiological point of view, especially in a world where PTMs play such an\nimportant role. This means in turn that transformation of proteomic data into\nbiological data requires an important intermediate layer of functional\nvalidation, i.e. not merely the confirmation of protein abundance changes by\nother methods, but a functional appraisal of the biological consequences of the\nprotein level changes highlighted by the proteomic screens.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.5414v1"
    },
    {
        "title": "SAMBLASTER: fast duplicate marking and structural variant read\n  extraction",
        "authors": [
            "Gregory G. Faust",
            "Ira M. Hall"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation: Illumina DNA sequencing is now the predominant source of raw\ngenomic data, and data volumes are growing rapidly. Bioinformatic analysis\npipelines are having trouble keeping pace. A common bottleneck in such\npipelines is the requirement to read, write, sort and compress large BAM files\nmultiple times.\n  Results: We present SAMBLASTER, a tool that reduces the number of times such\ncostly operations are performed. SAMBLASTER is designed to mark duplicates in\nread-sorted SAM files as a piped post-pass on DNA aligner output before it is\ncompressed to BAM. In addition, it can simultaneously output into separate\nfiles the discordant read-pairs and/or split-read mappings used for structural\nvariant calling. As an alignment post-pass, its own runtime overhead is\nnegligible, while dramatically reducing overall pipeline complexity and\nruntime. As a stand-alone duplicate marking tool, it performs significantly\nbetter than PICARD or SAMBAMBA in terms of both speed and memory usage, while\nachieving nearly identical results.\n  Availability: SAMBLASTER is open source C++ code and freely available from\nhttps://github.com/GregoryFaust/samblaster\n",
        "pdf_link": "http://arxiv.org/pdf/1403.7486v1"
    },
    {
        "title": "Identifying the Genetic Basis of Functional Protein Evolution Using\n  Reconstructed Ancestors",
        "authors": [
            "Victor Hanson-Smith",
            "Christopher Baker",
            "Alexander Johnson"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  A central challenge in the study of protein evolution is the identification\nof historic amino acid sequence changes responsible for creating novel\nfunctions observed in present-day proteins. To address this problem, we\ndeveloped a new method to identify and rank amino acid mutations in ancestral\nprotein sequences according to their function-shifting potential. Our approach\nscans the changes between two reconstructed ancestral sequences in order to\nfind (1) sites with sequence changes that significantly deviate from our\nmodel-based probabilistic expectations, (2) sites that demonstrate extreme\nchanges in mutual information, and (3) sites with extreme gains or losses of\ninformation content. By taking the overlaps of these statistical signals, the\nmethod accurately identifies cryptic evolutionary patterns that are often not\nobvious when examining only the conservation of modern-day protein sequences.\nWe validated this method with a training set of previously-discovered\nfunction-shifting mutations in three essential protein families in animals and\nfungi, whose evolutionary histories were the prior subject of systematic\nmolecular biological investigation. Our method identified the known\nfunction-shifting mutations in the training set with a very low rate of false\npositive discovery. Further, our approach significantly outperformed other\nmethods that use variability in evolutionary rates to detect functional loci.\nThe accuracy of our approach indicates it could be a useful tool for generating\nspecific testable hypotheses regarding the acquisition of new functions across\na wide range of protein families.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.3067v1"
    },
    {
        "title": "Genome disorder and breast cancer susceptibility",
        "authors": [
            "Conor Smyth",
            "Iva Špakulova",
            "Owen Cotton-Barratt",
            "Sajjad Rafiq",
            "William Tapper",
            "Rosanna Upstill-Goddard",
            "John L. Hopper",
            "Enes Makalic",
            "Daniel F. Schmidt",
            "Miroslav Kapuscinski",
            "Jörg Fliege",
            "Andrew Collins",
            "Jacek Brodzki",
            "Diana M. Eccles",
            "Ben D. MacArthur"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Many common diseases have a complex genetic basis in which large numbers of\ngenetic variations combine with environmental and lifestyle factors to\ndetermine risk. However, quantifying such polygenic effects and their\nrelationship to disease risk has been challenging. In order to address these\ndifficulties we developed a global measure of the information content of an\nindividual's genome relative to a reference population, which may be used to\nassess differences in global genome structure between cases and appropriate\ncontrols. Informally this measure, which we call relative genome information\n(RGI), quantifies the relative \"disorder\" of an individual's genome. In order\nto test its ability to predict disease risk we used RGI to compare single\nnucleotide polymorphism genotypes from two independent samples of women with\nearly-onset breast cancer with three independent sets of controls. We found\nthat RGI was significantly elevated in both sets of breast cancer cases in\ncomparison with all three sets of controls, with disease risk rising sharply\nwith RGI (odds ratio greater than 12 for the highest percentile RGI).\nFurthermore, we found that these differences are not due to associations with\ncommon variants at a small number of disease-associated loci, but rather are\ndue to the combined associations of thousands of markers distributed throughout\nthe genome. Our results indicate that the information content of an\nindividual's genome may be used to measure the risk of a complex disease, and\nsuggest that early-onset breast cancer has a strongly polygenic basis.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.3828v1"
    },
    {
        "title": "Mapping the Space of Genomic Signatures",
        "authors": [
            "Lila Kari",
            "Kathleen A. Hill",
            "Abu S. Sayem",
            "Rallis Karamichalis",
            "Nathaniel Bryans",
            "Katelyn Davis",
            "Nikesh S. Dattani"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  We propose a computational method to measure and visualize interrelationships\namong any number of DNA sequences allowing, for example, the examination of\nhundreds or thousands of complete mitochondrial genomes. An \"image distance\" is\ncomputed for each pair of graphical representations of DNA sequences, and the\ndistances are visualized as a Molecular Distance Map: Each point on the map\nrepresents a DNA sequence, and the spatial proximity between any two points\nreflects the degree of structural similarity between the corresponding\nsequences. The graphical representation of DNA sequences utilized, Chaos Game\nRepresentation (CGR), is genome- and species-specific and can thus act as a\ngenomic signature. Consequently, Molecular Distance Maps could inform species\nidentification, taxonomic classifications and, to a certain extent,\nevolutionary history. The image distance employed, Structural Dissimilarity\nIndex (DSSIM), implicitly compares the occurrences of oligomers of length up to\n$k$ (herein $k=9$) in DNA sequences. We computed DSSIM distances for more than\n5 million pairs of complete mitochondrial genomes, and used Multi-Dimensional\nScaling (MDS) to obtain Molecular Distance Maps that visually display the\nsequence relatedness in various subsets, at different taxonomic levels. This\ngeneral-purpose method does not require DNA sequence homology and can thus be\nused to compare similar or vastly different DNA sequences, genomic or\ncomputer-generated, of the same or different lengths. We illustrate potential\nuses of this approach by applying it to several taxonomic subsets: phylum\nVertebrata, (super)kingdom Protista, classes Amphibia-Insecta-Mammalia, class\nAmphibia, and order Primates. This analysis of an extensive dataset confirms\nthat the oligomer composition of full mtDNA sequences can be a source of\ntaxonomic information.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.4105v2"
    },
    {
        "title": "BEETL-fastq: a searchable compressed archive for DNA reads",
        "authors": [
            "Lilian Janin",
            "Ole Schulz-Trieglaff",
            "Anthony J. Cox"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation:\n  FASTQ is a standard file format for DNA sequencing data which stores both\nnucleotides and quality scores. A typical sequencing study can easily generate\nhundreds of gigabytes of FASTQ files, while public archives such as ENA and\nNCBI and large international collaborations such as the Cancer Genome Atlas can\naccumulate many terabytes of data in this format. Text compression tools such\nas gzip are often employed to reduce the storage burden, but have the\ndisadvantage that the data must be decompressed before it can be used.\n  Here we present BEETL-fastq, a tool that not only compresses FASTQ-formatted\nDNA reads more compactly than gzip, but also permits rapid search for $k$-mer\nqueries within the archived sequences. Importantly, the full FASTQ record of\neach matching read or read pair is returned, allowing the search results to be\npiped directly to any of the many standard tools that accept FASTQ data as\ninput.\n  Results:\n  We show that 6.6 terabytes of human reads in FASTQ format can be transformed\ninto 1.7 terabytes of indexed files, from where we can search for 1, 10, 100,\n1000, a million of 30-mers in respectively 3, 8, 14, 45 and 567 seconds plus 20\nms per output read. Useful applications of the search capability are\nhighlighted, including the genotyping of structural variant breakpoints and \"in\nsilico pull-down\" experiments in which only the reads that cover a region of\ninterest are selectively extracted for the purposes of variant calling or\nvisualization.\n  Availability:\n  BEETL-fastq is part of the BEETL library, available as a github repository at\ngit@github.com:BEETL/BEETL.git.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.4376v1"
    },
    {
        "title": "Assessing Technical Performance in Differential Gene Expression\n  Experiments with External Spike-in RNA Control Ratio Mixtures",
        "authors": [
            "Sarah A. Munro",
            "Steve P. Lund",
            "P. Scott Pine",
            "Hans Binder",
            "Djork-Arné Clevert",
            "Ana Conesa",
            "Joaquin Dopazo",
            "Mario Fasold",
            "Sepp Hochreiter",
            "Huixiao Hong",
            "Nederah Jafari",
            "David P. Kreil",
            "Paweł P. Łabaj",
            "Sheng Li",
            "Yang Liao",
            "Simon Lin",
            "Joseph Meehan",
            "Christopher E. Mason",
            "Javier Santoyo",
            "Robert A. Setterquist",
            "Leming Shi",
            "Wei Shi",
            "Gordon K. Smyth",
            "Nancy Stralis-Pavese",
            "Zhenqiang Su",
            "Weida Tong",
            "Charles Wang",
            "Jian Wang",
            "Joshua Xu",
            "Zhan Ye",
            "Yong Yang",
            "Ying Yu",
            "Marc Salit"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  There is a critical need for standard approaches to assess, report, and\ncompare the technical performance of genome-scale differential gene expression\nexperiments. We assess technical performance with a proposed \"standard\"\ndashboard of metrics derived from analysis of external spike-in RNA control\nratio mixtures. These control ratio mixtures with defined abundance ratios\nenable assessment of diagnostic performance of differentially expressed\ntranscript lists, limit of detection of ratio (LODR) estimates, and expression\nratio variability and measurement bias. The performance metrics suite is\napplicable to analysis of a typical experiment, and here we also apply these\nmetrics to evaluate technical performance among laboratories. An\ninterlaboratory study using identical samples shared amongst 12 laboratories\nwith three different measurement processes demonstrated generally consistent\ndiagnostic power across 11 laboratories. Ratio measurement variability and bias\nwere also comparable amongst laboratories for the same measurement process.\nDifferent biases were observed for measurement processes using different mRNA\nenrichment protocols.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.4893v1"
    },
    {
        "title": "Robust identification of noncoding RNA from transcriptomes requires\n  phylogenetically-informed sampling",
        "authors": [
            "Stinus Lindgreen",
            "Sinan Ugur Umu",
            "Alicia Sook-Wei Lai",
            "Hisham Eldai",
            "Wenting Liu",
            "Stephanie McGimpsey",
            "Nicole Wheeler",
            "Patrick J. Biggs",
            "Nick R. Thomson",
            "Lars Barquist",
            "Anthony M. Poole",
            "Paul P. Gardner"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Noncoding RNAs are integral to a wide range of biological processes,\nincluding translation, gene regulation, host-pathogen interactions and\nenvironmental sensing. While genomics is now a mature field, our capacity to\nidentify noncoding RNA elements in bacterial and archaeal genomes is hampered\nby the difficulty of de novo identification. The emergence of new technologies\nfor characterizing transcriptome outputs, notably RNA-seq, are improving\nnoncoding RNA identification and expression quantification. However, a major\nchallenge is to robustly distinguish functional outputs from transcriptional\nnoise. To establish whether annotation of existing transcriptome data has\neffectively captured all functional outputs, we analysed over 400 publicly\navailable RNA-seq datasets spanning 37 different Archaea and Bacteria. Using\ncomparative tools, we identify close to a thousand highly-expressed candidate\nnoncoding RNAs. However, our analyses reveal that capacity to identify\nnoncoding RNA outputs is strongly dependent on phylogenetic sampling.\nSurprisingly, and in stark contrast to protein-coding genes, the phylogenetic\nwindow for effective use of comparative methods is perversely narrow:\naggregating public datasets only produced one phylogenetic cluster where these\ntools could be used to robustly separate unannotated noncoding RNAs from a null\nhypothesis of transcriptional noise. Our results show that for the full\npotential of transcriptomics data to be realized, a change in experimental\ndesign is paramount: effective transcriptomics requires phylogeny-aware\nsampling.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.7133v3"
    },
    {
        "title": "Conservation and losses of avian non-coding RNA loci",
        "authors": [
            "Paul P. Gardner",
            "Mario Fasold",
            "Sarah W. Burge",
            "Maria Ninova",
            "Jana Hertel",
            "Stephanie Kehr",
            "Tammy E. Steeves",
            "Sam Griffiths-Jones",
            "Peter F. Stadler"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Here we present the results of a large-scale bioinformatic annotation of\nnon-coding RNA loci in 48 avian genomes. Our approach uses probabilistic models\nof hand-curated families from the Rfam database to infer conserved RNA families\nwithin each avian genome. We supplement these annotations with predictions from\nthe tRNA annotation tool, tRNAscan-SE and microRNAs from miRBase. We show that\na number of lncRNA-associated loci are conserved between birds and mammals,\nincluding several intriguing cases where the reported mammalian lncRNA function\nis not conserved in birds. We also demonstrate extensive conservation of\nclassical ncRNAs (e.g., tRNAs) and more recently discovered ncRNAs (e.g.,\nsnoRNAs and miRNAs) in birds. Furthermore, we describe numerous \"losses\" of\nseveral RNA families, and attribute these to genuine loss, divergence or\nmissing data. In particular, we show that many of these losses are due to the\nchallenges associated with assembling Avian microchromosomes. These combined\nresults illustrate the utility of applying homology-based methods for\nannotating novel vertebrate genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.7140v1"
    },
    {
        "title": "Revised Annotations, Sex-Biased Expression, and Lineage-Specific Genes\n  in the Drosophila melanogaster group",
        "authors": [
            "Rebekah L. Rogers",
            "Ling Shao",
            "Jaleal S. Sanjak",
            "Peter Andolfatto",
            "Kevin R. Thornton"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Here, we provide revised gene models for D. ananassae, D. yakuba, and D.\nsimulans, which include UTRs and empirically verified intron-exon boundaries,\nas well as ortholog groups identified using a fuzzy reciprocal-best-hit blast\ncomparison. Using these revised annotations, we perform differential expression\ntesting using the cufflinks suite to provide a broad overview of differential\nexpression between reproductive tissues and the carcass. We identify thousands\nof genes that are differentially expressed across tissues in D. yakuba and D.\nsimulans, with roughly 60% agreement in expression patterns of orthologs in D.\nyakuba and D. simulans. We identify several cases of putative polycistronic\ntranscripts, pointing to a combination of transcriptional read-through in the\ngenome as well as putative gene fusion and fission events across taxa. We\nfurthermore identify hundreds of lineage specific genes in each species with no\nblast hits among transcripts of any other Drosophila species, which are\ncandidates for neofunctionalized proteins and a potential source of genetic\nnovelty.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.0247v2"
    },
    {
        "title": "Integrative multi-omics module network inference with Lemon-Tree",
        "authors": [
            "Eric Bonnet",
            "Laurence Calzone",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Module network inference is an established statistical method to reconstruct\nco-expression modules and their upstream regulatory programs from integrated\nmulti-omics datasets measuring the activity levels of various cellular\ncomponents across different individuals, experimental conditions or time points\nof a dynamic process. We have developed Lemon-Tree, an open-source,\nplatform-independent, modular, extensible software package implementing\nstate-of-the-art ensemble methods for module network inference. We benchmarked\nLemon-Tree using large-scale tumor datasets and showed that Lemon-Tree\nalgorithms compare favorably with state-of-the-art module network inference\nsoftware. We also analyzed a large dataset of somatic copy-number alterations\nand gene expression levels measured in glioblastoma samples from The Cancer\nGenome Atlas and found that Lemon-Tree correctly identifies known glioblastoma\noncogenes and tumor suppressors as master regulators in the inferred module\nnetwork. Novel candidate driver genes predicted by Lemon-Tree were validated\nusing tumor pathway and survival analyses. Lemon-Tree is available from\nhttp://lemon-tree.googlecode.com under the GNU General Public License version\n2.0.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.0472v2"
    },
    {
        "title": "Paleoproteomics explained to youngsters: how did the wedding of\n  two-dimensional electrophoresis and protein sequencing spark proteomics on:\n  Let there be light",
        "authors": [
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Taking the opportunity of the 20th anniversary of the word \"proteomics\", this\nyoung adult age is a good time to remember how proteomics came from enormous\nprogress in protein separation and protein microanalysis techniques, and from\nthe conjugation of these advances into a high performance and streamlined\nworking setup. However, in the history of the almost three decades that\nencompass the first attempts to perform large scale analysis of proteins to the\ncurrent high throughput proteomics that we can enjoy now, it is also\ninteresting to underline and to recall how difficult the first decade was.\nIndeed when the word was cast, the battle was already won. This recollection is\nmostly devoted to the almost forgotten period where proteomics was being\nconceived and put to birth, as this collective scientific work will never\nappear when searched through the keyword \"proteomics\". BIOLOGICAL SIGNIFICANCE:\nThe significance of this manuscript is to recall and review the two decades\nthat separated the first attempts of performing large scale analysis of\nproteins from the solid technical corpus that existed when the word\n\"proteomics\" was coined twenty years ago. This recollection is made within the\nscientific historical context of this decade, which also saw the blossoming of\nDNA cloning and sequencing. This article is part of a Special Issue entitled:\n20 years of Proteomics in memory of Viatliano Pallini. Guest Editors: Luca Bini\n, Juan J. Calvete, Natacha Turck, Denis Hochstrasser and Jean-Charles Sanchez.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.1325v1"
    },
    {
        "title": "The degenerative evolution from multicellularity to unicellularity\n  during cancer",
        "authors": [
            "Han Chen",
            "Fangqin Lin",
            "Xionglei He"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Theoretical reasoning suggests that human cancer may result from knocking\ndown the genetic constraints evolved for maintenance of the metazoan\nmulticellularity, which, however, requires a critical test. Using\nxenograft-based experimental evolution we characterized for the first time the\nfull life history from initiation to metastasis of a tumor at the genomic and\ntranscriptomic levels, and observed metastasis-driving positive selection for\ngenerally loss-of-function mutations on a set of multicellularity-related\ngenes, which is further supported by large-scale exome data of clinical tumor\nsamples. Subsequent expression analysis revealed mainly expression\ndown-regulation of multicellularity-related genes, which form an evolving\nexpression profile approaching that of embryonic stem cells, the cell type with\nthe most characteristics of unicellular life. The theoretical conjecture\npredicts that genes born at the emergence of metazoan multicellularity tend to\nbe cancer drivers, which we validated using a rigorous phylostratigraphy\nanalysis on the birth rate of genes annotated by Cancer Gene Census. Also, the\nnumber of loss-of-function tumor suppressors often predominates over activated\noncogenes in a typical tumor of human patients. These data collectively suggest\nthat, different from typical organismal evolution in which gain of new genes is\nthe mainstream, cancer represents a loss-of-function-driven degenerative\nevolution back to the unicellular ground state. This cancer evolution model may\nexplain the enormous tumoral genetic heterogeneity in the clinic, underlie how\ndistant-organ metastases originate in primary tumors despite distinct\nenvironmental requirements, and hold implications for designing effective\ncancer therapy.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.3236v1"
    },
    {
        "title": "On the genetic architecture of intelligence and other quantitative\n  traits",
        "authors": [
            "Stephen D. H. Hsu"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  How do genes affect cognitive ability or other human quantitative traits such\nas height or disease risk? Progress on this challenging question is likely to\nbe significant in the near future. I begin with a brief review of psychometric\nmeasurements of intelligence, introducing the idea of a \"general factor\" or g\nscore. The main results concern the stability, validity (predictive power), and\nheritability of adult g. The largest component of genetic variance for both\nheight and intelligence is additive (linear), leading to important\nsimplifications in predictive modeling and statistical estimation. Due mainly\nto the rapidly decreasing cost of genotyping, it is possible that within the\ncoming decade researchers will identify loci which account for a significant\nfraction of total g variation. In the case of height analogous efforts are well\nunder way. I describe some unpublished results concerning the genetic\narchitecture of height and cognitive ability, which suggest that roughly 10k\nmoderately rare causal variants of mostly negative effect are responsible for\nnormal population variation. Using results from Compressed Sensing\n(L1-penalized regression), I estimate the statistical power required to\ncharacterize both linear and nonlinear models for quantitative traits. The main\nunknown parameter s (sparsity) is the number of loci which account for the bulk\nof the genetic variation. The required sample size is of order 100s, or roughly\na million in the case of cognitive ability.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.3421v2"
    },
    {
        "title": "Assembly of repetitive regions using next-generation sequencing data",
        "authors": [
            "Robert M. Nowak"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  High read depth can be used to assemble short sequence repeats. The existing\ngenome assemblers fail in repetitive regions of longer than average read.\n  I propose a new algorithm for a DNA assembly which uses the relative\nfrequency of reads to properly reconstruct repetitive sequences. The\nmathematical model shows the upper limits of accuracy of the results as a\nfunction of read coverage. For high coverage, the estimation error depends\nlinearly on repetitive sequence length and inversely proportional to the\nsequencing coverage. The algorithm requires high read depth, provided by the\nnext-generation sequencers and could use the existing data. The tests on\nerrorless reads, generated in silico from several model genomes, pointed the\nproperly reconstructed repetitive sequences, where existing assemblers fail.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.0395v1"
    },
    {
        "title": "Analysis of correlation structures in the Synechocystis PCC6803 genome",
        "authors": [
            "Zuo-Bing Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Transfer of nucleotide strings in the Synechocystis sp. PCC6803 genome is\ninvestigated to exhibit periodic and non-periodic correlation structures by\nusing the recurrence plot method and the phase space reconstruction technique.\nThe periodic correlation structures are generated by periodic transfer of\nseveral substrings in long periodic or non-periodic nucleotide strings embedded\nin the coding regions of genes. The non-periodic correlation structures are\ngenerated by non-periodic transfer of several substrings covering or\noverlapping with the coding regions of genes. In the periodic and non-periodic\ntransfer, some gaps divide the long nucleotide strings into the substrings and\nprevent their global transfer. Most of the gaps are either the replacement of\none base or the insertion/reduction of one base. In the reconstructed phase\nspace, the points generated from two or three steps for the continuous\niterative transfer via the second maximal distance can be fitted by two lines.\nIt partly reveals an intrinsic dynamics in the transfer of nucleotide strings.\nDue to the comparison of the relative positions and lengths, the substrings\nconcerned with the non-periodic correlation structures are almost identical to\nthe mobile elements annotated in the genome. The mobile elements are thus\nendowed with the basic results on the correlation structures.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.4121v1"
    },
    {
        "title": "Estimation of the methylation pattern distribution from deep sequencing\n  data",
        "authors": [
            "Peijie Lin",
            "Sylvain Foret",
            "Susan R. Wilson",
            "Conrad J. Burden"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation: Bisulphite sequencing enables the detection of cytosine\nmethylation. The sequence of the methylation states of cytosines on any given\nread forms a methylation pattern that carries substantially more information\nthan merely studying the average methylation level at individual positions. In\norder to understand better the complexity of DNA methylation landscapes in\nbiological samples, it is important to study the diversity of these methylation\npatterns. However, the accurate quantification of methylation patterns is\nsubject to sequencing errors and spurious signals due to incomplete bisulphite\nconversion of cytosines. Results: A statistical model is developed which\naccounts for the distribution of DNA methylation patterns at any given locus.\nThe model incorporates the effects of sequencing errors and spurious reads, and\nenables estimation of the true underlying distribution of methylation patterns.\nConclusions: Calculation of the estimated distribution over methylation\npatterns is implemented in the R Bioconductor package MPFE. Source code and\ndocumentation of the package are also available for download at\nhttp://bioconductor.org/packages/3.0/bioc/html/MPFE.html.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.2419v1"
    },
    {
        "title": "TREEOME: A framework for epigenetic and transcriptomic data integration\n  to explore regulatory interactions controlling transcription",
        "authors": [
            "David M Budden",
            "Daniel G Hurley",
            "Edmund J Crampin"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Motivation: Predictive modelling of gene expression is a powerful framework\nfor the in silico exploration of transcriptional regulatory interactions\nthrough the integration of high-throughput -omics data. A major limitation of\nprevious approaches is their inability to handle conditional and synergistic\ninteractions that emerge when collectively analysing genes subject to different\nregulatory mechanisms. This limitation reduces overall predictive power and\nthus the reliability of downstream biological inference.\n  Results: We introduce an analytical modelling framework (TREEOME: tree of\nmodels of expression) that integrates epigenetic and transcriptomic data by\nseparating genes into putative regulatory classes. Current predictive modelling\napproaches have found both DNA methylation and histone modification epigenetic\ndata to provide little or no improvement in accuracy of prediction of\ntranscript abundance despite, for example, distinct anti-correlation between\nmRNA levels and promoter-localised DNA methylation. To improve on this, in\nTREEOME we evaluate four possible methods of formulating gene-level DNA\nmethylation metrics, which provide a foundation for identifying gene-level\nmethylation events and subsequent differential analysis, whereas most previous\ntechniques operate at the level of individual CpG dinucleotides. We demonstrate\nTREEOME by integrating gene-level DNA methylation (bisulfite-seq) and histone\nmodification (ChIP-seq) data to accurately predict genome-wide mRNA transcript\nabundance (RNA-seq) for H1-hESC and GM12878 cell lines.\n  Availability: TREEOME is implemented using open-source software and made\navailable as a pre-configured bootable reference environment. All scripts and\ndata presented in this study are available online at\nhttp://sourceforge.net/projects/budden2015treeome/.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.01409v1"
    },
    {
        "title": "Correcting Illumina sequencing errors for human data",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Summary: We present a new tool to correct sequencing errors in Illumina data\nproduced from high-coverage whole-genome shotgun resequencing. It uses a\nnon-greedy algorithm and shows comparable performance and higher accuracy in an\nevaluation on real human data. This evaluation has the most complete collection\nof high-performance error correctors so far.\n  Availability and implementation: https://github.com/lh3/bfc\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1502.03744v1"
    },
    {
        "title": "Approximating the Minimum Breakpoint Linearization Problem for Genetic\n  Maps without Gene Strandedness",
        "authors": [
            "Xin Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The study of genetic map linearization leads to a combinatorial hard problem,\ncalled the {\\em minimum breakpoint linearization} (MBL) problem. It is aimed at\nfinding a linearization of a partial order which attains the minimum breakpoint\ndistance to a reference total order. The approximation algorithms previously\ndeveloped for the MBL problem are only applicable to genetic maps in which\ngenes or markers are represented as signed integers. However, current genetic\nmapping techniques generally do not specify gene strandedness so that genes can\nonly be represented as unsigned integers. In this paper, we study the MBL\nproblem in the latter more realistic case. An approximation algorithm is thus\ndeveloped, which achieves a ratio of $(m^2+2m-1)$ and runs in $O(n^7)$ time,\nwhere $m$ is the number of genetic maps used to construct the input partial\norder and $n$ the total number of distinct genes in these maps.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07083v1"
    },
    {
        "title": "Phen-Gen: combining phenotype and genotype to analyze rare disorders",
        "authors": [
            "Asif Javed",
            "Saloni Agrawal",
            "Pauline C. Ng"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We introduce Phen-Gen, a method which combines patient disease symptoms and\nsequencing data with prior domain knowledge to identify the causative gene(s)\nfor rare disorders.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07829v1"
    },
    {
        "title": "An investigation into inter- and intragenomic variations of graphic\n  genomic signatures",
        "authors": [
            "Rallis Karamichalis",
            "Lila Kari",
            "Stavros Konstantinidis",
            "Steffen Kopecki"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We provide, on an extensive dataset and using several different distances,\nconfirmation of the hypothesis that CGR patterns are preserved along a genomic\nDNA sequence, and are different for DNA sequences originating from genomes of\ndifferent species. This finding lends support to the theory that CGRs of\ngenomic sequences can act as graphic genomic signatures. In particular, we\ncompare the CGR patterns of over five hundred different 150,000 bp genomic\nsequences originating from the genomes of six organisms, each belonging to one\nof the kingdoms of life: H. sapiens, S. cerevisiae, A. thaliana, P. falciparum,\nE. coli, and P. furiosus. We also provide preliminary evidence of this method's\napplicability to closely related species by comparing H. sapiens (chromosome\n21) sequences and over one hundred and fifty genomic sequences, also 150,000 bp\nlong, from P. troglodytes (Animalia; chromosome Y), for a total length of more\nthan 101 million basepairs analyzed. We compute pairwise distances between CGRs\nof these genomic sequences using six different distances, and construct\nMolecular Distance Maps that visualize all sequences as points in a\ntwo-dimensional or three-dimensional space, to simultaneously display their\ninterrelationships. Our analysis confirms that CGR patterns of DNA sequences\nfrom the same genome are in general quantitatively similar, while being\ndifferent for DNA sequences from genomes of different species. Our analysis of\nthe performance of the assessed distances uses three different quality measures\nand suggests that several distances outperform the Euclidean distance, which\nhas so far been almost exclusively used for such studies. In particular we show\nthat, for this dataset, DSSIM (Structural Dissimilarity Index) and the\ndescriptor distance (introduced here) are best able to classify genomic\nsequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00162v2"
    },
    {
        "title": "HetFHMM: A novel approach to infer tumor heterogeneity using factorial\n  Hidden Markov model",
        "authors": [
            "Gholamreza Haffari",
            "Zhaoxiang Cai",
            "Mohammad S. Rahman",
            "Ann E. Nicholson"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Cancer arises from successive rounds of mutations which generate tumor cells\nwith different genomic variation i.e. clones. For drug responsiveness and\ntherapeutics, it is necessary to identify the clones in tumor sample\naccurately. Many methods are developed to infer tumor heterogeneity by either\ncomputing cellular prevalence and tumor phylogeny or predicting genotype of\nmutations. All methods suffer some problems e.g. inaccurate computation of\nclonal frequencies, discarding clone specific genotypes etc. In the paper, we\npropose a method, called- HetFHMM to infer tumor heterogeneity by predicting\nclone specific genotypes and cellular prevalence. To infer clone specific\ngenotype, we consider the presence of multiple mutations at any genomic\nlocation. We also tested our model on different simulated data. The results\nshows that HetFHMM outperforms recent methods which infer tumor heterogeneity.\nTherefore, HetFHMM is a novel approach in tumor heterogeneity research area.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00486v1"
    },
    {
        "title": "Reliable scaling of Position Weight Matrices for binding strength\n  comparisons between transcription factors",
        "authors": [
            "Xiaoyan Ma",
            "Daphne Ezer",
            "Carmen Navarro",
            "Boris Adryan"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Scoring DNA sequences against Position Weight Matrices (PWMs) is a widely\nadopted method to identify putative transcription factor binding sites. While\ncommon bioinformatics tools produce scores that can reflect the binding\nstrength between a specific transcription factor and the DNA, these scores are\nnot directly comparable between different transcription factors. Here, we\nprovide two different ways to find the scaling parameter $\\lambda$ that allows\nus to infer binding energy from a PWM score. The first approach uses a PWM and\nbackground genomic sequence as input to estimate $\\lambda$ for a specific\ntranscription factor, which we applied to show that $\\lambda$ distributions for\ndifferent transcription factor families correspond with their DNA binding\nproperties. Our second method can reliably convert $\\lambda$ between different\nPWMs of the same transcription factor, which allows us to directly compare PWMs\nthat were generated by different approaches. These two approaches provide\nconsistent and computationally efficient ways to scale PWMs scores and estimate\ntranscription factor binding sites strength.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.04992v1"
    },
    {
        "title": "The \"Giant Virus Finder\" Discovers an Abundance of Giant Viruses in the\n  Antarctic Dry Valleys",
        "authors": [
            "Csaba Kerepesi",
            "Vince Grolmusz"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The first giant virus was identified in 2003 from a biofilm of an industrial\nwater-cooling tower in England. Later, numerous new giant viruses were found in\noceans and freshwater habitats, some of them having even 2,500 genes. We have\ndemonstrated their very likely presence in four soil samples taken from the\nKutch Desert (Gujarat, India). Here we describe a bioinformatics work-flow,\ncalled the \"Giant Virus Finder\" that is capable to discover the very likely\npresence of the genomes of giant viruses in metagenomic shotgun-sequenced\ndatasets. The new tool is applied to numerous hot and cold desert soil samples\nas well as some tundra- and forest soils. We show that most of these samples\ncontain giant viruses, and especially many were found in the Antarctic dry\nvalleys. The results imply that giant viruses could be frequent not only in\naqueous habitats, but in a wide spectrum of soils on our planet.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05575v3"
    },
    {
        "title": "Long and short range multi-locus QTL interactions in a complex trait of\n  yeast",
        "authors": [
            "Evgeny M. Mirkes",
            "Thomas Walsh",
            "Edward J. Louis",
            "Alexander N. Gorban"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We analyse interactions of Quantitative Trait Loci (QTL) in heat selected\nyeast by comparing them to an unselected pool of random individuals. Here we\nre-examine data on individual F12 progeny selected for heat tolerance, which\nhave been genotyped at 25 locations identified by sequencing a selected pool\n[Parts, L., Cubillos, F. A., Warringer, J., Jain, K., Salinas, F., Bumpstead,\nS. J., Molin, M., Zia, A., Simpson, J. T., Quail, M. A., Moses, A., Louis, E.\nJ., Durbin, R., and Liti, G. (2011). Genome research, 21(7), 1131-1138]. 960\nindividuals were genotyped at these locations and multi-locus genotype\nfrequencies were compared to 172 sequenced individuals from the original\nunselected pool (a control group). Various non-random associations were found\nacross the genome, both within chromosomes and between chromosomes. Some of the\nnon-random associations are likely due to retention of linkage disequilibrium\nin the F12 population, however many, including the inter-chromosomal\ninteractions, must be due to genetic interactions in heat tolerance. One region\nof particular interest involves 3 linked loci on chromosome IV where the\ncentral variant responsible for heat tolerance is antagonistic, coming from the\nheat sensitive parent and the flanking ones are from the more heat tolerant\nparent. The 3-locus haplotypes in the selected individuals represent a highly\nbiased sample of the population haplotypes with rare double recombinants in\nhigh frequency. These were missed in the original analysis and would never be\nseen without the multigenerational approach. We show that a statistical\nanalysis of entropy and information gain in genotypes of a selected population\ncan reveal further interactions than previously seen. Importantly this must be\ndone in comparison to the unselected population's genotypes to account for\ninherent biases in the original population.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05869v1"
    },
    {
        "title": "Hox genes underlie metazoan development, but what controls them?",
        "authors": [
            "Raffaele Di Giacomo",
            "Bruno Maresca",
            "Jeffrey H. Schwartz"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Although metazoan development is conceived as resulting from gene regulatory\nnetworks (GRNs) controlled by Hox genes, a better analogy is computer\narchitecture: i.e., a task accomplished in sequential steps linked to an\nexternal referent that \"counts\" each step. A developmental \"step\" equals the\nexpression of genes in specific cells at specific times and telomeres represent\nexternal \"counters\" wherein \"counting\" is a function of telomere shortening at\neach cell division that permits the sequential expression of Hox genes and,\nultimately, complex form. Metazoan development thus best resembles a Turing\nmachine, which could be used to model the development of any metazoan.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06969v1"
    },
    {
        "title": "RNF: a general framework to evaluate NGS read mappers",
        "authors": [
            "Karel Břinda",
            "Valentina Boeva",
            "Gregory Kucherov"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Aligning reads to a reference sequence is a fundamental step in numerous\nbioinformatics pipelines. As a consequence, the sensitivity and precision of\nthe mapping tool, applied with certain parameters to certain data, can\ncritically affect the accuracy of produced results (e.g., in variant calling\napplications). Therefore, there has been an increasing demand of methods for\ncomparing mappers and for measuring effects of their parameters.\n  Read simulators combined with alignment evaluation tools provide the most\nstraightforward way to evaluate and compare mappers. Simulation of reads is\naccompanied by information about their positions in the source genome. This\ninformation is then used to evaluate alignments produced by the mapper.\nFinally, reports containing statistics of successful read alignments are\ncreated.\n  In default of standards for encoding read origins, every evaluation tool has\nto be made explicitly compatible with the simulator used to generate reads. In\norder to solve this obstacle, we have created a generic format RNF (Read Naming\nFormat) for assigning read names with encoded information about original\npositions.\n  Futhermore, we have developed an associated software package RNF containing\ntwo principal components. MIShmash applies one of popular read simulating tools\n(among DwgSim, Art, Mason, CuReSim etc.) and transforms the generated reads\ninto RNF format. LAVEnder evaluates then a given read mapper using simulated\nreads in RNF format. A special attention is payed to mapping qualities that\nserve for parametrization of ROC curves, and to evaluation of the effect of\nread sample contamination.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.00556v1"
    },
    {
        "title": "Inference of Markovian Properties of Molecular Sequences from NGS Data\n  and Applications to Comparative Genomics",
        "authors": [
            "Jie Ren",
            "Kai Song",
            "Minghua Deng",
            "Gesine Reinert",
            "Charles H. Cannon",
            "Fengzhu Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Next Generation Sequencing (NGS) technologies generate large amounts of short\nread data for many different organisms. The fact that NGS reads are generally\nshort makes it challenging to assemble the reads and reconstruct the original\ngenome sequence. For clustering genomes using such NGS data, word-count based\nalignment-free sequence comparison is a promising approach, but for this\napproach, the underlying expected word counts are essential.\n  A plausible model for this underlying distribution of word counts is given\nthrough modelling the DNA sequence as a Markov chain (MC). For single long\nsequences, efficient statistics are available to estimate the order of MCs and\nthe transition probability matrix for the sequences. As NGS data do not provide\na single long sequence, inference methods on Markovian properties of sequences\nbased on single long sequences cannot be directly used for NGS short read data.\n  Here we derive a normal approximation for such word counts. We also show that\nthe traditional Chi-square statistic has an approximate gamma distribution,\nusing the Lander-Waterman model for physical mapping. We propose several\nmethods to estimate the order of the MC based on NGS reads and evaluate them\nusing simulations. We illustrate the applications of our results by clustering\ngenomic sequences of several vertebrate and tree species based on NGS reads\nusing alignment-free sequence dissimilarity measures. We find that the\nestimated order of the MC has a considerable effect on the clustering results,\nand that the clustering results that use a MC of the estimated order give a\nplausible clustering of the species.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.00959v1"
    },
    {
        "title": "PopIns: population-scale detection of novel sequence insertions",
        "authors": [
            "Birte Kehr",
            "Páll Melsted",
            "Bjarni V. Halldórsson"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The detection of genomic structural variation (SV) has advanced tremendously\nin recent years due to progress in high-throughput sequencing technologies.\nNovel sequence insertions, insertions without similarity to a human reference\ngenome, have received less attention than other types of SVs due to the\ncomputational challenges in their detection from short read sequencing data,\nwhich inherently involves de novo assembly. De novo assembly is not only\ncomputationally challenging, but also requires high-quality data. While the\nreads from a single individual may not always meet this requirement, using\nreads from multiple individuals can increase power to detect novel insertions.\nWe have developed the program PopIns, which can discover and characterize\nnon-reference insertions of 100 bp or longer on a population scale. In this\npaper, we describe the approach we implemented in PopIns. It takes as input a\nreads-to-reference alignment, assembles unaligned reads using a standard\nassembly tool, merges the contigs of different individuals into high-confidence\nsequences, anchors the merged sequences into the reference genome, and finally\ngenotypes all individuals for the discovered insertions. Our tests on simulated\ndata indicate that the merging step greatly improves the quality and\nreliability of predicted insertions and that PopIns shows significantly better\nrecall and precision than the recent tool MindTheGap. Preliminary results on a\ndata set of 305 Icelanders demonstrate the practicality of the new approach.\nThe source code of PopIns is available from http://github.com/bkehr/popins.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.01813v1"
    },
    {
        "title": "Más allá del GWAS: alternativas para localizar QTLs",
        "authors": [
            "Filippo Biscarini",
            "Stefano Biffani",
            "Alessandra Stella"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Beyond GWAS: alternatives to localize QTLs in farm animals. Two methods that\ncould be used for QTL mapping as alternatives to standard GWAS are presented.\nThe first relies on the differential frequency of runs of homozygosity (ROH) in\ngroups of animals (e.g. cases and controls), while the second stems from\nresampling techniques used for the prediction of carriers of a mutation, and is\nbased on the frequency of inclusion of polymorphisms (SNP) in the predictive\nmodel. ROH were applied to the detection of reproductive diseases in\nHolstein-Friesian cattle, while resampling was applied to the detection of\ncarriers of the BH2 haplotype in Brown Swiss cattle. These alternative\napproaches may complement GWAS analyses in localizing more accurately QTLs for\ntraits of interest in livestock.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.03802v1"
    },
    {
        "title": "Computational reconstruction of mitochondria-encoded mammal ancestral\n  proteins",
        "authors": [
            "Bohdan Kozarzewski"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  A method based on mapping a symbolic sequence into a set of patterns (strings\nresulting from the sequence parsing) is proposed as a tool for the\nreconstruction of ancestral sequences. The set union of patterns comprises all\nthe patterns present in the family of related proteins sequences of an extant\nspecies. The set of most frequent patterns among protein sequences is selected\nand concatenated. The resulting sequence of amino acids is supposed to be the\nancestral protein of the family. No sequences alignment and phylogenetic tree\nof the species family are necessary. The method is used for inferring the\nancestral amino acid sequences of thirteen mitochondria-encoded protein\nfamilies of mammal species. Statistical distribution of the similarity between\nextant and ancestral sequences exhibits some structures related to\nenvironmental changes in the past.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.03845v1"
    },
    {
        "title": "Triander: A new program for visual analysis of nucleotide sequences",
        "authors": [
            "Volodymyr Duplij",
            "Steven Duplij"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The Triander program is an interactive software package for nucleotide\nsequence visualization. The program was developed using the freeware Pascal RAD\nIDE Lazarus, and its source code and binaries compiled for Windows are freely\naccessible at http://www.icbge.org.ua/eng/Triander . Triander can produce four\ntypes of plots. It is possible to build three DNA walks independently for each\nnucleotide position in triplets. The use of nucleotide vectors with unequal\nmodulus leads to a significant reduction in the visual information lost in DNA\nwalks. The program can be used in the investigation of the fine structure of\nsequences, to find standard patterns in them and to locate nontrivial regions\nfor further detailed analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.04866v2"
    },
    {
        "title": "Exploring genetic variation in the tomato (Solanum section Lycopersicon)\n  clade by whole-genome sequencing",
        "authors": [
            "Saulo A. Aflitos",
            "Elio Schijlen",
            "Richard Finkers",
            "Sandra Smit",
            "Jun Wang",
            "Gengyun Zhang",
            "Ning Li",
            "Likai Mao",
            "Hans de Jong",
            "Freek Bakker",
            "Barbara Gravendeel",
            "Timo Breit",
            "Rob Dirks",
            "Henk Huits",
            "Darush Struss",
            "Ruth Wagner",
            "Hans van Leeuwen",
            "Roeland van Ham",
            "Laia Fito",
            "Laëtitia Guigner",
            "Myrna Sevilla",
            "Philippe Ellul",
            "Eric W. Ganko",
            "Arvind Kapur",
            "Emmanuel Reclus",
            "Bernard de Geus",
            "Henri van de Geest",
            "Bas te Lintel Hekkert",
            "Jan C. Van Haarst",
            "Lars Smits",
            "Andries Koops",
            "Gabino Sanchez Perez",
            "Dick de Ridder",
            "Sjaak van Heusden",
            "Richard Visser",
            "Zhiwu Quan",
            "Jiumeng Min",
            "Li Liao",
            "Xiaoli Wang",
            "Guangbiao Wang",
            "Zhen Yue",
            "Xinhua Yang",
            "Na Xu",
            "Eric Schranz",
            "Eric F. Smets",
            "Rutger A. Vos",
            "Han Rauwerda",
            "Remco Ursem",
            "Cees Schuit",
            "Mike Kerns",
            "Jan van den Berg",
            "Wim H. Vriezen",
            "Antoine Janssen",
            "Torben Jahrman",
            "Frederic Moquet",
            "Julien Bonnet",
            "Sander A. Peters"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genetic variation in the tomato clade was explored by sequencing a selection\nof 84 tomato accessions and related wild species representative for the\nLycopersicon, Arcanum, Eriopersicon, and Neolycopersicon groups. We present a\nreconstruction of three new reference genomes in support of our comparative\ngenome analyses. Sequence diversity in commercial breeding lines appears\nextremely low, indicating the dramatic genetic erosion of crop tomatoes. This\nis reflected by the SNP count in wild species which can exceed 10 million i.e.\n20 fold higher than in crop accessions. Comparative sequence alignment reveals\ngroup, species, and accession specific polymorphisms, which explain\ncharacteristic fruit traits and growth habits in tomato accessions. Using gene\nmodels from the annotated Heinz reference genome, we observe a bias in dN/dS\nratio in fruit and growth diversification genes compared to a random set of\ngenes, which probably is the result of a positive selection. We detected highly\ndivergent segments in wild S. lycopersicum species, and footprints of\nintrogressions in crop accessions originating from a common donor accession.\nPhylogenetic relationships of fruit diversification and growth specific genes\nfrom crop accessions show incomplete resolution and are dependent on the\nintrogression donor. In contrast, whole genome SNP information has sufficient\npower to resolve the phylogenetic placement of each accession in the four main\ngroups in the Lycopersicon clade using Maximum Likelihood analyses.\nPhylogenetic relationships appear correlated with habitat and mating type and\npoint to the occurrence of geographical races within these groups and thus are\nof practical importance for introgressive hybridization breeding. Our study\nillustrates the need for multiple reference genomes in support of tomato\ncomparative genomics and Solanum genome evolution studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.05610v1"
    },
    {
        "title": "Introgression Browser: High throughput whole-genome SNP visualization",
        "authors": [
            "Saulo Alves Aflitos",
            "Gabino Sanchez-Perez",
            "Dick de Ridder",
            "Paul Fransz",
            "Eric Schranz",
            "Hans de Jong",
            "Sander Peters"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Breeding by introgressive hybridization is a pivotal strategy to broaden the\ngenetic basis of crops. Usually, the desired traits are monitored in\nconsecutive crossing generations by marker-assisted selection, but their\nanalyses fail in chromosome regions where crossover recombinants are rare or\nnot viable. Here, we present the Introgression Browser (IBROWSER), a novel\nbioinformatics tool aimed at visualizing introgressions at nucleotide or SNP\naccuracy. The software selects homozygous SNPs from Variant Call Format (VCF)\ninformation and filters out heterozygous SNPs, Multi-Nucleotide Polymorphisms\n(MNPs) and insertion-deletions (InDels). For data analysis IBROWSER makes use\nof sliding windows, but if needed it can generate any desired fragmentation\npattern through General Feature Format (GFF) information. In an example of\ntomato (Solanum lycopersicum) accessions we visualize SNP patterns and\nelucidate both position and boundaries of the introgressions. We also show that\nour tool is capable of identifying alien DNA in a panel of the closely related\nS. pimpinellifolium by examining phylogenetic relationships of the introgressed\nsegments in tomato. In a third example, we demonstrate the power of the\nIBROWSER in a panel of 600 Arabidopsis accessions, detecting the boundaries of\na SNP-free region around a polymorphic 1.17 Mbp inverted segment on the short\narm of chromosome 4. The architecture and functionality of IBROWSER makes the\nsoftware appropriate for a broad set of analyses including SNP mining, genome\nstructure analysis, and pedigree analysis. Its functionality, together with the\ncapability to process large data sets and efficient visualization of sequence\nvariation, makes IBROWSER a valuable breeding tool.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.05612v1"
    },
    {
        "title": "FermiKit: assembly-based variant calling for Illumina resequencing data",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Summary: FermiKit is a variant calling pipeline for Illumina data. It de novo\nassembles short reads and then maps the assembly against a reference genome to\ncall SNPs, short insertions/deletions (INDELs) and structural variations (SVs).\nFermiKit takes about one day to assemble 30-fold human whole-genome data on a\nmodern 16-core server with 85GB RAM at the peak, and calls variants in half an\nhour to an accuracy comparable to the current practice. FermiKit assembly is a\nreduced representation of raw data while retaining most of the original\ninformation.\n  Availability and implementation: https://github.com/lh3/fermikit\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06574v1"
    },
    {
        "title": "benchNGS : An approach to benchmark short reads alignment tools",
        "authors": [
            "Farzana Rahman",
            "Mehedi Hassan",
            "Alona Kryshchenko",
            "Inna Dubchak",
            "Tatiana V. Tatarinova",
            "Nickolai Alexandrov"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  In the last decade a number of algorithms and associated software have been\ndeveloped to align next generation sequencing (NGS) reads with relevant\nreference genomes. The accuracy of these programs may vary significantly,\nespecially when the NGS reads are quite different from the available reference\ngenome. We propose a benchmark to assess accuracy of short reads mapping based\non the pre-computed global alignment of related genome sequences.\n  In this paper we propose a benchmark to assess accuracy of the short reads\nmapping based on the pre-computed global alignment of closely related genome\nsequences. We outline the method and also present a short report of an\nexperiment performed on five popular alignment tools based on the pairwise\nalignments of Escherichia coli O6 CFT073 genome with genomes of seven other\nbacteria.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06659v1"
    },
    {
        "title": "Nucleotide 9-mers Characterize the Type II Diabetic Gut Metagenome",
        "authors": [
            "Balázs Szalkai",
            "Vince Grolmusz"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Discoveries of new biomarkers for frequently occurring diseases are of\nspecial importance in today's medicine. While fully developed type II diabetes\n(T2D) can be detected easily, the early identification of high risk individuals\nis an area of interest in T2D, too. Metagenomic analysis of the human bacterial\nflora has shown subtle changes in diabetic patients, but no specific microbes\nare known to cause or promote the disease. Moderate changes were also detected\nin the microbial gene composition of the metagenomes of diabetic patients, but\nagain, no specific gene was found that is present in disease-related and\nmissing in healthy metagenome. However, these fine differences in microbial\ntaxon- and gene composition are difficult to apply as quantitative biomarkers\nfor diagnosing or predicting type II diabetes. In the present work we report\nsome nucleotide 9-mers with significantly differing frequencies in diabetic and\nhealthy intestinal flora. To our knowledge, it is the first time such short DNA\nfragments have been associated with T2D. The automated, quantitative analysis\nof the frequencies of short nucleotide sequences seems to be more feasible than\naccurate phylogenetic and functional analysis, and thus it might be a promising\ndirection of diagnostic research.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.00476v1"
    },
    {
        "title": "Statistical models for RNA-seq data derived from a two-condition\n  48-replicate experiment",
        "authors": [
            "Marek Gierliński",
            "Christian Cole",
            "Pietà Schofield",
            "Nicholas J. Schurch",
            "Alexander Sherstnev",
            "Vijender Singh",
            "Nicola Wrobel",
            "Karim Gharbi",
            "Gordon Simpson",
            "Tom Owen-Hughes",
            "Mark Blaxter",
            "Geoffrey J. Barton"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  High-throughput RNA sequencing (RNA-seq) is now the standard method to\ndetermine differential gene expression. Identifying differentially expressed\ngenes crucially depends on estimates of read count variability. These estimates\nare typically based on statistical models such as the negative binomial\ndistribution, which is employed by the tools edgeR, DESeq and cuffdiff. Until\nnow, the validity of these models has usually been tested on either\nlow-replicate RNA-seq data or simulations. A 48-replicate RNA-seq experiment in\nyeast was performed and data tested against theoretical models. The observed\ngene read counts were consistent with both log-normal and negative binomial\ndistributions, while the mean-variance relation followed the line of constant\ndispersion parameter of ~0.01. The high-replicate data also allowed for strict\nquality control and screening of bad replicates, which can drastically affect\nthe gene read-count distribution. RNA-seq data have been submitted to ENA\narchive with project ID PRJEB5348.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.00588v1"
    },
    {
        "title": "Evaluation of tools for differential gene expression analysis by RNA-seq\n  on a 48 biological replicate experiment",
        "authors": [
            "Nicholas J. Schurch",
            "Pieta Schofield",
            "Marek Gierliński",
            "Christian Cole",
            "Alexander Sherstnev",
            "Vijender Singh",
            "Nicola Wrobel",
            "Karim Gharbi",
            "Gordon G. Simpson",
            "Tom Owen-Hughes",
            "Mark Blaxter",
            "Geoffrey J. Barton"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  An RNA-seq experiment with 48 biological replicates in each of 2 conditions\nwas performed to determine the number of biological replicates ($n_r$)\nrequired, and to identify the most effective statistical analysis tools for\nidentifying differential gene expression (DGE). When $n_r=3$, seven of the nine\ntools evaluated give true positive rates (TPR) of only 20 to 40 percent. For\nhigh fold-change genes ($|log_{2}(FC)|\\gt2$) the TPR is $\\gt85$ percent. Two\ntools performed poorly; over- or under-predicting the number of differentially\nexpressed genes. Increasing replication gives a large increase in TPR when\nconsidering all DE genes but only a small increase for high fold-change genes.\nAchieving a TPR $\\gt85$% across all fold-changes requires $n_r\\gt20$. For\nfuture RNA-seq experiments these results suggest $n_r\\gt6$, rising to\n$n_r\\gt12$ when identifying DGE irrespective of fold-change is important. For\n$6 \\lt n_r \\lt 12$, superior TPR makes edgeR the leading tool tested. For $n_r\n\\ge12$, minimizing false positives is more important and DESeq outperforms the\nother tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.02017v2"
    },
    {
        "title": "BACOM2: a Java tool for detecting normal cell contamination of copy\n  number in heterogeneous tumor",
        "authors": [
            "Yi Fu",
            "Jun Ruan",
            "Guoqiang Yu",
            "Douglas A. Levine",
            "Niya Wang",
            "Ie-Ming Shih",
            "Zhen Zhang",
            "Robert Clarke",
            "Yue Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We develop a cross-platform open-source Java application (BACOM2) with\ngraphic user interface (GUI), and users also can use a XML file to set the\nparameters of algorithm model, file paths and the dataset of paired samples.\nBACOM2 implements the new entire pipeline of copy number change analysis for\nheterogeneous cancer tissues, including extraction of raw copy number signals\nfrom CEL files of paired samples, attenuation correction, identification of\nbalanced AB-genotype loci, copy number detection and segmentation, global\nbaseline calculation and absolute normalization, differentiation of deletion\ntypes, estimation of the normal tissue fraction and correction of normal tissue\ncontamination. BACOM2 focuses on the common tools for data preparation and\nabsolute normalization for copy number analysis of heterogeneous cancer\ntissues. The software provides an additional choice for scientists who require\na user-friendly, high-speed processing, cross-platform computing environment\nfor large copy number data analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.04295v1"
    },
    {
        "title": "Dynamics of Wolbachia pipientis gene expression across the Drosophila\n  melanogaster life cycle",
        "authors": [
            "Florence Gutzwiller",
            "Catarina R. Carmo",
            "Danny E. Miller",
            "Danny W. Rice",
            "Irene L. Newton",
            "R. Scott Hawley",
            "Luis Teixeira",
            "Casey M. Bergman"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Symbiotic interactions between microbes and their multicellular hosts have\nmanifold impacts on molecular, cellular and organismal biology. To identify\ncandidate bacterial genes involved in maintaining endosymbiotic associations\nwith insect hosts, we analyzed genome-wide patterns of gene expression in the\nalpha-proteobacteria Wolbachia pipientis across the life cycle of Drosophila\nmelanogaster using public data from the modENCODE project that was generated in\na Wolbachia-infected version of the ISO1 reference strain. We find that the\nmajority of Wolbachia genes are expressed at detectable levels in D.\nmelanogaster across the entire life cycle, but that only 7.8% of 1195 Wolbachia\ngenes exhibit robust stage- or sex-specific expression differences when studied\nin the \"holo-organism\" context. Wolbachia genes that are differentially\nexpressed during development are typically up-regulated after D. melanogaster\nembryogenesis, and include many bacterial membrane, secretion system and\nankyrin-repeat containing proteins. Sex-biased genes are often organised as\nsmall operons of uncharacterised genes and are mainly up-regulated in adult\nmales D. melanogaster in an age-dependent manner suggesting a potential role in\ncytoplasmic incompatibility. Our results indicate that large changes in\nWolbachia gene expression across the Drosophila life-cycle are relatively rare\nwhen assayed across all host tissues, but that candidate genes to understand\nhost-microbe interaction in facultative endosymbionts can be successfully\nidentified using holo-organism expression profiling. Our work also shows that\nmining public gene expression data in D. melanogaster provides a rich set of\nresources to probe the functional basis of the Wolbachia-Drosophila symbiosis\nand annotate the transcriptional outputs of the Wolbachia genome.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.05782v2"
    },
    {
        "title": "Chromosomal rearrangements as barriers to genetic homogenization between\n  archaic and modern humans",
        "authors": [
            "Rebekah L. Rogers"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Chromosomal rearrangements, which shuffle DNA throughout the genome, are an\nimportant source of divergence across taxa. Using a paired-end read approach\nwith Illumina sequence data for archaic humans, I identify changes in genome\nstructure that occurred recently in human evolution. Hundreds of rearrangements\nindicate genomic trafficking between the sex chromosomes and autosomes, raising\nthe possibility of sex-specific changes. Additionally, genes adjacent to genome\nstructure changes in Neanderthals are associated with testis-specific\nexpression, consistent with evolutionary theory that new genes commonly form\nwith expression in the testes. I identify one case of new-gene creation through\ntransposition from the Y chromosome to chromosome 10 that combines the 5' end\nof the testis-specific gene Fank1 with previously untranscribed sequence. This\nnew transcript experienced copy number expansion in archaic genomes, indicating\nrapid genomic change. Among rearrangements identified in Neanderthals, 13% are\ntransposition of selfish genetic elements, while 32% appear to be ectopic\nexchange between repeats. In Denisovan, the pattern is similar but numbers are\nsignificantly higher with 18% of rearrangements reflecting transposition and\n40% ectopic exchange between distantly related repeats. There is an excess of\ndivergent rearrangements relative to polymorphism in Denisovan, which might\nresult from non-uniform rates of mutation, possibly reflecting a burst of TE\nactivity in the lineage that led to Denisovan. Finally, loci containing genome\nstructure changes show diminished rates of introgression from Neanderthals into\nmodern humans, consistent with the hypothesis that rearrangements serve as\nbarriers to gene flow during hybridization. Together, these results suggest\nthat this previously unidentified source of genomic variation has important\nbiological consequences in human evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07047v3"
    },
    {
        "title": "Genetically Improved BarraCUDA",
        "authors": [
            "W. B. Langdon",
            "Brian Yee Hong Lam"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  BarraCUDA is a C program which uses the BWA algorithm in parallel with nVidia\nCUDA to align short next generation DNA sequences against a reference genome.\nThe genetically improved (GI) code is up to three times faster on short paired\nend reads from The 1000 Genomes Project and 60percent more accurate on a short\nBioPlanet.com GCAT alignment benchmark. GPGPU Barracuda running on a single K80\nTesla GPU can align short paired end nextgen sequences up to ten times faster\nthan bwa on a 12 core CPU.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07855v1"
    },
    {
        "title": "MicroRNAs -- targeting and target prediction",
        "authors": [
            "Takaya Saito",
            "Pål Sætrom"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  MicroRNAs (miRNAs) are a class of small noncoding RNAs that can regulate many\ngenes by base pairing to sites in mRNAs. The functionality of miRNAs overlaps\nthat of short interfering RNAs (siRNAs), and many features of miRNA targeting\nhave been revealed experimentally by studying miRNA-mimicking siRNAs. This\nreview outlines the features associated with animal miRNA targeting and\ndescribes currently available prediction tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.01804v2"
    },
    {
        "title": "On mechanisms of neutral evolution of DNA resulting in scale-free\n  behaviour",
        "authors": [
            "M. V. Koroteev",
            "P. V. Baranov"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We introduce a family of models incorporating random segmental substitutions\nand point mutations and demonstrate that such models reproduce algebraic length\ndistributions of exact matches with the slope $-4$ observed earlier in pairwise\ncomparisons of DNA of distantly related species. It is demonstrated that\npower-law distributions of exact matches emerge when shorter sequences transfer\ntheir DNA content to longer sequences, indicating potential mechanisms of the\nincreased genome complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.02336v2"
    },
    {
        "title": "Rapidly evolving in humans topologically associating domains",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genome-wide proximity placement analysis of 10,598 HSGRL within the context\nof the principal regulatory structures of the interphase chromatin, namely\ntopologically-associating domains (TADs) and specific sub-TAD structures termed\nsuper-enhancer domains (SEDs) revealed that 0.8%-10.3% of TADs contain more\nthan half of HSGRL. Of the 3,127 TADs in the hESC genome, 24 (0.8%); 53 (1.7%);\n259 (8.3%); and 322 (10.3%) harbor 1,110 (52.4%); 1,936 (50.9%); 1,151 (59.6%);\nand 1,601 (58.3%) HSGRL sequences from four distinct families, respectively.\nTADs that are enriched for HSGRL and termed rapidly-evolving in humans TADs\n(revTADs) manifest distinct correlation patterns between HSGRL placements and\nrecombination rates. There are significant enrichment within revTAD boundaries\nof hESC-enhancers, primate-specific CTCF-binding sites, human-specific\nRNAPII-binding sites, hCONDELs, and H3K4me3 peaks with human-specific\nenrichment at TSS in prefrontal cortex neurons (p < 0.0001 in all instances).\nIn hESC genome, 331 of 504 (66%) of SE-harboring TADs contain HSGRL and 68% of\nSEs co-localize with HSGRL, suggesting that HSGRL rewired SE-driven GRNs within\nrevTADs by inserting novel and/or erasing existing regulatory sequences.\nConsequently, markedly distinct features of chromatin structures evolved in\nhESC compared to mouse: the SE quantity is 3-fold higher and the median SE size\nis significantly larger; concomitantly, the TAD number is increased by 42%\nwhile the median TAD size is decreased (p=9.11E-37). Present analyses revealed\na global role for HSGRL in increasing both quantity and size of SEs and\nincreasing the number and size reduction of TADs, which may facilitate a\nconvergence of TAD and SED architectures of interphase chromatin and define a\ntrend of increasing regulatory complexity during evolution of GRNs.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.05368v1"
    },
    {
        "title": "GMOL: An Interactive Tool for 3D Genome Structure Visualization",
        "authors": [
            "Jackson Nowotny",
            "Avery Wells",
            "Lingfei Xu",
            "Renzhi Cao",
            "Tuan Trieu",
            "Chenfeng He",
            "Jianlin Cheng"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  It has been shown that genome spatial structures largely affect both genome\nactivity and DNA function. Knowing this, many researchers are currently\nattempting to accurately model genome structures. Despite these increased\nefforts there still exists a shortage of tools dedicated to visualizing the\ngenome. Creating a tool that can accurately visualize the genome can aid\nresearchers by highlighting structural relationships that may not be obvious\nwhen examining the sequence information alone. Here we present a desktop\napplication, known as GMOL, designed to effectively visualize genome tertiary\nstructures at multiple scales so that researchers may better analyze their\ngenomic data. GMOL was developed based upon our multi-scale approach that\nallows a user to zoom in and out between six separate levels within the genome.\nThese six scales are full genome, chromosome, loci, fiber, nucleosome, and\nnucleotide. In order to store the data of the different scales, a new file\nformat, known as GSS, was created. With GMOL, a user can choose any unit at any\nscale and scale it up or down to visualize its structure and retrieve\ncorresponding genome sequences from either Ensembl or a local database. Users\ncan also interactively manipulate and measure the whole genome structure and\nextract static images and machine-readable data files in PDB format from the\nmulti-scale structure. By using GMOL researchers will be able to better\nunderstand and analyze genome structure models and the impact their structural\nrelations have on genome activity and DNA function through GMOLs unique\nfeatures and functions, which includes the multi-scale method that can satisfy\nthe users requirement to not only visualize genome tertiary structure, but also\nmeasure it.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.06383v1"
    },
    {
        "title": "Codon Bias Patterns of $E.coli$'s Interacting Proteins",
        "authors": [
            "Maddalena Dilucca",
            "Giulio Cimini",
            "Andrea Semmoloni",
            "Antonio Deiana",
            "Andrea Giansanti"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Synonymous codons, i.e., DNA nucleotide triplets coding for the same amino\nacid, are used differently across the variety of living organisms. The\nbiological meaning of this phenomenon, known as codon usage bias, is still\ncontroversial. In order to shed light on this point, we propose a new codon\nbias index, $CompAI$, that is based on the competition between cognate and\nnear-cognate tRNAs during translation, without being tuned to the usage bias of\nhighly expressed genes. We perform a genome-wide evaluation of codon bias for\n$E.coli$, comparing $CompAI$ with other widely used indices: $tAI$, $CAI$, and\n$Nc$. We show that $CompAI$ and $tAI$ capture similar information by being\npositively correlated with gene conservation, measured by ERI, and\nessentiality, whereas, $CAI$ and $Nc$ appear to be less sensitive to\nevolutionary-functional parameters. Notably, the rate of variation of $tAI$ and\n$CompAI$ with ERI allows to obtain sets of genes that consistently belong to\nspecific clusters of orthologous genes (COGs). We also investigate the\ncorrelation of codon bias at the genomic level with the network features of\nprotein-protein interactions in $E.coli$. We find that the most densely\nconnected communities of the network share a similar level of codon bias (as\nmeasured by $CompAI$ and $tAI$). Conversely, a small difference in codon bias\nbetween two genes is, statistically, a prerequisite for the corresponding\nproteins to interact. Importantly, among all codon bias indices, $CompAI$ turns\nout to have the most coherent distribution over the communities of the\ninteractome, pointing to the significance of competition among cognate and\nnear-cognate tRNAs for explaining codon usage adaptation.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.07693v1"
    },
    {
        "title": "Origins of de novo genes in human and chimpanzee",
        "authors": [
            "Jorge Ruiz-Orera",
            "Jessica Hernandez-Rodriguez",
            "Cristina Chiva",
            "Eduard Sabidó",
            "Ivanela Kondova",
            "Ronald Bontrop",
            "Tomàs Marqués-Bonet",
            "M. Mar Albà"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The birth of new genes is an important motor of evolutionary innovation.\nWhereas many new genes arise by gene duplication, others originate at genomic\nregions that do not contain any gene or gene copy. Some of these newly\nexpressed genes may acquire coding or non-coding functions and be preserved by\nnatural selection. However, it is yet unclear which is the prevalence and\nunderlying mechanisms of de novo gene emergence. In order to obtain a\ncomprehensive view of this process we have performed in-depth sequencing of the\ntranscriptomes of four mammalian species, human, chimpanzee, macaque and mouse,\nand subsequently compared the assembled transcripts and the corresponding\nsyntenic genomic regions. This has resulted in the identification of over five\nthousand new transcriptional multiexonic events in human and/or chimpanzee that\nare not observed in the rest of species. By comparative genomics we show that\nthe expression of these transcripts is associated with the gain of regulatory\nmotifs upstream of the transcription start site (TSS) and of U1 snRNP sites\ndownstream of the TSS. We also find that the coding potential of the new genes\nis higher than expected by chance, consistent with the presence of\nprotein-coding genes in the dataset. Using available human tissue proteomics\nand ribosome profiling data we identify several de novo genes with translation\nevidence. These genes show significant purifying selection signatures,\nindicating that they are probably functional. Taken together, the data supports\na model in which frequently-occurring new transcriptional events in the genome\nprovide the raw material for the evolution of new proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.07744v2"
    },
    {
        "title": "Automatic learning of pre-miRNAs from different species",
        "authors": [
            "Ivani de Oliveira Negrão Lopes",
            "Alexander Schliep",
            "André C. P. de L. F. de Carvalho"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Discovery of microRNAs (miRNAs) relies on predictive models for\ncharacteristic features from miRNA precursors (pre-miRNAs). The short length of\nmiRNA genes and the lack of pronounced sequence features complicate this task.\nTo accommodate the peculiarities of plant and animal miRNAs systems, tools for\nboth systems have evolved differently. However, these tools are biased towards\nthe species for which they were primarily developed and, consequently, their\npredictive performance on data sets from other species of the same kingdom\nmight be lower. While these biases are intrinsic to the species, the\ncharacterization of their occurrence can lead to computational approaches able\nto diminish their negative effect on the accuracy of pre-miRNAs predictive\nmodels. Here, we investigate in this study how 45 predictive models induced for\ndata sets from 45 species, distributed in eight subphyla, perform when applied\nto a species different from the species used in its induction. Our\ncomputational experiments show that the separability of pre-miRNAs and pseudo\npre-miRNAs instances is species-dependent and no feature set performs well for\nall species, even within the same subphylum. Mitigating this species\ndependency, we show that an ensemble of classifiers reduced the classification\nerrors for all 45 species. As the ensemble members were obtained using\nmeaningful, and yet computationally viable feature sets, the ensembles also\nhave a lower computational cost than individual classifiers that rely on energy\nstability parameters, which are of prohibitive computational cost in large\nscale applications. In this study, the combination of multiple pre-miRNAs\nfeature sets and multiple learning biases enhanced the predictive accuracy of\npre-miRNAs classifiers of 45 species. This is certainly a promising approach to\nbe incorporated in miRNA discovery tools towards more accurate and less\nspecies-dependent tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.00412v1"
    },
    {
        "title": "Pathway-based feature selection algorithms identify genes discriminating\n  patients with multiple sclerosis apart from controls",
        "authors": [
            "Lei Zhang",
            "Linlin Wang",
            "Pu Tian",
            "Suyan Tian"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Introduction The focus of analyzing data from microarray experiments and\nextracting biological insight from such data has experienced a shift from\nidentification of individual genes in association with a phenotype to that of\nbiological pathways or gene sets. Meanwhile, feature selection algorithm\nbecomes imperative to cope with the high dimensional nature of many modeling\ntasks in bioinformatics. Many feature selection algorithms use information\ncontained within a gene set as a biological priori, and select relevant\nfeatures by incorporating such information. Thus, an integration of gene set\nanalysis with feature selection is highly desired. Significance analysis of\nmicroarray to gene-set reduction analysis (SAM-GSR) algorithm is a novel\ndirection of gene set analysis, aiming at further reduction of gene set into a\ncore subset. Here, we explore the feature selection trait possessed by SAM-GSR\nand then modify SAM-GSR specifically to better fulfill this role. Results and\nConclusions Training on a multiple sclerosis (MS) microarray data using both\nSAM-GSR and our modification of SAM-GSR, excellent discriminative performance\non an independent test set was achieved. To conclude, absorbing biological\ninformation from a gene set may be helpful for classification and feature\nselection. Discussion Given the fact the complete pathway information is far\nfrom completeness, a statistical method capable of constructing biologically\nmeaningful gene networks is in demand. The basic requirement is that interplay\namong genes must be taken into account.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.01509v1"
    },
    {
        "title": "SCARs: endogenous human stem cell-associated retroviruses and\n  therapy-resistant malignant tumors",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Discoveries of endogenous human stem cell-associated retroviruses (SCARs)\nrevealed consistent activation of specific endogenous retroviral elements in\nhuman preimplantation embryos and documented the essential role of the\nsustained retroviral activities in the maintenance of pluripotency, functional\nidentity and integrity of naive-state embryonic stem cells, and anti-viral\nresistance of the early-stage human embryos. Activation of specific SCARs,\nnamely LTR7.HERVH and LTR5Hs.HERVK, has been demonstrated in patients diagnosed\nwith multiple types of cancer, autoimmune diseases, neurodegenerative disorders\nand it is likely associated with the emergence of clinically lethal therapy\nresistant death-from-cancer phenotypes in a sub-set of cancer patients\ndiagnosed with different types of malignant tumors.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02022v1"
    },
    {
        "title": "A Model for Competition for Ribosomes in the Cell",
        "authors": [
            "Alon Raveh",
            "Michael Margaliot",
            "Eduardo D. Sontag",
            "Tamir Tuller"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Large-scale simultaneous mRNA translation and the resulting competition for\nthe available ribosomes has important implications to the cell's functioning\nand evolution. Developing a better understanding of the intricate correlations\nbetween these simultaneous processes, rather than focusing on the translation\nof a single isolated transcript, should help in gaining a better understanding\nof mRNA translation regulation and the way elongation rates affect organismal\nfitness. A model of simultaneous translation is specifically important when\ndealing with highly expressed genes, as these consume more resources. In\naddition, such a model can lead to more accurate predictions that are needed in\nthe interconnection of translational modules in synthetic biology. We develop\nand analyze a general model for large-scale simultaneous mRNA translation and\ncompetition for ribosomes. This is based on combining several ribosome flow\nmodels (RFMs) interconnected via a pool of free ribosomes. We prove that the\ncompound system always converges to a steady-state and that it always entrains\nor phase locks to periodically time-varying transition rates in any of the mRNA\nmolecules. We use this model to explore the interactions between the various\nmRNA molecules and ribosomes at steady-state. We show that increasing the\nlength of an mRNA molecule decreases the production rate of all the mRNAs.\nIncreasing any of the codon translation rates in a specific mRNA molecule\nyields a local effect: an increase in the translation rate of this mRNA, and\nalso a global effect: the translation rates in the other mRNA molecules all\nincrease or all decrease. These results suggest that the effect of codon\ndecoding rates of endogenous and heterologous mRNAs on protein production is\nmore complicated than previously thought.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02408v1"
    },
    {
        "title": "Biases in differential expression analysis of RNA-seq data: A matter of\n  replicate type",
        "authors": [
            "Sora Yoon",
            "Dougu Nam"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  In differential expression (DE) analysis of RNA-seq count data, it is known\nthat genes with a larger read number are more likely to be differentially\nexpressed. This bias has a profound effect on the subsequent Gene Ontology (GO)\nanalysis by perturbing the ranks of gene-sets. Another known bias is that the\ncommonly used parametric DE analysis methods (e.g., edgeR, DESeq and baySeq)\ntend to yield more DE genes as the sequencing depth is increased. We\nnevertheless show that these biases are in fact confined to data of the\ntechnical replicate type. We also show the GO or gene-set enrichment analysis\nmethods applied to technical replicate data result in considerable number of\nfalse positives. In conclusion, the current DE and enrichment analysis methods\ncan be confidently used for biological replicate count data, while caution\nshould be exercised when analysing technical replicate data.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.03719v1"
    },
    {
        "title": "The mysterious orphans of Mycoplasmataceae",
        "authors": [
            "Tatiana V. Tatarinova",
            "Inna Lysnyansky",
            "Yuri V. Nikolsky",
            "Alexander Bolshoy"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Background: The length of a protein sequence is largely determined by its\nfunction, i.e. each functional group is associated with an optimal size.\nHowever, comparative genomics revealed that proteins length may be affected by\nadditional factors. In 2002 it was shown that in bacterium Escherichia coli and\nthe archaeon Archaeoglobus fulgidus, protein sequences with no homologs are, on\naverage, shorter than those with homologs. Most experts now agree that the\nlength distributions are distinctly different between protein sequences with\nand without homologs in bacterial and archaeal genomes. In this study, we\nexamine this postulate by a comprehensive analysis of all annotated prokaryotic\ngenomes and focusing on certain exceptions.\n  Results: We compared lengths distributions of having homologs proteins (HHPs)\nand non-having homologs proteins (orphans or ORFans) in all currently annotated\ncompletely sequenced prokaryotic genomes. As expected, the HHPs and ORFans have\nstrikingly different length distributions in almost all genomes. As previously\nestablished, the HHPs, indeed, are, on average, longer than the ORFans, and the\nlength distributions for the ORFans have a relatively narrow peak, in contrast\nto the HHPs, whose lengths spread over a wider range of values. However, about\nthirty genomes do not obey these rules. Practically all genomes of Mycoplasma\nand Ureaplasma have atypical ORFans distributions, with the mean lengths of\nORFan larger than the mean lengths of HHPs. These genera constitute over 80% of\natypical genomes.\n  Conclusions: We confirmed on a ubiquitous set of genomes the previous\nobservation that HHPs and ORFans have different gene length distributions. We\nalso showed that Mycoplasmataceae genomes have distinctive distributions of\nORFans lengths. We offer several possible biological explanations of this\nphenomenon.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.05991v1"
    },
    {
        "title": "Phenotypic divergence of Homo sapiens is driven by the evolution of\n  human-specific genomic regulatory networks via two mechanistically distinct\n  pathways of creation of divergent regulatory DNA sequences",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Thousands of candidate human-specific regulatory sequences (HSRS) have been\nidentified, supporting the hypothesis that unique to human phenotypes result\nfrom human-specific alterations of genomic regulatory networks. Here,\nconservation patterns analysis of 18,364 candidate HSRS was carried out based\non definition of the sequence conservation threshold as the minimum ratio of\nbases that must remap of 1.00. A total of 5,535 candidate HSRS were identified\nthat are: i) highly conserved in Great Apes; ii) evolved by the exaptation of\nhighly conserved ancestral DNA; iii) defined by either the acceleration of\nmutation rates on the human lineage or the functional divergence from nonhuman\nprimates. The exaptation of highly conserved ancestral DNA pathway seems\nmechanistically distinct from the evolution of regulatory DNA segments driven\nby the species-specific expansion of transposable elements. Present analysis\nsupports the idea that phenotypic divergence of Homo sapiens is driven by the\nevolution of human-specific genomic regulatory networks via two mechanistically\ndistinct pathways of creation of divergent sequences of regulatory DNA: i)\nexaptation of the highly conserved ancestral regulatory DNA segments; ii)\nhuman-specific insertions of transposable elements.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.02507v2"
    },
    {
        "title": "Bipartite Community Structure of eQTLs",
        "authors": [
            "John Platig",
            "Peter Castaldi",
            "Dawn DeMeo",
            "John Quackenbush"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genome Wide Association Studies (GWAS) and eQTL analyses have produced a\nlarge and growing number of genetic associations linked to a wide range of\nhuman phenotypes. As of 2013, there were more than 11,000 SNPs associated with\na trait as reported in the NHGRI GWAS Catalog. However, interpreting the\nfunctional roles played by these SNPs remains a challenge. Here we describe an\napproach that uses the inherent bipartite structure of eQTL networks to place\nSNPs into a functional context.\n  Using genotyping and gene expression data from 163 lung tissue samples in a\nstudy of Chronic Obstructive Pulmonary Disease (COPD) we calculated eQTL\nassociations between SNPs and genes and cast significant associations (FDR $<\n0.1$) as links in a bipartite network. To our surprise, we discovered that the\nhighly-connected \"hub\" SNPs within the network were devoid of\ndisease-associations. However, within the network we identified 35 highly\nmodular communities, which comprise groups of SNPs associated with groups of\ngenes; 13 of these communities were significantly enriched for distinct\nbiological functions (P $ < 5 \\times 10^{-4}$) including COPD-related\nfunctions. Further, we found that GWAS-significant SNPs were enriched at the\ncores of these communities, including previously identified GWAS associations\nfor COPD, asthma, and pulmonary function, among others. These results speak to\nour intuition: rather than single SNPs influencing single genes, we see groups\nof SNPs associated with the expression of families of functionally related\ngenes and that disease SNPs are associated with the perturbation of those\nfunctions. These methods are not limited in their application to COPD and can\nbe used in the analysis of a wide variety of disease processes and other\nphenotypic traits.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.02816v1"
    },
    {
        "title": "Life without dUTPase",
        "authors": [
            "Csaba Kerepesi",
            "Judit E. Szabó",
            "Vince Grolmusz",
            "Beáta G. Vértessy"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Fine-tuned regulation of the cellular nucleotide pools is indispensable for\nfaithful replication of DNA. The genetic information is also safeguarded by DNA\ndamage recognition and repair processes. Uracil is one of the most frequently\noccurring erroneous base in DNA; it can arise from cytosine deamination or\nthymine-replacing incorporation. Two enzyme families are primarily involved in\nkeeping DNA uracil-free: dUTPases that prevent thymine-replacing incorporation\nand uracil-DNA glycosylases that excise uracil from DNA and initiate\nuracil-excision repair. Both dUTPase and the most efficient uracil-DNA\nglycosylase UNG is thought to be ubiquitous in free-living organisms. In the\npresent work, we have systematically investigated the genotype of deposited\nfully sequenced bacterial and Archaeal genomes. Surprisingly, we have found\nthat in contrast to the generally held opinion, a wide number of bacterial and\nArchaeal species lack the dUTPase gene(s). The dut- genotype is present in\ndiverse bacterial phyla indicating that loss of this (or these) gene(s) has\noccurred multiple times during evolution. We have identified several survival\nstrategies in lack of dUTPases: i) simultaneous lack or inhibition of UNG, ii)\nacquisition of a less dUTP-specific sanitizing nucleotide pyrophosphatase, and\niii) supply of dUTPase from bacteriophages. Our data indicate that several\nunicellular microorganisms may efficiently cope with a dut- genotype\npotentially leading to an unusual uracil-enrichment in their genomic DNA.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.04850v1"
    },
    {
        "title": "Algorithmic Methods to Infer the Evolutionary Trajectories in Cancer\n  Progression",
        "authors": [
            "Giulio Caravagna",
            "Alex Graudenzi",
            "Daniele Ramazzotti",
            "Rebeca Sanz-Pamplona",
            "Luca De Sano",
            "Giancarlo Mauri",
            "Victor Moreno",
            "Marco Antoniotti",
            "Bud Mishra"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The genomic evolution inherent to cancer relates directly to a renewed focus\non the voluminous next generation sequencing (NGS) data, and machine learning\nfor the inference of explanatory models of how the (epi)genomic events are\nchoreographed in cancer initiation and development. However, despite the\nincreasing availability of multiple additional -omics data, this quest has been\nfrustrated by various theoretical and technical hurdles, mostly stemming from\nthe dramatic heterogeneity of the disease. In this paper, we build on our\nrecent works on \"selective advantage\" relation among driver mutations in cancer\nprogression and investigate its applicability to the modeling problem at the\npopulation level. Here, we introduce PiCnIc (Pipeline for Cancer Inference), a\nversatile, modular and customizable pipeline to extract ensemble-level\nprogression models from cross-sectional sequenced cancer genomes. The pipeline\nhas many translational implications as it combines state-of-the-art techniques\nfor sample stratification, driver selection, identification of\nfitness-equivalent exclusive alterations and progression model inference. We\ndemonstrate PiCnIc's ability to reproduce much of the current knowledge on\ncolorectal cancer progression, as well as to suggest novel experimentally\nverifiable hypotheses.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.07918v4"
    },
    {
        "title": "Unified theory of human genome reveals a constrained spatial chromosomal\n  arrangement in interphase nuclei",
        "authors": [
            "Sarosh N. Fatakia",
            "Ishita S. Mehta",
            "Basuthkar J. Rao"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We investigate a densely packed, non-random arrangement of forty-six\nchromosomes (46,XY) in human nuclei. Here, we model systems-level chromosomal\ncrosstalk by unifying intrinsic parameters (chromosomal length and number of\ngenes) across all pairs of chromosomes in the genome to derive an extrinsic\nparameter called effective gene density. The hierarchical clustering and\nunderlying degeneracy in the effective gene density space reveal systems-level\nconstraints for spatial arrangement of clusters of chromosomes that were\npreviously unknown. Our findings corroborate experimental data on spatial\nchromosomal arrangement in human nuclei, from fibroblast and lymphocyte cell\nlines, thereby establishing that human genome constrains chromosomal\narrangement. We propose that this unified theory, which requires no additional\nexperimental input, may be extended to other eukaryotic species with annotated\ngenomes to infer their constrained self-organized spatial arrangement of\nchromosomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.08074v3"
    },
    {
        "title": "Keep Me Around: Intron Retention Detection and Analysis",
        "authors": [
            "Harold Pimentel",
            "John G. Conboy",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We present a tool, keep me around (kma), a suite of python scripts and an R\npackage that finds retained introns in RNA-Seq experiments and incorporates\nbiological replicates to reduce the number of false positives when detecting\nretention events. kma uses the results of existing quantification tools that\nprobabilistically assign multi-mapping reads, thus interfacing easily with\ntranscript quantification pipelines. The data is represented in a convenient,\ndatabase style format that allows for easy aggregation across introns, genes,\nsamples, and conditions to allow for further exploratory analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.00696v1"
    },
    {
        "title": "The Transcription Factor E4F1 Coordinates CHK1-Dependent Checkpoint and\n  Mitochondrial Functions",
        "authors": [
            "Geneviéve Rodier",
            "Olivier Kirsh",
            "Martín Baraibar",
            "Thibault Houlés",
            "Matthieu Lacroix",
            "Héléne Delpech",
            "Elodie Hatchi",
            "Stéphanie Arnould",
            "Dany Severac",
            "Emeric Dubois",
            "Julie Caramel",
            "Eric Julien",
            "Bertrand Friguet",
            "Laurent Le Cam",
            "Claude Sardet"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Recent data support the notion that a group of key transcriptional regulators\ninvolved in tumorigenesis, including MYC, p53, E2F1, and BMI1, share an\nintriguing capacity to simultaneously regulate metabolism and cell cycle. Here,\nwe show that another factor, the multifunctional protein E4F1, directly\ncontrols genes involved in mitochondria functions and cell-cycle checkpoints,\nincluding Chek1, a major component of the DNA damage response. Coordination of\nthese cellular functions by E4F1 appears essential for the survival of\np53-deficient transformed cells. Acute inactivation of E4F1 in these cells\nresults in CHK1-dependent checkpoint deficiency and multiple mitochondrial\ndysfunctions that lead to increased ROS production, energy stress, and\ninhibition of de novo pyrimidine synthesis. This deadly cocktail leads to the\naccumulation of uncompensated oxidative damage to proteins and extensive DNA\ndamage, ending in cell death. This supports the rationale of therapeutic\nstrategies simultaneously targeting mitochondria and CHK1 for selective killing\nof p53-deficient cancer cells.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.05917v1"
    },
    {
        "title": "A large scale prediction of bacteriocin gene blocks suggests a wide\n  functional spectrum for bacteriocins",
        "authors": [
            "James T Morton",
            "Stefan D Freed",
            "Shaun W Lee",
            "Iddo Friedberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Bacteriocins are peptide-derived molecules produced by bacteria, whose\nrecently-discovered functions include virulence factors and signalling\nmolecules as well as their better known roles as antibiotics. To date, close to\nfive hundred bacteriocins have been identified and classified. Recent\ndiscoveries have shown that bacteriocins are highly diverse and widely\ndistributed among bacterial species. Given the heterogeneity of bacteriocin\ncompounds, many tools struggle with identifying novel bacteriocins due to their\nvast sequence and structural diversity. Many bacteriocins undergo\npost-translational processing or modifications necessary for the biosynthesis\nof the final mature form. Enzymatic modification of bacteriocins as well as\ntheir export is achieved by proteins whose genes are often located in a\ndiscrete gene cluster proximal to the bacteriocin precursor gene, referred to\nas \\textit{context genes} in this study. Although bacteriocins themselves are\nstructurally diverse, context genes have been shown to be largely conserved\nacross unrelated species. Using this knowledge, we set out to identify new\ncandidates for context genes which may clarify how bacteriocins are\nsynthesized, and identify new candidates for bacteriocins that bear no sequence\nsimilarity to known toxins. To achieve these goals, we have developed a\nsoftware tool, Bacteriocin Operon and gene block Associator (BOA) that can\nidentify homologous bacteriocin associated gene clusters and predict novel\nones. We discover that several phyla have a strong preference for bactericon\ngenes, suggesting distinct functions for this group of molecules. Availability:\nhttps://github.com/idoerg/BOA\n",
        "pdf_link": "http://arxiv.org/pdf/1510.06008v1"
    },
    {
        "title": "Machine learning for metagenomics: methods and tools",
        "authors": [
            "Hayssam Soueidan",
            "Macha Nikolski"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Owing to the complexity and variability of metagenomic studies, modern\nmachine learning approaches have seen increased usage to answer a variety of\nquestion encompassing the full range of metagenomic NGS data analysis. We\nreview here the contribution of machine learning techniques for the field of\nmetagenomics, by presenting known successful approaches in a unified framework.\nThis review focuses on five important metagenomic problems: OTU-clustering,\nbinning, taxonomic profling and assignment, comparative metagenomics and gene\nprediction. For each of these problems, we identify the most prominent methods,\nsummarize the machine learning approaches used and put them into perspective of\nsimilar methods. We conclude our review looking further ahead at the challenge\nposed by the analysis of interactions within microbial communities and\ndifferent environments, in a field one could call \"integrative metagenomics\".\n",
        "pdf_link": "http://arxiv.org/pdf/1510.06621v2"
    },
    {
        "title": "Identifying lineage effects when controlling for population structure\n  improves power in bacterial association studies",
        "authors": [
            "Sarah G Earle",
            "Chieh-Hsi Wu",
            "Jane Charlesworth",
            "Nicole Stoesser",
            "N Claire Gordon",
            "Timothy M Walker",
            "Chris C A Spencer",
            "Zamin Iqbal",
            "David A Clifton",
            "Katie L Hopkins",
            "Neil Woodford",
            "E Grace Smith",
            "Nazir Ismail",
            "Martin J Llewelyn",
            "Tim E Peto",
            "Derrick W Crook",
            "Gil McVean",
            "A Sarah Walker",
            "Daniel J Wilson"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Bacteria pose unique challenges for genome-wide association studies (GWAS)\nbecause of strong structuring into distinct strains and substantial linkage\ndisequilibrium across the genome. While methods developed for human studies can\ncorrect for strain structure, this risks considerable loss- of-power because\ngenetic differences between strains often contribute substantial phenotypic\nvariability. Here we propose a new method that captures lineage-level\nassociations even when locus-specific associations cannot be fine-mapped. We\ndemonstrate its ability to detect genes and genetic variants underlying\nresistance to 17 antimicrobials in 3144 isolates from four taxonomically\ndiverse clonal and recombining bacteria: Mycobacterium tuberculosis,\nStaphylococcus aureus, Escherichia coli and Klebsiella pneumoniae. Strong\nselection, recombination and penetrance confer high power to recover known\nantimicrobial resistance mechanisms, and reveal a candidate association between\nthe outer membrane porin nmpC and cefazolin resistance in E. coli. Hence our\nmethod pinpoints locus-specific effects where possible, and boosts power by\ndetecting lineage-level differences when fine-mapping is intractable.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.06863v3"
    },
    {
        "title": "Separating Putative Pathogens from Background Contamination with\n  Principal Orthogonal Decomposition: Evidence for Leptospira in the Ugandan\n  Neonatal Septisome",
        "authors": [
            "Steven J. Schiff",
            "Julius Kiwanuka",
            "Gina Riggio",
            "Lan Nguyen",
            "Kevin Mu",
            "Emily Sproul",
            "Joel Bazira",
            "Juliet Mwanga",
            "Dickson Tumusiime",
            "Eunice Nyesigire",
            "Nkangi Lwanga",
            "Kaleb T. Bogale",
            "Vivek Kapur",
            "James Broach",
            "Sarah Morton",
            "Benjamin C. Warf",
            "Mary Poss"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Neonatal sepsis (NS) is responsible for over a 1 million yearly deaths\nworldwide. In the developing world NS is often treated without an identified\nmicrobial pathogen. Amplicon sequencing of the bacterial 16S rRNA gene can be\nused to identify organisms that are difficult to detect by routine\nmicrobiological methods. However, contaminating bacteria are ubiquitous in both\nhospital settings and research reagents, and must be accounted for to make\neffective use of these data. In the present study, we sequenced the bacterial\n16S rRNA gene obtained from blood and cerebrospinal fluid (CSF) of 80 neonates\npresenting with NS to the Mbarara Regional Hospital in Uganda. Assuming that\npatterns of background contamination would be independent of pathogenic\nmicroorganism DNA, we applied a novel quantitative approach using principal\northogonal decomposition to separate background contamination from potential\npathogens in sequencing data. We designed our quantitative approach contrasting\nblood, CSF, and control specimens, and employed a variety of statistical random\nmatrix bootstrap hypotheses to estimate statistical significance. These\nanalyses demonstrate that Leptospira appears present in some infants presenting\nwithin 48 hr of birth, indicative of infection in utero, and up to 28 days of\nage, suggesting environmental exposure. This organism cannot be cultured in\nroutine bacteriological settings, and is enzootic in the cattle that the rural\npeoples of western Uganda often live in close proximity. Our findings\ndemonstrate that statistical approaches to remove background organisms common\nin 16S sequence data can reveal putative pathogens in small volume biological\nsamples from newborns. This computational analysis thus reveals an important\nmedical finding that has the potential to alter therapy and prevention efforts\nin a critically ill population.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00600v1"
    },
    {
        "title": "Gene Ontology: Pitfalls, Biases, Remedies",
        "authors": [
            "Pascale Gaudet",
            "Christophe Dessimoz"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The Gene Ontology (GO) is a formidable resource but there are several\nconsiderations about it that are essential to understand the data and interpret\nit correctly. The GO is sufficiently simple that it can be used without deep\nunderstanding of its structure or how it is developed, which is both a strength\nand a weakness. In this chapter, we discuss some common misinterpretations of\nthe ontology and the annotations. A better understanding of the pitfalls and\nthe biases in the GO should help users make the most of this very rich\nresource. We also review some of the misconceptions and misleading assumptions\ncommonly made about GO, including the effect of data incompleteness, the\nimportance of annotation qualifiers, and the transitivity or lack thereof\nassociated with different ontology relations. We also discuss several biases\nthat can confound aggregate analyses such as gene enrichment analyses. For each\nof these pitfalls and biases, we suggest remedies and best practices.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.01875v1"
    },
    {
        "title": "Primer on the Gene Ontology",
        "authors": [
            "Pascale Gaudet",
            "Nives Škunca",
            "James C. Hu",
            "Christophe Dessimoz"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The Gene Ontology (GO) project is the largest resource for cataloguing gene\nfunction. The combination of solid conceptual underpinnings and a practical set\nof features have made the GO a widely adopted resource in the research\ncommunity and an essential resource for data analysis. In this chapter, we\nprovide a concise primer for all users of the GO. We briefly introduce the\nstructure of the ontology and explain how to interpret annotations associated\nwith the GO.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.01876v1"
    },
    {
        "title": "Controllability analysis and control synthesis for the ribosome flow\n  model",
        "authors": [
            "Yoram Zarai",
            "Michael Margaliot",
            "Eduardo D. Sontag",
            "Tamir Tuller"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The ribosomal density along the coding region of the mRNA molecule affect\nvarious fundamental intracellular phenomena including: protein production\nrates, organismal fitness, ribosomal drop off, and co-translational protein\nfolding. Thus, regulating translation in order to obtain a desired ribosomal\nprofile along the mRNA molecule is an important biological problem. We study\nthis problem using a model for mRNA translation, called the ribosome flow model\n(RFM). In the RFM, the mRNA molecule is modeled as chain of n sites. The n\nstate-variables describe the ribosomal density profile along the mRNA molecule,\nwhereas the transition rates from each site to the next are controlled by n+1\npositive constants. To study the problem of controlling the density profile, we\nconsider some or all of the transition rates as time-varying controls. We\nconsider the following problem: given an initial and a desired ribosomal\ndensity profile, determine the time-varying values of the transition rates that\nsteer the RFM to this density profile, if they exist. Specifically, we consider\ntwo control problems. In the first, all transition rates can be regulated and\nthe goal is to steer the ribosomal density profile and the protein production\nrate from a given initial value to a desired value. In the second, a single\ntransition rate is controlled and the goal is to steer the production rate to a\ndesired value. In the first case, we show that the system is controllable, i.e.\nthe control is powerful enough to steer the RFM to any desired value, and we\nprovide closed-form expressions for constant control functions (or transition\nrates) asymptotically steering the RFM to the desired value. For the second\nproblem, we show that the production rate can be steered to any desired value\nin a feasible region determined by the other, constant transition rates. We\ndiscuss some of the biological implications of these results.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.02308v2"
    },
    {
        "title": "The combinatorics of overlapping genes",
        "authors": [
            "Sophie Lebre",
            "Olivier Gascuel"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Overlapping genes exist in all domains of life and are much more abundant\nthan expected at their first discovery in the late 1970s. Assuming that the\nreference gene is read in frame +0, an overlapping gene can be encoded in two\nreading frames in the sense strand, denoted by +1 and +2, and in three reading\nframes in the opposite strand, denoted by -0, -1 and -2. This motivated\nnumerous researchers to study the constraints induced by the genetic code on\nthe various overlapping frames, mostly based on information theory. Our focus\nin this paper is on the constraints induced on two overlapping genes in terms\nof amino acids, as well as polypeptides. We show that simple linear constraints\nbind the amino acid composition of two proteins encoded by overlapping genes.\nNovel constraints are revealed when polypeptides are considered, and not just\nsingle amino acids. For example, in double-coding sequences with an overlapping\nreading frame -2, each Tyrosine (denoted as Tyr or Y) in the overlapping frame\noverlaps a Tyrosine in the reference frame +0 (and reciprocally), whereas\nspecific words (e.g. YY) never occur. We thus distinguish between null\nconstraints (YY = 0 in frame -2) and non-null constraints (Y in frame +0 <=> Y\nin frame -2). Our equivalence-based constraints are symmetrical and thus enable\nthe characterization of the joint composition of overlapping proteins. We\ndescribe several formal frameworks and a graph algorithm to characterize and\ncompute these constraints. These results yield support for understanding the\nmechanisms and evolution of overlapping genes, and for developing novel\noverlapping gene detection methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.04971v4"
    },
    {
        "title": "MetaPalette: A $k$-mer painting approach for metagenomic taxonomic\n  profiling and quantification of novel strain variation",
        "authors": [
            "David Koslicki",
            "Daniel Falush"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Metagenomic profiling is challenging in part because of the highly uneven\nsampling of the tree of life by genome sequencing projects and the limitations\nimposed by performing phylogenetic inference at fixed taxonomic ranks. We\npresent the algorithm MetaPalette which uses long $k$-mer sizes ($k=30, 50$) to\nfit a $k$-mer \"palette\" of a given sample to the $k$-mer palette of reference\norganisms. By modeling the $k$-mer palettes of unknown organisms, the method\nalso gives an indication of the presence, abundance, and evolutionary\nrelatedness of novel organisms present in the sample. The method returns a\ntraditional, fixed-rank taxonomic profile which is shown on independently\nsimulated data to be one of the most accurate to date. Tree figures are also\nreturned that quantify the relatedness of novel organisms to reference\nsequences and the accuracy of such figures is demonstrated on simulated\nspike-ins and a metagenomic soil sample. The software implementing MetaPalette\nis available at: https://github.com/dkoslicki/MetaPalette. Pre-trained\ndatabases are included for Archaea, Bacteria, Eukaryota, and viruses.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.05328v1"
    },
    {
        "title": "Statistical modeling of isoform splicing dynamics from RNA-seq time\n  series data",
        "authors": [
            "Yuanhua Huang",
            "Guido Sanguinetti"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Isoform quantification is an important goal of RNA-seq experiments, yet it\nremains prob- lematic for genes with low expression or several isoforms. These\ndifficulties may in principle be ameliorated by exploiting correlated\nexperimental designs, such as time series or dosage response experiments. Time\nseries RNA-seq experiments, in particular, are becoming in- creasingly popular,\nyet there are no methods that explicitly leverage the experimental design to\nimprove isoform quantification. Here we present DICEseq, the first isoform\nquantification method tailored to correlated RNA-seq experiments. DICEseq\nexplicitly models the corre- lations between different RNA-seq experiments to\naid the quantification of isoforms across experiments. Numerical experiments on\nsimulated data sets show that DICEseq yields more accurate results than\nstate-of-the-art methods, an advantage that can become considerable at low\ncoverage levels. On real data sets, our results show that DICEseq provides\nsubstan- tially more reproducible and robust quantifications, increasing the\ncorrelation of estimates from replicate data sets by up to 10% on genes with\nlow or moderate expression levels (bot- tom third of all genes). Furthermore,\nDICEseq permits to quantify the trade-off between temporal sampling of RNA and\ndepth of sequencing, frequently an important choice when planning experiments.\nOur results have strong implications for the design of RNA-seq ex- periments,\nand offer a novel tool for improved analysis of such data sets. Python code is\nfreely available at http://diceseq.sf.net.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.06317v1"
    },
    {
        "title": "Visualizing Gene Ontology annotations",
        "authors": [
            "Fran Supek",
            "Nives Škunca"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Contemporary techniques in biology produce readouts for large numbers of\ngenes simultaneously, the typical example being differential gene expression\nmeasurements. Moreover, those genes are often richly annotated using GO terms\nthat describe gene function and that can be used to summarize the results of\nthe genome-scale experiments. However, making sense of such GO enrichment\nanalyses may be challenging. For instance, overrepresented GO functions in a\nset of differentially expressed genes are typically output as a flat list, a\nformat not adequate to capture the complexities of the hierarchical structure\nof the GO annotation labels.\n  In this chapter, we survey the various methods to visualize large,\ndifficult-to-interpret lists of GO terms. We catalogue their availability\n(web-based or standalone), the main principles they employ in summarizing large\nlists of GO terms, and the visualization styles they support. These brief\ncommentaries on each software are intended as a helpful inventory, rather than\ncomprehensive descriptions of the underlying algorithms. Instead, we show\nexamples of their use and suggest that the choice of an appropriate\nvisualization tool may be crucial to the utility of GO in biological discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.07103v1"
    },
    {
        "title": "Supra-operonic clusters of functionally related genes (SOCs) are a\n  source of horizontal gene co-transfers",
        "authors": [
            "Tin Y Pang",
            "Martin Lercher"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Adaptation of bacteria occurs predominantly via horizontal gene transfer\n(HGT). While it is widely recognized that horizontal acquisitions frequently\nencompass multiple genes, it is unclear what the size distribution of\nsuccessfully transferred DNA segments looks like and what evolutionary forces\nshape this distribution. Here, we identified 1790 gene family pairs that were\nconsistently co-gained on the same branches across a phylogeny of 53 E. coli\nstrains. We estimated a lower limit of their genomic distances at the time they\nwere transferred to their host genomes; this distribution shows a sharp upper\nbound at 30 kb. The same gene-pairs can have larger distances (up to 70 kb) in\nother genomes. These more distant pairs likely represent recent acquisitions\nvia transduction that involve the co-transfer of excised prophage genes, as\nthey are almost always associated with intervening phage-associated genes. The\nobserved distribution of genomic distances of co-transferred genes is much\nbroader than expected from a model based on the co-transfer of genes within\noperons; instead, this distribution is highly consistent with the size\ndistribution of supra-operonic clusters (SOCs), groups of co-occurring and\nco-functioning genes that extend beyond operons. Thus, we propose that SOCs\nform a basic unit of horizontal gene transfer.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.07266v3"
    },
    {
        "title": "The Discovery of Mutated Driver Pathways in Cancer: Models and\n  Algorithms",
        "authors": [
            "Junhua Zhang",
            "Shihua Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The pathogenesis of cancer in human is still poorly understood. With the\nrapid development of high-throughput sequencing technologies, huge volumes of\ncancer genomics data have been generated. Deciphering those data poses great\nopportunities and challenges to computational biologists. One of such key\nchallenges is to distinguish driver mutations, genes as well as pathways from\npassenger ones. Mutual exclusivity of gene mutations (each patient has no more\nthan one mutation in the gene set) has been observed in various cancer types\nand thus has been used as an important property of a driver gene set or\npathway. In this article, we aim to review the recent development of\ncomputational models and algorithms for discovering driver pathways or modules\nin cancer with the focus on mutual exclusivity-based ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.01298v1"
    },
    {
        "title": "New algorithmic challenges of adaptive immune repertoire construction",
        "authors": [
            "Alexander Shlemov",
            "Sergey Bankevich",
            "Andrey Bzikadze",
            "Yana Safonova"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: The analysis of antibodies and T-cell receptors (TCRs)\nconcentrations in serum is a fundamental problem in immunoinformatics.\nRepertoire construction is a preliminary step of analysis of clonal lineages,\nunderstanding of immune response dynamics, population analysis of\nimmunoglobulin and TCR loci. Emergence of MiSeq Illumina sequencing machine in\n2013 opened horizons of investigation of adaptive immune repertoires using\nhighly accurate reads. Reads produced by MiSeq are able to cover repertoires of\nmoderate size. At the same time, throughput of sequencing machines increases\nfrom year to year. This will enable ultra deep scanning of adaptive immune\nrepertoires and analysis of their diversity. Such data requires both efficient\nand highly accurate repertoire construction tools. In 2015 Safonova et al.\npresented IgRepertoireConstructor, a tool for accurate construction of antibody\nrepertoire and immunoproteogenomics analysis. Unfortunately, proposed algorithm\nwas very time and memory consuming and could be a bottleneck of processing\nlarge immunosequencing libraries. In this paper we overcome this challenge and\npresent IgReC, a novel algorithm for adaptive repertoire construction problem.\nIgReC reconstructs a repertoire with high precision even if each input read\ncontains sequencing errors and performs well on contemporary datasets. Results\nof computational experiments show that IgReC improves state-of-the-art in the\nfield. Availability: IgReC is an open source and freely available program\nrunning on Linux platforms. The source code is available at GitHub:\nyana-safonova.github.io/ig_repertoire_constructor. Contact:\nsafonova.yana@gmail.com\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02193v1"
    },
    {
        "title": "Accurate selfcorrection of errors in long reads using de Bruijn graphs",
        "authors": [
            "Leena Salmela",
            "Riku Walve",
            "Eric Rivals",
            "Esko Ukkonen"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  New long read sequencing technologies, like PacBio SMRT and Oxford NanoPore,\ncan produce sequencing reads up to 50,000 bp long but with an error rate of at\nleast 15%. Reducing the error rate is necessary for subsequent utilisation of\nthe reads in, e.g., de novo genome assembly. The error correction problem has\nbeen tackled either by aligning the long reads against each other or by a\nhybrid approach that uses the more accurate short reads produced by second\ngeneration sequencing technologies to correct the long reads. We present an\nerror correction method that uses long reads only. The method consists of two\nphases: first we use an iterative alignment-free correction method based on de\nBruijn graphs with increasing length of k-mers, and second, the corrected reads\nare further polished using long-distance dependencies that are found using\nmultiple alignments. According to our experiments the proposed method is the\nmost accurate one relying on long reads only for read sets with high coverage.\nFurthermore, when the coverage of the read set is at least 75x, the throughput\nof the new method is at least 20% higher. LoRMA is freely available at\nhttp://www.cs.helsinki.fi/u/lmsalmel/LoRMA/.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02233v1"
    },
    {
        "title": "Representing high throughput expression profiles via perturbation\n  barcodes reveals compound targets",
        "authors": [
            "Tracey Filzen",
            "Peter Kutchukian",
            "Jeffrey Hermes",
            "Jing Li",
            "Matthew Tudor"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  High throughput mRNA expression profiling can be used to characterize the\nresponse of cell culture models to perturbations such as pharmacologic\nmodulators and genetic perturbations. As profiling campaigns expand in scope,\nit is important to homogenize, summarize, and analyze the resulting data in a\nmanner that captures significant biological signals in spite of various noise\nsources such as batch effects and stochastic variation. We used the L1000\nplatform for large-scale profiling of 978 genes, chosen to be representative of\nthe genome as whole, across thousands of compound treatments. Here, a method is\ndescribed that uses deep learning techniques to convert the expression changes\nof the landmark genes into a perturbation barcode that reveals important\nfeatures of the underlying data, performing better than the raw data in\nrevealing important biological insights. The barcode captures compound\nstructure and target information, in addition to predicting a compound's high\nthroughput screening promiscuity, to a higher degree than the original data\nmeasurements, indicating that the approach uncovers underlying factors of the\nexpression data that are otherwise entangled or masked by noise. Furthermore,\nwe demonstrate that visualizations derived from the perturbation barcode can be\nused to more sensitively assign functions to unknown compounds through a\nguilt-by-association approach, which we use to predict and experimentally\nvalidate the activity of compounds on the MAPK pathway. The demonstrated\napplication of deep metric learning to large-scale chemical genetics projects\nhighlights the utility of this and related approaches to the extraction of\ninsights and testable hypotheses from big, sometimes noisy data.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02399v1"
    },
    {
        "title": "Multiple Comparative Metagenomics using Multiset k-mer Counting",
        "authors": [
            "Gaëtan Benoit",
            "Pierre Peterlongo",
            "Mahendra Mariadassou",
            "Erwan Drezen",
            "Sophie Schbath",
            "Dominique Lavenier",
            "Claire Lemaitre"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Background. Large scale metagenomic projects aim to extract biodiversity\nknowledge between different environmental conditions. Current methods for\ncomparing microbial communities face important limitations. Those based on\ntaxonomical or functional assignation rely on a small subset of the sequences\nthat can be associated to known organisms. On the other hand, de novo methods,\nthat compare the whole sets of sequences, either do not scale up on ambitious\nmetagenomic projects or do not provide precise and exhaustive results.\n  Methods. These limitations motivated the development of a new de novo\nmetagenomic comparative method, called Simka. This method computes a large\ncollection of standard ecological distances by replacing species counts by\nk-mer counts. Simka scales-up today's metagenomic projects thanks to a new\nparallel k-mer counting strategy on multiple datasets.\n  Results. Experiments on public Human Microbiome Project datasets demonstrate\nthat Simka captures the essential underlying biological structure. Simka was\nable to compute in a few hours both qualitative and quantitative ecological\ndistances on hundreds of metagenomic samples (690 samples, 32 billions of\nreads). We also demonstrate that analyzing metagenomes at the k-mer level is\nhighly correlated with extremely precise de novo comparison techniques which\nrely on all-versus-all sequences alignment strategy or which are based on\ntaxonomic profiling.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02412v3"
    },
    {
        "title": "Automated deconvolution of structured mixtures from bulk tumor genomic\n  data",
        "authors": [
            "Theodore Roman",
            "Lu Xie",
            "Russell Schwartz"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: As cancer researchers have come to appreciate the importance of\nintratumor heterogeneity, much attention has focused on the challenges of\naccurately profiling heterogeneity in individual patients. Experimental\ntechnologies for directly profiling genomes of single cells are rapidly\nimproving, but they are still impractical for large-scale sampling. Bulk\ngenomic assays remain the standard for population-scale studies, but conflate\nthe influences of mixtures of genetically distinct tumor, stromal, and\ninfiltrating immune cells. Many computational approaches have been developed to\ndeconvolute these mixed samples and reconstruct the genomics of genetically\nhomogeneous clonal subpopulations. All such methods, however, are limited to\nreconstructing only coarse approximations to a few major subpopulations. In\nprior work, we showed that one can improve deconvolution of genomic data by\nleveraging substructure in cellular mixtures through a strategy called\nsimplicial complex inference. This strategy, however, is also limited by the\ndifficulty of inferring mixture structure from sparse, noisy assays. Results:\nWe improve on past work by introducing enhancements to automate learning of\nsubstructured genomic mixtures, with specific emphasis on genome-wide copy\nnumber variation (CNV) data. We introduce methods for dimensionality estimation\nto better decompose mixture model substructure; fuzzy clustering to better\nidentify substructure in sparse, noisy data; and automated model inference\nmethods for other key model parameters. We show that these improvements lead to\nmore accurate inference of cell populations and mixture proportions in\nsimulated scenarios. We further demonstrate their effectiveness in identifying\nmixture substructure in real tumor CNV data. Availability: Source code is\navailable at http://www.cs.cmu.edu/~russells/software/WSCUnmix.zip\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02487v1"
    },
    {
        "title": "COCACOLA: binning metagenomic contigs using sequence COmposition, read\n  CoverAge, CO-alignment, and paired-end read LinkAge",
        "authors": [
            "Yang Young Lu",
            "Ting Chen",
            "Jed A. Fuhrman",
            "Fengzhu Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The advent of next-generation sequencing (NGS) technologies enables\nresearchers to sequence complex microbial communities directly from\nenvironment. Since assembly typically produces only genome fragments, also\nknown as contigs, instead of entire genome, it is crucial to group them into\noperational taxonomic units (OTUs) for further taxonomic profiling and\ndown-streaming functional analysis. OTU clustering is also referred to as\nbinning. We present COCACOLA, a general framework automatically bin contigs\ninto OTUs based upon sequence composition and coverage across multiple samples.\n  The effectiveness of COCACOLA is demonstrated in both simulated and real\ndatasets in comparison to state-of-art binning approaches such as CONCOCT,\nGroopM, MaxBin and MetaBAT. The superior performance of COCACOLA relies on two\naspects. One is employing $L_{1}$ distance instead of Euclidean distance for\nbetter taxonomic identification during initialization. More importantly,\nCOCACOLA takes advantage of both hard clustering and soft clustering by\nsparsity regularization.\n  In addition, the COCACOLA framework seamlessly embraces customized knowledge\nto facilitate binning accuracy. In our study, we have investigated two types of\nadditional knowledge, the co-alignment to reference genomes and linkage of\ncontigs provided by paired-end reads, as well as the ensemble of both. We find\nthat both co-alignment and linkage information further improve binning in the\nmajority of cases. COCACOLA is scalable and faster than CONCOCT ,GroopM, MaxBin\nand MetaBAT.\n  The software is available at https://github.com/younglululu/COCACOLA\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02512v1"
    },
    {
        "title": "Chloroplast Genome Yields Unusual Seven-Cluster Structure C",
        "authors": [
            "Michael G. Sadovsky",
            "Eugenia I. Bondar",
            "Yuliya A. Putintseva",
            "Konstantin V. Krutovsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  We studied the structuredness in a chloroplast genome of Siberian larch. The\nclusters in 63-dimensional space were identified with elastic map technique,\nwhere the objects to be clusterized are the different fragments of the genome.\nA seven-cluster structure in the distribution of those fragments reported\npreviously has been found. Unlike the previous results, we have found the\ndrastically other composition of the clusters comprising the fragments\nextracted from coding and non-coding regions of the genome.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04398v1"
    },
    {
        "title": "A frame-based representation of genomic sequences for removing errors\n  and rare variant detection in NGS data",
        "authors": [
            "Raunaq Malhotra",
            "Manjari Mukhopadhyay",
            "Mary Poss",
            "Raj Acharya"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  We propose a frame-based representation of k-mers for detecting sequencing\nerrors and rare variants in next generation sequencing data obtained from\npopulations of closely related genomes. Frames are sets of non-orthogonal basis\nfunctions, traditionally used in signal processing for noise removal. We define\na frame for genomes and sequenced reads to consist of discrete spatial signals\nof every k-mer of a given size. We show that each k-mer in the sequenced data\ncan be projected onto multiple frames and these projections are maximized for\nspatial signals corresponding to the k-mer's substrings. Our proposed\nclassifier, MultiRes, is trained on the projections of k-mers as features used\nfor marking k-mers as erroneous or true variations in the genome. We evaluate\nMultiRes on simulated and real viral population datasets and compare it to\nother error correction methods known in the literature. MultiRes has 4 to 500\ntimes less false positives k-mer predictions compared to other methods,\nessential for accurate estimation of viral population diversity and their\nde-novo assembly. It has high recall of the true k-mers, comparable to other\nerror correction methods. MultiRes also has greater than 95% recall for\ndetecting single nucleotide polymorphisms (SNPs), fewer false positive SNPs,\nwhile detecting higher number of rare variants compared to other variant\ncalling methods for viral populations. The software is freely available from\nthe GitHub link (https://github.com/raunaq-m/MultiRes).\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04803v1"
    },
    {
        "title": "Cell lineage tracing using nuclease barcoding",
        "authors": [
            "Stephanie Tzouanas Schmidt",
            "Stephanie M. Zimmerman",
            "Jianbin Wang",
            "Stuart K. Kim",
            "Stephen R. Quake"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Lineage tracing, the determination and mapping of progeny arising from single\ncells, is an important approach enabling the elucidation of mechanisms\nunderlying diverse biological processes ranging from development to disease. We\ndeveloped a dynamic sequence-based barcode for lineage tracing and have\ndemonstrated its performance in C. elegans, a model organism whose lineage tree\nis well established. The strategy we use creates lineage trees based upon the\nintroduction of specific mutations into cells and the propagation of these\nmutations to daughter cells at each cell division. We present an experimental\nproof of concept along with a corresponding simulation and analytical model for\ndeeper understanding of the coding capacity of the system. By introducing\nmutations in a predictable manner using CRISPR/Cas9, our technology will enable\nmore complete investigations of cellular processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.00786v1"
    },
    {
        "title": "An observation of circular RNAs in bacterial RNA-seq data",
        "authors": [
            "Nicolas Innocenti",
            "Hoang-Son Nguyen",
            "Aymeric Fouquier d'hérouël",
            "Erik Aurell"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Circular RNAs (circRNAs) are a class of RNA with an important role in micro\nRNA (miRNA) regulation recently discovered in Human and various other\neukaryotes as well as in archaea. Here, we have analyzed RNA-seq data obtained\nfrom {\\it Enterococcus faecalis} and {\\it Escherichia coli} in a way similar to\nprevious studies performed on eukaryotes. We report observations of circRNAs in\nRNA-seq data that are reproducible across multiple experiments performed with\ndifferent protocols or growth conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.04576v1"
    },
    {
        "title": "Recent advancement in Next Generation Sequencing techniques and its\n  computational analysis",
        "authors": [
            "Khalid Raza",
            "Sabahuddin Ahmad"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Next Generation Sequencing (NGS), a recently evolved technology, have served\na lot in the research and development sector of our society. This novel\napproach is a newbie and has critical advantages over the traditional Capillary\nElectrophoresis (CE) based Sanger Sequencing. The advancement of NGS has led to\nnumerous important discoveries, which could have been costlier and time taking\nin case of traditional CE based Sanger sequencing. NGS methods are highly\nparallelized enabling to sequence thousands to millions of molecules\nsimultaneously. This technology results into huge amount of data, which need to\nbe analysed to conclude valuable information. Specific data analysis algorithms\nare written for specific task to be performed. The algorithms in group, act as\na tool in analysing the NGS data. Analysis of NGS data unravels important clues\nin quest for the treatment of various life-threatening diseases; improved crop\nvarieties and other related scientific problems related to human welfare. In\nthis review, an effort was made to address basic background of NGS\ntechnologies, possible applications, computational approaches and tools\ninvolved in NGS data analysis, future opportunities and challenges in the area.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.05254v2"
    },
    {
        "title": "H(O)TA: estimation of DNA methylation and hydroxylation levels and\n  efficiencies from time course data",
        "authors": [
            "Charalampos Kyriakopoulos",
            "Pascal Giehr",
            "Verena Wolf"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Methylation and hydroxylation of cytosines to form 5-methylcytosine (5mC) and\n5-droxymethylcytosine (5hmC) belong to the most important epigenetic\nmodifications and their vital role in the regulation of gene expression has\nbeen widely recognized. Recent experimental techniques allow to infer\nmethylation and hydroxylation levels at CpG dinucleotides but require a\nsophisticated statistical analysis to achieve accurate estimates.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.07807v1"
    },
    {
        "title": "Optimal Down Regulation of mRNA Translation",
        "authors": [
            "Yoram Zarai",
            "Michael Margaliot",
            "Tamir Tuller"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Down regulation of mRNA translation is an important problem in various\nbio-medical domains ranging from developing effective medicines for tumors and\nfor viral diseases to developing attenuated virus strains that can be used for\nvaccination. Here, we study the problem of down regulation of mRNA translation\nusing a mathematical model called the ribosome flow model (RFM). In the RFM,\nthe mRNA molecule is modeled as a chain of $n$ sites. The flow of ribosomes\nbetween consecutive sites is regulated by $n+1$ transition rates. Given a set\nof feasible transition rates, that models the outcome of all possible\nmutations, we consider the problem of maximally down regulating the translation\nrate by altering the rates within this set of feasible rates. Under certain\nconditions on the feasible set, we show that an optimal solution can be\ndetermined efficiently. We also rigorously analyze two special cases of the\ndown regulation optimization problem. Our results suggest that one must focus\non the position along the mRNA molecule where the transition rate has the\nstrongest effect on the protein production rate. However, this rate is not\nnecessarily the slowest transition rate along the mRNA molecule. We discuss\nsome of the biological implications of these results.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.08094v2"
    },
    {
        "title": "Characterization of Methicillin-resistant Staphylococcus aureus Isolates\n  from Fitness Centers in Memphis Metropolitan Area, USA",
        "authors": [
            "Nabanita Mukherjee",
            "Irshad M. Sulaiman",
            "Pratik Banerjee"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Indoor skin-contact surfaces of public fitness centers may serve as\nreservoirs of potential human transmission of methicillin-resistant\nStaphylococcus aureus (MRSA). We found a high prevalence of multi-drug\nresistant (MDR)-MRSA of CC59 lineage harboring a variety of extracellular toxin\ngenes from surface swab samples collected from inanimate surfaces of fitness\ncenters in Memphis metropolitan area, USA. Our findings underscore the role of\ninanimate surfaces as potential sources of transmission of MDR-MRSA strains\nwith considerable genetic diversity.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.08377v1"
    },
    {
        "title": "Reanalyzing variable directionality of gene expression in\n  transgenerational epigenetic inheritance",
        "authors": [
            "Abhay Sharma"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  A previous report claimed no evidence of transgenerational epigenetic\ninheritance in a mouse model of in utero environmental exposure, based on the\nobservation that gene expression changes observed in the germ cells of G1 and\nG2 male fetus were not in the same direction. A subsequent data reanalysis\nhowever showed a statistically significant overlap between G1 and G2 genes\nirrespective of direction, leading to the suggestion that, as phenotypic\nvariability in epigenetic transmission has been observed in several other\nexamples also, the above report provided evidence in favor of, not against,\ntransgenerational inheritance. This criticism has recently been questioned.\nHere, it is shown that the questions raised are based not only on incorrect\nstatistical calculations but also on wrong premise that gene expression changes\ndo not constitute a phenotype.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.08585v1"
    },
    {
        "title": "Enhancing power of rare variant association test by Zoom-Focus Algorithm\n  (ZFA) to locate optimal testing region",
        "authors": [
            "Maggie Haitian Wang",
            "Haoyi Weng",
            "Rui Sun",
            "Benny Chung-Ying Zee"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: Exome or targeted sequencing data exerts analytical challenge to\ntest single nucleotide polymorphisms (SNPs) with extremely small minor allele\nfrequency (MAF). Various rare variant tests were proposed to increase power by\naggregating SNPs within a fixed genomic region, such as a gene or pathway.\nHowever, a gene could contain from several to thousands of markers, and not all\nof them may be related to the phenotype. Combining functional and\nnon-functional SNPs in arbitrary genomic region could impair the testing power.\nResults: We propose a Zoom-Focus algorithm (ZFA) to locate the optimal testing\nregion within a given genomic region, as a wrapper function to be applied in\nconjunction with rare variant association tests. In the first Zooming step, a\ngiven genomic region is partitioned by order of two, and the best partition is\nlocated within all partition levels. In the next Focusing step, boundaries of\nthe zoomed region are refined. Simulation studies showed that ZFA substantially\nenhanced the statistical power of rare variant tests by over 10 folds,\nincluding the WSS, SKAT and W-test. The algorithm is applied on real exome\nsequencing data of hypertensive disorder, and identified biologically relevant\ngenetic markers to metabolic disorder that are undiscoverable by testing using\nfull gene. The proposed algorithm is an efficient and powerful tool to increase\nthe effectiveness of rare variant association tests for exome sequencing\ndatasets of complex disorder.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.08941v1"
    },
    {
        "title": "Analysis of Chromosome 20 - A Study",
        "authors": [
            "Kristiina Ausmees",
            "Pushpam Aji John"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Since the arrival of next-generation sequencing technologies the amount of\ngenetic sequencing data has increased dramatically. This has has fueled an\nincrease in human genetics research. At the same time, with the recent advent\nof technologies in processing large data sets, lot of these technologies are\nproving valuable and efficient in analyzing these huge datasets. In this paper\nwe use some of these technologies to analyze genetic sequencing data of 1000\nGenomes Project,produce and evaluate a framework to process the sequencing data\nthereof and look into structural variations with respect to population groups.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00276v1"
    },
    {
        "title": "SMISS: A protein function prediction server by integrating multiple\n  sources",
        "authors": [
            "Renzhi Cao",
            "Zhaolong Zhong",
            "Jianlin Cheng"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  SMISS is a novel web server for protein function prediction. Three different\npredictors can be selected for different usage. It integrates different sources\nto improve the protein function prediction accuracy, including the query\nprotein sequence, protein-protein interaction network, gene-gene interaction\nnetwork, and the rules mined from protein function associations. SMISS\nautomatically switch to ab initio protein function prediction based on the\nquery sequence when there is no homologs in the database. It takes fasta format\nsequences as input, and several sequences can submit together without\ninfluencing the computation speed too much. PHP and Perl are two primary\nprogramming language used in the server. The CodeIgniter MVC PHP web framework\nand Bootstrap front-end framework are used for building the server. It can be\nused in different platforms in standard web browser, such as Windows, Mac OS X,\nLinux, and iOS. No plugins are needed for our website. Availability:\nhttp://tulip.rnet.missouri.edu/profunc/.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01384v1"
    },
    {
        "title": "A draft genome assembly of southern bluefin tuna Thunnus maccoyii",
        "authors": [
            "Sean McWilliam",
            "Peter M. Grewe",
            "Rowan J. Bunch",
            "William Barendse"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Tuna are large pelagic fish whose populations are close to panmixia. In\naddition, they are threatened species, so it is important for the maintenance\nand monitoring of genetic diversity that genetic information at a genome level\nbe obtained. Here we report the draft assembly of the southern bluefin tuna\ngenome and the collection of genome-wide sequence data for five other tuna\nspecies. We sampled five tuna species of the genus Thunnus, the northern and\nsouthern bluefin, yellowfin, albacore, and bigeye, as well as the skipjack\n(Katsuwonis pelamis), a tuna-like species. Genome assembly was facilitated at\nk-mer=25 while k-mer=51 generated assembly artefacts. The estimated size of the\nsouthern bluefin tuna genome was 795 Mb. We assembled two southern bluefin tuna\nindividuals independently using both paired end and mate pair sequence. This\nresulted in scaffolds with N50>174,000 bp and maximum scaffold lengths>1.4 Mb.\nOur estimate of the size of the assembled genome was the scaffolded sequences\nin common to both assemblies, which amounted to 721 Mb of the 795 Mb of the\nsouthern bluefin tuna genome sequence. Using BLAST, there were matches between\n13,039 of 14,341 (91%) refseq mRNA of the zebrafish Danio rerio to the tuna\nassembly indicating that most of a generic fish transcriptome was covered by\nthe assembly.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.03955v1"
    },
    {
        "title": "On the Ribosomal Density that Maximizes Protein Translation Rate",
        "authors": [
            "Yoram Zarai",
            "Michael Margaliot",
            "Tamir Tuller"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  During mRNA translation, several ribosomes attach to the same mRNA molecule\nsimultaneously translating it into a protein. This pipelining increases the\nprotein production rate. A natural and important question is what ribosomal\ndensity maximizes the protein production rate. Using mathematical models of\nribosome flow along both a linear and a circular mRNA molecule we prove that\ntypically the steady-state production rate is maximized when the ribosomal\ndensity is one half of the maximal possible density. We discuss the\nimplications of our results to endogenous genes under natural cellular\nconditions and also to synthetic biology.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.04064v1"
    },
    {
        "title": "Cytomegalovirus Antigenic Mimicry of Human Alloreactive Peptides: A\n  Potential Trigger for Graft versus Host Disease",
        "authors": [
            "Charles Hall",
            "Vishal Koparde",
            "Max Jameson-Lee",
            "Abdelrhman Elnasseh",
            "Allison Scalora",
            "Jared Kobulnicky",
            "Myrna Serrano",
            "Catherine Roberts",
            "Gregory Buck",
            "Micheal Neale",
            "Daniel Nixon",
            "Amir Toor"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The association between human cytomegalovirus (hCMV) reactivation and the\ndevelopment of graft-versus-host-disease (GVHD) has been observed in stem cell\ntransplantation (SCT). Seventy seven SCT donor-recipient pairs (DRP) (HLA\nmatched unrelated donor (MUD), n=50; matched related donor (MRD), n=27)\nunderwent whole exome sequencing to identify single nucleotide polymorphisms\n(SNPs) generating alloreactive peptide libraries for each DRP (9-mer\npeptide-HLA complexes); Human CMV CROSS (Cross-Reactive Open Source Sequence)\nDatabase was compiled from NCBI; HLA class I binding affinity for each DRPs HLA\nwas calculated by NetMHCpan 2.8 and hCMV- derived 9-mers algorithmically\ncompared to the alloreactive peptide-HLA complex libraries. Short consecutive\n(6 or greater) amino acid (AA) sequence homology matching hCMV to recipient\npeptides was considered for HLA-bound-peptide (IC50<500 nM) cross reactivity.\nOf the 70,686 hCMV 9-mers contained within the hCMV CROSS database, 29,658.8\n+/- 9038.5 were found to match MRD DRP alloreactive peptides and 52,910.2 +/-\n16121.8 matched MUD DRP peptides (Student's T-test, p<0.001). In silico\nanalysis revealed multiple high affinity, immunogenic CMV-Human peptide matches\n(IC50<500 nM) expressed in GVHD-affected tissue-specific manner (proteins\nexpressed at 10 RPKM or greater). hCMV+GVHD was found in 18 patients, 13\ndeveloping hCMV viremia before GVHD onset with a subset analysis of 7 instances\nof hCMV viremia prior to acute GVHD onset (n=3), chronic GVHD (n=2) and acute +\nchronic GVHD (n=2) indicating cross reactive peptide expression within affected\norgans. We propose that based on our analysis and preliminary clinical\ncorrelations that hCMV immune cross-reactivity may cause antigenic mimicry of\nhuman alloreactive peptides triggering GVHD.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.08444v1"
    },
    {
        "title": "Sam2bam: High-Performance Framework for NGS Data Preprocessing Tools",
        "authors": [
            "Takeshi Ogasawara",
            "Yinhe Cheng",
            "Tzy-Hwa Kathy Tzeng"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  This paper introduces a high-throughput software tool framework called {\\it\nsam2bam} that enables users to significantly speedup pre-processing for\nnext-generation sequencing data. The sam2bam is especially efficient on\nsingle-node multi-core large-memory systems. It can reduce the runtime of data\npre-processing in marking duplicate reads on a single node system by 156-186x\ncompared with de facto standard tools. The sam2bam consists of parallel\nsoftware components that can fully utilize the multiple processors, available\nmemory, high-bandwidth of storage, and hardware compression accelerators if\navailable.\n  The sam2bam provides file format conversion between well-known genome file\nformats, from SAM to BAM, as a basic feature. Additional features such as\nanalyzing, filtering, and converting the input data are provided by {\\it\nplug-in} tools, e.g., duplicate marking, which can be attached to sam2bam at\nruntime.\n  We demonstrated that sam2bam could significantly reduce the runtime of NGS\ndata pre-processing from about two hours to about one minute for a whole-exome\ndata set on a 16-core single-node system using up to 130 GB of memory. The\nsam2bam could reduce the runtime for whole-genome sequencing data from about 20\nhours to about nine minutes on the same system using up to 711 GB of memory.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.01753v1"
    },
    {
        "title": "Selecting between-sample RNA-Seq normalization methods from the\n  perspective of their assumptions",
        "authors": [
            "Ciaran Evans",
            "Johanna Hardin",
            "Daniel Stoebel"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  RNA-Seq is a widely-used method for studying the behavior of genes under\ndifferent biological conditions. An essential step in an RNA-Seq study is\nnormalization, in which raw data are adjusted to account for factors that\nprevent direct comparison of expression measures. Errors in normalization can\nhave a significant impact on downstream analysis, such as inflated false\npositives in differential expression analysis. An under-emphasized feature of\nnormalization is the assumptions upon which the methods rely and how the\nvalidity of these assumptions can have a substantial impact on the performance\nof the methods. In this paper, we explain how assumptions provide the link\nbetween raw RNA-Seq read counts and meaningful measures of gene expression. We\nexamine normalization methods from the perspective of their assumptions, as an\nunderstanding of methodological assumptions is necessary for choosing methods\nappropriate for the data at hand. Furthermore, we discuss why normalization\nmethods perform poorly when their assumptions are violated and how this causes\nproblems in subsequent analysis. To analyze a biological experiment,\nresearchers must select a normalization method with assumptions that are met\nand that produces a meaningful measure of expression for the given experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.00959v1"
    },
    {
        "title": "Learning Directed-Acyclic-Graphs from Large-Scale Genomics Data",
        "authors": [
            "Fabio Nikolay",
            "Marius Pesavento",
            "George Kritikos",
            "Nassos Typas"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  In this paper we consider the problem of learning the\ngenetic-interaction-map, i.e., the topology of a directed acyclic graph (DAG)\nof genetic interactions from noisy double knockout (DK) data. Based on a set of\nwell established biological interaction models we detect and classify the\ninteractions between genes. We propose a novel linear integer optimization\nprogram called the Genetic-Interactions-Detector (GENIE) to identify the\ncomplex biological dependencies among genes and to compute the DAG topology\nthat matches the DK measurements best. Furthermore, we extend the GENIE-program\nby incorporating genetic-interactions-profile (GI-profile) data to further\nenhance the detection performance. In addition, we propose a sequential\nscalability technique for large sets of genes under study, in order to provide\nstatistically stressable results for real measurement data. Finally, we show\nvia numeric simulations that the GENIE-program as well as the GI-profile data\nextended GENIE (GI-GENIE)-program clearly outperform the conventional\ntechniques and present real data results for our proposed sequential\nscalability technique.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.02794v1"
    },
    {
        "title": "BAUM: A DNA Assembler by Adaptive Unique Mapping and Local\n  Overlap-Layout-Consensus",
        "authors": [
            "Anqi Wang",
            "Zheng Li",
            "Zhanyu Wang",
            "Lei M. Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Genome assembly from the high-throughput sequencing (HTS) reads is a\nfundamental yet challenging computational problem. An intrinsic challenge is\nthe uncertainty caused by the widespread repetitive elements. Here we get\naround the uncertainty using the notion of uniquely mapped (UM) reads, which\nmotivated the design of a new assembler BAUM. It mainly consists of two types\nof iterations. The first type of iterations constructs initial contigs from a\nreference, say a genome of a species that could be quite distant, by adaptive\nread mapping, filtration by the reference's unique regions, and reference\nupdating. A statistical test is proposed to split the layouts at possible\nstructural variation sites. The second type of iterations includes mapping,\nscaffolding/contig-extension, and contig merging. We extend each contig by\nlocally assembling the reads whose mates are uniquely mapped to an end of the\ncontig. Instead of the de Bruijn graph method, we take the\noverlap-layout-consensus (OLC) paradigm. The OLC is implemented by parallel\ncomputation, and has linear complexity with respect to the number of contigs.\nThe adjacent extended contigs are merged if their alignment is confirmed by the\nadjusted gap distance. Throughout the assembling, the mapping criterion is\nselected by probabilistic calculations. These innovations can be used\ncomplementary to the existing de novo assemblers. Applying this novel method to\nthe assembly of wild rice Oryza longistaminata genome, we achieved much\nimproved contig N50, 18.8k, compared with other assemblers. The assembly was\nfurther validated by contigs constructed from an independent library of long\n454 reads.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.03073v1"
    },
    {
        "title": "Relation between Gene Content and Taxonomy in Chloroplasts",
        "authors": [
            "Bashar Al-Nuaimi",
            "Christophe Guyeux",
            "Bassam AlKindy",
            "Jean-François Couchot",
            "Michel Salomon"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The aim of this study is to investigate the relation that can be found\nbetween the phylogeny of a large set of complete chloroplast genomes, and the\nevolution of gene content inside these sequences. Core and pan genomes have\nbeen computed on \\textit{de novo} annotation of these 845 genomes, the former\nbeing used for producing well-supported phylogenetic tree while the latter\nprovides information regarding the evolution of gene contents over time. It\ndetails too the specificity of some branches of the tree, when specificity is\nobtained on accessory genes. After having detailed the material and methods, we\nemphasize some remarkable relation between well-known events of the chloroplast\nhistory, like endosymbiosis, and the evolution of gene contents over the\nphylogenetic tree.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.06055v1"
    },
    {
        "title": "A spectral algorithm for fast de novo layout of uncorrected long\n  nanopore reads",
        "authors": [
            "Antoine Recanati",
            "Thomas Brüls",
            "Alexandre d'Aspremont"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: New long read sequencers promise to transform sequencing and\ngenome assembly by producing reads tens of kilobases long. However their high\nerror rate significantly complicates assembly and requires expensive correction\nsteps to layout the reads using standard assembly engines.\n  Results: We present an original and efficient spectral algorithm to layout\nthe uncorrected nanopore reads, and its seamless integration into a\nstraightforward overlap/layout/consensus (OLC) assembly scheme. The method is\nshown to assemble Oxford Nanopore reads from several bacterial genomes into\ngood quality (~99% identity to the reference) genome-sized contigs, while\nyielding more fragmented assemblies from a Sacharomyces cerevisiae reference\nstrain.\n  Availability and implementation: http://github.com/antrec/spectrassembler\n  Contact: antoine.recanati@inria.fr\n",
        "pdf_link": "http://arxiv.org/pdf/1609.07293v3"
    },
    {
        "title": "Prediction of Prokaryotic and Eukaryotic Promoters Using Convolutional\n  Deep Learning Neural Networks",
        "authors": [
            "Victor Solovyev",
            "Ramzan Umarov"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Accurate computational identification of promoters remains a challenge as\nthese key DNA regulatory regions have variable structures composed of\nfunctional motifs that provide gene specific initiation of transcription. In\nthis paper we utilize Convolutional Neural Networks (CNN) to analyze sequence\ncharacteristics of prokaryotic and eukaryotic promoters and build their\npredictive models. We trained the same CNN architecture on promoters of four\nvery distant organisms: human, plant (Arabidopsis), and two bacteria\n(Escherichia coli and Mycoplasma pneumonia). We found that CNN trained on\nsigma70 subclass of Escherichia coli promoter gives an excellent classification\nof promoters and non-promoter sequences (Sn=0.90, Sp=0.96, CC=0.84). The\nBacillus subtilis promoters identification CNN model achieves Sn=0.91, Sp=0.95,\nand CC=0.86. For human and Arabidopsis promoters we employ CNNs for\nidentification of two well-known promoter classes (TATA and non-TATA\npromoters). CNNs models nicely recognize these complex functional regions. For\nhuman Sn/Sp/CC accuracy of prediction reached 0.95/0.98/0,90 on TATA and\n0.90/0.98/0.89 for non-TATA promoter sequences, respectively. For Arabidopsis\nwe observed Sn/Sp/CC 0.95/0.97/0.91 (TATA) and 0.94/0.94/0.86 (non-TATA)\npromoters. Thus, the developed CNN models (implemented in CNNProm program)\ndemonstrated the ability of deep learning with grasping complex promoter\nsequence characteristics and achieve significantly higher accuracy compared to\nthe previously developed promoter prediction programs. As the suggested\napproach does not require knowledge of any specific promoter features, it can\nbe easily extended to identify promoters and other complex functional regions\nin sequences of many other and especially newly sequenced genomes. The CNNProm\nprogram is available to run at web server http://www.softberry.com.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.00121v1"
    },
    {
        "title": "An Improved Filtering Algorithm for Big Read Datasets",
        "authors": [
            "Axel Wedemeyer",
            "Lasse Kliemann",
            "Anand Srivastav",
            "Christian Schielke",
            "Thorsten B. Reusch",
            "Philip Rosenstiel"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  For single-cell or metagenomic sequencing projects, it is necessary to\nsequence with a very high mean coverage in order to make sure that all parts of\nthe sample DNA get covered by the reads produced. This leads to huge datasets\nwith lots of redundant data. A filtering of this data prior to assembly is\nadvisable. Titus Brown et al. (2012) presented the algorithm Diginorm for this\npurpose, which filters reads based on the abundance of their $k$-mers. We\npresent Bignorm, a faster and quality-conscious read filtering algorithm. An\nimportant new feature is the use of phred quality scores together with a\ndetailed analysis of the $k$-mer counts to decide which reads to keep. With\nrecommended parameters, in terms of median we remove 97.15% of the reads while\nkeeping the mean phred score of the filtered dataset high. Using the SDAdes\nassembler, we produce assemblies of high quality from these filtered datasets\nin a fraction of the time needed for an assembly from the datasets filtered\nwith Diginorm. We conclude that read filtering is a practical method for\nreducing read data and for speeding up the assembly process. Our Bignorm\nalgorithm allows assemblies of competitive quality in comparison to Diginorm,\nwhile being much faster. Bignorm is available for download at\nhttps://git.informatik.uni-kiel.de/axw/Bignorm.git\n",
        "pdf_link": "http://arxiv.org/pdf/1610.03443v1"
    },
    {
        "title": "Pan-genome Analysis of the Genus Serratia",
        "authors": [
            "Zarrin Basharat",
            "Azra Yasmin"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Pan-genome analysis is a standard procedure to decipher genome heterogeneity\nand diversification of bacterial species. Specie evolution is traced by\ndefining and comparing the core (conserved), accessory (dispensable) and unique\n(strain-specific) gene pool with other strains of interest. Here, we present\npan-genome analysis of the genus Serratia, comprising of a dataset of 100\ngenomes. The isolates have clinical to environmental origin and consist of ten\ndifferent species from the genus, along with two subspecies of the\nrepresentative strain Serratia marcescens. Out of 19430 non-redundant coding\nDNA sequences (CDS) from the dataset, 972 (5%) belonged to the core genome.\nMajority of these genes were linked to metabolic function, followed by cellular\nprocesses/signalling, information storage/processing while rest of them were\npoorly characterized. 10,135 CDSs (52.16%) were associated with dispensible\ngenome while 8,321 CDSs (42.82%) were singletons or strain specific. The\nPan-genome orthologs indicated a positive correlation to the number of genomes\nwhereas negative correlation was obtained for core genome. Genomes were aligned\nto obtain information about synteny, insertion/inversion, deletion and\nduplications. This study provides insights into variation of Serratia species\nand paves way for pan-genome analysis of other bacterial species at genus\nlevel.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.04160v1"
    },
    {
        "title": "Computational genomic algorithms for miRNA-based diagnosis of lung\n  cancer: the potential of machine learning",
        "authors": [
            "Neerja Garikipati"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The advent of large scale, high-throughput genomic screening has introduced a\nwide range of tests for diagnostic purposes. Prominent among them are tests\nusing miRNA expression levels. Genomics and proteomics now provide expression\nlevels of hundreds of miRNAs at a time. However, for actual diagnostic tools to\nbecome reality requires the simultaneous development of methods to interpret\nthe large amounts of miRNA expression data that can be generated from a single\npatient sample. Because these data are in numeric form, quantitative methods\nmust be developed. Statistics such as p-values and log fold change give some\ninsight, but the diagnostic effectiveness of each miRNA test must first be\nevaluated. Here, the author has developed a traditional, sensitivity- and\nspecificity-based algorithm, as well as a modern machine learning algorithm,\nand evaluated their diagnostic potential for lung cancer against a publicly\navailable database. The findings suggest that the machine learning algorithm\nachieves higher accuracy (97% for cancerous and 73% for normal samples), in\naddition to providing confidence intervals that could provide valuable\ndiagnostic support. The machine learning algorithm also has significant\npotential for expansion to more complex diagnoses of lung cancer sub-types, to\nother cancers as well diseases beyond cancer. Both algorithms are available on\nthe Github repo: https://github.com/neerja-g/machine-learning-miRNA.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.09423v2"
    },
    {
        "title": "Essential role of long non-coding RNAs in de novo chromatin\n  modifications: The genomic address code hypothesis",
        "authors": [
            "Ken Nishikawa",
            "Akira R. Kinjo"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The epigenome, i.e. the whole of chromatin modifications, is transferred from\nmother to daughter cells during cell differentiation. When de novo chromatin\nmodifications (establishment or erasure of, respectively, new or pre-existing\nDNA methylations and/or histone modifications) are made in a daughter cell,\nhowever, it has a different epigenome than its mother cell. Although de novo\nchromatin modifications are an important event that comprises elementary\nprocesses of cell differentiation, its molecular mechanism remains poorly\nunderstood. We argue in this Letter that a key to solving this problem lies in\nunderstanding the role of long non-coding RNAs (lncRNAs)- a type of RNA that is\nbecoming increasingly prominent in epigenetic studies. Many studies show that\nlncRNAs form ribonucleo-protein complexes in the nucleus and are involved in\nchromatin modifications. However, chromatin-modifying enzymes lack the\ninformation about genomic positions on which they act. It is known, on the\nother hand, that a single-stranded RNA in general can bind to a double-stranded\nDNA to form a triple helix. If each lncRNA forms a ribonucleo-protein complex\nwith chromatin-modifying enzymes on one hand and, at the same time, a triple\nhelix with a genomic region based on its specific nucleotide sequence on the\nother hand, it can induce de novo chromatin modifications at specific sites.\nThus, the great variety of lncRNAs can be explained by the requirement for the\ndiversity of \"genomic address codes\" specific to their cognate genomic regions\nwhere de novo chromatin modifications take place.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.02667v1"
    },
    {
        "title": "An Algorithm for Cellular Reprogramming",
        "authors": [
            "Scott Ronquist",
            "Geoff Patterson",
            "Markus Brown",
            "Haiming Chen",
            "Anthony Bloch",
            "Lindsey Muir",
            "Roger Brockett",
            "Indika Rajapakse"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The day we understand the time evolution of subcellular elements at a level\nof detail comparable to physical systems governed by Newton's laws of motion\nseems far away. Even so, quantitative approaches to cellular dynamics add to\nour understanding of cell biology, providing data-guided frameworks that allow\nus to develop better predictions about and methods for control over specific\nbiological processes and system-wide cell behavior. In this paper we describe\nan approach to optimizing the use of transcription factors in the context of\ncellular reprogramming. We construct an approximate model for the natural\nevolution of a synchronized population of fibroblasts, based on data obtained\nby sampling the expression of some 22,083 genes at several times along the cell\ncycle. (These data are based on a colony of cells that have been cell cycle\nsynchronized) In order to arrive at a model of moderate complexity, we cluster\ngene expression based on the division of the genome into topologically\nassociating domains (TADs) and then model the dynamics of the expression levels\nof the TADs. Based on this dynamical model and known bioinformatics, we develop\na methodology for identifying the transcription factors that are the most\nlikely to be effective toward a specific cellular reprogramming task. The\napproach used is based on a device commonly used in optimal control. From this\ndata-guided methodology, we identify a number of validated transcription\nfactors used in reprogramming and/or natural differentiation. Our findings\nhighlight the immense potential of dynamical models models, mathematics, and\ndata guided methodologies for improving methods for control over biological\nprocesses.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.03441v2"
    },
    {
        "title": "Development and characterization of Brassica juncea fruticulosa\n  introgression lines exhibiting resistance to mustard aphid",
        "authors": [
            "Chhaya Atri",
            "Bharti Kumar",
            "Hitesh Kumar",
            "Sanjula Sharma",
            "Surinder S. Banga"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Background: Mustard aphid is a major pest of Brassica oilseeds. No source for\naphid resistance is presently available in Brassica juncea . A wild crucifer,\nBrassica fruticulosa is known to be resistant to mustard aphid. An artificially\nsynthesized amphiploid, AD-4 (B. fruticulosa x B. rapa var. brown sarson) was\ndeveloped for use as a bridge species to transfer fruticulosa resistance to B.\njuncea. Using the selfed backcross we could select a large number of lines with\nresistance to mustard aphid. This paper reports cytogenetic stability of\nintrogression lines, molecular evidence for alien introgression and their\nreaction to mustard aphid infestation. Results: Majority of introgression lines\nhad expected euploid chromosome number(2n= 36), showed normal meiosis and high\npollen grain fertility. Well-distributed and transferable simple-sequence\nrepeats (SSR) markers for all the 18 B. juncea chromosomes helped to\ncharacterize introgression events. Average proportions of recipient and donor\ngenome in the substitution lines were 49.72 and 35.06%, respectively. Minimum\nalien parent genome presence (27.29%) was observed in the introgression line,\nAd3K-280 . Introgressed genotypes also varied for their resistance responses to\nmustard aphid infestations under artificial release conditions for two\ncontinuous seasons. Some of the test genotypes showed consistent resistant\nreaction. Conclusions: B.juncea-fruticulosa introgression set may prove to be a\nvery powerful breeding tool for aphid resistance related QTL/gene discovery and\nfine mapping of the desired genes/QTLs to facilitate marker assisted transfer\nof identified gene(s) for mustard aphid resistance in the background of\ncommercial mustard genotypes.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.07987v1"
    },
    {
        "title": "Anchor points for genome alignment based on Filtered Spaced Word Matches",
        "authors": [
            "Chris-Andre Leimeister",
            "Thomas Dencker",
            "Burkhard Morgenstern"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Alignment of large genomic sequences is a fundamental task in computational\ngenome analysis. Most methods for genomic alignment use high-scoring local\nalignments as {\\em anchor points} to reduce the search space of the alignment\nprocedure. Speed and quality of these methods therefore depend on the\nunderlying anchor points. Herein, we propose to use {\\em Filtered Spaced Word\nMatches} to calculate anchor points for genome alignment. To evaluate this\napproach, we used these anchor points in the the widely used alignment pipeline\n{\\em Mugsy}. For distantly related sequence sets, we could substantially\nimprove the quality of alignments produced by {\\em Mugsy}.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.08792v1"
    },
    {
        "title": "Meraculous-2D: Haplotype-sensitive Assembly of Highly Heterozygous\n  genomes",
        "authors": [
            "Eugene Goltsman",
            "Isaac Ho",
            "Daniel Rokhsar"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  While many short read assemblers attempt to simplify the de Brujin graph by\nidentifying and resolving variant-induced bubbles to produce a haploid mosaic\nresult, this approach is only viable when variants are relatively rare and the\nbubbles are well defined in a graph context. We observed that diploid genomes\nwith very high levels of heterozygosity fail to display well-resolved bubble\nstructures in a typical assembly graph and thus result in highly fragmented and\nincomplete assemblies. Here we present an enhancement of Meraculous2 algorithm,\ncalled Meraculous-2D, which preserves haplotypes across variant sites and\ngenerates accurate assembly of highly heterozygous diploid genomes. Preserving\nand taking advantage of the allelic variation throughout the assembly process\nallows reconstructing both haplomes at once, without the need to pick arbitrary\npaths through bubble structures. We also enhanced the original diploidy\nresolution method of Meraculous2 to maintain and report phased haplotype\nvariant information.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.09852v1"
    },
    {
        "title": "Comparative genomic analysis of the human gut microbiome reveals a broad\n  distribution of metabolic pathways for the degradation of host-synthetized\n  mucin glycans",
        "authors": [
            "Dmitry A. Ravcheev",
            "Ines Thiele"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The colonic mucus layer is a dynamic and complex structure formed by secreted\nand transmembrane mucins, which are high-molecular-weight and heavily\nglycosylated proteins. Colonic mucus consists of a loose outer layer and a\ndense epithelium-attached layer. The outer layer is inhabited by various\nrepresentatives of the human gut microbiota (HGM). Glycans of the colonic mucus\ncan be used by the HGM as a source of carbon and energy when dietary fibers are\nnot sufficiently available. Here, we analyzed 397 individual HGM genomes to\nidentify pathways for the cleavage of host-synthetized mucin glycans to\nmonosaccharides as well as for the catabolism of the derived monosaccharides.\nOur key results are as follows: (i) Genes for the cleavage of mucin glycans\nwere found in 86% of the analyzed genomes, whereas genes for the catabolism of\nderived monosaccharides were found in 89% of the analyzed genomes. (ii)\nComparative genomic analysis identified four alternative forms of the\nmonosaccharide-catabolizing enzymes and four alternative forms of\nmonosaccharide transporters. (iii) Eighty-five percent of the analyzed genomes\nmay be involved in exchange pathways for the monosaccharides derived from\ncleaved mucin glycans. (iv) The analyzed genomes demonstrated different\nabilities to degrade known mucin glycans. Generally, the ability to degrade at\nleast one type of mucin glycan was predicted for 81% of the analyzed genomes.\n(v) Eighty-two percent of the analyzed genomes can form mutualistic pairs that\nare able to degrade mucin glycans and are not degradable by any of the paired\norganisms alone. Taken together, these findings provide further insight into\nthe inter-microbial communications of the HGM as well as into host-HGM\ninteractions.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.10524v1"
    },
    {
        "title": "ASB1 differential methylation in ischaemic cardiomyopathy. Relationship\n  with left ventricular performance in end stage heart failure patients",
        "authors": [
            "Ana Ortega",
            "Estefanía Tarazón",
            "Carolina Gil-Cayuela",
            "Luis Martínez-Dolz",
            "Francisca Lago",
            "José Ramón González-Juanatey",
            "Juan Sandoval",
            "Manuel Portolés",
            "Esther Roselló-Lletí",
            "Miguel Rivera"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Aims: Ischaemic cardiomyopathy (ICM) leads to impaired contraction and\nventricular dysfunction causing high rates of morbidity and mortality.\nEpigenomics allows the identification of epigenetic signatures in human\ndiseases. We analyse the differential epigenetic patterns of ASB gene family in\nICM patients and relate these alterations to their haemodynamic and functional\nstatus. Methods and Results: Epigenomic analysis was carried out using 16 left\nventricular (LV) tissue samples, 8 from ICM patients undergoing heart\ntransplantation and 8 from control (CNT) subjects without cardiac disease. We\nincreased the sample size up to 13 ICM and 10 CNT for RNA-sequencing and to 14\nICM for pyrosequencing analyses. We found a hypermethylated profile\n(cg11189868) in the ASB1 gene that showed a differential methylation of 0.26\nbeta difference, P < 0.05. This result was validated by pyrosequencing\ntechnique (0.23 beta difference, P < 0.05). Notably, the methylation pattern\nwas strongly related to LV ejection fraction (r = -0.849, P = 0.008) stroke\nvolume (r = -0.929, P = 0.001) and end-systolic and diastolic LV diameters (r =\n-0.743, P = 0.035 for both). ASB1 showed a down regulation in mRNA levels (-1.2\nfold, P < 0.05). Conclusion: Our findings link a specific ASB1 methylation\npattern to LV structure and performance in end-stage ICM, opening new\ntherapeutic opportunities and providing new insights regarding which is the\nfunctionally relevant genome in the ischemic failing myocardium. Keywords:\nischaemic cardiomyopathy; epigenomics; heart failure; left ventricular\ndysfunction; stroke volume; ASB1.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.00945v1"
    },
    {
        "title": "Exponential scaling of single-cell RNA-seq in the last decade",
        "authors": [
            "Valentine Svensson",
            "Roser Vento-Tormo",
            "Sarah A Teichmann"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The ability to measure the transcriptomes of single cells has only been\nfeasible for a few years, and is becoming an extremely popular assay. While\nmany types of analysis and questions can be answered using single cell\nRNA-sequencing, a central focus is the ability to survey the diversity of cell\ntypes within a sample. Unbiased and reproducible cataloging of distinct cell\ntypes requires large numbers of cells. Technological developments and protocol\nimprovements have fuelled a consistent exponential increase in the numbers of\ncells studied in single cell RNA-seq analyses. In this perspective, we will\nhighlight the key technological developments which have enabled this growth in\ndata.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.01379v2"
    },
    {
        "title": "Reconstructing antibody repertoires from error-prone immunosequencing\n  datasets",
        "authors": [
            "Alexander Shlemov",
            "Sergey Bankevich",
            "Andrey Bzikadze",
            "Maria A. Turchaninova",
            "Yana Safonova",
            "Pavel A. Pevzner"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Transforming error-prone immunosequencing datasets into antibody repertoires\nis a fundamental problem in immunogenomics, and a prerequisite for studies of\nimmune responses. Although various repertoire reconstruction algorithms were\nreleased in the last three years, it remains unclear how to benchmark them and\nhow to assess the accuracy of the reconstructed repertoires. We describe a\nnovel IgReC algorithm for constructing antibody repertoires from\nhigh-throughput immunosequencing datasets and a new framework for assessing the\nquality of reconstructed repertoires. Benchmarking IgReC against the existing\nantibody repertoire reconstruction tools has demonstrated that it results in\nhighly accurate repertoire reconstructions. Surprisingly, antibody repertoires\nconstructed by IgReC from barcoded immunosequencing datasets in blind mode\n(without using unique molecular identifiers information) improved upon the\nrepertoires constructed by the state-of-the-art tools that use barcoding. This\nfinding suggests that IgReC may alleviate the need to generate repertoires\nusing the barcoding technology (the workhorse of current immunogenomics\nefforts) because our computational approach to error correction of\nimmunosequencing data ends up being nearly as powerful as the experimental\napproach based on barcoding.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.07184v1"
    },
    {
        "title": "On the ability to reconstruct ancestral genomes from Mycobacterium genus",
        "authors": [
            "Christophe Guyeux",
            "Bashar Al-Nuaimi",
            "Bassam AlKindy",
            "Jean-François Couchot",
            "Michel Salomon"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Technical signs of progress during the last decades has led to a situation in\nwhich the accumulation of genome sequence data is increasingly fast and cheap.\nThe huge amount of molecular data available nowadays can help addressing new\nand essential questions in Evolution. However, reconstructing evolution of DNA\nsequences requires models, algorithms, statistical and computational methods of\never increasing complexity. Since most dramatic genomic changes are caused by\ngenome rearrangements (gene duplications, gain/loss events), it becomes crucial\nto understand their mechanisms and reconstruct ancestors of the given genomes.\nThis problem is known to be NP-complete even in the \"simplest\" case of three\ngenomes. Heuristic algorithms are usually executed to provide approximations of\nthe exact solution.\n  We state that, even if the ancestral reconstruction problem is NP-hard in\ntheory, its exact resolution is feasible in various situations, encompassing\norganelles and some bacteria. Such accurate reconstruction, which identifies\ntoo some highly homoplasic mutations whose ancestral status is undecidable,\nwill be initiated in this work-in-progress, to reconstruct ancestral genomes of\ntwo Mycobacterium pathogenetic bacterias. By mixing automatic reconstruction of\nobvious situations with human interventions on signaled problematic cases, we\nwill indicate that it should be possible to achieve a concrete, complete, and\nreally accurate reconstruction of lineages of the Mycobacterium tuberculosis\ncomplex. Thus, it is possible to investigate how these genomes have evolved\nfrom their last common ancestors.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00276v1"
    },
    {
        "title": "Genetic load makes cancer cells more sensitive to common drugs: evidence\n  from Cancer Cell Line Encyclopedia",
        "authors": [
            "Ana B. Pavel",
            "Kirill S. Korolev"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Genetic alterations initiate tumors and enable the evolution of drug\nresistance. The pro-cancer view of mutations is however incomplete, and several\nstudies show that mutational load can reduce tumor fitness. Given its negative\neffect, genetic load should make tumors more sensitive to anticancer drugs.\nHere, we test this hypothesis across all major types of cancer from the Cancer\nCell Line Encyclopedia, which provides genetic and expression data of 496 cell\nlines together with their response to 24 common anticancer drugs. We found that\nthe efficacy of 9 out of 24 drugs showed significant association with genetic\nload in a pan-cancer analysis. The associations for some tissue-drug\ncombinations were remarkably strong, with genetic load explaining up to 83% of\nthe variance in the drug response. Overall, the role of genetic load depended\non both the drug and the tissue type with 10 tissues being particularly\nvulnerable to genetic load. We also identified changes in gene expression\nassociated with increased genetic load, which included cell-cycle checkpoints,\nDNA damage and apoptosis. Our results show that genetic load is an important\ncomponent of tumor fitness and can predict drug sensitivity. Beyond being a\nbiomarker, genetic load might be a new, unexplored vulnerability of cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.05921v1"
    },
    {
        "title": "Genetic control of plasticity of oil yield for combined abiotic stresses\n  using a joint approach of crop modeling and genome-wide association",
        "authors": [
            "Brigitte Mangin",
            "Pierre Casadebaig",
            "Eléna Cadic",
            "Nicolas Blanchet",
            "Marie-Claude Boniface",
            "Sébastien Carrère",
            "Jérôme Gouzy",
            "Ludovic Legrand",
            "Baptiste Mayjonade",
            "Nicolas Pouilly",
            "Thierry André",
            "Marie Coque",
            "Joël Piquemal",
            "Marion Laporte",
            "Patrick Vincourt",
            "Stéphane Muños",
            "Nicolas B. Langlade"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Understanding the genetic basis of phenotypic plasticity is crucial for\npredicting and managing climate change effects on wild plants and crops. Here,\nwe combined crop modeling and quantitative genetics to study the genetic\ncontrol of oil yield plasticity for multiple abiotic stresses in sunflower.\n  First we developed stress indicators to characterize 14 environments for\nthree abiotic stresses (cold, drought and nitrogen) using the SUNFLO crop model\nand phenotypic variations of three commercial varieties. The computed plant\nstress indicators better explain yield variation than descriptors at the\nclimatic or crop levels. In those environments, we observed oil yield of 317\nsunflower hybrids and regressed it with three selected stress indicators. The\nslopes of cold stress norm reaction were used as plasticity phenotypes in the\nfollowing genome-wide association study.\n  Among the 65,534 tested SNP, we identified nine QTL controlling oil yield\nplasticity to cold stress. Associated SNP are localized in genes previously\nshown to be involved in cold stress responses: oligopeptide transporters, LTP,\ncystatin, alternative oxidase, or root development. This novel approach opens\nnew perspectives to identify genomic regions involved in\ngenotype-by-environment interaction of a complex traits to multiple stresses in\nrealistic natural or agronomical conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06447v1"
    },
    {
        "title": "Essentiality, conservation, evolutionary pressure and codon bias in\n  bacterial genes",
        "authors": [
            "Maddalena Dilucca",
            "Giulio Cimini",
            "Andrea Giansanti"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Essential genes constitute the core of genes which cannot be mutated too much\nnor lost along the evolutionary history of a species. Natural selection is\nexpected to be stricter on essential genes and on conserved (highly shared)\ngenes, than on genes that are either nonessential or peculiar to a single or a\nfew species. In order to further assess this expectation, we study here how\nessentiality of a gene is connected with its degree of conservation among\nseveral unrelated bacterial species, each one characterised by its own codon\nusage bias. Confirming previous results on E. coli, we show the existence of a\nuniversal exponential relation between gene essentiality and conservation in\nbacteria. Moreover we show that, within each bacterial genome, there are at\nleast two groups of functionally distinct genes, characterised by different\nlevels of conservation and codon bias: i) a core of essential genes, mainly\nrelated to cellular information processing; ii) a set of less conserved\nnonessential genes with prevalent functions related to metabolism. In\nparticular, the genes in the first group are more retained among species, are\nsubject to a stronger purifying conservative selection and display a more\nlimited repertoire of synonymous codons. The core of essential genes is close\nto the minimal bacterial genome, which is in the focus of recent studies in\nsynthetic biology, though we confirm that orthologs of genes that are essential\nin one species are not necessarily essential in other species. We also list a\nset of highly shared genes which, reasonably, could constitute a reservoir of\ntargets for new anti-microbial drugs.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.07850v2"
    },
    {
        "title": "Role of distal enhancers in shaping 3D-folding patterns and defining\n  human-specific features of interphase chromatin architecture in embryonic\n  stem cells",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Molecular and genetic definitions of human-specific changes to genomic\nregulatory networks (GRNs) contributing to development of unique to human\nphenotypes remain a highly significant challenge. Genome-wide proximity\nplacement analysis of diverse families of human-specific genomic regulatory\nloci (HSGRL) identified topologically-associating domains (TADs) that are\nsignificantly enriched for HSGRL and designated rapidly-evolving in humans TADs\n(Genome Biol Evol. 2016 8; 2774-88). Here, the analysis of HSGRL, hESC-enriched\nenhancers, super-enhancers (SEs), and specific sub-TAD structures termed\nsuper-enhancer domains (SEDs) has been performed. Markedly distinct features of\nthe principal regulatory structures of interphase chromatin evolved in the hESC\ngenome compared to mouse: the SED quantity is 3-fold higher and the median SED\nsize is significantly larger. Concomitantly, the overall TAD quantity is\nincreased by 42% while the median TAD size is significantly decreased (p =\n9.11E-37) in the hESC genome. Present analyses illustrate a putative global\nrole for HSGRL in shaping the human-specific features of the interphase\nchromatin organization and functions, which are facilitated by accelerated\ncreation of new enhancers associated with targeted placement of HSGRL at\ndefined genomic coordinates. A trend toward the convergence of TAD and SED\narchitectures of interphase chromatin in the hESC genome may reflect changes of\n3D-folding patterns of linear chromatin fibers designed to enhance both\nregulatory complexity and functional precision of GRNs by creating\npredominantly a single gene per regulatory domain structures.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.09614v1"
    },
    {
        "title": "MDA in Capillary for Whole Genome Amplification",
        "authors": [
            "Junji Li",
            "Na Lu",
            "Xulian Shi",
            "Yi Qiao",
            "Liang Chen",
            "Mengqin Duan",
            "Yong Hou",
            "Qinyu Ge",
            "Yuhan Tao",
            "Jing Tu",
            "Zuhong Lu"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Whole genome amplification (WGA) plays an important role in sample\npreparation of low-input templates for high-throughput sequencing. Multiple\ndisplacement amplification (MDA), a popular isothermal WGA method, suffers a\nmajor hurdle of highly uneven amplification. Optimizations have been made in\nthe past by separating the reagents into numbers of tiny chambers or droplets\nin microfluidic devices, which significantly improves the amplification\nuniformity of MDA. However, skill barrier still exists for biological\nresearchers to handle chip fabrication and droplet manipulation. Here, we\npresent a novel MDA protocol, in-capillary MDA (icMDA), which significantly\nsimplifies the manipulation and improves the uniformity of amplification by\ndispersing reagents in a long quasi-1D capillary tubing. We demonstrated that\nicMDA is able to accurately detect SNVs with higher efficiency and sensitivity.\nMoreover, this straightforward method employs neither customized instruments\nnor complicated operations, making it a ready-to-use approach for most\nlaboratories.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.10647v1"
    },
    {
        "title": "Minimap2: pairwise alignment for nucleotide sequences",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Motivation: Recent advances in sequencing technologies promise ultra-long\nreads of $\\sim$100 kilo bases (kb) in average, full-length mRNA or cDNA reads\nin high throughput and genomic contigs over 100 mega bases (Mb) in length.\nExisting alignment programs are unable or inefficient to process such data at\nscale, which presses for the development of new alignment algorithms.\n  Results: Minimap2 is a general-purpose alignment program to map DNA or long\nmRNA sequences against a large reference database. It works with accurate short\nreads of $\\ge$100bp in length, $\\ge$1kb genomic reads at error rate $\\sim$15%,\nfull-length noisy Direct RNA or cDNA reads, and assembly contigs or closely\nrelated full chromosomes of hundreds of megabases in length. Minimap2 does\nsplit-read alignment, employs concave gap cost for long insertions and\ndeletions (INDELs) and introduces new heuristics to reduce spurious alignments.\nIt is 3-4 times faster than mainstream short-read mappers at comparable\naccuracy and $\\ge$30 times faster at higher accuracy for both genomic and mRNA\nreads, surpassing most aligners specialized in one type of alignment.\n  Availability and implementation: https://github.com/lh3/minimap2\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1708.01492v5"
    },
    {
        "title": "Determining whether the non-protein-coding DNA sequences are in a\n  complex interactive relationship by using an artificial intelligence method",
        "authors": [
            "Kerim Arioglu",
            "Umut Eser"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Non protein coding regions of the human genome contain many complex patterns\nwhich regulate the cellular activity. Studying the human genome is limited by\nthe lack of understanding of its features and their complex interactions.\nHowever, recent advances in AI research have enabled automatically learning\nrepresentations of high dimensional complex data without feature engineering,\nusing deep neural networks. Therefore, in this paper, we demonstrate that a\nconvolutional neural network can learn a representation of DNA sequence without\nspecifying any motifs or patterns, such that it becomes capable of predicting\nwhether a DNA sequence is natural or artificial. The trained model could\ndistinguish scrambled vs real DNA sequences for scrambling lengths of 2 bp, 10\nbp, 50 bp and even 100 bp, with a significantly higher accuracy than linear\nSVMs. With this study, we have discovered that regions of non protein coding\nDNA might have meaningful interactions at even longer than 100 bp distances\neven though they do not code proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04019v1"
    },
    {
        "title": "GRIM-filter: fast seed filtering in read mapping using emerging memory\n  technologies",
        "authors": [
            "Jeremie S Kim",
            "Damla Senol",
            "Hongyi Xin",
            "Donghyuk Lee",
            "Saugata Ghose",
            "Mohammed Alser",
            "Hasan Hassan",
            "Oguz Ergin",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Motivation: Seed filtering is critical in DNA read mapping, a process where\nbillions of DNA fragments (reads) sampled from a donor are mapped onto a\nreference genome to identify genomic variants of the donor. Read mappers 1)\nquickly generate possible mapping locations (i.e., seeds) for each read, 2)\nextract reference sequences at each of the mapping locations, and then 3) check\nsimilarity between each read and its associated reference sequences with a\ncomputationally expensive dynamic programming algorithm (alignment) to\ndetermine the origin of the read. Location filters come into play before\nalignment, discarding seed locations that alignment would have deemed a poor\nmatch. The ideal location filter would discard all poor matching locations\nprior to alignment such that there is no wasted computation on poor alignments.\n  Results: We propose a novel filtering algorithm, GRIM-Filter, optimized to\nexploit emerging 3D-stacked memory systems that integrate computation within a\nstacked logic layer, enabling processing-in-memory (PIM). GRIM-Filter quickly\nfilters locations by 1) introducing a new representation of coarse-grained\nsegments of the reference genome and 2) using massively-parallel in-memory\noperations to identify read presence within each coarse-grained segment. Our\nevaluations show that for 5% error acceptance rates, GRIM-Filter eliminates\n5.59x-6.41x more false negatives and exhibits end-to-end speedups of\n1.81x-3.65x compared to mappers employing the best previous filtering\nalgorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04329v1"
    },
    {
        "title": "Integrative analysis reveals disrupted pathways regulated by microRNAs\n  in cancer",
        "authors": [
            "Gary Wilk",
            "Rosemary Braun"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  MicroRNAs (miRNAs) are small endogenous regulatory molecules that modulate\ngene expression post-transcriptionally. Although differential expression of\nmiRNAs have been implicated in many diseases (including cancers), the\nunderlying mechanisms of action remain unclear. Because each miRNA can target\nmultiple genes, miRNAs may potentially have functional implications for the\noverall behavior of entire pathways. Here we investigate the functional\nconsequences of miRNA dysregulation through an integrative analysis of miRNA\nand mRNA expression data using a novel approach that incorporates pathway\ninformation a priori. By searching for miRNA-pathway associations that differ\nbetween healthy and tumor tissue, we identify specific relationships at the\nsystems-level which are disrupted in cancer. Our approach is motivated by the\nhypothesis that if a miRNA and pathway are associated, then the expression of\nthe miRNA and the collective behavior of the genes in a pathway will be\ncorrelated. As such, we first obtain an expression-based summary of pathway\nactivity using Isomap, a dimension reduction method which can articulate\nnonlinear structure in high-dimensional data. We then search for miRNAs that\nexhibit differential correlations with the pathway summary between phenotypes\nas a means of finding aberrant miRNA-pathway coregulation in tumors. We apply\nour method to cancer data using gene and miRNA expression datasets from The\nCancer Genome Atlas (TCGA) and compare ${\\sim}10^5$ miRNA-pathway relationships\nbetween healthy and tumor samples from four tissues (breast, prostate, lung,\nand liver). Many of the flagged pairs we identify have a biological basis for\ndisruption in cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.05765v1"
    },
    {
        "title": "Integrate Multi-omic Data Using Affinity Network Fusion (ANF) for Cancer\n  Patient Clustering",
        "authors": [
            "Tianle Ma",
            "Aidong Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Clustering cancer patients into subgroups and identifying cancer subtypes is\nan important task in cancer genomics. Clustering based on comprehensive\nmulti-omic molecular profiling can often achieve better results than those\nusing a single data type, since each omic data type (representing one view of\npatients) may contain complementary information. However, it is challenging to\nintegrate heterogeneous omic data types directly. Based on one popular method\n-- Similarity Network Fusion (SNF), we presented Affinity Network Fusion (ANF)\nin this paper, an \"upgrade\" of SNF with several advantages. Similar to SNF, ANF\ntreats each omic data type as one view of patients and learns a fused affinity\n(transition) matrix for clustering. We applied ANF to a carefully processed\nharmonized cancer dataset downloaded from GDC data portals consisting of 2193\npatients, and generated promising results on clustering patients into correct\ndisease types. Our experimental results also demonstrated the power of feature\nselection and transformation combined with using ANF in patient clustering.\nMoreover, eigengap analysis suggests that the learned affinity matrices of four\ncancer types using our proposed framework may have successfully captured\npatient group structure and can be used for discovering unknown cancer\nsubtypes.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.07136v1"
    },
    {
        "title": "Method for identification of condition-associated public antigen\n  receptor sequences",
        "authors": [
            "Mikhail V. Pogorelyy",
            "Anastasia A. Minervina",
            "Dmitriy M. Chudakov",
            "Ilgar Z. Mamedov",
            "Yury B. Lebedev",
            "Thierry Mora",
            "Aleksandra M. Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Diverse repertoires of hypervariable immunoglobulin receptors (TCR and BCR)\nrecognize antigens in the adaptive immune system. The development of\nimmunoglobulin receptor repertoire sequencing methods makes it possible to\nperform repertoire-wide disease association studies of antigen receptor\nsequences. We developed a statistical framework for associating receptors to\ndisease from only a small cohort of patients, with no need for a control\ncohort. Our method successfully identifies previously validated Cytomegalovirus\nand type 1 diabetes responsive receptors.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.09703v1"
    },
    {
        "title": "Nanopore Sequencing Technology and Tools for Genome Assembly:\n  Computational Analysis of the Current State, Bottlenecks and Future\n  Directions",
        "authors": [
            "Damla Senol Cali",
            "Jeremie S. Kim",
            "Saugata Ghose",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Nanopore sequencing technology has the potential to render other sequencing\ntechnologies obsolete with its ability to generate long reads and provide\nportability. However, high error rates of the technology pose a challenge while\ngenerating accurate genome assemblies. The tools used for nanopore sequence\nanalysis are of critical importance as they should overcome the high error\nrates of the technology. Our goal in this work is to comprehensively analyze\ncurrent publicly available tools for nanopore sequence analysis to understand\ntheir advantages, disadvantages, and performance bottlenecks. It is important\nto understand where the current tools do not perform well to develop better\ntools. To this end, we 1) analyze the multiple steps and the associated tools\nin the genome assembly pipeline using nanopore sequence data, and 2) provide\nguidelines for determining the appropriate tools for each step. We analyze\nvarious combinations of different tools and expose the tradeoffs between\naccuracy, performance, memory usage and scalability. We conclude that our\nobservations can guide researchers and practitioners in making conscious and\neffective choices for each step of the genome assembly pipeline using nanopore\nsequence data. Also, with the help of bottlenecks we have found, developers can\nimprove the current tools or build new ones that are both accurate and fast, in\norder to overcome the high error rates of the nanopore sequencing technology.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.08774v4"
    },
    {
        "title": "Ococo: an online variant and consensus caller",
        "authors": [
            "Karel Břinda",
            "Valentina Boeva",
            "Gregory Kucherov"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Motivation: Identifying genomic variants is an essential step for connecting\ngenotype and phenotype. The usual approach consists of statistical inference of\nvariants from alignments of sequencing reads. State-of-the-art variant callers\ncan resolve a wide range of different variant types with high accuracy.\nHowever, they require that all read alignments be available from the beginning\nof variant calling and be sorted by coordinates. Sorting is computationally\nexpensive, both memory- and speed-wise, and the resulting pipelines suffer from\nstoring and retrieving large alignments files from external memory. Therefore,\nthere is interest in developing methods for resource-efficient variant calling.\n  Results: We present Ococo, the first program capable of inferring variants in\na real-time, as read alignments are fed in. Ococo inputs unsorted alignments\nfrom a stream and infers single-nucleotide variants, together with a genomic\nconsensus, using statistics stored in compact several-bit counters. Ococo\nprovides a fast and memory-efficient alternative to the usual variant calling.\nIt is particularly advantageous when reads are sequenced or mapped\nprogressively, or when available computational resources are at a premium.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.01146v2"
    },
    {
        "title": "DCJVis: visualization of genome rearrangements using DCJ operations",
        "authors": [
            "Sruthi Chappidi",
            "Sergey Bereg"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The {\\em double-cut-and-join} (DCJ) operation, introduced by Yancopoulos\n\\emph{et al.}, allows minimum edit distance to be computed by modeling all\npossible classical rearrangement operations, such as inversions, fusions,\nfissions, translocations, and transpositions, in linear-time between two\ngenomes. However, there is lack of visualization tool that can effectively\npresent DCJ operations that will help biologists to use DCJ operation. In this\npaper, a new visualization program is introduced, DCJVis, to create a diagram\nof each DCJ operation necessary to transform between the genomes of two\ndistinct organisms by describing a possible sequence of genome graphs based on\nthe selected gene adjacency on the source genome for the DCJ operation. Our\nprogram is the first visualization tool for DCJ operations using circular\nlayout. Specifically, the genomes of \\textit{Saccharomyces cerevisiae} and\n\\textit{Candida albicans} are used to demonstrate the functionality of this\nprogram and provide an example of the type of problem this program can solve\nfor biologists.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.09403v1"
    },
    {
        "title": "Universal and idiosyncratic characteristic lengths in bacterial genomes",
        "authors": [
            "Ivan Junier",
            "Paul Frémont",
            "Olivier Rivoire"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  In condensed matter physics, simplified descriptions are obtained by\ncoarse-graining the features of a system at a certain characteristic length,\ndefined as the typical length beyond which some properties are no longer\ncorrelated. From a physics standpoint, in vitro DNA has thus a characteristic\nlength of 300 base pairs (bp), the Kuhn length of the molecule beyond which\ncorrelations in its orientations are typically lost. From a biology standpoint,\nin vivo DNA has a characteristic length of 1000 bp, the typical length of\ngenes. Since bacteria live in very different physico-chemical conditions and\nsince their genomes lack translational invariance, whether larger, universal\ncharacteristic lengths exist is a non-trivial question. Here, we examine this\nproblem by leveraging the large number of fully sequenced genomes available in\npublic databases. By analyzing GC content correlations and the evolutionary\nconservation of gene contexts (synteny) in hundreds of bacterial chromosomes,\nwe conclude that a fundamental characteristic length around 10-20 kb can be\ndefined. This characteristic length reflects elementary structures involved in\nthe coordination of gene expression, which are present all along the genome of\nnearly all bacteria. Technically, reaching this conclusion required us to\nimplement methods that are insensitive to the presence of large idiosyncratic\ngenomic features, which may co-exist along these fundamental universal\nstructures.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07585v1"
    },
    {
        "title": "Differential proteomics highlights macrophage-specific responses to\n  amorphous silica nanoparticles",
        "authors": [
            "Bastien Dalzon",
            "Catherine Aude-Garcia",
            "Véronique Collin-Faure",
            "Hélène Diemer",
            "David Béal",
            "Fanny Dussert",
            "Daphna Fenel",
            "Guy Schoehn",
            "Sarah Cianférani",
            "Marie Carrière",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The technological and economic benefits of engineered nanomaterials may be\noffset by their adverse effects on living organisms. One of the highly produced\nnanomaterials under such scrutiny is amorphous silica nanoparticles, which are\nknown to have an appreciable, although reversible, inflammatory potential. This\nis due to their selective toxicity toward macrophages, and it is thus important\nto study the cellular responses of this cell type to silica nanoparticles to\nbetter understand the direct or indirect adverse effects of nanosilica. We have\nhere studied the responses of the RAW264.7 murine macrophage cells and of the\ncontrol MPC11 plasma cells to subtoxic concentrations of nanosilica, using a\ncombination of pro-teomic and targeted approaches. This allowed us to document\nalterations in the cellular cytoskeleton, in the phagocytic capacity of the\ncells as well as their ability to respond to bacterial stimuli. More\nsurprisingly, silica nanoparticles also induce a greater sensitivity of\nmacrophages to DNA alkylating agents, such as styrene oxide, even at doses\nwhich do not induce any appreciable cell death.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08421v1"
    },
    {
        "title": "Zinc oxide induces the stringent response and major reorientations in\n  the central metabolism of Bacillus subtilis",
        "authors": [
            "Sylvie Luche",
            "Elise Eymard-Vernain",
            "Hélène Diemer",
            "Alain Van Dorsselaer",
            "Thierry Rabilloud",
            "Cécile Lelong"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Microorganisms, such as bacteria, are one of the first targets of\nnanoparticles in the environment. In this study, we tested the effect of two\nnanoparticles, ZnO and TiO2, with the salt ZnSO4 as the control, on the\nGram-positive bacterium Bacillus subtilis by 2D gel electrophoresis-based\nproteomics. Despite a significant effect on viability (LD50), TiO2 NPs had no\ndetectable effect on the proteomic pattern, while ZnO NPs and ZnSO4\nsignificantly modified B. subtilis metabolism. These results allowed us to\nconclude that the effects of ZnO observed in this work were mainly attributable\nto Zn dissolution in the culture media. Proteomic analysis highlighted twelve\nmodulated proteins related to central metabolism: MetE and MccB (cysteine\nmetabolism), OdhA, AspB, IolD, AnsB, PdhB and YtsJ (Krebs cycle) and XylA,\nYqjI, Drm and Tal (pentose phosphate pathway). Biochemical assays, such as free\nsulfhydryl, CoA-SH and malate dehydrogenase assays corroborated the observed\ncentral metabolism reorientation and showed that Zn stress induced oxidative\nstress, probably as a consequence of thiol chelation stress by Zn ions. The\nother patterns affected by ZnO and ZnSO4 were the stringent response and the\ngeneral stress response. Nine proteins involved in or controlled by the\nstringent response showed a modified expression profile in the presence of ZnO\nNPs or ZnSO4: YwaC, SigH, YtxH, YtzB, TufA, RplJ, RpsB, PdhB and Mbl. An\nincrease in the ppGpp concentration confirmed the involvement of the stringent\nresponse during a Zn stress. All these metabolic reorientations in response to\nZn stress were probably the result of complex regulatory mechanisms including\nat least the stringent response via YwaC.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08722v1"
    },
    {
        "title": "NGS Based Haplotype Assembly Using Matrix Completion",
        "authors": [
            "Sina Majidian",
            "MH Kahaei"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  We apply matrix completion methods for haplotype assembly from NGS reads to\ndevelop the new HapSVT, HapNuc, and HapOPT algorithms. This is performed by\napplying a mathematical model to convert the reads to an incomplete matrix and\nestimating unknown components. This process is followed by quantizing and\ndecoding the completed matrix in order to estimate haplotypes. These algorithms\nare compared to the state-of-the-art algorithms using simulated data as well as\nthe real fosmid data. It is shown that the SNP missing rate and the haplotype\nblock length of the proposed HapOPT are better than those of HapCUT2 with\ncomparable accuracy in terms of reconstruction rate and switch error rate. A\nprogram implementing the proposed algorithms in MATLAB is freely available at\nhttps://github.com/smajidian/HapMC.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.09864v2"
    },
    {
        "title": "Eight-cluster structure of chloroplast genomes differs from similar one\n  observed for bacteria",
        "authors": [
            "Michael Sadovsky",
            "Maria Senashova",
            "Andrew Malyshev"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Previously, a seven-cluster pattern claiming to be a universal one in\nbacterial genomes has been reported. Keeping in mind the most popular theory of\nchloroplast origin, we checked whether a similar pattern is observed in\nchloroplast genomes. Surprisingly, eight cluster structure has been found, for\nchloroplasts. The pattern observed for chloroplasts differs rather\nsignificantly, from bacterial one, and from that latter observed for\ncyanobacteria. The structure is provided by clustering of the fragments of\nequal length isolated within a genome so that each fragment is converted in\ntriplet frequency dictionary with non-overlapping triplets with no gaps in\nframe tiling. The points in 63-dimensional space were clustered due to elastic\nmap technique. The eight cluster found in chloroplasts comprises the fragments\nof a genome bearing tRNA genes and exhibiting excessively high\n$\\mathsf{GC}$-content, in comparison to the entire genome.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.02962v1"
    },
    {
        "title": "Modeling and analysis of RNA-seq data: a review from a statistical\n  perspective",
        "authors": [
            "Wei Vivian Li",
            "Jingyi Jessica Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Background: Since the invention of next-generation RNA sequencing (RNA-seq)\ntechnologies, they have become a powerful tool to study the presence and\nquantity of RNA molecules in biological samples and have revolutionized\ntranscriptomic studies. The analysis of RNA-seq data at four different levels\n(samples, genes, transcripts, and exons) involve multiple statistical and\ncomputational questions, some of which remain challenging up to date.\n  Results: We review RNA-seq analysis tools at the sample, gene, transcript,\nand exon levels from a statistical perspective. We also highlight the\nbiological and statistical questions of most practical considerations.\n  Conclusion: The development of statistical and computational methods for\nanalyzing RNA- seq data has made significant advances in the past decade.\nHowever, methods developed to answer the same biological question often rely on\ndiverse statical models and exhibit different performance under different\nscenarios. This review discusses and compares multiple commonly used\nstatistical models regarding their assumptions, in the hope of helping users\nselect appropriate methods as needed, as well as assisting developers for\nfuture method development.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.06050v3"
    },
    {
        "title": "Identification of a complete YPT1 Rab GTPase sequence from the fungal\n  pathogen Colletotrichum incanum",
        "authors": [
            "Cecil Barnett-Neefs",
            "Ruth N. Collins"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Colletotrichum represent a genus of fungal species primarily known as plant\npathogens with severe economic impacts in temperate, subtropical and tropical\nclimates Consensus taxonomy and classification systems for Colletotrichum\nspecies have been undergoing revision as high resolution genomic data becomes\navailable. Here we propose an alternative annotation that provides a complete\nsequence for a Colletotrichum YPT1 gene homolog using the whole genome shotgun\nsequence of Colletotrichum incanum isolated from soybean crops in Illinois,\nUSA.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.00570v1"
    },
    {
        "title": "The Qatar Genome: A Population-Specific Tool for Precision Medicine in\n  the Middle East",
        "authors": [
            "Khalid A. Fakhro",
            "Michelle R. Staudt",
            "Monica Denise Ramstetter",
            "Amal Robay",
            "Joel A. Malek",
            "Ramin Badii",
            "Ajayeb Al-Nabet Al-Marri",
            "Charbel Abi Khalil",
            "Alya Al-Shakaki",
            "Omar Chidiac",
            "Dora Stadler",
            "Mahmoud Zirie",
            "Amin Jayyousi",
            "Jacqueline Salit",
            "Jason G. Mezey",
            "Ronald G. Crystal",
            "Juan L. Rodriguez-Flores"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Reaching the full potential of precision medicine depends on the quality of\npersonalized genome interpretation. In order to facilitate precision medicine\nin regions of the Middle East and North Africa (MENA), a population-specific\nreference genome for the indigenous Arab popula-tion of Qatar (QTRG) was\nconstructed by incorporating allele frequency data from sequencing of 1,161\nQataris, representing 0.4% of the population. A total of 20.9 million SNP and\n3.1 million indels were observed in Qatar, including an average of 1.79% novel\nvariants per individual ge-nome. Replacement of the GRCh37 standard reference\nwith QTRG in a best practices genome analysis workflow resulted in an average\nof 7* deeper coverage depth (an improvement of 23%), and 756,671 fewer variants\non average, a reduction of 16% that is attributed to common Qatari alleles\nbeing present in the QTRG reference. The benefit for using QTRG varies across\nances-tries, a factor that should be taken into consideration when selecting an\nappropriate reference for analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03233v2"
    },
    {
        "title": "A quick guide for student-driven community genome annotation",
        "authors": [
            "Prashant S. Hosmani",
            "Teresa Shippy",
            "Sherry Miller",
            "Joshua B. Benoit",
            "Monica Munoz-Torres",
            "Mirella Flores",
            "Lukas A. Mueller",
            "Helen Wiersma-Koch",
            "Tom D'elia",
            "Susan J. Brown",
            "Surya Saha"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  High quality gene models are necessary to expand the molecular and genetic\ntools available for a target organism, but these are available for only a\nhandful of model organisms that have undergone extensive curation and\nexperimental validation over the course of many years. The majority of gene\nmodels present in biological databases today have been identified in draft\ngenome assemblies using automated annotation pipelines that are frequently\nbased on orthologs from distantly related model organisms. Manual curation is\ntime consuming and often requires substantial expertise, but is instrumental in\nimproving gene model structure and identification. Manual annotation may seem\nto be a daunting and cost-prohibitive task for small research communities but\ninvolving undergraduates in community genome annotation consortiums can be\nmutually beneficial for both education and improved genomic resources. We\noutline a workflow for efficient manual annotation driven by a team of\nprimarily undergraduate annotators. This model can be scaled to large teams and\nincludes quality control processes through incremental evaluation. Moreover, it\ngives students an opportunity to increase their understanding of genome biology\nand to participate in scientific research in collaboration with peers and\nsenior researchers at multiple institutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03602v2"
    },
    {
        "title": "Transcription Factor-DNA Binding Via Machine Learning Ensembles",
        "authors": [
            "Yue Fan",
            "Mark Kon",
            "Charles DeLisi"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  We present ensemble methods in a machine learning (ML) framework combining\npredictions from five known motif/binding site exploration algorithms. For a\ngiven TF the ensemble starts with position weight matrices (PWM's) for the\nmotif, collected from the component algorithms. Using dimension reduction, we\nidentify significant PWM-based subspaces for analysis. Within each subspace a\nmachine classifier is built for identifying the TF's gene (promoter) targets\n(Problem 1). These PWM-based subspaces form an ML-based sequence analysis tool.\nProblem 2 (finding binding motifs) is solved by agglomerating k-mer (string)\nfeature PWM-based subspaces that stand out in identifying gene targets. We\napproach Problem 3 (binding sites) with a novel machine learning approach that\nuses promoter string features and ML importance scores in a classification\nalgorithm locating binding sites across the genome. For target gene\nidentification this method improves performance (measured by the F1 score) by\nabout 10 percentage points over the (a) motif scanning method and (b) the\ncoexpression-based association method. Top motif outperformed 5 component\nalgorithms as well as two other common algorithms (BEST and DEME). For\nidentifying individual binding sites on a benchmark cross species database\n(Tompa et al., 2005) we match the best performer without much human\nintervention. It also improved the performance on mammalian TFs.\n  The ensemble can integrate orthogonal information from different weak\nlearners (potentially using entirely different types of features) into a\nmachine learner that can perform consistently better for more TFs. The TF gene\ntarget identification component (problem 1 above) is useful in constructing a\ntranscriptional regulatory network from known TF-target associations. The\nensemble is easily extendable to include more tools as well as future PWM-based\ninformation.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03771v1"
    },
    {
        "title": "The sequencing and interpretation of the genome obtained from a Serbian\n  individual",
        "authors": [
            "Wazim Mohammed Ismail",
            "Kymberleigh A. Pagel",
            "Vikas Pejaver",
            "Simo V. Zhang",
            "Sofia Casasa",
            "Matthew Mort",
            "David N. Cooper",
            "Matthew W. Hahn",
            "Predrag Radivojac"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Recent genetic studies and whole-genome sequencing projects have greatly\nimproved our understanding of human variation and clinically actionable genetic\ninformation. Smaller ethnic populations, however, remain underrepresented in\nboth individual and large-scale sequencing efforts and hence present an\nopportunity to discover new variants of biomedical and demographic\nsignificance. This report describes the sequencing and analysis of a genome\nobtained from an individual of Serbian origin, introducing tens of thousands of\npreviously unknown variants to the currently available pool. Ancestry analysis\nplaces this individual in close proximity of the Central and Eastern European\npopulations; i.e., closest to Croatian, Bulgarian and Hungarian individuals\nand, in terms of other Europeans, furthest from Ashkenazi Jewish, Spanish,\nSicilian, and Baltic individuals. Our analysis confirmed gene flow between\nNeanderthal and ancestral pan-European populations, with similar contributions\nto the Serbian genome as those observed in other European groups. Finally, to\nassess the burden of potentially disease-causing/clinically relevant variation\nin the sequenced genome, we utilized manually curated genotype-phenotype\nassociation databases and variant-effect predictors. We identified several\nvariants that have previously been associated with severe early-onset disease\nthat is not evident in the proband, as well as variants that could yet prove to\nbe clinically relevant to the proband over the next decades. The presence of\nnumerous private and low-frequency variants along with the observed and\npredicted disease-causing mutations in this genome exemplify some of the global\nchallenges of genome interpretation, especially in the context of understudied\nethnic groups.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.06950v1"
    },
    {
        "title": "Quantifying Local Randomness in Human DNA and RNA Sequences Using Erdos\n  Motifs",
        "authors": [
            "Wentian Li",
            "Dimitrios Thanos",
            "Astero Provata"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  In 1932, Paul Erdos asked whether a random walk constructed from a binary\nsequence can achieve the lowest possible deviation (lowest discrepancy), for\nthe sequence itself and for all its subsequences formed by homogeneous\narithmetic progressions. Although avoiding low discrepancy is impossible for\ninfinite sequences, as recently proven by Terence Tao, attempts were made to\nconstruct such sequences with finite lengths. We recognize that such\nconstructed sequences (we call these \"Erdos sequences\") exhibit certain\nhallmarks of randomness at the local level: they show roughly equal frequencies\nof subsequences, and at the same time exclude the trivial periodic patterns.\nFor the human DNA we examine the frequency of a set of Erdos motifs of\nlength-10 using three nucleotides-to-binary mappings. The particular length-10\nErdos sequence is derived by the length-11 Mathias sequence and is identical\nwith the first 10 digits of the Thue-Morse sequence, underscoring the fact that\nboth are deficient in periodicities. Our calculations indicate that: (1) the\npurine (A and G)/pyridimine (C and T) based Erdos motifs are greatly\nunderrepresented in the human genome, (2) the strong(G and C)/weak(A and T)\nbased Erdos motifs are slightly overrepresented, (3) the densities of the two\nare negatively correlated, (4) the Erdos motifs based on all three mappings\nbeing combined are slightly underrepresented, and (5) the strong/weak based\nErdos motifs are greatly overrepresented in the human messenger RNA sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10248v2"
    },
    {
        "title": "Computational and molecular dissection of an X-box cis-Regulatory module",
        "authors": [
            "Timothy Burton Warrington"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Ciliopathies are a class of human diseases marked by dysfunction of the\ncellular organelle, cilia. While many of the molecular components that make up\ncilia have been identified and studied, comparatively little is understood\nabout the transcriptional regulation of genes encoding these components. The\nconserved transcription factor Regulatory Factor X (RFX)/DAF-19, which acts\nthrough binding to the cis-regulatory motif known as X-box, has been shown to\nregulate ciliary genes in many animals from Caenorhabditis elegans to humans.\nHowever, accumulating evidence suggests that RFX is unable to initiate\ntranscription on its own. Therefore, other factors and cis-regulatory elements\nare likely required. One such element, a DNA motif called the C-box, has\nrecently been identified in C. elegans. It is still unclear if the X-box and\nC-boxes are the only regulatory elements involved and how they interact. To\nthis end, I analyzed the transcriptional regulation of dyf-5, the C. elegans\northolog of the human ciliopathy gene Male-Associated Kinase (MAK). Using\ncomputational methods, I was able to confirm the presence of the previously\nreported X-box and C-boxes as well as identifying an additional C-box. By\nsequentially mutating each of the identified motifs, I identified the role each\npotential motif plays in transcriptional regulation of dyf-5. My results showed\nthat only the X-box and the three C-boxes are necessary and are sufficient to\ndrive transcription, with the X-box and the centre C-box being the major\ncontributors and the other two C-boxes enhancing expression. This study\nadvances the knowledge of gene regulation in general and will further our\nunderstanding of ciliopathies and the mutations that cause them.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.00478v1"
    },
    {
        "title": "Analysis of evolutionary origins of genomic loci harboring 59,732\n  candidate human-specific regulatory sequences identifies genetic divergence\n  patterns during evolution of Great Apes",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Our view of the universe of genomic regions harboring various types of\ncandidate human-specific regulatory sequences (HSRS) has been markedly expanded\nin recent years. To infer the evolutionary origins of loci harboring HSRS,\nanalyses of conservations patterns of 59,732 loci in Modern Humans, Chimpanzee,\nBonobo, Gorilla, Orangutan, Gibbon, and Rhesus genomes have been performed. Two\nmajor evolutionary pathways have been identified comprising thousands of\nsequences that were either inherited from extinct common ancestors (ECAs) or\ncreated de novo in humans after human/chimpanzee split. Thousands of HSRS\nappear inherited from ECAs yet bypassed genomes of our closest evolutionary\nrelatives, presumably due to the incomplete lineage sorting and/or\nspecies-specific loss or regulatory DNA. The bypassing pattern is prominent for\nHSRS associated with development and functions of human brain. Common genomic\nloci that may contributed to speciation during evolution of Great Apes comprise\n248 insertions sites of African Great Ape-specific retrovirus PtERV1 (45.9%; p\n= 1.03E-44) intersecting regions harboring 442 HSRS, which are enriched for\nHSRS associated with human-specific (HS) changes of gene expression in cerebral\norganoids. Among non-human primates (NHP), most significant fractions of\ncandidate HSRS associated with HS expression changes in both excitatory neurons\n(347 loci; 67%) and radial glia (683 loci; 72%) are highly conserved in Gorilla\ngenome. Modern Humans acquired unique combinations of regulatory sequences\nhighly conserved in distinct species of six NHP separated by 30 million years\nof evolution. Concurrently, this unique mosaic of regulatory sequences\ninherited from ECAs was supplemented with 12,486 created de novo HSRS. These\nobservations support the model of complex continuous speciation process during\nevolution of Great Apes that is not likely to occur as an instantaneous event.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01062v1"
    },
    {
        "title": "CTCF Degradation Causes Increased Usage of Upstream Exons in Mouse\n  Embryonic Stem Cells",
        "authors": [
            "Boyi Yang",
            "Nabil Aounallah"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Transcriptional repressor CTCF is an important regulator of chromatin 3D\nstructure, facilitating the formation of topologically associating domains\n(TADs). However, its direct effects on gene regulation is less well understood.\nHere, we utilize previously published ChIP-seq and RNA-seq data to investigate\nthe effects of CTCF on alternative splicing of genes with CTCF sites. We\ncompared the amount of RNA-seq signals in exons upstream and downstream of\nbinding sites following auxin-induced degradation of CTCF in mouse embryonic\nstem cells. We found that changes in gene expression following CTCF depletion\nwere significant, with a general increase in the presence of upstream exons. We\ninfer that a possible mechanism by which CTCF binding contributes to\nalternative splicing is by causing pauses in the transcription mechanism during\nwhich splicing elements are able to concurrently act on upstream exons already\ntranscribed into RNA.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.03205v1"
    },
    {
        "title": "A Comparison of Microbial Genome Web Portals",
        "authors": [
            "Peter D. Karp",
            "Natalia Ivanova",
            "Markus Krummenacker",
            "Nikos Kyrpides",
            "Mario Latendresse",
            "Peter Midford",
            "Wai Kit Ong",
            "Suzanne Paley",
            "Rekha Seshadri"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Microbial genome web portals have a broad range of capabilities that address\na number of information-finding and analysis needs for scientists. This article\ncompares the capabilities of the major microbial genome web portals to aid\nresearchers in determining which portal(s) are best suited to solving their\ninformation-finding and analytical needs. We assessed both the bioinformatics\ntools and the data content of BioCyc, KEGG, Ensembl Bacteria, KBase, IMG, and\nPATRIC. For each portal, our assessment compared and tallied the available\ncapabilities. The strengths of BioCyc include its genomic and metabolic tools,\nmulti-search capabilities, table-based analysis tools, regulatory network tools\nand data, omics data analysis tools, breadth of data content, and large amount\nof curated data. The strengths of KEGG include its genomic and metabolic tools.\nThe strengths of Ensembl Bacteria include its genomic tools and large number of\ngenomes. The strengths of KBase include its genomic tools and metabolic models.\nThe strengths of IMG include its genomic tools, multi-search capabilities,\nlarge number of genomes, table-based analysis tools, and breadth of data\ncontent. The strengths of PATRIC include its large number of genomes,\ntable-based analysis tools, metabolic models, and breadth of data content.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.12860v1"
    },
    {
        "title": "Whole genome single nucleotide polymorphism genotyping of Staphylococcus\n  aureus",
        "authors": [
            "Changchuan Yin",
            "Stephen S. -T. Yau"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Next-generation sequencing technology enables routine detection of bacterial\npathogens for clinical diagnostics and genetic research. Whole genome\nsequencing has been of importance in the epidemiologic analysis of bacterial\npathogens. However, few whole genome sequencing-based genotyping pipelines are\navailable for practical applications. Here, we present the whole genome\nsequencing-based single nucleotide polymorphism (SNP) genotyping method and\napply to the evolutionary analysis of methicillin-resistant Staphylococcus\naureus. The SNP genotyping method calls genome variants using next-generation\nsequencing reads of whole genomes and calculates the pair-wise Jaccard\ndistances of the genome variants. The method may reveal the high-resolution\nwhole genome SNP profiles and the structural variants of different isolates of\nmethicillin-resistant S. aureus (MRSA) and methicillin-susceptible S. aureus\n(MSSA) strains. The phylogenetic analysis of whole genomes and particular\nregions may monitor and track the evolution and the transmission dynamic of\nbacterial pathogens. The computer programs of the whole genome sequencing-based\nSNP genotyping method are available to the public at\nhttps://github.com/cyinbox/NGS.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.13027v1"
    },
    {
        "title": "GenHap: A Novel Computational Method Based on Genetic Algorithms for\n  Haplotype Assembly",
        "authors": [
            "Andrea Tangherloni",
            "Simone Spolaor",
            "Leonardo Rundo",
            "Marco S. Nobile",
            "Paolo Cazzaniga",
            "Giancarlo Mauri",
            "Pietro Liò",
            "Ivan Merelli",
            "Daniela Besozzi"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The computational problem of inferring the full haplotype of a cell starting\nfrom read sequencing data is known as haplotype assembly, and consists in\nassigning all heterozygous Single Nucleotide Polymorphisms (SNPs) to exactly\none of the two chromosomes. Indeed, the knowledge of complete haplotypes is\ngenerally more informative than analyzing single SNPs and plays a fundamental\nrole in many medical applications. To reconstruct the two haplotypes, we\naddressed the weighted Minimum Error Correction (wMEC) problem, which is a\nsuccessful approach for haplotype assembly. This NP-hard problem consists in\ncomputing the two haplotypes that partition the sequencing reads into two\ndisjoint sub-sets, with the least number of corrections to the SNP values. To\nthis aim, we propose here GenHap, a novel computational method for haplotype\nassembly based on Genetic Algorithms, yielding optimal solutions by means of a\nglobal search process. In order to evaluate the effectiveness of our approach,\nwe run GenHap on two synthetic (yet realistic) datasets, based on the Roche/454\nand PacBio RS II sequencing technologies. We compared the performance of GenHap\nagainst HapCol, an efficient state-of-the-art algorithm for haplotype phasing.\nOur results show that GenHap always obtains high accuracy solutions (in terms\nof haplotype error rate), and is up to 4x faster than HapCol in the case of\nRoche/454 instances and up to 20x faster when compared on the PacBio RS II\ndataset. Finally, we assessed the performance of GenHap on two different real\ndatasets. Future-generation sequencing technologies, producing longer reads\nwith higher coverage, can highly benefit from GenHap, thanks to its capability\nof efficiently solving large instances of the haplotype assembly problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.07689v1"
    },
    {
        "title": "HIV-1 virus cycle replication: a review of RNA polymerase II\n  transcription, alternative splicing and protein synthesis",
        "authors": [
            "Miguel Ramos Pascual"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  HIV virus replication is a time-related process that includes several stages.\nFocusing on the core steps, RNA polymerase II transcripts in an early stage\npre-mRNA containing regulator proteins (i.e nef,tat,rev,vif,vpr,vpu), which are\ncompletely spliced by the spliceosome complex (0.9kb and 1.8kb) and exported to\nthe ribosome for protein synthesis. These splicing and export processes are\nregulated by tat protein, which binds on Trans-activation response (TAR)\nelement, and by rev protein, which binds to the Rev-responsive Element (RRE).\nAs long as these regulators are synthesized, splicing is progressively\ninhibited (from 4.0kb to 9.0kb) and mRNAs are translated into structural and\nenzymatic proteins (env, gag-pol). During this RNAPII scanning and splicing,\naround 40 different multi-cystronic mRNA have been produced. Long-read\nsequencing has been applied to the HIV-1 virus genome (type HXB2CG) with the\nHIV.pro software, a fortran 90 code for simulating the virus replication cycle,\nspecially RNAPII transcription, exon/intron splicing and ribosome protein\nsynthesis, including the frameshift at gag/pol gene and the ribosome pause at\nenv gene. All HIV-1 virus proteins have been identified as far as other ORFs.\nAs observed, tat/rev protein regulators have different length depending on the\nsplicing cleavage site: tat protein varies from 224aa to a final state of 72aa,\nwhereas rev protein from 25aa to 27aa, with a maximum of 119aa. Furthermore,\nseveral ORFs coding for small polypeptides sPEP (less than 10 amino acids) and\nfor other unidentified proteins have been localised with unknown functionality.\nThe detailed analysis of the HIV virus replication and the virus proteomics are\nimportant for identifying which antigens are presented by macrophages to CD4\ncells, for localizing reactive epitopes or for creating transfer vectors to\ndevelop new HIV vaccines and effective therapies.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.05067v2"
    },
    {
        "title": "SARS-CoV-2 and miRNA-like inhibition power",
        "authors": [
            "Jacques Demongeot",
            "Hervé Seligmann"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  (1) Background: RNA viruses and especially coronaviruses could act inside\nhost cells not only by building their own proteins, but also by perturbing the\ncell metabolism. We show the possibility of miRNA-like inhibitions by the\nSARS-CoV-2 concerning for example the hemoglobin and type I interferons\nsyntheses, hence highly perturbing oxygen distribution in vital organs and\nimmune response as described by clinicians; (2) Methods: We compare RNA\nsubsequences of SARS-CoV-2 protein S and RNA-dependent RNA polymerase genes to\nmRNA sequences of beta-globin and type I interferons; (3) Results: RNA\nsubsequences longer than eight nucleotides from SARS-CoV-2 genome could\nhybridize subsequences of the mRNA of beta-globin and of type I interferons;\n(4) Conclusions: Beyond viral protein production, Covid-19 might affect vital\nprocesses like host oxygen transport and immune response.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.00126v1"
    },
    {
        "title": "Strategies to integrate multi-omics data for patient survival prediction",
        "authors": [
            "Lana X Garmire"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genomics, especially multi-omics, has made precision medicine feasible. The\ncompletion and publicly accessible multi-omics resource with clinical outcome,\nsuch as The Cancer Genome Atlas (TCGA) is a great test bed for developing\ncomputational methods that integrate multi-omics data to predict patient cancer\nphenotypes. We have been utilizing TCGA multi-omics data to predict cancer\npatient survival, using a variety of approaches, including prior-biological\nknowledge (such as pathways), and more recently, deep-learning methods. Over\ntime, we have developed methods such as Cox-nnet, DeepProg, and two-stage\nCox-nnet, to address the challenges due to multi-omics and multi-modality.\nDespite the limited sample size (hundreds to thousands) in the training\ndatasets as well as the heterogeneity nature of human populations, these\nmethods have shown significance and robustness at predicting patient survival\nin independent population cohorts. In the following, we would describe in\ndetail these methodologies, the modeling results, and important biological\ninsights revealed by these methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.12455v1"
    },
    {
        "title": "Convex Clustering: An Attractive Alternative to Hierarchical Clustering",
        "authors": [
            "Gary K. Chen",
            "Eric Chi",
            "John Ranola",
            "Kenneth Lange"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  The primary goal in cluster analysis is to discover natural groupings of\nobjects. The field of cluster analysis is crowded with diverse methods that\nmake special assumptions about data and address different scientific aims.\nDespite its shortcomings in accuracy, hierarchical clustering is the dominant\nclustering method in bioinformatics. Biologists find the trees constructed by\nhierarchical clustering visually appealing and in tune with their evolutionary\nperspective. Hierarchical clustering operates on multiple scales\nsimultaneously. This is essential, for instance, in transcriptome data where\none may be interested in making qualitative inferences about how lower-order\nrelationships like gene modules lead to higher-order relationships like\npathways or biological processes. The recently developed method of convex\nclustering preserves the visual appeal of hierarchical clustering while\nameliorating its propensity to make false inferences in the presence of\noutliers and noise. The current paper exploits the proximal distance principle\nto construct a novel algorithm for solving the convex clustering problem. The\nsolution paths generated by convex clustering reveal relationships between\nclusters that are hidden by static methods such as k-means clustering. Our\nconvex clustering software separates parameters, accommodates missing data, and\nsupports prior information on relationships. The software is implemented on ATI\nand nVidia graphics processing units (GPUs) for maximal speed. Several\nbiological examples illustrate the strengths of convex clustering and the\nability of the proximal distance algorithm to handle high-dimensional problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.2065v1"
    },
    {
        "title": "Behavioral individuality reveals genetic control of phenotypic\n  variability",
        "authors": [
            "Julien F. Ayroles",
            "Sean M. Buchanan",
            "Chelsea Jenney",
            "Kyobi Skutt-Kakaria",
            "Jennifer Grenier",
            "Andrew G. Clark",
            "Daniel L. Hartl",
            "Benjamin L. de Bivort"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Variability is ubiquitous in nature and a fundamental feature of complex\nsystems. Few studies, however, have investigated variance itself as a trait\nunder genetic control. By focusing primarily on trait means and ignoring the\neffect of alternative alleles on trait variability, we may be missing an\nimportant axis of genetic variation contributing to phenotypic differences\namong individuals. To study genetic effects on individual-to-individual\nphenotypic variability (or intragenotypic variability), we used a panel of\nDrosophila inbred lines and focused on locomotor handedness, in an assay\noptimized to measure variability. We discovered that some lines had\nconsistently high levels of intragenotypic variability among individuals while\nothers had low levels. We demonstrate that the degree of variability is itself\nheritable. Using a genome-wide association study (GWAS) for the degree of\nintragenotypic variability as the phenotype across lines, we identified several\ngenes expressed in the brain that affect variability in handedness without\naffecting the mean. One of these genes, Ten-a, implicated a neuropil in the\ncentral complex of the fly brain as influencing the magnitude of behavioral\nvariability, a brain region involved in sensory integration and locomotor\ncoordination. We have validated these results using genetic deficiencies, null\nalleles, and inducible RNAi transgenes. This study reveals the constellation of\nphenotypes that can arise from a single genotype and it shows that different\ngenetic backgrounds differ dramatically in their propensity for phenotypic\nvariability. Because traditional mean-focused GWASs ignore the contribution of\nvariability to overall phenotypic variation, current methods may miss important\nlinks between genotype and phenotype.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.3272v1"
    },
    {
        "title": "Methods for Joint Imaging and RNA-seq Data Analysis",
        "authors": [
            "Junhai Jiang",
            "Nan Lin",
            "Shicheng Guo",
            "Jinyun Chen",
            "Momiao Xiong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Emerging integrative analysis of genomic and anatomical imaging data which\nhas not been well developed, provides invaluable information for the holistic\ndiscovery of the genomic structure of disease and has the potential to open a\nnew avenue for discovering novel disease susceptibility genes which cannot be\nidentified if they are analyzed separately. A key issue to the success of\nimaging and genomic data analysis is how to reduce their dimensions. Most\nprevious methods for imaging information extraction and RNA-seq data reduction\ndo not explore imaging spatial information and often ignore gene expression\nvariation at genomic positional level. To overcome these limitations, we extend\nfunctional principle component analysis from one dimension to two dimension\n(2DFPCA) for representing imaging data and develop a multiple functional linear\nmodel (MFLM) in which functional principal scores of images are taken as\nmultiple quantitative traits and RNA-seq profile across a gene is taken as a\nfunction predictor for assessing the association of gene expression with\nimages. The developed method has been applied to image and RNA-seq data of\novarian cancer and KIRC studies. We identified 24 and 84 genes whose\nexpressions were associated with imaging variations in ovarian cancer and KIRC\nstudies, respectively. Our results showed that many significantly associated\ngenes with images were not differentially expressed, but revealed their\nmorphological and metabolic functions. The results also demonstrated that the\npeaks of the estimated regression coefficient function in the MFLM often\nallowed the discovery of splicing sites and multiple isoform of gene\nexpressions.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.3899v1"
    },
    {
        "title": "Visual annotations and a supervised learning approach for evaluating and\n  calibrating ChIP-seq peak detectors",
        "authors": [
            "Toby Dylan Hocking",
            "Patricia Goerner-Potvin",
            "Andreanne Morin",
            "Xiaojian Shao",
            "Guillaume Bourque"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Many peak detection algorithms have been proposed for ChIP-seq data analysis,\nbut it is not obvious which method and what parameters are optimal for any\ngiven data set. In contrast, peaks can easily be located by visual inspection\nof profile data on a genome browser. We thus propose a supervised machine\nlearning approach to ChIP-seq data analysis, using annotated regions that\nencode an expert's qualitative judgments about which regions contain or do not\ncontain peaks. The main idea is to manually annotate a small subset of the\ngenome, and then learn a model that makes consistent predictions on the rest of\nthe genome. We show how our method can be used to quantitatively calibrate and\nbenchmark the performance of peak detection algorithms on specific data sets.\nWe compare several peak detectors on 7 annotated region data sets, consisting\nof 2 histone marks, 4 expert annotators, and several different cell types. In\nthese data the macs algorithm was best for a narrow peak histone profile\n(H3K4me3) while the hmcan.broad algorithm was best for a broad histone profile\n(H3K36me3). Our benchmark annotated region data sets can be downloaded from a\npublic website, and there is an R package for computing the annotation error on\nGitHub.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.6209v1"
    },
    {
        "title": "Beyond the E-value: stratified statistics for protein domain prediction",
        "authors": [
            "Alejandro Ochoa",
            "John D. Storey",
            "Manuel Llinás",
            "Mona Singh"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  E-values have been the dominant statistic for protein sequence analysis for\nthe past two decades: from identifying statistically significant local sequence\nalignments to evaluating matches to hidden Markov models describing protein\ndomain families. Here we formally show that for \"stratified\" multiple\nhypothesis testing problems, controlling the local False Discovery Rate (lFDR)\nper stratum, or partition, yields the most predictions across the data at any\ngiven threshold on the FDR or E-value over all strata combined. For the\nimportant problem of protein domain prediction, a key step in characterizing\nprotein structure, function and evolution, we show that stratifying statistical\ntests by domain family yields excellent results. We develop the first\nFDR-estimating algorithms for domain prediction, and evaluate how well\nthresholds based on q-values, E-values and lFDRs perform in domain prediction\nusing five complementary approaches for estimating empirical FDRs in this\ncontext. We show that stratified q-value thresholds substantially outperform\nE-values. Contradicting our theoretical results, q-values also outperform\nlFDRs; however, our tests reveal a small but coherent subset of domain\nfamilies, biased towards models for specific repetitive patterns, for which\nFDRs are greatly underestimated due to weaknesses in random sequence models.\nUsage of lFDR thresholds outperform q-values for the remaining families, which\nhave as-expected noise, suggesting that further improvements in domain\npredictions can be achieved with improved modeling of random sequences.\nOverall, our theoretical and empirical findings suggest that the use of\nstratified q-values and lFDRs could result in improvements in a host of\nstructured multiple hypothesis testing problems arising in bioinformatics,\nincluding genome-wide association studies, orthology prediction, motif\nscanning, and multi-microarray analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.6384v2"
    },
    {
        "title": "Deciphering regulation in eukaryotic cell: from sequence to function",
        "authors": [
            "Valentina Boeva"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  A transversal topic of my research has been the development and application\nof computational methods for DNA sequence analysis. The methods I have been\ndeveloping aim at improving our understanding of the regulation processes\nhappening in normal and cancer cells. This topic connects together the projects\npresented in this thesis. Two chapters of the thesis represent major areas of\nmy research interests: (1) methods for deciphering transcriptional regulation\nand their application to answer specific biological questions, and (2) methods\nto study the genome structure and their application in cancer studies. The\nfirst chapter predominantly focuses on transcriptional regulation. Here I\ndescribe my contribution to the development of methodology for the discovery of\ntranscription factor binding sites and the positioning of histone proteins. I\nalso explain how sequence analysis, in combination with gene expression data,\ncan allow the identification of direct target genes of a transcription factor\nunder study, as well as the physical mechanisms of its action. As two examples,\nI provide the results of my study of transcriptional regulation by (i)\noncogenic protein EWS-FLI1 in Ewing sarcoma and (ii) oncogenic transcription\nfactor Spi-1/PU.1 in erythroleukemia. In the second chapter, I describe the\nsequence analysis methods aimed at the identification of the genomic\nrearrangements in species with existing reference genome. I explain how the\ndeveloped methodology can be applied to detect the structure of cancer genomes.\nI provide an example of how such an analysis of tumor genomes can result in a\ndiscovery of a new phenomenon: chromothripsis, when hundreds of rearrangements\noccur in a single cellular catastrophe. The thesis is concluded by listing the\nmajor challenges in high-throughput sequencing analysis. I also discuss the\ncurrent top questions demanding the integration of sequencing data.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.6661v1"
    },
    {
        "title": "MEGAHIT: An ultra-fast single-node solution for large and complex\n  metagenomics assembly via succinct de Bruijn graph",
        "authors": [
            "Dinghua Li",
            "Chi-Man Liu",
            "Ruibang Luo",
            "Kunihiko Sadakane",
            "Tak-Wah Lam"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  MEGAHIT is a NGS de novo assembler for assembling large and complex\nmetagenomics data in a time- and cost-efficient manner. It finished assembling\na soil metagenomics dataset with 252Gbps in 44.1 hours and 99.6 hours on a\nsingle computing node with and without a GPU, respectively. MEGAHIT assembles\nthe data as a whole, i.e., it avoids pre-processing like partitioning and\nnormalization, which might compromise on result integrity. MEGAHIT generates 3\ntimes larger assembly, with longer contig N50 and average contig length than\nthe previous assembly. 55.8% of the reads were aligned to the assembly, which\nis 4 times higher than the previous. The source code of MEGAHIT is freely\navailable at https://github.com/voutcn/megahit under GPLv3 license.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.7208v2"
    },
    {
        "title": "MAGNET: Understanding and Improving the Accuracy of Genome Pre-Alignment\n  Filtering",
        "authors": [
            "Mohammed Alser",
            "Onur Mutlu",
            "Can Alkan"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  In the era of high throughput DNA sequencing (HTS) technologies, calculating\nthe edit distance (i.e., the minimum number of substitutions, insertions, and\ndeletions between a pair of sequences) for billions of genomic sequences is the\ncomputational bottleneck in todays read mappers. The shifted Hamming distance\n(SHD) algorithm proposes a fast filtering strategy that can rapidly filter out\ninvalid mappings that have more edits than allowed. However, SHD shows high\ninaccuracy in its filtering by admitting invalid mappings to be marked as\ncorrect ones. This wastes the execution time and imposes a large computational\nburden. In this work, we comprehensively investigate four sources that lead to\nthe filtering inaccuracy. We propose MAGNET, a new filtering strategy that\nmaintains high accuracy across different edit distance thresholds and data\nsets. It significantly improves the accuracy of pre-alignment filtering by one\nto two orders of magnitude. The MATLAB implementations of MAGNET and SHD are\nopen source and available at: https://github.com/BilkentCompGen/MAGNET.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.01631v2"
    },
    {
        "title": "Discovery of new drug therapeutic indications from gene mutation\n  information for hepatocellular carcinoma",
        "authors": [
            "Liang Yu",
            "Fengdan Xu",
            "Lin Gao"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Hepatocellular carcinoma (HCC) is the most common primary liver malignancy\nand is a leading cause of cancer-related death worldwide. However, cure is not\npossible with currently used therapies, and there is not so much approved\ntargeted therapy for HCC despite numerous attempts and clinical trials. So, it\nis essential to identify additional therapeutic strategies to block the growth\nof HCC tumors. As a cancer disease, it is associated with aberrant genomic and\ntranscriptional landscapes. We sought to use a systematic drug repositioning\nbioinformatics approach to identify novel candidate drugs to treat HCC, which\nconsiders not only aberrant genomic information, but also the changes of\ntranscriptional landscapes. First, we screen the collection of HCC feature\ngenes that frequently mutated in most samples of HCC based on human mutation\ndata. Then, the gene expression data of HCC in TCGA are combined to classify\nthe kernel genes of HCC. Finally, the therapeutic score (TS) of each drug is\ncalculated based on the kolmogorov-smirnov statistical method. Using this\nstrategy, we identified five drugs that associated with HCC, including three\ndrugs that could treat HCC and two drugs that might have side-effect on HCC. In\naddition, we also make Connectivity Map (CMap) profiles similarity analysis and\nKEGG enrichment analysis on drug targets. All these findings suggest that our\napproach is effective for accurate discovering novel therapeutic options for\nHCC and easily to be extended to other tumors.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.04586v1"
    },
    {
        "title": "DNA methylation heterogeneity induced by collaborations between\n  enhancers",
        "authors": [
            "Yusong Ye",
            "Zhuoqin Yang",
            "Jinzhi Lei"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  During mammalian embryo development, reprogramming of DNA methylation plays\nimportant roles in the erasure of parental epigenetic memory and the\nestablishment of na\\\"{i}ve pluripogent cells. Multiple enzymes that regulate\nthe processes of methylation and demethylation work together to shape the\npattern of genome-scale DNA methylation and guid the process of cell\ndifferentiation. Recent availability of methylome information from single-cell\nwhole genome bisulfite sequencing (scBS-seq) provides an opportunity to study\nDNA methylation dynamics in the whole genome in individual cells, which reveal\nthe heterogeneous methylation distributions of enhancers in embryo stem cells\n(ESCs). In this study, we developed a computational model of enhancer\nmethylation inheritance to study the dynamics of genome-scale DNA methylation\nreprogramming during exit from pluripotency. The model enables us to track\ngenome-scale DNA methylation reprogramming at single-cell level during the\nembryo development process, and reproduce the DNA methylation heterogeneity\nreported by scBS-seq. Model simulations show that DNA methylation heterogeneity\nis an intrinsic property driven by cell division along the development process,\nand the collaboration between neighboring enhancers is required for\nheterogeneous methylation. Our study suggest that the mechanism of genome-scale\noscillation proposed by Rulands et al. (2018) might not necessary to the DNA\nmethylation during exit from pluripotency.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06401v1"
    },
    {
        "title": "Phylogenetic analyses of the severe acute respiratory syndrome\n  coronavirus 2 reflected the several routes of introduction to Taiwan, the\n  United States, and Japan",
        "authors": [
            "Tomoko Matsuda",
            "Hikoyu Suzuki",
            "Norichika Ogata"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Worldwide Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\ninfection is disrupting in the economy and anxiety of people. The public\nanxiety has increased the psychological burden on government and healthcare\nprofessionals, resulting in a government worker suicide in Japan. The terrified\npeople are asking the government for border measures. However, are border\nmeasures possible for this virus? By analyzing 48 almost complete virus genome\nsequences, we found out that the viruses that invaded Taiwan, the United\nStates, and Japan were introduced independently. We identified thirteen\nparsimony-informative sites and three groups (CTC, TCC, and TCT). Viruses found\noutside China did not form a monophyletic clade, opposite to previous study.\nThese results suggest the difficulty of implementing effective border measures\nagainst this virus.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08802v2"
    },
    {
        "title": "Classification of arrayCGH data using a fused SVM",
        "authors": [
            "Franck Rapaport",
            "Emmanuel Barillot",
            "Jean-Philippe Vert"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Motivation: Array-based comparative genomic hybridization (arrayCGH) has\nrecently become a popular tool to identify DNA copy number variations along the\ngenome. These profiles are starting to be used as markers to improve prognosis\nor diagnosis of cancer, which implies that methods for automated supervised\nclassification of arrayCGH data are needed. Like gene expression profiles,\narrayCGH profiles are characterized by a large number of variables usually\nmeasured on a limited number of samples. However, arrayCGH profiles have a\nparticular structure of correlations between variables, due to the spatial\norganization of BACs along the genome. This suggests that classical\nclassification methods, often based on the selection of a small number of\ndiscriminative features, may not be the most accurate methods and may not\nproduce easily interpretable prediction rules.\n  Results: We propose a new method for supervised classification of arrayCGH\ndata. The method is a variant of support vector machine (SVM) that incorporates\nthe biological specificities of DNA copy number variations along the genome as\nprior knowledge. The resulting classifier is a sparse linear classifier based\non a limited number of regions automatically selected on the chromosomes,\nleading to easy interpretation and identification of discriminative regions of\nthe genome. We test this method on three classification problems for bladder\nand uveal cancer, involving both diagnosis and prognosis. We demonstrate that\nthe introduction of the new prior on the classifier leads not only to more\naccurate predictions, but also to the identification of known and new regions\nof interest in the genome.\n  Availability: All data and algorithms are publicly available.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.3007v1"
    },
    {
        "title": "Centromere reference models for human chromosomes X and Y satellite\n  arrays",
        "authors": [
            "Karen H. Miga",
            "Yulia Newton",
            "Miten Jain",
            "Nicolas Altemose",
            "Huntington F. Willard",
            "W. James Kent"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The human genome remains incomplete, with multi-megabase sized gaps\nrepresenting the endogenous centromeres and other heterochromatic regions.\nThese regions are commonly enriched with long arrays of near-identical tandem\nrepeats, known as satellite DNAs, that offer a limited number of variant sites\nto differentiate individual repeat copies across millions of bases. This\nsubstantial sequence homogeneity challenges available assembly strategies, and\nas a result, centromeric regions are omitted from ongoing genomic studies. To\naddress this problem, we present a locally ordered assembly across two haploid\nhuman satellite arrays on chromosomes X and Y, resulting in an initial linear\nrepresentation of 3.83 Mb of centromeric DNA within an individual genome. To\nfurther expand the utility of each centromeric reference sequence, we evaluate\nsites within the arrays for short-read mappability and chromosome specificity.\nAs satellite DNAs evolve in a concerted manner, we use these centromeric\nassemblies to assess the extent of sequence variation among 372 individuals\nfrom distinct human populations. In doing so, we identify two ancient satellite\narray variants in both X and Y centromeres as determined by array length and\nsequence composition. This study provides an initial linear representation and\ncomprehensive sequence characterization of a regional centromere and\nestablishes a foundation to extend genomic characterization to these sites as\nwell as to other repeat-rich regions within complex genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0035v3"
    },
    {
        "title": "A hierarchical network heuristic for solving the orientation problem in\n  genome assembly",
        "authors": [
            "Karl R. B. Schmitt",
            "Aleksey V. Zimin",
            "Guillaume Marcaçs",
            "James A. Yorke",
            "Michelle Girvan"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  In the past several years, the problem of genome assembly has received\nconsiderable attention from both biologists and computer scientists. An\nimportant component of current assembly methods is the scaffolding process.\nThis process involves building ordered and oriented linear collections of\ncontigs (continuous overlapping sequence reads) called scaffolds and relies on\nthe use of mate pair data. A mate pair is a set of two reads that are sequenced\nfrom the ends of a single fragment of DNA, and therefore have opposite mutual\norientations. When two reads of a mate-pair are placed into two different\ncontigs, one can infer the mutual orientation of these contigs. While several\norientation algorithms exist as part of assembly programs, all encounter\nchallenges while solving the orientation problem due to errors from\nmis-assemblies in contigs or errors in read placements. In this paper we\npresent an algorithm based on hierarchical clustering that independently solves\nthe orientation problem and is robust to errors. We show that our algorithm can\ncorrectly solve the orientation problem for both faux (generated) assembly data\nand real assembly data for {\\em R. sphaeroides bacteria}. We demonstrate that\nour algorithm is stable to both changes in the initial orientations as well as\nnoise in the data, making it advantageous compared to traditional approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0541v1"
    },
    {
        "title": "Systematic identification of gene families for use as markers for\n  phylogenetic and phylogeny- driven ecological studies of bacteria and archaea\n  and their major subgroups",
        "authors": [
            "Dongying Wu",
            "Guillaume Jospin",
            "Jonathan A. Eisen"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  With the astonishing rate that the genomic and metagenomic sequence data sets\nare accumulating, there are many reasons to constrain the data analyses. One\napproach to such constrained analyses is to focus on select subsets of gene\nfamilies that are particularly well suited for the tasks at hand. Such gene\nfamilies have generally been referred to as marker genes. We are particularly\ninterested in identifying and using such marker genes for phylogenetic and\nphylogeny-driven ecological studies of microbes and their communities. We\ntherefore refer to these as PhyEco (for phylogenetic and phylogenetic ecology)\nmarkers. The dual use of these PhyEco markers means that we needed to develop\nand apply a set of somewhat novel criteria for identification of the best\ncandidates for such markers. The criteria we focused on included universality\nacross the taxa of interest, ability to be used to produce robust phylogenetic\ntrees that reflect as much as possible the evolution of the species from which\nthe genes come, and low variation in copy number across taxa. We describe here\nan automated protocol for identifying potential PhyEco markers from a set of\ncomplete genome sequences. The protocol combines rapid searching, clustering\nand phylogenetic tree building algorithms to generate protein families that\nmeet the criteria listed above. We report here the identification of PhyEco\nmarkers for different taxonomic levels including 40 for all bacteria and\narchaea, 114 for all bacteria, and much more for some of the individual phyla\nof bacteria. This new list of PhyEco markers should allow much more detailed\nautomated phylogenetic and phylogenetic ecology analyses of these groups than\npossible previously.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0869v1"
    },
    {
        "title": "Cloudbreak: Accurate and Scalable Genomic Structural Variation Detection\n  in the Cloud with MapReduce",
        "authors": [
            "Christopher W. Whelan",
            "Jeffrey Tyner",
            "Alberto L'Abbate",
            "Clelia Tiziana Storlazzi",
            "Lucia Carbone",
            "Kemal Sönmez"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The detection of genomic structural variations (SV) remains a difficult\nchallenge in analyzing sequencing data, and the growing size and number of\nsequenced genomes have rendered SV detection a bona fide big data problem.\nMapReduce is a proven, scalable solution for distributed computing on huge data\nsets. We describe a conceptual framework for SV detection algorithms in\nMapReduce based on computing local genomic features, and use it to develop a\ndeletion and insertion detection algorithm, Cloudbreak. On simulated and real\ndata sets, Cloudbreak achieves accuracy improvements over popular SV detection\nalgorithms, and genotypes variants from diploid samples. It provides\ndramatically shorter runtimes and the ability to scale to big data volumes on\nlarge compute clusters. Cloudbreak includes tools to set up and configure\nMapReduce (Hadoop) clusters on cloud services, enabling on-demand cluster\ncomputing. Our implementation and source code are available at\nhttp://github.com/cwhelan/cloudbreak .\n",
        "pdf_link": "http://arxiv.org/pdf/1307.2331v2"
    },
    {
        "title": "QuorUM: an error corrector for Illumina reads",
        "authors": [
            "Guillaume Marçais",
            "James A. Yorke",
            "Aleksey Zimin"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation: Illumina Sequencing data can provide high coverage of a genome by\nrelatively short (100 bp150 bp) reads at a low cost. Our goal is to produce\ntrimmed and error-corrected reads to improve genome assemblies. Our error\ncorrection procedure aims at producing a set of error-corrected reads (1)\nminimizing the number of distinct false k-mers, i.e. that are not present in\nthe genome, in the set of reads and (2) maximizing the number that are true,\ni.e. that are present in the genome. Because coverage of a genome by Illumina\nreads varies greatly from point to point, we cannot simply eliminate k-mers\nthat occur rarely.\n  Results: Our software, called QuorUM, provides reasonably accurate correction\nand is suitable for large data sets (1 billion bases checked and corrected per\nday per core).\n  Availability: QuorUM is distributed as an independent software package and as\na module of the MaSuRCA assembly software. Both are available under the GPL\nopen source license at http://www.genome.umd.edu.\n  Contact: gmarcais@umd.edu\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3515v1"
    },
    {
        "title": "kruX: Matrix-based non-parametric eQTL discovery",
        "authors": [
            "Jianlong Qi",
            "Hassan Foroughi Asl",
            "Johan Bjorkegren",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The Kruskal-Wallis test is a popular non-parametric statistical test for\nidentifying expression quantitative trait loci (eQTLs) from genome-wide data\ndue to its robustness against variations in the underlying genetic model and\nexpression trait distribution, but testing billions of marker-trait\ncombinations one-by-one can become computationally prohibitive. We developed\nkruX, an algorithm implemented in Matlab, Python and R that uses matrix\nmultiplications to simultaneously calculate the Kruskal-Wallis test statistic\nfor several millions of marker-trait combinations at once. KruX is more than\nten thousand times faster than computing associations one-by-one on a typical\nhuman dataset. We used kruX and a dataset of more than 500k SNPs and 20k\nexpression traits measured in 102 human blood samples to compare eQTLs detected\nby the Kruskal-Wallis test to eQTLs detected by the parametric ANOVA and linear\nmodel methods. We found that the Kruskal-Wallis test is more robust against\ndata outliers and heterogeneous genotype group sizes and detects a higher\nproportion of non-linear associations, but is more conservative for calling\nadditive linear associations. In summary, kruX enables the use of robust\nnon-parametric methods for massive eQTL mapping without the need for a\nhigh-performance computing infrastructure.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3519v3"
    },
    {
        "title": "Synteny in Bacterial Genomes: Inference, Organization and Evolution",
        "authors": [
            "Ivan Junier",
            "Olivier Rivoire"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Genes are not located randomly along genomes. Synteny, the conservation of\ntheir relative positions in genomes of different species, reflects fundamental\nconstraints on natural evolution. We present approaches to infer pairs of\nco-localized genes from multiple genomes, describe their organization, and\nstudy their evolutionary history. In bacterial genomes, we thus identify\nsynteny units, or \"syntons\", which are clusters of proximal genes that\nencompass and extend operons. The size distribution of these syntons divide\nthem into large syntons, which correspond to fundamental macro-molecular\ncomplexes of bacteria, and smaller ones, which display a remarkable exponential\ndistribution of sizes. This distribution is \"universal\" in two respects: it\nholds for vastly different genomes, and for functionally distinct genes.\nSimilar statistical laws have been reported previously in studies of bacterial\ngenomes, and generally attributed to purifying selection or neutral processes.\nHere, we perform a new analysis based on the concept of parsimony, and find\nthat the prevailing evolutionary mechanism behind the formation of small\nsyntons is a selective process of gene aggregation. Altogether, our results\nimply a common evolutionary process that selectively shapes the organization\nand diversity of bacterial genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.4291v1"
    },
    {
        "title": "Integrating sequencing datasets to form highly confident SNP and indel\n  genotype calls for a whole human genome",
        "authors": [
            "Justin M. Zook",
            "Brad Chapman",
            "Jason Wang",
            "David Mittelman",
            "Oliver Hofmann",
            "Winston Hide",
            "Marc Salit"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Clinical adoption of human genome sequencing requires methods with known\naccuracy of genotype calls at millions or billions of positions across a\ngenome. Previous work showing discordance amongst sequencing methods and\nalgorithms has made clear the need for a highly accurate set of genotypes\nacross a whole genome that could be used as a benchmark. We present methods to\nmake highly confident SNP, indel, and homozygous reference genotype calls for\nNA12878, the pilot genome for the Genome in a Bottle Consortium. We minimize\nbias towards any method by integrating and arbitrating between 14 datasets from\n5 sequencing technologies, 7 mappers, and 3 variant callers. Regions for which\nno confident genotype call could be made are identified as uncertain, and\nclassified into different reasons for uncertainty. Our highly confident\ngenotype calls are publicly available on the Genome Comparison and Analytic\nTesting (GCAT) website to enable real-time benchmarking of any method.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.4661v2"
    },
    {
        "title": "Agalma: an automated phylogenomics workflow",
        "authors": [
            "Casey W. Dunn",
            "Mark Howison",
            "Felipe Zapata"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  In the past decade, transcriptome data have become an important component of\nmany phylogenetic studies. Phylogenetic studies now regularly include genes\nfrom newly sequenced transcriptomes, as well as publicly available\ntranscriptomes and genomes. Implementing such a phylogenomic study, however, is\ncomputationally intensive, requires the coordinated use of many complex\nsoftware tools, and includes multiple steps for which no published tools exist.\nPhylogenomic studies have therefore been manual or semiautomated. In addition\nto taking considerable user time, this makes phylogenomic analyses difficult to\nreproduce, compare, and extend. In addition, methodological improvements made\nin the context of one study often cannot be easily applied and evaluated in the\ncontext of other studies. We present Agalma, an automated tool that conducts\nphylogenomic analyses. The user provides raw Illumina transcriptome data, and\nAgalma produces annotated assemblies, aligned gene sequence matrices, a\npreliminary phylogeny, and detailed diagnostics that allow the investigator to\nmake extensive assessments of intermediate analysis steps and the final\nresults. Sequences from other sources, such as externally assembled genomes and\ntranscriptomes, can also be incorporated in the analyses. Agalma tracks\nprovenance, profiles processor and memory use, records diagnostics, manages\nmetadata, and enables rich HTML reports for all stages of the analysis. Agalma\nincludes a test data set and a built-in test analysis of these data. In\naddition to describing Agalma, we here present a sample analysis of a larger\nseven-taxon data set. Agalma is available for download at\nhttps://bitbucket.org/caseywdunn/agalma. Agalma allows complex phylogenomic\nanalyses to be implemented and described unambiguously as a series of\nhigh-level commands. This will enable phylogenomic studies to be readily\nreproduced, modified, and extended.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.6432v1"
    },
    {
        "title": "Genetics of single-cell protein abundance variation in large yeast\n  populations",
        "authors": [
            "Frank W. Albert",
            "Sebastian Treusch",
            "Arthur H. Shockley",
            "Joshua S. Bloom",
            "Leonid Kruglyak"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Many DNA sequence variants influence phenotypes by altering gene expression.\nOur understanding of these variants is limited by sample sizes of current\nstudies and by measurements of mRNA rather than protein abundance. We developed\na powerful method for identifying genetic loci that influence protein\nexpression in very large populations of the yeast Saccharomyes cerevisiae. The\nmethod measures single-cell protein abundance through the use of\ngreen-fluorescent-protein tags. We applied this method to 160 genes and\ndetected many more loci per gene than previous studies. We also observed closer\ncorrespondence between loci that influence protein abundance and loci that\ninfluence mRNA abundance of a given gene. Most loci cluster at hotspot\nlocations that influence multiple proteins - in some cases, more than half of\nthose examined. The variants that underlie these hotspots have profound effects\non the gene regulatory network and provide insights into genetic variation in\ncell physiology between yeast strains.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.6829v1"
    },
    {
        "title": "The genome of the medieval Black Death agent (extended abstract)",
        "authors": [
            "Ashok Rajaraman",
            "Eric Tannier",
            "Cedric Chauve"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The genome of a 650 year old Yersinia pestis bacteria, responsible for the\nmedieval Black Death, was recently sequenced and assembled into 2,105 contigs\nfrom the main chromosome. According to the point mutation record, the medieval\nbacteria could be an ancestor of most Yersinia pestis extant species, which\nopens the way to reconstructing the organization of these contigs using a\ncomparative approach. We show that recent computational paleogenomics methods,\naiming at reconstructing the organization of ancestral genomes from the\ncomparison of extant genomes, can be used to correct, order and complete the\ncontig set of the Black Death agent genome, providing a full chromosome\nsequence, at the nucleotide scale, of this ancient bacteria. This sequence\nsuggests that a burst of mobile elements insertions predated the Black Death,\nleading to an exceptional genome plasticity and increase in rearrangement rate.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7642v1"
    },
    {
        "title": "Exploring Genome Characteristics and Sequence Quality Without a\n  Reference",
        "authors": [
            "Jared T. Simpson"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The de novo assembly of large, complex genomes is a significant challenge\nwith currently available DNA sequencing technology. While many de novo assembly\nsoftware packages are available, comparatively little attention has been paid\nto assisting the user with the assembly. This paper addresses the practical\naspects of de novo assembly by introducing new ways to perform quality\nassessment on a collection of DNA sequence reads. The software implementation\ncalculates per-base error rates, paired-end fragment size histograms and\ncoverage metrics in the absence of a reference genome. Additionally, the\nsoftware will estimate characteristics of the sequenced genome, such as repeat\ncontent and heterozygosity, that are key determinants of assembly difficulty.\nThe software described is freely available and open source under the GNU Public\nLicense.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.8026v1"
    },
    {
        "title": "Late-replicating CNVs as a source of new genes",
        "authors": [
            "David Juan",
            "Daniel Rico",
            "Tomas Marques-Bonet",
            "Oscar Fernandez-Capetillo",
            "Alfonso Valencia"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Asynchronous replication of the genome has been associated with different\nrates of point mutation and copy number variation (CNV) in human populations.\nHere, we explored if the bias in the generation of CNV that is associated to\nDNA replication timing might have conditioned the birth of new protein-coding\ngenes during evolution. We show that genes that were duplicated during primate\nevolution are more commonly found among the human genes located in\nlate-replicating CNV regions. We traced the relationship between replication\ntiming and the evolutionary age of duplicated genes. Strikingly, we found that\nthere is a significant enrichment of evolutionary younger duplicates in late\nreplicating regions of the human and mouse genome. Indeed, the presence of\nduplicates in late replicating regions gradually decreases as the evolutionary\ntime since duplication extends. Our results suggest that the accumulation of\nrecent duplications in late replicating CNV regions is an active process\ninfluencing genome evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.8249v2"
    },
    {
        "title": "SlopMap: a software application tool for quick and flexible\n  identification of similar sequences using exact k-mer matching",
        "authors": [
            "Ilya Y. Zhbannikov",
            "Samuel S. Hunter",
            "Matthew L. Settles",
            "James A. Foster"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  With the advent of Next-Generation (NG) sequencing, it has become possible to\nsequence an entire genome quickly and inexpensively. However, in some\nexperiments one only needs to extract and assembly a portion of the sequence\nreads, for example when performing transcriptome studies, sequencing\nmitochondrial genomes, or characterizing exomes. With the raw DNA-library of a\ncomplete genome it would appear to be a trivial problem to identify reads of\ninterest. But it is not always easy to incorporate well-known tools such as\nBLAST, BLAT, Bowtie, and SOAP directly into a bioinformatics pipelines before\nthe assembly stage, either due to in- compatibility with the assembler's file\ninputs, or because it is desirable to incorporate information that must be\nextracted separately. For example, in order to incorporate flowgrams from a\nRoche 454 sequencer into the Newbler assembler it is necessary to first extract\nthem from the original SFF files. We present SlopMap, a bioinformatics software\nutility which allows rapid identification similar to provided target sequences\nfrom either Roche 454 or Illumnia DNA library. With a simple and intuitive\ncommand- line interface along with file output formats compatible with assembly\nprograms, SlopMap can be directly embedded in biological data processing\npipeline without any additional programming work. In addition, SlopMap\npreserves flowgram information needed for Roche 454 assembler.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.8407v1"
    },
    {
        "title": "Towards Better Understanding of Artifacts in Variant Calling from\n  High-Coverage Samples",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation: Whole-genome high-coverage sequencing has been widely used for\npersonal and cancer genomics as well as in various research areas. However, in\nthe lack of an unbiased whole-genome truth set, the global error rate of\nvariant calls and the leading causal artifacts still remain unclear even given\nthe great efforts in the evaluation of variant calling methods.\n  Results: We made ten SNP and INDEL call sets with two read mappers and five\nvariant callers, both on a haploid human genome and a diploid genome at a\nsimilar coverage. By investigating false heterozygous calls in the haploid\ngenome, we identified the erroneous realignment in low-complexity regions and\nthe incomplete reference genome with respect to the sample as the two major\nsources of errors, which press for continued improvements in these two areas.\nWe estimated that the error rate of raw genotype calls is as high as 1 in\n10-15kb, but the error rate of post-filtered calls is reduced to 1 in 100-200kb\nwithout significant compromise on the sensitivity.\n  Availability: BWA-MEM alignment: http://bit.ly/1g8XqRt; Scripts:\nhttps://github.com/lh3/varcmp; Additional data:\nhttps://figshare.com/articles/Towards_better_understanding_of_artifacts_in_variating_calling_from_high_coverage_samples/981073\n",
        "pdf_link": "http://arxiv.org/pdf/1404.0929v2"
    },
    {
        "title": "Taxator-tk: Fast and Precise Taxonomic Assignment of Metagenomes by\n  Approximating Evolutionary Neighborhoods",
        "authors": [
            "J. Dröge",
            "I. Gregor",
            "A. C. McHardy"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Metagenomics characterizes microbial communities by random shotgun sequencing\nof DNA isolated directly from an environment of interest. An essential step in\ncomputational metagenome analysis is taxonomic sequence assignment, which\nallows us to identify the sequenced community members and to reconstruct\ntaxonomic bins with sequence data for the individual taxa. We describe an\nalgorithm and the accompanying software, taxator-tk, which performs taxonomic\nsequence assignments by fast approximate determination of evolutionary\nneighbors from sequence similarities. Taxator-tk was precise in its taxonomic\nassignment across all ranks and taxa for a range of evolutionary distances and\nfor short sequences. In addition to the taxonomic binning of metagenomes, it is\nwell suited for profiling microbial communities from metagenome samples\nbecauseit identifies bacterial, archaeal and eukaryotic community members\nwithout being affected by varying primer binding strengths, as in marker gene\namplification, or copy number variations of marker genes across different taxa.\nTaxator-tk has an efficient, parallelized implementation that allows the\nassignment of 6 Gb of sequence data per day on a standard multiprocessor system\nwith ten CPU cores and microbial RefSeq as the genomic reference data.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1029v1"
    },
    {
        "title": "Identification and characterization of unique to human regulatory\n  sequences in embryonic stem cells reveal associations with transposable\n  elements, distal enhancers, non-coding RNA, and DNA methylation-driven\n  mechanisms of genome editing",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Despite significant progress in structural and functional characterization of\nhuman genome, understanding of mechanisms underlying the genetic basis of human\nphenotypic uniqueness remains limited. We report that non-randomly distributed\ntransposable element-derived sequences, most notably HERV-H/LTR7 and L1HS, are\nassociated with creation of 99.8% unique to human transcription factor binding\nsites in genome of embryonic stem cells (ESC). 4,094 unique to human regulatory\nloci display selective and site-specific binding of critical regulators (NANOG,\nPOU5F1, CTCF, Lamin B1) and are preferentially placed within the matrix of\ntranscriptionally active DNA segments hyper-methylated in ESC. Unique to human\nNANOG-binding sites are enriched near the rapidly evolving in primates\nprotein-coding genes regulating brain size, pluripotency lncRNAs, hESC\nenhancers, and 5-hydroxymethylcytosine-harboring regions immediately adjacent\nto binding sites. We propose a proximity placement model explaining how 33-47%\nexcess of NANOG and POU5F1 proteins immobilized on a DNA scaffold may play a\nfunctional role at distal regulatory elements.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1057v1"
    },
    {
        "title": "Human Y-chromosome gene classification using Fractal Dimension & Shannon\n  Entropy",
        "authors": [
            "Todd Holden",
            "JianMin Ye"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  All genes on the human Y-chromosome were studied using fractal dimension and\nShannon entropy. Clear outlier clusters were identified. Among these were 6\nsequences that have since been withdrawn as CDSs and 1 additional sequence that\nis not in the current assembly. A methodology for ranking the sequences based\non deviation from average values of FD and SE was developed. The group of\nsequences scored among the 10% largest deviations had abnormally high\nlikelihood to be from centromeric or pseudoautosomal regions and low likelihood\nto be from X-chromosome transposed regions. lncRNA sequences were also enriched\namong the outliers. In addition, the number of expressed genes previously\nidentified for evolutionary study tended to not have large deviations from the\naverage.\n  Keywords: Y-chromosome; Shannon di-nucleotide entropy; fractal dimension;\ncentromeric genes; gene degredation; lncRNA\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2540v1"
    },
    {
        "title": "Modeling DNA methylation dynamics with approaches from phylogenetics",
        "authors": [
            "John A. Capra",
            "Dennis Kostka"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Methylation of CpG dinucleotides is a prevalent epigenetic modification that\nis required for proper development in vertebrates, and changes in CpG\nmethylation are essential to cellular differentiation. Genome-wide DNA\nmethylation assays have become increasingly common, and recently distinct\nstages across differentiating cellular lineages have been assayed. How- ever,\ncurrent methods for modeling methylation dynamics do not account for the\ndependency structure between precursor and dependent cell types. We developed a\ncontinuous-time Markov chain approach, based on the observation that changes in\nmethylation state over tissue differentiation can be modeled similarly to DNA\nnucleotide changes over evolutionary time. This model explicitly takes\nprecursor to descendant relationships into account and enables inference of CpG\nmethylation dynamics. To illustrate our method, we analyzed a high-resolution\nmethylation map of the differentiation of mouse stem cells into several blood\ncell types. Our model can successfully infer unobserved CpG methylation states\nfrom observations at the same sites in related cell types (90% correct), and\nthis approach more accurately reconstructs missing data than imputation based\non neighboring CpGs (84% correct). Additionally, the single CpG resolution of\nour methylation dynamics estimates enabled us to show that DNA sequence context\nof CpG sites is informative about methylation dynamics across tissue\ndifferentiation. Finally, we identified genomic regions with clusters of highly\ndynamic CpGs and present a likely functional example. Our work establishes a\nframework for inference and modeling that is well-suited to DNA methylation\ndata, and our success suggests that other methods for analyzing DNA nucleotide\nsubstitutions will also translate to the modeling of epigenetic phenomena.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3223v1"
    },
    {
        "title": "Genetic Influences on Brain Gene Expression in Rats Selected for\n  Tameness and Aggression",
        "authors": [
            "Henrike O. Heyne",
            "Susann Lautenschläger",
            "Ronald Nelson",
            "François Besnier",
            "Maxime Rotival",
            "Alexander Cagan",
            "Rimma Kozhemyakina",
            "Irina Z. Plyusnina",
            "Lyudmila Trut",
            "Örjan Carlborg",
            "Enrico Petretto",
            "Leonid Kruglyak",
            "Svante Pääbo",
            "Torsten Schöneberg",
            "Frank W. Albert"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Inter-individual differences in many behaviors are partly due to genetic\ndifferences, but the identification of the genes and variants that influence\nbehavior remains challenging. Here, we studied an F2 intercross of two outbred\nlines of rats selected for tame and aggressive behavior towards humans for more\nthan 64 generations. By using a mapping approach that is able to identify\ngenetic loci segregating within the lines, we identified four times more loci\ninfluencing tameness and aggression than by an approach that assumes fixation\nof causative alleles, suggesting that many causative loci were not driven to\nfixation by the selection. We used RNA sequencing in 150 F2 animals to identify\nhundreds of loci that influence brain gene expression. Several of these loci\ncolocalize with tameness loci and may reflect the same genetic variants.\nThrough analyses of correlations between allele effects on behavior and gene\nexpression, differential expression between the tame and aggressive rat\nselection lines, and correlations between gene expression and tameness in F2\nanimals, we identify the genes Gltscr2, Lgi4, Zfp40 and Slc17a7 as candidate\ncontributors to the strikingly different behavior of the tame and aggressive\nanimals.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3655v1"
    },
    {
        "title": "Mapping to a Reference Genome Structure",
        "authors": [
            "Benedict Paten",
            "Adam Novak",
            "David Haussler"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  To support comparative genomics, population genetics, and medical genetics,\nwe propose that a reference genome should come with a scheme for mapping each\nbase in any DNA string to a position in that reference genome. We refer to a\ncollection of one or more reference genomes and a scheme for mapping to their\npositions as a reference structure. Here we describe the desirable properties\nof reference structures and give examples. To account for natural genetic\nvariation, we consider the more general case in which a reference genome is\nrepresented by a graph rather than a set of phased chromosomes; the latter is\ntreated as a special case.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.5010v1"
    },
    {
        "title": "Graph-based data integration predicts long-range regulatory interactions\n  across the human genome",
        "authors": [
            "Sofie Demeyer",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Transcriptional regulation of gene expression is one of the main processes\nthat affect cell diversification from a single set of genes. Regulatory\nproteins often interact with DNA regions located distally from the\ntranscription start sites (TSS) of the genes. We developed a computational\nmethod that combines open chromatin and gene expression information for a large\nnumber of cell types to identify these distal regulatory elements. Our method\nbuilds correlation graphs for publicly available DNase-seq and exon array\ndatasets with matching samples and uses graph-based methods to filter findings\nsupported by multiple datasets and remove indirect interactions. The resulting\nset of interactions was validated with both anecdotal information of known\nlong-range interactions and unbiased experimental data deduced from Hi-C and\nCAGE experiments. Our results provide a novel set of high-confidence candidate\nopen chromatin regions involved in gene regulation, often located several Mb\naway from the TSS of their target gene.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.7281v1"
    },
    {
        "title": "Parenclitic network analysis of methylation data for cancer\n  identification",
        "authors": [
            "Alexander Karsakov",
            "Thomas Bartlett",
            "Iosif Meyerov",
            "Alexey Zaikin",
            "Mikhail Ivanchenko"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We make use of ideas from the theory of complex networks to implement a\nmachine learning classification of human DNA methylation data, that carry\nsignatures of cancer development. The data were obtained from patients with\nvarious kinds of cancers and represented as parenclictic networks, wherein\nnodes correspond to genes, and edges are weighted according to pairwise\nvariation from control group subjects. We demonstrate that for the $10$ types\nof cancer under study, it is possible to obtain a high performance of binary\nclassification between cancer-positive and negative samples based on network\nmeasures. Remarkably, an accuracy as high as $93-99\\%$ is achieved with only\n$12$ network topology indices, in a dramatic reduction of complexity from the\noriginal $15295$ gene methylation levels. Moreover, it was found that the\nparenclictic networks are scale-free in cancer-negative subjects, and deviate\nfrom the power-law node degree distribution in cancer. The node centrality\nranking and arising modular structure could provide insights into the systems\nbiology of cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.04421v2"
    },
    {
        "title": "Bermuda: Bidirectional de novo assembly of transcripts with new insights\n  for handling uneven coverage",
        "authors": [
            "Qingming Tang",
            "Sheng Wang",
            "Jian Peng",
            "Jianzhu Ma",
            "Jinbo Xu"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Motivation: RNA-seq has made feasible the analysis of a whole set of\nexpressed mRNAs. Mapping-based assembly of RNA-seq reads sometimes is\ninfeasible due to lack of high-quality references. However, de novo assembly is\nvery challenging due to uneven expression levels among transcripts and also the\nread coverage variation within a single transcript. Existing methods either\napply de Bruijn graphs of single-sized k-mers to assemble the full set of\ntranscripts, or conduct multiple runs of assembly, but still apply graphs of\nsingle-sized k-mers at each run. However, a single k-mer size is not suitable\nfor all the regions of the transcripts with varied coverage. Contribution: This\npaper presents a de novo assembler Bermuda with new insights for handling\nuneven coverage. Opposed to existing methods that use a single k-mer size for\nall the transcripts in each run of assembly, Bermuda self-adaptively uses a few\nk-mer sizes to assemble different regions of a single transcript according to\ntheir local coverage. As such, Bermuda can deal with uneven expression levels\nand coverage not only among transcripts, but also within a single transcript.\nExtensive tests show that Bermuda outperforms popular de novo assemblers in\nreconstructing unevenly-expressed transcripts with longer length, better\ncontiguity and lower redundancy. Further, Bermuda is computationally efficient\nwith moderate memory consumption.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.05538v1"
    },
    {
        "title": "BGT: efficient and flexible genotype query across many samples",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Summary: BGT is a compact format, a fast command line tool and a simple web\napplication for efficient and convenient query of whole-genome genotypes and\nfrequencies across tens to hundreds of thousands of samples. On real data, it\nencodes the haplotypes of 32,488 samples across 39.2 million SNPs into a 7.4GB\ndatabase and decodes a couple of hundred million genotypes per CPU second. The\nhigh performance enables real-time responses to complex queries.\n  Availability and implementation: https://github.com/lh3/bgt\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1506.08452v2"
    },
    {
        "title": "Multivariate Functional Regression Models for Epistasis Analysis",
        "authors": [
            "Futao Zhang",
            "Dan Xie",
            "Meimei Liang",
            "Momiao Xiong"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  To date, most genetic analyses of phenotypes have focused on analyzing single\ntraits or, analyzing each phenotype independently. However, joint epistasis\nanalysis of multiple complementary traits will increase statistical power, and\nhold the key to understanding the complicated genetic structure of the complex\ndiseases. Despite their importance in uncovering the genetic structure of\ncomplex traits, the statistical methods for identifying epistasis in multiple\nphenotypes remains fundamentally unexplored. To fill this gap, we formulate a\ntest for interaction between two gens in multiple quantitative trait analysis\nas a multiple functional regression (MFRG) in which the genotype functions\n(genetic variant profiles) are defined as a function of the genomic position of\nthe genetic variants. We use large scale simulations to calculate its type I\nerror rates for testing interaction between two genes with multiple phenotypes\nand to compare its power with multivariate pair-wise interaction analysis and\nsingle trait interaction analysis by a single variate functional regression\nmodel. To further evaluate its performance, the MFRG for epistasis analysis is\napplied to five phenotypes and exome sequence data from the NHLBI Exome\nSequencing Project (ESP) to detect pleiotropic epistasis. A total of 136 pairs\nof genes that formed a genetic interaction network showed significant evidence\nof epistasis influencing five traits. The results demonstrate that the joint\ninteraction analysis of multiple phenotypes has much higher power to detect\ninteraction than the interaction analysis of single trait and may open a new\ndirection to fully uncovering the genetic structure of multiple phenotypes.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.00949v1"
    },
    {
        "title": "Minimap and miniasm: fast mapping and de novo assembly for noisy long\n  sequences",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Motivation: Single Molecule Real-Time (SMRT) sequencing technology and Oxford\nNanopore technologies (ONT) produce reads over 10kbp in length, which have\nenabled high-quality genome assembly at an affordable cost. However, at\npresent, long reads have an error rate as high as 10-15%. Complex and\ncomputationally intensive pipelines are required to assemble such reads.\n  Results: We present a new mapper, minimap, and a de novo assembler, miniasm,\nfor efficiently mapping and assembling SMRT and ONT reads without an error\ncorrection stage. They can often assemble a sequencing run of bacterial data\ninto a single contig in a few minutes, and assemble 45-fold C. elegans data in\n9 minutes, orders of magnitude faster than the existing pipelines. We also\nintroduce a pairwise read mapping format (PAF) and a graphical fragment\nassembly format (GFA), and demonstrate the interoperability between ours and\ncurrent tools.\n  Availability and implementation: https://github.com/lh3/minimap and\nhttps://github.com/lh3/miniasm\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1512.01801v2"
    },
    {
        "title": "MeFiT: Merging and Filtering Tool for Illumina Paired-End Reads for 16S\n  rRNA Amplicon Sequencing",
        "authors": [
            "Hardik I. Parikh",
            "Vishal N. Koparde",
            "Steven P. Bradley",
            "Gregory A. Buck",
            "Nihar U. Sheth"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Recent advances in next-generation sequencing have revolutionized genomic\nresearch. 16S rRNA amplicon sequencing using paired-end sequencing on the MiSeq\nplatform from Illumina, Inc., is being used to characterize the composition and\ndynamics of extremely complex/diverse microbial communities. For this analysis\non the Illumina platform, merging and quality filtering of paired-end reads are\nessential first steps in data analysis to ensure the accuracy and reliability\nof downstream analysis. We have developed the Merging and Filtering Tool\n(MeFiT) to combine these pre-processing steps into one simple, intuitive\npipeline. MeFiT provides an open-source solution that permits users to merge\nand filter paired end illumina reads based on user-selected quality parameters.\nThe tool has been implemented in python and the source-code is freely available\nat https://github.com/nisheth/MeFiT.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.03342v1"
    },
    {
        "title": "MEEPTOOLS: A maximum expected error based FASTQ read filtering and\n  trimming toolkit",
        "authors": [
            "Vishal N. Koparde",
            "Hardik I. Parikh",
            "Steven P. Bradley",
            "Nihar U. Sheth"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Next generation sequencing technology rapidly produces massive volume of data\nand quality control of this sequencing data is essential to any genomic\nanalysis. Here we present MEEPTOOLS, which is a collection of open-source tools\nbased on maximum expected error as a percentage of read length (MEEP score) to\nfilter, trim, truncate and assess next generation DNA sequencing data in FASTQ\nfile format. MEEPTOOLS provides a non-traditional approach towards read\nfiltering/trimming based on maximum error probabilities of the bases in the\nread on a non-logarithmic scale. This method simultaneously retains more\nreliable bases and removes more unreliable bases than the traditional quality\nfiltering strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.03344v1"
    },
    {
        "title": "Functional transcription factor target discovery via compendia of\n  binding and expression profiles",
        "authors": [
            "Christopher J. Banks",
            "Anagha Joshi",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genome-wide experiments to map the DNA-binding locations of\ntranscription-associated factors (TFs) have shown that the number of genes\nbound by a TF far exceeds the number of possible direct target genes.\nDistinguishing functional from non-functional binding is therefore a major\nchallenge in the study of transcriptional regulation. We hypothesized that\nfunctional targets can be discovered by correlating binding and expression\nprofiles across multiple experimental conditions. To test this hypothesis, we\nobtained ChIP-seq and RNA-seq data from matching cell types from the human\nENCODE resource, considered promoter-proximal and distal cumulative regulatory\nmodels to map binding sites to genes, and used a combination of linear and\nnon-linear measures to correlate binding and expression data. We found that a\nhigh degree of correlation between a gene's TF-binding and expression profiles\nwas significantly more predictive of the gene being differentially expressed\nupon knockdown of that TF, compared to using binding sites in the cell type of\ninterest only. Remarkably, TF targets predicted from correlation across a\ncompendium of cell types were also predictive of functional targets in other\ncell types. Finally, correlation across a time course of ChIP-seq and RNA-seq\nexperiments was also predictive of functional TF targets in that tissue.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.05573v1"
    },
    {
        "title": "Detection and Visualization of Differential Splicing in RNA-Seq Data\n  with JunctionSeq",
        "authors": [
            "Stephen W. Hartley",
            "James C. Mullikin"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Although RNA-Seq data provide unprecedented isoform-level expression\ninformation, detection of alternative isoform regulation (AIR) remains\ndifficult, particularly when working with an incomplete transcript annotation.\nWe introduce JunctionSeq, a new method that builds on the statistical\ntechniques used by the well-established DEXSeq package to detect differential\nusage of both exonic regions and splice junctions. In particular, JunctionSeq\nis capable of detecting differentials in novel splice junctions without the\nneed for an additional isoform assembly step, greatly improving performance\nwhen the available transcript annotation is flawed or incomplete. JunctionSeq\nalso provides a powerful and streamlined visualization toolset that allows\nbioinformaticians to quickly and intuitively interpret their results. We tested\nour method on publicly available data from several experiments performed on the\nrat pineal gland and Toxoplasma gondii, successfully detecting known and\npreviously validated AIR genes in 19 out of 19 gene-level hypothesis tests. Due\nto its ability to query novel splice sites, JunctionSeq is still able to detect\nthese differentials even when all alternative isoforms for these genes were not\nincluded in the transcript annotation. JunctionSeq thus provides a powerful\nmethod for detecting alternative isoform regulation even with low-quality\nannotations. An implementation of JunctionSeq is available as an R/Bioconductor\npackage.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.06038v2"
    },
    {
        "title": "HSEARCH: fast and accurate protein sequence motif search and clustering",
        "authors": [
            "Haifeng Chen",
            "Ting Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Protein motifs are conserved fragments occurred frequently in protein\nsequences. They have significant functions, such as active site of an enzyme.\nSearch and clustering protein sequence motifs are computational intensive. Most\nexisting methods are not fast enough to analyze large data sets for motif\nfinding or achieve low accuracy for motif clustering. We present a new protein\nsequence motif finding and clustering algorithm, called HSEARCH. It converts\nfixed length protein sequences to data points in high dimensional space, and\napplies locality-sensitive hashing to fast search homologous protein sequences\nfor a motif. HSEARCH is significantly faster than the brute force algorithm for\nprotein motif finding and achieves high accuracy for protein motif clustering.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.00452v1"
    },
    {
        "title": "Predicting the Plant Root-Associated Ecological Niche of 21 Pseudomonas\n  Species Using Machine Learning and Metabolic Modeling",
        "authors": [
            "Jennifer Chien",
            "Peter Larsen"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Plants rarely occur in isolated systems. Bacteria can inhabit either the\nendosphere, the region inside the plant root, or the rhizosphere, the soil\nregion just outside the plant root. Our goal is to understand if using genomic\ndata and media dependent metabolic model information is better for training\nmachine learning of predicting bacterial ecological niche than media\nindependent models or pure genome based species trees. We considered three\nmachine learning techniques: support vector machine, non-negative matrix\nfactorization, and artificial neural networks. In all three machine-learning\napproaches, the media-based metabolic models and flux balance analyses were\nmore effective at predicting bacterial niche than the genome or PRMT models.\nSupport Vector Machine trained on a minimal media base with Mannose, Proline\nand Valine was most predictive of all models and media types with an f-score of\n0.8 for rhizosphere and 0.97 for endosphere. Thus we can conclude that\nmedia-based metabolic modeling provides a holistic view of the metabolome,\nallowing machine learning algorithms to highlight the differences between and\ncategorize endosphere and rhizosphere bacteria. There was no single media type\nthat best highlighted differences between endosphere and rhizosphere bacteria\nmetabolism and therefore no single enzyme, reaction, or compound that defined\nwhether a bacteria's origin was of the endosphere or rhizosphere.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.03220v1"
    },
    {
        "title": "A generalized linear model for decomposing cis-regulatory,\n  parent-of-origin, and maternal effects on allele-specific gene expression",
        "authors": [
            "Yasuaki Takada",
            "Ryutaro Miyagi",
            "Aya Takahashi",
            "Toshinori Endo",
            "Naoki Osada"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Joint quantification of genetic and epigenetic effects on gene expression is\nimportant for understanding the establishment of complex gene regulation\nsystems in living organisms. In particular, genomic imprinting and maternal\neffects play important roles in the developmental process of mammals and\nflowering plants. However, the influence of these effects on gene expression\nare difficult to quantify because they act simultaneously with cis-regulatory\nmutations. Here we propose a simple method to decompose cis-regulatory (i.e.,\nallelic genotype, AG), genomic imprinting (i.e., parent-of-origin, PO), and\nmaternal (i.e., maternal genotype, MG) effects on allele-specific gene\nexpression using RNA-seq data obtained from reciprocal crosses. We evaluated\nthe efficiency of method using a simulated dataset and applied the method to\nwhole-body Drosophila and mouse trophoblast stem cell (TSC) and liver RNA-seq\ndata. Consistent with previous studies, we found little evidence of PO and MG\neffects in adult Drosophila samples. In contrast, we identified dozens and\nhundreds of mouse genes with significant PO and MG effects, respectively.\nInterestingly, a similar number of genes with significant PO effect were detect\nin mouse TSCs and livers, whereas more genes with significant MG effect were\nobserved in livers. Further application of this method will clarify how these\nthree effects influence gene expression levels in different tissues and\ndevelopmental stages, and provide novel insight into the evolution of gene\nexpression regulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.06776v4"
    },
    {
        "title": "Inferring clonal composition from multiple tumor biopsies",
        "authors": [
            "Matteo Manica",
            "Hyunjae Ryan Kim",
            "Roland Mathis",
            "Philippe Chouvarine",
            "Dorothea Rutishauser",
            "Laura De Vargas Roditi",
            "Bence Szalai",
            "Ulrich Wagner",
            "Kathrin Oehl",
            "Karim Saba",
            "Arati Pati",
            "Julio Saez-Rodriguez",
            "Angshumoy Roy",
            "Donald W. Parsons",
            "Peter J. Wild",
            "María Rodríguez Martínez",
            "Pavel Sumazin"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Explicit accounting for copy number alterations can dramatically improve\nmutation frequency estimates, leading to more accurate phylogeny\nreconstructions and subclone characterizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.07940v2"
    },
    {
        "title": "Epigenome-wide association study and integrative analysis with the\n  transcriptome based on GWAS summary statistics",
        "authors": [
            "Hon-Cheong So"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The past decade has seen a rapid growth in omics technologies. Genome-wide\nassociation studies (GWAS) have uncovered susceptibility variants for a variety\nof complex traits. However, the functional significance of most discovered\nvariants are still not fully understood. On the other hand, there is increasing\ninterest in exploring the role of epigenetic variations such as DNA methylation\nin disease pathogenesis. In this work, we present a general framework for\nepigenome-wide association study and integrative analysis with the\ntranscriptome based on GWAS summary statistics and data from methylation and\nexpression quantitative trait loci (QTL) studies. The framework is based on\nMendelian randomization, which is much less vulnerable to confounding and\nreverse causation compared to conventional studies. The framework was applied\nto five complex diseases. We first identified loci that are differentially\nmethylated due to genetic variations, and then developed several approaches for\njoint testing with the GWAS-imputed transcriptome. We discovered a number of\nnovel candidate genes that are not implicated in the original GWAS studies. We\nalso observed strong evidence (lowest p = 2.01e-184) for differential\nexpression among the top genes mapped to methylation loci. The framework\nproposed here opens a new way of analyzing GWAS summary data and will be useful\nfor gaining deeper insight into disease mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.00329v2"
    },
    {
        "title": "Evidence-based gene models for structural and functional annotations of\n  the oil palm genome",
        "authors": [
            "Chan Kuang Lim",
            "Tatiana V. Tatarinova",
            "Rozana Rosli",
            "Nadzirah Amiruddin",
            "Norazah Azizi",
            "Mohd Amin Ab Halim",
            "Nik Shazana Nik Mohd Sanusi",
            "Jayanthi Nagappan",
            "Petr Ponomarenko",
            "Martin Triska",
            "Victor Solovyev",
            "Mohd Firdaus-Raih",
            "Ravigadevi Sambanthamurthi",
            "Denis Murphy",
            "Leslie Low Eng Ti"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The advent of rapid and inexpensive DNA sequencing has led to an explosion of\ndata waiting to be transformed into knowledge about genome organization and\nfunction. Gene prediction is customarily the starting point for genome\nanalysis. This paper presents a bioinformatics study of the oil palm genome,\nincluding comparative genomics analysis, database and tools development, and\nmining of biological data for genes of interest. We have annotated 26,059 oil\npalm genes integrated from two independent gene-prediction pipelines, Fgenesh++\nand Seqping. This integrated annotation constitutes a significant improvement\nin comparison to the preliminary annotation published in 2013. We conducted a\ncomprehensive analysis of intronless, resistance and fatty acid biosynthesis\ngenes, and demonstrated that the high quality of the current genome annotation.\n3,658 intronless genes were identified in the oil palm genome, an important\nresource for evolutionary study. Further analysis of the oil palm genes\nrevealed 210 candidate resistance genes involved in pathogen defense. Fatty\nacids have diverse applications ranging from food to industrial feedstocks, and\nwe identified 42 key genes involved in fatty acid biosynthesis in oil palm.\nThese results provide an important resource for studies of plant genomes and a\ntheoretical foundation for marker-assisted breeding of oil palm and related\ncrops.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07246v2"
    },
    {
        "title": "MetaHMM: A Webserver for Identifying Novel Genes with Specified\n  Functions in Metagenomic Samples",
        "authors": [
            "Balazs Szalkai",
            "Vince Grolmusz"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The fast and affordable sequencing of large clinical and environmental\nmetagenomic datasets opens up new horizons in medical and biotechnological\napplications. It is believed that today we have described only about 1\\% of the\nmicroorganisms on the Earth, therefore, metagenomic analysis mostly deals with\nunknown species in the samples. Microbial communities in extreme environments\nmay contain genes with high biotechnological potential, and clinical\nmetagenomes, related to diseases, may uncover still unknown pathogens and\npathological mechanisms in known diseases. While the species-level\nidentification and description of the taxa in the samples does not seem to be\npossible today, we can search for novel genes with known functions in these\nsamples, using numerous techniques, including artificial intelligence tools,\nlike the hidden Markov models (HMMs). Here we describe a simple-to-use\nwebserver, the MetaHMM, which is capable of homology-based automatic\nmodel-building for the genes to be searched for, and it also finds the closest\nmatches in the metagenome. The webserver uses already highly successful\nbuilding blocks: it performs multiple alignment by applying Clustal Omega,\nbuilds a hidden Markov model with HMMER components of hmmbuild and uses\nhmmsearch for finding similar sequences to the specified model in the\nmetagenomes. The webserver is publicly available at\n\\url{https://metahmm.pitgroup.org}.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.10995v1"
    },
    {
        "title": "MOSGA: Modular Open-Source Genome Annotator",
        "authors": [
            "Roman Martin",
            "Thomas Hackl",
            "Georges Hattab",
            "Matthias G. Fischer",
            "Dominik Heider"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The generation of high-quality assemblies, even for large eukaryotic genomes,\nhas become a routine task for many biologists thanks to recent advances in\nsequencing technologies. However, the annotation of these assemblies - a\ncrucial step towards unlocking the biology of the organism of interest - has\nremained a complex challenge that often requires advanced bioinformatics\nexpertise. Here we present MOSGA, a genome annotation framework for eukaryotic\ngenomes with a user-friendly web-interface that generates and integrates\nannotations from various tools. The aggregated results can be analyzed with a\nfully integrated genome browser and are provided in a format ready for\nsubmission to NCBI. MOSGA is built on a portable, customizable, and easily\nextendible Snakemake backend, and thus, can be tailored to a wide range of\nusers and projects. We provide MOSGA as a publicly free available web service\nat https://mosga.mathematik.uni-marburg.de and as a docker container at\nregistry.gitlab.com/mosga/mosga:latest. Source code can be found at\nhttps://gitlab.com/mosga/mosga\n",
        "pdf_link": "http://arxiv.org/pdf/2009.03758v2"
    },
    {
        "title": "Genome-wide association and transcriptome analysis reveals serum ghrelin\n  to be linked with GFRAL",
        "authors": [
            "Dirk Alexander Wittekind",
            "Markus Scholz",
            "Jürgen Kratzsch",
            "Markus Löffler",
            "Katrin Horn",
            "Holger Kirsten",
            "Veronica Witte",
            "Arno Villringer",
            "Michael Kluge"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Objective: Ghrelin is an orexigenic peptide hormone involved in the\nregulation of energy homeostasis, food intake and glucose metabolism. Serum\nlevels increase anticipating a meal and fall afterwards. Underlying genetic\nmechanisms of the ghrelin secretion are unknown. Methods: Total serum ghrelin\nwas measured in 1501 subjects selected from the population-based\nLIFE-ADULT-sample after an overnight fast. A genome-wide association study\n(GWAS) was performed. Gene-based expression association analyses\n(transcriptome-wide association study (TWAS)) were done using MetaXcan.\nResults: In the GWAS, three loci reached genome-wide significance: the\nWW-domain containing the oxidoreductase-gene (WWOX; p=1.80E-10) on chromosome\n16q23.3-24.1 (SNP: rs76823993); the Contactin-Associated Protein-Like 2 gene\n(CNTNAP2; p=9.0E-9) on chromosome 7q35-q36 (SNP: rs192092592) and the Ghrelin\nAnd Obestatin Prepropeptide gene (GHRL; p=2.72E-8) on chromosome 3p25.3 (SNP:\nrs143729751). In the TWAS, serum ghrelin was negatively associated with RNA\nexpression of the GDNF Family Receptor Alpha Like (GFRAL), receptor of the\nanorexigenic Growth Differentiation Factor-15 (GDF15), (z-score=-4.288,\np=1.81E-05). Furthermore, ghrelin was positively associated with Ribosomal\nProtein L36 (RPL36; z-score=4.848, p=1.25E-06). Conclusions: Our findings\nprovide evidence of a functional link between two major players of weight\nregulation, the ghrelin system and the GDF15/GFRAL-pathway.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.11549v1"
    },
    {
        "title": "KRAS mutation testing in colorectal cancer as an example of the\n  pathologist's role in personalized targeted therapy: a practical approach",
        "authors": [
            "Pawel Domagala",
            "Jolanta Hybiak",
            "Violetta Sulzyc-Bielicka",
            "Cezary Cybulski",
            "Janusz Rys",
            "Wenancjusz Domagala"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Identifying targets for personalized targeted therapy is the pathologist's\ndomain and a treasure. For decades, pathologists have had to learn, understand,\nadopt and implement many new laboratory techniques as they arrived on the\nscene. Pathologists successfully integrate the results of those tests into\nfinal pathology reports that were, and still are, the basis of clinical\ntherapeutic decisions. The molecular methods are different but no more\ndifficult to comprehend in the era of \"kit procedures\". Pathologists have the\nknowledge and expertise to identify particular gene mutations using the\nappropriate molecular tests currently available. This review focuses on the\nmost important recent developments in KRAS mutation testing in metastatic\ncolorectal cancer (CRC), and shows that a pathologist is involved in 10 stages\nof this procedure. Recent studies have shown that highly sensitive, simple,\nreliable and rapid assays may significantly improve the identification of CRC\npatients resistant to anti-EGFR therapy. Thus, direct sequencing does not seem\nto be an optimal procedure of KRAS testing for clinical purposes. Twelve\ncurrently available high-sensitivity diagnostic assays (with the CE-IVD mark)\nfor KRAS mutation testing are briefly described and compared. The suggested\npathology report content for somatic mutation tests is described. In\nconclusion, evidence is presented that sending away paraffin blocks with tumor\ntissue for KRAS mutation testing may not be in the best interest of patients.\nInstead, an evidence-based approach indicates that KRAS mutation testing should\nbe performed in pathology departments, only with the use of CE-IVD/FDA-approved\nKRAS tests, and with the obligatory, periodic participation in the KRAS EQA\nscheme organized by the European Society of Pathology as an independent\ninternational body.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.1286v1"
    },
    {
        "title": "Role of HIV RNA structure in recombination and speciation: romping in\n  purine A, keeps HTLV away",
        "authors": [
            "Donald R. Forsdyke"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Extreme enrichment of the human immunodeficiency virus (HIV-1) RNA genome for\nthe purine A parallels the mild purine-loading of the RNAs of most organisms.\nThis should militate against loop-loop \"kissing\" interactions between the\nstructured viral genome and structured host RNAs, which can generate segments\nof double-stranded RNA sufficient to trigger intracellular alarms. However,\nhuman T cell leukaemia virus (HTLV-1), with the potential to invade the same\nhost cell, shows extreme enrichment for the pyrimidine C. Assuming the low GC%\nHIV and the high GC% HTLV-1 to share a common ancestor, it was postulated that\ndifferences in GC% arose to prevent homologous recombination between these\nemerging lentiviral species. Sympatrically isolated by this intracellular\nreproductive barrier, prototypic HIV-1 seized the AU-rich (low GC%) high ground\n(thus committing to purine A rather than purine G). Prototypic HTLV-1 forwent\nthis advantage and evolved an independent evolutionary strategy. Evidence\nsupporting this hypothesis since its elaboration in the 1990s is growing. The\nconflict between the needs to encode accurately both a protein, and nucleic\nacid structure, is often resolved in favour of the nucleic acid because, apart\nfrom regulatory roles, structure is critical for recombination. However, above\na sequence difference threshold, structure (and hence recombination) is\nimpaired. New species can then arise.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.2132v1"
    },
    {
        "title": "Bayesian Test for Colocalisation Between Pairs of Genetic Association\n  Studies Using Summary Statistics",
        "authors": [
            "Claudia Giambartolomei",
            "Damjan Vukcevic",
            "Eric E. Schadt",
            "Lude Franke",
            "Aroon D. Hingorani",
            "Chris Wallace",
            "Vincent Plagnol"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Genetic association studies, in particular the genome-wide association study\ndesign, have provided a wealth of novel insights into the aetiology of a wide\nrange of human diseases and traits. The next challenge consists of\nunderstanding the molecular basis of these associations. The integration of\nmultiple association datasets, including gene expression datasets, can\ncontribute to this goal. We have developed a novel statistical methodology to\nassess whether two association signals are consistent with a shared causal\nvariant. An application is the integration of disease scans with expression\nquantitative trait locus (eQTL) studies, but any pair of GWAS datasets can be\nintegrated in this framework. We demonstrate the value of the approach by\nreanalysing a gene expression dataset in 966 liver samples with a published\nmeta-analysis of lipid traits including >100, 000 individuals of European\nancestry. Combining all lipid biomarkers, our reanalysis supported 29 out of 38\nreported colocalisation results with eQTLs and identified 14 new colocalisation\nresults, highlighting the value of a formal statistical test. In two cases of\nreported eQTL-lipid pairs (IFT172, TBKBP1) for which our analysis suggests that\nthe eQTL pattern is not consistent with the lipid association, we identify\nalternative colocalisation results with GCKR and KPNB1, indicating that these\ngenes are more likely to be causal in these genomic intervals. A key feature of\nthe method is the ability to derive the output statistics from single SNP\nsummary statistics, hence making it possible to perform systematic\nmeta-analysis type comparisons across multiple GWAS datasets\n(http://coloc.cs.ucl.ac.uk/coloc/). Our methodology provides information about\ncandidate causal genes in associated intervals and has direct implications for\nthe understanding of complex diseases and the design of drugs to target disease\npathways.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.4022v3"
    },
    {
        "title": "The rise and fall of the Phytophthora infestans lineage that triggered\n  the Irish potato famine",
        "authors": [
            "Kentaro Yoshida",
            "Verena J. Schuenemann",
            "Liliana M. Cano",
            "Marina Pais",
            "Bagdevi Mishra",
            "Rahul Sharma",
            "Christa Lanz",
            "Frank N. Martin",
            "Sophien Kamoun",
            "Johannes Krause",
            "Marco Thines",
            "Detlef Weigel",
            "Hernán A. Burbano"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Phytophthora infestans, the cause of potato late blight, is infamous for\nhaving triggered the Irish Great Famine in the 1840s. Until the late 1970s, P.\ninfestans diversity outside of its Mexican center of origin was low, and one\nscenario held that a single strain, US-1, had dominated the global population\nfor 150 years; this was later challenged based on DNA analysis of historical\nherbarium specimens. We have compared the genomes of 11 herbarium and 15 modern\nstrains. We conclude that the nineteenth century epidemic was caused by a\nunique genotype, HERB-1, that persisted for over 50 years. HERB-1 is distinct\nfrom all examined modern strains, but it is a close relative of US-1, which\nreplaced it outside of Mexico in the twentieth century. We propose that HERB-1\nand US-1 emerged from a metapopulation that was established in the early 1800s\noutside of the species' center of diversity.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.4206v1"
    },
    {
        "title": "Augmenting transcriptome assembly combinatorially",
        "authors": [
            "Prachi Jain",
            "Neeraja M. Krishnan",
            "Binay Panda"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  RNA-seq allows detection and precise quantification of transcripts, provides\ncomprehensive understanding of exon/intron boundaries, aids discovery of\nalternatively spliced isoforms and fusion transcripts along with measurement of\nallele-specific expression. Researchers interested in studying and constructing\ntranscriptomes, especially for non-model species, often face the conundrum of\nchoosing from a number of available de novo and genome-guided assemblers. A\ncomprehensive comparative study is required to assess and evaluate their\nefficiency and sensitivity for transcript assembly, reconstruction and\nrecovery. None of the popular assembly tools in use today achieves requisite\nsensitivity, specificity or recovery of full-length transcripts on its own.\nHence, it is imperative that methods be developed in order to augment\nassemblies generated from multiple tools, with minimal compounding of error.\nHere, we present an approach to combinatorially augment transciptome assembly\nbased on a rigorous comparative study of popular de novo and genome-guided\ntranscriptome assembly tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.6259v2"
    },
    {
        "title": "Using R and Bioconductor for proteomics data analysis",
        "authors": [
            "Laurent Gatto",
            "Andy Christoforou"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  This review presents how R, the popular statistical environment and\nprogramming language, can be used in the frame of proteomics data analysis. A\nshort introduction to R is given, with special emphasis on some of the features\nthat make R and its add-on packages a premium software for sound and\nreproducible data analysis. The reader is also advised on how to find relevant\nR software for proteomics. Several use cases are then presented, illustrating\ndata input/output, quality control, quantitative proteomics and data analysis.\nDetailed code and additional links to extensive documentation are available in\nthe freely available companion package RforProteomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.6559v1"
    },
    {
        "title": "SOAPdenovo-Trans: De novo transcriptome assembly with short RNA-Seq\n  reads",
        "authors": [
            "Yinlong Xie",
            "Gengxiong Wu",
            "Jingbo Tang",
            "Ruibang Luo",
            "Jordan Patterson",
            "Shanlin Liu",
            "Weihua Huang",
            "Guangzhu He",
            "Shengchang Gu",
            "Shengkang Li",
            "Xin Zhou",
            "Tak-Wah Lam",
            "Yingrui Li",
            "Xun Xu",
            "Gane Ka-Shu Wong",
            "Jun Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation: Transcriptome sequencing has long been the favored method for\nquickly and inexpensively obtaining the sequences for a large number of genes\nfrom an organism with no reference genome. With the rapidly increasing\nthroughputs and decreasing costs of next generation sequencing, RNA-Seq has\ngained in popularity; but given the typically short reads (e.g. 2 x 90 bp\npaired ends) of this technol- ogy, de novo assembly to recover complete or\nfull-length transcript sequences remains an algorithmic challenge. Results: We\npresent SOAPdenovo-Trans, a de novo transcriptome assembler designed\nspecifically for RNA-Seq. Its performance was evaluated on transcriptome\ndatasets from rice and mouse. Using the known transcripts from these\nwell-annotated genomes (sequenced a decade ago) as our benchmark, we assessed\nhow SOAPdenovo- Trans and two other popular software handle the practical\nissues of alternative splicing and variable expression levels. Our conclusion\nis that SOAPdenovo-Trans provides higher contiguity, lower redundancy, and\nfaster execution. Availability and Implementation: Source code and user manual\nare at http://sourceforge.net/projects/soapdenovotrans/ Contact:\nxieyl@genomics.cn or bgi-soap@googlegroups.com\n",
        "pdf_link": "http://arxiv.org/pdf/1305.6760v2"
    },
    {
        "title": "Genome Sequencing Highlights Genes Under Selection and the Dynamic Early\n  History of Dogs",
        "authors": [
            "Adam H. Freedman",
            "Rena M. Schweizer",
            "Ilan Gronau",
            "Eunjung Han",
            "Diego Ortega-Del Vecchyo",
            "Pedro M. Silva",
            "Marco Galaverni",
            "Zhenxin Fan",
            "Peter Marx",
            "Belen Lorente-Galdos",
            "Holly Beale",
            "Oscar Ramirez",
            "Farhad Hormozdiari",
            "Can Alkan",
            "Carles Vilà",
            "Kevin Squire",
            "Eli Geffen",
            "Josip Kusak",
            "Adam R. Boyko",
            "Heidi G. Parker",
            "Clarence Lee",
            "Vasisht Tadigotla",
            "Adam Siepel",
            "Carlos D. Bustamante",
            "Timothy T. Harkins",
            "Stanley F. Nelson",
            "Elaine A. Ostrander",
            "Tomas Marques-Bonet",
            "Robert K. Wayne",
            "John Novembre"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  To identify genetic changes underlying dog domestication and reconstruct\ntheir early evolutionary history, we analyzed novel high-quality genome\nsequences of three gray wolves, one from each of three putative centers of dog\ndomestication, two ancient dog lineages (Basenji and Dingo) and a golden jackal\nas an outgroup. We find dogs and wolves diverged through a dynamic process\ninvolving population bottlenecks in both lineages and post-divergence gene\nflow, which confounds previous inferences of dog origins. In dogs, the\ndomestication bottleneck was severe involving a 17 to 49-fold reduction in\npopulation size, a much stronger bottleneck than estimated previously from less\nintensive sequencing efforts. A sharp bottleneck in wolves occurred soon after\ntheir divergence from dogs, implying that the pool of diversity from which dogs\narose was far larger than represented by modern wolf populations. Conditional\non mutation rate, we narrow the plausible range for the date of initial dog\ndomestication to an interval from 11 to 16 thousand years ago. This period\npredates the rise of agriculture, implying that the earliest dogs arose\nalongside hunter-gathers rather than agriculturists. Regarding the geographic\norigin of dogs, we find that surprisingly, none of the extant wolf lineages\nfrom putative domestication centers are more closely related to dogs, and the\nsampled wolves instead form a sister monophyletic clade. This result, in\ncombination with our finding of dog-wolf admixture during the process of\ndomestication, suggests a re-evaluation of past hypotheses of dog origin is\nnecessary. Finally, we also detect signatures of selection, including evidence\nfor selection on genes implicated in morphology, metabolism, and neural\ndevelopment. Uniquely, we find support for selective sweeps at regulatory sites\nsuggesting gene regulatory changes played a critical role in dog domestication.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.7390v2"
    },
    {
        "title": "Exploring shared genetic bases and causal relationships of schizophrenia\n  and bipolar disorder with 28 cardiovascular and metabolic traits",
        "authors": [
            "Hon-Cheong So",
            "Carlos Kwan-Long Chau",
            "Fu-Kiu Ao",
            "Cheuk-Hei Mo",
            "Pak-Chung Sham"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Cardiovascular diseases (CVD) represent a major health issue in patients with\nschizophrneia (SCZ) and bipolar disorder (BD), but the exact nature of\ncardiometabolic (CM) abnormalities involved and the underlying mechanisms\nremain unclear. Using polygenic risk scores (PRS) and LD score regression, we\ninvestigated the shared genetic bases of SCZ and BD with a panel of 28\ncardiometabolic traits. We performed Mendelian randomization (MR) to elucidate\ncasual relationships between the two groups of disorders. The analysis was\nbased on large-scale meta-analyses of genome-wide association studies (GWAS).\nWe also identified the potential shared genetic variants by a statistical\napproach based on local true discovery rates, and inferred the pathways\ninvolved. We found polygenic associations of SCZ with glucose metabolism\nabnormalities, adverse adipokine profiles, increased wait-hip ratio and raised\nvisceral adiposity. However, BMI showed inverse genetic correlation and\npolygenic link with SCZ. On the other hand, we observed polygenic associations\nwith an overall favorable CM profile in BD. MR analysis showed that SCZ may be\ncausally linked to raised triglyceride and that lower fasting glucose may be\nlinked to BD; otherwise MR did not reveal other significant causal\nrelationships in general. We also identified numerous SNPs and pathways shared\nbetween SCZ/BD with cardiometabolic traits, some of which are related to\ninflammation or the immune system. In conclusion, SCZ patients may be\ngenetically associated with several CM abnormalities independent of medication\nside-effects, and proper surveillance and management of CV risk factors may be\nrequired from the onset of the disease. On the other hand, CM abnormalities in\nBD are more likely to be secondary.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.03191v5"
    },
    {
        "title": "Discovery of cancer common and specific driver gene sets",
        "authors": [
            "Junhua Zhang",
            "Shihua Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Cancer is known as a disease mainly caused by gene alterations. Discovery of\nmutated driver pathways or gene sets is becoming an important step to\nunderstand molecular mechanisms of carcinogenesis. However, systematically\ninvestigating commonalities and specificities of driver gene sets among\nmultiple cancer types is still a great challenge, but this investigation will\nundoubtedly benefit deciphering cancers and will be helpful for personalized\ntherapy and precision medicine in cancer treatment. In this study, we propose\ntwo optimization models to \\emph{de novo} discover common driver gene sets\namong multiple cancer types (ComMDP) and specific driver gene sets of one\ncertain or multiple cancer types to other cancers (SpeMDP), respectively. We\nfirst apply ComMDP and SpeMDP to simulated data to validate their efficiency.\nThen, we further apply these methods to 12 cancer types from The Cancer Genome\nAtlas (TCGA) and obtain several biologically meaningful driver pathways. As\nexamples, we construct a common cancer pathway model for BRCA and OV, infer a\ncomplex driver pathway model for BRCA carcinogenesis based on common driver\ngene sets of BRCA with eight cancer types, and investigate specific driver\npathways of the liquid cancer lymphoblastic acute myeloid leukemia (LAML)\nversus other solid cancer types. In these processes more candidate cancer genes\nare also found.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.09478v1"
    },
    {
        "title": "Identifying viruses from metagenomic data by deep learning",
        "authors": [
            "Jie Ren",
            "Kai Song",
            "Chao Deng",
            "Nathan A. Ahlgren",
            "Jed A. Fuhrman",
            "Yi Li",
            "Xiaohui Xie",
            "Fengzhu Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The recent development of metagenomic sequencing makes it possible to\nsequence microbial genomes including viruses in an environmental sample.\nIdentifying viral sequences from metagenomic data is critical for downstream\nvirus analyses. The existing reference-based and gene homology-based methods\nare not efficient in identifying unknown viruses or short viral sequences. Here\nwe have developed a reference-free and alignment-free machine learning method,\nDeepVirFinder, for predicting viral sequences in metagenomic data using deep\nlearning techniques. DeepVirFinder was trained based on a large number of viral\nsequences discovered before May 2015. Evaluated on the sequences after that\ndate, DeepVirFinder outperformed the state-of-the-art method VirFinder at all\ncontig lengths. Enlarging the training data by adding millions of purified\nviral sequences from environmental metavirome samples significantly improves\nthe accuracy for predicting under-represented viruses. Applying DeepVirFinder\nto real human gut metagenomic samples from patients with colorectal carcinoma\n(CRC) identified 51,138 viral sequences belonging to 175 bins. Ten bins were\nassociated with the cancer status, indicating their potential use for\nnon-invasive diagnosis of CRC. In summary, DeepVirFinder greatly improved the\nprecision and recall rates of viral identification, and it will significantly\naccelerate the discovery rate of viruses.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.07810v1"
    },
    {
        "title": "Innovative method for reducing uninformative calls in non-invasive\n  prenatal testing",
        "authors": [
            "Jaroslav Budis",
            "Juraj Gazdarica",
            "Jan Radvanszky",
            "Gabor Szucs",
            "Marcel Kucharik",
            "Lucia Strieskova",
            "Iveta Gazdaricova",
            "Maria Harsanyova",
            "Frantisek Duris",
            "Gabriel Minarik",
            "Martina Sekelska",
            "Balint Nagy",
            "Jan Turna",
            "Tomas Szemes"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Non-invasive prenatal testing or NIPT is currently among the top researched\ntopic in obstetric care. While the performance of the current state-of-the-art\nNIPT solutions achieve high sensitivity and specificity, they still struggle\nwith a considerable number of samples that cannot be concluded with certainty.\nSuch uninformative results are often subject to repeated blood sampling and\nre-analysis, usually after two weeks, and this period may cause a stress to the\nfuture mothers as well as increase the overall cost of the test. We propose a\nsupplementary method to traditional z-scores to reduce the number of such\nuninformative calls. The method is based on a novel analysis of the length\nprofile of circulating cell free DNA which compares the change in such profiles\nwhen random-based and length-based elimination of some fragments is performed.\nThe proposed method is not as accurate as the standard z-score; however, our\nresults suggest that combination of these two independent methods correctly\nresolves a substantial portion of healthy samples with an uninformative result.\nAdditionally, we discuss how the proposed method can be used to identify\nmaternal aberrations, thus reducing the risk of false positive and false\nnegative calls.\n  Keywords: Next-generation sequencing, Cell-free DNA, Uninformative result,\nMethod, Trisomy, Prenatal testing\n",
        "pdf_link": "http://arxiv.org/pdf/1806.08552v1"
    },
    {
        "title": "Genesis of the alpha beta T-cell receptor",
        "authors": [
            "Thomas Dupic",
            "Quentin Marcou",
            "Aleksandra M. Walczak",
            "Thierry Mora"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The T-cell (TCR) repertoire relies on the diversity of receptors composed of\ntwo chains, called $\\alpha$ and $\\beta$, to recognize pathogens. Using results\nof high throughput sequencing and computational chain-pairing experiments of\nhuman TCR repertoires, we quantitively characterize the $\\alpha\\beta$\ngeneration process. We estimate the probabilities of a rescue recombination of\nthe $\\beta$ chain on the second chromosome upon failure or success on the first\nchromosome. Unlike $\\beta$ chains, $\\alpha$ chains recombine simultaneously on\nboth chromosomes, resulting in correlated statistics of the two genes which we\npredict using a mechanistic model. We find that $\\sim 28 \\%$ of cells express\nboth $\\alpha$ chains. We report that clones sharing the same $\\beta$ chain but\ndifferent $\\alpha$ chains are overrepresented, suggesting that they respond to\ncommon immune challenges. Altogether, our statistical analysis gives a complete\nquantitative mechanistic picture that results in the observed correlations in\nthe generative process. We learn that the probability to generate any\nTCR$\\alpha\\beta$ is lower than $10^{-12}$ and estimate the generation diversity\nand sharing properties of the $\\alpha\\beta$ TCR repertoire.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.11030v2"
    },
    {
        "title": "Predicting Toxicity from Gene Expression with Neural Networks",
        "authors": [
            "Peter Eastman",
            "Vijay S. Pande"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  We train a neural network to predict chemical toxicity based on gene\nexpression data. The input to the network is a full expression profile\ncollected either in vitro from cultured cells or in vivo from live animals. The\noutput is a set of fine grained predictions for the presence of a variety of\npathological effects in treated animals. When trained on the Open TG-GATEs\ndatabase it produces good results, outperforming classical models trained on\nthe same data. This is a promising approach for efficiently screening chemicals\nfor toxic effects, and for more accurately evaluating drug candidates based on\npreclinical data.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.00060v1"
    },
    {
        "title": "BOAssembler: a Bayesian Optimization Framework to Improve RNA-Seq\n  Assembly Performance",
        "authors": [
            "Shunfu Mao",
            "Yihan Jiang",
            "Edwin Basil Mathew",
            "Sreeram Kannan"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  High throughput sequencing of RNA (RNA-Seq) can provide us with millions of\nshort fragments of RNA transcripts from a sample. How to better recover the\noriginal RNA transcripts from those fragments (RNA-Seq assembly) is still a\ndifficult task. For example, RNA-Seq assembly tools typically require\nhyper-parameter tuning to achieve good performance for particular datasets.\nThis kind of tuning is usually unintuitive and time-consuming. Consequently,\nusers often resort to default parameters, which do not guarantee consistent\ngood performance for various datasets.\n  Here we propose BOAssembler (https://github.com/olivomao/boassembler), a\nframework that enables end-to-end automatic tuning of RNA-Seq assemblers, based\non Bayesian Optimization principles. Experiments show this data-driven approach\nis effective to improve the overall assembly performance. The approach would be\nhelpful for downstream (e.g. gene, protein, cell) analysis, and more broadly,\nfor future bioinformatics benchmark studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.05235v1"
    },
    {
        "title": "Using sequencing coverage statistics to identify sex chromosomes in\n  minke whales",
        "authors": [
            "Ketil Malde",
            "Rasmus Skern",
            "Kevin A. Glover"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The ever-increasing number of genome sequencing and resequencing projects is\na central source of insights into the ecology and evolution of non-model\norganisms. An important aspect of genomics is the elucidation of sex\ndetermination systems and identifying genes on sex chromosomes. This not only\nhelps reveal mechanisms behind sex determination in the species under study,\nbut their characteristics make sex chromosomes a unique tool for studying the\nmechanisms and effects of recombination and genomic rearrangements and how they\naffect adaption and selection. Despite this, many sequencing projects omit such\ninvestigations. Here, we apply a simple method using sequencing coverage\nstatistics to identify scaffolds belonging to the sex chromosomes of minke\nwhale, and show how the sex chromosome system can be determined using coverage\nstatistics alone. Using publicly available data, we identify the previously\nunknown sex of an Antarctic minke whale as female. We further investigate\npublic sequence data from the different species and sub-species of minke whale,\nand classify genomic scaffolds from a published minke whale assembly as X or Y\nchromosomal sequences. Our findings are consistent with previous results that\nidentified a handful of scaffolds as sex chromosomal, but we are able to\nidentify a much larger set of scaffolds, likely to represent close to the\ncomplete sex chromosomal sequences for the minke whale. Sequence coverage\nstatistics provides a readily available tool for investigating the sex\ndetermination system and locate genes on sex chromosomes. This analysis is\nstraightforward and can often be performed with existing resources.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.06654v1"
    },
    {
        "title": "A bioinformatics pipeline for the identification of CHO cell\n  differential gene expression from RNA-Seq data",
        "authors": [
            "Craig Monger",
            "Krishna Motheramgari",
            "John McSharry",
            "Niall Barron",
            "Colin Clarke"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In recent years the publication of genome sequences for the Chinese hamster\nand Chinese hamster ovary (CHO) cell lines have facilitated study of these\nbiopharmaceutical cell factories with unprecedented resolution. Our\nunderstanding of the CHO cell transcriptome, in particular, has rapidly\nadvanced through the application of next-generation sequencing (NGS) technology\nto characterise RNA expression (RNA-Seq). In this chapter we present a\ncomputational pipeline for the analysis of CHO cell RNA-Seq data from the\nIllumina platform to identify differentially expressed genes. The example data\nand bioinformatics workflow required to run this analysis are freely available\nat www.cgcdb.org/rnaseq_analysis_protocol.html.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.00204v1"
    },
    {
        "title": "RACS: Rapid Analysis of ChIP-Seq data for contig based genomes",
        "authors": [
            "Marcelo Ponce",
            "Alejandro Saettone",
            "Syed Nabeel-Shah",
            "Jeffrey Fillingham"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Background: Chromatin immunoprecipitation coupled to next generation\nsequencing (ChIP-Seq) is a widely used technique to investigate the function of\nchromatin-related proteins in a genome-wide manner. ChIP-Seq generates large\nquantities of data which can be difficult to process and analyse, particularly\nfor organisms with contig based genomes. Contig-based genomes often have poor\nannotations for cis-elements, for example enhancers, that are important for\ngene expression. Poorly annotated genomes make a comprehensive analysis of\nChIP-Seq data difficult and as such standardized analysis pipelines are\nlacking. Methods: We report a computational pipeline that utilizes traditional\nHigh-Performance Computing techniques and open source tools for processing and\nanalysing data obtained from ChIP-Seq. We applied our computational pipeline\n\"Rapid Analysis of ChIP-Seq data\" (RACS) to ChIP-Seq data that was generated in\nthe model organism Tetrahymena thermophila, an example of an organism with a\ngenome that is available in contigs. Results: To test the performance and\nefficiency of RACs, we performed control ChIP-Seq experiments allowing us to\nrapidly eliminate false positives when analyzing our previously published data\nset. Our pipeline segregates the found read accumulations between genic and\nintergenic regions and is highly efficient for rapid downstream analyses.\nConclusions: Altogether, the computational pipeline presented in this report is\nan efficient and highly reliable tool to analyze genome-wide ChIP-Seq data\ngenerated in model organisms with contig-based genomes.\n  RACS is an open source computational pipeline available to download from:\nhttps://bitbucket.org/mjponce/racs --or--\nhttps://gitrepos.scinet.utoronto.ca/public/?a=summary&p=RACS\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02771v1"
    },
    {
        "title": "RNASeqR: an R package for automated two-group RNA-Seq analysis workflow",
        "authors": [
            "Kuan-Hao Chao",
            "Yi-Wen Hsiao",
            "Yi-Fang Lee",
            "Chien-Yueh Lee",
            "Liang-Chuan Lai",
            "Mong-Hsun Tsai",
            "Tzu-Pin Lu",
            "Eric Y. Chuang"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  RNA-Seq analysis has revolutionized researchers' understanding of the\ntranscriptome in biological research. Assessing the differences in\ntranscriptomic profiles between tissue samples or patient groups enables\nresearchers to explore the underlying biological impact of transcription.\nRNA-Seq analysis requires multiple processing steps and huge computational\ncapabilities. There are many well-developed R packages for individual steps;\nhowever, there are few R/Bioconductor packages that integrate existing software\ntools into a comprehensive RNA-Seq analysis and provide fundamental end-to-end\nresults in pure R environment so that researchers can quickly and easily get\nfundamental information in big sequencing data. To address this need, we have\ndeveloped the open source R/Bioconductor package, RNASeqR. It allows users to\nrun an automated RNA-Seq analysis with only six steps, producing essential\ntabular and graphical results for further biological interpretation. The\nfeatures of RNASeqR include: six-step analysis, comprehensive visualization,\nbackground execution version, and the integration of both R and command-line\nsoftware. RNASeqR provides fast, light-weight, and easy-to-run RNA-Seq analysis\npipeline in pure R environment. It allows users to efficiently utilize popular\nsoftware tools, including both R/Bioconductor and command-line tools, without\npredefining the resources or environments. RNASeqR is freely available for\nLinux and macOS operating systems from Bioconductor\n(https://bioconductor.org/packages/release/bioc/html/RNASeqR.html).\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03909v1"
    },
    {
        "title": "Tumor Microenvironment-based Gene Signatures Divides Novel Immune and\n  Stromal Subgroup Classification of Lung Adenocarcinoma",
        "authors": [
            "Zihang Zeng",
            "Jiali Li",
            "Nannan Zhang",
            "Xueping Jiang",
            "Yanping Gao",
            "Liexi Xu",
            "Xingyu Liu",
            "Jiarui Chen",
            "Yuke Gao",
            "Linzhi Han",
            "Jiangbo Ren",
            "Yan Gong",
            "Conghua Xie"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Tumor microenvironment has complex effects on tumorigenesis and metastasis.\nHowever, there is still a lack of comprehensive understanding of the\nrelationship among molecular and cellular characteristics in tumor\nmicroenvironment, clinical prognosis and immunotherpy response. In this study,\nthe immune and stromal (non-immune) signatures of tumor microenvironment were\nintegrated to identify novel subgroups of lung adenocarcinoma by\neigendecomposition and extraction algorithms of bioinformatics and machine\nlearning, such as non-negative matrix factorization and multitask learning.\nTumors were classified into 4 groups according to the activation of immunity\nand stroma by novel signatures. The 4 groups had different mutation landscape,\nmolecular, cellular characteristics and prognosis, which have been validation\nin 6 independent data sets containing 1551 patients. High-immune and\nlow-stromal activation group links to high immunocyte infiltration, high\nimmunocompetence, low fibroblasts, endothelial cells, collagen, laminin, tumor\nmutation burden, and better overall survival. We developed a novel model based\non tumor microenvironment by integrating immune and stromal activation, namely\nPMBT (prognostic model based on tumor microenvironment). The PMBT showed the\nvalue to predict overall survival and immunotherapy responses.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03978v1"
    },
    {
        "title": "Identification of Biomarkers Driving Blood Cell Development",
        "authors": [
            "Maryam Nazarieh",
            "Volkhard Helms"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  A blood cell lineage consists of several consecutive developmental stages\nfrom the pluripotent or multipotent stem cell to a particular stage of\nterminally differentiated cells. There is considerable interest in identifying\nthe key regulatory genes that govern blood cell development from the gene\nexpression data without considering the underlying network between\ntranscription factors (TFs) and their target genes. In this study, we introduce\na novel expression pattern that key regulators expose along the differentiation\npath. We deploy this pattern to identify the cell-specific key regulators\nresponsible for the development. As proof of concept, we consider this approach\nto data on six developmental stages from mouse embryonic stem cells to\nterminally differentiated macrophages.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01890v1"
    },
    {
        "title": "A Common Gene Expression Signature Analysis Method for Multiple Types of\n  Cancer",
        "authors": [
            "Yingcheng Sun",
            "Xiangru Liang",
            "Kenneth Loparo"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Mining gene expression profiles has proven valuable for identifying\nsignatures serving as surrogates of cancer phenotypes. However, the\nsimilarities of such signatures across different cancer types have not been\nstrong enough to conclude that they represent a universal biological mechanism\nshared among multiple cancer types. Here we describe a network-based approach\nthat explores gene-to-gene connections in multiple cancer datasets while\nmaximizing the overall association of the subnetwork with clinical outcomes.\nWith the dataset of The Cancer Genome Atlas (TCGA), we studied the\ncharacteristics of common gene expression of three types of cancers: Rectum\nadenocarcinoma (READ), Breast invasive carcinoma (BRCA) and Colon\nadenocarcinoma (COAD). By analyzing several pairs of highly correlated genes\nafter filtering and clustering work, we found that the co-expressed genes\nacross multiple types of cancers point to particular biological mechanisms\nrelated to cancer cell progression , suggesting that they represent important\nattributes of cancer in need of being elucidated for potential applications in\ndiagnostic, prognostic and therapeutic products applicable to multiple cancer\ntypes.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.12379v1"
    },
    {
        "title": "De Novo Assembly of Uca minax Transcriptome from Next Generation\n  Sequencing",
        "authors": [
            "Hanin Omar",
            "Casey A. Cole",
            "Arjang Fahim",
            "Giuliana Gusmaroli",
            "Stephen Borgianini",
            "Homayoun Valafar"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  High-throughput cDNA sequencing (RNA-seq) is a very powerful technique to\nquantify gene expression in an unbiased way. The Crustacean family is among the\ngroups of organisms sparsely represented in current genomic databases. Here we\npresent transcriptome data from Uca minax (red-jointed fiddler crab) as an\nopportunity to extend our knowledge. Next generation sequencing was performed\non six tissue samples from Uca minax using the Illumina HiSeq system. Six\nTranscriptome libraries were created using Trinity; a free, open-source\nsoftware tool for de novo transcriptome assembly of high-throughput mRNA\nsequencing (RNA-seq) data with the absence of a reference genome. In addition,\nseveral tools that aid in management of data were used, such as RSEM, Bowtie,\nBlast, and IGV; a tool for visualizing RNA-seq analysis results. Fast quality\ncontrol (FastQC) analysis of the raw sequenced files revealed that both adapter\nand PCR primer sequences were prevalently present, which may require a\npreprocessing step.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03092v1"
    },
    {
        "title": "Deciphering the regulatory genome of $\\textit{Escherichia coli}$, one\n  hundred promoters at a time",
        "authors": [
            "William T. Ireland",
            "Suzannah M. Beeler",
            "Emanuel Flores-Bautista",
            "Nathan M. Belliveau",
            "Michael J. Sweredoski",
            "Annie Moradian",
            "Justin B. Kinney",
            "Rob Phillips"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Advances in DNA sequencing have revolutionized our ability to read genomes.\nHowever, even in the most well-studied of organisms, the bacterium ${\\it\nEscherichia coli}$, for $\\approx$ 65$\\%$ of the promoters we remain completely\nignorant of their regulation. Until we have cracked this regulatory Rosetta\nStone, efforts to read and write genomes will remain haphazard. We introduce a\nnew method (Reg-Seq) linking a massively-parallel reporter assay and mass\nspectrometry to produce a base pair resolution dissection of more than 100\npromoters in ${\\it E. coli}$ in 12 different growth conditions. First, we show\nthat our method recapitulates regulatory information from known sequences.\nThen, we examine the regulatory architectures for more than 80 promoters in the\n${\\it E. coli}$ genome which previously had no known regulation. In many cases,\nwe also identify which transcription factors mediate their regulation. The\nmethod introduced here clears a path for fully characterizing the regulatory\ngenome of model organisms, with the potential of moving on to an array of other\nmicrobes of ecological and medical relevance.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.07396v1"
    },
    {
        "title": "High fidelity epigenetic inheritance: Information theoretic model\n  predicts $k$-threshold filling of histone modifications post replication",
        "authors": [
            "Nithya Ramakrishnan",
            "Sibi Raj B Pillai",
            "Ranjith Padinhateeri"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Beyond the genetic code, there is another layer of information encoded as\nchemical modifications on histone proteins positioned along the DNA.\nMaintaining these modifications is crucial for survival and identity of cells.\nHow the information encoded in the histone marks gets inherited, given that\nonly half the parental nucleosomes are transferred to each daughter chromatin,\nis a puzzle. We address this problem using ideas from Information theory and\nunderstanding from recent biological experiments. Mapping the replication and\nreconstruction of modifications to equivalent problems in communication, we ask\nhow well an enzyme-machinery can recover information, if they were ideal\ncomputing machines. Studying a parameter regime where realistic enzymes can\nfunction, our analysis predicts that, pragmatically, enzymes may implement a\nthreshold$-k$ filling algorithm which derives from maximum \\`a posteriori\nprobability decoding. Simulations using our method produce modification\npatterns similar to what is observed in recent experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06539v1"
    },
    {
        "title": "Identification of Repurposable Drugs and Adverse Drug Reactions for\n  Various Courses of COVID-19 Based on Single-Cell RNA Sequencing Data",
        "authors": [
            "Zhihan Wang",
            "Kai Guo",
            "Pan Gao",
            "Qinqin Pu",
            "Min Wu",
            "Changlong Li",
            "Junguk Hur"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Coronavirus disease 2019 (COVID-19) has impacted almost every part of human\nlife worldwide, posing a massive threat to human health. There is no specific\ndrug for COVID-19, highlighting the urgent need for the development of\neffective therapeutics. To identify potentially repurposable drugs, we employed\na systematic approach to mine candidates from U.S. FDA-approved drugs and\npreclinical small-molecule compounds by integrating the gene expression\nperturbation data for chemicals from the Library of Integrated Network-Based\nCellular Signatures project with a publicly available single-cell RNA\nsequencing dataset from mild and severe COVID-19 patients. We identified 281\nFDA-approved drugs that have the potential to be effective against SARS-CoV-2\ninfection, 16 of which are currently undergoing clinical trials to evaluate\ntheir efficacy against COVID-19. We experimentally tested the inhibitory\neffects of tyrphostin-AG-1478 and brefeldin-a on the replication of the\nsingle-stranded ribonucleic acid (ssRNA) virus influenza A virus. In\nconclusion, we have identified a list of repurposable anti-SARS-CoV-2 drugs\nusing a systems biology approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07856v2"
    },
    {
        "title": "Longitudinal high-throughput TCR repertoire profiling reveals the\n  dynamics of T cell memory formation after mild COVID-19 infection",
        "authors": [
            "Anastasia A. Minervina",
            "Ekaterina A. Komech",
            "Aleksei Titov",
            "Meriem Bensouda Koraichi",
            "Elisa Rosati",
            "Ilgar Z. Mamedov",
            "Andre Franke",
            "Grigory A. Efimov",
            "Dmitriy M. Chudakov",
            "Thierry Mora",
            "Aleksandra M. Walczak",
            "Yuri B. Lebedev",
            "Mikhail V. Pogorelyy"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  COVID-19 is a global pandemic caused by the SARS-CoV-2 coronavirus. T cells\nplay a key role in the adaptive antiviral immune response by killing infected\ncells and facilitating the selection of virus-specific antibodies. However\nneither the dynamics and cross-reactivity of the SARS-CoV-2-specific T cell\nresponse nor the diversity of resulting immune memory are well understood. In\nthis study we use longitudinal high-throughput T cell receptor (TCR) sequencing\nto track changes in the T cell repertoire following two mild cases of COVID-19.\nIn both donors we identified CD4+ and CD8+ T cell clones with transient clonal\nexpansion after infection. The antigen specificity of CD8+ TCR sequences to\nSARS-CoV-2 epitopes was confirmed by both MHC tetramer binding and presence in\nlarge database of SARS-CoV-2 epitope-specific TCRs. We describe characteristic\nmotifs in TCR sequences of COVID-19-reactive clones and show preferential\noccurence of these motifs in publicly available large dataset of repertoires\nfrom COVID-19 patients. We show that in both donors the majority of\ninfection-reactive clonotypes acquire memory phenotypes. Certain T cell clones\nwere detected in the memory fraction at the pre-infection timepoint, suggesting\nparticipation of pre-existing cross-reactive memory T cells in the immune\nresponse to SARS-CoV-2.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.08290v3"
    },
    {
        "title": "Identification of candidate regulatory sequences in mammalian 3' UTRs by\n  statistical analysis of oligonucleotide distributions",
        "authors": [
            "Davide Cora",
            "Ferdinando Di Cunto",
            "Michele Caselle",
            "Paolo Provero"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  3' untranslated regions (3' UTRs) contain binding sites for many regulatory\nelements, and in particular for microRNAs (miRNAs). The importance of\nmiRNA-mediated post-transcriptional regulation has become increasingly clear in\nthe last few years.\n  We propose two complementary approaches to the statistical analysis of\noligonucleotide frequencies in mammalian 3' UTRs aimed at the identification of\ncandidate binding sites for regulatory elements. The first method is based on\nthe identification of sets of genes characterized by evolutionarily conserved\noverrepresentation of an oligonucleotide. The second method is based on the\nidentification of oligonucleotides showing statistically significant strand\nasymmetry in their distribution in 3' UTRs.\n  Both methods are able to identify many previously known binding sites located\nin 3'UTRs, and in particular seed regions of known miRNAs. Many new candidates\nare proposed for experimental verification.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.0394v2"
    },
    {
        "title": "Global regulation of genome duplication in eukaryotes: an overview from\n  the epifluorescence microscope",
        "authors": [
            "John Herrick",
            "Aaron Bensimon"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  In eukaryotes, DNA replication is initiated along each chromosome at multiple\nsites called replication origins. Locally, each replication origin is\n\"licensed\", or specified, at the end of the M and the beginning of G1 phases of\nthe cell cycle. During S phase when DNA synthesis takes place, origins are\nactivated in stages corresponding to early and late replicating domains. The\nstaged and progressive activation of replication origins reflects the need to\nmaintain a strict balance between the number of active replication forks and\nthe rate at which DNA synthesis procedes. This suggests that origin densities\n(frequency of intiation) and replication fork movement (rates of elongation)\nmust be co-regulated in order to guarantee the efficient and complete\nduplication of each subchromosomal domain. Emerging evidence supports this\nproposal and suggests that the ATM/ATR intra-S phase checkpoint plays an\nimportant role in the co-regulation of initiation frequencies and rates of\nelongation. In the following, we review recent results concerning the\nmechanisms governing the global regulation of DNA replication and discuss the\nroles these mechanisms play in maintaining genome stability during both a\nnormal and perturbed S phase.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.3811v4"
    },
    {
        "title": "Rare coding SNP in DZIP1 gene associated with late-onset sporadic\n  Parkinson's disease",
        "authors": [
            "A. X. C. N. Valente",
            "J. H. Shin",
            "A. Sarkar",
            "Y. Gao"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  We present the first application of the hypothesis-rich mathematical theory\nto genome-wide association data. The Hamza et al. late-onset sporadic\nParkinson's disease genome-wide association study dataset was analyzed. We\nfound a rare, coding, non-synonymous SNP variant in the gene DZIP1 that confers\nincreased susceptibility to Parkinson's disease. The association of DZIP1 with\nParkinson's disease is consistent with a Parkinson's disease stem-cell ageing\ntheory.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0029v2"
    },
    {
        "title": "High-order chromatin architecture determines the landscape of\n  chromosomal alterations in cancer",
        "authors": [
            "Geoff Fudenberg",
            "Gad Getz",
            "Matthew Meyerson",
            "Leonid Mirny"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  The rapid growth of cancer genome structural information provides an\nopportunity for a better understanding of the mutational mechanisms of genomic\nalterations in cancer and the forces of selection that act upon them. Here we\ntest the evidence for two major forces, spatial chromosome structure and\npurifying (or negative) selection, that shape the landscape of somatic\ncopy-number alterations (SCNAs) in cancer1. Using a maximum likelihood\nframework we compare SCNA maps and three-dimensional genome architecture as\ndetermined by genome-wide chromosome conformation capture (HiC) and described\nby the proposed fractal-globule (FG) model2. This analysis provides evidence\nthat the distribution of chromosomal alterations in cancer is spatially related\nto three-dimensional genomic architecture and additionally suggests that\npurifying selection as well as positive selection shapes the landscape of SCNAs\nduring somatic evolution of cancer cells.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.1321v1"
    },
    {
        "title": "Two-dimensional gel electrophoresis in proteomics: A tutorial",
        "authors": [
            "Thierry Rabilloud",
            "Cécile Lelong"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Two-dimensional electrophoresis of proteins has preceded, and accompanied,\nthe birth of proteomics. Although it is no longer the only experimental scheme\nused in modern proteomics, it still has distinct features and advantages. The\npurpose of this tutorial paper is to guide the reader through the history of\nthe field, then through the main steps of the process, from sample preparation\nto in-gel detection of proteins, commenting the constraints and caveats of the\ntechnique. Then the limitations and positive features of two-dimensional\nelectrophoresis are discussed (e.g. its unique ability to separate complete\nproteins and its easy interfacing with immunoblotting techniques), so that the\noptimal type of applications of this technique in current and future proteomics\ncan be perceived. This is illustrated by a detailed example taken from the\nliterature and commented in detail. This Tutorial is part of the International\nProteomics Tutorial Programme (IPTP 2).\n",
        "pdf_link": "http://arxiv.org/pdf/1109.3178v1"
    },
    {
        "title": "Quantifying uniformity of mapped reads",
        "authors": [
            "Valerie Hower",
            "Richard Starfield",
            "Adam Roberts",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Summary: We describe a tool for quantifying the uniformity of mapped reads in\nhigh-throughput sequencing experiments. Our statistic directly measures the\nuniformity of both read position and fragment length, and we explain how to\ncompute a p-value that can be used to quantify biases arising from experimental\nprotocols and mapping procedures. Our method is useful for comparing different\nprotocols in experiments such as RNA-Seq.\n  Availability and Implementation: We provide a freely available and open\nsource python script that can be used to analyze raw read data or reads mapped\nto transcripts in BAM format at http://www.math.miami.edu/~vhower/ReadSpy.html .\n  Contact: lpachter@math.berkeley.edu\n",
        "pdf_link": "http://arxiv.org/pdf/1109.5681v3"
    },
    {
        "title": "Inference of Natural Selection from Interspersed Genomic Elements Based\n  on Polymorphism and Divergence",
        "authors": [
            "Ilan Gronau",
            "Leonardo Arbiza",
            "Jaaved Mohammed",
            "Adam Siepel"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Complete genome sequences contain valuable information about natural\nselection, but extracting this information for short, widely scattered\nnoncoding elements remains a challenging problem. Here we introduce a new\ncomputational method for addressing this problem called Inference of Natural\nSelection from Interspersed Genomically coHerent elemenTs (INSIGHT). INSIGHT\nuses a generative probabilistic model to contrast patterns of polymorphism and\ndivergence in the elements of interest with those in flanking neutral sites,\npooling weak information from many short elements in a manner that accounts for\nvariation among loci in mutation rates and genealogical backgrounds. The method\nis able to disentangle the contributions of weak negative, strong negative, and\npositive selection based on their distinct effects on patterns of polymorphism\nand divergence. Information about divergence is obtained from multiple outgroup\ngenomes using a full phylogenetic model. The model is efficiently fitted to\ngenome-wide data by decomposing the maximum likelihood estimation procedure\ninto three straightforward stages. The key selection-related parameters are\nestimated by expectation maximization. Using simulations, we show that INSIGHT\ncan accurately estimate several parameters of interest even in complex\ndemographic scenarios. We apply our methods to noncoding RNAs, promoter\nregions, and transcription factor binding sites in the human genome, and find\nclear evidence of natural selection. We also present a detailed analysis of\nparticular nucleotide positions within GATA2 binding sites and primary\nmicro-RNA transcripts.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.6381v6"
    },
    {
        "title": "An explanation of unexpected Hoxd expressions in mutant mice",
        "authors": [
            "Spyros Papageorgiou"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The Hox gene collinearity enigma has often been approached using models based\non biomolecular mechanisms. The biophysical model, is an alternative approach,\nspeculating that collinearity is caused by physical forces pulling the Hox\nclusters from a territory where they are inactive to a distinct spatial domain\nwhere they are activated in a step by step manner.\n  Hox gene translocations have recently been observed in support of the\nbiophysical model. Furthermore, genetic engineering experiments, performed in\nembryonic mice, gave rise to some unexpected mutant expressions that\nbiomolecular models could not predict. In several cases when anterior Hoxd\ngenes are deleted, the expression of the genes whose expression is probed in\nthe mutants are impossible to anticipate. On the contrary, the biophysical\nmodel offers convincing explanation.\n  All these experimental results support the idea of physical forces being\nresponsible for Hox gene collinearity. In order to test the validity of the\nvarious models further, certain experiment involving gene deletions are\nproposed. The biophysical and biomolecular models predict different results for\nthese experiments, hence the expected outcome will confirm or question the\nvalidity of these models.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.0312v1"
    },
    {
        "title": "Genome-wide analysis points to roles for extracellular matrix\n  remodeling, the visual cycle, and neuronal development in myopia",
        "authors": [
            "Amy K. Kiefer",
            "Joyce Y. Tung",
            "Chuong B. Do",
            "David A. Hinds",
            "Joanna L. Mountain",
            "Uta Francke",
            "Nicholas Eriksson"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Myopia, or nearsightedness, is the most common eye disorder, resulting\nprimarily from excess elongation of the eye. The etiology of myopia, although\nknown to be complex, is poorly understood. Here we report the largest ever\ngenome-wide association study (43,360 participants) on myopia in Europeans. We\nperformed a survival analysis on age of myopia onset and identified 19\nsignificant associations (p < 5e-8), two of which are replications of earlier\nassociations with refractive error. These 19 associations in total explain 2.7%\nof the variance in myopia age of onset, and point towards a number of different\nmechanisms behind the development of myopia. One association is in the gene\nPRSS56, which has previously been linked to abnormally small eyes; one is in a\ngene that forms part of the extracellular matrix (LAMA2); two are in or near\ngenes involved in the regeneration of 11-cis-retinal (RGR and RDH5); two are\nnear genes known to be involved in the growth and guidance of retinal ganglion\ncells (ZIC2, SFRP1); and five are in or near genes involved in neuronal\nsignaling or development. These novel findings point towards multiple genetic\nfactors involved in the development of myopia and suggest that complex\ninteractions between extracellular matrix remodeling, neuronal development, and\nvisual signals from the retina may underlie the development of myopia in\nhumans.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2089v1"
    },
    {
        "title": "A genetic variant near olfactory receptor genes influences cilantro\n  preference",
        "authors": [
            "Nicholas Eriksson",
            "Shirley Wu",
            "Chuong B. Do",
            "Amy K. Kiefer",
            "Joyce Y. Tung",
            "Joanna L. Mountain",
            "David A. Hinds",
            "Uta Francke"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The leaves of the Coriandrum sativum plant, known as cilantro or coriander,\nare widely used in many cuisines around the world. However, far from being a\nbenign culinary herb, cilantro can be polarizing---many people love it while\nothers claim that it tastes or smells foul, often like soap or dirt. This soapy\nor pungent aroma is largely attributed to several aldehydes present in\ncilantro. Cilantro preference is suspected to have a genetic component, yet to\ndate nothing is known about specific mechanisms. Here we present the results of\na genome-wide association study among 14,604 participants of European ancestry\nwho reported whether cilantro tasted soapy, with replication in a distinct set\nof 11,851 participants who declared whether they liked cilantro. We find a\nsingle nucleotide polymorphism (SNP) significantly associated with soapy-taste\ndetection that is confirmed in the cilantro preference group. This SNP,\nrs72921001, (p=6.4e-9, odds ratio 0.81 per A allele) lies within a cluster of\nolfactory receptor genes on chromosome 11. Among these olfactory receptor genes\nis OR6A2, which has a high binding specificity for several of the aldehydes\nthat give cilantro its characteristic odor. We also estimate the heritability\nof cilantro soapy-taste detection in our cohort, showing that the heritability\ntagged by common SNPs is low, about 0.087. These results confirm that there is\na genetic component to cilantro taste perception and suggest that cilantro\ndislike may stem from genetic variants in olfactory receptors. We propose that\nOR6A2 may be the olfactory receptor that contributes to the detection of a\nsoapy smell from cilantro in European populations.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2096v1"
    },
    {
        "title": "Horizontal gene transfer drives extreme physiological change in\n  Haloarchaea",
        "authors": [
            "Chris Creevey",
            "James McInerney"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The haloarchaea are aerobic, heterotrophic, photophosphorylating prokaryotes,\nwhose supposed closest relatives and ancestors, the methanogens, are\nCO2-reducing, anaerobic chemolithotrophs. Using two available haloarchaeal\ngenomes we firstly confirmed the methanogenic ancestry of the group and then\ninvestigated those individual genes in the haloarchaea that differ in their\nphylogenetic signal to this relationship. We found that almost half the genes,\nabout which we can make strong statements, have bacterial ancestry and are\nlikely a result of multiple horizontal transfer events. Futhermore their\nfunctions specifically relate to the phenotypic changes required for a\nchemolithotroph to become a heterotroph. If this phylogenetic relationship is\ncorrect, it implies the development of the haloarchaeal phenotype was among the\nmost extreme changes in cellular physiology fuelled by horizontal gene\ntransfer.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2455v1"
    },
    {
        "title": "Comparative Analysis of Tandem Repeats from Hundreds of Species Reveals\n  Unique Insights into Centromere Evolution",
        "authors": [
            "Daniël P. Melters",
            "Keith R. Bradnam",
            "Hugh A. Young",
            "Natalie Telis",
            "Michael R. May",
            "J. Graham Ruby",
            "Robert Sebra",
            "Paul Peluso",
            "John Eid",
            "David Rank",
            "José Fernando Garcia",
            "Joseph L. DeRisi",
            "Timothy Smith",
            "Christian Tobias",
            "Jeffrey Ross-Ibarra",
            "Ian F. Korf",
            "Simon W. -L. Chan"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Centromeres are essential for chromosome segregation, yet their DNA sequences\nevolve rapidly. In most animals and plants that have been studied, centromeres\ncontain megabase-scale arrays of tandem repeats. Despite their importance, very\nlittle is known about the degree to which centromere tandem repeats share\ncommon properties between different species across different phyla. We used\nbioinformatic methods to identify high-copy tandem repeats from 282 species\nusing publicly available genomic sequence and our own data. The assumption that\nthe most abundant tandem repeat is the centromere DNA was true for most species\nwhose centromeres have been previously characterized, suggesting this is a\ngeneral property of genomes. Our methods are compatible with all current\nsequencing technologies. Long Pacific Biosciences sequence reads allowed us to\nfind tandem repeat monomers up to 1,419 bp. High-copy centromere tandem repeats\nwere found in almost all animal and plant genomes, but repeat monomers were\nhighly variable in sequence composition and in length. Furthermore,\nphylogenetic analysis of sequence homology showed little evidence of sequence\nconservation beyond ~50 million years of divergence. We find that despite an\noverall lack of sequence conservation, centromere tandem repeats from diverse\nspecies showed similar modes of evolution, including the appearance of higher\norder repeat structures in which several polymorphic monomers make up a larger\nrepeating unit. While centromere position in most eukaryotes is epigenetically\ndetermined, our results indicate that tandem repeats are highly prevalent at\ncentromeres of both animals and plants. This suggests a functional role for\nsuch repeats, perhaps in promoting concerted evolution of centromere DNA across\nchromosomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.4967v1"
    },
    {
        "title": "Protein function influences frequency of encoded regions containing\n  VNTRs and number of unique interactions",
        "authors": [
            "Suzanne Bowen"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Proteins encoded by genes containing regions of variable number tandem\nrepeats (VNTRs) are known to be polymorphic within species but the influence of\ntheir instability in molecular interactions remains unclear. VNTRs are\noverrepresented in encoding sequence of particular functional groups where\ntheir presence could influence protein interactions. Using human consensus\ncoding sequence, this work examines if genomic instability, determined by\nregions of VNTRs, influences the number of protein interactions. Findings\nreveal that, in relation to protein function, the frequency of unique\ninteractions in human proteins increase with the number of repeated regions.\nThis supports experimental evidence that repeat expansion may lead to an\nincrease in molecular interactions. Genetic diversity, estimated by Ka/Ks,\nappeared to decrease as the number of protein-protein interactions increased.\nAdditionally, G+C and CpG content were negatively correlated with increasing\noccurrence of VNTRs. This may indicate that nucleotide composition along with\nselective processes can increase genomic stability and thereby restrict the\nexpansion of repeated regions. Proteins involved in acetylation are associated\nwith a high number of repeated regions and interactions but a low G+C and CpG\ncontent. While in contrast, less interactive membrane proteins contain a lower\nnumber of repeated regions but higher levels of C+G and CpGs. This work\nprovides further evidence that VNTRs may provide the genetic variability to\ngenerate unique interactions between proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5760v2"
    },
    {
        "title": "Antibiotic resistant characteristics from 16S rRNA",
        "authors": [
            "Casey Richardson"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Background: Microbiota have evolved to acclimate themselves to many\nenvironments. Humanity is become ever increasingly medicated and many of those\nmedications are antibiotics. Sadly, Microbiota are adapting to medication and\nwith each passing generation they become more difficult to subdue. The 16S\nsmall subunit of bacterial ribosomal rRNA provides a wealth of information for\nclassifying the species level taxonomy of bacteria. Methodology/Principal\nFindings: Experiments were collected utilizing broad and narrow spectrum\nantibiotics, which act primarily on DNA. In each experiment a statistically\nsignificant, unique and predictable pattern of sequential and thermodynamic\nstability or instability was found to correlate to antibiotic resistance.\nConclusions/Significance: Classification of antibiotic resistance is possible\nfor some species and antibiotic combinations using the 16S rRNA sequential and\nthermodynamic properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5801v1"
    },
    {
        "title": "Gene silencing and large-scale domain structure of the E. coli genome",
        "authors": [
            "Mina Zarei",
            "Bianca Sclavi",
            "Marco Cosentino Lagomarsino"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The H-NS chromosome-organizing protein in E. coli can stabilize genomic DNA\nloops, and form oligomeric structures connected to repression of gene\nexpression. Motivated by the link between chromosome organization, protein\nbinding and gene expression, we analyzed publicly available genomic data sets\nof various origins, from genome-wide protein binding profiles to evolutionary\ninformation, exploring the connections between chromosomal organization,\ngenesilencing, pseudo-gene localization and horizontal gene transfer. We report\nthe existence of transcriptionally silent contiguous areas corresponding to\nlarge regions of H-NS protein binding along the genome, their position\nindicates a possible relationship with the known large-scale features of\nchromosome organization.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.6513v1"
    },
    {
        "title": "Rare recombination events generate sequence diversity among balancer\n  chromosomes in Drosophila melanogaster",
        "authors": [
            "Danny E. Miller",
            "Kevin R. Cook",
            "Nazanin Yeganehkazemi",
            "Clarissa B. Smith",
            "Alexandria J. Cockrell",
            "R. Scott Hawley",
            "Casey M. Bergman"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Multiply inverted balancer chromosomes that suppress exchange with their\nhomologs are an essential part of the genetic toolkit in Drosophila\nmelanogaster. Despite their widespread use, the organization of balancer\nchromosomes has not been characterized at the molecular level, and the degree\nof sequence variation among copies of any given balancer chromosome is unknown.\nTo map inversion breakpoints and study potential sequence diversity in the\ndescendants of a structurally identical balancer chromosome, we sequenced a\npanel of laboratory stocks containing the most widely used X-chromosome\nbalancer, First Multiple 7 (FM7). We mapped the locations of FM7 breakpoints to\nprecise euchromatic coordinates and identified the flanking sequence of\nbreakpoints in heterochromatic regions. Analysis of SNP variation revealed\nmegabase-scale blocks of sequence divergence among currently used FM7 stocks.\nWe present evidence that this divergence arose by rare double crossover events\nthat replaced a female-sterile allele of the singed gene (sn[X2]) on FM7c with\nwild type sequence from balanced chromosomes, and propose that many FM7c\nchromosomes in the Bloomington Drosophila Stock Center have lost sn[X2] by this\nmechanism. Finally, we characterize the original allele of the Bar gene (B[1])\nthat is carried on FM7 and validate the hypothesis that the origin and\nsubsequent reversion of the B1 duplication is mediated by unequal exchange. Our\nresults reject a simple non-recombining, clonal mode for the laboratory\nevolution of balancer chromosomes and have implications for how balancer\nchromosomes should be used in the design and interpretation of genetic\nexperiments in Drosophila.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.04997v1"
    },
    {
        "title": "Cnidaria: fast, reference-free clustering of raw and assembled genome\n  and transcriptome NGS data",
        "authors": [
            "Saulo Alves Aflitos",
            "Edouard Severing",
            "Gabino Sanchez-Perez",
            "Sander Peters",
            "Hans de Jong",
            "Dick de Ridder"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Background: Identification of biological specimens is a major requirement for\na range of applications. Reference-free methods analyse unprocessed sequencing\ndata without relying on prior knowledge, but generally do not scale to\narbitrarily large genomes and arbitrarily large phylogenetic distances.\nResults: We present Cnidaria, a practical tool for clustering genomic and\ntranscriptomic data with no limitation on genome size or phylogenetic\ndistances. We successfully simultaneously clustered 169 genomic and\ntranscriptomic datasets from 4 kingdoms, achieving 100% identification accuracy\nat supra-species level and 78% accuracy for species level. Discussion: CNIDARIA\nallows for fast, resource-efficient comparison and identification of both raw\nand assembled genome and transcriptome data. This can help answer both\nfundamental (e.g. in phylogeny, ecological diversity analysis) and practical\nquestions (e.g. sequencing quality control, primer design).\n",
        "pdf_link": "http://arxiv.org/pdf/1511.05530v1"
    },
    {
        "title": "Predicting the spectrum of TCR repertoire sharing with a data-driven\n  model of recombination",
        "authors": [
            "Yuval Elhanati",
            "Zachary Sethna",
            "Curtis G. Callan Jr.",
            "Thierry Mora",
            "Aleksandra M. Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Despite the extreme diversity of T cell repertoires, many identical T-cell\nreceptor (TCR) sequences are found in a large number of individual mice and\nhumans. These widely-shared sequences, often referred to as `public', have been\nsuggested to be over-represented due to their potential immune functionality or\ntheir ease of generation by V(D)J recombination. Here we show that even for\nlarge cohorts the observed degree of sharing of TCR sequences between\nindividuals is well predicted by a model accounting for by the known\nquantitative statistical biases in the generation process, together with a\nsimple model of thymic selection. Whether a sequence is shared by many\nindividuals is predicted to depend on the number of queried individuals and the\nsampling depth, as well as on the sequence itself, in agreement with the data.\nWe introduce the degree of publicness conditional on the queried cohort size\nand the size of the sampled repertoires. Based on these observations we propose\na public/private sequence classifier, `PUBLIC' (Public Universal Binary\nLikelihood Inference Classifier), based on the generation probability, which\nperforms very well even for small cohort sizes.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.01056v1"
    },
    {
        "title": "Single nucleotide polymorphisms that modulate microRNA regulation of\n  gene expression in tumors",
        "authors": [
            "Gary Wilk",
            "Rosemary Braun"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Genome-wide association studies (GWAS) have identified single nucleotide\npolymorphisms (SNPs) associated with trait diversity and disease\nsusceptibility, yet the functional properties of many genetic variants and\ntheir molecular interactions remains unclear. It has been hypothesized that\nSNPs in microRNA binding sites may disrupt gene regulation by microRNAs\n(miRNAs), short non-coding RNAs that bind to mRNA and downregulate the target\ngene. While a number of studies have been conducted to predict the location of\nSNPs in miRNA binding sites, to date there has been no comprehensive analysis\nof how SNP variants may impact miRNA regulation of genes. Here we investigate\nthe functional properties of genetic variants and their effects on miRNA\nregulation of gene expression in cancer. Our analysis is motivated by the\nhypothesis that distinct alleles may cause differential binding (from miRNAs to\nmRNAs or from transcription factors to DNA) and change the expression of genes.\nWe previously identified pathways--systems of genes conferring specific cell\nfunctions--that are dysregulated by miRNAs in cancer, by comparing\nmiRNA-pathway associations between healthy and tumor tissue. We draw on these\nresults as a starting point to assess whether SNPs in genes on dysregulated\npathways are responsible for miRNA dysregulation of individual genes in tumors.\nUsing an integrative analysis that incorporates miRNA expression, mRNA\nexpression, and SNP genotype data, we identify SNPs that appear to influence\nthe association between miRNAs and genes, which we term \"regulatory QTLs\n(regQTLs)\": loci whose alleles impact the regulation of genes by miRNAs. We\ndescribe the method, apply it to analyze four cancer types (breast, liver,\nlung, prostate) using data from The Cancer Genome Atlas (TCGA), and provide a\ntool to explore the findings.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.03189v2"
    },
    {
        "title": "Minimum error correction-based haplotype assembly: considerations for\n  long read data",
        "authors": [
            "Sina Majidian",
            "Mohammad Hossein Kahaei",
            "Dick de Ridder"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The single nucleotide polymorphism (SNP) is the most widely studied type of\ngenetic variation. A haplotype is defined as the sequence of alleles at SNP\nsites on each haploid chromosome. Haplotype information is essential in\nunravelling the genome-phenotype association. Haplotype assembly is a\nwell-known approach for reconstructing haplotypes, exploiting reads generated\nby DNA sequencing devices. The Minimum Error Correction (MEC) metric is often\nused for reconstruction of haplotypes from reads. However, problems with the\nMEC metric have been reported. Here, we investigate the MEC approach to\ndemonstrate that it may result in incorrectly reconstructed haplotypes for\ndevices that produce error-prone long reads. Specifically, we evaluate this\napproach for devices developed by Illumina, Pacific BioSciences and Oxford\nNanopore Technologies. We show that imprecise haplotypes may be reconstructed\nwith a lower MEC than that of the exact haplotype. The performance of MEC is\nexplored for different coverage levels and error rates of data. Our simulation\nresults reveal that in order to avoid incorrect MEC-based haplotypes, a\ncoverage of 25 is needed for reads generated by Pacific BioSciences RS systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.05019v2"
    },
    {
        "title": "The bromodomain-containing protein Ibd1 links multiple chromatin related\n  protein complexes to highly expressed genes in Tetrahymena thermophila",
        "authors": [
            "Alejandro Saettone",
            "Jyoti Garg",
            "Jean-Philippe Lambert",
            "Syed Nabeel-Shah",
            "Marcelo Ponce",
            "Alyson Burtch",
            "Cristina Thuppu Mudalige",
            "Anne-Claude Gingras",
            "Ronald E. Pearlman",
            "Jeffrey Fillingham"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Background: The chromatin remodelers of the SWI/SNF family are critical\ntranscriptional regulators. Recognition of lysine acetylation through a\nbromodomain (BRD) component is key to SWI/SNF function; in most eukaryotes,\nthis function is attributed to SNF2/Brg1.\n  Results: Using affinity purification coupled to mass spectrometry (AP-MS) we\nidentified members of a SWI/SNF complex (SWI/SNFTt) in Tetrahymena thermophila.\nSWI/SNFTt is composed of 11 proteins, Snf5Tt, Swi1Tt, Swi3Tt, Snf12Tt, Brg1Tt,\ntwo proteins with potential chromatin interacting domains and four proteins\nwithout orthologs to SWI/SNF proteins in yeast or mammals. SWI/SNFTt subunits\nlocalize exclusively to the transcriptionally active macronucleus (MAC) during\ngrowth and development, consistent with a role in transcription. While\nTetrahymena Brg1 does not contain a BRD, our AP-MS results identified a\nBRD-containing SWI/SNFTt component, Ibd1 that associates with SWI/SNFTt during\ngrowth but not development. AP-MS analysis of epitope-tagged Ibd1 revealed it\nto be a subunit of several additional protein complexes, including putative\nSWRTt, and SAGATt complexes as well as a putative H3K4-specific histone methyl\ntransferase complex. Recombinant Ibd1 recognizes acetyl-lysine marks on\nhistones correlated with active transcription. Consistent with our AP-MS and\nhistone array data suggesting a role in regulation of gene expression, ChIP-Seq\nanalysis of Ibd1 indicated that it primarily binds near promoters and within\ngene bodies of highly expressed genes during growth.\n  Conclusions: Our results suggest that through recognizing specific histones\nmarks, Ibd1 targets active chromatin regions of highly expressed genes in\nTetrahymena where it subsequently might coordinate the recruitment of several\nchromatin remodeling complexes to regulate the transcriptional landscape of\nvegetatively growing Tetrahymena cells.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.08575v1"
    },
    {
        "title": "The exon junction complex undergoes a compositional switch that alters\n  mRNP structure and nonsense-mediated mRNA decay activity",
        "authors": [
            "Justin W. Mabin",
            "Lauren A. Woodward",
            "Robert Patton",
            "Zhongxia Yi",
            "Mengxuan Jia",
            "Vicki Wysocki",
            "Ralf Bundschuh",
            "Guramrit Singh"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The exon junction complex (EJC) deposited upstream of mRNA exon junctions\nshapes structure, composition and fate of spliced mRNA ribonucleoprotein\nparticles (mRNPs). To achieve this, the EJC core nucleates assembly of a\ndynamic shell of peripheral proteins that function in diverse\npost-transcriptional processes. To illuminate consequences of EJC composition\nchange, we purified EJCs from human cells via peripheral proteins RNPS1 and\nCASC3. We show that EJC originates as an SR-rich mega-dalton sized RNP that\ncontains RNPS1 but lacks CASC3. After mRNP export to the cytoplasm and before\ntranslation, the EJC undergoes a remarkable compositional and structural\nremodeling into an SR-devoid monomeric complex that contains CASC3.\nSurprisingly, RNPS1 is important for nonsense-mediated mRNA decay (NMD) in\ngeneral whereas CASC3 is needed for NMD of only select mRNAs. The promotion of\nswitch to CASC3-EJC slows down NMD. Overall, the EJC compositional switch\ndramatically alters mRNP structure and specifies two distinct phases of\nEJC-dependent NMD.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.00789v1"
    },
    {
        "title": "OLGA: fast computation of generation probabilities of B- and T-cell\n  receptor amino acid sequences and motifs",
        "authors": [
            "Zachary Sethna",
            "Yuval Elhanati",
            "Curtis G. Callan Jr.",
            "Aleksandra M. Walczak",
            "Thierry Mora"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Motivation: High-throughput sequencing of large immune repertoires has\nenabled the development of methods to predict the probability of generation by\nV(D)J recombination of T- and B-cell receptors of any specific nucleotide\nsequence. These generation probabilities are very non-homogeneous, ranging over\n20 orders of magnitude in real repertoires. Since the function of a receptor\nreally depends on its protein sequence, it is important to be able to predict\nthis probability of generation at the amino acid level. However, brute-force\nsummation over all the nucleotide sequences with the correct amino acid\ntranslation is computationally intractable. The purpose of this paper is to\npresent a solution to this problem.\n  Results: We use dynamic programming to construct an efficient and flexible\nalgorithm, called OLGA (Optimized Likelihood estimate of immunoGlobulin\nAmino-acid sequences), for calculating the probability of generating a given\nCDR3 amino acid sequence or motif, with or without V/J restriction, as a result\nof V(D)J recombination in B or T cells. We apply it to databases of\nepitope-specific T-cell receptors to evaluate the probability that a typical\nhuman subject will possess T cells responsive to specific disease-associated\nepitopes. The model prediction shows an excellent agreement with published\ndata. We suggest that OLGA may be a useful tool to guide vaccine design.\n  Availability: Source code is available at https://github.com/zsethna/OLGA\n",
        "pdf_link": "http://arxiv.org/pdf/1807.04425v2"
    },
    {
        "title": "Detecting T-cell receptors involved in immune responses from single\n  repertoire snapshots",
        "authors": [
            "Mikhail V Pogorelyy",
            "Anastasia A Minervina",
            "Mikhail Shugay",
            "Dmitriy M Chudakov",
            "Yuri B Lebedev",
            "Thierry Mora",
            "Aleksandra M Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Hypervariable T-cell receptors (TCR) play a key role in adaptive immunity,\nrecognising a vast diversity of pathogen-derived antigens. High throughput\nsequencing of TCR repertoires (RepSeq) produces huge datasets of T-cell\nreceptor sequences from blood and tissue samples. However, our ability to\nextract clinically relevant information from RepSeq data is limited, mainly\nbecause little is known about TCR-disease associations. Here we present a\nstatistical approach called ALICE (Antigen-specific Lymphocyte Identification\nby Clustering of Expanded sequences) that identifies TCR sequences that are\nactively involved in the current immune response from a single RepSeq sample,\nand apply it to repertoires of patients with a variety of disorders -\nautoimmune disease (ankylosing spondylitis), patients under cancer\nimmunotherapy, or subject to an acute infection (live yellow fever vaccine).\nThe method's robustness is demonstrated by the agreement of its predictions\nwith independent assays, and is supported by its ability to selectively detect\nresponding TCR in the memory but not in the naive subset. ALICE requires no\nlongitudinal data collection nor large cohorts, and is thus directly applicable\nto most RepSeq datasets. Its results facilitate the identification of TCR\nvariants associated with a wide variety of diseases and conditions, which can\nbe used for diagnostics, rational vaccine design and evaluation of the adaptive\nimmune system state.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.08833v1"
    },
    {
        "title": "pdbmine: A Node.js API for the RCSB Protein Data Bank (PDB)",
        "authors": [
            "Newlyn N. Joseph",
            "Raktim N. Roy",
            "Thomas A. Steitz"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Summary: The advent of Web-based tools that assist in the analysis and\nvisualization of macromolecules require application programming interfaces\n(APIs) designed for modern web frameworks. To this end, we have developed a\nNode.js module pdbmine that allows any user to generate faster data-request\nqueries to the RCSB Protein Data Bank (PDB). This JavaScript API acts as a\nlayer over the XML-based RCSB PDB RESTful API. The relatively simple nature of\nthe function calls within this module allows the user to easily implement and\nintegrate pdbmine into larger Node.js web applications.\n  Availability: This module can be installed via the Node Package Manager (NPM)\nat https://www.npmjs.com/package/pdbmine/, and is hosted on GitHub under the\nopen-source MIT license at https://github.com/nnj1/pdbmine/. Relevant\ndocumentation is detailed at https://nnj1.github.io/pdbmine/\n",
        "pdf_link": "http://arxiv.org/pdf/1904.03801v1"
    },
    {
        "title": "Statistical methods for the quantitative genetic analysis of\n  high-throughput phenotyping data",
        "authors": [
            "Gota Morota",
            "Diego Jarquin",
            "Malachy T. Campbell",
            "Hiroyoshi Iwata"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The advent of plant phenomics, coupled with the wealth of genotypic data\ngenerated by next-generation sequencing technologies, provides exciting new\nresources for investigations into and improvement of complex traits. However,\nthese new technologies also bring new challenges in quantitative genetics,\nnamely, a need for the development of robust frameworks that can accommodate\nthese high-dimensional data. In this chapter, we describe methods for the\nstatistical analysis of high-throughput phenotyping (HTP) data with the goal of\nenhancing the prediction accuracy of genomic selection (GS). Following the\nIntroduction in Section 1, Section 2 discusses field-based HTP, including the\nuse of unmanned aerial vehicles and light detection and ranging, as well as how\nwe can achieve increased genetic gain by utilizing image data derived from HTP.\nSection 3 considers extending commonly used GS models to integrate HTP data as\ncovariates associated with the principal trait response, such as yield.\nParticular focus is placed on single-trait, multi-trait, and genotype by\nenvironment interaction models. One unique aspect of HTP data is that phenomics\nplatforms often produce large-scale data with high spatial and temporal\nresolution for capturing dynamic growth, development, and stress responses.\nSection 4 discusses the utility of a random regression model for performing\nlongitudinal GS. The chapter concludes with a discussion of some standing\nissues.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12341v1"
    },
    {
        "title": "ReadsMap: a new tool for high precision mapping of DNAseq and RNAseq\n  read sequences",
        "authors": [
            "Igor Seledtsov",
            "Jaroslav Efremov",
            "Vladimir Molodtsov",
            "Victor Solovyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  There are currently plenty of programs available for mapping short sequences\n(reads) to a genome. Most of them, however, including such popular and actively\ndeveloped programs as Bowtie, BWA, TopHat and many others, are based on\nBurrows-Wheeler Transform (BWT) algorithm. This approach is very effective for\nmapping high-homology reads, but runs into problems when mapping reads with\nhigh level of errors or SNP. Also it has problems with mapping RNASeq spliced\nreads (such as reads that aligning with gaps corresponding intron sequences),\nthe kind that is essential for finding introns and alternative splicing gene\nisoforms. Meanwhile, finding intron positions is the most important task for\ndetermining the gene structure, and especially alternatively spliced variants\nof genes. In this paper, we propose a new algorithm that involves hashing\nreference genome. ReadsMap program, implementing such algorithm, demonstrate\nvery high-accuracy mapping of large number of short reads to one or more\ngenomic contigs. It is achieved mostly by better alignment of very short parts\nof reads separated by long introns with accounting information from mapping\nother reads containing the same intron inserted between bigger blocks.\nAvailability and implementation: ReadsMap is implemented in C. It is\nincorporated in Fgenesh++ gene identification pipeline and is freely available\nto academic users at Softberry web server www.softberry.com.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.01445v1"
    },
    {
        "title": "Transcriptomic Causal Networks identified patterns of differential gene\n  regulation in human brain from Schizophrenia cases versus controls",
        "authors": [
            "Akram Yazdani",
            "Raul Mendez-Giraldez",
            "Michael R Kosorok",
            "Panos Roussos"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Common and complex traits are the consequence of the interaction and\nregulation of multiple genes simultaneously, which work in a coordinated way.\nHowever, the vast majority of studies focus on the differential expression of\none individual gene at a time. Here, we aim to provide insight into the\nunderlying relationships of the genes expressed in the human brain in cases\nwith schizophrenia (SCZ) and controls. We introduced a novel approach to\nidentify differential gene regulatory patterns and identify a set of essential\ngenes in the brain tissue. Our method integrates genetic, transcriptomic, and\nHi-C data and generates a transcriptomic-causal network. Employing this\napproach for analysis of RNA-seq data from CommonMind Consortium, we identified\ndifferential regulatory patterns for SCZ cases and control groups to unveil the\nmechanisms that control the transcription of the genes in the human brain. Our\nanalysis identified modules with a high number of SCZ-associated genes as well\nas assessing the relationship of the hubs with their down-stream genes in both,\ncases and controls. In addition, the results identified essential genes for\nbrain function and suggested new genes putatively related to SCZ.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.07520v1"
    },
    {
        "title": "A multi-modal neural network for learning cis and trans regulation of\n  stress response in yeast",
        "authors": [
            "Boxiang Liu",
            "Nadine Hussami",
            "Avanti Shrikumar",
            "Tyler Shimko",
            "Salil Bhate",
            "Scott Longwell",
            "Stephen Montgomery",
            "Anshul Kundaje"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Deciphering gene regulatory networks is a central problem in computational\nbiology. Here, we explore the use of multi-modal neural networks to learn\npredictive models of gene expression that include cis and trans regulatory\ncomponents. We learn models of stress response in the budding yeast\nSaccharomyces cerevisiae. Our models achieve high performance and substantially\noutperform other state-of-the-art methods such as boosting algorithms that use\npre-defined cis-regulatory features. Our model learns several cis and trans\nregulators including well-known master stress response regulators. We use our\nmodels to perform in-silico TF knock-out experiments and demonstrate that\nin-silico predictions of target gene changes correlate with the results of the\ncorresponding TF knockout microarray experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.09426v1"
    },
    {
        "title": "Reading tea leaves? Polygenic scores and differences in traits among\n  groups",
        "authors": [
            "Graham Coop"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In the past decade, Genome-Wide Association Studies (GWAS) have delivered an\nincreasingly broad view of the genetic basis of human phenotypic variation. One\nof the major developments from GWAS is polygenic scores, a genetic predictor of\nan individual's genetic predisposition towards a trait constructed from GWAS.\nThe success of GWAS and polygenic scores seems to suggest that we will soon be\nable to settle debates about whether phenotypic differences among groups are\ndriven in part by genetics. However, answering these questions is more\ncomplicated than it seems at first glance and touches on many old issues about\nthe interpretation of human genetic variation. In this perspective piece, I\noutline the ways in which issues of causality, stratification,\ngene-by-environment interactions, and divergence among groups all complicate\nthe interpretation of among-population polygenic score differences.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.00892v1"
    },
    {
        "title": "Organizing genome engineering for the gigabase scale",
        "authors": [
            "Bryan A. Bartley",
            "Jacob Beal",
            "Jonathan R. Karr",
            "Elizabeth A. Strychalski"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Engineering the entire genome of an organism enables large-scale changes in\norganization, function, and external interactions, with significant\nimplications for industry, medicine, and the environment. Improvements to DNA\nsynthesis and organism engineering are already enabling substantial changes to\norganisms with megabase genomes, such as Escherichia coli and Saccharomyces\ncerevisiae. Simultaneously, recent advances in genome-scale modeling are\nincreasingly informing the design of metabolic networks. However, major\nchallenges remain for integrating these and other relevant technologies into\nworkflows that can scale to the engineering of gigabase genomes.\n  In particular, we find that a major under-recognized challenge is\ncoordinating the flow of models, designs, constructs, and measurements across\nthe large teams and complex technological systems that will likely be required\nfor gigabase genome engineering. We recommend that the community address these\nchallenges by 1) adopting and extending existing standards and technologies for\nrepresenting and exchanging information at the gigabase genomic scale, 2)\ndeveloping new technologies to address major open questions around data\ncuration and quality control, 3) conducting fundamental research on the\nintegration of modeling and design at the genomic scale, and 4) developing new\nlegal and contractual infrastructure to better enable collaboration across\nmultiple institutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01468v1"
    },
    {
        "title": "Autism spectrum disorder: a neuro-immunometabolic hypothesis of the\n  developmental origins",
        "authors": [
            "Martin G. Frasch",
            "Byung-Jun Yoon",
            "Dario-Lucas Helbing",
            "Gal Snir",
            "Marta C. Antonelli",
            "Reinhard Bauer"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Fetal neuroinflammation and prenatal stress (PS) may contribute to lifelong\nneurological disabilities. Astrocytes and microglia, among the brain's\nnon-neuronal glia cell populations, play a pivotal role in neurodevelopment,\npredisposition to and initiation of disease throughout lifespan. One of the\nmost common neurodevelopmental disorders manifesting between 1-4 years of age\nis autism spectrum disorder (ASD). A pathological glial-neuronal interplay is\nthought to increase the risk for clinical manifestation of ASD in at-risk\nchildren, but the mechanisms remain poorly understood and integrative,\nmulti-scale models are needed. We propose a model that integrates the data\nacross the scales of physiological organization, from genome to phenotype, and\nprovides a foundation to explain the disparate findings on the genomic level.\nWe hypothesize that via gene-environment interactions, fetal neuroinflammation\nand PS may reprogram glial immunometabolic phenotypes that impact\nneurodevelopment and neurobehavior. Drawing on genomic data from the recently\npublished series of ovine and rodent glial transcriptome analyses with fetuses\nexposed to neuroinflammation or PS, we conduct an analysis on the Simons\nFoundation Autism Research Initiative (SFARI) Gene database. We confirm 21 gene\nhits. Using unsupervised statistical network analysis, we then identify six\nclusters of probable protein-protein interactions mapping onto the\nimmunometabolic and stress response networks and epigenetic memory. These\nfindings support our hypothesis. We discuss the implications for ASD etiology,\nearly detection, and novel therapeutic approaches. We conclude with delineation\nof the next steps to verify our model on the individual gene level in an\nassumption-free manner.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.05198v3"
    },
    {
        "title": "Whole genome sequencing identifies putative associations between genomic\n  polymorphisms and clinical response to the antiepileptic drug levetiracetam",
        "authors": [
            "DV Vavoulis",
            "AT Pagnamenta",
            "SJL Knight",
            "MM Pentony",
            "M Armstrong",
            "EC Galizia",
            "S Balestrini",
            "SM Sisodiya",
            "JC Taylor"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In the context of pharmacogenomics, whole genome sequencing provides a\npowerful approach for identifying correlations between response variability to\nspecific drugs and genomic polymorphisms in a population, in an unbiased\nmanner. In this study, we employed whole genome sequencing of DNA samples from\npatients showing extreme response (n=72) and non-response (n=27) to the\nantiepileptic drug levetiracetam, in order to identify genomic variants that\nunderlie response to the drug. Although no common SNP (MAF>5%) crossed the\nconventional genome-wide significance threshold of 5e-8, we found common\npolymorphisms in genes SPNS3, HDC, MDGA2, NSG1 and RASGEF1C, which collectively\npredict clinical response to levetiracetam in our cohort with ~91% predictive\naccuracy. Among these genes, HDC, NSG1, MDGA2 and RASGEF1C are potentially\nimplicated in synaptic neurotransmission, while SPNS3 is an atypical solute\ncarrier transporter homologous to SV2A, the known molecular target of\nlevetiracetam. Furthermore, we performed gene- and pathway-based statistical\nanalysis on sets of rare and low-frequency variants (MAF<5%) and we identified\nassociations between the following genes or pathways and response to\nlevetiracetam: a) genes PRKCB and DLG2, which are involved in glutamatergic\nneurotransmission, a known target of anticonvulsants, including levetiracetam;\nb) genes FILIP1 and SEMA6D, which are involved in axon guidance and modelling\nof neural connections; and c) pathways with a role in synaptic\nneurotransmission, such as WNT5A-dependent internalization of FZD4 and\ndisinhibition of SNARE formation. In summary, our approach to utilise whole\ngenome sequencing on subjects with extreme response phenotypes is a feasible\nroute to generate plausible hypotheses for investigating the genetic factors\nunderlying drug response variability in cases of pharmaco-resistant epilepsy.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.10580v1"
    },
    {
        "title": "Generalized Method of Moments Estimation for Stochastic Models of DNA\n  Methylation Patterns",
        "authors": [
            "Alexander Lück",
            "Verena Wolf"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  With recent advances in sequencing technologies, large amounts of epigenomic\ndata have become available and computational methods are contributing\nsignificantly to the progress of epigenetic research. As an orthogonal approach\nto methods based on machine learning, mechanistic modeling aims at a\ndescription of the mechanisms underlying epigenetic changes. Here, we propose\nan efficient method for parameter estimation for stochastic models that\ndescribe the dynamics of DNA methylation patterns over time. Our method is\nbased on the Generalized Method of Moments (GMM) and gives results with an\naccuracy similar to that of maximum likelihood-based estimation approaches.\nHowever, in contrast to the latter, the GMM still allows an efficient and\naccurate calibration of parameters even if the complexity of the model is\nincreased by considering longer methylation patterns. We show the usefulness of\nour method by applying it to hairpin bisulfite sequencing data from mouse ESCs\nfor varying pattern lengths.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01174v1"
    },
    {
        "title": "Turning genome-wide association study findings into opportunities for\n  drug repositioning",
        "authors": [
            "Alexandria Lau",
            "Hon-Cheong So"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Drug development is a very costly and lengthy process, while repositioned or\nrepurposed drugs could be brought into clinical practice within a shorter\ntime-frame and at a much reduced cost. The past decade has observed a massive\ngrowth in the amount of data from genome-wide association studies (GWAS). The\nrich information contained in GWAS data has great potential to guide drug\ndiscovery or repositioning. Here we provide an overview of different\ncomputational approaches which employ GWAS data to guide drug repositioning.\nThese methods include selection of top candidate genes from GWAS as drug\ntargets, deducing drug candidates based on drug-drug and disease-disease\nsimilarity, searching for reversed expression profiles between drugs and\ndiseases, pathway-based methods as well as repositioning based on analysis of\nbiological networks. Each method is illustrated with examples, and their\nrespective strengths and limitations are discussed. Finally we discussed\nseveral areas for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05477v1"
    },
    {
        "title": "Identification of key genes related to the mechanism and prognosis of\n  lung squamous cell carcinoma using bioinformatics analysis",
        "authors": [
            "Miaomiao Gao",
            "Weikaixin Kong",
            "Zhuo Huang",
            "Zhengwei Xie"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Objectives Lung squamous cell carcinoma (LUSC) often diagnosed as advanced\nwith poor prognosis. The mechanisms of its pathogenesis and prognosis require\nurgent elucidation. This study was performed to screen potential biomarkers\nrelated to the occurrence, development and prognosis of LUSC to reveal unknown\nphysiological and pathological processes. Materials and Methods Using\nbioinformatics analysis, the lung squamous cell carcinoma microarray datasets\nfrom the GEO and TCGA databases were analyzed to identify differentially\nexpressed genes(DEGs). Furthermore, PPI and WGCNA network analysis were\nintegrated to identify the key genes closely related to the process of LUSC\ndevelopment. In addition, survival analysis was performed to achieve a\nprognostic model that accomplished a high level of prediction accuracy. Results\nand Conclusion Eighty-five up-regulated and 39 down-regulated genes were\nidentified, on which functional and pathway enrichment analysis was conducted.\nGO analysis demonstrated that up-regulated genes were principally enriched in\nepidermal development and DNA unwinding in DNA replication. Down-regulated\ngenes were mainly involved in cell adhesion, signal transduction and positive\nregulation of inflammatory response. After PPI and WGCNA network analysis,\neight genes, including AURKA, RAD51, TTK, AURKB, CCNA2, TPX2, KPNA2 and KIF23,\nhave been found to play a vital role in LUSC development. The prognostic model\ncontained 20 genes, 18 of which were detrimental to prognosis. The AUC of the\nestablished prognostic model for predicting the survival of patients at 1, 3,\nand 5 years was 0.828, 0.826 and 0.824, respectively. To conclude, this study\nidentified a number of biomarkers of significant interest for additional\ninvestigation of the therapies and methods of prognosis of lung squamous cell\ncarcinoma.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05621v1"
    },
    {
        "title": "Indoor microbiome, environmental characteristics and asthma among junior\n  high school students in Johor Bahru, Malaysia",
        "authors": [
            "Xi Fu",
            "Dan Norback",
            "Qianqian Yuan",
            "Yanling Li",
            "Xunhua Zhu",
            "Yiqun Deng",
            "Jamal Hisham Hashim",
            "Zailina Hashim",
            "Yi-Wu Zheng",
            "Xu-Xin Lai",
            "Michael Dho Spangfort",
            "Yu Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Indoor microbial diversity and composition are suggested to affect the\nprevalence and severity of asthma. In this study, we collected floor dust and\nenvironmental characteristics from 21 classrooms, and health data related to\nasthma symptoms from 309 students, in junior high schools in Johor Bahru,\nMalaysia. Bacterial and fungal composition was characterized by sequencing 16s\nrRNA gene and internal transcribed spacer (ITS) region, and the absolute\nmicrobial concentration was quantified by qPCR. In total, 326 bacterial and 255\nfungal genera were characterized. Five bacterial (Sphingobium, Rhodomicrobium,\nShimwellia, Solirubrobacter, Pleurocapsa) and two fungal (Torulaspora and\nLeptosphaeriaceae) taxa were protective for asthma severity. Two bacterial\ntaxa, Izhakiella and Robinsoniella, were positively associated with asthma\nseverity. Several protective bacterial taxa including Rhodomicrobium,\nShimwellia and Sphingobium has been reported as protective microbes in previous\nstudies, whereas other taxa were first time reported. Environmental\ncharacteristics, such as age of building, size of textile curtain per room\nvolume, occurrence of cockroaches, concentration of house dust mite allergens\ntransferred from homes by the occupants, were involved in shaping the overall\nmicrobial community but not asthma-associated taxa; whereas visible dampness\nand mold, which did not change the overall microbial community for floor dust,\ndecreased the concentration of protective bacteria Rhodomicrobium\n(\\b{eta}=-2.86, p=0.021) of asthma, indicating complex interactions between\nmicrobes, environmental characteristics and asthma symptoms. Overall, this is\nthe first indoor microbiome study to characterize the asthma-associated\nmicrobes and their environmental determinant in tropical area, promoting the\nunderstanding of microbial exposure and respiratory health in this region.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.06946v1"
    },
    {
        "title": "A genomic dominion with regulatory dependencies on human-specific\n  single-nucleotide changes in Modern Humans",
        "authors": [
            "Gennadi V. Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Gene set enrichment analyses of 8,405 genes linked with 35,074 human-specific\n(hs) regulatory single-nucleotide changes (SNCs) revealed the staggering\nbreadth of significant associations with morphological structures,\nphysiological processes, and pathological conditions of Modern Humans.\nSignificant enrichment traits include more than 1,000 anatomically-distinct\nregions of the adult human brain, many different types of human cells and\ntissues, more than 200 common human disorders and more than 1,000 records of\nrare diseases. Thousands of genes connected with regulatory hsSNCs have been\nidentified in this contribution, which represent essential genetic elements of\nthe autosomal inheritance and survival of species phenotypes: a total of 1,494\ngenes linked with either autosomal dominant or recessive inheritance as well as\n2,273 genes associated with premature death, embryonic lethality, as well as\npre-, peri-, neo-, and post-natal lethality of both complete and incomplete\npenetrance. Therefore, thousands of heritable traits and critical genes\nimpacting the offspring survival appear under the human-specific regulatory\ncontrol in genomes of Modern Humans. These observations highlight the\nremarkable translational opportunities afforded by the discovery of genetic\nregulatory loci harboring hsSNCs that are fixed in humans, distinct from other\nprimates, and located in differentially-accessible (DA) chromatin regions\nduring human brain development.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.08646v1"
    },
    {
        "title": "DomainScope: A disease network based on protein domain connections",
        "authors": [
            "Alin Voskanian-Kordi",
            "Ashley Funai",
            "Maricel G. Kann"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Protein domains are highly conserved functional units of proteins. Because\nthey carry functionally significant information, the majority of the coding\ndisease variants are located on domains. Additionally, domains are specific\nunits of the proteins that can be targeted for drug delivery purposes. Here,\nusing information about variants sites associated with diseases, a disease\nnetwork was built, based on their sharing the same domain and domain variation\nsite. The result was 49,990 disease pairs linked by domain variant site and\n533,687 disease pairs that share the same mutated domain. These pairs were\ncompared to disease pairs made using previous methods such as gene identity and\ngene variant site identity, which revealed that over 8,000 of these pairs were\nnot only missing from the gene pairings but also not found commonly together in\nliterature. The disease network was analyzed from their disease subject\ncategories, which when compared to the gene-based disease network revealed that\nthe domain method results in higher number of connections across disease\ncategories versus within a disease category. Further, a study into the drug\nrepurposing possibilities of the disease network created using domain revealed\nthat 16,902 of the disease pairs had a drug reported for one disease but not\nthe other, highlighting the drug repurposing potential of this new methodology.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.08676v1"
    },
    {
        "title": "Can artificial neural networks supplant the polygene risk score for risk\n  prediction of complex disorders given very large sample sizes?",
        "authors": [
            "Carlos Pinto",
            "Michael Gill",
            "Schizophrenia Working Group of the Psychiatric Genomics Consortium",
            "Elizabeth A. Heron"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Genome-wide association studies (GWAS) provide a means of examining the\ncommon genetic variation underlying a range of traits and disorders. In\naddition, it is hoped that GWAS may provide a means of differentiating affected\nfrom unaffected individuals. This has potential applications in the area of\nrisk prediction. Current attempts to address this problem focus on using the\npolygene risk score (PRS) to predict case-control status on the basis of GWAS\ndata. However this approach has so far had limited success for complex traits\nsuch as schizophrenia (SZ). This is essentially a classification problem.\nArtificial neural networks (ANNs) have been shown in recent years to be highly\neffective in such applications. Here we apply an ANN to the problem of\ndistinguishing SZ patients from unaffected controls. We compare the\neffectiveness of the ANN with the PRS in classifying individuals by\ncase-control status based only on genetic data from a GWAS. We use the\nschizophrenia dataset from the Psychiatric Genomics Consortium (PGC) for this\nstudy. Our analysis indicates that the ANN is more sensitive to sample size\nthan the PRS. As larger and larger sample sizes become available, we suggest\nthat ANNs are a promising alternative to the PRS for classification and risk\nprediction for complex genetic disorders.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.08996v1"
    },
    {
        "title": "Dinucleotide repeats in coronavirus SARS-CoV-2 genome: evolutionary\n  implications",
        "authors": [
            "Changchuan Yin"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The ongoing global pandemic of infection disease COVID-19 caused by the 2019\nnovel coronavirus (SARS-COV-2, formerly 2019-nCoV) presents critical threats to\npublic health and the economy since it was identified in China, December 2019.\nThe genome of SARS-CoV-2 had been sequenced and structurally annotated, yet\nlittle is known of the intrinsic organization and evolution of the genome. To\nthis end, we present a mathematical method for the genomic spectrum, a kind of\nbarcode, of SARS-CoV-2 and common human coronaviruses. The genomic spectrum is\nconstructed according to the periodic distributions of nucleotides, and\ntherefore reflects the unique characteristics of the genome. The results\ndemonstrate that coronavirus SARS-CoV-2 exhibits dinucleotide TT islands in the\nnon-structural proteins 3, 4, 5, and 6. Further analysis of the dinucleotide\nregions suggests that the dinucleotide repeats are increased during evolution\nand may confer the evolutionary fitness of the virus. The special dinucleotide\nregions in the SARS-CoV-2 genome identified in this study may become diagnostic\nand pharmaceutical targets in monitoring and curing the COVID-19 disease.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.00280v1"
    },
    {
        "title": "EDGE COVID-19: A Web Platform to generate submission-ready genomes for\n  SARS-CoV-2 sequencing efforts",
        "authors": [
            "Chien-Chi Lo",
            "Migun Shakya",
            "Karen Davenport",
            "Mark Flynn",
            "Adán Myers y Gutiérrez",
            "Bin Hu",
            "Po-E Li",
            "Elais Player Jackson",
            "Yan Xu",
            "Patrick S. G. Chain"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genomics has become an essential technology for surveilling emerging\ninfectious disease outbreaks. A wide range of technologies and strategies for\npathogen genome enrichment and sequencing are being used by laboratories\nworldwide, together with different, and sometimes ad hoc, analytical procedures\nfor generating genome sequences. As a result, public repositories now contain\nnon-standard entries of varying quality. A standardized analytical process for\nconsensus genome sequence determination, particularly for outbreaks such as the\nongoing COVID-19 pandemic, is critical to provide a solid genomic basis for\nepidemiological analyses and well-informed decision making. To address this\nneed, we have developed a bioinformatic workflow to standardize the analysis of\nSARS-CoV-2 sequencing data generated with either the Illumina or Oxford\nNanopore platforms. Using an intuitive web-based interface, this workflow\nautomates SARS-CoV-2 reference-based genome assembly, variant calling, lineage\ndetermination, and provides the ability to submit the consensus sequence and\nnecessary metadata to GenBank or GISAID. Given a raw Illumina or Oxford\nNanopore FASTQ read file, this web-based platform enables non-bioinformatics\nexperts to automatically produce a SARS-CoV-2 genome that is ready for\nsubmission to GISAID or GenBank.\n  Availability:https://edge-covid19.edgebioinformatics.org;https://github.com/LANL-Bioinformatics/EDGE/tree/SARS-CoV2\n",
        "pdf_link": "http://arxiv.org/pdf/2006.08058v4"
    },
    {
        "title": "An Immune-related lncRNAs Model for Prognostic of SKCM Patients Base on\n  Cox Regression and Coexpression Analysis",
        "authors": [
            "Wenjie Jiang",
            "Chang Lu",
            "Jing Qu",
            "Xiaoyu Mei"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  SKCM is the most dangerous one of skin cancer, its high degree of malignant,\nis the leading cause of skin cancer. And the level of radiation treatment and\nchemical treatment is minimal, so the mortality is high. Because of its complex\nmolecular and cellular heterogeneity, the existing prediction model of skin\ncancer risk is not ideal. In this study, we developed an immune-related lncRNAs\nmodel to predict the prognosis of patients with SKCM. Screening for\nSKCM-related differential expression of lncRNA from TCGA. Identified\nimmune-related lncRNAs and lncRNA-related mRNA based on the co-expression\nmethod. Through univariate and multivariate analysis, an immune-related lncRNA\nmodel is established to analyze the prognosis of SKCM patients. A 4-lncRNA skin\ncancer prediction model was constructed, including MIR155HG, AL137003.2,\nAC011374.2, and AC009495.2. According to the model, SKCM samples were divided\ninto a high-risk group and low-risk group, and predict the survival of the two\ngroups in 30 years. The area under the ROC curve is 0.749, which shows that the\nmodel has excellent performance. We constructed a 4-lncRNA model to predict the\nprognosis of patients with SKCM, indicating that these lncRNAs may play a\nunique role in the carcinogenesis of SKCM.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.09856v1"
    },
    {
        "title": "Immune Fingerprinting through Repertoire Similarity",
        "authors": [
            "Thomas Dupic",
            "Meriem Bensouda Koraichi",
            "Anastasia Minervina",
            "Mikhail Pogorelyy",
            "Thierry Mora",
            "Aleksandra M. Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Immune repertoires provide a unique fingerprint reflecting the immune history\nof individuals, with potential applications in precision medicine. However, the\nquestion of how personal that information is and how it can be used to identify\nindividuals has not been explored. Here, we show that individuals can be\nuniquely identified from repertoires of just a few thousands lymphocytes. We\npresent \"Immprint,\" a classifier using an information-theoretic measure of\nrepertoire similarity to distinguish pairs of repertoire samples coming from\nthe same versus different individuals. Using published T-cell receptor\nrepertoires and statistical modeling, we tested its ability to identify\nindividuals with great accuracy, including identical twins, by computing false\npositive and false negative rates $< 10^{-6}$ from samples composed of 10,000\nT-cells. We verified through longitudinal datasets and simulations that the\nmethod is robust to acute infections and the passage of time. These results\nemphasize the private and personal nature of repertoire data.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13530v2"
    },
    {
        "title": "Using micro- and macro-level network metrics unveils top communicative\n  gene modules in psoriasis",
        "authors": [
            "Reyhaneh Naderi",
            "Homa Saadati Mollaei",
            "Arne Elofsson",
            "Saman Hosseini Ashtiani"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Background: Psoriasis is a multifactorial chronic inflammatory disorder of\nthe skin with significant morbidity, characterized by hyper proliferation of\nthe epidermis. Even though psoriasis etiology is not fully understood, it is\nbelieved to be multifactorial with numerous key components. Methods: In order\nto cast light on the complex molecular interactions in psoriasis vulgaris at\nboth protein-protein interactions and transcriptomics levels, we analyzed a set\nof microarray gene expression analysis consisting of 170 paired lesional and\nnon-lesional samples. Afterwards, a network analysis was conducted on\nprotein-protein interaction network of differentially expressed genes based on\nmicro- and macro-level network metrics at a systemic level standpoint. Results:\nWe found 17 top communicative genes, all of which experimentally proven to be\npivotal in psoriasis were identified in two modules, namely, cell cycle and\nimmune system. Intra- and inter-gene interaction subnetworks from the top\ncommunicative genes might provide further insight into the corresponding\ncharacteristic mechanisms. Conclusions: Potential gene combinations for\ntherapeutic/diagnostics purposes were identified. Moreover, our proposed\npipeline could be of interest to a broader range of biological network analysis\nstudies.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.15414v1"
    },
    {
        "title": "The bat coronavirus RmYN02 is characterized by a 6-nucleotide deletion\n  at the S1/S2 junction, and its claimed PAA insertion is highly doubtful",
        "authors": [
            "Yuri Deigin",
            "Rossana Segreto"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Zhou et al. reported the discovery of RmYN02, a strain closely related to\nSARS-CoV-2, which is claimed to contain a natural PAA amino acid insertion at\nthe S1/S2 junction of the spike protein at the same position of the PRRA\ninsertion that has created a polybasic furin cleavage site in SARS-CoV-2. The\nauthors support with their findings the theory that the furin cleavage site\ninsertion present in SARS-CoV-2 is natural. Because no nucleotide alignment\nwith closely related strains of the region coding for the supposed insertion is\nprovided by Zhou et al., we have applied several alignment algorithms to search\nfor the most parsimonious alignments. We conclude that RmYN02 does not contain\nan insertion at the S1/S2 junction when compared to its closest relatives at\nthe nucleotide level, but rather a 6-nucleotide deletion and that the claimed\nPAA insertion is more likely to be the result of mutations. A close examination\nof RmYN02 sequencing records and assembly methods is wishful. In conclusion,\nSARS-CoV-2, with its 12-nucleotide insertion at the S1/S2 junction remains\nunique among its sarbecovirus relatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.00627v1"
    },
    {
        "title": "Towards a robust out-of-the-box neural network model for genomic data",
        "authors": [
            "Zhaoyi Zhang",
            "Songyang Cheng",
            "Claudia Solis-Lemus"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The accurate prediction of biological features from genomic data is paramount\nfor precision medicine and sustainable agriculture. For decades, neural network\nmodels have been widely popular in fields like computer vision, astrophysics\nand targeted marketing given their prediction accuracy and their robust\nperformance under big data settings. Yet neural network models have not made a\nsuccessful transition into the medical and biological world due to the\nubiquitous characteristics of biological data such as modest sample sizes,\nsparsity, and extreme heterogeneity. Here, we investigate the robustness,\ngeneralization potential and prediction accuracy of widely used convolutional\nneural network and natural language processing models with a variety of\nheterogeneous genomic datasets. Mainly, recurrent neural network models\noutperform convolutional neural network models in terms of prediction accuracy,\noverfitting and transferability across the datasets under study. While the\nperspective of a robust out-of-the-box neural network model is out of reach, we\nidentify certain model characteristics that translate well across datasets and\ncould serve as a baseline model for translational researchers.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.05995v4"
    },
    {
        "title": "Twelve years of SAMtools and BCFtools",
        "authors": [
            "Petr Danecek",
            "James K. Bonfield",
            "Jennifer Liddle",
            "John Marshall",
            "Valeriu Ohan",
            "Martin O Pollard",
            "Andrew Whitwham",
            "Thomas Keane",
            "Shane A. McCarthy",
            "Robert M. Davies",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Background\n  SAMtools and BCFtools are widely used programs for processing and analysing\nhigh-throughput sequencing data.\n  Findings\n  The first version appeared online twelve years ago and has been maintained\nand further developed ever since, with many new features and improvements added\nover the years. The SAMtools and BCFtools packages represent a unique\ncollection of tools that have been used in numerous other software projects and\ncountless genomic pipelines.\n  Conclusion\n  Both SAMtools and BCFtools are freely available on GitHub under the\npermissive MIT licence, free for both non-commercial and commercial use. Both\npackages have been installed over a million times via Bioconda. The source code\nand documentation are available from http://www.htslib.org.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10295v2"
    },
    {
        "title": "EPIHC: Improving Enhancer-Promoter Interaction Prediction by using\n  Hybrid features and Communicative learning",
        "authors": [
            "Shuai Liu",
            "Xinran Xu",
            "Zhihao Yang",
            "Xiaohan Zhao",
            "Wen Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Enhancer-promoter interactions (EPIs) regulate the expression of specific\ngenes in cells, and EPIs are important for understanding gene regulation, cell\ndifferentiation and disease mechanisms. EPI identification through the wet\nexperiments is costly and time-consuming, and computational methods are in\ndemand. In this paper, we propose a deep neural network-based method EPIHC\nbased on sequence-derived features and genomic features for the EPI prediction.\nEPIHC extracts features from enhancer and promoter sequences respectively using\nconvolutional neural networks (CNN), and then design a communicative learning\nmodule to captures the communicative information between enhancer and promoter\nsequences. EPIHC also take the genomic features of enhancers and promoters into\naccount. At last, EPIHC combines sequence-derived features and genomic features\nto predict EPIs. The computational experiments show that EPIHC outperforms the\nexisting state-of-the-art EPI prediction methods on the benchmark datasets and\nchromosome-split datasets, and the study reveal that the communicative learning\nmodule can bring explicit information about EPIs, which is ignore by CNN.\nMoreover, we consider two strategies to improve performances of EPIHC in the\ncross-cell line prediction, and experimental results show that EPIHC\nconstructed on training cell lines exhibit improved performances for the other\ncell lines.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.15418v1"
    },
    {
        "title": "Interactive SARS-CoV-2 mutation timemaps",
        "authors": [
            "Rene L. Warren",
            "Inanc Birol"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  As the year 2020 draws to an end, several new strains have been reported for\nthe SARS-CoV-2 coronavirus, the agent responsible for the COVID-19 pandemic\nthat has afflicted us all this past year. However, it is difficult to\ncomprehend the scale, in sequence space, geographical location and time, at\nwhich SARS-CoV-2 mutates and evolves in its human hosts. To get an appreciation\nfor the rapid evolution of the coronavirus, we built interactive scalable\nvector graphics maps that show daily nucleotide variations in genomes from the\nsix most populated continents compared to that of the initial, ground-zero\nSARS-CoV-2 isolate sequenced at the beginning of the year. Availability:\nMutation time maps are available from https://bcgsc.github.io/SARS2/\n",
        "pdf_link": "http://arxiv.org/pdf/2012.15697v1"
    },
    {
        "title": "NoisET: Noise learning and Expansion detection of T-cell receptors",
        "authors": [
            "Meriem Bensouda Koraichi",
            "Maximilian Puelma Touzel",
            "Andrea Mazzolini",
            "Thierry Mora",
            "Aleksandra M. Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  High-throughput sequencing of T- and B-cell receptors makes it possible to\ntrack immune repertoires across time, in different tissues, in acute and\nchronic diseases and in healthy individuals. However quantitative comparison\nbetween repertoires is confounded by variability in the read count of each\nreceptor clonotype due to sampling, library preparation, and expression noise.\nWe review methods for accounting for both biological and experimental noise and\npresent an easy-to-use python package NoisET that implements and generalizes a\npreviously developed Bayesian method. It can be used to learn experimental\nnoise models for repertoire sequencing from replicates, and to detect\nresponding clones following a stimulus. We test the package on different\nrepertoire sequencing technologies and datasets. We review how such approaches\nhave been used to identify responding clonotypes in vaccination and disease\ndata. Availability: NoisET is freely available to use with source code at\ngithub.com/statbiophys/NoisET.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03568v2"
    },
    {
        "title": "Performance Evaluation of Transcriptomics Data Normalization for\n  Survival Risk Prediction",
        "authors": [
            "Ai Ni",
            "Li-Xuan Qin"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  One pivotal feature of transcriptomics data is the unwanted variations caused\nby disparate experimental handling, known as handling effects. Various data\nnormalization methods were developed to alleviate the adverse impact of\nhandling effects in the setting of differential expression analysis. However,\nlittle research has been done to evaluate their performance in the setting of\nsurvival outcome prediction, an important analysis goal for transcriptomics\ndata in biomedical research. Leveraging a unique pair of datasets for the same\nset of tumor samples-one with handling effects and the other without, we\ndeveloped a benchmarking tool for conducting such an evaluation in microRNA\nmicroarrays. We applied this tool to evaluate the performance of three popular\nnormalization methods-quantile normalization, median normalization, and\nvariance stabilizing normalization-in survival prediction using various\napproaches for model building and designs for sample assignment. We showed that\nhandling effects can have a strong impact on survival prediction, and that\nquantile normalization, a most popular method in current practice, tends to\nunderperform median normalization and variance stabilizing normalization. We\ndemonstrated with a small example the reason for quantile normalization's poor\nperformance in this setting. Our finding highlights the importance of putting\nnormalization evaluation in the context of the downstream analysis setting and\nthe potential of improving the development of survival predictors by applying\nmedian normalization. We make available our benchmarking tool for performing\nsuch evaluation on additional normalization methods in connection with\nprediction modeling approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04001v1"
    },
    {
        "title": "Modern tools for annotation of small genomes of non-model eukaryotes",
        "authors": [
            "Marina Galchenkova",
            "Aleksei Korzhenkov"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Nowadays, due to the increasing amount of experimental data obtained by\nsequencing, the most interest is focused on determining the functions and\ncharacteristics of its individual parts of the genome instead of determining\nthe nucleotide sequence of the genome. The genome annotation includes the\nidentification of coding and non-coding sequences, determining the structure of\nthe gene and determining the functions of these sequences. Despite the\nsignificant achievements in computational technologies working with sequencing\ndata, there is no general approach to the functional annotation of the genome\nin the reason of the large number of unresolved molecular determination of the\nfunction of some genomes parts. Nevertheless, the scientific community is\ntrying to solve this problem. This review analyzed existing approaches to\neukaryotic genome annotation. This work includes 3 main parts: introduction,\nmain body and discussion. The introduction reflects the development of\nindependent tools and automatic pipelines for annotation of eukaryotic genomes,\nwhich are associated with existing achievements in annotating prokaryotic ones.\nThe main body consists of two distinguished parts, the first one is devoted to\ninstructions for annotating genomes of non-model eukaryotes, and the second\nblock is about recent versions of automatic pipelines that require minimal\nuser's curation. The question of assessing the quality and completeness of the\nannotated genome is noted briefly, and the tools to conduct this analysis are\ndiscussed. Currently, there is no universal automatic software for eukaryotic\ngenome annotation, covering the whole list of tasks, without manual curation or\nusing additional external tools and resources. Thus it leads to the task of\ndeveloping a wider functional and universal protocol for automatic annotation\nof small eukaryotic genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04058v1"
    },
    {
        "title": "Polygenic Risk Score in Africa Population: Progress and challenges",
        "authors": [
            "Yagoub Adam",
            "Suraju Sadeeq",
            "Judit Kumuthini",
            "Olabode Ajayi",
            "Gordon Wells",
            "Rotimi Solomon",
            "Olubanke Ogunlana",
            "Emmmanuel Adetiba",
            "Emeka Iweala",
            "Benedikt Brors",
            "Ezekiel Adebiyi"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Polygenic risk score (PRS) analysis is a powerful method been used to\nestimate an individual's genetic risk towards targeted traits. PRS analysis\ncould be used to obtain evidence of a genetic effect beyond Genome-Wide\nAssociation Studies (GWAS) results i.e. when there are no significant markers.\nPRS analysis has been widely applied to investigate the genetic basis of\nseveral traits including rare diseases. However, the accuracy of PRS analysis\ndepends on the genomic data of the underlying population. For instance, several\nstudies showed that obtaining higher prediction power of PRS analysis is\nchallenging for non-Europeans. In this manuscript, we reviewed the conventional\nPRS methods and their application to sub-saharan Africa communities. We\nconcluded that the limiting factor of applying PRS analysis to sub-saharan\npopulations is the lack of sufficient GWAS data. Also, we recommended\ndeveloping African-specific PRS tools\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08468v1"
    },
    {
        "title": "LRez: C++ API and toolkit for analyzing and managing Linked-Reads data",
        "authors": [
            "Pierre Morisse",
            "Claire Lemaitre",
            "Fabrice Legeai"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Linked-Reads technologies, such as 10x Genomics, combine both the\nhigh-quality and low cost of short-reads sequencing and a long-range\ninformation, through the use of barcodes able to tag reads which originate from\na common long DNA fragment. This technology has been employed in a broad range\nof applications including assembly or phasing of genomes, and structural\nvariant calling. However, to date, no tool or API dedicated to the manipulation\nof Linked-Reads data exist. We introduce LRez, a C++ API and toolkit which\nallows easy management of Linked-Reads data. LRez includes various\nfunctionalities, for computing number of common barcodes between genomic\nregions, extracting barcodes from BAM files, as well as indexing and querying\nboth BAM and FASTQ files to quickly fetch reads or alignments sharing one or\nmultiple barcodes. LRez can thus be used in a broad range of applications\nrequiring barcode processing, in order to improve their performances. LRez is\nimplemented in C++, supported on Linux platforms, and available under AGPL-3.0\nLicense at https://github.com/morispi/LRez.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.14419v2"
    },
    {
        "title": "COSINE: A Web Server for Clonal and Subclonal Structure Inference and\n  Evolution in Cancer Genomics",
        "authors": [
            "Xiguo Yuan",
            "Yuan Zhao",
            "Yang Guo",
            "Linmei Ge",
            "Wei Liu",
            "Shiyu Wen",
            "Qi Li",
            "Zhangbo Wan",
            "Peina Zheng",
            "Tao Guo",
            "Zhida Li",
            "Martin Peifer",
            "Yupeng Cun"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Cancers evolve from mutation of a single cell with sequential clonal and\nsubclonal expansion of somatic mutation acquisition. Inferring clonal and\nsubclonal structures from bulk or single cell tumor genomic sequencing data has\na huge impact on cancer evolution studies. Clonal state and mutational order\ncan provide detailed insight into tumor origin and its future development. In\nthe past decade, a variety of methods have been developed for subclonal\nreconstruction using bulk tumor sequencing data. As these methods have been\ndeveloped in different programming languages and using different input data\nformats, their use and comparison can be problematic. Therefore, we established\na web server for clonal and subclonal structure inference and evolution of\ncancer genomic data (COSINE), which included 12 popular subclonal\nreconstruction methods. We decomposed each method via a detailed workflow of\nsingle processing steps with a user-friendly interface. To the best of our\nknowledge, this is the first web server providing online subclonal inference,\nincluding the most popular subclonal reconstruction methods. COSINE is freely\naccessible at www.clab-cosine.net or http://bio.rj.run:48996/cun-web.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.15142v1"
    },
    {
        "title": "grenepipe: A flexible, scalable, and reproducible pipeline to automate\n  variant and frequency calling from sequence reads",
        "authors": [
            "Lucas Czech",
            "Moises Exposito-Alonso"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Processing high-throughput DNA sequencing data of individuals or populations\nrequires stringing together independent software tools with many parameters,\noften leading to non-reproducible pipelines and datasets. We developed\ngrenepipe to streamline this data processing, an all-in-one Snakemake workflow\nfrom raw sequencing data to the end product of a table of individuals'\ngenotypes or population frequencies. Our pipeline allows users to select among\na range of popular software tools within a single configuration file,\nautomatically downloads and installs software and dependencies, and runs with\ntwo command calls: to prepare and to run. It is highly optimized for\nscalability in cluster environments and parallel computing, splitting data\ntasks into manageable genomic sections and automatically consolidating the\noutputs. grenepipe is published under the GPL-3 license, and freely available\nat https://github.com/moiexpositoalonsolab/grenepipe.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.15167v1"
    },
    {
        "title": "Statistical Power Analysis for Designing Bulk, Single-Cell, and Spatial\n  Transcriptomics Experiments: Review, Tutorial, and Perspectives",
        "authors": [
            "Hyeongseon Jeon",
            "Juan Xie",
            "Yeseul Jeon",
            "Kyeong Joo Jung",
            "Arkobrato Gupta",
            "Won Chang",
            "Dongjun Chung"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Gene expression profiling technologies have been used in various applications\nsuch as cancer biology. The development of gene expression profiling has\nexpanded the scope of target discovery in transcriptomic studies, and each\ntechnology produces data with distinct characteristics. In order to guarantee\nbiologically meaningful findings using transcriptomic experiments, it is\nimportant to consider various experimental factors in a systematic way through\nstatistical power analysis. In this paper, we review and discuss the power\nanalysis for three types of gene expression profiling technologies from a\npractical standpoint, including bulk RNA-seq, single-cell RNA-seq, and\nhigh-throughput spatial transcriptomics. Specifically, we describe the existing\npower analysis tools for each research objective for each of the bulk RNA-seq\nand scRNA-seq experiments, along with recommendations. On the other hand, since\nthere are no power analysis tools for high-throughput spatial transcriptomics\nat this point, we instead investigate the factors that can influence power\nanalysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02918v1"
    },
    {
        "title": "Algorithms for the uniqueness of the longest common subsequence",
        "authors": [
            "Yue Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Given several number sequences, determining the longest common subsequence is\na classical problem in computer science. This problem has applications in\nbioinformatics, especially determining transposable genes. Nevertheless,\nrelated works only consider how to find one longest common subsequence. In this\npaper, we consider how to determine the uniqueness of the longest common\nsubsequence. If there are multiple longest common subsequences, we also\ndetermine which number appears in all/some/none of the longest common\nsubsequences. We focus on four scenarios: (1) linear sequences without\nduplicated numbers; (2) circular sequences without duplicated numbers; (3)\nlinear sequences with duplicated numbers; (4) circular sequences with\nduplicated numbers. We develop corresponding algorithms and apply them to gene\nsequencing data.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.03827v4"
    },
    {
        "title": "Beyond the exome: what's next in diagnostic testing for Mendelian\n  conditions",
        "authors": [
            "Monica H. Wojcik",
            "Chloe M. Reuter",
            "Shruti Marwaha",
            "Medhat Mahmoud",
            "Michael H. Duyzend",
            "Hayk Barseghyan",
            "Bo Yuan",
            "Philip M. Boone",
            "Emily E. Groopman",
            "Emmanuèle C. Délot",
            "Deepti Jain",
            "Alba Sanchis-Juan",
            "Genomics Research to Elucidate the Genetics of Rare Diseases",
            " Consortium",
            "Lea M. Starita",
            "Michael Talkowski",
            "Stephen B. Montgomery",
            "Michael J. Bamshad",
            "Jessica X. Chong",
            "Matthew T. Wheeler",
            "Seth I. Berger",
            "Anne O'Donnell-Luria",
            "Fritz J. Sedlazeck",
            "Danny E. Miller"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Despite advances in clinical genetic testing, including the introduction of\nexome sequencing (ES), more than 50% of individuals with a suspected Mendelian\ncondition lack a precise molecular diagnosis. Clinical evaluation is\nincreasingly undertaken by specialists outside of clinical genetics, often\noccurring in a tiered fashion and typically ending after ES. The current\ndiagnostic rate reflects multiple factors, including technical limitations,\nincomplete understanding of variant pathogenicity, missing genotype-phenotype\nassociations, complex gene-environment interactions, and reporting differences\nbetween clinical labs. Maintaining a clear understanding of the rapidly\nevolving landscape of diagnostic tests beyond ES, and their limitations,\npresents a challenge for non-genetics professionals. Newer tests, such as\nshort-read genome or RNA sequencing, can be challenging to order and emerging\ntechnologies, such as optical genome mapping and long-read DNA or RNA\nsequencing, are not available clinically. Furthermore, there is no clear\nguidance on the next best steps after inconclusive evaluation. Here, we review\nwhy a clinical genetic evaluation may be negative, discuss questions to be\nasked in this setting, and provide a framework for further investigation,\nincluding the advantages and disadvantages of new approaches that are nascent\nin the clinical sphere. We present a guide for the next best steps after\ninconclusive molecular testing based upon phenotype and prior evaluation,\nincluding when to consider referral to a consortium such as GREGoR, which is\nfocused on elucidating the underlying cause of rare unsolved genetic disorders.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.07363v1"
    },
    {
        "title": "ntLink: a toolkit for de novo genome assembly scaffolding and mapping\n  using long reads",
        "authors": [
            "Lauren Coombe",
            "René L. Warren",
            "Johnathan Wong",
            "Vladimir Nikolic",
            "Inanc Birol"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  With the increasing affordability and accessibility of genome sequencing\ndata, de novo genome assembly is an important first step to a wide variety of\ndownstream studies and analyses. Therefore, bioinformatics tools that enable\nthe generation of high-quality genome assemblies in a computationally efficient\nmanner are essential. Recent developments in long-read sequencing technologies\nhave greatly benefited genome assembly work, including scaffolding, by\nproviding long-range evidence that can aid in resolving the challenging\nrepetitive regions of complex genomes. ntLink is a flexible and\nresource-efficient genome scaffolding tool that utilizes long-read sequencing\ndata to improve upon draft genome assemblies built from any sequencing\ntechnologies, including the same long reads. Instead of using read alignments\nto identify candidate joins, ntLink utilizes minimizer-based mappings to infer\nhow input sequences should be ordered and oriented into scaffolds. Recent\nimprovements to ntLink have added important features such as overlap detection,\ngap-filling and in-code scaffolding iterations. Here, we present three basic\nprotocols demonstrating how to use each of these new features to yield highly\ncontiguous genome assemblies, while still maintaining ntLink's proven\ncomputational efficiency. Further, as we illustrate in the alternate protocols,\nthe lightweight minimizer-based mappings that enable ntLink scaffolding can\nalso be utilized for other downstream applications, such as misassembly\ndetection. With its modularity and multiple modes of execution, ntLink has\nbroad benefit to the genomics community, from genome scaffolding and beyond.\nntLink is an open-source project and is freely available from\nhttps://github.com/bcgsc/ntLink.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08785v1"
    },
    {
        "title": "RawHash: Enabling Fast and Accurate Real-Time Analysis of Raw Nanopore\n  Signals for Large Genomes",
        "authors": [
            "Can Firtina",
            "Nika Mansouri Ghiasi",
            "Joel Lindegger",
            "Gagandeep Singh",
            "Meryem Banu Cavlak",
            "Haiyu Mao",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Nanopore sequencers generate electrical raw signals in real-time while\nsequencing long genomic strands. These raw signals can be analyzed as they are\ngenerated, providing an opportunity for real-time genome analysis. An important\nfeature of nanopore sequencing, Read Until, can eject strands from sequencers\nwithout fully sequencing them, which provides opportunities to computationally\nreduce the sequencing time and cost. However, existing works utilizing Read\nUntil either 1) require powerful computational resources that may not be\navailable for portable sequencers or 2) lack scalability for large genomes,\nrendering them inaccurate or ineffective.\n  We propose RawHash, the first mechanism that can accurately and efficiently\nperform real-time analysis of nanopore raw signals for large genomes using a\nhash-based similarity search. To enable this, RawHash ensures the signals\ncorresponding to the same DNA content lead to the same hash value, regardless\nof the slight variations in these signals. RawHash achieves an accurate\nhash-based similarity search via an effective quantization of the raw signals\nsuch that signals corresponding to the same DNA content have the same quantized\nvalue and, subsequently, the same hash value.\n  We evaluate RawHash on three applications: 1) read mapping, 2) relative\nabundance estimation, and 3) contamination analysis. Our evaluations show that\nRawHash is the only tool that can provide high accuracy and high throughput for\nanalyzing large genomes in real-time. When compared to the state-of-the-art\ntechniques, UNCALLED and Sigmap, RawHash provides 1) 25.8x and 3.4x better\naverage throughput and 2) significantly better accuracy for large genomes,\nrespectively. Source code is available at\nhttps://github.com/CMU-SAFARI/RawHash.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09200v4"
    },
    {
        "title": "PhaVIP: Phage VIrion Protein classification based on chaos game\n  representation and Vision Transformer",
        "authors": [
            "Jiayu Shang",
            "Cheng Peng",
            "Xubo Tang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Motivation: As viruses that mainly infect bacteria, phages are key players\nacross a wide range of ecosystems. Analyzing phage proteins is indispensable\nfor understanding phages' functions and roles in microbiomes. High-throughput\nsequencing enables us to obtain phages in different microbiomes with low cost.\nHowever, compared to the fast accumulation of newly identified phages, phage\nprotein classification remains difficult. In particular, a fundamental need is\nto annotate virion proteins, the structural proteins such as major tail,\nbaseplate etc. Although there are experimental methods for virion protein\nidentification, they are too expensive or time-consuming, leaving a large\nnumber of proteins unclassified. Thus, there is a great demand to develop a\ncomputational method for fast and accurate phage virion protein classification.\nResults: In this work, we adapted the state-of-the-art image classification\nmodel, Vision Transformer, to conduct virion protein classification. By\nencoding protein sequences into unique images using chaos gaming\nrepresentation, we can leverage Vision Transformer to learn both local and\nglobal features from sequence ``images''. Our method, PhaVIP, has two main\nfunctions: classifying PVP and non-PVP sequences and annotating the types of\nPVP, such as capsid and tail. We tested PhaVIP on several datasets with\nincreasing difficulty and benchmarked it against alternative tools. The\nexperimental results show that PhaVIP has superior performance. After\nvalidating the performance of PhaVIP, we investigated two applications that can\nuse the output of PhaVIP: phage taxonomy classification and phage host\nprediction. The results show the benefit of using classified proteins rather\nthan all proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.12422v2"
    },
    {
        "title": "DnaA and the timing of chromosome replication in Escherichia coli as a\n  function of growth rate",
        "authors": [
            "Matthew A. A. Grant",
            "Chiara Saggioro",
            "Ulisse Ferrari",
            "Bruno Bassetti",
            "Bianca Sclavi",
            "Marco Cosentino Lagomarsino"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Background: In Escherichia coli, overlapping rounds of DNA replication allow\nthe bacteria to double in faster times than the time required to copy the\ngenome. The precise timing of initiation of DNA replication is determined by a\nregulatory circuit that depends on the binding of a critical number of\nATP-bound DnaA proteins at the origin of replication. The synthesis of DnaA in\nthe cell is controlled by a growth-rate dependent, negatively autoregulated\ngene found near the origin of replication. Both the regulatory and initiation\nactivity of DnaA depend on its nucleotide bound state and its availability.\n  Results: In order to investigate the contributions of the different\nregulatory processes to the timing of initiation of DNA replication at varying\ngrowth rates, we formulate a minimal quantitative model of the initiator\ncircuit that includes the key ingredients known to regulate the activity of the\nDnaA protein. This model describes the average-cell oscillations in\nDnaA-ATP/DNA during the cell cycle, for varying growth rates. We evaluate the\nconditions under which this ratio attains the same threshold value at the time\nof initiation, independently of the growth rate.\n  Conclusions: We find that a quantitative description of replication\ninitiation by DnaA must rely on the dependency of the basic parameters on\ngrowth rate, in order to account for the timing of initiation of DNA\nreplication at different cell doubling times. We isolate two main possible\nscenarios for this. One possibility is that the basal rate of regulatory\ninactivation by ATP hydrolysis must vary with growth rate. Alternatively, some\nparameters defining promoter activity need to be a function of the growth rate.\nIn either case, the basal rate of gene expression needs to increase with the\ngrowth rate, in accordance with the known characteristics of the dnaA promoter.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1030v1"
    },
    {
        "title": "Phenotypic class ratios as marker signs of different types of\n  agamospermy",
        "authors": [
            "Svetlana Sergeevna Kirikovich",
            "Evgenii Vladimirovich Levites"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  This article focuses on the development of the method for the genetic\nclassification of agamospermous reproduction types in plants using sugar beet\nas an example. The classification feasibility is ensured by the use of isozymes\nas genetic markers allowing the identification of all three phenotypic classes\nin the progeny of individual heterozygous diploid plant and is based on\ndifferent phenotypic class ratios in the progenies obtained by meiotic and\nmitotic agamospermy. The data indicate that for sugar beet meiotic agamospermy\nis the more typical since 13 of 15 explored progenies were classified as those\nproduced by meiotic agamospermy and only 2 as produced by mitotic agamospermy.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.0002v1"
    },
    {
        "title": "Fast and accurate alignment of long bisulfite-seq reads",
        "authors": [
            "Brent S. Pedersen",
            "Kenneth Eyring",
            "Subhajyoti De",
            "Ivana V. Yang",
            "David A. Schwartz"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Summary: Longer sequencing reads, with at least 200 bases per template are\nnow common. While traditional aligners have adopted new strategies to improve\nthe mapping of longer reads, aligners specific to bisulfite-sequencing were\noptimized when much shorter reads were the norm. We sought to perform the first\ncomparison using longer reads to determine which aligners were most accurate\nand efficient and to evaluate a novel software tool, bwa-meth, built on a\ntraditional mapper that supports insertions, deletions and clipped alignments.\nWe gauge accuracy by comparing the number of on and off-target reads from a\ntargeted sequencing project and by simulations. Availability and\nImplementation: The benchmarking scripts and the bwa-meth software are\navailable at https://github/com/brentp/bwa-meth/ under the MIT License.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1129v2"
    },
    {
        "title": "Statistical Mechanics Model for the Dynamics of Collective Epigenetic\n  Histone Modification",
        "authors": [
            "Hang Zhang",
            "Xiao-Jun Tian",
            "Abhishek Mukhopadhyay",
            "K. S. Kim",
            "Jianhua Xing"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Epigenetic histone modifications play an important role in the maintenance of\ndifferent cell phenotypes. The exact molecular mechanism for inheritance of the\nmodification patterns over cell generations remains elusive. We construct a\nPotts-type model based on experimentally observed nearest-neighbor enzyme\nlateral interactions and nucleosome covalent modification state biased enzyme\nrecruitment. The model can lead to effective nonlocal interactions among\nnucleosomes suggested in previous theoretical studies, and epigenetic memory is\nrobustly inheritable against stochastic cellular processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1422v4"
    },
    {
        "title": "Integrative genomics analysis identifies pericentromeric regions of\n  human chromosomes affecting patterns of inter-chromosomal interactions",
        "authors": [
            "Gennadi V. Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Genome-wide analysis of distributions of densities of long-range interactions\nof human chromosomes with each other, nucleoli, nuclear lamina, and binding\nsites of chromatin state regulatory proteins, CTCF and STAT1, identifies\nnon-random highly correlated patterns of density distributions along the\nchromosome length for all these features. Marked co-enrichments and clustering\nof all these interactions are detected at discrete genomic regions on selected\nchromosomes, which are located within pericentromeric heterochromatin and\ndesignated Centromeric Regions of Interphase Chromatin Homing (CENTRICH).\nCENTRICH manifest 199-716-fold higher density of inter-chromosomal binding\nsites compared to genome-wide or chromosomal averages (p =\n2.10E-101-1.08E-292). Sequence alignment analysis shows that CENTRICH represent\nunique DNA sequences of 3.9 to 22.4 Kb in size which are: 1) associated with\nnucleolus; 2) exhibit highly diverse set of DNA-bound chromatin state\nregulators, including marked enrichment of CTCF and STAT1 binding sites; 3)\nbind multiple intergenic disease-associated genomic loci (IDAGL) with\ndocumented long-range enhancer activities and established links to increased\nrisk of developing epithelial malignancies and other common human disorders.\nUsing distances of SNP loci homing sites within genomic coordinates of CENTRICH\nas a proxy of likelihood of disease-linked SNP loci binding to CENTRICH, we\ndemonstrate statistically significant correlations between the probability of\nSNP loci binding to CENTRICH and GWAS-defined odds ratios of increased risk of\na disease for cancer, coronary artery disease, and type 2 diabetes. Our\nanalysis suggests that centromeric sequences and pericentromeric\nheterochromatin may play an important role in human cells beyond the critical\nfunctions in chromosome segregation.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.2238v1"
    },
    {
        "title": "Palaeosymbiosis revealed by genomic fossils of Wolbachia in a\n  strongyloidean nematode",
        "authors": [
            "Georgios Koutsovoulos",
            "Benjamin Makepeace",
            "Vincent N. Tanya",
            "Mark Blaxter"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Wolbachia are common endosymbionts of terrestrial arthropods, and are also\nfound in nematodes: the animal-parasitic filaria, and the plant-parasite\nRadopholus similis. Lateral transfer of Wolbachia DNA to the host genome is\ncommon. We generated a draft genome sequence for the strongyloidean nematode\nparasite Dictyocaulus viviparus, the cattle lungworm. In the assembly, we\nidentified nearly 1 Mb of sequence with similarity to Wolbachia. The fragments\nwere unlikely to derive from a live Wolbachia infection: most were short, and\nthe genes were disabled through inactivating mutations. Many fragments were\nco-assembled with definitively nematode-derived sequence. We found limited\nevidence of expression of the Wolbachia-derived genes. The D. viviparus\nWolbachia genes were most similar to filarial strains, and strains from the\nhost-promiscuous clade F. We conclude that D. viviparus was infected by\nWolbachia in the past. Genome sequence based surveys are a powerful tool for\nrevealing the genome archaeology of infection and symbiosis.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.2286v1"
    },
    {
        "title": "A possible gut microbiota basis for weight gain side effects of\n  antipsychotic drugs",
        "authors": [
            "Harshad Joshi",
            "Ankita Parihar",
            "Dazhi Jiao",
            "Shwetha Murali",
            "David J. Wild"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Weight gain is a well-established side effect of both conventional and newer\nanti-psychotic drugs, but the cause is not well understood. Recent studies\ncorrelate obesity with the presence or absence of particular genetic sequences\nin the gut microbiota. We identified strong associations between protein\ntargets of antipsychotics and microbiota sequences directly related to weight\nregulation in human body, leading to a potential metagenomic mechanism of\naction. Further experimental study is recommended.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.2389v1"
    },
    {
        "title": "A model capturing novel strand symmetries in bacterial DNA",
        "authors": [
            "Marcelo Sobottka",
            "Andrew G. Hart"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Chargaff's second parity rule for short oligonucleotides states that the\nfrequency of any short nucleotide sequence on a strand is approximately equal\nto the frequency of its reverse complement on the same strand. Recent studies\nhave shown that, with the exception of organellar DNA, this parity rule\ngenerally holds for double stranded DNA genomes and fails to hold for\nsingle-stranded genomes. While Chargaff's first parity rule is fully explained\nby the Watson-Crick pairing in the DNA double helix, a definitive explanation\nfor the second parity rule has not yet been determined. In this work, we\npropose a model based on a hidden Markov process for approximating the\ndistributional structure of primitive DNA sequences. Then, we use the model to\nprovide another possible theoretical explanation for Chargaff's second parity\nrule, and to predict novel distributional aspects of bacterial DNA sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3254v1"
    },
    {
        "title": "Whole Exome Sequencing to Estimate Alloreactivity Potential Between\n  Donors and Recipients in Stem Cell Transplantation",
        "authors": [
            "Juliana K. Sampson",
            "Nihar U. Sheth",
            "Vishal N. Koparde",
            "Allison F. Scalora",
            "Myrna G. Serrano",
            "Vladimir Lee",
            "Catherine H. Roberts",
            "Maximilian Jameson-Lee",
            "Andrea Ferriera-Gonzalez",
            "Masoud H. Manjili",
            "Gregory A. Buck",
            "Michael C. Neale",
            "Amir A. Toor"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Whole exome sequencing was performed on HLA-matched stem cell donors and\ntransplant recipients to measure sequence variation contributing to minor\nhistocompatibility antigen differences between the two. A large number of\nnonsynonymous single nucleotide polymorphisms were identified in each of the\nnine unique donor-recipient pairs tested. This variation was greater in\nmagnitude in unrelated donors as compared with matched related donors.\nKnowledge of the magnitude of exome variation between stem cell transplant\nrecipients and donors may allow more accurate titration of immunosuppressive\ntherapy following stem cell transplantation.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3452v1"
    },
    {
        "title": "The life cycle of Drosophila orphan genes",
        "authors": [
            "Nicola Palmieri",
            "Carolin Kosiol",
            "Christian Schlötterer"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Orphans are genes restricted to a single phylogenetic lineage and emerge at\nhigh rates. While this predicts an accumulation of genes, the gene number has\nremained remarkably constant through evolution. This paradox has not yet been\nresolved. Because orphan genes have been mainly analyzed over long evolutionary\ntime scales, orphan loss has remained unexplored. Here we study the patterns of\norphan turnover among close relatives in the Drosophila obscura group. We show\nthat orphans are not only emerging at a high rate, but that they are also\nrapidly lost. Interestingly, recently emerged orphans are more likely to be\nlost than older ones. Furthermore, highly expressed orphans with a strong\nmale-bias are more likely to be retained. Since both lost and retained orphans\nshow similar evolutionary signatures of functional conservation, we propose\nthat orphan loss is not driven by high rates of sequence evolution, but\nreflects lineage specific functional requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4956v1"
    },
    {
        "title": "Diverse and widespread contamination evident in the unmapped depths of\n  high throughput sequencing data",
        "authors": [
            "Richard W Lusk"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Background: Trace quantities of contaminating DNA are widespread in the\nlaboratory environment, but their presence has received little attention in the\ncontext of high throughput sequencing. This issue is highlighted by recent\nworks that have rested controversial claims upon sequencing data that appear to\nsupport the presence of unexpected exogenous species.\n  Results: I used reads that preferentially aligned to alternate genomes to\ninfer the distribution of potential contaminant species in a set of independent\nsequencing experiments. I confirmed that dilute samples are more exposed to\ncontaminating DNA, and, focusing on four single-cell sequencing experiments,\nfound that these contaminants appear to originate from a wide diversity of\nclades. Although negative control libraries prepared from \"blank\" samples\nrecovered the highest-frequency contaminants, low-frequency contaminants, which\nappeared to make heterogeneous contributions to samples prepared in parallel\nwithin a single experiment, were not well controlled for. I used these results\nto show that, despite heavy replication and plausible controls, contamination\ncan explain all of the observations used to support a recent claim that\ncomplete genes pass from food to human blood.\n  Conclusions: Contamination must be considered a potential source of signals\nof exogenous species in sequencing data, even if these signals are replicated\nin independent experiments, vary across conditions, or indicate a species which\nseems a priori unlikely to contaminate. Negative control libraries processed in\nparallel are essential to control for contaminant DNAs, but their limited\nability to recover low-frequency contaminants must be recognized.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.7975v1"
    },
    {
        "title": "Hierarchical clustering of DNA k-mer counts in RNA-seq fastq files\n  reveals batch effects",
        "authors": [
            "Wolfgang Kaisers",
            "Holger Schwender",
            "Heiner Schaal"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Batch effects, artificial sources of variation due to experimental design,\nare a widespread phenomenon in high throughput data. Therefore, mechanisms for\ndetection of batch effects are needed requiring comparison of multiple samples.\nWe apply hierarchical clustering (HC) on DNA k-mer counts of multiple RNA-seq\nderived Fastq files. Ideally, HC generated trees reflect experimental treatment\ngroups and thus may indicate experimental effects, but clustering of\npreparation groups indicates the presence of batch effects. In order to provide\na simple applicable tool we implemented sequential analysis of Fastq reads with\nlow memory usage in an R package (seqTools) available on Bioconductor. DNA\nk-mer counts were analysed on 61 Fastq files containing RNA-seq data from two\ncell types (dermal fibroblasts and Jurkat cells) sequenced on 8 different\nIllumina Flowcells. Results: Pairwise comparison of all Flowcells with\nhierarchical clustering revealed strong Flowcell based tree separation in 6 (21\n%) and detectable Flowcell based clustering in 17 (60.7 %) of 28 Flowcell\ncomparisons. In our samples, batch effects were also present in reads mapped to\nthe human genome. Filtering reads for high quality (Phred >30) did not remove\nthe batch effects. Conclusions: Hierarchical clustering of DNA k-mer counts\nprovides a quality criterion and an unspecific diagnostic tool for RNA-seq\nexperiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.0114v6"
    },
    {
        "title": "Long non-coding RNAs as a source of new peptides",
        "authors": [
            "Jorge Ruiz-Orera",
            "Xavier Messeguer",
            "Juan A. Subirana",
            "M. Mar Albà"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Deep transcriptome sequencing has revealed the existence of many transcripts\nthat lack long or conserved open reading frames and which have been termed long\nnon-coding RNAs (lncRNAs). Despite the existence of several well-characterized\nlncRNAs that play roles in the regulation of gene expression, the vast majority\nof them do not yet have a known function. Motivated by the existence of\nribosome profiling data for several species, we have tested the hypothesis that\nthey may act as a repository for the synthesis of new peptides using data from\nhuman, mouse, zebrafish, fruit fly, Arabidopsis and yeast. The ribosome\nprotection patterns are consistent with the presence of translated open reading\nframes (ORFs) in a very large number of lncRNAs. Most of the ribosome-protected\nORFs are shorter than 100 amino acids and usually cover less than half the\ntranscript. Ribosome density in these ORFs is high and contrasts sharply with\nthe 3UTR region, in which very often there is no detectable ribosome binding,\nsimilar to bona fide protein-coding genes. The coding potential of\nribosome-protected ORFs, measured using hexamer frequencies, is significantly\nhigher than that of randomly selected intronic ORFs and similar to that of\nevolutionary young coding sequences. Selective constraints in\nribosome-protected ORFs from lncRNAs are lower than in typical protein-coding\ngenes but again similar to young proteins. These results strongly suggest that\nlncRNAs play an important role in de novo protein evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.4174v1"
    },
    {
        "title": "Evidence for strong co-evolution of mitochondrial and somatic genomes",
        "authors": [
            "Michael G. Sadovsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  We studied a relations between the triplet frequency composition of\nmitochondria genomes, and the phylogeny of their bearers. First, the clusters\nin 63dimensional space were developed due to $K$-means. Second, the clade\ncomposition of those clusters has been studied. It was found that genomes are\ndistributed among the clusters very regularly, with strong correlation to\ntaxonomy. Strong co-evolution manifests through this correlation: the proximity\nin frequency space was determined over the mitochondrion genomes, while the\nproximity in taxonomy was determined morphologically.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5128v1"
    },
    {
        "title": "High-resolution transcriptome analysis with long-read RNA sequencing",
        "authors": [
            "Hyunghoon Cho",
            "Joe Davis",
            "Xin Li",
            "Kevin S. Smith",
            "Alexis Battle",
            "Stephen B. Montgomery"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  RNA sequencing (RNA-seq) enables characterization and quantification of\nindividual transcriptomes as well as detection of patterns of allelic\nexpression and alternative splicing. Current RNA-seq protocols depend on\nhigh-throughput short-read sequencing of cDNA. However, as ongoing advances are\nrapidly yielding increasing read lengths, a technical hurdle remains in\nidentifying the degree to which differences in read length influence various\ntranscriptome analyses. In this study, we generated two paired-end RNA-seq\ndatasets of differing read lengths (2x75 bp and 2x262 bp) for lymphoblastoid\ncell line GM12878 and compared the effect of read length on transcriptome\nanalyses, including read-mapping performance, gene and transcript\nquantification, and detection of allele-specific expression (ASE) and\nallele-specific alternative splicing (ASAS) patterns. Our results indicate\nthat, while the current long-read protocol is considerably more expensive than\nshort-read sequencing, there are important benefits that can only be achieved\nwith longer read length, including lower mapping bias and reduced ambiguity in\nassigning reads to genomic elements, such as mRNA transcript. We show that\nthese benefits ultimately lead to improved detection of cis-acting regulatory\nand splicing variation effects within individuals.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.7316v1"
    },
    {
        "title": "Maximizing Protein Translation Rate in the Ribosome Flow Model: the\n  Homogeneous Case",
        "authors": [
            "Yoram Zarai",
            "Michael Margaliot",
            "Tamir Tuller"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Gene translation is the process in which intracellular macro-molecules,\ncalled ribosomes, decode genetic information in the mRNA chain into the\ncorresponding proteins. Gene translation includes several steps. During the\nelongation step, ribosomes move along the mRNA in a sequential manner and link\namino-acids together in the corresponding order to produce the proteins.\n  The homogeneous ribosome flow model(HRFM) is a deterministic computational\nmodel for translation-elongation under the assumption of constant elongation\nrates along the mRNA chain. The HRFM is described by a set of n first-order\nnonlinear ordinary differential equations, where n represents the number of\nsites along the mRNA chain. The HRFM also includes two positive parameters:\nribosomal initiation rate and the (constant) elongation rate. In this paper, we\nshow that the steady-state translation rate in the HRFM is a concave function\nof its parameters. This means that the problem of determining the parameter\nvalues that maximize the translation rate is relatively simple. Our results may\ncontribute to a better understanding of the mechanisms and evolution of\ntranslation-elongation. We demonstrate this by using the theoretical results to\nestimate the initiation rate in M. musculus embryonic stem cell. The underlying\nassumption is that evolution optimized the translation mechanism.\n  For the infinite-dimensional HRFM, we derive a closed-form solution to the\nproblem of determining the initiation and transition rates that maximize the\nprotein translation rate. We show that these expressions provide good\napproximations for the optimal values in the n-dimensional HRFM already for\nrelatively small values of n. These results may have applications for synthetic\nbiology where an important problem is to re-engineer genomic systems in order\nto maximize the protein production rate.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.0207v1"
    },
    {
        "title": "SEK: Sparsity exploiting $k$-mer-based estimation of bacterial community\n  composition",
        "authors": [
            "Saikat Chatterjee",
            "David Koslicki",
            "Siyuan Dong",
            "Nicolas Innocenti",
            "Lu Cheng",
            "Yueheng Lan",
            "Mikko Vehkaperä",
            "Mikael Skoglund",
            "Lars K. Rasmussen",
            "Erik Aurell",
            "Jukka Corander"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation: Estimation of bacterial community composition from a\nhigh-throughput sequenced sample is an important task in metagenomics\napplications. Since the sample sequence data typically harbors reads of\nvariable lengths and different levels of biological and technical noise,\naccurate statistical analysis of such data is challenging. Currently popular\nestimation methods are typically very time consuming in a desktop computing\nenvironment.\n  Results: Using sparsity enforcing methods from the general sparse signal\nprocessing field (such as compressed sensing), we derive a solution to the\ncommunity composition estimation problem by a simultaneous assignment of all\nsample reads to a pre-processed reference database. A general statistical model\nbased on kernel density estimation techniques is introduced for the assignment\ntask and the model solution is obtained using convex optimization tools.\nFurther, we design a greedy algorithm solution for a fast solution. Our\napproach offers a reasonably fast community composition estimation method which\nis shown to be more robust to input data variation than a recently introduced\nrelated method.\n  Availability: A platform-independent Matlab implementation of the method is\nfreely available at http://www.ee.kth.se/ctsoftware; source code that does not\nrequire access to Matlab is currently being tested and will be made available\nlater through the above website.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.0387v1"
    },
    {
        "title": "Analysis of cellular responses of macrophages to zinc ions and zinc\n  oxide nanoparticles: a combined targeted and proteomic approach",
        "authors": [
            "Sarah Triboulet",
            "Catherine Aude-Garcia",
            "Lucie Armand",
            "Adèle Gerdil",
            "Hélène Diemer",
            "Fabienne Proamer",
            "Véronique Collin-Faure",
            "Aurélie Habert",
            "Jean-Marc Strub",
            "Daniel Hanau",
            "Nathalie Herlin",
            "Marie Carrière",
            "Alain Van Dorsselaer",
            "Thierry Rabilloud"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Two different zinc oxide nanoparticles, as well as zinc ions, are used to\nstudy the cellular responses of the RAW 264 macrophage cell line. A proteomic\nscreen is used to provide a wide view of the molecular effects of zinc, and the\nmost prominent results are cross-validated by targeted studies. Furthermore,\nthe alteration of important macrophage functions (e.g. phagocytosis) by zinc is\nalso investigated. The intracellular dissolution/uptake of zinc is also studied\nto further characterize zinc toxicity. Zinc oxide nanoparticles dissolve\nreadily in the cells, leading to high intracellular zinc concentrations, mostly\nas protein-bound zinc. The proteomic screen reveals a rather weak response in\nthe oxidative stress response pathway, but a strong response both in the\ncentral metabolism and in the proteasomal protein degradation pathway. Targeted\nexperiments confirm that carbohydrate catabolism and proteasome are critical\ndeterminants of sensitivity to zinc, which also induces DNA damage. Conversely,\nglutathione levels and phagocytosis appear unaffected at moderately toxic zinc\nconcentrations.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2732v1"
    },
    {
        "title": "Human-chimpanzee alignment: Ortholog Exponentials and Paralog Power Laws",
        "authors": [
            "Kun Gao",
            "Jonathan Miller"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Genomic subsequences conserved between closely related species such as human\nand chimpanzee exhibit an exponential length distribution, in contrast to the\nalgebraic length distribution observed for sequences shared between distantly\nrelated genomes. We find that the former exponential can be further decomposed\ninto an exponential component primarily composed of orthologous sequences, and\na truncated algebraic component primarily composed of paralogous sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.3895v2"
    },
    {
        "title": "Maximizing Protein Translation Rate in the Nonhomogeneous Ribosome Flow\n  Model: A Convex Optimization Approach",
        "authors": [
            "Gilad Poker",
            "Yoram Zarai",
            "Michael Margaliot",
            "Tamir Tuller"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Translation is an important stage in gene expression. During this stage,\nmacro-molecules called ribosomes travel along the mRNA strand linking\namino-acids together in a specific order to create a functioning protein. An\nimportant question is how to maximize protein production. Indeed, translation\nis known to consume most of the cell's energy and it is natural to assume that\nevolution shaped this process so that it maximizes the protein production rate.\nIf this is indeed so then one can estimate various parameters of the\ntranslation machinery by solving an appropriate mathematical optimization\nproblem. The same problem also arises in the context of synthetic biology,\nnamely, re-engineer heterologous genes in order to maximize their translation\nrate in a host organism. We consider the problem of maximizing the protein\nproduction rate using a computational model for translation-elongation called\nthe ribosome flow model (RFM). This model describes the flow of the ribosomes\nalong an mRNA chain of length n using a set of n first-order nonlinear ODEs. It\nalso includes n+1 positive parameters: the ribosomal initiation rate into the\nmRNA chain, and n elongation rates along the chain sites. We show that the\nsteady-state translation rate in the RFM is a strictly concave function of its\nparameters. This means that the problem of maximizing the translation rate\nunder a suitable constraint always admits a unique solution, and that this\nsolution can be determined using highly-efficient algorithms for solving convex\noptimization problems even for large values of n. Furthermore, our analysis\nshows that the optimal translation rate can be computed based only on the\noptimal initiation rate and the elongation rate of the codons near the\nbeginning of the ORF. We discuss some applications of the theoretical results\nto synthetic biology, molecular evolution, and functional genomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6340v1"
    },
    {
        "title": "Multi-species network inference improves gene regulatory network\n  reconstruction for early embryonic development in Drosophila",
        "authors": [
            "Anagha Joshi",
            "Yvonne Beck",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Gene regulatory network inference uses genome-wide transcriptome measurements\nin response to genetic, environmental or dynamic perturbations to predict\ncausal regulatory influences between genes. We hypothesized that evolution also\nacts as a suitable network perturbation and that integration of data from\nmultiple closely related species can lead to improved reconstruction of gene\nregulatory networks. To test this hypothesis, we predicted networks from\ntemporal gene expression data for 3,610 genes measured during early embryonic\ndevelopment in six Drosophila species and compared predicted networks to gold\nstandard networks of ChIP-chip and ChIP-seq interactions for developmental\ntranscription factors in five species. We found that (i) the performance of\nsingle-species networks was independent of the species where the gold standard\nwas measured; (ii) differences between predicted networks reflected the known\nphylogeny and differences in biology between the species; (iii) an integrative\nconsensus network which minimized the total number of edge gains and losses\nwith respect to all single-species networks performed better than any\nindividual network. Our results show that in an evolutionarily conserved\nsystem, integration of data from comparable experiments in multiple species\nimproves the inference of gene regulatory networks. They provide a basis for\nfuture studies on the numerous multi-species gene expression datasets for other\nbiological processes available in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6554v2"
    },
    {
        "title": "Generalized Integrated Functional Test for Regional Methylation Rates",
        "authors": [
            "Duchwan Ryu",
            "Hongyan Xu",
            "Varghese George",
            "Shaoyong Su",
            "Xiaoling Wang",
            "Huidong Shi",
            "Robert H. Podolsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation: Methods are needed to test pre-defined genomic regions such as\npromoters for differential methylation in genome-wide association studies,\nwhere the number of samples is limited and the data have large amounts of\nmeasurement error. Results: We developed a new statistical test, the\ngeneralized integrated functional test (GIFT), which tests for regional\ndifferences in methylation based on differences in the functional relationship\nbetween methylation percent and location of the CpG sites within a region. In\nthis method, subject-specific functional profiles are first estimated, and the\naverage profile within groups is compared between groups using an ANOVA-like\ntest. Simulations and analyses of data obtained from patients with chronic\nlymphocytic leukemia indicate that GIFT has good statistical properties and is\nable to identify promising genomic regions. Further, GIFT is likely to work\nwith multiple different types of experiments since different smoothing\nfunctions can be used to estimate the functional relationship between\nmethylation percent and CpG site location. Availability and Implementation:\nMatlab code for GIFT and sample data are available at\nhttp://biostat.gru.edu/~dryu/research.html. Contact: rpodolsk@med.wayne.edu or\ndryu@gru.edu\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6697v1"
    },
    {
        "title": "Clustering pipeline for determining consensus sequences in targeted\n  next-generation sequencing",
        "authors": [
            "Raunaq Malhotra",
            "Daniel Elleder",
            "Le Bao",
            "David R Hunter",
            "Raj Acharya",
            "Mary Poss"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Analyses of targeted genomic sequencing data from next-generation-sequencing\n(NGS) technologies typically involves mapping reads to a reference sequence or\nclustering reads. For a number of species a reference genome is not available\nso the analyses of targeted sequencing data, for example polymorphic structural\nvariation caused by mobile elements is difficult; clustering methods are\npreferred for such data analysis. Clustering of reads requires a clustering\nthreshold parameter, which is used to compare and group reads. However,\ndetermining the optimal clustering threshold for a read dataset is challenging\nbecause of different sequence composition, the number of sequences present, and\nalso the amount of sequencing errors in the dataset. High values of the\nclustering threshold parameter can falsely inflate the number of recovered\ngenomic regions, while low values of clustering threshold can merge reads from\ndistinct regions into a single cluster. Thus, an algorithm that can empirically\ndetermine clustering threshold is needed. We propose a pipeline for clustering\ngenomic sequences wherein the clustering threshold is empirically determined\nfrom the NGS data. The optimal threshold is decided based on two internal\nclustering measures which assess clusters for small intra-cluster diameters and\nlarge inter-cluster distances. We evaluate the pipeline on two simulated\ndatasets derived from human genome sequence simulating different genomic\nregions and sequencing depth. The total number of clusters obtained from our\npipeline is closer to the actual number of reference sequences when compared to\nsingle round of clustering. Also, the number of clusters whose consensus\nsequence matches a corresponding reference sequence is higher in our pipeline.\nWe observe that the presence of repeat regions affects clustering accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.1608v3"
    },
    {
        "title": "DBG2OLC: Efficient Assembly of Large Genomes Using Long Erroneous Reads\n  of the Third Generation Sequencing Technologies",
        "authors": [
            "Chengxi Ye",
            "Chris Hill",
            "Shigang Wu",
            "Jue Ruan",
            " Zhanshan",
            " Ma"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  (An updated version of this manuscript has been accepted to Scientific\nReports in 2016, please refer to http://www.nature.com/articles/srep31900)\n  The highly anticipated transition from next generation sequencing (NGS) to\nthird generation sequencing (3GS) has been difficult primarily due to high\nerror rates and excessive sequencing cost. The high error rates make the\nassembly of long erroneous reads of large genomes challenging because existing\nsoftware solutions are often overwhelmed by error correction tasks. Here we\nreport a hybrid assembly approach that simultaneously utilizes NGS and 3GS data\nto address both issues. We gain advantages from three general and basic design\nprinciples: (i) Compact representation of the long reads lead to efficient\nalignments. (ii) Base-level errors can be skipped; structural errors need to be\ndetected and corrected. (iii) Structurally correct 3GS reads are assembled and\npolished. In our implementation, preassembled NGS contigs are used to derive\nthe compact representation of the long reads, which established an algorithmic\nconversion from a de Bruijn graph to an overlap graph, the two major assembly\nparadigms. Moreover, since NGS and 3GS data can compensate each other, our\nhybrid assembly approach reduces both of their sequencing requirements.\nExperiments show that our software is able to assemble mammalian-sized genomes\norders of magnitude more efficiently in time than existing methods, while\nsaving about half of the sequencing cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.2801v4"
    },
    {
        "title": "On the Structure of the Initiation and Elongation Rates that Maximize\n  Protein Production in the Ribosome Flow Model",
        "authors": [
            "Yoram Zarai",
            "Michael Margaliot"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Translation is a crucial step in gene expression. During translation,\nmacromolecules called ribosomes \"read\" the mRNA strand in a sequential manner\nand produce a corresponding protein. Translation is known to consume most of\nthe cell's energy. Maximizing the protein production rate in mRNA translation,\nsubject to the bounded biomolecullar budget, is thus an important problem in\nboth biology and biotechnology. We consider this problem using a mathematical\nmodel for mRNA translation called the ribosome flow model (RFM). For an mRNA\nstrand with $n$ sites the RFM includes $n$ state-variables that encode the\nnormalized ribosomal density at each site, and $n+1$ positive parameters: the\ninitiation rate and elongation rates along the chain. An affine constraint on\nthese rates is used to model the bounded cellular budget. We show that for a\nhomogeneous constraint the rates that maximize the steady-state protein\nproduction rate have a special structure. They are symmetric with respect to\nthe middle of the chain, and monotonically increase as we move towards the\ncenter of the chain. The ribosomal densities corresponding to the optimal rates\nmonotonically decrease along the chain. We discuss some of the biological\nimplications of these results.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.4088v1"
    },
    {
        "title": "DNA methylation variation in Arabidopsis has a genetic basis and shows\n  evidence of local adaptation",
        "authors": [
            "Manu J. Dubin",
            "Pei Zhang",
            "Dazhe Meng",
            "Marie-Stanislas Remigereau",
            "Edward J. Osborne",
            "Francesco Paolo Casale",
            "Phillip Drewe",
            "André Kahles",
            "Bjarni Vilhjálmsson",
            "Joanna Jagoda",
            "Selen Irez",
            "Viktor Voronin",
            "Qiang Song",
            "Quan Long",
            "Gunnar Rätsch",
            "Oliver Stegle",
            "Richard M. Clark",
            "Magnus Nordborg"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Epigenome modulation in response to the environment potentially provides a\nmechanism for organisms to adapt, both within and between generations. However,\nneither the extent to which this occurs, nor the molecular mechanisms involved\nare known. Here we investigate DNA methylation variation in Swedish Arabidopsis\nthaliana accessions grown at two different temperatures. Environmental effects\non DNA methylation were limited to transposons, where CHH methylation was found\nto increase with temperature. Genome-wide association mapping revealed that the\nextensive CHH methylation variation was strongly associated with genetic\nvariants in both cis and trans, including a major trans-association close to\nthe DNA methyltransferase CMT2. Unlike CHH methylation, CpG gene body\nmethylation (GBM) on the coding region of genes was not affected by growth\ntemperature, but was instead strongly correlated with the latitude of origin.\nAccessions from colder regions had higher levels of GBM for a significant\nfraction of the genome, and this was correlated with elevated transcription\nlevels for the genes affected. Genome-wide association mapping revealed that\nthis effect was largely due to trans-acting loci, a significant fraction of\nwhich showed evidence of local adaptation. These findings constitute the first\ndirect link between DNA methylation and adaptation to the environment, and\nprovide a basis for further dissecting how environmentally driven and\ngenetically determined epigenetic variation interact and influence organismal\nfitness.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.5723v1"
    },
    {
        "title": "An Event-Driven Approach for Studying Gene Block Evolution in Bacteria",
        "authors": [
            "David C Ream",
            "Asma R Bankapur",
            "Iddo Friedberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Motivation: Gene blocks are genes co-located on the chromosome. In many\ncases, genes blocks are conserved between bacterial species, sometimes as\noperons, when genes are co-transcribed. The conservation is rarely absolute:\ngene loss, gain, duplication, block splitting, and block fusion are frequently\nobserved. An open question in bacterial molecular evolution is that of the\nformation and breakup of gene blocks, for which several models have been\nproposed. These models, however, are not generally applicable to all types of\ngene blocks, and consequently cannot be used to broadly compare and study gene\nblock evolution. To address this problem we introduce an event-based method for\ntracking gene block evolution in bacteria. Results: We show here that the\nevolution of gene blocks in proteobacteria can be described by a small set of\nevents. Those include the insertion of genes into, or the splitting of genes\nout of a gene block, gene loss, and gene duplication. We show how the\nevent-based method of gene block evolution allows us to determine the\nevolutionary rate, and to trace the ancestral states of their formation. We\nconclude that the event-based method can be used to help us understand the\nformation of these important bacterial genomic structures. Availability: The\nsoftware is available under GPLv3 license on\nhttp://github.com/reamdc1/gene_block_evolution.git Supplementary online\nmaterial: http://iddo-friedberg.net/operon-evolution Contact: Iddo Friedberg\ni.friedberg@miamioh.edu\n",
        "pdf_link": "http://arxiv.org/pdf/1501.00302v2"
    },
    {
        "title": "On The Organization Of Human T Cell Receptor Loci",
        "authors": [
            "Amir A. Toor",
            "Abdullah A. Toor",
            "Masoud H. Manjili"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The human T cell repertoire is generated by the rearrangement of variable\n(V), diversity (D) and joining (J) segments on the T cell receptor (TCR) loci.\nTo determine whether the structural ordering of these gene segments on the TCR\nloci contributes to the observed clonal frequencies, the TCR loci were examined\nfor self-similarity and periodicity in terms of gene segment organization.\nLogarithmic transformation of numeric sequence order demonstrated that the V\nand J gene segments for both T cell receptor alpha (TRA) and beta (TRB) loci\nwere arranged in a self-similar manner when the spacing between adjacent\nsegments was considered as a function of the size of the neighboring gene\nsegment. The ratio of genomic distance between either the J (in TRA) or D (in\nTRB) segments and successive V segments on these loci declined logarithmically.\nAccounting for the gene segments occurring on helical DNA molecules, in a\nlogarithmic distribution, sine and cosine functions of the log transformed\nangular coordinates of the start and stop nucleotides of successive TCR gene\nsegments showed an ordered progression across the locus, supporting a\nlog-periodic organization. T cell clonal frequencies, based on V and J segment\nusage, from three normal stem cell donors plotted against the respective\nsegment locations on TRB locus demonstrated a periodic variation. We\nhypothesize that this quasi-periodic variation in T cell clonal repertoire may\nbe influenced by the location of the gene segments on the logarithmically\nscaled TCR loci. Interactions between the two strands of DNA in the double\nhelix may influence the probability of gene segment usage by means of either\nconstructive or destructive interference resulting from the superposition of\nthe two helices, impacting probability of DNA recombination.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.00717v1"
    },
    {
        "title": "Canonical, Stable, General Mapping using Context Schemes",
        "authors": [
            "Adam Novak",
            "Yohei Rosen",
            "David Haussler",
            "Benedict Paten"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Motivation: Sequence mapping is the cornerstone of modern genomics. However,\nmost existing sequence mapping algorithms are insufficiently general.\n  Results: We introduce context schemes: a method that allows the unambiguous\nrecognition of a reference base in a query sequence by testing the query for\nsubstrings from an algorithmically defined set. Context schemes only map when\nthere is a unique best mapping, and define this criterion uniformly for all\nreference bases. Mappings under context schemes can also be made stable, so\nthat extension of the query string (e.g. by increasing read length) will not\nalter the mapping of previously mapped positions. Context schemes are general\nin several senses. They natively support the detection of arbitrary complex,\nnovel rearrangements relative to the reference. They can scale over orders of\nmagnitude in query sequence length. Finally, they are trivially extensible to\nmore complex reference structures, such as graphs, that incorporate additional\nvariation. We demonstrate empirically the existence of high performance context\nschemes, and present efficient context scheme mapping algorithms.\n  Availability and Implementation: The software test framework created for this\nwork is available from\nhttps://registry.hub.docker.com/u/adamnovak/sequence-graphs/.\n  Contact: benedict@soe.ucsc.edu\n  Supplementary Information: Six supplementary figures and one supplementary\nsection are available with the online version of this article.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.04128v3"
    },
    {
        "title": "Retrotransposon mobilization in cancer genomes",
        "authors": [
            "Tracy Ballinger",
            "Adam D. Ewing",
            "David Haussler"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The Cancer Genome Atlas project was initiated by the National Cancer\nInstitute in order to characterize the genomes of hundreds of tumors of various\ncancer types. While much effort has been put into detecting somatic genomic\nvariation in these data, somatic structural variation induced by the activity\nof transposable element insertions has not been reported. Transposable elements\n(TEs) are particularly relevant in cancer in part because of several known\ncases in which a TE insertion is directly linked to cancer formation and\nstudies linking the epigenetic status of retrotransposons to carcinogenesis and\npatient outcome. Additionally, evidence for somatic retrotransposition in\neukaryotic genomes suggests that some tissues and therefore some cancer types\nmay be disposed to increased retrotransposition. We built upon previous work to\ndevelop a highly efficient computational pipeline for the detection of\nnon-reference mobile ele- ment insertions from high-throughput paired-end whole\ngenome sequencing data that is capable of detecting breakpoints through a local\nassembly strategy. Using this, we analyzed 33 whole genome tumor datasets with\npaired normal samples from TCGA across 3 different cancer types: glioblastoma\nmultiforme (GBM), ovarian serous cystoadenocarcinoma (OV) and colorectal ade-\nnocarcinoma (COAD). We detected 72 insertions in colon samples, almost all of\nthem LINE-1 elements, and none in GBM or OV. The amount of somatic\nretrotransposition varies widely between samples with 61 insertions present in\none case. The lack of somatic retrotransposon insertions in GBM and OV samples\nsuggests that TE activity in cancer is restricted to certain cancer types.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.04268v1"
    },
    {
        "title": "Rubbish DNA: The functionless fraction of the human genome",
        "authors": [
            "Dan Graur"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Because genomes are products of natural processes rather than intelligent\ndesign, all genomes contain functional and nonfunctional parts. The fraction of\nthe genome that has no biological function is called rubbish DNA. Rubbish DNA\nconsists of junk DNA, i.e., the fraction of the genome on which selection does\nnot operate, and garbage DNA, i.e., sequences that lower the fitness of the\norganism, but exist in the genome because purifying selection is neither\nomnipotent nor instantaneous. In this chapter, I (1) review the concepts of\ngenomic function and functionlessness from an evolutionary perspective, (2)\npresent a precise nomenclature of genomic function, (3) discuss the evidence\nfor the existence of vast quantities of junk DNA within the human genome, (4)\ndiscuss the mutational mechanisms responsible for generating junk DNA, (5)\nspell out the necessary evolutionary conditions for maintaining junk DNA, (6)\noutline various methodologies for estimating the functional fraction within the\ngenome, and (7) present a recent estimate for the functional fraction of our\ngenome.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.06047v1"
    },
    {
        "title": "Machine Learning for Protein Function",
        "authors": [
            "Dan Ofer"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Systematic identification of protein function is a key problem in current\nbiology. Most traditional methods fail to identify functionally equivalent\nproteins if they lack similar sequences, structural data or extensive manual\nannotations. In this thesis, I focused on feature engineering and machine\nlearning methods for identifying diverse classes of proteins that share\nfunctional relatedness but little sequence or structural similarity, notably,\nNeuropeptide Precursors (NPPs).\n  I aim to identify functional protein classes solely using unannotated protein\nprimary sequences from any organism. This thesis focuses on feature\nrepresentations of whole protein sequences, sequence derived engineered\nfeatures, their extraction, frameworks for their usage by machine learning (ML)\nmodels, and the application of ML models to biological tasks, focusing on high\nlevel protein functions. I implemented the ideas of feature engineering to\ndevelop a platform (called NeuroPID) that extracts meaningful features for\nclassification of overlooked NPPs. The platform allows mass discovery of new\nNPs and NPPs. It was expanded as a webserver.\n  I expanded our approach towards other challenging protein classes. This is\nimplemented as a novel bioinformatics toolkit called ProFET (Protein Feature\nEngineering Toolkit). ProFET extracts hundreds of biophysical and sequence\nderived attributes, allowing the application of machine learning methods to\nproteins. ProFET was applied on many protein benchmark datasets with state of\nthe art performance. The success of ProFET applies to a wide range of\nhigh-level functions such as metagenomic analysis, subcellular localization,\nstructure and unique functional properties (e.g. thermophiles, nucleic acid\nbinding).\n  These methods and frameworks represent a valuable resource for using ML and\ndata science methods on proteins.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.02021v1"
    },
    {
        "title": "DeepNano: Deep Recurrent Neural Networks for Base Calling in MinION\n  Nanopore Reads",
        "authors": [
            "Vladimír Boža",
            "Broňa Brejová",
            "Tomáš Vinař"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: The MinION device by Oxford Nanopore is the first portable\nsequencing device. MinION is able to produce very long reads (reads over\n100~kBp were reported), however it suffers from high sequencing error rate. In\nthis paper, we show that the error rate can be reduced by improving the base\ncalling process.\n  Results: We present the first open-source DNA base caller for the MinION\nsequencing platform by Oxford Nanopore. By employing carefully crafted\nrecurrent neural networks, our tool improves the base calling accuracy compared\nto the default base caller supplied by the manufacturer. This advance may\nfurther enhance applicability of MinION for genome sequencing and various\nclinical applications.\n  Availability: DeepNano can be downloaded at\nhttp://compbio.fmph.uniba.sk/deepnano/.\n  Contact: boza@fmph.uniba.sk\n",
        "pdf_link": "http://arxiv.org/pdf/1603.09195v1"
    },
    {
        "title": "An end-to-end assembly of the Aedes aegypti genome",
        "authors": [
            "Daisy E. Pagete"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  We present an end-to-end genome assembly of a female Aedes aegypti mosquito,\nwhich spreads viral diseases such as yellow fever, dengue, chikungunya, and\nZika to humans. The assembly is based on an earlier genome published in 2007\nand improved in 2013. The new assembly has a scaffold N50 of 419Mb, with 96.9%\nof the ungapped sequence anchored to chromosomes. We used the new assembly to\nexamine the conservation of A. aegypti chromosomes. Our results suggest that\nsynteny is strongly conserved between Ae. aegypti and An. gambiae. Comparison\nto D. melanogaster highlights the extent to which the identity of entire\nchromosome arms is preserved across dipterans.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.04619v2"
    },
    {
        "title": "A model for the clustered distribution of SNPs in the human genome",
        "authors": [
            "Chang-Yong Lee"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivated by a non-random but clustered distribution of SNPs, we introduce a\nphenomenological model to account for the clustering properties of SNPs in the\nhuman genome. The phenomenological model is based on a preferential mutation to\nthe closer proximity of existing SNPs. With the Hapmap SNP data, we empirically\ndemonstrate that the preferential model is better for illustrating the\nclustered distribution of SNPs than the random model. Moreover, the model is\napplicable not only to autosomes but also to the X chromosome, although the X\nchromosome has different characteristics from autosomes. The analysis of the\nestimated parameters in the model can explain the pronounced population\nstructure and the low genetic diversity of the X chromosome. In addition,\ncorrelation between the parameters reveals the population-wise difference of\nthe mutation probability. These results support the mutational non-independence\nhypothesis against random mutation.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.06576v1"
    },
    {
        "title": "Transcriptional Similarity in Couples Reveals the Impact of Shared\n  Environment and Lifestyle on Gene Regulation through Modified Cytosines",
        "authors": [
            "Ke Tang",
            "Wei Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Gene expression is a complex and quantitative trait that is influenced by\nboth genetic and non-genetic regulators including environmental factors.\nEvaluating the contribution of environment to gene expression regulation and\nidentifying which genes are more likely to be influenced by environmental\nfactors are important for understanding human complex traits. We hypothesize\nthat by living together as couples, there can be commonly co-regulated genes\nthat may reflect the shared living environment (e.g., diet, indoor air\npollutants, behavioral lifestyle). The lymphoblastoid cell lines (LCLs) derived\nfrom unrelated couples of African ancestry (YRI, Yoruba people from Ibadan,\nNigeria) from the International HapMap Project provided a unique model for us\nto characterize gene expression pattern in couples by comparing gene expression\nlevels between husbands and wives. Strikingly, 778 genes were found to show\nmuch smaller variances in couples than random pairs of individuals at a false\ndiscovery rate (FDR) of 5%. Since genetic variation between unrelated family\nmembers in a general population is expected to be the same assuming a\nrandom-mating society, non-genetic factors (e.g., epigenetic systems) are more\nlikely to be the mediators for the observed transcriptional similarity in\ncouples. We thus evaluated the contribution of modified cytosines to those\ngenes showing transcriptional similarity in couples as well as the\nrelationships these CpG sites with other gene regulatory elements, such as\ntranscription factor binding sites (TFBS). Our findings suggested that\ntranscriptional similarity in couples likely reflected shared common\nenvironment partially mediated through cytosine modifications.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.07488v1"
    },
    {
        "title": "Controlling the joint local false discovery rate is more powerful than\n  meta-analysis methods in joint analysis of summary statistics from multiple\n  genome-wide association studies",
        "authors": [
            "Wei Jiang",
            "Weichuan Yu"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  In genome-wide association studies (GWASs) of common diseases/traits, we\noften analyze multiple GWASs with the same phenotype together to discover\nassociated genetic variants with higher power. Since it is difficult to access\ndata with detailed individual measurements, summary-statistics-based\nmeta-analysis methods have become popular to jointly analyze data sets from\nmultiple GWASs. In this paper, we propose a novel summary-statistics-based\njoint analysis method based on controlling the joint local false discovery rate\n(Jlfdr). We prove that our method is the most powerful summary-statistics-based\njoint analysis method when controlling the false discovery rate at a certain\nlevel. In particular, the Jlfdr-based method achieves higher power than\ncommonly used meta-analysis methods when analyzing heterogeneous data sets from\nmultiple GWASs. Simulation experiments demonstrate the superior power of our\nmethod over meta-analysis methods. Also, our method discovers more associations\nthan meta-analysis methods from empirical data sets of four phenotypes. The\nR-package is available at: http://bioinformatics.ust.hk/Jlfdr.html.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.08887v1"
    },
    {
        "title": "Dynamic read mapping and online consensus calling for better variant\n  detection",
        "authors": [
            "Karel Břinda",
            "Valentina Boeva",
            "Gregory Kucherov"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Variant detection from high-throughput sequencing data is an essential step\nin identification of alleles involved in complex diseases and cancer. To deal\nwith these massive data, elaborated sequence analysis pipelines are employed. A\ncore component of such pipelines is a read mapping module whose accuracy\nstrongly affects the quality of resulting variant calls.\n  We propose a dynamic read mapping approach that significantly improves read\nalignment accuracy. The general idea of dynamic mapping is to continuously\nupdate the reference sequence on the basis of previously computed read\nalignments. Even though this concept already appeared in the literature, we\nbelieve that our work provides the first comprehensive analysis of this\napproach.\n  To evaluate the benefit of dynamic mapping, we developed a software pipeline\n(http://github.com/karel-brinda/dymas) that mimics different dynamic mapping\nscenarios. The pipeline was applied to compare dynamic mapping with the\nconventional static mapping and, on the other hand, with the so-called\niterative referencing - a computationally expensive procedure computing an\noptimal modification of the reference that maximizes the overall quality of all\nalignments. We conclude that in all alternatives, dynamic mapping results in a\nmuch better accuracy than static mapping, approaching the accuracy of iterative\nreferencing.\n  To correct the reference sequence in the course of dynamic mapping, we\ndeveloped an online consensus caller named OCOCO\n(http://github.com/karel-brinda/ococo). OCOCO is the first consensus caller\ncapable to process input reads in the online fashion.\n  Finally, we provide conclusions about the feasibility of dynamic mapping and\ndiscuss main obstacles that have to be overcome to implement it. We also review\na wide range of possible applications of dynamic mapping with a special\nemphasis on variant detection.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.09070v1"
    },
    {
        "title": "Convolutional Kitchen Sinks for Transcription Factor Binding Site\n  Prediction",
        "authors": [
            "Alyssa Morrow",
            "Vaishaal Shankar",
            "Devin Petersohn",
            "Anthony Joseph",
            "Benjamin Recht",
            "Nir Yosef"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We present a simple and efficient method for prediction of transcription\nfactor binding sites from DNA sequence. Our method computes a random\napproximation of a convolutional kernel feature map from DNA sequence and then\nlearns a linear model from the approximated feature map. Our method outperforms\nstate-of-the-art deep learning methods on five out of six test datasets from\nthe ENCODE consortium, while training in less than one eighth the time.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.00125v1"
    },
    {
        "title": "Relation between Insertion Sequences and Genome Rearrangements in\n  Pseudomonas aeruginosa",
        "authors": [
            "Huda Al-Nayyef",
            "Christophe Guyeux",
            "Marie Petitjean",
            "Didier Hocquet",
            "Jacques M. Bahi"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  During evolution of microorganisms genomes underwork have different changes\nin their lengths, gene orders, and gene contents. Investigating these\nstructural rearrangements helps to understand how genomes have been modified\nover time. Some elements that play an important role in genome rearrangements\nare called insertion sequences (ISs), they are the simplest types of\ntransposable elements (TEs) that widely spread within prokaryotic genomes. ISs\ncan be defined as DNA segments that have the ability to move (cut and paste)\nthemselves to another location within the same chromosome or not. Due to their\nability to move around, they are often presented as responsible of some of\nthese genomic recombination. Authors of this research work have regarded this\nclaim, by checking if a relation between insertion sequences (ISs) and genome\nrearrangements can be found. To achieve this goal, a new pipeline that combines\nvarious tools have firstly been designed, for detecting the distribution of\nORFs that belongs to each IS category. Secondly, links between these predicted\nISs and observed rearrangements of two close genomes have been investigated, by\nseeing them with the naked eye, and by using computational approaches. The\nproposal has been tested on 18 complete bacterial genomes of Pseudomonas\naeruginosa, leading to the conclusion that IS3 family of insertion sequences\nare related to genomic inversions.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.08119v1"
    },
    {
        "title": "Genetic variation in human drug-related genes",
        "authors": [
            "Charlotta P. I. Schärfe",
            "Roman Tremmel",
            "Matthias Schwab",
            "Oliver Kohlbacher",
            "Debora S. Marks"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Variability in drug efficacy and adverse effects are observed in clinical\npractice. While the extent of genetic variability in classical pharmacokinetic\ngenes is rather well understood, the role of genetic variation in drug targets\nis typically less studied. Based on 60,706 human exomes from the ExAC dataset,\nwe performed an in-depth computational analysis of the prevalence of\nfunctional-variants in in 806 drug-related genes, including 628 known drug\ntargets. We find that most genetic variants in these genes are very rare (f <\n0.1%) and thus likely not observed in clinical trials. Overall, however, four\nin five patients are likely to carry a functional-variant in a target for\ncommonly prescribed drugs and many of these might alter drug efficacy. We\nfurther computed the likelihood of 1,236 FDA approved drugs to be affected by\nfunctional-variants in their targets and show that the patient-risk varies for\nmany drugs with respect to geographic ancestry. A focused analysis of\noncological drug targets indicates that the probability of a patient carrying\ngermline variants in oncological drug targets is with 44% high enough to\nsuggest that not only somatic alterations, but also germline variants carried\nover into the tumor genome should be included in therapeutic decision-making.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.08238v1"
    },
    {
        "title": "A Pipeline for Insertion Sequence Detection and Study for Bacterial\n  Genome",
        "authors": [
            "Huda Al-Nayyef",
            "Christophe Guyeux",
            "Jacques M. Bahi"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Insertion Sequences (ISs) are small DNA segments that have the ability of\nmoving themselves into genomes. These types of mobile genetic elements (MGEs)\nseem to play an essential role in genomes rearrangements and evolution of\nprokaryotic genomes, but the tools that deal with discovering ISs in an\nefficient and accurate way are still too few and not totally precise. Two main\nfactors have big effects on IS discovery, namely: genes annotation and\nfunctionality prediction. Indeed, some specific genes called \"transposases\" are\nenzymes that are responsible of the production and catalysis for such\ntransposition, but there is currently no fully accurate method that could\ndecide whether a given predicted gene is either a real transposase or not. This\nis why authors of this article aim at designing a novel pipeline for ISs\ndetection and classification, which embeds the most recently available tools\ndeveloped in this field of research, namely OASIS (Optimized Annotation System\nfor Insertion Sequence) and ISFinder database (an up-to-date and accurate\nrepository of known insertion sequences). As this latter depend on predicted\ncoding sequences, the proposed pipeline will encompass too various kinds of\nbacterial genes annotation tools (that is, Prokka, BASys, and Prodigal). A\ncomplete IS detection and classification pipeline is then proposed and tested\non a set of 23 complete genomes of Pseudomonas aeruginosa. This pipeline can\nalso be used as an investigator of annotation tools performance, which has led\nus to conclude that Prodigal is the best software for IS prediction. A deepen\nstudy regarding IS elements in P.aeruginosa has then been conducted, leading to\nthe conclusion that close genomes inside this species have also a close numbers\nof IS families and groups.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.08267v1"
    },
    {
        "title": "A Stochastic Model for the Formation of Spatial Methylation Patterns",
        "authors": [
            "Alexander Lück",
            "Pascal Giehr",
            "Jörn Walter",
            "Verena Wolf"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  DNA methylation is an epigenetic mechanism whose important role in\ndevelopment has been widely recognized. This epigenetic modification results in\nheritable changes in gene expression not encoded by the DNA sequence. The\nunderlying mechanisms controlling DNA methylation are only partly understood\nand recently different mechanistic models of enzyme activities responsible for\nDNA methylation have been proposed. Here we extend existing Hidden Markov\nModels (HMMs) for DNA methylation by describing the occurrence of spatial\nmethylation patterns over time and propose several models with different\nneighborhood dependencies. We perform numerical analysis of the HMMs applied to\nbisulfite sequencing measurements and accurately predict wild-type data. In\naddition, we find evidence that the enzymes' activities depend on the left 5'\nneighborhood but not on the right 3' neighborhood.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.10145v2"
    },
    {
        "title": "Evolution of biosequence search algorithms: a brief survey",
        "authors": [
            "Gregory Kucherov"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The paper surveys the evolution of main algorithmic techniques to compare and\nsearch biological sequences. We highlight key algorithmic ideas emerged in\nresponse to several interconnected factors: shifts of biological analytical\nparadigm, advent of new sequencing technologies, and a substantial increase in\nsize of the available data. We discuss the expansion of alignment-free\ntechniques coming to replace alignment-based algorithms in large-scale\nanalyses. We further emphasize recently emerged and growing applications of\nsketching methods which support comparison of massive datasets, such as\nmetagenomics samples. Finally, we focus on the transition to population\ngenomics and outline associated algorithmic challenges.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.01038v4"
    },
    {
        "title": "Quantitative and functional post-translational modification proteomics\n  reveals that TREPH1 plays a role in plant thigmomorphogenesis",
        "authors": [
            "Kai Wang",
            "Zhu Yang",
            "Dongjin Qing",
            "Feng Ren",
            "Shichang Liu",
            "Qingsong Zheng",
            "Jun Liu",
            "Weiping Zhang",
            "Chen Dai",
            "Madeline Wu",
            "E. Wassim Chehab",
            "Janet Braam",
            "Ning Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Plants can sense both intracellular and extracellular mechanical forces and\ncan respond through morphological changes. The signaling components responsible\nfor mechanotransduction of the touch response are largely unknown. Here, we\nperformed a high-throughput SILIA (stable isotope labeling in\nArabidopsis)-based quantitative phosphoproteomics analysis to profile changes\nin protein phosphorylation resulting from 40 seconds of force stimulation in\nArabidopsis thaliana. Of the 24 touch-responsive phosphopeptides identified,\nmany were derived from kinases, phosphatases, cytoskeleton proteins, membrane\nproteins and ion transporters. TOUCH-REGULATED PHOSPHOPROTEIN1 (TREPH1) and MAP\nKINASE KINASE 2 (MKK2) and/or MKK1 became rapidly phosphorylated in\ntouch-stimulated plants. Both TREPH1 and MKK2 are required for touch-induced\ndelayed flowering, a major component of thigmomorphogenesis. The treph1-1 and\nmkk2 mutants also exhibited defects in touch-inducible gene expression. A\nnon-phosphorylatable site-specific isoform of TREPH1 (S625A) failed to restore\ntouch-induced flowering delay of treph1-1, indicating the necessity of S625 for\nTREPH1 function and providing evidence consistent with the possible functional\nrelevance of the touch-regulated TREPH1 phosphorylation. Bioinformatic analysis\nand biochemical subcellular fractionation of TREPH1 protein indicate that it is\na soluble protein. Altogether, these findings identify new protein players in\nArabidopsis thigmomorphogenesis regulation, suggesting that protein\nphosphorylation may play a critical role in plant force responses.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.04113v1"
    },
    {
        "title": "SSCU: an R/Bioconductor package for analyzing selective profile in\n  synonymous codon usage",
        "authors": [
            "Yu Sun",
            "Siv G. E. Andersson"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Background Synonymous codon choice is mainly affected by mutation and\nselection. For the majority of genes within a genome, mutational pressure is\nthe major driving force, but selective strength can be strong and dominant for\nspecific set of genes or codons. More specifically, the selective strength on\ntranslational efficiency and accuracy increases with the gene's expression\nlevel. Many statistical approaches have been developed to evaluate and quantify\nthe selective profile in codon usage, including S index and Akashi's test, but\nno program or pipeline has been developed that includes these tests and\nautomates the calculation.\n  Results In this study, we release an R package SSCU (selective strength for\ncodon usage, v2.4.0), which includes tools for codon usage analyses. The\npackage identifies optimal codons using two approaches (comparative and\ncorrelative methods), implements well-established statistics for detecting\ncodon selection, such as S index, Akashi's test, and estimates standard genomic\nstatistics, such as genomic GC3, RSCU and Nc.\n  Conclusions The package is useful for researchers working on the codon usage\nanalysis, and thus has general interest to the biological research community.\nThe package is deposited and curated at the Bioconductor site, and has\ncurrently been downloaded for more than 2000 times and ranked as top 50%\npackages.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.07259v1"
    },
    {
        "title": "Pharmacogenomics in the Age of GWAS, Omics Atlases, and PheWAS",
        "authors": [
            "Ari Allyn-Feuer",
            "Gerald A. Higgins",
            "Brian D. Athey"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The search for causative pharmacogenomic loci is being transformed by\nintegrative omics pipelines, but their outputs have only begun being applied to\ntest design. We assess the direction of the field in light of Biobanks/PheWAS,\nomics atlases, and AI. We first assess the potential of recent epigenome and\nspatial genome concepts, datasets, and methods to improve the functionality of\nPIP-style pipelines. We then discuss new potential methods of genetic test\ndesign on the basis of the outputs of such pipelines. We conclude with a vision\nfor a pharmacophenomic atlas, in which omics atlas data, PheWAS associations,\nand biobank data would be used with AI to design thousands of genetic tests for\nclinical deployment in an automated parallel process.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.09481v1"
    },
    {
        "title": "Whole genome resequencing reveals diagnostic markers for investigating\n  global migration and hybridization between minke whale species",
        "authors": [
            "Ketil Malde",
            "Bjørghild B. Seliussen",
            "María Quintela",
            "Geir Dahle",
            "François Besnier",
            "Hans J. Skaug",
            "Nils Øien",
            "Hiroko K. Solvang",
            "Tore Haug",
            "Rasmus Skern-Mauritzen",
            "Naohisa Kanda",
            "Luis A. Pastene",
            "Inge Jonassen",
            "Kevin A. Glover"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Background: In the marine environment, where there are few absolute physical\nbarriers, contemporary contact between previously isolated species can occur\nacross great distances, and in some cases, may be inter-oceanic. [..] in the\nminke whale species complex [...] migrations [..] have been documented and\nfertile hybrids and back-crossed individuals between both species have also\nbeen identified. However, it is not known whether this represents a\ncontemporary event, potentially driven by ecosystem changes in the Antarctic,\nor a sporadic occurrence happening over an evolutionary time-scale. We\nsuccessfully used whole genome resequencing to identify a panel of diagnostic\nSNPs which now enable us address this evolutionary question.\n  Results: A large number of SNPs displaying fixed or nearly fixed allele\nfrequency differences among the minke whale species were identified from the\nsequence data. Five panels of putatively diagnostic markers were established on\na genotyping platform for validation of allele frequencies; two panels (26 and\n24 SNPs) separating the two species of minke whale, and three panels (22, 23,\nand 24 SNPs) differentiating the three subspecies of common minke whale. The\npanels were validated against a set of reference samples, demonstrating the\nability to accurately identify back-crossed whales up to three generations.\n  Conclusions: This work has resulted in the development of a panel of novel\ndiagnostic genetic markers to address inter-oceanic and global contact among\nthe genetically isolated minke whale species and sub-species. These markers,\nincluding a globally relevant genetic reference data set for this species\ncomplex, are now openly available for researchers [..]. The approach used here,\ncombining whole genome resequencing and high-throughput genotyping, represents\na universal approach to develop similar tools for other species and population\ncomplexes.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01992v1"
    },
    {
        "title": "A reproducible effect size is more useful than an irreproducible\n  hypothesis test to analyze high throughput sequencing datasets",
        "authors": [
            "Andrew D. Fernandes",
            "Michael T. H. Q. Vu",
            "Lisa-Monique Edward",
            "Jean M. Macklaim",
            "Gregory B. Gloor"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Motivation: P values derived from the null hypothesis significance testing\nframework are strongly affected by sample size, and are known to be\nirreproducible in underpowered studies, yet no suitable replacement has been\nproposed. Results: Here we present implementations of non-parametric\nstandardized median effect size estimates, dNEF, for high-throughput sequencing\ndatasets. Case studies are shown for transcriptome and tag-sequencing datasets.\nThe dNEF measure is shown to be more reproducible and robust than P values and\nrequires sample sizes as small as 3 to reproducibly identify differentially\nabundant features. Availability: Source code and binaries freely available at:\nhttps://bioconductor.org/packages/ALDEx2.html , omicplotR, and\nhttps://github.com/ggloor/CoDaSeq .\n",
        "pdf_link": "http://arxiv.org/pdf/1809.02623v2"
    },
    {
        "title": "Virus genome sequence classification using features based on\n  nucleotides, words and compression",
        "authors": [
            "T. Wang",
            "M. Herbster",
            "I. S. Mian"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The ICTV develops, refines and maintains a universal virus taxonomy; Order is\nthe highest taxon in the branching hierarchy of recognised viral taxa.\nHistorically, ICTV (sub)committees have classified viruses on the basis of\nmorphological characteristics and various other attributes. Today, virtually\nall new viral genomes are assembled from metagenomic datasets and are not\nlinked directly to biological agents. Thus, placing a virus into a taxonomic\nscheme solely from primary genome structure is an increasingly important\nproblem. Various simple descriptive statistics of a viral genome sequence have\nbeen used successfully for virus classification. Here, we use the NCBI's viral\nand viroid reference sequence collection (RefSeq) and a common experimental\nframework to compare the performance of different genome sequence-derived\nfeatures and classifiers in the task of assigning a virus to one of seven ICTV\nOrders. The nucleotide-, word-, and compression-based features we consider\ninclude genome length, the k-mer Natural Vector (k = 1, ..., 6) and its\nderivatives, return time distribution, and general-purpose and DNA-specific\ncompression ratios; the classifiers used are the k-NN and SVM. The combination\nof genome length and k-NN has the worst, yet still respectable, performance\n(mean error rate of 0.137); the best performance is achieved using 4-mer counts\nand SVM (mean error rate of 0.006). We investigate the main causes of\nmisclassification, explore which viruses are more difficult to classify, and\nuse the best performing combination to predict the Orders of 1,834 unclassified\nviruses. A subsequent version of RefSeq assigned Orders to 17 of these\npreviously unlabelled viruses. Since 16 of our predictions match these\nassignments, our approach could aid virologists dealing with viruses that are\nknown only from sequence data.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.03950v1"
    },
    {
        "title": "Integrated systems approach identifies pathways from the genome to\n  triglycerides through a metabolomic causal network",
        "authors": [
            "Azam Yazdani",
            "Akram Yazdani",
            "Philip L. Lorenzi",
            "Ahmad Samiei"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Introduction: To leverage functionality and clinical relevance into\nunderstanding systems biology, one needs to understand the pathway of the\ngenetic effects on risk factors/disease through intermediate molecular levels,\nsuch as metabolomics. Systems approaches integrate multi-omic information to\nfind pathways to disease endpoints and make optimal inference decisions.\nMethod: Here, we introduce a multi-stage approach to integrate causal networks\nin observational studies and GWAS to facilitate mechanistic understanding\nthrough identification of pathways from the genome to risk factors/disease via\nmetabolomics. The pathways in causal networks reveal the underlying\nrelationships behind observations, which do not play a significant role in more\ntraditional correlative analyses, where one variable at a time is considered.\nResults: We identified a causal network over the metabolomic level using the\ngenome directed acyclic graph (G-DAG), to systematically assess whether\nvariations in the genome lead to variations in triglyceride levels as a risk\nfactor of cardiovascular disease. We found LRRC46 and LRRC69 harboring\nloss-of-function mutations have significant effect on two metabolites with\ndirect effects on triglyceride levels. We also found pathways of FAM198B and\nC6orf25 to triglycerides through indirect paths from metabolites. Conclusion:\nIntegrating causal networks with GWAS facilitates mechanistic understanding in\ncomparison to one-variable-at-a-time approaches due to accounting for\nrelationships among components at intermediate molecular levels. This approach\nis complementary to experimental studies to identify efficacious targets in the\nage of big data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05024v1"
    },
    {
        "title": "Effect of Blast Exposure on Gene-Gene Interactions",
        "authors": [
            "Akram Yazdani"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Repeated exposure to low-level blast may initiate a range of adverse health\nproblem such as traumatic brain injury (TBI). Although many studies\nsuccessfully identified genes associated with TBI, yet the cellular mechanisms\nunderpinning TBI are not fully elucidated. In this study, we investigated\nunderlying relationship among genes through constructing transcript Bayesian\nnetworks using RNA-seq data. The data for pre- and post-blast transcripts,\nwhich were collected on 33 individuals in Army training program, combined with\nour system approach provide unique opportunity to investigate the effect of\nblast-wave exposure on gene-gene interactions. Digging into the networks, we\nidentified four subnetworks related to immune system and inflammatory process\nthat are disrupted due to the exposure. Among genes with relatively high fold\nchange in their transcript expression level, ATP6V1G1, B2M, BCL2A1, PELI,\nS100A8, TRIM58 and ZNF654 showed major impact on the dysregulation of the\ngene-gene interactions. This study reveals how repeated exposures to traumatic\nconditions increase the level of fold change of transcript expression and\nhypothesizes new targets for further experimental studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05095v2"
    },
    {
        "title": "Transient crosslinking kinetics optimize gene cluster interactions",
        "authors": [
            "Benjamin Walker",
            "Dane Taylor",
            "Josh Lawrimore",
            "Caitlin Hult",
            "David Adalsteinsson",
            "Kerry Bloom",
            "M. Gregory Forest"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Our understanding of how chromosomes structurally organize and dynamically\ninteract has been revolutionized through the lens of long-chain polymer\nphysics. Major protein contributors to chromosome structure and dynamics are\ncondensin and cohesin that stochastically generate loops within and between\nchains, and entrap proximal strands of sister chromatids. In this paper, we\nexplore the ability of transient, protein-mediated, gene-gene crosslinks to\ninduce clusters of genes, thereby dynamic architecture, within the highly\nrepeated ribosomal DNA that comprises the nucleolus of budding yeast. We\nimplement three approaches: live cell microscopy; computational modeling of the\nfull genome during G1 in budding yeast, exploring four decades of timescales\nfor transient crosslinks between 5k bp domains in the nucleolus on Chromosome\nXII; and, temporal network models with automated community detection algorithms\napplied to the full range of 4D modeling datasets. The data analysis tools\ndetect and track gene clusters, their size, number, persistence time, and their\nplasticity. Of biological significance, our analysis reveals an optimal mean\ncrosslink lifetime that promotes pairwise and cluster gene interactions through\n\"flexible\" clustering. In this state, large gene clusters self-assemble yet\nfrequently interact, marked by gene exchanges between clusters, which in turn\nmaximizes global gene interactions in the nucleolus. This regime stands between\ntwo limiting cases each with far less global gene interactions: with shorter\ncrosslink lifetimes, \"rigid\" clustering emerges with clusters that interact\ninfrequently; with longer crosslink lifetimes, there is a dissolution of\nclusters. These observations are compared with imaging experiments on a normal\nyeast strain and two condensin-modified mutant cell strains, applying the same\nimage analysis pipeline to the experimental and simulated datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06928v3"
    },
    {
        "title": "Integrating splice-isoform expression into genome-scale models\n  characterizes breast cancer metabolism",
        "authors": [
            "Claudio Angione"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Motivation: Despite being often perceived as the main contributors to cell\nfate and physiology, genes alone cannot predict cellular phenotype. During the\nprocess of gene expression, 95% of human genes can code for multiple proteins\ndue to alternative splicing. While most splice variants of a gene carry the\nsame function, variants within some key genes can have remarkably different\nroles. To bridge the gap between genotype and phenotype, condition- and\ntissue-specific models of metabolism have been constructed. However, current\nmetabolic models only include information at the gene level. Consequently, as\nrecently acknowledged by the scientific community, common situations where\nchanges in splice-isoform expression levels alter the metabolic outcome cannot\nbe modeled. Results: We here propose GEMsplice, the first method for the\nincorporation of splice-isoform expression data into genome-scale metabolic\nmodels. Using GEMsplice, we make full use of RNA-Seq quantitative expression\nprofiles to predict, for the first time, the effects of splice isoform-level\nchanges in the metabolism of 1455 patients with 31 different breast cancer\ntypes. We validate GEMsplice by generating cancer-versus-normal predictions on\nmetabolic pathways, and by comparing with gene-level approaches and available\nliterature on pathways affected by breast cancer. GEMsplice is freely available\nfor academic use at https://github.com/GEMsplice/GEMsplice_code. Compared to\nstate-of-the-art methods, we anticipate that GEMsplice will enable for the\nfirst time computational analyses at transcript level with splice-isoform\nresolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.08289v1"
    },
    {
        "title": "Searching by index for similar sequences: the SEQR algorithm",
        "authors": [
            "David I. Hurwitz",
            "Lianyi Han",
            "Lewis Y. Geer"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  This paper describes a method to efficiently retrieve protein database\nsequences similar to a query sequence, while allowing for significant numbers\nof mutations. We call this method SEQR for SEQuence Retrieval. This approach\nincreases the speed of sequence similarity searches by an order of magnitude\ncompared to conventional algorithms at the expense of sensitivity. Furthermore,\nretrieval time increases less than linearly with the number of sequences, a\ndesirable property during an era when next generation sequencing technologies\nhave yielded greater than exponential increases in sequence records. The lower\nsensitivity of the algorithm for distantly related sequences compared to\nbenchmarks is not intrinsic to the method itself, but rather due to the\nprocedure used to construct the indexing terms, and may be improved. The\nindexing terms themselves can be added to standard information retrieval\nengines, enabling complex queries that include sequence similarity and other\ndescriptors such as taxonomy and text descriptions.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.00931v1"
    },
    {
        "title": "Linking de novo assembly results with long DNA reads by dnaasm-link\n  application",
        "authors": [
            "Wiktor Kuśmirek",
            "Wiktor Franus",
            "Robert Nowak"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Currently, third-generation sequencing techniques, which allow to obtain much\nlonger DNA reads compared to the next-generation sequencing technologies, are\nbecoming more and more popular. There are many possibilities to combine data\nfrom next-generation and third-generation sequencing.\n  Herein, we present a new application called dnaasm-link for linking contigs,\na result of \\textit{de novo} assembly of second-generation sequencing data,\nwith long DNA reads. Our tool includes an integrated module to fill gaps with a\nsuitable fragment of appropriate long DNA read, which improves the consistency\nof the resulting DNA sequences. This feature is very important, in particular\nfor complex DNA regions, as presented in the paper. Finally, our implementation\noutperforms other state-of-the-art tools in terms of speed and memory\nrequirements, which may enable the usage of the presented application for\norganisms with a large genome, which is not possible in~existing applications.\n  The presented application has many advantages as (i) significant memory\noptimization and reduction of computation time (ii) filling the gaps through\nthe appropriate fragment of a specified long DNA read (iii) reducing number of\nspanned and unspanned gaps in the existing genome drafts.\n  The application is freely available to all users under GNU Library or Lesser\nGeneral Public License version 3.0 (LGPLv3). The demo application, docker image\nand source code are available at http://dnaasm.sourceforge.net.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05456v1"
    },
    {
        "title": "DNA methylation markers to assess biological age",
        "authors": [
            "Dmitriy I. Podolskiy",
            "Vadim N. Gladyshev"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Among the different biomarkers of aging based on omics and clinical data, DNA\nmethylation clocks stand apart providing unmatched accuracy in assessing the\nbiological age of both humans and animal models of aging. Here, we discuss\nrobustness of DNA methylation clocks and bounds on their out-of-sample\nperformance and review computational strategies for development of the clocks.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06018v1"
    },
    {
        "title": "JS-MA: A Jensen-Shannon Divergence Based Method for Mapping Genome-wide\n  Associations on Multiple Diseases",
        "authors": [
            "Xuan Guo"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Taking advantages of high-throughput genotyping technology of single\nnucleotide polymorphism (SNP), large genome-wide association studies (GWASs)\nhave been considered as the promise to unravel the complex relationships\nbetween genotypes and phenotypes, in particularly common diseases. However,\ncurrent multi-locus-based methods are insufficient, in terms of computational\ncost and discrimination power, to detect statistically significant interactions\nand they are lacking in the ability of finding diverse genetic effects on\nmultifarious diseases. Especially, multiple statistic tests for high-order\nepistasis ($ \\geq $ 2 SNPs) will raise huge analytical challenges because the\ncomputational cost increases exponentially as the growth of the cardinality of\nSNPs in an epistatic module. In this paper, we develop a simple, fast and\npowerful method, named JS-MA, using the Jensen-Shannon divergence and a\nhigh-dimensional $ k $-mean clustering algorithm for mapping the genome-wide\nmulti-locus epistatic interactions on multiple diseases. Compared with some\nstate-of-the-art association mapping tools, our method is demonstrated to be\nmore powerful and efficient from the experimental results on the systematical\nsimulations. We also applied JS-MA to the GWAS datasets from WTCCC for two\ncommon diseases, i.e. Rheumatoid Arthritis and Type 1 Diabetes. JS-MA not only\nconfirms some recently reported biologically meaningful associations but also\nidentifies some novel findings. Therefore, we believe that our method is\nsuitable and efficient for the full-scale analysis of multi-disease-related\ninteractions in the large GWASs.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07099v1"
    },
    {
        "title": "A Multi-Trait Approach Identified Genetic Variants Including a Rare\n  Mutation in RGS3 with Impact on Abnormalities of Cardiac Structure/Function",
        "authors": [
            "Akram Yazdani",
            "Azam Yazdani",
            "Raúl Méndez Giráldez",
            "David Aguilar",
            "Luca Sartore"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Heart failure is a major cause for premature death. Given heterogeneity of\nthe heart failure syndrome, identifying genetic determinants of cardiac\nfunction and structure may provide greater insights into heart failure. Despite\nprogress in understanding the genetic basis of heart failure through genome\nwide association studies, heritability of heart failure is not well understood.\nGaining further insights into mechanisms that contribute to heart failure\nrequires systematic approaches that go beyond single trait analysis. We\nintegrated Bayesian multi-trait approach and Bayesian networks for the analysis\nof 10 correlated traits of cardiac structure and function measured for 3387\nindividuals with whole exome sequence data. While using single-trait based\napproaches did not find any significant genetic variant, applying the\nintegrative Bayesian multi-trait approach, we identified 3 novel variants\nlocated in genes, RGS3, CHD3, and MRPL38 with significant impact on the cardiac\ntraits such as left ventricular volume index, parasternal long axis\ninterventricular septum thickness, and mean left ventricular wall thickness.\nAmong these, the rare variant NC_000009.11:g.116346115C>A (rs144636307) in RGS3\nshowed pleiotropic effect on left ventricular mass index, left ventricular\nvolume index and Maximum left atrial anterior-posterior diameter while RGS3 can\ninhibit TGF-beta signaling associated with left ventricle dilation and systolic\ndysfunction.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07838v1"
    },
    {
        "title": "Private Shotgun DNA Sequencing",
        "authors": [
            "Ali Gholami",
            "Mohammad Ali Maddah-Ali",
            "Seyed Abolfazl Motahari"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Current techniques in sequencing a genome allow a service provider (e.g. a\nsequencing company) to have full access to the genome information, and thus the\nprivacy of individuals regarding their lifetime secret is violated. In this\npaper, we introduce the problem of private DNA sequencing, where the goal is to\nkeep the DNA sequence private to the sequencer. We propose an architecture,\nwhere the task of reading fragments of DNA and the task of DNA assembly are\nseparated, the former is done at the sequencer(s), and the later is completed\nat a local trusted data collector. To satisfy the privacy constraint at the\nsequencer and reconstruction condition at the data collector, we create an\ninformation gap between these two relying on two techniques: (i) we use more\nthan one non-colluding sequencer, all reporting the read fragments to the\nsingle data collector, (ii) adding the fragments of some known DNA molecules,\nwhich are still unknown to the sequencers, to the pool. We prove that these two\ntechniques provide enough freedom to satisfy both conditions at the same time.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.10693v1"
    },
    {
        "title": "De novo inference of diversity genes and analysis of non-canonical\n  V(DD)J recombination in immunoglobulins",
        "authors": [
            "Yana Safonova",
            "Pavel A. Pevzner"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The V(D)J recombination forms the immunoglobulin genes by joining the\nvariable (V), diversity (D), and joining (J) germline genes. Since variations\nin germline genes have been linked to various diseases, personalized\nimmunogenomics aims at finding alleles of germline genes across various\npatients. Although recent studies described algorithms for de novo inference of\nV and J genes from immunosequencing data, they stopped short of solving a more\ndifficult problem of reconstructing D genes that form the highly divergent CDR3\nregions and provide the most important contribution to the antigen binding. We\npresent the IgScout algorithm for de novo D gene reconstruction and apply it to\nreveal new alleles of human D genes and previously unknown D genes in camel, an\nimportant model organism in immunology. We further analyze non-canonical V(DD)J\nrecombination that results in unusually long tandem CDR3s and thus expands the\ndiversity of the antibody repertoires. We demonstrate that tandem CDR3s\nrepresent a consistent and functional feature of all analyzed immunosequencing\ndatasets, reveal ultra-long tandem CDR3s, and shed light on the mechanism\nresponsible for their formation.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.02483v1"
    },
    {
        "title": "A Hybrid HMM Approach for the Dynamics of DNA Methylation",
        "authors": [
            "Charalampos Kyriakopoulos",
            "Pascal Giehr",
            "Alexander Lück",
            "Jörn Walter",
            "Verena Wolf"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The understanding of mechanisms that control epigenetic changes is an\nimportant research area in modern functional biology. Epigenetic modifications\nsuch as DNA methylation are in general very stable over many cell divisions.\nDNA methylation can however be subject to specific and fast changes over a\nshort time scale even in non-dividing (i.e. not-replicating) cells. Such\ndynamic DNA methylation changes are caused by a combination of active\ndemethylation and de novo methylation processes which have not been\ninvestigated in integrated models. Here we present a hybrid (hidden) Markov\nmodel to describe the cycle of methylation and demethylation over (short) time\nscales. Our hybrid model decribes several molecular events either happening at\ndeterministic points (i.e. describing mechanisms that occur only during cell\ndivision) and other events occurring at random time points. We test our model\non mouse embryonic stem cells using time-resolved data. We predict methylation\nchanges and estimate the efficiencies of the different modification steps\nrelated to DNA methylation and demethylation.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.06286v1"
    },
    {
        "title": "Identifying centromeric satellites with dna-brnn",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Summary: Human alpha satellite and satellite 2/3 contribute to several\npercent of the human genome. However, identifying these sequences with\ntraditional algorithms is computationally intensive. Here we develop dna-brnn,\na recurrent neural network to learn the sequences of the two classes of\ncentromeric repeats. It achieves high similarity to RepeatMasker and is times\nfaster. Dna-brnn explores a novel application of deep learning and may\naccelerate the study of the evolution of the two repeat classes.\n  Availability and implementation: https://github.com/lh3/dna-nn\n  Contact: hli@jimmy.harvard.edu\n",
        "pdf_link": "http://arxiv.org/pdf/1901.07327v2"
    },
    {
        "title": "Proteomic and metagenomic insights into prehistoric Spanish Levantine\n  Rock Art",
        "authors": [
            "Clodoaldo Roldán",
            "Sonia Murcia-Mascarós",
            "Esther López-Montalvo",
            "Cristina Vilanova",
            "Manuel Porcar"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The Iberian Mediterranean Basin is home to one of the largest groups of\nprehistoric rock art sites in Europe. Despite the cultural relevance of\nprehistoric Spanish Levantine rock art, pigment composition remains partially\nunknown, and the nature of the binders used for painting has yet to be\ndisclosed. In this work, we present the first omic analysis applied to one of\nthe flagship Levantine rock art sites: the Valltorta ravine (Castell{\\'o}n,\nSpain). We used high-throughput sequencing to provide the first description of\nthe bacterial communities colonizing the rock art patina, which proved to be\ndominated by Firmicutes species and might have a protective effect on the\npaintings. Proteomic analysis was also performed on rock art microsamples in\norder to determine the organic binders present in Levantine prehistoric rock\nart pigments. This information could shed light on the controversial dating of\nthis UNESCO Cultural Heritage, and contribute to defining the chrono-cultural\nframework of the societies responsible for these paintings.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11160v1"
    },
    {
        "title": "Predicting Gene Expression Between Species with Neural Networks",
        "authors": [
            "Peter Eastman",
            "Vijay S. Pande"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  We train a neural network to predict human gene expression levels based on\nexperimental data for rat cells. The network is trained with paired human/rat\nsamples from the Open TG-GATES database, where paired samples were treated with\nthe same compound at the same dose. When evaluated on a test set of held out\ncompounds, the network successfully predicts human expression levels. On the\nmajority of the test compounds, the list of differentially expressed genes\ndetermined from predicted expression levels agrees well with the list of\ndifferentially expressed genes determined from actual human experimental data.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.03041v1"
    },
    {
        "title": "SpliceCombo: A Hybrid Technique efficiently use for Principal Component\n  Analysis of Splice Site Prediction",
        "authors": [
            "Srabanti Maji",
            "Soumen Kanrar"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The primary step in search of the gene prediction is an identification of the\ncoding region from genomic DNA sequence. Gene structure in the case of a\neukaryotic organism is composed of promoter, intron, start codon, exons, stop\ncodon, etc. Splice site prediction, which separates the junction between exon\nand intron, though the sequence beside. The splice sites have huge\npreservation, however, the precision of the tool exhibits less than 90%. The\nmain objective of this work to exhibits a hybrid technique that efficiently\nimproves the existing gene recognition technique. Therefore to enhance the\nidentification of splice sites, the respective algorithm needs to be improved.\nOver the last decade, the researcher paid more attention to improve the\naccuracy of a predicted model in this domain. Our proposed method, SpliceCombo\ninvolves three stages. At initial stage, which considers the principal\nComponent Analysis, based on the feature extracted. In the intermediate stage,\ni.e.,, the second stage Case- Based Reasoning is done, i.e., feature selection.\nThe third stage uses support vector machine based along with polynomial kernel\nfunction for final classification. In comparison with other methods, the\nproposed SpliceCombo model outperforms other prediction models with respect to\nprediction accuracies. Particularly for donor splice site the methodology\nexhibits sensitivity is 97.25% accurate and specificity is 97.46% accurate. For\nacceptor Splice Site the sensitivity is 96.51% and Specificity is 94.48%\ncorrect.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.09401v1"
    },
    {
        "title": "ReadsClean: a new approach to error correction of sequencing reads based\n  on alignments clustering",
        "authors": [
            "Oleg Fokin",
            "Anastasia Bakulina",
            "Igor Seledtsov",
            "Victor Solovyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Motivation: Next generation methods of DNA sequencing produce relatively high\nrate of reading errors, which interfere with de novo genome assembly of newly\nsequenced organisms and particularly affect the quality of SNP detection\nimportant for diagnostics of many hereditary diseases. There exists a number of\nprograms developed for correcting errors in NGS reads. Such programs utilize\nvarious approaches and are optimized for different specific tasks, but all of\nthem are far from being able to correct all errors, especially in sequencing\nreads that crossing by repeats and DNA from di/polyploid eukaryotic genomes.\nResults: This paper describes a novel method of error correction based on\nclustering of alignments of similar reads. This method is implemented in\nReadsClean program, which is designed for cleaning Illumina HiSeq sequencing\nreads. We compared ReadsClean to other reads cleaning programs recognized to be\nthe best by several publications. Our sequence assembly tests using actual and\nsimulated sequencing reads show superior results achieved by ReadsClean.\nAvailability and implementation: ReadsClean is implemented as a standalone C\ncode. It is incorporated in an error correction pipeline and is freely\navailable to academic users at Softberry web server www.softberry.com.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12718v1"
    },
    {
        "title": "AFDP: An Automated Function Description Prediction Approach to Improve\n  Accuracy of Protein Function Predictions",
        "authors": [
            "Samaneh Jozashoori",
            "Amir Jozashoori",
            "Heiko Schoof"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  With the rapid growth in high-throughput biological sequencing technologies\nand subsequently the amount of produced omics data, it is essential to develop\nautomated methods to annotate the functionality of unknown genes and proteins.\nThere are developed tools such as AHRD applying known proteins characterization\nto annotate unknown ones. Some other algorithms such as eggNOG apply\northologous groups of proteins to detect the most probable function. However,\nwhile the available tools focus on the detection of the most similar\ncharacterization, they are not able to generalize and integrate information\nfrom multiple homologs while maintaining accuracy. Here, we devise AFDP, an\nintegrated approach for protein function prediction which benefits from the\ncombination of two available tools, AHRD and eggNOG, to predict the\nfunctionality of novel proteins and produce more precise human readable\ndescriptions by applying our stCFExt algorithm. StCFExt creates function\ndescriptions applying available manually curated descriptions in swiss-prot.\nUsing a benchmark dataset we show that the annotations predicted by our\napproach are more accurate than eggNOG and AHRD annotations.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.06965v1"
    },
    {
        "title": "A Stochastic Automata Network Description for Spatial DNA-Methylation\n  Models",
        "authors": [
            "Alexander Lück",
            "Verena Wolf"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  DNA methylation is an important biological mechanism to regulate gene\nexpression and control cell development. Mechanistic modeling has become a\npopular approach to enhance our understanding of the dynamics of methylation\npattern formation in living cells. Recent findings suggest that the methylation\nstate of a cytosine base can be influenced by its DNA neighborhood. Therefore,\nit is necessary to generalize existing mathematical models that consider only\none cytosine and its partner on the opposite DNA-strand (CpG), in order to\ninclude such neighborhood dependencies. One approach is to describe the system\nas a stochastic automata network (SAN) with functional transitions. We show\nthat single-CpG models can successfully be generalized to multiple CpGs using\nthe SAN description and verify the results by comparing them to results from\nextensive Monte-Carlo simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.10968v1"
    },
    {
        "title": "CD44 alternative splicing is a sensor of intragenic DNA methylation in\n  tumors",
        "authors": [
            "Eric Batsché",
            "Oriane Mauger",
            "Etienne Kornobis",
            "Benjamin Hopkins",
            "Charlotte Hanmer-Lloyd",
            "Christian Muchardt"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  DNA methylation (meDNA) is a suspected modulator of alternative splicing,\nwhile splicing in turn is involved in tumour formations nearly as frequently as\nDNA mutations. Yet, the impact of meDNA on tumorigenesis via its effect on\nsplicing has not been thoroughly explored. Here, we find that HCT116 colon\ncarcinoma cells inactivated for the DNA methylases DNMT1 and DNMT3b undergo a\npartial epithelial to mesenchymal transition (EMT) associated with alternative\nsplicing of the CD44 transmembrane receptor. The skipping of CD44 variant exons\nis in part explained by altered expression or splicing of splicing and\nchromatin factors. A direct effect of meDNA on alternative splicing was\nsustained by transient depletion of DNMT1 and the methyl-binding genes MBD1,\nMBD2, and MBD3. Yet, local changes in intragenic meDNA also altered recruitment\nof MBD1 protein and of the chromatin factor HP1$\\gamma$ known to alter\ntranscriptional pausing and alternative splicing decisions. We further tested\nif meDNA level has sufficiently strong direct impact on the outcome of\nalternative splicing to have a predictive value in the MCF10A model for breast\ncancer progression and in patients with acute lymphoblastic leukemia (B ALL).\nWe found that a small number of differentially spliced genes mostly involved in\nsplicing and signal transduction is systematically correlated with local meDNA.\nAltogether, our observations suggest that, although DNA methylation has\nmultiple avenues to alternative splicing, its indirect effect may be also\nmediated through alternative splicing isoforms of these sensors of meDNA.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11180v1"
    },
    {
        "title": "Primary and secondary anti-viral response captured by the dynamics and\n  phenotype of individual T cell clones",
        "authors": [
            "Anastasia A. Minervina",
            "Mikhail V. Pogorelyy",
            "Ekaterina A. Komech",
            "Vadim K. Karnaukhov",
            "Petra Bacher",
            "Elisa Rosati",
            "Andre Franke",
            "Dmitriy M. Chudakov",
            "Ilgar Z. Mamedov",
            "Yuri B. Lebedev",
            "Thierry Mora",
            "Aleksandra M. Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The diverse repertoire of T-cell receptors (TCR) plays a key role in the\nadaptive immune response to infections. Previous studies show that secondary\nresponses to the yellow fever vaccine - the model for acute infection in humans\n- are weaker than primary ones, but only quantitative measurements can describe\nthe concentration changes and lineage fates for distinct T-cell clones in vivo\nover time. Using TCR alpha and beta repertoire sequencing for T-cell subsets,\nas well as single-cell RNAseq and TCRseq, we track the concentrations and\nphenotypes of individual T-cell clones in response to primary and secondary\nyellow fever immunization showing their large diversity. We confirm the\nsecondary response is an order of magnitude weaker, albeit $\\sim10$ days faster\nthan the primary one. Estimating the fraction of the T-cell response directed\nagainst the single immunodominant epitope, we identify the sequence features of\nTCRs that define the high precursor frequency of the two major TCR motifs\nspecific for this particular epitope. We also show the consistency of clonal\nexpansion dynamics between bulk alpha and beta repertoires, using a new\nmethodology to reconstruct alpha-beta pairings from clonal trajectories.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11928v2"
    },
    {
        "title": "Guidelines for reporting single-cell RNA-Seq experiments",
        "authors": [
            "Anja Füllgrabe",
            "Nancy George",
            "Matthew Green",
            "Parisa Nejad",
            "Bruce Aronow",
            "Laura Clarke",
            "Silvie Korena Fexova",
            "Clay Fischer",
            "Mallory Ann Freeberg",
            "Laura Huerta",
            "Norman Morrison",
            "Richard H. Scheuermann",
            "Deanne Taylor",
            "Nicole Vasilevsky",
            "Nils Gehlenborg",
            "John Marioni",
            "Sarah Teichmann",
            "Alvis Brazma",
            "Irene Papatheodorou"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Single-cell RNA-Sequencing (scRNA-Seq) has undergone major technological\nadvances in recent years, enabling the conception of various organism-level\ncell atlassing projects. With increasing numbers of datasets being deposited in\npublic archives, there is a need to address the challenges of enabling the\nreproducibility of such data sets. Here, we describe guidelines for a minimum\nset of metadata to sufficiently describe scRNA-Seq experiments, ensuring\nreproducibility of data analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.14623v1"
    },
    {
        "title": "Phylogenetic Study of 2019-nCoV by Using Alignment Free Method\n  (Evolutionary Bifurcation of Novel Coronavirus Mutants)",
        "authors": [
            "Yang Gao",
            "Tao Li",
            "Liaofu Luo"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The phylogenetic tree of SARS-CoV-2 (nCov-19) viruses is reconstructed\naccording to the similarity of genome sequences. The tree topology of\nBetacoronavirus is remarkably consistent with biologist's systematics. Because\nthe tree construction contains enough information about virus mutants, it is\nsuitable to study the evolutionary relationship between novel coronavirus\nmutants transmitted among humans. The emergences of 14 kinds of main mutants\nare studied and these strains can be classified as eight bifurcations of the\nphylogenetic tree. It is found that there exist three types of virus mutations,\nnamely, the mutation among sub-branches of the same branch, the off-root\nmutation and the root-oriented mutation between large branches of the tree.\nFrom the point of the relation between viral mutation and host selection we\nfound that individuals with low immunity provide a special environment for the\npositive natural selection of virus evolution. It gives a mechanism to explain\nwhy large mutations between two distant branches generally occur in the nCov-19\nphylogenetic tree. The finding is helpful to formulate strategies to control\nthe spread of COVID-19.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.01324v3"
    },
    {
        "title": "The design and construction of reference pangenome graphs",
        "authors": [
            "Heng Li",
            "Xiaowen Feng",
            "Chong Chu"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The recent advances in sequencing technologies enables the assembly of\nindividual genomes to the reference quality. How to integrate multiple genomes\nfrom the same species and to make the integrated representation accessible to\nbiologists remain an open challenge. Here we propose a graph-based data model\nand associated formats to represent multiple genomes while preserving the\ncoordinate of the linear reference genome. We implemented our ideas in the\nminigraph toolkit and demonstrate that we can efficiently construct a pangenome\ngraph and compactly encode tens of thousands of structural variants missing\nfrom the current reference genome.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.06079v1"
    },
    {
        "title": "Analysis of genetic differences between psychiatric disorders: Exploring\n  pathways and cell-types/tissues involved and ability to differentiate the\n  disorders by polygenic scores",
        "authors": [
            "Shitao Rao",
            "Liangying Yin",
            "Yong Xiang",
            "Hon-Cheong So"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Although displaying genetic correlations, psychiatric disorders are\nclinically defined as categorical entities as they each have distinguishing\nclinical features and may involve different treatments. Identifying\ndifferential genetic variations between these disorders may reveal how the\ndisorders differ biologically and help to guide more personalized treatment.\n  Here we presented a comprehensive analysis to identify genetic markers\ndifferentially associated with various psychiatric disorders/traits based on\nGWAS summary statistics, covering 18 psychiatric traits/disorders and 26\ncomparisons. We also conducted comprehensive analysis to unravel the genes,\npathways and SNP functional categories involved, and the cell types and tissues\nimplicated. We also assessed how well one could distinguish between psychiatric\ndisorders by polygenic risk scores (PRS).\n  SNP-based heritabilities (h2SNP) were significantly larger than zero for most\ncomparisons. Based on current GWAS data, PRS have mostly modest power to\ndistinguish between psychiatric disorders. For example, we estimated that AUC\nfor distinguishing schizophrenia from major depressive disorder (MDD), bipolar\ndisorder (BPD) from MDD and schizophrenia from BPD were 0.694, 0.602 and 0.618\nrespectively, while the maximum AUC (based on h2SNP) were 0.763, 0.749 and\n0.726 respectively. We also uncovered differences in each pair of studied\ntraits in terms of their differences in genetic correlation with comorbid\ntraits. For example, clinically-defined MDD appeared to more strongly\ngenetically correlated with other psychiatric disorders and heart disease, when\ncompared to non-clinically-defined depression in UK Biobank.\n  Our findings highlight genetic differences between psychiatric disorders and\nthe mechanisms involved. PRS may aid differential diagnosis of selected\npsychiatric disorders in the future with larger GWAS samples.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07105v4"
    },
    {
        "title": "Genome Variant Calling with a Deep Averaging Network",
        "authors": [
            "Nikolai Yakovenko",
            "Avantika Lal",
            "Johnny Israeli",
            "Bryan Catanzaro"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Variant calling, the problem of estimating whether a position in a DNA\nsequence differs from a reference sequence, given noisy, redundant, overlapping\nshort sequences that cover that position, is fundamental to genomics. We\npropose a deep averaging network designed specifically for variant calling. Our\nmodel takes into account the independence of each short input read sequence by\ntransforming individual reads through a series of convolutional layers,\nlimiting the communication between individual reads to averaging and\nconcatenating operations. Training and testing on the precisionFDA Truth\nChallenge (pFDA), we match state of the art overall 99.89 F1 score. Genome\ndatasets exhibit extreme skew between easy examples and those on the decision\nboundary. We take advantage of this property to converge models at 5x the speed\nof standard epoch-based training by skipping easy examples during training. To\nfacilitate future work, we release our code, trained models and pre-processed\npublic domain datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07220v1"
    },
    {
        "title": "A framework to decipher the genetic architecture of combinations of\n  complex diseases: applications in cardiovascular medicine",
        "authors": [
            "Liangying Yin",
            "Carlos Kwan-long Chau",
            "Yu-Ping Lin",
            "Pak-Chung Sham",
            "Hon-Cheong So"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genome-wide association studies(GWAS) have proven to be highly useful in\nrevealing the genetic basis of complex diseases. At present, most GWAS are\nstudies of a particular single disease diagnosis against controls. However, in\npractice, an individual is often affected by more than one condition/disorder.\nFor example, patients with coronary artery disease(CAD) are often comorbid with\ndiabetes mellitus(DM). Along a similar line, it is often clinically meaningful\nto study patients with one disease but without a comorbidity. For example,\nobese DM may have different pathophysiology from non-obese DM.\n  Here we developed a statistical framework to uncover susceptibility variants\nfor comorbid disorders (or a disorder without comorbidity), using GWAS summary\nstatistics only. In essence, we mimicked a case-control GWAS in which the cases\nare affected with comorbidities or a disease without a relevant comorbid\ncondition (in either case, we may consider the cases as those affected by a\nspecific subtype of disease, as characterized by the presence or absence of\ncomorbid conditions). We extended our methodology to deal with continuous\ntraits with clinically meaningful categories (e.g. lipids). In addition, we\nillustrated how the analytic framework may be extended to more than two traits.\nWe verified the feasibility and validity of our method by applying it to\nsimulated scenarios and four cardiometabolic (CM) traits. We also analyzed the\ngenes, pathways, cell-types/tissues involved in CM disease subtypes. LD-score\nregression analysis revealed some subtypes may indeed be biologically distinct\nwith low genetic correlations. Further Mendelian randomization analysis found\ndifferential causal effects of different subtypes to relevant complications. We\nbelieve the findings are of both scientific and clinical value, and the\nproposed method may open a new avenue to analyzing GWAS data.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.08518v4"
    },
    {
        "title": "Estimation of genome size using k-mer frequencies from corrected long\n  reads",
        "authors": [
            "Hengchao Wang",
            "Bo Liu",
            "Yan Zhang",
            "Fan Jiang",
            "Yuwei Ren",
            "Lijuan Yin",
            "Hangwei Liu",
            "Sen Wang",
            "Wei Fan"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The third-generation long reads sequencing technologies, such as PacBio and\nNanopore, have great advantages over second-generation Illumina sequencing in\nde novo assembly studies. However, due to the inherent low base accuracy,\nthird-generation sequencing data cannot be used for k-mer counting and\nestimating genomic profile based on k-mer frequencies. Thus, in current genome\nprojects, second-generation data is also necessary for accurately determining\ngenome size and other genomic characteristics. We show that corrected\nthird-generation data can be used to count k-mer frequencies and estimate\ngenome size reliably, in replacement of using second-generation data.\nTherefore, future genome projects can depend on only one sequencing technology\nto finish both assembly and k-mer analysis, which will largely decrease\nsequencing cost in both time and money. Moreover, we present a fast\nlight-weight tool kmerfreq and use it to perform all the k-mer counting tasks\nin this work. We have demonstrated that corrected third-generation sequencing\ndata can be used to estimate genome size and developed a new open-source C/C++\nk-mer counting tool, kmerfreq, which is freely available at\nhttps://github.com/fanagislab/kmerfreq.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.11817v1"
    },
    {
        "title": "SOS: Online probability estimation and generation of T and B cell\n  receptors",
        "authors": [
            "Giulio Isacchini",
            "Carlos Olivares",
            "Armita Nourmohammad",
            "Aleksandra M. Walczak",
            "Thierry Mora"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Recent advances in modelling VDJ recombination and subsequent selection of T\nand B cell receptors provide useful tools to analyze and compare immune\nrepertoires across time, individuals, and tissues. A suite of tools--IGoR [1],\nOLGA [2] and SONIA [3]--have been publicly released to the community that allow\nfor the inference of generative and selection models from high-throughput\nsequencing data. However using these tools requires some scripting or\ncommand-line skills and familiarity with complex datasets. As a result the\napplication of the above models has not been available to a broad audience. In\nthis application note we fill this gap by presenting Simple OLGA & SONIA (SOS),\na web-based interface where users with no coding skills can compute the\ngeneration and post-selection probabilities of their sequences, as well as\ngenerate batches of synthetic sequences. The application also functions on\nmobile phones.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.13149v1"
    },
    {
        "title": "Coronavirus SARS-CoV-2: Analysis of subgenomic mRNA transcription,\n  3CLpro and PL2pro protease cleavage sites and protein synthesis",
        "authors": [
            "Miguel Ramos Pascual"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Coronaviruses have recently caused world-wide severe outbreaks: SARS (Severe\nAcute Respiratory Syndrome) in 2002 and MERS (Middle-East Respiratory Syndrome)\nin 2012. At the end of 2019, a new coronavirus outbreak appeared in Wuhan\n(China) seafood market as first focus of infection, becoming a pandemics in\n2020, spreading mainly into Europe and Asia. Although the virus family is\nwell-known, this specific virus presents considerable differences, as higher\ntransmission rates, being a challenge for diagnostic methods, treatments and\nvaccines. Coronavirus(C++).pro is a C++ application which simulates Coronavirus\nreplication cycle. This software has identified virus type in short times and\nprovided FASTA files of virus proteins, a list of mRNA sequences and secondary\nstructures. Furthermore, the software has identified a list of structural,\nnon-structural and accessory proteins in 2019-nCoV virus genome more similar to\nSARS than to MERS, as several fusion proteins characteristics of this virus\ntype. These results are useful as a first step in order to develop diagnostic\nmethods, new vaccines or antiviral drugs, which could avoid virus replication\nin any stage: fusion inhibitors, RdRp inhibitors and PL2pro/3CLpro protease\ninhibitors.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.00746v1"
    },
    {
        "title": "HLA predictions from the bronchoalveolar lavage fluid samples of five\n  patients at the early stage of the Wuhan seafood market COVID-19 outbreak",
        "authors": [
            "Rene L Warren",
            "Inanc Birol"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  We are in the midst of a global viral pandemic, one with no cure and a high\nmortality rate. The Human Leukocyte Antigen (HLA) gene complex plays a critical\nrole in host immunity. We predicted HLA class I and II alleles from the\ntranscriptome sequencing data prepared from the bronchoalveolar lavage fluid\nsamples of five patients at the early stage of the COVID-19 outbreak. We\nidentified the HLA-I allele A*24:02 in four out of five patients, which is\nhigher than the expected frequency (17.2%) in the South Han Chinese population.\nThe difference is statistically significant with a p-value less than $10^{-4}$.\nOur analysis results may help provide future insights on disease\nsusceptibility.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.07108v3"
    },
    {
        "title": "LAI-Net: Local-Ancestry Inference with Neural Networks",
        "authors": [
            "Daniel Mas Montserrat",
            "Carlos Bustamante",
            "Alexander Ioannidis"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Local-ancestry inference (LAI), also referred to as ancestry deconvolution,\nprovides high-resolution ancestry estimation along the human genome. In both\nresearch and industry, LAI is emerging as a critical step in DNA sequence\nanalysis with applications extending from polygenic risk scores (used to\npredict traits in embryos and disease risk in adults) to genome-wide\nassociation studies, and from pharmacogenomics to inference of human population\nhistory. While many LAI methods have been developed, advances in computing\nhardware (GPUs) combined with machine learning techniques, such as neural\nnetworks, are enabling the development of new methods that are fast, robust and\neasily shared and stored. In this paper we develop the first neural network\nbased LAI method, named LAI-Net, providing competitive accuracy with\nstate-of-the-art methods and robustness to missing or noisy data, while having\na small number of layers.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.10377v1"
    },
    {
        "title": "Comprehensive assessment of error correction methods for high-throughput\n  sequencing data",
        "authors": [
            "Yun Heo",
            "Gowthami Manikandan",
            "Anand Ramachandran",
            "Deming Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The advent of DNA and RNA sequencing has revolutionized the study of genomics\nand molecular biology. Next generation sequencing (NGS) technologies like\nIllumina, Ion Torrent, SOLiD sequencing etc. have brought about a quick and\ncheap way to sequence genomes. Recently, third generation sequencing (TGS)\ntechnologies like PacBio and Oxford Nanopore Technology (ONT) have also been\ndeveloped. Different technologies use different underlying methods for\nsequencing and are prone to different error rates. Though many tools exist for\nerror correction of sequencing data from NGS and TGS methods, no standard\nmethod is available yet to evaluate the accuracy and effectiveness of these\nerror-correction tools. In this study, we present a Software Package for Error\nCorrection Tool Assessment on nuCLEic acid sequences (SPECTACLE) providing\ncomprehensive algorithms to evaluate error-correction methods for DNA and RNA\nsequencing, for NGS and TGS platforms. We also present a compilation of\nsequencing datasets for Illumina, PacBio and ONT platforms that present\nchallenging scenarios for error-correction tools. Using these datasets and\nSPECTACLE, we evaluate the performance of 23 different error-correction tools\nand present unique and helpful insights into their strengths and weaknesses. We\nhope that our methodology will standardize the evaluation of DNA and RNA\nerror-correction tools in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.05121v2"
    },
    {
        "title": "Dynamics of B-cell repertoires and emergence of cross-reactive responses\n  in COVID-19 patients with different disease severity",
        "authors": [
            "Zachary Montague",
            "Huibin Lv",
            "Jakub Otwinowski",
            "William S. DeWitt",
            "Giulio Isacchini",
            "Garrick K. Yip",
            "Wilson W. Ng",
            "Owen Tak-Yin Tsang",
            "Meng Yuan",
            "Hejun Liu",
            "Ian A. Wilson",
            "J. S. Malik Peiris",
            "Nicholas C. Wu",
            "Armita Nourmohammad",
            "Chris Ka Pun Mok"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  COVID-19 patients show varying severity of the disease ranging from\nasymptomatic to requiring intensive care. Although a number of SARS-CoV-2\nspecific monoclonal antibodies have been identified, we still lack an\nunderstanding of the overall landscape of B-cell receptor (BCR) repertoires in\nCOVID-19 patients. Here, we used high-throughput sequencing of bulk and plasma\nB-cells collected over multiple time points during infection to characterize\nsignatures of B-cell response to SARS-CoV-2 in 19 patients. Using principled\nstatistical approaches, we determined differential features of BCRs associated\nwith different disease severity. We identified 38 significantly expanded clonal\nlineages shared among patients as candidates for specific responses to\nSARS-CoV-2. Using single-cell sequencing, we verified reactivity of BCRs shared\namong individuals to SARS-CoV-2 epitopes. Moreover, we identified natural\nemergence of a BCR with cross-reactivity to SARS-CoV-1 and SARS-CoV-2 in a\nnumber of patients. Our results provide important insights for development of\nrational therapies and vaccines against COVID-19.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.06762v2"
    },
    {
        "title": "Learning the heterogeneous hypermutation landscape of immunoglobulins\n  from high-throughput repertoire data",
        "authors": [
            "Natanael Spisak",
            "Aleksandra M. Walczak",
            "Thierry Mora"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Somatic hypermutations of immunoglobulin (Ig) genes occuring during affinity\nmaturation drive B-cell receptors' ability to evolve strong binding to their\nantigenic targets. The landscape of these mutations is highly heterogeneous,\nwith certain regions of the Ig gene being preferentially targeted. However, a\nrigorous quantification of this bias has been difficult because of phylogenetic\ncorrelations between sequences and the interference of selective forces. Here,\nwe present an approach that corrects for these issues, and use it to learn a\nmodel of hypermutation preferences from a recently published large IgH\nrepertoire dataset. The obtained model predicts mutation profiles accurately\nand in a reproducible way, including in the previously uncharacterized\nComplementarity Determining Region 3, revealing that both the sequence context\nof the mutation and its absolute position along the gene are important. In\naddition, we show that hypermutations occurring concomittantly along B-cell\nlineages tend to co-localize, suggesting a possible mechanism for accelerating\naffinity maturation.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11841v2"
    },
    {
        "title": "On the Transcriptomic Signature and General Stress State Associated with\n  Aneuploidy",
        "authors": [
            "Hung-Ji Tsai",
            "Anjali R. Nelliat",
            "Andrei Kucharavy",
            "Mohammad Ikbal Choudhury",
            "Sean X. Sun",
            "Michael C. Schatz",
            "Rong Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Whether aneuploid cells with diverse karyotypes have any properties in common\nhas a been a subject of intense interest. A recent study by Terhorst et al. (1)\nreinvestigated the common aneuploidy gene expression (CAGE), disputing the\nconclusion of our recent work (2). In this short article, which has been\nsubmitted to PNAS as a Letter to the Editor, we explain our major concerns\nabout Terhorst et al. and why we believe that our previous conclusion stands\nvalid.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.14585v1"
    },
    {
        "title": "Structural representations of DNA regulatory substrates can enhance\n  sequence-based algorithms by associating functional sequence variants",
        "authors": [
            "Jan Zrimec"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The nucleotide sequence representation of DNA can be inadequate for resolving\nprotein-DNA binding sites and regulatory substrates, such as those involved in\ngene expression and horizontal gene transfer. Considering that sequence-like\nrepresentations are algorithmically very useful, here we fused over 60\ncurrently available DNA physicochemical and conformational variables into\ncompact structural representations that can encode single DNA binding sites to\nwhole regulatory regions. We find that the main structural components reflect\nkey properties of protein-DNA interactions and can be condensed to the amount\nof information found in a single nucleotide position. The most accurate\nstructural representations compress functional DNA sequence variants by 30% to\n50%, as each instance encodes from tens to thousands of sequences. We show that\na structural distance function discriminates among groups of DNA substrates\nmore accurately than nucleotide sequence-based metrics. As this opens up a\nvariety of implementation possibilities, we develop and test a distance-based\nalignment algorithm, demonstrating the potential of using the structural\nrepresentations to enhance sequence-based algorithms. Due to the bias of most\ncurrent bioinformatic methods to nucleotide sequence representations, it is\npossible that considerable performance increases might still be achievable with\nsuch solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.14922v1"
    },
    {
        "title": "Did circoviruses intermediate the recombination between bat and pangolin\n  coronaviruses, yielding SARS-CoV-2?",
        "authors": [
            "Nabil Abid",
            "Giovanni Chillemi",
            "Ahmed Rebai"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Since the first reports of a coronavirus (CoV) disease 2019 (COVID-19) caused\nby severe acute respiratory syndrome virus (SARS-CoV-2) in Wuhan, Hubei\nprovince, China, scientists are working around the clock to find sound answers\nto the issue of its origin. While the number of scientific articles on\nSARS-CoV-2 is increasing, there are still many gaps as to its origin. All\nstudies failed to find a coronavirus in other animals that is more similar to\nhuman SARS-COV2 than the bat virus, considered to be the primary reservoir. In\nthis paper we address a new hypothesis, based on a possible recombination\nbetween a DNA and SARS-CoV viruses, to explain the rise of SRAS-CoV-2. By\ncomparing SARS-CoV-2 and related CoVs with circoviruses (CVs), we found strong\nsequence similarity of the genomic region at the 3-end of Bat-CoV ORF1a and the\norigin of replication (Ori) of porcine CV type 2 (PCV2), as well as similar RNA\nsecondary structures of the region encompassing the cleavage site of CoV S gene\nwith the PCV2 Ori. This constitutes a primary evidence that supports a possible\nrecombination, which occurrence might explain the origin of SARS-CoV-2.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.00531v1"
    },
    {
        "title": "Computational tools for the multiscale analysis of Hi-C data in\n  bacterial chromosomes",
        "authors": [
            "Nelle Varoquaux",
            "Virginia S. Lioy",
            "Frédéric Boccard",
            "Ivan Junier"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Just as in eukaryotes, high-throughput chromosome conformation capture (Hi-C)\ndata have revealed nested organizations of bacterial chromosomes into\noverlapping interaction domains. In this chapter, we present a multiscale\nanalysis framework aiming at capturing and quantifying these properties. These\ninclude both standard tools (e.g. contact laws) and novel ones such as an index\nthat allows identifying loci involved in domain formation independently of the\nstructuring scale at play. Our objective is two-fold. On the one hand, we aim\nat providing a full, understandable Python/Jupyter-based code which can be used\nby both computer scientists as well as biologists with no advanced\ncomputational background. On the other hand, we discuss statistical issues\ninherent to Hi-C data analysis, focusing more particularly on how to properly\nassess the statistical significance of results. As a pedagogical example, we\nanalyze data produced in {\\it Pseudomonas aeruginosa}, a model pathogenetic\nbacterium. All files (codes and input data) can be found on a github\nrepository. We have also embedded the files into a Binder package so that the\nfull analysis can be run on any machine through internet.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.01718v1"
    },
    {
        "title": "Genome Compression Against a Reference",
        "authors": [
            "Anirduddha Laud",
            "Gaurav Menghani",
            "Madhava Keralapura"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Being able to store and transmit human genome sequences is an important part\nin genomic research and industrial applications. The complete human genome has\n3.1 billion base pairs (haploid), and storing the entire genome naively takes\nabout 3 GB, which is infeasible for large scale usage.\n  However, human genomes are highly redundant. Any given individual's genome\nwould differ from another individual's genome by less than 1%. There are tools\nlike DNAZip, which express a given genome sequence by only noting down the\ndifferences between the given sequence and a reference genome sequence. This\nallows losslessly compressing the given genome to ~ 4 MB in size.\n  In this work, we demonstrate additional improvements on top of the DNAZip\nlibrary, where we show an additional ~ 11% compression on top of DNAZip's\nalready impressive results. This would allow further savings in disk space and\nnetwork costs for transmitting human genome sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.02286v1"
    },
    {
        "title": "RNA-seq data science: From raw data to effective interpretation",
        "authors": [
            "Dhrithi Deshpande",
            "Karishma Chhugani",
            "Yutong Chang",
            "Aaron Karlsberg",
            "Caitlin Loeffler",
            "Jinyang Zhang",
            "Agata Muszynska",
            "Jeremy Rotman",
            "Laura Tao",
            "Brunilda Balliu",
            "Elizabeth Tseng",
            "Eleazar Eskin",
            "Fangqing Zhao",
            "Pejman Mohammadi",
            "Pawel P Labaj",
            "Serghei Mangul"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  RNA-sequencing (RNA-seq) has become an exemplar technology in modern biology\nand clinical applications over the past decade. It has gained immense\npopularity in the recent years driven by continuous efforts of the\nbioinformatics community to develop accurate and scalable computational tools.\nRNA-seq is a method of analyzing the RNA content of a sample using the modern\nsequencing platforms. It generates enormous amounts of transcriptomic data in\nthe form of nucleotide sequences, known as reads. RNA-seq analysis enables the\nprobing of genes and corresponding transcripts which is essential for answering\nimportant biological questions, such as detecting novel exons, transcripts,\ngene expressions, and studying alternative splicing structure. However,\nobtaining meaningful biological signals from raw data using computational\nmethods is challenging due to the limitations of modern sequencing\ntechnologies. The need to leverage these technological challenges have pushed\nthe rapid development of many novel computational tools which have evolved and\ndiversified in accordance with technological advancements, leading to the\ncurrent myriad population of RNA-seq tools. Our review provides a systemic\noverview of RNA-seq technology and 235 available RNA-seq tools across various\ndomains published from 2008 to 2020, discussing the interdisciplinary nature of\nbioinformatics involved in RNA sequencing, analysis, and software development.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.02391v3"
    },
    {
        "title": "Likelihood Models for Forensic Genealogy",
        "authors": [
            "William H. Press",
            "John Hawkins"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  In the idealized Morgan model of crossover, we study the probability\ndistributions of shared DNA (identical by descent) between individuals having a\nwide range of relationships (not just lineal descendants), especially cases for\nwhich previous work produces inaccurate results. Using Monte Carlo simulation,\nwe show that a particular, complicated functional form with just one continuous\nfitted parameter accurately approximates the distributions in all cases tried.\nAnalysis of that functional form shows that it is close to a normal\ndistribution, not in shared fraction f, but in the square-root of f. We\ndescribe a multivariate normal model in this variable for use as a practical\nframework for several general tasks in forensic genealogy that are currently\ndone by less-accurate and less well-founded methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.02985v1"
    },
    {
        "title": "Deep Learning Prediction of Adverse Drug Reactions Using Open TG-GATEs\n  and FAERS Databases",
        "authors": [
            "Attayeb Mohsen",
            "Lokesh P. Tripathi",
            "Kenji Mizuguchi"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  With the advancements in Artificial intelligence (AI) and the accumulation of\nhealthrelated big data, it has become increasingly feasible and commonplace to\nleverage machine learning technologies to analyze clinical and omics metadata\nto assess the possibility of adverse drug reactions or events (ADRs) in the\ncourse of drug discovery. Here, we have described a novel approach that\ncombined drug-induced gene expression profile from Open TG-GATEs\n(Toxicogenomics Project-Genomics Assisted Toxicity Evaluation Systems) and ADR\noccurrence information from FAERS (FDA [Food and Drug Administration] Adverse\nEvents Reporting System) database to predict the likelihood of ADRs. We\ngenerated a total of 14 models using Deep Neural Networks (DNN) to predict\ndifferent ADRs; in the validation tests, our models achieved a mean accuracy of\n85.71%, indicating that our approach successfully and consistently predicted\nADRs for a wide range of drugs. As an example, we have described the ADR model\nin the context of Duodenal ulcer. We believe that our models will help predict\nthe likelihood of ADRs while testing novel pharmaceutical compounds, and will\nbe useful for researchers in drug discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.05411v1"
    },
    {
        "title": "Diversity in immunogenomics: the value and the challenge",
        "authors": [
            "Kerui Peng",
            "Yana Safonova",
            "Mikhail Shugay",
            "Alice Popejoy",
            "Oscar Rodriguez",
            "Felix Breden",
            "Petter Brodin",
            "Amanda M. Burkhardt",
            "Carlos Bustamante",
            "Van-Mai Cao-Lormeau",
            "Martin M. Corcoran",
            "Darragh Duffy",
            "Macarena Fuentes Guajardo",
            "Ricardo Fujita",
            "Victor Greiff",
            "Vanessa D. Jonsson",
            "Xiao Liu",
            "Lluis Quintana-Murci",
            "Maura Rossetti",
            "Jianming Xie",
            "Gur Yaari",
            "Wei Zhang",
            "Malak S. Abedalthagafi",
            "Khalid O. Adekoya",
            "Rahaman A. Ahmed",
            "Wei-Chiao Chang",
            "Clive Gray",
            "Yusuke Nakamura",
            "William D. Lees",
            "Purvesh Khatri",
            "Houda Alachkar",
            "Cathrine Scheepers",
            "Corey T. Watson",
            "Gunilla B. Karlsson Hedestam",
            "Serghei Mangul"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  With the advent of high-throughput sequencing technologies, the fields of\nimmunogenomics and adaptive immune receptor repertoire research are facing both\nopportunities and challenges. Adaptive immune receptor repertoire sequencing\n(AIRR-seq) has become an increasingly important tool to characterize T and B\ncell responses in settings of interest. However, the majority of AIRR-seq\nstudies conducted so far were performed in individuals of European ancestry,\nrestricting the ability to identify variation in human adaptive immune\nresponses across populations and limiting their applications. As AIRR-seq\nstudies depend on the ability to assign VDJ sequence reads to the correct\ngermline gene segments, efforts to characterize the genomic loci that encode\nadaptive immune receptor genes in different populations are urgently needed.\nThe availability of comprehensive germline gene databases and further\napplications of AIRR-seq studies to individuals of non-European ancestry will\nsubstantially enhance our understanding of human adaptive immune responses,\npromote the development of effective diagnostics and treatments, and eventually\nadvance precision medicine.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.10402v4"
    },
    {
        "title": "Extraction of long k-mers using spaced seeds",
        "authors": [
            "Miika Leinonen",
            "Leena Salmela"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The extraction of k-mers from sequencing reads is an important task in many\nbioinformatics applications, such as all DNA sequence analysis methods based on\nde Bruijn graphs. These methods tend to be more accurate when the used k-mers\nare unique in the analyzed DNA, and thus the use of longer k-mers is preferred.\nWhen the read lengths of short read sequencing technologies increase, the error\nrate will become the determining factor for the largest possible value of k.\nHere we propose LoMeX which uses spaced seeds to extract long k-mers accurately\neven in the presence of sequencing errors. Our experiments show that LoMeX can\nextract long k-mers from current Illumina reads with a higher recall than a\nstandard k-mer counting tool. Furthermore, our experiments on simulated data\nshow that when the read length further increases, the performance of standard\nk-mer counters declines, whereas LoMeX still extracts long k-mers successfully.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.11592v2"
    },
    {
        "title": "Whole-Genome Sequence of the Trypoxylus dichotomus Japanese rhinoceros\n  beetle",
        "authors": [
            "Norichika Ogata"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The draft whole-genome sequence of the Japanese rhinoceros beetle, Trypoxylus\ndichotomus was obtained using long-read PacBio sequence technology. The final\nassembled genome consisted of 739 Mbp in 2,347 contigs, with 24.5x mean\ncoverage and a G+C content of 35.99%.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.08845v1"
    },
    {
        "title": "Expanding the phenotype of SCA19/22: Parkinsonism, cognitive impairment\n  and epilepsy",
        "authors": [
            "Vincent Huin",
            "Isabelle Strubi-Vuillaume",
            "Kathy Dujardin",
            "Marine Brion",
            "Marie Delliaux",
            "Delphine Dellacherie",
            "Jean-Christophe Cuvellier",
            "Jean-Marie Cuisset",
            "Audrey Riquet",
            "Caroline Moreau",
            "Luc Defebvre",
            "Bernard Sablonniere",
            "David Devos"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  BACKGROUND: Spinocerebellar ataxia types 19 and 22 (SCA19/22) are rare\nconditions in which relatively isolated cerebellar involvement is frequently\nassociated with cognitive impairment. Here, we report on new clinical features\nand provide details of the cognitive profile in two SCA19/22 families.METHODS:\nTwo families displaying an autosomal-dominant form of cerebellar ataxia\nunderwent clinical examinations and genetic testing.RESULTS: In addition to the\nclassical clinical features of SCA, a wide spectrum of cognitive disorders\n(including visuospatial impairments) was observed. Eight patients had mild\nParkinsonism, and five had epilepsy. Genetic testing showed that the KCND3\nmutation (c.679_681delTTC, p.F227del) was present in both families.CONCLUSIONS:\nOur findings broaden the phenotypic spectrum of SCA19/22, and suggest that\nKCND3 should be included in the list of candidate genes for epilepsy,\nParkinsonism and cognitive impairment.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10449v1"
    },
    {
        "title": "TMEM240 mutations cause spinocerebellar ataxia 21 with mental\n  retardation and severe cognitive impairment",
        "authors": [
            "Jérôme Delplanque",
            "David Devos",
            "Vincent Huin",
            "Alexandre Genet",
            "Olivier Sand",
            "Caroline Moreau",
            "Cyril Goizet",
            "Perrine Charles",
            "Mathieu Anheim",
            "Marie Lorraine Monin",
            "Luc Buée",
            "Alain Destée",
            "Guillaume Grolez",
            "Christine Delmaire",
            "Kathy Dujardin",
            "Delphine Dellacherie",
            "Alexis Brice",
            "Giovanni Stevanin",
            "Isabelle Strubi-Vuillaume",
            "Alexandra Durr",
            "Bernard Sablonnière"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Autosomal dominant cerebellar ataxia corresponds to a clinically and\ngenetically heterogeneous group of neurodegenerative disorders that primarily\naffect the cerebellum. Here, we report the identification of the causative gene\nin spinocerebellar ataxia 21, an autosomal-dominant disorder previously mapped\nto chromosome 7p21.3-p15.1. This ataxia was firstly characterized in a large\nFrench family with slowly progressive cerebellar ataxia, accompanied by severe\ncognitive impairment and mental retardation in two young children. Following\nthe recruitment of 12 additional young family members, linkage analysis enabled\nus to definitively map the disease locus to chromosome 1p36.33-p36.32. The\ncausative mutation, (c.509C4T/p.P170L) in the transmembrane protein gene\nTMEM240, was identified by whole exome sequencing and then was confirmed by\nSanger sequencing and co-segregation analyses. Index cases from 368 French\nfamilies with autosomal-dominant cerebellar ataxia were also screened for\nmutations. In seven cases, we identified a range of missense mutations\n(c.509C4T/p.P170L, c.239C4T/p.T80M, c.346C4T/p.R116C, c.445G4A/p.E149K,\nc.511C4T/p.R171W), and a stop mutation (c.489C4G/p.Y163*) in the same gene.\nTMEM240 is a small, strongly conserved transmembrane protein of unknown\nfunction present in cerebellum and brain. Spinocerebellar ataxia 21 may be a\nparticular early-onset disease associated with severe cognitive impairment.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10771v1"
    },
    {
        "title": "Evolution of default genetic control mechanisms",
        "authors": [
            "William Bains",
            "Enrico Borriello",
            "Dirk Schulze-Makuch"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We present a model of the evolution of control systems in a genome under\nenvironmental constraints. The model conceptually follows the Jacob and Monod\nmodel of gene control. Genes contain control elements which respond to the\ninternal state of the cell as well as the environment to control expression of\na coding region. Control and coding regions evolve to maximize a fitness\nfunction between expressed coding sequences and the environment. 118 runs of\nthe model run to an average of 1.4 x 10^6 `generations' each with a range of\nstarting parameters probed the conditions under which genomes evolved a\n`default style' of control. Unexpectedly, the control logic that evolved was\nnot significantly correlated to the complexity of the environment. Genetic\nlogic was strongly correlated with genome complexity and with the fraction of\ngenes active in the cell at any one time. More complex genomes correlated with\nthe evolution of genetic controls in which genes were active (`default on'),\nand a low fraction of genes being expressed correlated with a genetic logic in\nwhich genes were biased to being inactive unless positively activated (`default\noff' logic). We discuss how this might relate to the evolution of the complex\neukaryotic genome, which operates in a `default off' mode.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.03147v1"
    },
    {
        "title": "Partition Quantitative Assessment (PQA): A quantitative methodology to\n  assess the embedded noise in clustered omics and systems biology data",
        "authors": [
            "Diego A. Camacho-Hernández",
            "Victor E. Nieto-Caballero",
            "José E. León-Burguete",
            "Julio A. Freyre-González"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Identifying groups that share common features among datasets through\nclustering analysis is a typical problem in many fields of science,\nparticularly in post-omics and systems biology research. In respect of this,\nquantifying how a measure can cluster or organize intrinsic groups is important\nsince currently there is no statistical evaluation of how ordered is, or how\nmuch noise is embedded in the resulting clustered vector. Many of the\nliterature focuses on how well the clustering algorithm orders the data, with\nseveral measures regarding external and internal statistical measures; but none\nmeasure has been developed to statistically quantify the noise in an arranged\nvector posterior a clustering algorithm, i.e., how much of the clustering is\ndue to randomness. Here, we present a quantitative methodology, based on\nautocorrelation, to assess this problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.03228v1"
    },
    {
        "title": "Genes predisposing to syndromic and nonsyndromic infertility: a\n  narrative review",
        "authors": [
            "Tajudeen O. Yahaya",
            "Usman U. Liman",
            "Haliru Abdullahi",
            "Yahuza S. Koko",
            "Samuel S. Ribah",
            "Zulkarnain Adamu",
            "Suleiman Abubakar"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: Advanced biological techniques have helped produce more\ninsightful findings on the genetic etiology of infertility that may lead to\nbetter management of the condition. This review provides an update on genes\npredisposing to syndromic and nonsyndromic infertility.\n  Main body: The review identified 65 genes linked with infertility and\ninfertility-related disorders. These genes regulate fertility. However,\nmutational loss of the functions of the genes predisposes to infertility.\nTwenty-three (23) genes representing 35% were linked with syndromic\ninfertility, while 42 genes (65%) cause nonsyndromic infertility. Of the 42\nnonsyndromic genes, 26 predispose to spermatogenic failure and sperm\nmorphological abnormalities, 11 cause ovarian failures, and 5 cause sex\nreversal and puberty delay. Overall, 31 genes (48%) predispose to male\ninfertility, 15 genes (23%) cause female infertility, and 19 genes (29%)\npredispose to both. The common feature of male infertility was spermatogenic\nfailure and sperm morphology abnormalities, while ovarian failure has been the\nmost frequently reported among infertile females. The mechanisms leading to\nthese pathologies are gene-specific, which, if targeted in the affected, may\nlead to improved treatment.\n  Conclusions: Mutational loss of the functions of some genes involved in the\ndevelopment and maintenance of fertility may predispose to syndromic or\nnonsyndromic infertility via gene-specific mechanisms. A treatment procedure\nthat targets the affected gene(s) in individuals expressing infertility may\nlead to improved treatment.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05335v1"
    },
    {
        "title": "From Genotype to Phenotype: polygenic prediction of complex human traits",
        "authors": [
            "Timothy G. Raben",
            "Louis Lello",
            "Erik Widen",
            "Stephen D. H. Hsu"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Decoding the genome confers the capability to predict characteristics of the\norganism(phenotype) from DNA (genotype). We describe the present status and\nfuture prospects of genomic prediction of complex traits in humans. Some highly\nheritable complex phenotypes such as height and other quantitative traits can\nalready be predicted with reasonable accuracy from DNA alone. For many\ndiseases, including important common conditions such as coronary artery\ndisease, breast cancer, type I and II diabetes, individuals with outlier\npolygenic scores (e.g., top few percent) have been shown to have 5 or even 10\ntimes higher risk than average. Several psychiatric conditions such as\nschizophrenia and autism also fall into this category. We discuss related\ntopics such as the genetic architecture of complex traits, sibling validation\nof polygenic scores, and applications to adult health, in vitro fertilization\n(embryo selection), and genetic engineering.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05870v1"
    },
    {
        "title": "Genes predisposing to type 1 diabetes mellitus and pathophysiology: a\n  narrative review",
        "authors": [
            "Tajudeen Yahaya",
            "Titilola Salisu"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The possibility of targeting the causal genes along with the mechanisms of\npathogenically complex diseases has led to numerous studies on the genetic\netiology of some diseases. In particular, studies have added more genes to the\nlist of type 1 diabetes mellitus (T1DM) suspect genes, necessitating an update\nfor the interest of all stakeholders. Therefore this review articulates T1DM\nsuspect genes and their pathophysiology. Notable electronic databases,\nincluding Medline, Scopus, PubMed, and Google-Scholar were searched for\nrelevant information. The search identified over 73 genes suspected in the\npathogenesis of T1DM, with human leukocyte antigen, insulin gene, and cytotoxic\nT lymphocyte-associated antigen 4 accounting for most of the cases. Mutations\nin these genes, along with environmental factors, may produce a defective\nimmune response in the pancreas, resulting in \\b{eta}-cell autoimmunity,\ninsulin deficiency, and hyperglycemia. The mechanisms leading to these cellular\nreactions are gene-specific and, if targeted in diabetic individuals, may lead\nto improved treatment. Medical practitioners are advised to formulate treatment\nprocedures that target these genes in patients with T1DM.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.06680v1"
    },
    {
        "title": "Genetics and Pathophysiology of Maturity-onset Diabetes of the Young\n  (MODY): A Review of Current Trends",
        "authors": [
            "Tajudeen O. Yahaya",
            "Shemishere B. Ufuoma"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Single gene mutations have been implicated in the pathogenesis of a form of\ndiabetes mellitus (DM) known as the maturity-onset diabetes of the young\n(MODY). However, there are diverse opinions on the suspect genes and\npathophysiology, necessitating the need to review and communicate the genes to\nraise public awareness. We used the Google search engine to retrieve relevant\ninformation from reputable sources such as PubMed and Google Scholar. We\nidentified 14 classified MODY genes as well as three new and unclassified genes\nlinked with MODY. These genes are fundamentally embedded in the beta cells, the\nmost common of which are HNF1A, HNF4A, HNF1B, and GCK genes. Mutations in these\ngenes cause beta-cell dysfunction, resulting in decreased insulin production\nand hyperglycemia. MODY genes have distinct mechanisms of action and phenotypic\npresentations compared with type 1 and type 2 DM and other forms of DM.\nHealthcare professionals are therefore advised to formulate drugs and treatment\nbased on the causal genes rather than the current generalized treatment for all\ntypes of DM. This will increase the effectiveness of diabetes drugs and\ntreatment and reduce the burden of the disease.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.06788v1"
    },
    {
        "title": "Update on the genetic and epigenetic etiology of gestational diabetes\n  mellitus: a review",
        "authors": [
            "Tajudeen Yahaya",
            "Titilola Salisu",
            "Yusuf Abdulrahman",
            "Abdulrazak Umar"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: Many studies have been conducted on the genetic and epigenetic\netiology of gestational diabetes mellitus (GDM) in the last two decades because\nof the diseases increasing prevalence and role in the global diabetes mellitus\n(DM) explosion. An update on the genetic and epigenetic etiology of GDM then\nbecomes imperative to better understand and stem the rising incidence of the\ndisease. This review, therefore, articulated GDM candidate genes and their\npathophysiology for the awareness of stakeholders. Main body (genetic and\nepigenetic etiology, GDM): The search discovered 83 GDM candidate genes, of\nwhich TCF7L2, MTNR1B, CDKAL1, IRS1, and KCNQ1 are the most prevalent. Certain\npolymorphisms of these genes can modulate beta-cell dysfunction, adiposity,\nobesity, and insulin resistance through several mechanisms. Environmental\ntriggers such as diets, pollutants, and microbes may also cause epigenetic\nchanges in these genes, resulting in a loss of insulin-boosting and glucose\nmetabolism functions. Early detection and adequate management may resolve the\ncondition after delivery; otherwise, it will progress to maternal type 2\ndiabetes mellitus (T2DM) and fetal configuration to future obesity and DM. This\nshows that GDM is a strong risk factor for T2DM and, in rare cases, type 1\ndiabetes mellitus (T1DM) and maturity-onset diabetes of the young (MODY). This\nfurther shows that GDM significantly contributes to the rising incidence and\nburden of DM worldwide and its prevention may reverse the trend. Conclusion:\nMutations and epigenetic changes in certain genes are strong risk factors for\nGDM. For affected individuals with such etiologies, medical practitioners\nshould formulate drugs and treatment procedures that target these genes and\ntheir pathophysiology.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.07350v1"
    },
    {
        "title": "Protocol for Executing and Benchmarking Eight Computational\n  Doublet-Detection Methods in Single-Cell RNA Sequencing Data Analysis",
        "authors": [
            "Nan Miles Xi",
            "Jingyi Jessica Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The existence of doublets is a key confounder in single-cell RNA sequencing\n(scRNA-seq) data analysis. Computational methods have been developed for\ndetecting doublets from scRNA-seq data. We developed an R package\nDoubletCollection to integrate the installation and execution of eight\ndoublet-detection methods. DoubletCollection also provides a unified interface\nto perform and visualize downstream analysis after doublet detection. Here, we\npresent a protocol of using DoubletCollection to benchmark doublet-detection\nmethods. This protocol can automatically accommodate new doublet-detection\nmethods in the fast-growing scRNA-seq field.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.08860v3"
    },
    {
        "title": "Unexpected novel Merbecovirus discoveries in agricultural sequencing\n  datasets from Wuhan, China",
        "authors": [
            "Daoyu Zhang",
            "Adrian Jones",
            "Yuri Deigin",
            "Karl Sirotkin",
            "Alejandro Sousa"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  In this study we document the unexpected discovery of multiple coronaviruses\nand a BSL-3 pathogen in agricultural cotton and rice sequencing datasets. In\nparticular, we have identified a novel HKU5-related Merbecovirus in a cotton\ndataset sequenced by the Huazhong Agricultural University in 2017. We have also\nfound an infectious clone sequence containing a novel HKU4-related Merbecovirus\nrelated to MERS coronavirus in a rice dataset sequenced by the Huazhong\nAgricultural University in early 2020. Another HKU5-related Merbecovirus, as\nwell as Japanese encephalitis virus, were identified in a cotton dataset\nsequenced by the Huazhong Agricultural University in 2018. An HKU3-related\nBetacoronavirus was found in a Mus musculus sequencing dataset from the Wuhan\nInstitute of Virology in 2017. Finally, a SARS-WIV1-like Betacoronavirus was\nfound in a rice dataset sequenced by the Fujian Agriculture and Forestry\nUniversity in 2017. Using the contaminating reads we have extracted from the\nabove datasets, we were able to assemble complete genomes of two novel\ncoronaviruses which we disclose herein. In light of our findings, we raise\nconcerns about biosafety protocol breaches, as indicated by our discovery of\nmultiple dangerous human pathogens in agricultural sequencing laboratories in\nWuhan and Fouzou City, China.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.01533v2"
    },
    {
        "title": "Functional annotation of creeping bentgrass protein sequences based on\n  convolutional neural network",
        "authors": [
            "Han-Yu Jiang",
            "Jun He"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: Creeping bentgrass (Agrostis soionifera) is a perennial grass of\nGramineae, belonging to cold season turfgrass, but has poor disease resistance.\nUp to now, little is known about the induced systemic resistance (ISR)\nmechanism, especially the relevant functional proteins, which is important to\ndisease resistance of turfgrass. Achieving more information of proteins of\ninfected creeping bentgrass is helpful to understand the ISR mechanism.\nResults: With BDO treatment, creeping bentgrass seedlings were grown, and the\nISR response was induced by infecting Rhizoctonia solani. High-quality protein\nsequences of creeping bentgrass seedlings were obtained. Some of protein\nsequences were functionally annotated according to the database alignment while\na large part of the obtained protein sequences was left non-annotated. To treat\nthe non-annotated sequences, a prediction model based on convolutional neural\nnetwork was established with the dataset from Uniport database in three domains\nto acquire good performance, especially the higher false positive control rate.\nWith established model, the non-annotated protein sequences of creeping\nbentgrass were analyzed to annotate proteins relevant to disease-resistance\nresponse and signal transduction. Conclusions: The prediction model based on\nconvolutional neural network was successfully applied to select good candidates\nof the proteins with functions relevant to the ISR mechanism from the protein\nsequences which cannot be annotated by database alignment. The waste of\nsequence data can be avoided, and research time and labor will be saved in\nfurther research of protein of creeping bentgrass by molecular biology\ntechnology. It also provides reference for other sequence analysis of turfgrass\ndisease-resistance research.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.03139v2"
    },
    {
        "title": "Integration of Unpaired Single-cell Chromatin Accessibility and Gene\n  Expression Data via Adversarial Learning",
        "authors": [
            "Yang Xu",
            "Andrew Jeremiah Strick"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Deep learning has empowered analysis for single-cell sequencing data in many\nways and has generated deep understanding about a range of complex cellular\nsystems. As the booming single-cell sequencing technologies brings the surge of\nhigh dimensional data that come from different sources and represent cellular\nsystems with different features, there is an equivalent rise and challenge of\nintegrating single-cell sequence across modalities. Here, we present a novel\nadversarial approach to integrate single-cell chromatin accessibility and gene\nexpression data in a semi-supervised manner. We demonstrate that our method\nsubstantially improves data integration from a simple adversarial domain\nadaption approach, and it also outperforms two state-of-the-art (SOTA) methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.12320v1"
    },
    {
        "title": "snpQT: flexible, reproducible, and comprehensive quality control and\n  imputation of genomic data",
        "authors": [
            "Christina Vasilopoulou",
            "Benjamin Wingfield",
            "Andrew P. Morris",
            "William Duddy"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: Quality control of genomic data is an essential but complicated\nmulti-step procedure, often requiring separate installation and expert\nfamiliarity with a combination of disparate bioinformatics tools. Results: To\nprovide an automated solution that retains comprehensive quality checks and\nflexible workflow architecture, we have developed snpQT, a scalable,\nstand-alone software pipeline, offering some 36 discrete quality filters or\ncorrection steps, with plots before-and-after user-modifiable thresholding.\nThis includes build conversion, population stratification against 1,000 Genomes\ndata, population outlier removal, and built-in imputation with its own pre- and\npost- quality controls. Common input formats are used and users need not be\nsuperusers nor have any prior coding experience. A comprehensive online\ntutorial and installation guide is provided through to GWAS\n(https://snpqt.readthedocs.io/en/latest/), introducing snpQT using a synthetic\ndemonstration dataset and a real-world Amyotrophic Lateral Sclerosis SNP-array\ndataset. Availability: snpQT is open source and freely available at\nhttps://github.com/nebfield/snpQT Contact: Vasilopoulou-C@ulster.ac.uk,\nw.duddy@ulster.ac.uk\n",
        "pdf_link": "http://arxiv.org/pdf/2105.01923v1"
    },
    {
        "title": "Accelerating SARS-CoV-2 low frequency variant calling on ultra deep\n  sequencing datasets",
        "authors": [
            "Bryce Kille",
            "Yunxi Liu",
            "Nicolae Sapoval",
            "Michael Nute",
            "Lawrence Rauchwerger",
            "Nancy Amato",
            "Todd J. Treangen"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  With recent advances in sequencing technology it has become affordable and\npractical to sequence genomes to very high depth-of-coverage, allowing\nresearchers to discover low-frequency variants in the genome. However, due to\nthe errors in sequencing it is an active area of research to develop algorithms\nthat can separate noise from the true variants. LoFreq is a state of the art\nalgorithm for low-frequency variant detection but has a relatively long runtime\ncompared to other tools. In addition to this, the interface for running in\nparallel could be simplified, allowing for multithreading as well as\ndistributing jobs to a cluster. In this work we describe some specific\ncontributions to LoFreq that remedy these issues.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03062v1"
    },
    {
        "title": "maplet: An extensible R toolbox for modular and reproducible omics\n  pipelines",
        "authors": [
            "Kelsey Chetnik",
            "Elisa Benedetti",
            "Daniel P. Gomari",
            "Annalise Schweickart",
            "Richa Batra",
            "Mustafa Buyukozkan",
            "Zeyu Wang",
            "Matthias Arnold",
            "Jonas Zierer",
            "Karsten Suhre",
            "Jan Krumsiek"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  This paper presents maplet, an open-source R package for the creation of\nhighly customizable, fully reproducible statistical pipelines for omics data\nanalysis, with a special focus on metabolomics-based methods. It builds on the\nSummarizedExperiment data structure to create a centralized pipeline framework\nfor storing data, analysis steps, results, and visualizations. maplet's key\ndesign feature is its modularity, which offers several advantages, such as\nensuring code quality through the individual maintenance of functions and\npromoting collaborative development by removing technical barriers to code\ncontribution. With over 90 functions, the package includes a wide range of\nfunctionalities, covering many widely used statistical approaches and data\nvisualization techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.04305v1"
    },
    {
        "title": "Survival prediction of head and neck squamous cell carcinoma using\n  machine learning models",
        "authors": [
            "Saurav Mandal",
            "Akshansh Gupta",
            "Waribam Pratibha Chanu"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Head and Neck Squamous Cell Carcinoma (HNSCC) is one of cancer type that is\nmost distressing leading to acute pain, effecting speech and primary survival\nfunctions such as swallowing and breathing. The morbidity and mortality of\nHNSCC patients have not significantly improved even tough there has been\nadvancement in surgical and radiotherapy treatments. The high mortality may be\nattributed to the complexity and significant changes in the clinical outcomes.\nTherefore, it is important to increase the accuracy of predicting the outcome\nof cancer survival. Few cancer survival prediction models of HNSCC have been\nproposed so far. In this study, genomic data (whole exome sequencing) are\nintegrated with clinical data to improve the performance of prediction model.\nThe somatic mutations of every patient is processed using Multifractal\nDeterended Fluctuation Analysis (MFDFA) algorithm and the parameter values of\nFractal Dimension (Dq) is included along with clinical data for cancer survival\nprediction. Feature ranking proves that the new engineered feature is one of\nthe important feature in prediction model. In order to improve the performance\nindex of models, hyperparameters were also tuned in all the classifiers\nconsidered. 10-Fold cross validation is implemented and XGBoost (98% AUROC, 94%\nprecision, and 93% recall) proves to be best model classifier followed by\nRandom Forest 93% AUROC, 93% precision, and 93% recall), Support Vector Machine\n(84% AUCROC, 79% precision, and 79% recall) and Logistic Regression (80% AUROC,\n77% precision, and 76% recall).\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07390v1"
    },
    {
        "title": "Prospects for Multi-omics in the Microbial Ecology of Water Engineering",
        "authors": [
            "Elizabeth A. McDaniel",
            "Sebastian Aljoscha Wahl",
            "Shun'ichi Ishii",
            "Ameet Pinto",
            "Ryan Ziels",
            "Per H. Nielsen",
            "Katherine D. McMahon",
            "Rohan B. H. Williams"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Advances in high-throughput sequencing technologies and bioinformatics\napproaches over almost the last three decades have substantially increased our\nability to explore microorganisms and their functions-including those that have\nyet to be cultivated in pure isolation. Genome-resolved metagenomic approaches\nhave enabled linking powerful functional predictions to specific taxonomical\ngroups with increasing fidelity. Additionally, whole community gene expression\nsurveys and metabolite profiling have permitted direct surveys of\ncommunity-scale functions in specific environmental settings. These advances\nhave allowed for a shift in microbiome science away from descriptive studies\nand towards mechanistic and predictive frameworks for designing and harnessing\nmicrobial communities for desired beneficial outcomes. Here, we review how\nmodern genome-resolved metagenomic approaches have been applied to a variety of\nwater engineering applications from lab-scale bioreactors to full-scale\nsystems. We describe integrated omics analysis across engineered water systems\nand the foundations for pairing these insights with modeling approaches.\nLastly, we summarize emerging omics-based technologies that we believe will be\npowerful tools for water engineering applications. Overall, we provide a\nframework for microbial ecologists specializing in water engineering to apply\ncutting-edge omics approaches to their research questions to achieve novel\nfunctional insights. Successful adoption of predictive frameworks in engineered\nwater systems could enable more economically and environmentally sustainable\nbioprocesses as demand for water and energy resources increases.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08856v1"
    },
    {
        "title": "High rate of SARS-CoV2 nonsense spike genomes coding for prematurely\n  truncated proteins",
        "authors": [
            "Alessio D'Alessandro"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Replication of SARS-CoV2 virions is an error-prone process which may\neventually generate a percentage of impaired protein copies with complete lack\nof functionality. For instance, after RNA mis-replication, a very premature\nstop codon (UAG, UAA, UGA) coding for a prematurely truncated\n(nonsense-mutated) spike protein may occur.\n  In the natural virus replication process via cell infection, the nonsense\ngenomes are corrected by the proofreading enzymes of the virus, strongly\npenalized by natural selection and condemned to a very short life by the host\ncell's mRNA watching mechanisms. However, for the very long spike genome of\n1273 codons, a truncated non-functional spike protein may potentially still\noccur with a high frequency, even in presence of a low mutation rate per single\nnucleotide.\n  With this paper, a hi-fidelity post-processing of SARS-CoV2 spike sequences\nis provided: in ex-vivo samples from patients, an impressively high rate of\n26\\% of prematurely-stopped (nonsense-mutated) spike genomes sequences due to\ninsertions/deletions is found, compared with a 9.7\\% obtained from in-vitro\ncell culture.\n  A general warning on the possible high rate of prematurely-stopped spike\nprotein sequences is also raised for \"artificial\" de novo DNA synthesis\nprocesses of SARS-CoV2 spike genomes with no associated natural\nproofreading/selection, possibly including vaccine preparations.\n  Finally, a metric based on the ratio between prematurely stopped and \"normal\"\ngenomes is proposed as a potential host-independent variant-watching tool, able\nto classify the infectivity of new spike mutations.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10074v2"
    },
    {
        "title": "A Multi-task Deep Feature Selection Method for Brain Imaging Genetics",
        "authors": [
            "Chenglin Yu",
            "Dingnan Cui",
            "Muheng Shang",
            "Shu Zhang",
            "Lei Guo",
            "Junwei Han",
            "Lei Du",
            "Alzheimer's Disease Neuroimaging Initiative"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Using brain imaging quantitative traits (QTs) to identify the genetic risk\nfactors is an important research topic in imaging genetics. Many efforts have\nbeen made via building linear models, e.g. linear regression (LR), to extract\nthe association between imaging QTs and genetic factors such as single\nnucleotide polymorphisms (SNPs). However, to the best of our knowledge, these\nlinear models could not fully uncover the complicated relationship due to the\nloci's elusive and diverse impacts on imaging QTs. Though deep learning models\ncan extract the nonlinear relationship, they could not select relevant genetic\nfactors. In this paper, we proposed a novel multi-task deep feature selection\n(MTDFS) method for brain imaging genetics. MTDFS first adds a multi-task\none-to-one layer and imposes a hybrid sparsity-inducing penalty to select\nrelevant SNPs making significant contributions to abnormal imaging QTs. It then\nbuilds a multi-task deep neural network to model the complicated associations\nbetween imaging QTs and SNPs. MTDFS can not only extract the nonlinear\nrelationship but also arms the deep neural network with the feature selection\ncapability. We compared MTDFS to both LR and single-task DFS (DFS) methods on\nthe real neuroimaging genetic data. The experimental results showed that MTDFS\nperformed better than both LR and DFS in terms of the QT-SNP relationship\nidentification and feature selection. In a word, MTDFS is powerful for\nidentifying risk loci and could be a great supplement to the method library for\nbrain imaging genetics.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00388v1"
    },
    {
        "title": "Sramm: short read alignment mapping metrics",
        "authors": [
            "Alvin Chon",
            "Xiaoqiu Huang"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Short Read Alignment Mapping Metrics (SRAMM): is an efficient and versatile\ncommand line tool providing additional short read mapping metrics, filtering,\nand graphs. Short read aligners report MAPing Quality (MAPQ), but these methods\ngenerally are neither standardized nor well described in literature or software\nmanuals. Additionally, third party mapping quality programs are typically\ncomputationally intensive or designed for specific applications. SRAMM\nefficiently generates multiple different concept-based mapping scores to\nprovide for an informative post alignment examination and filtering process of\naligned short reads for various downstream applications. SRAMM is compatible\nwith Python 2.6+ and Python 3.6+ on all operating systems. It works with any\nshort read aligner that generates SAM/BAM/CRAM file outputs and reports 'AS'\ntags. It is freely available under the MIT license at\nhttp://github.com/achon/sramm.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.02935v1"
    },
    {
        "title": "Stool Studies Don't Pass the Sniff Test: A Systematic Review of Human\n  Gut Microbiome Research Suggests Widespread Misuse of Machine Learning",
        "authors": [
            "Thomas P. Quinn"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  In the machine learning culture, an independent test set is required for\nproper model verification. Failures in model verification, including test set\nomission and test set leakage, make it impossible to know whether or not a\ntrained model is fit for purpose. In this article, we present a systematic\nreview and quantitative analysis of human gut microbiome classification\nstudies, conducted to measure the frequency and impact of test set omission and\ntest set leakage on area under the receiver operating curve (AUC) reporting.\nAmong 102 articles included for analysis, we find that only 12% of studies\nreport a bona fide test set AUC, meaning that the published AUCs for 88% of\nstudies cannot be trusted at face value. Our findings cast serious doubt on the\ngeneral validity of research claiming that the gut microbiome has high\ndiagnostic or prognostic potential in human disease.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.03611v1"
    },
    {
        "title": "Variant-driven multi-wave pattern of COVID-19 via a Machine Learning\n  analysis of spike protein mutations",
        "authors": [
            "Adele de Hoffer",
            "Shahram Vatani",
            "Corentin Cot",
            "Giacomo Cacciapaglia",
            "Maria Luisa Chiusano",
            "Andrea Cimarelli",
            "Francesco Conventi",
            "Antonio Giannini",
            "Stefan Hohenegger",
            "Francesco Sannino"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Applying a ML approach to the temporal variability of the Spike protein\nsequence enables us to identify, classify and track emerging virus variants.\nOur analysis is unbiased, in the sense that it does not require any prior\nknowledge of the variant characteristics, and our results are validated by\nother informed methods that define variants based on the complete genome.\nFurthermore, correlating persistent variants of our approach to epidemiological\ndata, we discover that each new wave of the COVID-19 pandemic is driven and\ndominated by a new emerging variant. Our results are therefore indispensable\nfor further studies on the evolution of SARS-CoV-2 and the prediction of\nevolutionary patterns that determine current and future mutations of the Spike\nproteins, as well as their diversification and persistence during the viral\nspread. Moreover, our ML algorithm works as an efficient early warning system\nfor the emergence of new persistent variants that may pose a threat of\ntriggering a new wave of COVID-19. Capable of a timely identification of\npotential new epidemiological threats when the variant only represents 1% of\nthe new sequences, our ML strategy is a crucial tool for decision makers to\ndefine short and long term strategies to curb future outbreaks. The same\nmethodology can be applied to other viral diseases, influenza included, if\nsufficient sequencing data is available.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.10115v2"
    },
    {
        "title": "Variant interpretation using population databases: lessons from gnomAD",
        "authors": [
            "Sanna Gudmundsson",
            "Moriel Singer-Berk",
            "Nicholas A. Watts",
            "William Phu",
            "Julia K. Goodrich",
            "Matthew Solomonson",
            "Genome Aggregation Database Consortium",
            "Heidi L. Rehm",
            "Daniel G. MacArthur",
            "Anne ODonnell-Luria"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Reference population databases are an essential tool in variant and gene\ninterpretation. Their use guides the identification of pathogenic variants\namidst the sea of benign variation present in every human genome, and supports\nthe discovery of new disease-gene relationships. The Genome Aggregation\nDatabase (gnomAD) is currently the largest and most widely used publicly\navailable collection of population variation from harmonized sequencing data.\nThe data is available through the online gnomAD browser\n(https://gnomad.broadinstitute.org/) that enables rapid and intuitive variant\nanalysis. This review provides guidance on the content of the gnomAD browser,\nand its usage for variant and gene interpretation. We introduce key features\nincluding allele frequency, per-base expression levels, constraint scores, and\nvariant co-occurrence, alongside guidance on how to use these in analysis, with\na focus on the interpretation of candidate variants and novel genes in rare\ndisease.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11458v3"
    },
    {
        "title": "Bam-readcount -- rapid generation of basepair-resolution sequence\n  metrics",
        "authors": [
            "Ajay Khanna",
            "David E. Larson",
            "Sridhar Nonavinkere Srivatsan",
            "Matthew Mosior",
            "Travis E. Abbott",
            "Susanna Kiwala",
            "Timothy J. Ley",
            "Eric J. Duncavage",
            "Matthew J. Walter",
            "Jason R. Walker",
            "Obi L. Griffith",
            "Malachi Griffith",
            "Christopher A. Miller"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Bam-readcount is a utility for generating low-level information about\nsequencing data at specific nucleotide positions. Originally designed to help\nfilter genomic mutation calls, the metrics it outputs are useful as input for\nvariant detection tools and for resolving ambiguity between variant callers .\nIn addition, it has found broad applicability in diverse fields including tumor\nevolution, single-cell genomics, climate change ecology, and tracking community\nspread of SARS-CoV-2. Here we report on the release of version 1.0 of this\ntool, which adds CRAM support, among other improvements. It is released under a\npermissive MIT license and available at\nhttps://github.com/genome/bam-readcount.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.12817v1"
    },
    {
        "title": "OncoEnrichR: cancer-dedicated gene set interpretation",
        "authors": [
            "Sigve Nakken",
            "Sveinung Gundersen",
            "Fabian L. M. Bernal",
            "Dimitris Polychronopoulos",
            "Eivind Hovig",
            "Jørgen Wesche"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Genome-scale screening experiments in cancer produce long lists of candidate\ngenes that require extensive interpretation for biological insight and\nprioritization for follow-up studies. Interrogation of gene lists frequently\nrepresents a significant and time-consuming undertaking, in which experimental\nbiologists typically combine results from a variety of bioinformatics resources\nin an attempt to portray and understand cancer relevance. As a means to\nsimplify and strengthen the support for this endeavor, we have developed\noncoEnrichR, a flexible bioinformatics tool that allows cancer researchers to\ncomprehensively interrogate a given gene list along multiple facets of cancer\nrelevance. oncoEnrichR differs from general gene set analysis frameworks\nthrough the integration of an extensive set of prior knowledge specifically\nrelevant for cancer, including ranked gene-tumor type associations,\nliterature-supported proto-oncogene and tumor suppressor gene annotations,\ntarget druggability data, regulatory interactions, synthetic lethality\npredictions, as well as prognostic associations, gene aberrations, and\nco-expression patterns across tumor types. The software produces a structured\nand user-friendly analysis report as its main output, where versions of all\nunderlying data resources are explicitly logged, the latter being a critical\ncomponent for reproducible science. We demonstrate the usefulness of\noncoEnrichR through interrogation of two candidate lists from proteomic and\nCRISPR screens. oncoEnrichR is freely available as a web-based workflow hosted\nby the Galaxy platform (https://oncotools.elixir.no), and can also be accessed\nas a stand-alone R package (https://github.com/sigven/oncoEnrichR).\n",
        "pdf_link": "http://arxiv.org/pdf/2107.13247v3"
    },
    {
        "title": "New strategies to improve minimap2 alignment accuracy",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Summary: We present several recent improvements to minimap2, a versatile\npairwise aligner for nucleotide sequences. Now minimap2 v2.22 can more\naccurately map long reads to highly repetitive regions and align through\ninsertions or deletions up to 100kb by default, addressing major weakness in\nminimap2 v2.18 or earlier.\n  Availability and implementation: https://github.com/lh3/minimap2\n",
        "pdf_link": "http://arxiv.org/pdf/2108.03515v1"
    },
    {
        "title": "SquiggleFilter: An Accelerator for Portable Virus Detection",
        "authors": [
            "Tim Dunn",
            "Harisankar Sadasivan",
            "Jack Wadden",
            "Kush Goliya",
            "Kuan-Yu Chen",
            "Reetuparna Das",
            "David Blaauw",
            "Satish Narayanasamy"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The MinION is a recent-to-market handheld nanopore sequencer. It can be used\nto determine the whole genome of a target virus in a biological sample. Its\nRead Until feature allows us to skip sequencing a majority of non-target reads\n(DNA/RNA fragments), which constitutes more than 99% of all reads in a typical\nsample. However, it does not have any on-board computing, which significantly\nlimits its portability.\n  We analyze the performance of a Read Until metagenomic pipeline for detecting\ntarget viruses and identifying strain-specific mutations. We find new sources\nof performance bottlenecks (basecaller in classification of a read) that are\nnot addressed by past genomics accelerators.\n  We present SquiggleFilter, a novel hardware accelerated dynamic time warping\n(DTW) based filter that directly analyzes MinION's raw squiggles and filters\neverything except target viral reads, thereby avoiding the expensive\nbasecalling step. We show that our 14.3W 13.25mm2 accelerator has 274X greater\nthroughput and 3481X lower latency than existing GPU-based solutions while\nconsuming half the power, enabling Read Until for the next generation of\nnanopore sequencers.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.06610v2"
    },
    {
        "title": "Analysis of pangolin metagenomic datasets reveals significant\n  contamination, raising concerns for pangolin CoV host attribution",
        "authors": [
            "Adrian Jones",
            "Daoyu Zhang",
            "Yuri Deigin",
            "Steven C. Quay"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Metagenomic datasets from pangolin tissue specimens have previously yielded\nSARS-related coronaviruses which show high homology in their receptor binding\ndomain to SARS-CoV-2, suggesting a potential zoonotic source for this feature\nof the human virus, possibly via recombination (Liu et al. 2019, Lam et al.\n2020, Xiao et al. 2020, Liu et al. 2020). Here we re-examine these published\ndatasets. We report that only a few pangolin samples were found to contain\ncoronavirus reads, and even then in low abundance, while other non-pangolin\nhosted viruses were present in higher abundance. We also discovered extensive\ncontamination with human, rodent, and other mammalian gene sequences, which was\na surprising finding. Furthermore, we uncovered a number of pangolin CoV\nsequences embedded in standard laboratory cloning vectors, which suggests the\npangolin specimens could have been contaminated with sequences derived from\nsynthetic biology experiments. Finally, we discover a third pangolin dataset\n(He et al. 2022) with low levels of SARSr-CoV sequences and unambiguous\nextensive contamination of several pangolin samples. For these reasons, we find\nit unlikely that the pangolins in question had a coronavirus infection while\nalive, and all current versions of the cited papers claiming a zoonotic\ninfection of pangolins with a SARS-r CoV require substantial corrections and\nshould be retracted until such corrections are made.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.08163v3"
    },
    {
        "title": "A review of computational tools for generating metagenome-assembled\n  genomes from metagenomic sequencing data",
        "authors": [
            "Chao Yang",
            "Debajyoti Chowdhury",
            "Zhenmiao Zhang",
            "William K. Cheung",
            "Aiping Lu",
            "Zhao Xiang Bian",
            "Lu Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Microbes are essentially yet convolutedly linked with human lives on the\nearth. They critically interfere in different physiological processes and thus\ninfluence overall health status. Studying microbial species is used to be\nconstrained to those that can be cultured in the lab. But it excluded a huge\nportion of the microbiome that could not survive on lab conditions. In the past\nfew years, the culture-independent metagenomic sequencing enabled us to explore\nthe complex microbial community coexisting within and on us. Metagenomics has\nequipped us with new avenues of investigating the microbiome, from studying a\nsingle species to a complex community in a dynamic ecosystem. Thus, identifying\nthe involved microbes and their genomes becomes one of the core tasks in\nmetagenomic sequencing. Metagenome-assembled genomes are groups of contigs with\nsimilar sequence characteristics from de novo assembly and could represent the\nmicrobial genomes from metagenomic sequencing. In this paper, we reviewed a\nspectrum of tools for producing and annotating metagenome-assembled genomes\nfrom metagenomic sequencing data and discussed their technical and biological\nperspectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.00809v1"
    },
    {
        "title": "Robust haplotype-resolved assembly of diploid individuals without\n  parental data",
        "authors": [
            "Haoyu Cheng",
            "Erich D. Jarvis",
            "Olivier Fedrigo",
            "Klaus-Peter Koepfli",
            "Lara Urban",
            "Neil J. Gemmell",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Routine single-sample haplotype-resolved assembly remains an unresolved\nproblem. Here we describe a new algorithm that combines PacBio HiFi reads and\nHi-C chromatin interaction data to produce a haplotype-resolved assembly\nwithout the sequencing of parents. Applied to human and other vertebrate\nsamples, our algorithm consistently outperforms existing single-sample assembly\npipelines and generates assemblies of comparable quality to the best\npedigree-based assemblies.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.04785v1"
    },
    {
        "title": "Deep learning tackles single-cell analysis A survey of deep learning for\n  scRNA-seq analysis",
        "authors": [
            "Mario Flores",
            "Zhentao Liu",
            "Ting-He Zhang",
            "Md Musaddaqui Hasib",
            "Yu-Chiao Chiu",
            "Zhenqing Ye",
            "Karla Paniagua",
            "Sumin Jo",
            "Jianqiu Zhang",
            "Shou-Jiang Gao",
            "Yu-Fang Jin",
            "Yidong Chen",
            "Yufei Huang"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Since its selection as the method of the year in 2013, single-cell\ntechnologies have become mature enough to provide answers to complex research\nquestions. With the growth of single-cell profiling technologies, there has\nalso been a significant increase in data collected from single-cell profilings,\nresulting in computational challenges to process these massive and complicated\ndatasets. To address these challenges, deep learning (DL) is positioning as a\ncompetitive alternative for single-cell analyses besides the traditional\nmachine learning approaches. Here we present a processing pipeline of\nsingle-cell RNA-seq data, survey a total of 25 DL algorithms and their\napplicability for a specific step in the processing pipeline. Specifically, we\nestablish a unified mathematical representation of all variational autoencoder,\nautoencoder, and generative adversarial network models, compare the training\nstrategies and loss functions for these models, and relate the loss functions\nof these models to specific objectives of the data processing step. Such\npresentation will allow readers to choose suitable algorithms for their\nparticular objective at each step in the pipeline. We envision that this survey\nwill serve as an important information portal for learning the application of\nDL for scRNA-seq analysis and inspire innovative use of DL to address a broader\nrange of new challenges in emerging multi-omics and spatial single-cell\nsequencing.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.12404v1"
    },
    {
        "title": "Metagenome assembly of high-fidelity long reads with hifiasm-meta",
        "authors": [
            "Xiaowen Feng",
            "Haoyu Cheng",
            "Daniel Portik",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Current metagenome assemblers developed for short sequence reads or noisy\nlong readswere not optimized for accurate long reads. Here we describe\nhifiasm-meta, a new metagenome assembler that exploits the high accuracy of\nrecent data. Evaluated on seven empirical datasets, hifiasm-meta reconstructed\ntens to hundreds of complete circular bacterial genomes per dataset,\nconsistently outperforming other metagenome assemblers.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08457v1"
    },
    {
        "title": "An optimized protocol for single cell transcriptional profiling by\n  combinatorial indexing",
        "authors": [
            "Beth K. Martin",
            "Chengxiang Qiu",
            "Eva Nichols",
            "Melissa Phung",
            "Rula Green-Gladden",
            "Sanjay Srivatsan",
            "Ronnie Blecher-Gonen",
            "Brian J. Beliveau",
            "Cole Trapnell",
            "Junyue Cao",
            "Jay Shendure"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Single cell combinatorial indexing RNA sequencing (sci-RNA-seq) is a powerful\nmethod for recovering gene expression data from an exponentially scalable\nnumber of individual cells or nuclei. However, sci-RNA-seq is a complex\nprotocol that has historically exhibited variable performance on different\ntissues, as well as lower sensitivity than alternative methods. Here we report\na simplified, optimized version of the three-level sci-RNA-seq protocol that is\nfaster, higher yield, more robust, and more sensitive, than the original\nsci-RNA-seq3 protocol, with reagent costs on the order of 1 cent per cell or\nless. We showcase the optimized protocol via whole organism analysis of an\nE16.5 mouse embryo, profiling ~380,000 nuclei in a single experiment. Finally,\nwe introduce a \"tiny sci-*\" protocol for experiments where input is extremely\nlimited.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.15400v4"
    },
    {
        "title": "SARS-CoV-2's closest relative, RaTG13, was generated from a bat\n  transcriptome not a fecal swab: implications for the origin of COVID-19",
        "authors": [
            "Steven E Massey"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  RaTG13 is the closest related coronavirus genome phylogenetically to\nSARS-CoV-2, consequently understanding its provenance is of key importance to\nunderstanding the origin of the COVID-19 pandemic. The RaTG13 NGS dataset is\nattributed to a fecal swab from the intermediate horseshoe bat Rhinolophus\naffinis. However, sequence analysis reveals that this is unlikely. Metagenomic\nanalysis using Metaxa2 shows that only 10.3 % of small subunit (SSU) rRNA\nsequences in the dataset are bacterial, inconsistent with a fecal sample, which\nare typically dominated by bacterial sequences. In addition, the bacterial taxa\npresent in the sample are inconsistent with fecal material. Assembly of\nmitochondrial SSU rRNA sequences in the dataset produces a contig 98.7 %\nidentical to R.affinis mitochondrial SSU rRNA, indicating that the sample was\ngenerated from this or a closely related species. 87.5 % of the NGS reads map\nto the Rhinolophus ferrumequinum genome, the closest bat genome to R.affinis\navailable. In the annotated genome assembly, 62.2 % of mapped reads map to\nprotein coding genes. These results clearly demonstrate that the dataset\nrepresents a Rhinolophus sp. transcriptome, and not a fecal swab sample.\nOverall, the data show that the RaTG13 dataset was generated by the Wuhan\nInstitute of Virology (WIV) from a transcriptome derived from Rhinolophus sp.\ntissue or cell line, indicating that RaTG13 was in live culture. This raises\nthe question of whether the WIV was culturing additional unreported\ncoronaviruses closely related to SARS-CoV-2 prior to the pandemic. The\nimplications for the origin of the COVID-19 pandemic are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09469v2"
    },
    {
        "title": "CRISPR SWAPnDROP -- A multifunctional system for genome editing and\n  large-scale interspecies gene transfer",
        "authors": [
            "Marc Teufel",
            "Carlo A. Klein",
            "Maurice Mager",
            "Patrick Sobetzko"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The need for diverse chromosomal modifications in biotechnology, synthetic\nbiology and basic research requires the development of new technologies. With\nCRISPR SWAPnDROP, we extend the limits of genome editing to large-scale in-vivo\nDNA transfer between bacterial species. Its modular platform approach\nfacilitates species specific adaptation to confer genome editing in various\nspecies. In this study, we show the implementation of the CRISPR SWAPnDROP\nconcept for the model organism Escherichia coli and the currently fastest\ngrowing and biotechnologically relevant organism Vibrio natriegens. We\ndemonstrate the excision, transfer and integration of 151kb chromosomal DNA\nbetween E. coli strains and from E. coli to V. natriegens without size-limiting\nintermediate DNA extraction. With the transfer of the E. coli MG1655 wild type\nlac operon, we establish a functional lactose and galactose degradation pathway\nin V. natriegens to extend its biotechnological spectrum. We also transfer the\nE. coli DH5alpha lac operon and make V. natriegens capable of\nalpha-complementation - a step towards an ultra-fast cloning strain.\nFurthermore, CRISPR SWAPnDROP is designed to be the swiss army knife of genome\nengineering. Its spectrum of application comprises scarless, marker-free,\niterative and parallel insertions and deletions, genome rearrangements, as well\nas gene transfer between strains and across species. The modular character\nfacilitates DNA library applications and the recycling of standardized parts.\nIts novel multi-color scarless co-selection system significantly improves\nediting efficiency to 92% for single edits and 83% for quadruple edits and\nprovides visual quality controls throughout the assembly and editing process.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.11880v1"
    },
    {
        "title": "EndHiC: assemble large contigs into chromosomal-level scaffolds using\n  the Hi-C links from contig ends",
        "authors": [
            "Sen Wang",
            "Hengchao Wang",
            "Fan Jiang",
            "Anqi Wang",
            "Hangwei Liu",
            "Hanbo Zhao",
            "Boyuan Yang",
            "Dong Xu",
            "Yan Zhang",
            "Wei Fan"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: The application of PacBio HiFi and ultra-long ONT reads have\nachieved huge progress in the contig-level assembly, but it is still\nchallenging to assemble large contigs into chromosomes with available Hi-C\nscaffolding software, which all compute the contact value between contigs using\nthe Hi-C links from the whole contig regions. As the Hi-C links of two adjacent\ncontigs concentrate only at the neighbor ends of the contigs, larger contig\nsize will reduce the power to differentiate adjacent (signal) and non-adjacent\n(noise) contig linkages, leading to a higher rate of mis-assembly.\n  Results: We present a software package EndHiC, which is suitable to assemble\nlarge contigs (> 1-Mb) into chromosomal-level scaffolds, using Hi-C links from\nonly the contig end regions instead of the whole contig regions. Benefiting\nfrom the increased signal to noise ratio, EndHiC achieves much higher\nscaffolding accuracy compared to existing software LACHESIS, ALLHiC, and\n3D-DNA. Moreover, EndHiC has few parameters, runs 10-1000 times faster than\nexisting software, needs trivial memory, provides robustness evaluation, and\nallows graphic viewing of the scaffold results. The high scaffolding accuracy\nand user-friendly interface of EndHiC, liberate the users from labor-intensive\nmanual checks and revision works.\n  Availability and implementation: EndHiC is written in Perl, and is freely\navailable at https://github.com/fanagislab/EndHiC. Contact: fanwei@caas.cn and\nmilrazhang@163.com Supplementary information: Supplementary data are available\nat Bioinformatics online.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.15411v1"
    },
    {
        "title": "Classification of genetic variants using machine learning",
        "authors": [
            "Abhinav Jain",
            "Greg Slabaugh",
            "Deepti Gurdasani"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Recent advances in genomic sequencing technology have resulted in an\nabundance of genome sequence data. Despite the progress in interpreting those\ndata, there remains a broad scope for their translation into clinical and\nsocietal benefits. Loss-of-function variations in the human genome can be\ncausal in disease development. Precise identification of such variations and\npathogenicity prediction may lead to better drug targeting, among other\nbenefits. Machine learning comes across as a promising method for its proven\npredictive ability. We have curated a novel dataset for the classification of\nLOF variants using high-quality databases of genetic variation. We trained and\nvalidated seven different classification algorithms using the new dataset to\nclassify the variants as Benign, Pathogenic and Likely pathogenic. We recorded\nthe best overall performance using the XG-Boost algorithm with an F1-score of\n0.88 on the test set. We observed fair performance on Pathogenic samples with\nhigh recall and moderate precision and subpar performance on Likely pathogenic\nclass, albeit with moderate precision. Overall, the encouraging results make\nour final model a promising candidate for further real-world tests.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.05154v1"
    },
    {
        "title": "Laotian Bat Sarbecovirus BANAL-236 Uses ACE2 to Infect Cells by an\n  Unknown Mechanism",
        "authors": [
            "Steven Carl Quay"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  A manuscript identified bat sarbecoviruses with high sequence homology to\nSARS-CoV-2 found in caves in Laos that can directly infect human cells via the\nhuman ACE2 receptor (Coronaviruses with a SARS-CoV-2-like receptor binding\ndomain allowing ACE2-mediated entry into human cells isolated from bats of\nIndochinese peninsula, Temmam S., et al.). Here, I examine the genomic sequence\nof one of these viruses, BANAL-236, and show it has 5-UTR and 3-UTR secondary\nstructures that are non-canonical and, in fact, have never been seen in an\ninfective coronavirus. Specifically, the 5-UTR has a 177 nt copy-back extension\nwhich forms an extended, highly stable duplex RNA structure. Because of this\ncopy-back, the four obligate Stem Loops (SL) -1, -2, -3, and -4 cis-acting\nelements found in all currently known replicating coronaviruses are buried in\nthe extended duplex. The 3-UTR has a similar fold-back duplex of 144 nts and is\nmissing the obligate poly-A tail. Taken together, these findings demonstrate\nBANAL-236 is missing eight obligate UTR cis-acting elements; each one of which\nhas previously been lethal to replication when modified individually. Neither\nduplex copyback has ever been observed in an infective sarbecovirus, although\nsome of the features have been seen in defective interfering particles, which\ncan be found in co-infections with non-defective, replicating viruses. They are\nalso a common error seen during synthetic genome assembly in a laboratory.\nBANAL-236 must have evolved an entirely unique mechanism for replication, RNA\ntranslation, and RNA packaging never seen in a coronavirus and because it is a\nbat sarbecovirus closely related to SARS-CoV-2, it is imperative that we\nunderstand its unique mode of infectivity by a collaborative, international\nresearch effort.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.06141v2"
    },
    {
        "title": "Replication of SARS-CoV-2 mutation analysis suggests differences in\n  per-protein mutation characteristics",
        "authors": [
            "William Svoboda",
            "Brendan McManamon",
            "Sara Schwartz"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The increasing spread of COVID-19, caused by the virus SARS-CoV-2, raises\nconcerns about the extent to which mutations have occurred across the viral\ngenome. We present a partial replication of an earlier 2021 study by Wang, R.\net al. that determined the presence of four substrains and eleven top mutations\nin the United States. We analyze a portion of the authors' data set in order to\nrecreate Figure S1 from the paper, recapitulating the same features observed in\nthe original figure. We further generate a summary of mutation characteristics\nfor each of the 26 named proteins and confirm the significance of the spike\nprotein at roughly 24% of all recorded mutations. Our analysis suggests that\nadditional factors may affect per-protein mutation rate besides protein length.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.07770v2"
    },
    {
        "title": "Learning the statistics and landscape of somatic mutation-induced\n  insertions and deletions in antibodies",
        "authors": [
            "Cosimo Lupo",
            "Natanael Spisak",
            "Aleksandra M. Walczak",
            "Thierry Mora"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Affinity maturation is crucial for improving the binding affinity of\nantibodies to antigens. This process is mainly driven by point substitutions\ncaused by somatic hypermutations of the immunoglobulin gene. It also includes\ndeletions and insertions of genomic material known as indels. While the\nlandscape of point substitutions has been extensively studied, a detailed\nstatistical description of indels is still lacking. Here we present a\nprobabilistic inference tool to learn the statistics of indels from repertoire\nsequencing data, which overcomes the pitfalls and biases of standard annotation\nmethods. The model includes antibody-specific maturation ages to account for\nvariable mutational loads in the repertoire. After validation on synthetic\ndata, we applied our tool to a large dataset of human immunoglobulin heavy\nchains. The inferred model allows us to identify universal statistical features\nof indels in heavy chains. We report distinct insertion and deletion hotspots,\nand show that the distribution of lengths of indels follows a geometric\ndistribution, which puts constraints on future mechanistic models of the\nhypermutation process.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.07953v2"
    },
    {
        "title": "BLEND: A Fast, Memory-Efficient, and Accurate Mechanism to Find Fuzzy\n  Seed Matches in Genome Analysis",
        "authors": [
            "Can Firtina",
            "Jisung Park",
            "Mohammed Alser",
            "Jeremie S. Kim",
            "Damla Senol Cali",
            "Taha Shahroodi",
            "Nika Mansouri Ghiasi",
            "Gagandeep Singh",
            "Konstantinos Kanellopoulos",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Generating the hash values of short subsequences, called seeds, enables\nquickly identifying similarities between genomic sequences by matching seeds\nwith a single lookup of their hash values. However, these hash values can be\nused only for finding exact-matching seeds as the conventional hashing methods\nassign distinct hash values for different seeds, including highly similar\nseeds. Finding only exact-matching seeds causes either 1) increasing the use of\nthe costly sequence alignment or 2) limited sensitivity.\n  We introduce BLEND, the first efficient and accurate mechanism that can\nidentify both exact-matching and highly similar seeds with a single lookup of\ntheir hash values, called fuzzy seed matches. BLEND 1) utilizes a technique\ncalled SimHash, that can generate the same hash value for similar sets, and 2)\nprovides the proper mechanisms for using seeds as sets with the SimHash\ntechnique to find fuzzy seed matches efficiently.\n  We show the benefits of BLEND when used in read overlapping and read mapping.\nFor read overlapping, BLEND is faster by 2.4x - 83.9x (on average 19.3x), has a\nlower memory footprint by 0.9x - 14.1x (on average 3.8x), and finds higher\nquality overlaps leading to accurate de novo assemblies than the\nstate-of-the-art tool, minimap2. For read mapping, BLEND is faster by 0.8x -\n4.1x (on average 1.7x) than minimap2. Source code is available at\nhttps://github.com/CMU-SAFARI/BLEND.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.08687v7"
    },
    {
        "title": "Temporal epistasis inference from more than 3,500,000 SARS-CoV-2 Genomic\n  Sequences",
        "authors": [
            "Hong-Li Zeng",
            "Yue Liu",
            "Vito Dichio",
            "Erik Aurell"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We use Direct Coupling Analysis (DCA) to determine epistatic interactions\nbetween loci of variability of the SARS-CoV-2 virus, segmenting genomes by\nmonth of sampling. We use full-length, high-quality genomes from the GISAID\nrepository up to October 2021, in total over 3,500,000 genomes. We find that\nDCA terms are more stable over time than correlations, but nevertheless change\nover time as mutations disappear from the global population or reach fixation.\nCorrelations are enriched for phylogenetic effects, and in particularly\nstatistical dependencies at short genomic distances, while DCA brings out links\nat longer genomic distance. We discuss the validity of a DCA analysis under\nthese conditions in terms of a transient Quasi-Linkage Equilibrium state. We\nidentify putative epistatic interaction mutations involving loci in Spike.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.12957v2"
    },
    {
        "title": "Cell-in-cell structures are involved in the competition between cells in\n  breast cancer",
        "authors": [
            "S. Sajedeh Mousavi",
            "Sara Razi"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Breast cancer is the most common cancer in women worldwide, and discovering\nthe biomarkers of this disease became so vital nowadays and Cell in Cell\nstructure could be one of them, and it may be used as an available proxy for\ntumor malignancy. (CICs) are unusual in that keep morphologically healthy cells\nwithin another cell. They are found in various human cancers and result from\nactive cell-cell interaction, and it has different kinds. In this study, we\nanalyzed the microarray data from GEO (GSE103865) to genetically evaluate CICs'\nincidence in samples obtained from breast cancer patients to understand the\nrelationship between the rate of CIC and the prognosis of breast cancer. The\npreprocessing was performed using R software. The DAVID website was used to\nanalyze gene ontology (GO) and Gene and Genome (KEGG) pathways. The\nprotein-protein interactions (PPIs) of the obtained DEGs were assessed using\nthe STRING website, and hub modules in Cytoscape and cytoHubba were screened.\nAccording to the results from analyzing the 20 hub genes, we understood that\noverexpression of our Top genes is effective in focal adhesion, ECM-receptor\ninteraction, platelet activation and PI3K-Akt signaling pathway, which shows\nthat changes in these pathways could be the reason the overexpression of CICs\nin breast cancer. These data and research by many others have uncovered various\ngenes involved in CIC formation and have started to give us an idea of why they\nare formed and how they could contribute to breast cancer\n",
        "pdf_link": "http://arxiv.org/pdf/2112.13271v1"
    },
    {
        "title": "Accurate identification of bacteriophages from metagenomic data using\n  Transformer",
        "authors": [
            "Jiayu Shang",
            "Xubo Tang",
            "Ruocheng Guo",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Motivation: Bacteriophages are viruses infecting bacteria. Being key players\nin microbial communities, they can regulate the composition/function of\nmicrobiome by infecting their bacterial hosts and mediating gene transfer.\nRecently, metagenomic sequencing, which can sequence all genetic materials from\nvarious microbiome, has become a popular means for new phage discovery.\nHowever, accurate and comprehensive detection of phages from the metagenomic\ndata remains difficult. High diversity/abundance, and limited reference genomes\npose major challenges for recruiting phage fragments from metagenomic data.\nExisting alignment-based or learning-based models have either low recall or\nprecision on metagenomic data. Results: In this work, we adopt the\nstate-of-the-art language model, Transformer, to conduct contextual embedding\nfor phage contigs. By constructing a protein-cluster vocabulary, we can feed\nboth the protein composition and the proteins' positions from each contig into\nthe Transformer. The Transformer can learn the protein organization and\nassociations using the self-attention mechanism and predicts the label for test\ncontigs. We rigorously tested our developed tool named PhaMer on multiple\ndatasets with increasing difficulty, including quality RefSeq genomes, short\ncontigs, simulated metagenomic data, mock metagenomic data, and the public\nIMG/VR dataset. All the experimental results show that PhaMer outperforms the\nstate-of-the-art tools. In the real metagenomic data experiment, PhaMer\nimproves the F1-score of phage detection by 27\\%.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.04778v2"
    },
    {
        "title": "On the influence of several factors on pathway enrichment analysis",
        "authors": [
            "Sarah Mubeen",
            "Alpha Tom Kodamullil",
            "Martin Hofmann-Apitius",
            "Daniel Domingo-Fernández"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Pathway enrichment analysis has become a widely used knowledge-based approach\nfor the interpretation of biomedical data. Its popularity has led to an\nexplosion of both enrichment methods and pathway databases. While the elegance\nof pathway enrichment lies in its simplicity, multiple factors can impact the\nresults of such an analysis which may not be accounted for. Researchers may\nfail to give influential aspects their due, resorting instead to popular\nmethods and gene set collections, or default settings. Despite ongoing efforts\nto establish set guidelines, meaningful results are still hampered by a lack of\nconsensus or gold standards around how enrichment analysis should be conducted.\nNonetheless, such concerns have prompted a series of benchmark studies\nspecifically focused on evaluating the influence of various factors on pathway\nenrichment results. In this review, we organize and summarize the findings of\nthese benchmarks to provide a comprehensive overview on the influence of these\nfactors. Our work covers a broad spectrum of factors, spanning from\nmethodological assumptions to those related to prior biological knowledge, such\nas pathway definitions and database choice. In doing so, we aim to shed light\non how these aspects can lead to insignificant, uninteresting, or even\ncontradictory results. Finally, we conclude the review by proposing future\nbenchmarks as well as solutions to overcome some of the challenges which\noriginate from the outlined factors.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.05593v1"
    },
    {
        "title": "FastRemap: A Tool for Quickly Remapping Reads between Genome Assemblies",
        "authors": [
            "Jeremie S. Kim",
            "Can Firtina",
            "Meryem Banu Cavlak",
            "Damla Senol Cali",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  A genome read data set can be quickly and efficiently remapped from one\nreference to another similar reference (e.g., between two reference versions or\ntwo similar species) using a variety of tools, e.g., the commonly-used CrossMap\ntool. With the explosion of available genomic data sets and references,\nhigh-performance remapping tools will be even more important for keeping up\nwith the computational demands of genome assembly and analysis.\n  We provide FastRemap, a fast and efficient tool for remapping reads between\ngenome assemblies. FastRemap provides up to a 7.82$\\times$ speedup\n(6.47$\\times$, on average) and uses as low as 61.7% (80.7%, on average) of the\npeak memory consumption compared to the state-of-the-art remapping tool,\nCrossMap.\n  FastRemap is written in C++. The source code and user manual are freely\navailable at: github.com/CMU-SAFARI/FastRemap. Docker image available at:\nhttps://hub.docker.com/r/alkanlab/fast. Also available in Bioconda at:\nhttps://anaconda.org/bioconda/fastremap-bio.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06255v3"
    },
    {
        "title": "Computational Methods for Single-Cell Multi-Omics Integration and\n  Alignment",
        "authors": [
            "Stefan Stanojevic",
            "Yijun Li",
            "Lana X. Garmire"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Recently developed technologies to generate single-cell genomic data have\nmade a revolutionary impact in the field of biology. Multi-omics assays offer\neven greater opportunities to understand cellular states and biological\nprocesses. However, the problem of integrating different -omics data with very\ndifferent dimensionality and statistical properties remains quite challenging.\nA growing body of computational tools are being developed for this task,\nleveraging ideas ranging from machine translation to the theory of networks and\nrepresenting a new frontier on the interface of biology and data science. Our\ngoal in this review paper is to provide a comprehensive, up-to-date survey of\ncomputational techniques for the integration of multi-omics and alignment of\nmultiple modalities of genomics data in the single cell research field.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06725v1"
    },
    {
        "title": "Investigating the genomic background of CRISPR-Cas genomes for\n  CRISPR-based antimicrobials",
        "authors": [
            "Hyunjin Shim"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  CRISPR-Cas systems are an adaptive immunity that protects prokaryotes against\nforeign genetic elements. Genetic templates acquired during past infection\nevents enable DNA-interacting enzymes to recognize foreign DNA for destruction.\nDue to the programmability and specificity of these genetic templates,\nCRISPR-Cas systems are potential alternative antibiotics that can be engineered\nto self-target antimicrobial resistance genes on the chromosome or plasmid.\nHowever, several fundamental questions remain to repurpose these tools against\ndrug-resistant bacteria. For endogenous CRISPR-Cas self-targeting,\nantimicrobial resistance genes and functional CRISPR-Cas systems have to\nco-occur in the target cell. Furthermore, these tools have to outplay DNA\nrepair pathways that respond to the nuclease activities of Cas proteins, even\nfor exogenous CRISPR-Cas delivery. Here, we conduct a comprehensive survey of\nCRISPR-Cas genomes. First, we address the co-occurrence of CRISPR-Cas systems\nand antimicrobial resistance genes in the CRISPR-Cas genomes. We show that the\naverage number of these genes varies greatly by the CRISPR-Cas type, and some\nCRISPR-Cas types (IE and IIIA) have over 20 genes per genome. Next, we\ninvestigate the DNA repair pathways of these CRISPR-Cas genomes, revealing that\nthe diversity and frequency of these pathways differ by the CRISPR-Cas type.\nThe interplay between CRISPR-Cas systems and DNA repair pathways is essential\nfor the acquisition of new spacers in CRISPR arrays. We conduct simulation\nstudies to demonstrate that the efficiency of these DNA repair pathways may be\ninferred from the time-series patterns in the RNA structure of CRISPR repeats.\nThis bioinformatic survey of CRISPR-Cas genomes elucidates the necessity to\nconsider multifaceted interactions between different genes and systems to\ndesign effective CRISPR-based antimicrobials.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07171v1"
    },
    {
        "title": "Client applications and Server Side docker for management of RNASeq\n  and/or VariantSeq workflows and pipelines of the GPRO Suite",
        "authors": [
            "Ahmed Hafez",
            "Beatriz Soriano",
            "Aya A. Elsayed",
            "Ricardo Futami",
            "Raquel Ceprian",
            "Ricardo Ramos-Ruiz",
            "Genis Martinez",
            "Francisco J. Roig",
            "Miguel A. Torres-Font",
            "Fernando Naya-Català",
            "Josep Alvar Calduch-Giner",
            "Lucia Trilla-Fuertes",
            "Angelo Gamez-Pozo",
            "Vicente Arnau",
            "Jose M. Sempere",
            "Jaume Perez-Sánchez",
            "Toni Gabaldón",
            "Carlos Llorens"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The GPRO suite is an in-progress bioinformatic project for -omic data\nanalyses. As part of the continued growth of this project, we introduce a\nclient side & server side solution for comparative transcriptomics and analysis\nof variants. The client side consists of two Java applications called \"RNASeq\"\nand \"VariantSeq\" to manage workflows for RNA-seq and Variant-seq analysis,\nrespectively, based on the most common command line interface tools for each\ntopic. Both applications are coupled with a Linux server infrastructure (named\nGPRO Server Side) that hosts all dependencies of each application (scripts,\ndatabases, and command line interface tools). Implementation of the server side\nrequires a Linux operating system, PHP, SQL, Python, bash scripting, and\nthird-party software. The GPRO Server Side can be deployed via a Docker\ncontainer that can be installed in the user's PC using any operating system or\non remote servers as a cloud solution. The two applications are available as\ndesktop and cloud applications and provide two execution modes: a Step-by-Step\nmode enables each step of a workflow to be executed independently and a\nPipeline mode allows all steps to be run sequentially. The two applications\nalso feature an experimental support system called GENIE that consists of a\nvirtual chatbot/assistant and a pipeline jobs panel coupled with an expert\nsystem. The chatbot can troubleshoot issues with the usage of each tool, the\npipeline job panel provides information about the status of each task executed\nin the GPRO Server Side, and the expert provides the user with a potential\nrecommendation to identify or fix failed analyses. The two applications and the\nGPRO Server Side combine the user-friendliness and security of client software\nwith the efficiency of front-end & back-end solutions to manage command line\ninterface software for RNA-seq and variant-seq analysis via interface\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07473v4"
    },
    {
        "title": "Correspondence on ACMG STATEMENT: ACMG SF v3.0 list for reporting of\n  secondary findings in clinical exome and genome sequencing: a policy\n  statement of the American College of Medical Genetics and Genomics (ACMG) by\n  Miller et al",
        "authors": [
            "Kathryn A. McGurk",
            "Sean L. Zheng",
            "Albert Henry",
            "Katherine Josephs",
            "Matthew Edwards",
            "Antonio de Marvao",
            "Nicola Whiffin",
            "Angharad Roberts",
            "Thomas R. Lumbers",
            "Declan P. O Regan",
            "James S. Ware"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  We were interested to read the recent update on recommendations for reporting\nof secondary findings in clinical sequencing1, and the accompanying updated\nlist of genes in which secondary findings should be sought (ACMG SF v3.0)2.\nThough the authors discuss challenges around incomplete penetrance in\nconsiderable detail, we are concerned that the recommendations do not fully\nconvey the degree of uncertainty regarding the penetrance of variants in genes\nassociated with inherited cardiomyopathies, which make up almost a quarter of\nthe list. Since penetrance is incomplete and age-related, individuals found to\ncarry variants will often require surveillance, rather than a one-off\ndefinitive diagnostic assessment. There is a lack of evidence regarding\nbenefits, harms, and healthcare costs associated with opportunistic screening.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04684v1"
    },
    {
        "title": "graph-GPA 2.0: A Graphical Model for Multi-disease Analysis of GWAS\n  Results with Integration of Functional Annotation Data",
        "authors": [
            "Qiaolan Deng",
            "Jin Hyun Nam",
            "Ayse Selen Yilmaz",
            "Won Chang",
            "Maciej Pietrzak",
            "Lang Li",
            "Hang J. Kim",
            "Dongjun Chung"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Genome-wide association studies (GWAS) have successfully identified a large\nnumber of genetic variants associated with traits and diseases. However, it\nstill remains challenging to fully understand functional mechanisms underlying\nmany associated variants. This is especially the case when we are interested in\nvariants shared across multiple phenotypes. To address this challenge, we\npropose graph-GPA 2.0 (GGPA 2.0), a novel statistical framework to integrate\nGWAS datasets for multiple phenotypes and incorporate functional annotations\nwithin a unified framework. We conducted simulation studies to evaluate GGPA\n2.0. The results indicate that incorporating functional annotation data using\nGGPA 2.0 does not only improve detection of disease-associated variants, but\nalso allows to identify more accurate relationships among diseases. We analyzed\nfive autoimmune diseases and five psychiatric disorders with the functional\nannotations derived from GenoSkyline and GenoSkyline-Plus and the prior disease\ngraph generated by biomedical literature mining. For autoimmune diseases, GGPA\n2.0 identified enrichment for blood, especially B cells and regulatory T cells\nacross multiple diseases. Psychiatric disorders were enriched for brain,\nespecially prefrontal cortex and inferior temporal lobe for bipolar disorder\n(BIP) and schizophrenia (SCZ), respectively. Finally, GGPA 2.0 successfully\nidentified the pleiotropy between BIP and SCZ. These results demonstrate that\nGGPA 2.0 can be a powerful tool to identify associated variants associated with\neach phenotype or those shared across multiple phenotypes, while also promoting\nunderstanding of functional mechanisms underlying the associated variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.06714v1"
    },
    {
        "title": "GeoTyper: Automated Pipeline from Raw scRNA-Seq Data to Cell Type\n  Identification",
        "authors": [
            "Cecily Wolfe",
            "Yayi Feng",
            "David Chen",
            "Edwin Purcell",
            "Anne Talkington",
            "Sepideh Dolatshahi",
            "Heman Shakeri"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The cellular composition of the tumor microenvironment can directly impact\ncancer progression and the efficacy of therapeutics. Understanding immune cell\nactivity, the body's natural defense mechanism, in the vicinity of cancerous\ncells is essential for developing beneficial treatments. Single cell RNA\nsequencing (scRNA-seq) enables the examination of gene expression on an\nindividual cell basis, providing crucial information regarding both the\ndisturbances in cell functioning caused by cancer and cell-cell communication\nin the tumor microenvironment. This novel technique generates large amounts of\ndata, which require proper processing. Various tools exist to facilitate this\nprocessing but need to be organized to standardize the workflow from data\nwrangling to visualization, cell type identification, and analysis of changes\nin cellular activity, both from the standpoint of malignant cells and immune\nstromal cells that eliminate them. We aimed to develop a standardized pipeline\n(GeoTyper, https://github.com/celineyayifeng/GeoTyper) that integrates multiple\nscRNA-seq tools for processing raw sequence data extracted from NCBI GEO,\nvisualization of results, statistical analysis, and cell type identification.\nThis pipeline leverages existing tools, such as Cellranger from 10X Genomics,\nAlevin, and Seurat, to cluster cells and identify cell types based on gene\nexpression profiles. We successfully tested and validated the pipeline on\nseveral publicly available scRNA-seq datasets, resulting in clusters\ncorresponding to distinct cell types. By determining the cell types and their\nrespective frequencies in the tumor microenvironment across multiple cancers,\nthis workflow will help quantify changes in gene expression related to\ncell-cell communication and identify possible therapeutic targets.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.01187v1"
    },
    {
        "title": "CAGI, the Critical Assessment of Genome Interpretation, establishes\n  progress and prospects for computational genetic variant interpretation\n  methods",
        "authors": [
            "The Critical Assessment of Genome Interpretation Consortium"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The Critical Assessment of Genome Interpretation (CAGI) aims to advance the\nstate of the art for computational prediction of genetic variant impact,\nparticularly those relevant to disease. The five complete editions of the CAGI\ncommunity experiment comprised 50 challenges, in which participants made blind\npredictions of phenotypes from genetic data, and these were evaluated by\nindependent assessors. Overall, results show that while current methods are\nimperfect, they have major utility for research and clinical applications.\nMissense variant interpretation methods are able to estimate biochemical\neffects with increasing accuracy. Performance is particularly strong for\nclinical pathogenic variants, including some difficult-to-diagnose cases, and\nextends to interpretation of cancer-related variants. Assessment of methods for\nregulatory variants and complex trait disease risk is less definitive, and\nindicates performance potentially suitable for auxiliary use in the clinic.\nEmerging methods and increasingly large, robust datasets for training and\nassessment promise further progress ahead.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05897v1"
    },
    {
        "title": "SODA: a TypeScript/JavaScript Library for Visualizing Biological\n  Sequence Annotation",
        "authors": [
            "Jack W. Roddy",
            "George T. Lesica",
            "Travis J. Wheeler"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  We present SODA, a lightweight and open-source visualization library for\nbiological sequence annotations that enables straightforward development of\nflexible, dynamic, and interactive web graphics. SODA is implemented in\nTypeScript and can be used as a library within TypeScript and JavaScript.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.06349v1"
    },
    {
        "title": "Functional and evolutionary genomics of the Streptomyces metabolism",
        "authors": [
            "Pablo Cruz-Morales"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  This thesis is focused in the study of the evolution of the metabolic\nrepertoire of Streptomyces, which are renowned as proficient producers of\nbioactive Natural Products (NPs). The main goal of my work was to contribute\ninto the understanding of the evolutionary mechanisms behind the evolution of\nNP biosynthetic pathways. Specifically, the development of a bioinformatic\nmethod that helps into the discovery of new NP biosynthetic pathways from\nactinobacterial genome sequences with emphasis on members of the genus\nStreptomyces. I developed this method using a comparative and functional\ngenomics perspective. My studies indicate that central metabolic enzymes were\nexpanded in a genus-specific manner in Actinobacteria, and that they have been\nextensively recruited for the biosynthesis of NPs. Based in these observations,\nI developed EvoMining, a bioinformatic pipeline for the identificatoon of novel\nbiosynthetic pathways in microbial genomes. Using EvoMining several new NP\nbiosynthetic pathways have been predicted in different members of the phylum\nActinobacteria, including the model organism S. lividans 66. To test this\napproach, the genome sequence of this model strain was obtained, and its\nanalysis led to the discovery of an unprecedented system for peptide bond\nformation, as well as a biosynthetic pathway for an arsenic-containing\nmetabolite. Moreover, this work also led to the identification of expansions on\na conserved metabolic node in the glycolytic pathway of Streptomyces. These\nexpansions occurred before the radiation of Streptomyces and are concomitant\nwith the evolution of their capability to produce NPs. Experimental analyses\nindicate that this node evolved to mediate the interplay between central an NP\nmetabolism.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.14945v1"
    },
    {
        "title": "LAPIS is a fast web API for massive open virus sequencing databases",
        "authors": [
            "Chaoran Chen",
            "Alexander Taepper",
            "Fabian Engelniederhammer",
            "Jonas Kellerer",
            "Cornelius Roemer",
            "Tanja Stadler"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Background: Recent epidemic outbreaks such as the SARS-CoV-2 pandemic and the\nmpox outbreak in 2022 have demonstrated the value of genomic sequencing data\nfor tracking the origin and spread of pathogens. Laboratories around the globe\ngenerated new sequences at unprecedented speed and volume and bioinformaticians\ndeveloped new tools and dashboards to analyze this wealth of data. However, a\nmajor challenge that remains is the lack of simple and efficient approaches for\naccessing and processing sequencing data.\n  Results: The Lightweight API for Sequences (LAPIS) facilitates rapid\nretrieval and analysis of genomic sequencing data through a REST API. It\nsupports complex mutation- and metadata-based queries and can perform\naggregation operations on massive datasets. LAPIS is optimized for typical\nquestions relevant to genomic epidemiology. Using a newly-developed in-memory\ndatabase engine, it has a high speed and throughput: between 25 January and 4\nFebruary 2023, the SARS-CoV-2 instance of LAPIS, which contains 14.5 million\nsequences, processed over 20 million requests with a mean response time of 411\nms and a median response time of 1 ms. LAPIS is the core engine behind our\ndashboards on genspectrum.org and we currently maintain public LAPIS instances\nfor SARS-CoV-2 and mpox.\n  Conclusions: Powered by an optimized database engine and available through a\nweb API, LAPIS enhances the accessibility of genomic sequencing data. It is\ndesigned to serve as a common backend for dashboards and analyses with the\npotential to be integrated into common database platforms such as GenBank.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.01210v4"
    },
    {
        "title": "PhaTYP: Predicting the lifestyle for bacteriophages using BERT",
        "authors": [
            "Jiayu Shang",
            "Xubo Tang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Bacteriophages (or phages), which infect bacteria, have two distinct\nlifestyles: virulent and temperate. Predicting the lifestyle of phages helps\ndecipher their interactions with their bacterial hosts, aiding phages'\napplications in fields such as phage therapy. Because experimental methods for\nannotating the lifestyle of phages cannot keep pace with the fast accumulation\nof sequenced phages, computational method for predicting phages' lifestyles has\nbecome an attractive alternative. Despite some promising results, computational\nlifestyle prediction remains difficult because of the limited known annotations\nand the sheer amount of sequenced phage contigs assembled from metagenomic\ndata. In particular, most of the existing tools cannot precisely predict\nphages' lifestyles for short contigs. In this work, we develop PhaTYP (Phage\nTYPe prediction tool) to improve the accuracy of lifestyle prediction on short\ncontigs. We design two different training tasks, self-supervised and\nfine-tuning tasks, to overcome lifestyle prediction difficulties. We rigorously\ntested and compared PhaTYP with four state-of-the-art methods: DeePhage,\nPHACTS, PhagePred, and BACPHLIP. The experimental results show that PhaTYP\noutperforms all these methods and achieves more stable performance on short\ncontigs. In addition, we demonstrated the utility of PhaTYP for analyzing the\nphage lifestyle on human neonates' gut data. This application shows that PhaTYP\nis a useful means for studying phages in metagenomic data and helps extend our\nunderstanding of microbial communities.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09693v1"
    },
    {
        "title": "Further analysis of metagenomic datasets containing GD and GX pangolin\n  CoVs indicates widespread contamination, undermining pangolin host\n  attribution",
        "authors": [
            "Adrian Jones",
            "Steven E. Massey",
            "Daoyu Zhang",
            "Yuri Deigin",
            "Steven C. Quay"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The only animals other than bats reported to have been infected with\nSARS-CoV-2-related coronaviruses (SARS2r-CoVs) prior to the COVID-19 pandemic\nare pangolins. In early 2020 multiple papers reported the identification of two\nclades of SARS2r-CoVs, GD and GX, infecting pangolins. However the RNA-Seq\ndatasets supporting pangolin genome assembly were widely contaminated,\ncontained synthetic vectors or were heavily enriched or filtered with little\nbut coronavirus sequences left in the datasets. Here we investigate two\npangolin fecal samples sequenced by Li et al. (2021) provided in support of GD\nPCoV infection of pangolins in Guangdong and find the read distribution\nconsistent with PCR amplicon contamination and SARS-CoV-2 contamination, and\nfurther identify the presence of synthetic plasmid sequences. We also build\nupon our previous work to further analyze the dataset GX/P3B by Lam et al.\n(2020), which is the only non enriched/heavily filtered pangolin tissue dataset\nsequenced by Lam et al. (2020). We identify synthetic vectors and confirm human\ngenomic origin samples in the dataset. Finally, we find human mitochondrial\nsequences in all pangolin organ datasets and mouse and tiger mitochondrial\nsequences in selected pangolin organ datasets sequenced by Liu et al. (2019).\nWe infer that human and mouse genomic origin sequences were probably sourced\nfrom contamination prior to sequencing, while tiger origin sequence\ncontamination may have occurred due to index hopping during sequencing. These\nobservations are problematic for attributing pangolins as SARS2r-CoV hosts in\nthe datasets examined. The forensic methods developed and used here can be\napplied to examine any third party SRA data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.03288v2"
    },
    {
        "title": "A Bayesian method for estimating gene-level polygenicity under the\n  framework of transcriptome-wide association study",
        "authors": [
            "Arunabha Majumdar",
            "Bogdan Pasaniuc"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Polygnicity refers to the phenomenon that multiple genetic variants have a\nnon-zero effect on a complex trait. It is defined as the proportion of genetic\nvariants that have a nonzero effect on the trait. Evaluation of polygenicity\ncan provide valuable insights into the genetic architecture of the trait.\nSeveral recent works have attempted to estimate polygenicity at the SNP level.\nHowever, evaluating polygenicity at the gene level can be biologically more\nmeaningful. We propose the notion of gene-level polygenicity, defined as the\nproportion of genes having a non-zero effect on the trait under the framework\nof transcriptome-wide association study. We introduce a Bayesian approach\npolygene to estimate this quantity for a trait. The method is based on spike\nand slab prior and simultaneously provides an optimal subset of non-null genes.\nOur simulation study shows that polygene efficiently estimates gene-level\npolygenicity. The method produces downward bias for small choices of trait\nheritability due to a non-null gene, which diminishes rapidly with an increase\nin the GWAS sample size. While identifying the optimal subset of non-null\ngenes, polygene offers a high level of specificity and an overall good level of\nsensitivity -- the sensitivity increases as the sample size of the reference\npanel expression and GWAS data increase. We applied the method to seven\nphenotypes in the UK Biobank, integrating expression data. We find height to be\nmost polygenic and asthma to be the least polygenic. Our analysis suggests that\nboth HDL and triglycerides are more polygenic than LDL.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.12173v1"
    },
    {
        "title": "Therapeutic algebra of immunomodulatory drug responses at single-cell\n  resolution",
        "authors": [
            "Jialong Jiang",
            "Sisi Chen",
            "Tiffany Tsou",
            "Christopher S. McGinnis",
            "Tahmineh Khazaei",
            "Qin Zhu",
            "Jong H. Park",
            "Paul Rivaud",
            "Inna-Marie Strazhnik",
            "Eric D. Chow",
            "David A. Sivak",
            "Zev J. Gartner",
            "Matt Thomson"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Therapeutic modulation of immune states is central to the treatment of human\ndisease. However, how drugs and drug combinations impact the diverse cell types\nin the human immune system remains poorly understood at the transcriptome\nscale. Here, we apply single-cell mRNA-seq to profile the response of human\nimmune cells to 502 immunomodulatory drugs alone and in combination. We develop\na unified mathematical model that quantitatively describes the transcriptome\nscale response of myeloid and lymphoid cell types to individual drugs and drug\ncombinations through a single inferred regulatory network. The mathematical\nmodel reveals how drug combinations generate novel, macrophage and T-cell\nstates by recruiting combinations of gene expression programs through both\nadditive and non-additive drug interactions. A simplified drug response algebra\nallows us to predict the continuous modulation of immune cell populations\nbetween activated, resting and hyper-inhibited states through combinatorial\ndrug dose titrations. Our results suggest that transcriptome-scale mathematical\nmodels could enable the design of therapeutic strategies for programming the\nhuman immune system using combinations of therapeutics.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.10661v1"
    },
    {
        "title": "Mapache: a flexible pipeline to map ancient DNA",
        "authors": [
            "Samuel Neuenschwander",
            "Diana I. Cruz Dávalos",
            "Lucas Anchieri",
            "Bárbara Sousa da Mota",
            "Davide Bozzi",
            "Simone Rubinacci",
            "Olivier Delaneau",
            "Simon Rasmussen",
            "Anna-Sapfo Malaspinas"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Summary: Mapping ancient DNA to a reference genome is challenging as it\ninvolves numerous steps, is time-consuming and has to be repeated within a\nstudy to assess the quality of extracts and libraries; as a result, the mapping\nneeds to be automatized to handle large amounts of data in a reproducible way.\nWe present mapache, a flexible, robust, and scalable pipeline to map, quantify\nand impute ancient and present-day DNA in a reproducible way. Mapache is\nimplemented in the workflow manager Snakemake and is optimized for low-space\nconsumption, allowing to efficiently (re)map large data sets such as reference\npanels and multiple extracts and libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.13283v1"
    },
    {
        "title": "genomepy: genes and genomes at your fingertips",
        "authors": [
            "Siebren Frölich",
            "Maarten van der Sande",
            "Tilman Schäfers",
            "Simon J. van Heeringen"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Analyzing a functional genomics experiment, such as ATAC-, ChIP- or\nRNA-sequencing, requires reference data including a genome assembly and gene\nannotation. These resources can generally be retrieved from different\norganizations and in different versions. Most bioinformatic workflows require\nthe user to supply this genomic data manually, which can be a tedious and\nerror-prone process.\n  Here we present genomepy, which can search, download, and preprocess the\nright genomic data for your analysis. Genomepy can search genomic data on NCBI,\nEnsembl, UCSC and GENCODE, and compare available gene annotations to enable an\ninformed decision. The selected genome and gene annotation can be downloaded\nand preprocessed with sensible, yet controllable, defaults. Additional\nsupporting data can be automatically generated or downloaded, such as aligner\nindexes, genome metadata and blacklists.\n  Genomepy is freely available at https://github.com/vanheeringen-lab/genomepy\nunder the MIT license and can be installed through pip or bioconda.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.00842v1"
    },
    {
        "title": "Phage family classification under Caudoviricetes: a review of current\n  tools using the latest ICTV classification framework",
        "authors": [
            "Yilin Zhu",
            "Jiayu Shang",
            "Cheng Peng",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Bacteriophages, which are viruses infecting bacteria, are the most ubiquitous\nand diverse entities in the biosphere. There is accumulating evidence revealing\ntheir important roles in shaping the structure of various microbiomes. Thanks\nto (viral) metagenomic sequencing, a large number of new bacteriophages have\nbeen discovered. However, lacking a standard and automatic virus classification\npipeline, the taxonomic characterization of new viruses seriously lag behind\nthe sequencing efforts. In particular, according to the latest version of ICTV,\nseveral large phage families in the previous classification system are removed.\nTherefore, a comprehensive review and comparison of taxonomic classification\ntools under the new standard are needed to establish the state-of-the-art. In\nthis work, we retrained and tested four recently published tools on newly\nlabeled databases. We demonstrated their utilities and tested them on multiple\ndatasets, including the RefSeq, short contigs, simulated metagenomic datasets,\nand low-similarity datasets. This study provides a comprehensive review of\nphage family classification in different scenarios and a practical guidance for\nchoosing appropriate taxonomic classification pipelines. To our best knowledge,\nthis is the first review conducted under the new ICTV classification framework.\nThe results show that the new family classification framework overall leads to\nbetter-conserved groups and thus makes family-level classification more\nfeasible.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01942v2"
    },
    {
        "title": "HLA predictions from long sequence read alignments, streamed directly\n  into HLAminer",
        "authors": [
            "René L. Warren"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The rapidly changing landscape of sequencing technologies brings new\nopportunities to genomics research. Longer sequence reads and higher sequence\nthroughput coupled with ever-improving base accuracy and decreasing per-base\ncost is now making long reads suitable for analyzing polymorphic regions of the\nhuman genome, such as those of the human leucocyte antigen (HLA) gene complex.\nHere I present a simple protocol for predicting HLA signatures from whole\ngenome shotgun (WGS) long sequencing reads, by directly streaming sequence\nalignments into HLAminer. The method is as simple as running minimap2, it\nscales with the number of sequences to align, and can be used with any read\naligner capable of sam format output without the need to store bulky alignment\nfiles to disk. I show how the predictions are robust even with older and less\n[base] accurate WGS nanopore datasets and relatively low (10X) sequence\ncoverage and present a step-by-step protocol to predict HLA class I and II\ngenes from the long sequencing reads of modern third-generation technologies.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.09155v1"
    },
    {
        "title": "On the unknown proteins of eukaryotic proteomes",
        "authors": [
            "Yves-Henri Sanejouand"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  In order to study unknown proteins on a large scale, a reference system has\nbeen set up for the three major eukaryotic lineages, built with 36 proteomes as\ntaxonomically diverse as possible. Proteins from 362 eukaryotic proteomes with\nno known homologue in this set were then analyzed, focusing noteworthy on\nsingletons, that is, on unknown proteins with no known homologue in their own\nproteome. Consistently, according to Uniprot, for a given species, no more than\n12% of the singletons thus found are known at the protein level. Also, since\nthey rely on the information found in the alignment of homologous sequences,\npredictions of AlphaFold2 for their tridimensional structure are usually poor.\nIn the case of metazoan species, the number of singletons seems to increase as\na function of the evolutionary distance from the reference system.\nInterestingly, no such trend is found in the cases of viridiplantae and fungi,\nas if the timescale on which singletons are added to proteomes were different\nin metazoa and in other eukaryotic kingdoms. In order to confirm this\nphenomenon, further studies of proteomes closer to those of the reference\nsystem are however needed.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.11001v1"
    },
    {
        "title": "Towards complete representation of bacterial contents in metagenomic\n  samples",
        "authors": [
            "Xiaowen Feng",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Background: In the metagenome assembly of a microbiome community, we may\nthink abundant species would be easier to assemble due to their deeper\ncoverage. However, this conjucture is rarely tested. We often do not know how\nmany abundant species we are missing and do not have an approach to recover\nthese species.\n  Results: Here we proposed k-mer based and 16S RNA based methods to measure\nthe completeness of metagenome assembly. We showed that even with PacBio\nHigh-Fidelity (HiFi) reads, abundant species are often not assembled as high\nstrain diversity may lead to fragmented contigs. We developed a novel algorithm\nto recover abundant metagenome-assembled genomes (MAGs) by identifying circular\nassembly subgraphs. Our algorithm is reference-free and complement to standard\nmetagenome binning. Evaluated on 14 real datasets, it rescued many abundant\nspecies that would be missing with existing methods.\n  Conclusions: Our work stresses the importance of metagenome completeness\nwhich is often overlooked before. Our algorithm generates more circular MAGs\nand moves a step closer to the complete representation of microbiome\ncommunities.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00098v2"
    },
    {
        "title": "KGP: An R Package with Metadata from the 1000 Genomes Project",
        "authors": [
            "Stephen D. Turner"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The 1000 Genomes Project provides sequencing data on 3,202 samples from 26\npopulations spanning five continental regions with no access or use\nrestrictions. The kgp R package provides consistent and comprehensive metadata\nabout samples and populations in the 1000 Genomes Project and other population\nsequencing data in the International Genome Sample Resource collection. The kgp\npackage is distributed via the Comprehensive R Archive Network (CRAN) at\nhttps://cran.r-project.org/package=kgp. Source code is available on GitHub at\nhttps://github.com/stephenturner/kgp. Further documentation is online at\nhttps://stephenturner.github.io/kgp/.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00539v1"
    },
    {
        "title": "NLP-based classification of software tools for metagenomics sequencing\n  data analysis into EDAM semantic annotation",
        "authors": [
            "Kaoutar Daoud Hiri",
            "Matjaž Hren",
            "Tomaž Curk"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Motivation: The rapid growth of metagenomics sequencing data makes\nmetagenomics increasingly dependent on computational and statistical methods\nfor fast and efficient analysis. Consequently, novel analysis tools for\nbig-data metagenomics are constantly emerging. One of the biggest challenges\nfor researchers occurs in the analysis planning stage: selecting the most\nsuitable metagenomics software tool to gain valuable insights from sequencing\ndata. The building process of data analysis pipelines is often laborious and\ntime-consuming since it requires a deep and critical understanding of how to\napply a particular tool to complete a specified metagenomics task.\n  Results: We have addressed this challenge by using machine learning methods\nto develop a classification system of metagenomics software tools into 13\nclasses (11 semantic annotations of EDAM and two virus-specific classes) based\non the descriptions of the tools. We trained three classifiers (Naive Bayes,\nLogistic Regression, and Random Forest) using 15 text feature extraction\ntechniques (TF-IDF, GloVe, BERT-based models, and others). The manually curated\ndataset includes 224 software tools and contains text from the abstract and the\nmethods section of the tools' publications. The best classification\nperformance, with an Area Under the Precision-Recall Curve score of 0.85, is\nachieved using Logistic regression, BioBERT for text embedding, and text from\nabstracts only. The proposed system provides accurate and unified\nidentification of metagenomics data analysis tools and tasks, which is a\ncrucial step in the construction of metagenomics data analysis pipelines.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00831v2"
    },
    {
        "title": "An RNA Sequencing Analysis of Glaucoma Genesis in Mice",
        "authors": [
            "Jai Sharma",
            "Vidhyacharan Bhaskar"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Glaucoma is the leading cause of irreversible blindness in people over the\nage of 60, accounting for 6.6 to 8% of all blindness in 2010, but there is\nstill much to be learned about the genetic origins of the eye disease. With the\nmodern development of Next-Generation Sequencing (NGS) technologies, scientists\nare starting to learn more about the genetic origins of Glaucoma. This research\nuses differential expression (DE) and gene ontology (GO) analyses to study the\ngenetic differences between mice with severe Glaucoma and multiple control\ngroups. Optical nerve head (ONH) and retina data samples of genome-wide RNA\nexpression from NCBI (NIH) are used for pairwise comparison experimentation. In\naddition, principal component analysis (PCA) and dispersion visualization\nmethods are employed to perform quality control tests of the sequenced data.\nGenes with skewed gene counts are also identified, as they may be marker genes\nfor a particular severity of Glaucoma. The gene ontologies found in this\nexperiment support existing knowledge of Glaucoma genesis, providing confidence\nthat the results were valid. Future researchers can thoroughly study the gene\nlists generated by the DE and GO analyses to find potential activator or\nprotector genes for Glaucoma in mice to develop drug treatments or gene\ntherapies to slow or stop the progression of the disease. The overall goal is\nthat in the future, such treatments can be made for humans as well to improve\nthe quality of life for human patients with Glaucoma and reduce Glaucoma\nblindness rates.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.01546v1"
    },
    {
        "title": "Deep Learning in Spatially Resolved Transcriptomics: A Comprehensive\n  Technical View",
        "authors": [
            "Roxana Zahedi Nasab",
            "Mohammad Reza Eftekhariyan Ghamsari",
            "Ahmadreza Argha",
            "Callum Macphillamy",
            "Amin Beheshti",
            "Roohallah Alizadehsani",
            "Nigel H. Lovell",
            "Mohammad Lotfollahi",
            "Hamid Alinejad-Rokny"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Spatially resolved transcriptomics (SRT) has evolved rapidly through various\ntechnologies, enabling scientists to investigate both morphological contexts\nand gene expression profiling at single-cell resolution in parallel. SRT data\nare complex and multi-modal, comprising gene expression matrices, spatial\ninformation, and often high-resolution histology images. Because of this\ncomplexity and multi-modality, sophisticated computational algorithms are\nrequired to accurately analyze SRT data. Most efforts in this domain have been\nmade to utilize conventional machine learning and statistical approaches,\nexhibiting sub-optimal results due to the complicated nature of SRT datasets.\nTo address these shortcomings, researchers have recently employed deep learning\nalgorithms including various state-of-the-art methods mainly in spatial\nclustering, spatially variable gene identification, and alignment. While great\nprogress has been made in developing deep learning-based models for SRT data\nanalysis, further improvement is still needed to create more biologically aware\nmodels that consider aspects such as phylogeny-aware clustering or the analysis\nof small histology image patches. Additionally, strategies for batch effect\nremoval, normalization, and handling overdispersion and zero inflation patterns\nof gene expression are still needed in the analysis of SRT data using deep\nlearning methods. In this paper, we provide a comprehensive overview of these\ndeep learning methods, including their strengths and limitations. We also\nhighlight new frontiers, current challenges, limitations, and open questions in\nthis field. Also, we provide a comprehensive list of all available SRT\ndatabases that can be used as an extensive resource for future studies.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.04453v3"
    },
    {
        "title": "Protein-to-genome alignment with miniprot",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Motivation: Protein-to-genome alignment is critical to annotating genes in\nnon-model organisms. While there are a few tools for this purpose, all of them\nwere developed over ten years ago and did not incorporate the latest advances\nin alignment algorithms. They are inefficient and could not keep up with the\nrapid production of new genomes and quickly growing protein databases.\n  Results: Here we describe miniprot, a new aligner for mapping protein\nsequences to a complete genome. Miniprot integrates recent techniques such as\nk-mer sketch and SIMD-based dynamic programming. It is tens of times faster\nthan existing tools while achieving comparable accuracy on real data.\n  Availability and implementation: https://github.com/lh3/miniprot\n",
        "pdf_link": "http://arxiv.org/pdf/2210.08052v2"
    },
    {
        "title": "Integrative Pan-Cancer Analysis of RNMT: a Potential Prognostic and\n  Immunological Biomarker",
        "authors": [
            "Shuqiang Huang",
            "Cuiyu Tan",
            "Jinzhen Zheng",
            "Zhugu Huang",
            "Zhihong Li",
            "Ziyin Lv",
            "Wanru Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Background: RNA guanine-7 methyltransferase (RNMT) is one of the main\nregulators of N7-methylguanosine, and the deregulation of RNMT correlated with\ntumor development and immune metabolism. However, the specific function of RNMT\nin pan-cancer remains unclear.\n  Methods: RNMT expression in different cancers was analyzed using multiple\ndatabases, including Cancer Cell Line Encyclopedia (CCLE), Genotype-Tissue\nExpression Project (GTEx), and The Cancer Genome Atlas (TCGA). Cox regression\nanalysis and Kaplan-Meier analysis were used to estimate the correlation of\nRNMT expression to prognosis. The data was also used to research the\nrelationship between RNMT expression and common immunoregulators, tumor\nmutation burden (TMB), microsatellite instability (MSI), mismatch repair (MMR),\nand DNA methyltransferase (DNMT). Additionally, the cBioPortal website was used\nto evaluate the characteristics of RNMT alteration. The TISDB database was used\nto obtain the expression of different subtypes. The Tumor Immune Estimation\nResource (TIMER) database was used to analyze the association between RNMT and\ntumor immune infiltration. Gene set enrichment analysis (GSEA) was used to\nidentify the relevant pathways.\n  Results: RNMT was ubiquitously highly expressed across cancers and survival\nanalysis revealed that its expression was highly associated with the clinical\nprognosis of various cancer types. Remarkably, RNMT participates in immune\nregulation and plays a crucial part in the tumor microenvironment. A positive\nassociation was found between RNMT expression and six immune cell types\nexpression in colon adenocarcinoma, kidney renal clear cell carcinoma, and\nliver hepatocellular carcinoma. Moreover, RNMT expression was highly associated\nwith immunoregulators in most cancer types, and correlated to TMB, MSI, MMR,\nand DNMT. Finally, GSEA indicated that RNMT may correlate with tumor immunity.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.09574v2"
    },
    {
        "title": "MVP: Detection of motif-making and -breaking mutations",
        "authors": [
            "Afif Elghraoui",
            "Faramarz Valafar"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Background: DNA, RNA, and protein sequence motifs can be recognition sites\nfor biological functions such as regulation, DNA base modification, and\nmolecular binding in general. The gain and loss of such motifs can carry\nimportant consequences. When comparing sequences, the analysis of individual\nvariants does not impart an understanding of the impact on these sites. Rather,\nonly when these variants considered together with their neighbors and the\noriginal sequence context does this become possible.\n  Results: The motif-variant probe (mvp) makes this consideration, counting\ninstances of user-specified sequence motifs before and after mutation and\nreports those that result in motif gain or loss. mvp can perform a similar\nanalysis for proteins with amino acid variant data. The software is freely\navailable at https://lpcdrp.gitlab.io/mvp and also installable with the conda\npackage manager.\n  Conclusions: The ability to easily search for variants affecting any motif,\ntogether with the simultaneous consideration of neighboring variants makes mvp\na versatile tool to aid in a less-frequented dimension of comparative genomics.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.09842v1"
    },
    {
        "title": "Transcriptome Complexities Across Eukaryotes",
        "authors": [
            "James E. Titus-McQuillan",
            "Adalena V. Nanni",
            "Lauren M. McIntyre",
            "Rebekah L. Rogers"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Genomic complexity is a growing field of evolution, with case studies for\ncomparative evolutionary analyses in model and emerging non-model systems.\nUnderstanding complexity and the functional components of the genome is an\nuntapped wealth of knowledge ripe for exploration. With the \"remarkable lack of\ncorrespondence\" between genome size and complexity, there needs to be a way to\nquantify complexity across organisms. In this study we use a set of complexity\nmetrics that allow for evaluation of changes in complexity using TranD. We\nascertain if complexity is increasing or decreasing across transcriptomes and\nat what structural level, as complexity is varied. We define three metrics --\nTpG, EpT, and EpG in this study to quantify the complexity of the transcriptome\nthat encapsulate the dynamics of alternative splicing. Here we compare\ncomplexity metrics across 1) whole genome annotations, 2) a filtered subset of\northologs, and 3) novel genes to elucidate the impacts of ortholog and novel\ngenes in transcriptome analysis. We also derive a metric from Hong et al.,\n2006, Effective Exon Number (EEN), to compare the distribution of exon sizes\nwithin transcripts against random expectations of uniform exon placement. EEN\naccounts for differences in exon size, which is important because novel genes\ndifferences in complexity for orthologs and whole transcriptome analyses are\nbiased towards low complexity genes with few exons and few alternative\ntranscripts. With our metric analyses, we are able to implement changes in\ncomplexity across diverse lineages with greater precision and accuracy than\nprevious cross-species comparisons under ortholog conditioning. These analyses\nrepresent a step forward toward whole transcriptome analysis in the emerging\nfield of non-model evolutionary genomics, with key insights for evolutionary\ninference of complexity changes on deep timescales across the tree of life. We\nsuggest a means to quantify biases generated in ortholog calling and correct\ncomplexity analysis for lineage-specific effects. With these metrics, we\ndirectly assay the quantitative properties of newly formed lineage-specific\ngenes as they lower complexity in transcriptomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02546v1"
    },
    {
        "title": "Reconstructing gene expression and knockout effect scores from DNA\n  mutation (Mut2Ex): methodology and application to cancer prediction problems",
        "authors": [
            "Maya Ramchandran",
            "Maayan Baron"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Building prediction models for outcomes of clinical relevance when only a\nlimited number of mutational features are available causes considerable\nchallenges due to the sparseness and low-dimensionality of the data. In this\narticle, we present a method to augment the predictive power of these features\nby leveraging multi-modal associative relationships between an individual's\nmutational profile and their corresponding gene expression or knockout effect\nprofiles. We can thus reconstruct expression or effect scores for genes of\ninterest from the available mutation features and then use this reconstructed\nrepresentation directly to model and predict clinical outcomes. We show that\nour method produces significant improvements in predictive accuracy compared to\nmodels utilizing only the raw mutational data, and results in conclusions\ncomparable to those obtained using real expression or effect profiles.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.05170v1"
    },
    {
        "title": "Neural Replicator Analysis for virus genomes binomial systematics in\n  metagenomics",
        "authors": [
            "Alexandr A. Ezhov"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  We have presented some arguments to substantiate the usefulness of neural\nreplicator analysis (NRA) for constructing variants of the natural binomial\nclassification of virus genomes based only on knowledge of their complete\ngenomic sequences, without involving other data on the phenotype, functions,\nencoded proteins, etc., and also without the need of genomic sequences\nalignment. Perhaps this will make sense when processing metagenomic data. This\nmakes it possible to construct the binomial classification accepted for the\nviruses themselves. We restrict ourselves to three families of viruses having\ndsDNA circular genomes (Papillomaviridae, Polyomaviridae and Caulimoviridae)\nand partly to the family Geminiviridae having ssDNA genomes though the approach\npresented can be also applied to genomes of other dsDNA, ssDNA and ssRNA\nviruses, including linear ones (some results for Mitoviridae are also\npresented). It is argued that binomial classification of virus genomes which is\ndifficult to apply in all cases can nevertheless be informative tool of\nrevealing virus properties, areal of hosts, forms of diseases and can also show\nthe connections of the viruses belonging to different families and even to\ndifferent kingdoms.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.05476v1"
    },
    {
        "title": "Sequential Labelling and DNABERT For Splice Site Prediction in Homo\n  Sapiens DNA",
        "authors": [
            "Muhammad Anwari Leksono",
            "Ayu Purwarianti"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Genome sequencing technology has improved significantly in few last years and\nresulted in abundance genetic data. Artificial intelligence has been employed\nto analyze genetic data in response to its sheer size and variability. Gene\nprediction on single DNA has been conducted using various deep learning\narchitectures to discover splice sites and therefore discover intron and exon\nregion. Recent predictions are carried out with models trained on sequence with\nfixed splice site location which eliminates possibility of multiple splice\nsites existence in single sequence. This paper proposes sequential labelling to\npredict splice sites regardless their position in sequence. Sequential\nlabelling is carried out on DNA to determine intron and exon region and thus\ndiscover splice sites. Sequential labelling models used are based on pretrained\nDNABERT-3 which has been trained on human genome. Both fine-tuning and\nfeature-based approach are tested. Proposed model is benchmarked against latest\nsequential labelling model designed for mutation type and location prediction.\nWhile achieving high F1 scores on validation data, both baseline and proposed\nmodel perform poorly on test data. Error and test results analysis reveal that\nmodel experience overfitting and therefore, model is deemed not suitable for\nsplice site prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07638v2"
    },
    {
        "title": "Metabolomics of Aging and Alzheimer's Disease: From Single-Omics to\n  Multi-Omics",
        "authors": [
            "Yiming Li",
            "Yuan Luo"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Aging is a multifactorial process and a key factor of morbidity and\nmortality. Alzheimer's disease (AD) is an age-related disorder and a main cause\nof worldwide disability. Both aging and AD can be characterized by metabolic\ndysfunction. Metabolomics can quantify the complete set of metabolites in a\nstudied sample and is helpful for studying metabolic alterations in aging and\nAD. In this review, we summarize the metabolomic changes regarding aging and\nAD, discuss their biological functions, and highlight their potential\napplication as diagnostic biomarkers or therapeutic targets. Recent advances in\nmulti-omics approaches for understanding the metabolic mechanism of aging and\nAD are also reviewed.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.09870v1"
    },
    {
        "title": "COGEDAP: A COmprehensive GEnomic Data Analysis Platform",
        "authors": [
            "Bayram Cevdet Akdeniz",
            "Oleksandr Frei",
            "Espen Hagen",
            "Tahir Tekin Filiz",
            "Sandeep Karthikeyan",
            "Joelle Pasman",
            "Andreas Jangmo",
            "Jacob Bergsted",
            "John R. Shorter",
            "Richard Zetterberg",
            "Joeri Meijsen",
            "Ida Elken Sonderby",
            "Alfonso Buil",
            "Martin Tesli",
            "Yi Lu",
            "Patrick Sullivan",
            "Ole Andreassen",
            "Eivind Hovig"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Non-sharable sensitive data collection and analysis in large-scale consortia\nfor genomic research is complicated. Time consuming issues in installing\nsoftware arise due to different operating systems, software dependencies and\nrunning the software. Therefore, easier, more standardized, automated protocols\nand platforms can be a solution to overcome these issues. We have developed one\nsuch solution for genomic data analysis using software container technologies.\nThe platform, COGEDAP, consists of different software tools placed into\nSingularity containers with corresponding pipelines and instructions on how to\nperform genome-wide association studies (GWAS) and other genomic data analysis\nvia corresponding tools. Using a provided helper script written in Python,\nusers can obtain auto-generated scripts to conduct the desired analysis both on\nhigh-performance computing (HPC) systems and on personal computers. The\nanalyses can be done by running these auto-generated scripts with the software\ncontainers. The helper script also performs minor re-formatting of the\ninput/output data, so that the end user can work with a unified file format\nregardless of which genetic software is used for the analysis. COGEDAP is\nactively being used by users from different countries/projects to conduct their\ngenomic data analyses. Thanks to this platform, users can easily run GWAS and\nother genomic analyses without spending much effort on software installation,\ndata formats, and other technical requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.14103v1"
    },
    {
        "title": "The big challenge for livestock genomics is to make sequence data pay",
        "authors": [
            "M. Johnsson"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  This paper will argue that one of the biggest challenges for livestock\ngenomics is to make whole-genome sequencing and functional genomics applicable\nto breeding practice. It discusses potential explanations for why it is so\ndifficult to consistently improve the accuracy of genomic prediction by means\nof whole-genome sequence data, and three potential attacks on the problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.01140v4"
    },
    {
        "title": "Unambiguosly expressing expectations about the content of prokaryotic\n  genomes",
        "authors": [
            "Giorgio Gonnella"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In recent years, the sequencing, assembling and annotation of prokaryotic\ngenomes has become increasingly easy and cheap. Thus it becomes increasingly\nfeasible and interesting to perform comparative genomics analyses of new\ngenomes to those of related organisms. Thereby related organisms can be defined\nby different criteria, such as taxonomy or phenotype.\n  Expectations regarding the contents of genomes are often expressed in\nscientific articles describing group of organisms. Evaluating such\nexpectations, when a new genome becomes available, requires analysing the text\nsnippets which express such expectations, extracting the logical elements of\nthe text and enabling a formal expression, more suitable for further automated\nanalyses.\n  Hereby we present a theoretical framework, alongside practical consideration\nfor expressing expectations about the content of genomes, with the purpose of\nenabling such comparative genomics analyses. The components of the framework\ninclude a system for the definition of groups of organisms, supported by a\nProkaryotic Group Types Ontology, a system for the definition of genomic\ncontents, supported by a Prokaryotic Genomic Contents Definition Ontology.\nFinally we discuss how the combination of these two systems may enable an\nunambiguous definition of absolute and relative genome content expectation\nrules.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.02919v2"
    },
    {
        "title": "Early Risk Prediction of Chronic Myeloid Leukemia with Protein Sequences\n  using Machine Learning-based Meta-Ensemble",
        "authors": [
            "Madiha Hameed",
            "Muhammad Bilal",
            "Tuba Majid",
            "Abdul Majid",
            "Asifullah Khan"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Leukemia, the cancer of blood cells, originates in the blood-forming cells of\nthe bone marrow. In Chronic Myeloid Leukemia (CML) conditions, the cells\npartially become mature that look like normal white blood cells but do not\nresist infection effectively. Early detection of CML is important for effective\ntreatment, but there is a lack of routine screening tests. Regular check-ups\nand monitoring of symptoms are the best way to detect CML in the early stages.\nIn the study, we developed a multi-layer-perception-based meta-ensemble system\nusing protein amino acid sequences for early risk prediction of CML. The\ndeleterious mutation analysis of protein sequences provides 7discriminant\ninformation in amino acid sequences causing CML. The protein sequences are\nexpressed into molecular descriptors using the values of hydrophobicity and\nhydrophilicity of the amino acids. 9 These descriptors are transformed in\nvarious statistical and correlation-based feature spaces. These 10 features\ninformation is given to several diverse types of base learners. The preliminary\npredictions of 11 base-learners are employed to develop Multi-Layered\nPerceptron (MLP) based meta-ensemble. The 12 proposed learning approach\neffectively utilizes the discriminant information to classify CML/non- 13 CML\nprotein sequences. The proposed prediction system has given improved results\nand it can be 14 employed as a potential biomarker for early diagnosis of CML.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04200v1"
    },
    {
        "title": "Quantifying the common genetic variability of bacterial traits",
        "authors": [
            "T. Tien Mai",
            "Gerry Tonkin-Hill",
            "John A. Lees",
            "Jukka Corander"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The study of common heritability, or co-heritability, among multiple traits\nhas been widely established in quantitative and molecular genetics. However, in\nbacteria, genome-based estimation of heritability has only been considered very\nrecently and no methods are currently available for considering\nco-heritability. Here we introduce such a method and demonstrate its usefulness\nby multi-trait analyses of the three major human pathogens \\textit{Escherichia\ncoli}, \\textit{Neisseria gonorrhoeae} and \\textit{Streprococcus pneumoniae}. We\nanticipate that the increased availability of high-throughput genomic and\nphenotypic screens of bacterial populations will spawn ample future\nopportunities to understand the common molecular basis of different traits in\nbacteria.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.11378v1"
    },
    {
        "title": "eQTL Studies: from Bulk Tissues to Single Cells",
        "authors": [
            "Jingfei Zhang",
            "Hongyu Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  An expression quantitative trait locus (eQTL) is a chromosomal region where\ngenetic variants are associated with the expression levels of certain genes\nthat can be both nearby or distant. The identifications of eQTLs for different\ntissues, cell types, and contexts have led to better understanding of the\ndynamic regulations of gene expressions and implications of functional genes\nand variants for complex traits and diseases. Although most eQTL studies to\ndate have been performed on data collected from bulk tissues, recent studies\nhave demonstrated the importance of cell-type-specific and context-dependent\ngene regulations in biological processes and disease mechanisms. In this\nreview, we discuss statistical methods that have been developed to enable the\ndetections of cell-type-specific and context-dependent eQTLs from bulk tissues,\npurified cell types, and single cells. We also discuss the limitations of the\ncurrent methods and future research opportunities.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.11662v1"
    },
    {
        "title": "Russel and Rao Coefficient is a Suitable Substitute for Dice Coefficient\n  in Studying Restriction Mapped Genetic Distances of Escherichia coli",
        "authors": [
            "Zhu En Chay",
            "Chin How Lee",
            "Kun Cheng Lee",
            "Jack SH Oon",
            "Maurice HT Ling"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Escherichia coli is one of many bacterial inhabitants found in human\nintestines and any adaptation as a result of mutations may affect its host. A\ncommonly used technique employed to study these mutations is Restriction\nFragment Length Polymorphism (RFLP) and is proceeded with a suitable distance\ncoefficient to quantify genetic differences between 2 samples. Dice is\nconsidered a suitable distance coefficient in RFLP analyses, while others were\nleft unstudied in its suitability for use. Hence, this study aims to identify\nsubstitutes for Dice. Experimental data was obtained by subculturing E. coli\nfor 72 passages in 8 different adaptation media and RFLP profiles analyzed\nusing 20 distance coefficients. Our results suggest that Dennis, Fossum,\nMatching and Russel and Rao to work as well or better than Dice. Dennis,\nMatching and Fossum coefficients had highest discriminatory abilities but are\nlimited by the lack of upper or lower boundaries. Russel and Rao coefficient is\nhighly correlated with Dice coefficient (r2 = 0.998), with both higher and\nlower boundaries, suggesting that Russel and Rao coefficient can be used to\nsubstitute Dice coefficient in studying genetic distances in E. coli.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12714v1"
    },
    {
        "title": "Deciphering a Sleeping Pathogen: Uncovering Novel Transcriptional\n  Regulators of Hypoxia-Induced Dormancy in Mycobacterium Tuberculosis",
        "authors": [
            "Rohak Jain"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Along the pathogenesis of Mycobacterium Tuberculosis (MTB), hypoxia-induced\ndormancy is a process involving the oxygen-depleted environment encountered\ninside the lung granuloma, where bacilli enter a viable, non-replicating state\ntermed as latency. Affecting nearly two billion people, latent TB can linger in\nthe host for indefinite periods of time before resuscitating, which\nsignificantly strains the accuracy of treatment options and patient prognosis.\nTranscriptional factors thought to mediate this process have only conferred\nmild growth defects, signaling that our current understanding of the MTB\ngenetic architecture is highly insufficient. In light of these inconsistencies,\nthe objective of this study was to characterize regulatory mechanisms\nunderlying the transition of MTB into dormancy. The project methodology\ninvolved a three-part approach - constructing an aggregate hypoxia dataset,\ninferring a gene regulatory network based on those observations, and leveraging\nseveral downstream network analyses to make sense of it all. Results indicated\ndormancy to be functionally associated with cell redox homeostasis, metal ion\ncycling, and cell wall metabolism, all of which modulate essential\nhost-pathogen interactions. Additionally, the crosstalk between individual\nregulons (Rv0821c and Rv0144; Rv1152 and Rv2359) was shown to be critical in\nfacilitating bacterial persistence and allowing MTB to gain control over key\nmicronutrients within the cell. Defense antioxidants and nutritional immunity\nwere also identified as future avenues to explore further. In providing some of\nthe first insights into the methods utilized by MTB to endure in a hypoxic\nstate, this research suggests a range of strategies that might aid in improved\nclinical outcomes of TB treatment.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.04034v2"
    },
    {
        "title": "Molecular detection and antimicrobial activity of Endophytic fungi\n  isolated from a medical plant Rosmarinus officinalis",
        "authors": [
            "Shimal Yonuis Abdulhadi",
            "Ghazwan Qasim Hasan",
            "Raghad Nawaf Gergees"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Endophytes are tiny organisms present in living tissues of distinct plants\nand have been extensively studied for their endophytic microbial complement.\nRoots of Rosmarinus officinalis were subjected to the isolation of endophytic\nfungi and screened for antimicrobial activity against Gram-positive\n(Staphylococcus aureus and Bacillus subtilis) and Gram-negative (Escherichia\ncoli, Pseudomonas aeruginosa, Klebsiella pneumoniae) bacteria. Genomic DNA from\nactive fungal strain of Trichoderma harzianum was isolated, and the internal\ntranscribed spacer (ITS) region was amplified using ITS4 and ITS5 primers and\nsequenced for genetic inference in fungus. The crude extract of T. harzianum\nisolate with Ethyl acetate was showed significant antimicrobial activity\nagainst P. aeruginosa, S. aureus, K. pneumonia, B. subtilis and E. coli. The\nantimicrobial activity was highest against P. aeruginosa at concentration of 40\nmicrogram/ ml, followed by S. aureus and K. pneumonia at the same\nconcentration. The lowest antimicrobial activity was against by S. aureus at\nconcentration of 60 microgram/ ml. The current study is confirmed that the\nantimicrobial activity is due to bioactive compounds founded in endophytic\nfungi.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.05242v1"
    },
    {
        "title": "Molecular characterization of wild Pleurotus ostreatus (MW457626) and\n  evaluation of $β$-glucans polysaccharide activities",
        "authors": [
            "Ghazwan Qasim Hasan",
            "Shimal Younis Abdulhadi"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Pleurotus ostreatus is a common cultivated edible mushroom worldwide. The\nfruiting bodies of P. ostreatus is a rich source of a $\\beta$-glucans\npolysaccharide. The current study aimed to investigate the effectiveness of\n$\\beta$-glucans as a natural polysaccharide produced by P. ostreatus as an\nantioxidant, antimicrobial, and anticancer. The molecular identification of P.\nostreatus isolate was confirmed by Internal Transcribed Spacer (ITS) sequence.\nThe sequence alignment and phylogenetic evolutionary relationship of studied\nITS sequence were performed against some deposited sequences in GenBank. The\nanalysis of high-performance liquid chromatography (HPLC) as well as the result\nof fourier transform infrared spectroscopy (FTIR) has confirmed the presence of\n$\\beta$-glucans polysaccharide in the tested samples. The percentage of\nantioxidant activity of $\\beta$-glucans showed a gradual increase from 8.59% to\n12.36, 18.56, 23.69, 44.66 and 80.36% at the concentrations of 31.2, 64.4, 125,\n250, 500, and 800 $\\mu$g/ml, respectively. In addition, all concentrations of\n$\\beta$-glucans showed higher antioxidant activities when compared with\nstandard antioxidant (Vitamin C). The highest antimicrobial activity of\n$\\beta$-glucans polysaccharide was against P. aeruginosa with a zone of\ninhibition (45 mm), while the lowest activity was against S. aureus (13 mm)\nboth at 100 mg/mL. The percentage of growth-inhibiting of MCF-7 a humanbreast\ncancer cell line and normal WRL-68 cell line affected by $\\beta$-glucans were\ndetermined by 3-(4,5)-dimethylthiazol (-z-y1)-3,5-di-phenytetrazoliumromide\n(MTT assay).\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06187v1"
    },
    {
        "title": "A primer on correlation-based dimension reduction methods for\n  multi-omics analysis",
        "authors": [
            "Tim Downing",
            "Nicos Angelopoulos"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The continuing advances of omic technologies mean that it is now more\ntangible to measure the numerous features collectively reflecting the molecular\nproperties of a sample. When multiple omic methods are used, statistical and\ncomputational approaches can exploit these large, connected profiles.\nMulti-omics is the integration of different omic data sources from the same\nbiological sample. In this review, we focus on correlation-based dimension\nreduction approaches for single omic datasets, followed by methods for pairs of\nomics datasets, before detailing further techniques for three or more omic\ndatasets. We also briefly detail network methods when three or more omic\ndatasets are available and which complement correlation-oriented tools. To aid\nreaders new to this area, these are all linked to relevant R packages that can\nimplement these procedures. Finally, we discuss scenarios of experimental\ndesign and present road maps that simplify the selection of appropriate\nanalysis methods. This review will guide researchers navigate the emerging\nmethods for multi-omics and help them integrate diverse omic datasets\nappropriately and embrace the opportunity of population multi-omics.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06975v7"
    },
    {
        "title": "EGC: a format for expressing prokaryotic genomes content expectations",
        "authors": [
            "Giorgio Gonnella"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The number of available genomes of prokaryotic organisms is rapidly growing\nenabling comparative genomics studies. The comparison of genomes of organisms\nwith a common phenotype, habitat or phylogeny often shows that these genomes\nshare some common contents. Collecting rules expressing common genome traits\ndepending on given factors is useful, as such rules could be used for quality\ncontrol or for identifying interesting exceptions and formulating hypothesis.\nAutomatizing the rules verification using computation tools requires the\ndefinition of a representation schema. In this study, we present EGC (Expected\nGenome Contents), a flat-text file format for the representation of expectation\nrules about the content of prokaryotic genomes. A parser for the EGC format has\nbeen implemented using the TextFormats software library, accompanied by a set\nof related Python packages.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08758v2"
    },
    {
        "title": "PhaBOX: A web server for identifying and characterizing phage contigs in\n  metagenomic data",
        "authors": [
            "Jiayu Shang",
            "Cheng Peng",
            "Herui Liao",
            "Xubo Tang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Motivation: There is accumulating evidence showing the important roles of\nbacteriophages (phages) in regulating the structure and functions of the\nmicrobiome. However, lacking an easy-to-use and integrated phage analysis\nsoftware hampers microbiome-related research from incorporating phages in the\nanalysis. Results: In this work, we developed a web server, PhaBOX, which can\ncomprehensively identify and analyze phage contigs in metagenomic data. It\nsupports integrated phage analysis, including phage contig identification from\nthe metagenomic assembly, lifestyle prediction, taxonomic classification, and\nhost prediction. Instead of treating the algorithms as a black box, PhaBOX also\nsupports visualization of the essential features for making predictions. The\nweb server is designed with a user-friendly graphical interface that enables\nboth informatics-trained and non-specialist users to analyze phages in\nmicrobiome data with ease. Availability: The web server of PhaBOX is available\nvia: https://phage.ee.cityu.edu.hk. The source code of PhaBOX is available at:\nhttps://github.com/KennthShang/PhaBOX Contact: yannisun@cityu.edu.hk\n",
        "pdf_link": "http://arxiv.org/pdf/2303.15707v3"
    },
    {
        "title": "Prediction of cancer driver genes and mutations: the potential of\n  integrative computational frameworks",
        "authors": [
            "Mona Nourbakhsh",
            "Kristine Degn",
            "Astrid Saksager",
            "Matteo Tiberti",
            "Elena Papaleo"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The vast amount of sequencing data presently available allow the scientific\ncommunity to explore a range of genetic variables that may drive and progress\ncancer. A myriad of predictive tools has been proposed, allowing researchers\nand clinicians to compare and prioritize driver genes and mutations and their\nrelative pathogenicity. However, there is little consensus on the computational\napproach or a golden standard for comparison. Hence, benchmarking the different\ntools depends highly on the input data, indicating that overfitting is still a\nmassive problem. One of the solutions is to limit the scope and usage of\nspecific tool. However, such limitations forces researchers to walk on a\ntightrope between creating and using high-quality tools for a specific purpose\nand describing the complex alterations driving cancer. While the knowledge of\ncancer development increases every day, many bioinformatic pipelines rely on\nsingle nucleotide variants or alterations in a vacuum without accounting for\ncellular compartment, mutational burden, or disease progression. Even within\nbioinformatics and computational cancer biology, the research fields work in\nsilos, risking overlooking potential synergies or breakthroughs. Here, we\nprovide an overview of databases and datasets for building or testing\npredictive tools for discovery of cancer drivers. We introduce predictive tools\nfor driver genes, driver mutations, and the impact of these based on structural\nanalysis. Additionally, we suggest and recommend directions in the field to\navoid silo-research, moving in the direction of integrative frameworks.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.17402v1"
    },
    {
        "title": "Buffalo Genome Projects: Current Situation and Future Perspective in\n  Improving Breeding Programs",
        "authors": [
            "Ahmed M. Mousbah",
            "Hesham M. Abdullah",
            "Waleed S. Mohammed",
            "Ali M. El-Refy",
            "Mohamed Helmy"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Buffaloes are farm animals that contribute to food security by providing high\nquality meat and milk. They can better tolerate the adverse effects of global\nclimate change on their meat and milk production. Despite their advantages,\nbuffaloes are heavily neglected animals with fewer studies compared to other\nfarm animals, hence, the real potential of buffaloes has never been realized.\nThe complete genome sequencing projects of buffaloes are essential to better\nunderstanding the buffalos biology and production since they allow scientists\nto identify important genes and understand how the gene networks interact to\ndetermine the critical features of buffaloes. The genome projects are also\nvaluable for gaining better knowledge of growth, development, maintenance, and\ndetermining factors associated with increased meat and milk production.\nFurthermore, having access to a complete genome of high quality and\ncomprehensive annotations provides a powerful tool in breeding programs. The\ncurrent review surveyed the publicly available buffalo genome projects and\nstudied the impact of incorporating genomic selection into the buffalo breeding\nprogram. Our survey of the publicly available buffalo genome projects showed\nthe promise of genomic selection in developing water buffalo science and\ntechnology for food security on a global scale.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.04977v1"
    },
    {
        "title": "MIK2 is a candidate gene of the S-locus for sporophytic\n  self-incompatibility (SSI) in chicory (Cichorium intybus, Asteraceae)",
        "authors": [
            "Fabio Palumbo",
            "Samela Draga",
            "Gabriele Magon",
            "Giovanni Gabelli",
            "Alessandro Vannozzi",
            "Silvia Farinati",
            "Francesco Scariolo",
            "Margherita Lucchin",
            "Gianni Barcaccia"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The Cichorium genus offers a unique opportunity to study the sporophytic self\nincompatibility (SSI) system, being composed of species characterized by highly\nefficient SI (C. intybus) and complete self compatibility (C. endivia). The\nchicory genome was used to map 7 previously identified SSI locus-associated\nmarkers. The region containing the S locus was restricted to an 4 M bp window\non chromosome 5. Among the genes predicted in this region, MDIS1 INTERACTING\nRECEPTOR LIKE KINASE 2 (MIK2) was promising as a candidate for SSI. Its\northolog in Arabidopsis is involved in pollen stigma recognition reactions, and\nits protein structure is similar to that of S-receptor kinase (SRK), a key\ncomponent of the SSI in the Brassica genus. The sequencing of MIK2 in chicory\nand endive accessions revealed two contrasting scenarios. In C. endivia, MIK2\nwas fully conserved even comparing different botanical varieties (smooth and\ncurly). In C. intybus, 387 SNPs and 3 INDELs were identified when comparing\naccessions of different biotypes from the same botanical variety (radicchio).\nThe SNP distribution throughout the gene was uneven, with hypervariable domains\npreferentially localized in the LRR-rich extracellular region, putatively\nidentified as the receptor domain. The gene was hypothesized to be under\npositive selection, as the nonsynonymous mutations were more than double the\nsynonymous ones (dN / dS = 2.17). An analogous situation was observed analyzing\nthe first 500 bp of the MIK2 promoter: no SNPs were observed among the endive\nsamples, whereas 44 SNPs and 6 INDELs were detected among the chicory samples.\nFurther analyses are needed to confirm the role of MIK2 in SSI and to\ndemonstrate whether the 23 species-specific nonsynonymous SNPs in the CDS\nand/or the species-specific 10 bp INDEL found in a CCAAT box region of the\npromoter are responsible for the contrasting sexual behaviors of the two\nspecies.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.06410v1"
    },
    {
        "title": "A Method for Improving the Detection Accura-cy of MSIsensor Based on\n  Downsampling",
        "authors": [
            "Ji Detao",
            "Liu Weier"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Motivation: Microsatellite instability (MSI) is a cancer biomarker associated\nwith cancer prognosis and chemotherapy sensitivity. Since the discovery of MSI,\npolymerase chain reaction (PCR)-based testing has been considered the gold\nstandard for MSI detection. However, with the decrease in sequencing costs,\nsoftware that calculates MSI based on next-generation sequencing (NGS) data has\nbeen widely applied. Results: In this study, we evaluated the performance of\nthe MSIsensor detection software, focusing on the limitations of the chi-square\ntest algorithm in determining microsatellite stability under high-depth\nsequencing data. We demonstrated that the chi-square test algorithm is\ninsufficient for accurately as-sessing microsatellite stability in this\ncontext. Furthermore, we explored the application of downsampling techniques to\nenhance the accuracy of MSIsensor detection. Our findings provide insight into\nthe limita-tions of current methods and offer potential improvements for more\nreliable MSI detection based on NGS data.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.07205v1"
    },
    {
        "title": "De novo reconstruction of satellite repeat units from sequence data",
        "authors": [
            "Yujie Zhang",
            "Justin Chu",
            "Haoyu Cheng",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Satellite DNA are long tandemly repeating sequences in a genome and may be\norganized as high-order repeats (HORs). They are enriched in centromeres and\nare challenging to assemble. Existing algorithms for identifying satellite\nrepeats either require the complete assembly of satellites or only work for\nsimple repeat structures without HORs. Here we describe Satellite Repeat Finder\n(SRF), a new algorithm for reconstructing satellite repeat units and HORs from\naccurate reads or assemblies without prior knowledge on repeat structures.\nApplying SRF to real sequence data, we showed that SRF could reconstruct known\nsatellites in human and well-studied model organisms. We also found satellite\nrepeats are pervasive in various other species, accounting for up to 12% of\ntheir genome contents but are often underrepresented in assemblies. With the\nrapid progress on genome sequencing, SRF will help the annotation of new\ngenomes and the study of satellite DNA evolution even if such repeats are not\nfully assembled.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09729v1"
    },
    {
        "title": "Advancing regulatory genomics with machine learning",
        "authors": [
            "Laurent Bréhélin"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In recent years, several machine learning approaches have been proposed to\npredict gene expression and epigenetic signals from the DNA sequence alone.\nThese models are often used to deduce, and, to some extent, assess putative new\nbiological insights about gene regulation, and they have led to very\ninteresting advances in regulatory genomics. This article reviews a selection\nof these methods, ranging from linear models to random forests, kernel methods,\nand more advanced deep learning models. Specifically, we detail the different\ntechniques and strategies that can be used to extract new gene-regulation\nhypotheses from these models. Furthermore, because these putative insights need\nto be validated with wet-lab experiments, we emphasize that it is important to\nhave a measure of confidence associated with the extracted hypotheses. We\nreview the procedures that have been proposed to measure this confidence for\nthe different types of machine learning models, and we discuss the fact that\nthey do not provide the same kind of information.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12963v1"
    },
    {
        "title": "Representing and extracting knowledge from single cell data",
        "authors": [
            "Ionut Sebastian Mihai",
            "Sarang Chafle",
            "Johan Henriksson"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Single-cell analysis is currently one of the most high-resolution techniques\nto study biology. The large complex datasets that have been generated have\nspurred numerous developments in computational biology, in particular the use\nof advanced statistics and machine learning. This review attempts to explain\nthe deeper theoretical concepts that underpin current state-of-the-art analysis\nmethods. Single-cell analysis is covered from cell, through instruments, to\ncurrent and upcoming models. A minimum of mathematics and statistics has been\nused, but the reader is assumed to either have basic knowledge of single-cell\nanalysis workflows, or have a solid knowledge of statistics. The aim of this\nreview is to spread concepts which are not yet in common use, especially from\ntopology and generative processes, and how new statistical models can be\ndeveloped to capture more of biology. This opens epistemological questions\nregarding our ontology and models, and some pointers will be given to how\nnatural language processing (NLP) may help overcome our cognitive limitations\nfor understanding single-cell data.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.13084v1"
    },
    {
        "title": "SinglePointRNA, an user-friendly application implementing single cell\n  RNA-seq analysis software",
        "authors": [
            "Laura Puente-Santamaría",
            "Luis del Peso"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Single-cell transcriptomics techniques, such as scRNA-seq, attempt to\ncharacterize gene expression profiles in each cell of a heterogeneous sample\nindividually. Due to growing amounts of data generated and the increasing\ncomplexity of the computational protocols needed to process the resulting\ndatasets, the demand for dedicated training in mathematical and programming\nskills may preclude the use of these powerful techniques by many teams.\n  In order to help close that gap between wet-lab and dry-lab capabilities we\nhave developed SinglePointRNA, a shiny-based R application that provides a\ngraphic interface for different publicly available tools to analyze single cell\nRNA-seq data.\n  The aim of SinglePointRNA is to provide an accessible and transparent tool\nset to researchers that allows them to perform detailed and custom analysis of\ntheir data autonomously. SinglePointRNA is structured in a context-driven\nframework that prioritizes providing the user with solid qualitative guidance\nat each step of the analysis process and interpretation of the results.\nAdditionally, the rich user guides accompanying the software are intended to\nserve as a point of entry for users to learn more about computational\ntechniques applied to single cell data analysis.\n  The SinglePointRNA app, as well as case datasets for the different tutorials\nare available at www.github.com/ScienceParkMadrid/SinglePointRNA\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00008v1"
    },
    {
        "title": "Prokaryotic genome editing based on the subtype I-B-Svi CRISPR-Cas\n  system",
        "authors": [
            "Wang-Yu Tong",
            "De-Xiang Yong",
            "Xin Xu",
            "Cai-Hua Qiu",
            "Yan Zhang",
            "Xing-Wang Yang",
            "Ting-Ting Xia",
            "Qing-Yang Liu",
            "Su-Li Cao",
            "Yan Sun",
            "Xue Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Type I CRISPR-Cas systems are the most common among six types of CRISPR-Cas\nsystems, however, non-self-targeting genome editing based on a single Cas3 of\ntype I CRISPR-Cas systems has not been reported. Here, we present the subtype\nI-B-Svi CRISPR-Cas system (with three confirmed CRISPRs and a cas gene cluster)\nand genome editing based on this system found in Streptomyces virginiae IBL14.\nImportantly, like the animal-derived bacterial protein SpCas9 (1368\namino-acids), the single, compact, non-animal-derived bacterial protein SviCas3\n(771 amino-acids) can also direct template-based microbial genome editing\nthrough the target cell's own homology-directed repair system, which breaks the\nview that the genome editing based on type I CRISPR-Cas systems requires a full\nCascade. Notably, no off-target changes or indel-formation were detected in the\nanalysis of potential off-target sites. This discovery broadens our\nunderstanding of the diversity of type I CRISPR-Cas systems and will facilitate\nnew developments in genome editing tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.05093v1"
    },
    {
        "title": "Template-based eukaryotic genome editing directed by SviCas3",
        "authors": [
            "Wang-Yu Tong",
            "Yong Li",
            "Shou-Dong Ye",
            "An-Jing Wang",
            "Yan-Yan Tang",
            "Mei-Li Li",
            "Zhong-Fan Yu",
            "Ting-Ting Xia",
            "Qing-Yang Liu",
            "Si-Qi Zhu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  RNA-guided gene editing based on the CRISPR-Cas system is currently the most\neffective genome editing technique. Here, we report that the SviCas3 from the\nsubtype I-B-Svi Cas system in Streptomyces virginiae IBL14 is an RNA-guided and\nDNA-guided DNA endonuclease suitable for the HDR-directed gene and/or base\nediting of eukaryotic cell genomes. The genome editing efficiency of SviCas3\nguided by DNA is no less than that of SviCas3 guided by RNA. In particular,\nt-DNA, as a template and a guide, does not require a proto-spacer-adjacent\nmotif, demonstrating that CRISPR, as the basis for crRNA design, is not\nrequired for the SviCas3-mediated gene and base editing. This discovery will\nbroaden our understanding of enzyme diversity in CRISPR-Cas systems, will\nprovide important tools for the creation and modification of living things and\nthe treatment of human genetic diseases, and will usher in a new era of\nDNA-guided gene editing and base editing.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.05861v1"
    },
    {
        "title": "The evolution of next-generation sequencing technologies",
        "authors": [
            "Olaitan Akintunde",
            "Trichina Tucker",
            "Valerie J. Carabetta"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The genetic information that dictates the structure and function of all life\nforms is encoded in the DNA. In 1953, Watson and Crick first presented the\ndouble helical structure of a DNA molecule. Their findings unearthed the desire\nto elucidate the exact composition and sequence of DNA molecules. Discoveries\nand the subsequent development and optimization of techniques that allowed for\ndeciphering the DNA sequence has opened new doors in research, biotech, and\nhealthcare. The application of high-throughput sequencing technologies in these\nindustries has positively impacted and will continue to contribute to the\nbetterment of humanity and the global economy. Improvements, such as the use of\nradioactive molecules for DNA sequencing to the use of florescent dyes and the\nimplementation of polymerase chain reaction (PCR) for amplification, led to\nsequencing a few hundred base pairs in days, to automation, where sequencing of\nthousands of base pairs in hours became possible. Significant advances have\nbeen made, but there is still room for improvement. Here, we look at the\nhistory and the technology of the currently available next-generation\nsequencing platforms and the possible applications of such technologies to\nbiomedical research and beyond.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08724v1"
    },
    {
        "title": "New Sequence Alignment Algorithm using AI Rules and Dynamic Seeds",
        "authors": [
            " Suchindra",
            "Preetam Nagaraj"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  DNA sequence alignment is important today as it is usually the first step in\nfinding gene mutation, evolutionary similarities, protein structure, drug\ndevelopment and cancer treatment. Covid-19 is one recent example. There are\nmany sequencing algorithms developed over the past decades but the sequence\nalignment using expert systems is quite new. To find DNA sequence alignment,\ndynamic programming was used initially. Later faster algorithms used small DNA\nsequence length of fixed size to find regions of similarity, and then build the\nfinal alignment using these regions. Such systems were not sensitive but were\nfast. To improve the sensitivity, we propose a new algorithm which is based on\nfinding maximal matches between two sequences, find seeds between them, employ\nrules to find more seeds of varying length, and then employ a new stitching\nalgorithm, and weighted seeds to solve the problem\n",
        "pdf_link": "http://arxiv.org/pdf/2305.19276v1"
    },
    {
        "title": "pgMAP: a pipeline to enable guide RNA read mapping from dual-targeting\n  CRISPR screens",
        "authors": [
            "Phoebe C. R. Parrish",
            "Daniel J. Groso",
            "James D. Thomas",
            "Robert K. Bradley",
            "Alice H. Berger"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  We developed pgMAP, an analysis pipeline to map gRNA sequencing reads from\ndual-targeting CRISPR screens. pgMAP output includes a dual gRNA read counts\ntable and quality control metrics including the proportion of correctly-paired\nreads and CRISPR library sequencing coverage across all time points and\nsamples. pgMAP is implemented using Snakemake and is available open-source\nunder the MIT license at https://github.com/fredhutch/pgmap_pipeline.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.00944v1"
    },
    {
        "title": "A FAIR platform for reproducing mutational signature detection on tumor\n  sequencing data",
        "authors": [
            "Aaron Ge",
            "Tongwu Zhang",
            "Clara Bodelon",
            "Montserrat Garcia-Closas",
            "Jonas Almeida",
            "Jeya Balasubramanian"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  This paper presents a portable, privacy-preserving, in-browser platform for\nthe reproducible assessment of mutational signature detection methods from\nsparse sequencing data generated by targeted gene panels. The platform aims to\naddress the reproducibility challenges in mutational signature research by\nadhering to the FAIR principles, making it findable, accessible, interoperable,\nand reusable. Our approach focuses on the detection of specific mutational\nsignatures, such as SBS3, which have been linked to specific mutagenic\nprocesses. The platform relies on publicly available data, simulation,\ndownsampling techniques, and machine learning algorithms to generate training\ndata and labels and to train and evaluate models. The key achievement of our\nplatform is its transparency, reusability, and privacy preservation, enabling\nresearchers and clinicians to analyze mutational signatures with the guarantee\nthat no data circulates outside the client machine.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.01634v1"
    },
    {
        "title": "Scalable telomere-to-telomere assembly for diploid and polyploid genomes\n  with double graph",
        "authors": [
            "Haoyu Cheng",
            "Mobin Asri",
            "Julian Lucas",
            "Sergey Koren",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Despite recent advances in the length and the accuracy of long-read data,\nbuilding haplotype-resolved genome assemblies from telomere to telomere still\nrequires considerable computational resources. In this study, we present an\nefficient de novo assembly algorithm that combines multiple sequencing\ntechnologies to scale up population-wide telomere-to-telomere assemblies. By\nutilizing twenty-two human and two plant genomes, we demonstrate that our\nalgorithm is around an order of magnitude cheaper than existing methods, while\nproducing better diploid and haploid assemblies. Notably, our algorithm is the\nonly feasible solution to the haplotype-resolved assembly of polyploid genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.03399v1"
    },
    {
        "title": "Collection of prokaryotic genome contents expectation rules from\n  scientific literature",
        "authors": [
            "Serena Lam",
            "Giorgio Gonnella"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Shaped by natural selection and other evolutionary forces, an organism's\nevolutionary history is reflected through its genome sequence, content of\nfunctional elements and organization. Consequently, organisms connected through\nphylogeny, metabolic or morphological traits, geographical proximity, or\nhabitat features are likely to exhibit similarities in their genomes. These\nsimilarities give rise to expectations about the content of genomes within\nthese organism groups.\n  Such expectations are often informally expressed in scientific literature,\nfocusing on the analysis of individual genomes or comparisons among related\ngroups of organisms. Our objective is to develop a system for formalized\nexpectations as rules, facilitating automated verification, and evaluation of\nnewly sequenced genomes.\n  In this study, we present a database comprising rules manually extracted from\nscientific literature. Furthermore, we explore the feasibility of automatizing\nthe extraction and analysis process using large language models, such as GPT3.5\nand GPT4.\n  We have developed a web application, EGCWebApp, which enables users to\nvisualize and edit the rules. Additionally, we provided a Python library and\ncommand-line tools collection, egctools, to further extend the functionality\nfor processing and managing these rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.08486v1"
    },
    {
        "title": "A Novel Approach to Encode Two-Way Epistatic Interactions Between Single\n  Nucleotide Polymorphisms",
        "authors": [
            "Nathaniel Gunter",
            "Prashanthi Vemuri",
            "Vijay Ramanan",
            "Robel K Gebre"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Modelling gene-gene epistatic interactions when computing genetic risk scores\nis not a well-explored subfield of genetics and could have potential to improve\nrisk stratification in practice. Though applications of machine learning (ML)\nshow promise as an avenue of improvement for current genetic risk assesments,\nthey frequently suffer from the problem of two many features and to little\ndata. We propose a method that when combined with ML allows information from\nindividual genetic contributors to be preserved while incorporating information\non their interactions in a single feature. This allows second-order analysis,\nwhile simultaneously increasing the number of input features to ML models as\nlittle as possible. We presented three methods that can be utilized to account\nfor genetic interactions. We found that interaction methods that preserved\ninformation from the constituent SNPs performed significantly better than the\nsimplest interaction method. Since the currently available ML methods are able\nto account for complex interactions, utilizing raw SNP genotypes alone is\nsufficient because the simplest model outperforms all the interaction methods\nGiven that understanding and accounting for epistatic interactions is one of\nthe most promising avenues for increasing explained variability in heritable\ndisease, this work represents a first step toward an algorithmic interaction\nmethod that preserves the information in each component. This is relevant not\nonly because of potential improvements in model quality, but also because\nexplicit interaction terms allow a human readable interpretation of potential\ninteraction pathways within the disease.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.09175v1"
    },
    {
        "title": "Prognostic Biomarker Identification for Pancreatic Cancer by Analyzing\n  Multiple mRNA Microarray and microRNA Expression Datasets",
        "authors": [
            "Azmain Yakin Srizon"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Possessing the five-year durability rate of nearly 5%, currently, the fourth\nleading cause for cancer-related deaths is pancreatic cancer. Previously,\nseveral works have resolved that early diagnosis performs a meaningful function\nin enhancing the durability rate and diverse online tools have been utilized to\ndistinguish prognostic biomarker which is a lengthy process. We believe that\nthe statistical feature selection method can produce a better and faster result\nhere. To authenticate our statement, we picked three different mRNA microarray\n(GSE15471, GSE28735, and GSE16515) and a microRNA (GSE41372) dataset for\nidentification of differentially expressed genes (DEGs) and differentially\nexpressed microRNAs (DEMs). By adopting some feature selecting methods, 178\nDEGs and 16 DEMs were elected. After identifying target genes of DEMs, we\nselected two DEGs (ECT2 and NRP2) which were also identified among DEMs target\ngenes. Moreover, overall durability report established that ECT2 and NRP2 were\nassociated with poor overall survival. Hence, we concluded that for pancreatic\ncancer, statistical feature selection approaches certainly perform better for\nbiomarker identification than pre-defined online programs, and here, ECT2 and\nNRP2 can act as possible prognostic biomarkers. All the resources, programs and\nsnippets of our literature can be discovered at\nhttps://github.com/Srizon143005/PancreaticCancerBiomarkers.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.12320v1"
    },
    {
        "title": "SumVg: Total heritability explained by all variants in genome-wide\n  association studies based on summary statistics with standard error estimates",
        "authors": [
            "Hon-Cheong So",
            "Xiao Xue",
            "Pak-Chung Sham"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Genome-wide association studies (GWAS) are commonly employed to study the\ngenetic basis of complex traits and diseases, and a key question is how much\nheritability could be explained by all variants in GWAS. One widely used\napproach that relies on summary statistics only is LD score regression (LDSC),\nhowever the approach requires certain assumptions on the SNP effects (all SNPs\ncontribute to heritability and each SNP contributes equal variance). More\nflexible modeling methods may be useful. We previously developed an approach\nrecovering the true z-statistics from a set of observed z-statistics with an\nempirical Bayes approach, using only summary statistics. However, methods for\nstandard error (SE) estimation are not available yet, limiting the\ninterpretation of results and applicability of the approach. In this study we\ndeveloped several resampling-based approaches to estimate the SE of SNP-based\nheritability, including two jackknife and three parametric bootstrap methods.\nSimulations showed that delete-d-jackknife and parametric bootstrap approaches\nprovide good estimates of the SE. Particularly, the parametric bootstrap\napproaches yield the lowest root-mean-squared-error (RMSE) of the true SE. In\naddition, we applied our method to estimate SNP-based heritability of 12\nimmune-related traits (levels of cytokines and growth factors) to shed light on\ntheir genetic architecture. We also implemented the methods to compute the sum\nof heritability explained and the corresponding SE in an R package SumVg,\navailable at https://github.com/lab-hcso/Estimating-SE-of-total-heritability/ .\nIn conclusion, SumVg may provide a useful alternative tool for SNP heritability\nand SE estimates, which does not rely on distributional assumptions of SNP\neffects.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.14200v1"
    },
    {
        "title": "Comparative study of under-expressed prognostic biomarkers and pivotal\n  signaling pathways in colon cancer and ulcerative colitis using integrated\n  bioinformatics approach",
        "authors": [
            "Sedigheh Behrouzifar"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Colon cancer is a prevalent gastrointestinal malignancy arising in the colon.\nUlcerative colitis(UC) is one of the risk factors of colorectal cancer. The\ndetection of under-expressed biomarkers and molecular mechanisms in UC and\ncolon cancer can lead to effective management of colitis-associated cancer. A\ntotal of two mRNA expression datasets (GSE87473 and GSE44076) were downloaded\nfrom the Gene Expression Omnibus (GEO) database. GEO2R was used to screen\ndifferentially expressed genes (DEGs) between extensive ulcerative colitis\nsamples and healthy samples, limited ulcerative colitis samples and healthy\nsamples, and colon cancer samples and healthy samples. In extensive ulcerative\ncolitis, limited ulcerative colitis and colon cancer groups, 95,69 and 635\nunder-expressed genes with adjusted p-value<0.05 and log(2) fold change<-2 were\ndetected respectively. Using Cytoscape software, the genes with degree> 15\nincluding CLCA1, SLC26A3, SI, KIT, HPGDS, NR1H4, ADIPOQ, PPARGC1A, GCG, MS4A12,\nGUCA2A and FABP1 were screened as hub under-expressed genes in colon cancer. In\nextensive ulcerative colitis, the genes with degree>5 including ABCB1, ABCG2,\nUGT1A6, CYP2B6 and AQP8 were identified as hub genes. Moreover, the genes\nincluding NR1H4, CYP2B6, ABCB1, ABCG2, UGT2A3 and PLA2G12B were detected as hub\ngenes with degree>5 in limited ulcerative colitis. According to inclusion\ncriteria and venn diagram, the downregulated gene NR1H4 was common gene in\nlimited ulcerative colitis and colon cancer. The current in silico study showed\nthat downregulation of CLCA1, PPARGC1A and AQP8 genes may increase cancer cell\ninvasion and metastasis ability.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.00295v1"
    },
    {
        "title": "Root Causal Inference from Single Cell RNA Sequencing with the Negative\n  Binomial",
        "authors": [
            "Eric V. Strobl"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Accurately inferring the root causes of disease from sequencing data can\nimprove the discovery of novel therapeutic targets. However, existing root\ncausal inference algorithms require perfectly measured continuous random\nvariables. Single cell RNA sequencing (scRNA-seq) datasets contain large\nnumbers of cells but non-negative counts measured by an error prone process. We\ntherefore introduce an algorithm called Root Causal Inference with Negative\nBinomials (RCI-NB) that accounts for count-based measurement error by\nseparating negative binomial distributions into their gamma and Poisson\ncomponents; the gamma distributions form a fully identifiable but latent post\nnon-linear causal model representing the true RNA expression levels, which we\nonly observe with Poisson corruption. RCI-NB identifies patient-specific root\ncausal contributions from scRNA-seq datasets by integrating novel sparse\nregression and goodness of fit testing procedures that bypass Poisson\nmeasurement error. Experiments demonstrate significant improvements over\nexisting alternatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.05338v1"
    },
    {
        "title": "ProSt: computing, storing and visualizing attributes of prokaryotic\n  genomes",
        "authors": [
            "Giorgio Gonnella"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Prokaryotic organisms usually possess compact genomes, which are particularly\nsuitable to complete sequencing with existing technologies, which led to an\nescalating accumulation of available genome data. In response to this\never-expanding repository of information, we introduce ProSt, a computational\nsystem designed for the batch computation, storage, and interactive\nvisualization of the values of attributes of prokaryotic genomes. The system\nallows for parallel attribute value batch computation, dynamically designed to\nincrementally integrate new attribute values as additional genomes become\navailable.\n  ProSt is flexible permitting the definition of attributes by implementing\nattribute value computation plugins, supporting several languages (Python, Nim,\nRust and Bash). This allows the system to continually evolve in accordance with\nchanging research needs and developments. Additionally, our computation and\nstorage systems maintain comprehensive metadata, thereby enabling data\nprovenance tracking for the computed attribute values.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.08367v2"
    },
    {
        "title": "Somatic mutations in human ageing: New insights from DNA sequencing and\n  inherited mutations",
        "authors": [
            "Kasit Chatsirisupachai",
            "João Pedro de Magalhães"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The accumulation of somatic mutations is a driver of cancer and has long been\nassociated with ageing. Due to limitations in quantifying mutation burden with\nage in non-cancerous tissues, the impact of somatic mutations in other ageing\nphenotypes is unclear. Recent advances in DNA sequencing technologies have\nallowed the large-scale quantification of somatic mutations in ageing. These\nstudies have revealed a gradual accumulation of mutations in most normal\ntissues with age as well as a substantial clonal expansion driven mostly by\ncancer-related mutations. Nevertheless, because of the relatively modest burden\nof age-related somatic mutations identified so far and their stochastic nature,\nit is difficult to envision how somatic mutation accumulation alone can explain\nmost ageing phenotypes that develop gradually. Studies across species have also\nfound that longer-lived species have lower somatic mutation rates, though these\ncould be explained by selective pressures to reduce or postpone cancer as\nlongevity increases. Overall, with a few exceptions like cancer, results from\nrecent DNA sequencing studies do not add weight to the idea that somatic\nmutations with age drive ageing phenotypes and the phenotypic role, if any, of\nsomatic mutations in ageing remains unclear. Recent studies in patients with\nsomatic mutation burden and no signs of accelerated ageing further question the\nrole of somatic mutations in ageing.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.15471v1"
    },
    {
        "title": "Enhancing Cell Proliferation and Migration by MIR-Carbonyl Vibrational\n  Coupling: Insights from Transcriptome Profiling",
        "authors": [
            "Xingkun Niu",
            "Feng Gao",
            "Shaojie Hou",
            "Shihao Liu",
            "Xinmin Zhao",
            "Jun Guo",
            "Liping Wang",
            "Feng Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Cell proliferation and migration highly relate to normal tissue self-healing,\ntherefore it is highly significant for artificial controlling. Recently,\nvibrational strong coupling between biomolecules and Mid-infrared (MIR) light\nphotons has been successfully used to modify in vitro bioreactions, neuronal\nsignaling and even animal behavior. However, the synergistic effects from\nmolecules to cells remains unclear, and the regulation of MIR on cells needs to\nbe explained from the molecular level. Herein, the proliferation rate and\nmigration capacity of fibroblasts were increased by 156% and 162.5%,\nrespectively, by vibratory coupling of 5.6 micrometers photons with carbonyl\ngroups in biomolecules. Through transcriptome sequencing analysis, the\nregulatory mechanism of infrared light in 5.6 micrometers was explained from\nthe level of signal pathway and cell components. 5.6 micrometers optical high\npower lasers can regulate cell function through vibrational strong coupling\nwhile minimizing photothermal damage. This work not only sheds light on the\nnon-thermal effect on MIR light-based on wound healing, but also provides new\nevidence to future frequency medicine.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.02257v1"
    },
    {
        "title": "mSigSDK -- private, at scale, computation of mutation signatures",
        "authors": [
            "Aaron Ge",
            "Yasmmin Côrtes Martins",
            "Tongwu Zhang",
            "Kailing Chen",
            "Maria Teresa Landi",
            "Brian Park",
            "Jeya Balasubramanian",
            "Jonas S Almeida"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In our previous work, we demonstrated that it is feasible to perform analysis\non mutation signature data without the need for downloads or installations and\nanalyze individual patient data at scale without compromising privacy. Building\non this foundation, we developed a Software Development Kit (SDK) called\nmSigSDK to facilitate the orchestration of distributed data processing\nworkflows and graphic visualization of mutational signature analysis results.\nWe strictly adhered to modern web computing standards, particularly the\nmodularization standards set by the ECMAScript ES6 framework (JavaScript\nmodules). Our approach allows for computation to be entirely performed by\nsecure delegation to the computational resources of the user's own machine\n(in-browser), without any downloads or installations. The mSigSDK was developed\nprimarily as a companion library to the mSig Portal resource of the National\nCancer Institute Division of Cancer Epidemiology and Genetics (NIH/NCI/DCEG),\nwith a focus on its FAIR extensibility as components of other researchers'\ncomputational constructs. Anticipated extensions include the programmatic\noperation of other mutation signature API ecosystems such as SIGNAL and COSMIC,\nadvancing towards a data commons for mutational signature research (Grossman et\nal., 2016).\n",
        "pdf_link": "http://arxiv.org/pdf/2308.02995v2"
    },
    {
        "title": "Genome assembly in the telomere-to-telomere era",
        "authors": [
            "Heng Li",
            "Richard Durbin"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  De novo assembly is the process of reconstructing the genome sequence of an\norganism from sequencing reads. Genome sequences are essential to biology, and\nassembly has been a central problem in bioinformatics for four decades. Until\nrecently, genomes were typically assembled into fragments of a few megabases at\nbest but technological advances in long-read sequencing now enable near\ncomplete chromosome-level assembly, also known as telomere-to-telomere\nassembly, for many organisms. Here we review recent progress on assembly\nalgorithms and protocols. We focus on how to derive near telomere-to-telomere\nassemblies and discuss potential future developments.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.07877v1"
    },
    {
        "title": "Genomic reproducibility in the bioinformatics era",
        "authors": [
            "Pelin Icer Baykal",
            "Paweł P. Łabaj",
            "Florian Markowetz",
            "Lynn M. Schriml",
            "Daniel J. Stekhoven",
            "Serghei Mangul",
            "Niko Beerenwinkel"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In biomedical research, validation of a new scientific discovery is tied to\nthe reproducibility of its experimental results. However, in genomics, the\ndefinition and implementation of reproducibility still remain imprecise. Here,\nwe argue that genomic reproducibility, defined as the ability of bioinformatics\ntools to maintain consistent genomics results across technical replicates, is\nkey to generating scientific knowledge and enabling medical applications. We\nfirst discuss different concepts of reproducibility and then focus on\nreproducibility in the context of genomics, aiming to establish clear\ndefinitions of relevant terms. We then focus on the role of bioinformatics\ntools and their impact on genomic reproducibility and assess methods of\nevaluating bioinformatics tools in terms of genomic reproducibility. Lastly, we\nsuggest best practices for enhancing genomic reproducibility, with an emphasis\non assessing the performance of bioinformatics tools through rigorous testing\nacross multiple technical replicates.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09558v1"
    },
    {
        "title": "SARS-CoV-2 Wastewater Genomic Surveillance: Approaches, Challenges, and\n  Opportunities",
        "authors": [
            "Viorel Munteanu",
            "Michael Saldana",
            "Dumitru Ciorba",
            "Viorel Bostan",
            "Justin Maine Su",
            "Nadiia Kasianchuk",
            "Nitesh Kumar Sharma",
            "Sergey Knyazev",
            "Victor Gordeev",
            "Eva Aßmann",
            "Andrei Lobiuc",
            "Mihai Covasa",
            "Keith A. Crandall",
            "Wenhao O. Ouyang",
            "Nicholas C. Wu",
            "Christopher Mason",
            "Braden T Tierney",
            "Alexander G Lucaci",
            "Alex Zelikovsky",
            "Fatemeh Mohebbi",
            "Pavel Skums",
            "Cynthia Gibas",
            "Jessica Schlueter",
            "Piotr Rzymski",
            "Helena Solo-Gabriele",
            "Martin Hölzer",
            "Adam Smith",
            "Serghei Mangul"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  During the SARS-CoV-2 pandemic, wastewater-based genomic surveillance (WWGS)\nemerged as an efficient viral surveillance tool that takes into account\nasymptomatic cases and can identify known and novel mutations and offers the\nopportunity to assign known virus lineages based on the detected mutations\nprofiles. WWGS can also hint towards novel or cryptic lineages, but it is\ndifficult to clearly identify and define novel lineages from wastewater (WW)\nalone. While WWGS has significant advantages in monitoring SARS-CoV-2 viral\nspread, technical challenges remain, including poor sequencing coverage and\nquality due to viral RNA degradation. As a result, the viral RNAs in wastewater\nhave low concentrations and are often fragmented, making sequencing difficult.\nWWGS analysis requires advanced computational tools that are yet to be\ndeveloped and benchmarked. The existing bioinformatics tools used to analyze\nwastewater sequencing data are often based on previously developed methods for\nquantifying the expression of transcripts or viral diversity. Those methods\nwere not developed for wastewater sequencing data specifically, and are not\noptimized to address unique challenges associated with wastewater. While\nspecialized tools for analysis of wastewater sequencing data have also been\ndeveloped recently, it remains to be seen how they will perform given the\nongoing evolution of SARS-CoV-2 and the decline in testing and patient-based\ngenomic surveillance. Here, we discuss opportunities and challenges associated\nwith WWGS, including sample preparation, sequencing technology, and\nbioinformatics methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.13326v2"
    },
    {
        "title": "Categorization and analysis of 14 computational methods for estimating\n  cell potency from single-cell RNA-seq data",
        "authors": [
            "Qingyang Wang",
            "Zhiqian Zhai",
            "Qiuyu Lian",
            "Dongyuan Song",
            "Jingyi Jessica Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In single-cell RNA sequencing (scRNA-seq) analysis, a key challenge is\ninferring hidden cellular dynamics from static cell snapshots. Various\ncomputational methods have been developed to address this, focusing on\nperspectives like pseudotime trajectories, RNA velocities, and estimating the\ndifferentiation potential of cells, often referred to as \"cell potency.\" This\nreview summarizes 14 methods for defining cell potency from scRNA-seq data,\ncategorizing them into average-based, entropy-based, and correlation-based\nmethods based on how they summarize gene expression levels into a potency\nmeasure. We highlight the key similarities and differences within and between\nthese categories, offering a high-level intuition for each method.\nAdditionally, we use unified mathematical notations to detail each method's\nmethodology and summarize their usage complexities, including parameters,\nrequired inputs, and differences between published descriptions and software\nimplementations. We conclude that cell potency estimation remains an open\nquestion without a consensus on the optimal approach, emphasizing the need for\nbenchmark datasets and studies. This review aims to provide a foundation for\nfuture benchmark studies, while also addressing the broader challenge of\ncomparing methods that infer cellular dynamics from scRNA-seq data through\nvarious perspectives, including pseudotime trajectories, RNA velocities, and\ncell potency.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.13518v2"
    },
    {
        "title": "A rigorous benchmarking of methods for SARS-CoV-2 lineage abundance\n  estimation in wastewater",
        "authors": [
            "Viorel Munteanu",
            "Victor Gordeev",
            "Michael Saldana",
            "Eva Aßmann",
            "Justin Maine Su",
            "Nicolae Drabcinski",
            "Oksana Zlenko",
            "Maryna Kit",
            "Felicia Iordachi",
            "Khooshbu Kantibhai Patel",
            "Abdullah Al Nahid",
            "Likhitha Chittampalli",
            "Yidian Xu",
            "Pavel Skums",
            "Shelesh Agrawal",
            "Martin Hölzer",
            "Adam Smith",
            "Alex Zelikovsky",
            "Serghei Mangul"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In light of the continuous transmission and evolution of SARS-CoV-2 coupled\nwith a significant decline in clinical testing, there is a pressing need for\nscalable, cost-effective, long-term, passive surveillance tools to effectively\nmonitor viral variants circulating in the population. Wastewater genomic\nsurveillance of SARS-CoV-2 has arrived as an alternative to clinical genomic\nsurveillance, allowing to continuously monitor the prevalence of viral lineages\nin communities of various size at a fraction of the time, cost, and logistic\neffort and serving as an early warning system for emerging variants, critical\nfor developed communities and especially for underserved ones. Importantly,\nlineage prevalence estimates obtained with this approach aren't distorted by\nbiases related to clinical testing accessibility and participation. However,\nthe relative performance of bioinformatics methods used to measure relative\nlineage abundances from wastewater sequencing data is unknown, preventing both\nthe research community and public health authorities from making informed\ndecisions regarding computational tool selection. Here, we perform\ncomprehensive benchmarking of 18 bioinformatics methods for estimating the\nrelative abundance of SARS-CoV-2 (sub)lineages in wastewater by using data from\n36 in vitro mixtures of synthetic lineage and sublineage genomes. In addition,\nwe use simulated data from 78 mixtures of lineages and sublineages co-occurring\nin the clinical setting with proportions mirroring their prevalence ratios\nobserved in real data. Importantly, we investigate how the accuracy of the\nevaluated methods is impacted by the sequencing technology used, the associated\nerror rate, the read length, read depth, but also by the exposure of the\nsynthetic RNA mixtures to wastewater, with the goal of capturing the effects\ninduced by the wastewater matrix, including RNA fragmentation and degradation.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.16994v3"
    },
    {
        "title": "GOLEM: distribution of Gene regulatOry eLEMents within the plant\n  promoters",
        "authors": [
            "Lukáš Nevosád",
            "Božena Klodová",
            "David Honys",
            "Radka Svobodová",
            "Tomáš Raček",
            "Petra Procházková Schrumpfová"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Motivation: The regulation of gene expression during tissue development is\nextremely complex. One of the key regulatory mechanisms of gene expression\ninvolves the recognition of regulatory motifs by various proteins in the\npromoter regions of many genes. Localisation of these motifs in proximity to\nthe transcription start site (TSS) or translation start site (ATG) is critical\nfor regulating the initiation and rate of transcription. The levels of\ntranscription of individual genes, regulated by these motifs, can vary signifi\ncantly in diff erent tissues and developmental stages, especially during\ntightly regulated processes such as sexual reproduction. However, the precise\nlocalisation and visualisation of the regulatory motifs within gene promoters\nwith respect to gene transcription in specifi c tissues, can be challenging.\nResults: Here, we introduce a program called GOLEM (Gene regulatOry eLEMents)\nwhich enables users to precisely locate any motif of interest with respect to\nTSS or ATG within the relevant plant genomes across the plant Tree of Life\n(Marchantia, Physcomitrium, Amborella, Oryza, Zea, Solanum and Arabidopsis).\nThe visualisation of the motifs is performed with respect to the transcript\nlevels of particular genes in leaves and male reproductive tissues, and can be\ncompared with genome-wide distribution regardless of the transcription level.\nAvailability and implementation: GOLEM is freely available at\nhttps://golem.ncbr.muni.cz and its source codes are provided under the MIT\nlicence at GitHub at https://github.com/sb-ncbr/golem.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.15206v1"
    },
    {
        "title": "Comparative Analysis of Plastid Genomes Using Pangenome Research ToolKit\n  (PGR-TK)",
        "authors": [
            "Richa Jayanti",
            "Andrew Kim",
            "Sean Pham",
            "Athreya Raghavan",
            "Anish Sharma",
            "Manoj P. Samanta"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Plastid genomes (plastomes) of angiosperms are of great interest among\nbiologists. High-throughput sequencing is making many such genomes accessible,\nincreasing the need for tools to perform rapid comparative analysis. This\nexploratory analysis investigates whether the Pangenome Research Tool Kit\n(PGR-TK) is suitable for analyzing plastomes. After determining the optimal\nparameters for this tool on plastomes, we use it to compare sequences from each\nof the genera - Magnolia, Solanum, Fragaria and Cotoneaster, as well as a\ncombined set from 20 rosid genera. PGR-TK recognizes large-scale plastome\nstructures, such as the inverted repeats, among combined sequences from distant\nrosid families. If the plastid genomes are rotated to the same starting point,\nit also correctly groups different species from the same genus together in a\ngenerated cladogram. The visual approach of PGR-TK provides insights into\ngenome evolution without requiring gene annotations.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.19110v1"
    },
    {
        "title": "scX: A user-friendly tool for scRNA-seq exploration",
        "authors": [
            "Tomás Vega Waichman",
            "M. Luz Vercesi",
            "Ariel A. Berardino",
            "Maximiliano S. Beckel",
            "Damiana Giacomini",
            "Natalí B. Rasetto",
            "Magalí Herrero",
            "Daniela J. Di Bella",
            "Paola Arlotta",
            "Alejandro F. Schinder",
            "Ariel Chernomoretz"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Single-cell RNA sequencing (scRNA-seq) has transformed our ability to explore\nbiological systems. Nevertheless, proficient expertise is essential for\nhandling and interpreting the data. In this paper, we present scX, an R package\nbuilt on the Shiny framework that streamlines the analysis, exploration, and\nvisualization of single-cell experiments. With an interactive graphic\ninterface, implemented as a web application, scX provides easy access to key\nscRNAseq analyses, including marker identification, gene expression profiling,\nand differential gene expression analysis. Additionally, scX seamlessly\nintegrates with commonly used single-cell Seurat and SingleCellExperiment R\nobjects, resulting in efficient processing and visualization of varied\ndatasets. Overall, scX serves as a valuable and user-friendly tool for\neffortless exploration and sharing of single-cell data, simplifying some of the\ncomplexities inherent in scRNAseq analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.00012v2"
    },
    {
        "title": "Generating site saturation mutagenesis libraries and transferring them\n  to broad host range plasmids using type IIS restriction enzymes",
        "authors": [
            "Niels N. Oehlmann",
            "Johannes G. Rebelein"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Protein engineering is an established method for tailoring enzymatic\nreactivity. A commonly used method is directed evolution, where the mutagenesis\nand natural selection process is mimicked and accelerated in the laboratory.\nHere, we describe a reliable method for generating saturation mutagenesis\nlibraries by golden gate cloning in a broad host range plasmid containing the\npBBR1 replicon. The applicability is demonstrated by generating a mutant\nlibrary of the iron nitrogenase gene cluster (anfHDGK) of Rhodobacter\ncapsulatus, which is subsequently screened for the improved formation of\nmolecular hydrogen.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.00138v1"
    },
    {
        "title": "Probing omics data via harmonic persistent homology",
        "authors": [
            "Davide Gurnari",
            "Aldo Guzmán-Sáenz",
            "Filippo Utro",
            "Aritra Bose",
            "Saugata Basu",
            "Laxmi Parida"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Identifying molecular signatures from complex disease patients with\nunderlying symptomatic similarities is a significant challenge in the analysis\nof high dimensional multi-omics data. Topological data analysis (TDA) provides\na way of extracting such information from the geometric structure of the data\nand identifying multiway higher-order relationships. Here, we propose an\napplication of Harmonic persistent homology, which overcomes the limitations of\nambiguous assignment of the topological information to the original elements in\na representative topological cycle from the data. When applied to multi-omics\ndata, this leads to the discovery of hidden patterns highlighting the\nrelationships between different omic profiles, while allowing for common tasks\nin multi-omics analyses, such as disease subtyping, and most importantly\nbiomarker identification for similar latent biological pathways that are\nassociated with complex diseases. Our experiments on multiple cancer data show\nthat harmonic persistent homology effectively dissects multi-omics data to\nidentify biomarkers by detecting representative cycles predictive of disease\nsubtypes.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06357v2"
    },
    {
        "title": "Accelerating ILP solvers for Minimum Flow Decompositions through search\n  space and dimensionality reductions",
        "authors": [
            "Andreas Grigorjew",
            "Fernando H. C. Dias",
            "Andrea Cracco",
            "Romeo Rizzi",
            "Alexandru I. Tomescu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Given a flow network, the Minimum Flow Decomposition (MFD) problem is finding\nthe smallest possible set of weighted paths whose superposition equals the\nflow. It is a classical, strongly NP-hard problem that is proven to be useful\nin RNA transcript assembly and applications outside of Bioinformatics. We\nimprove an existing ILP (Integer Linear Programming) model by Dias et al.\n[RECOMB 2022] for DAGs by decreasing the solver's search space using solution\nsafety and several other optimizations. This results in a significant speedup\ncompared to the original ILP, of up to 55-90x on average on the hardest\ninstances. Moreover, we show that our optimizations apply also to MFD problem\nvariants, resulting in similar speedups, going up to 123x on the hardest\ninstances. We also developed an ILP model of reduced dimensionality for an MFD\nvariant in which the solution path weights are restricted to a given set. This\nmodel can find an optimal MFD solution for most instances, and overall, its\naccuracy significantly outperforms that of previous greedy algorithms while\nbeing up to an order of magnitude faster than our optimized ILP.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.10563v1"
    },
    {
        "title": "Using Guided Transfer Learning to Predispose AI Agent to Learn\n  Efficiently from Small RNA-sequencing Datasets",
        "authors": [
            "Kevin Li",
            "Danko Nikolić",
            "Vjekoslav Nikolić",
            "Davor Andrić",
            "Lauren M. Sanders",
            "Sylvain V. Costes"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Given the increasing availability of RNA-seq data and its complex and\nheterogeneous nature, there has been growing interest in applying AI/machine\nlearning methodologies to work with such data modalities. However, because\nomics data is characterized by high dimensionality and low sample size (HDLSS),\ncurrent attempts at integrating AI in this domain require significant human\nguidance and expertise to mitigate overfitting. In this work we look at how\ntransfer learning can be improved to learn from small RNA-seq sample sizes\nwithout significant human interference. The strategy is to gain general prior\nknowledge about a particular domain of data (e.g. RNA-seq data) by pre-training\non a general task with a large aggregate of data, then fine-tuning to various\nspecific, downstream target tasks in the same domain. Because previous attempts\nhave shown traditional transfer learning failing on HLDSS, we propose to\nimprove performance by using Guided Transfer Learning (GTL). Collaborating with\nRobots Go Mental, the AI we deploy here not only learns good initial parameters\nduring pre-training, but also learns inductive biases that affect how the AI\nlearns downstream tasks. In this approach, we first pre-trained on recount3\ndata, a collection of over 400,000 mouse RNA-seq samples sourced from thousands\nof individual studies. With such a large collection, patterns of expression\nbetween the ~30,000 genes in mammalian systems were pre-determined. Such\npatterns were sufficient for the pre-trained AI agent to efficiently learn new\ndownstream tasks involving RNA-seq datasets with very low sample sizes and\nperformed notably better on few-shot learning tasks compared to the same model\nwithout pre-training.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12045v1"
    },
    {
        "title": "A selective review of recent developments in spatially variable gene\n  detection for spatial transcriptomics",
        "authors": [
            "Sikta Das Adhikari",
            "Jiaxin Yang",
            "Jianrong Wang",
            "Yuehua Cui"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  With the emergence of advanced spatial transcriptomic technologies, there has\nbeen a surge in research papers dedicated to analyzing spatial transcriptomics\ndata, resulting in significant contributions to our understanding of biology.\nThe initial stage of downstream analysis of spatial transcriptomic data has\ncentered on identifying spatially variable genes (SVGs) or genes expressed with\nspecific spatial patterns across the tissue. SVG detection is an important task\nsince many downstream analyses depend on these selected SVGs. Over the past few\nyears, a plethora of new methods have been proposed for the detection of SVGs,\naccompanied by numerous innovative concepts and discussions. This article\nprovides a selective review of methods and their practical implementations,\noffering valuable insights into the current literature in this field.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.13801v1"
    },
    {
        "title": "Identifying topologically associating domains using differential kernels",
        "authors": [
            "Luka Maisuradze",
            "Megan C. King",
            "Ivan V. Surovtsev",
            "Simon G. J. Mochrie",
            "Mark D. Shattuck",
            "Corey S. O'Hern"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Chromatin is a polymer complex of DNA and proteins that regulates gene\nexpression. The three-dimensional structure and organization of chromatin\ncontrols DNA transcription and replication. High-throughput chromatin\nconformation capture techniques generate Hi-C maps that can provide insight\ninto the 3D structure of chromatin. Hi-C maps can be represented as a symmetric\nmatrix where each element represents the average contact probability or number\nof contacts between two chromatin loci. Previous studies have detected\ntopologically associating domains (TADs), or self-interacting regions in Hi-C\nmaps within which the contact probability is greater than that outside the\nregion. Many algorithms have been developed to identify TADs within Hi-C maps.\nHowever, most TAD identification algorithms are unable to identify nested or\noverlapping TADs and for a given Hi-C map there is significant variation in the\nlocation and number of TADs identified by different methods. We develop a novel\nmethod, KerTAD, using a kernel-based technique from computer vision and image\nprocessing that is able to accurately identify nested and overlapping TADs. We\nbenchmark this method against state-of-the-art TAD identification methods on\nboth synthetic and experimental data sets. We find that KerTAD consistently has\nhigher true positive rates (TPR) and lower false discovery rates (FDR) than all\ntested methods for both synthetic and manually annotated experimental Hi-C\nmaps. The TPR for KerTAD is also largely insensitive to increasing noise and\nsparsity, in contrast to the other methods. We also find that KerTAD is\nconsistent in the number and size of TADs identified across replicate\nexperimental Hi-C maps for several organisms. KerTAD will improve automated TAD\nidentification and enable researchers to better correlate changes in TADs to\nbiological phenomena, such as enhancer-promoter interactions and disease\nstates.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14342v1"
    },
    {
        "title": "DSBplot: Indels in DNA Double-strand Break Repair Experiments",
        "authors": [
            "Tejasvi Channagiri",
            "Margherita Maria Ferrari",
            "Youngkyu Jeon",
            "Penghao Xu",
            "Francesca Storici",
            "Nataša Jonoska"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Double-strand breaks (DSBs) in DNA are naturally occurring destructive events\nin all organisms that may lead to genome instability. Cells employ various\nrepair methods known as non-homologous end joining (NHEJ), microhomology\nmediated end joining (MMEJ), and homology-directed recombination (HDR). These\nrepair processes may lead to DNA sequence variations (e.g., nucleotide\ninsertions, deletions, and substitutions) at the location of the break.\nStudying DNA DSB repair processes often involves the use of high throughput\nsequencing assays to precisely quantify the sequence variations near the break\nwith software tools. Often methods of assessing and visualizing these data have\nnot taken into account the full complexity of the sequencing data, such as the\nfrequency, type, and position of the sequence variations in a single\ncomprehensive representation. Here we present a method that allows\nvisualization of the overall variation pattern as well as comparison of these\npatterns among experimental setups.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.17590v3"
    },
    {
        "title": "Approximating a linear dynamical system from non-sequential data",
        "authors": [
            "Cliff Stein",
            "Pratik Worah"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Given non-sequential snapshots from instances of a dynamical system, we\ndesign a compressed sensing based algorithm that reconstructs the dynamical\nsystem. We formally prove that successful reconstruction is possible under the\nassumption that we can construct an approximate clock from a subset of the\ncoordinates of the underlying system.\n  As an application, we argue that our assumption is likely true for genomic\ndatasets, and we recover the underlying nuclear receptor networks and predict\npathways, as opposed to genes, that may differentiate phenotypes in some\npublicly available datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11858v1"
    },
    {
        "title": "Enhancing Cardiovascular Disease Risk Prediction with Machine Learning\n  Models",
        "authors": [
            "Farnoush Shishehbori",
            "Zainab Awan"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Cardiovascular disease remains a leading global cause of mortality,\nnecessitating accurate risk prediction tools. Traditional methods, such as\nQRISK and the Framingham heart score, exhibit limitations in their ability to\nincorporate comprehensive patient data, potentially resulting in incomplete\nrisk factor consideration. To address these shortcomings, this study conducts a\nmeticulous review focusing on the application of machine learning models to\nenhance predictive accuracy. Machine learning models, such as support vector\nmachines, and Random Forest, as well as deep learning techniques like\nconvolutional neural networks and recurrent neural networks, have emerged as\npromising alternatives. These models offer superior performance, accommodating\na broader spectrum of variables and providing precise subgroup-specific\npredictions. While machine learning integration holds promise for enhancing\nrisk assessment, it presents challenges such as data requirements and\ncomputational constraints. Additionally, large language models have\nrevolutionised healthcare applications, augmenting diagnostic precision and\npatient care. This study examines the core aspects of cardiovascular disease\nevent risk and presents a thorough review of traditional and machine learning\nmodels, alongside deep learning techniques, for improved accuracy. It offers a\ncomprehensive survey of relevant datasets, critically compares ML models with\nconventional approaches, and synthesizes key findings, highlighting their\nimplications for clinical practice. Furthermore, the potential of machine\nlearning and large language models in cardiovascular medicine is undeniable.\nHowever, rigorous validation and optimisation are imperative before widespread\napplication in healthcare. This integration promises more accurate and\npersonalised cardiovascular care.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.17328v3"
    },
    {
        "title": "Evaluation of simulation methods for tumor subclonal reconstruction",
        "authors": [
            "Jiaying Lai",
            "Yunzhou Liu",
            "Robert B. Scharpf",
            "Rachel Karchin"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Most neoplastic tumors originate from a single cell, and their evolution can\nbe genetically traced through lineages characterized by common alterations such\nas small somatic mutations (SSMs), copy number alterations (CNAs), structural\nvariants (SVs), and aneuploidies. Due to the complexity of these alterations in\nmost tumors and the errors introduced by sequencing protocols and calling\nalgorithms, tumor subclonal reconstruction algorithms are necessary to\nrecapitulate the DNA sequence composition and tumor evolution in silico. With a\ngrowing number of these algorithms available, there is a pressing need for\nconsistent and comprehensive benchmarking, which relies on realistic tumor\nsequencing generated by simulation tools. Here, we examine the current\nsimulation methods, identifying their strengths and weaknesses, and provide\nrecommendations for their improvement. Our review also explores potential new\ndirections for research in this area. This work aims to serve as a resource for\nunderstanding and enhancing tumor genomic simulations, contributing to the\nadvancement of the field.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09599v1"
    },
    {
        "title": "Predicting Breast Cancer Phenotypes from Single-cell RNA-seq Data Using\n  CloudPred",
        "authors": [
            "Hossein Moghimianavval",
            "Baharan Meghdadi",
            "Tasmine Clement",
            "Man I Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Numerous tools have been recently developed to predict disease phenotypes\nusing single-cell RNA sequencing (RNA-seq) data. CloudPred is an end-to-end\ndifferentiable learning algorithm coupled with a biologically informed mixture\nmodel, originally tested on lupus data. This study extends CloudPred's\napplications to breast cancer disease phenotype prediction to test its\nrobustness and applicability on untested and unrelated biological data. When\napplying a breast cancer single-cell RNA seq dataset, CloudPred achieved an\narea under the ROC curve (AUC) of 1 in predicting cancer status and performed\nbetter than a linear and Deepset models.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11289v1"
    },
    {
        "title": "Exploring gene content with pangene graphs",
        "authors": [
            "Heng Li",
            "Maximillian Marin",
            "Maha Reda Farhat"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Motivation: The gene content regulates the biology of an organism. It varies\nbetween species and between individuals of the same species. Although tools\nhave been developed to identify gene content changes in bacterial genomes, none\nis applicable to collections of large eukaryotic genomes such as the human\npangenome.\n  Results: We developed pangene, a computational tool to identify gene\norientation, gene order and gene copy-number changes in a collection of\ngenomes. Pangene aligns a set of input protein sequences to the genomes,\nresolves redundancies between protein sequences and constructs a gene graph\nwith each genome represented as a walk in the graph. It additionally finds\nsubgraphs, which we call bibubbles, that capture gene content changes. Applied\nto the human pangenome, pangene identifies known gene-level variations and\nreveals complex haplotypes that are not well studied before. Pangene also works\nwith high-quality bacterial pangenome and reports similar numbers of core and\naccessory genes in comparison to existing tools.\n  Availability and implementation: Source code at\nhttps://github.com/lh3/pangene; pre-built pangene graphs can be downloaded from\nhttps://zenodo.org/records/8118576 and visualized at\nhttps://pangene.bioinweb.org\n",
        "pdf_link": "http://arxiv.org/pdf/2402.16185v3"
    },
    {
        "title": "Graph-based variant discovery reveals novel dynamics in the human\n  microbiome",
        "authors": [
            "Harihara Subrahmaniam Muralidharan",
            "Jacquelyn S Michaelis",
            "Jay Ghurye",
            "Todd Treangen",
            "Sergey Koren",
            "Marcus Fedarko",
            "Mihai Pop"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Sequence differences between the strains of bacteria comprising\nhost-associated and environmental microbiota may play a role in community\nassembly and influence the resilience of microbial communities to disturbances.\nTools for characterizing strain-level variation within microbial communities,\nhowever, are limited in scope, focusing on just single nucleotide\npolymorphisms, or relying on reference-based analyses that miss complex\nfunctional and structural variants. Here, we demonstrate the power of assembly\ngraph analysis to detect and characterize structural variants in almost 1,000\nmetagenomes generated as part of the Human Microbiome Project. We identify over\nnine million variants comprising insertion/deletion events, repeat copy-number\nchanges, and mobile elements such as plasmids. We highlight some of the\npotential functional roles of these genomic changes. Our analysis revealed\nstriking differences in the rate of variation across body sites, highlighting\nniche-specific mechanisms of bacterial adaptation. The structural variants we\ndetect also include potentially novel prophage integration events, highlighting\nthe potential use of graph-based analyses for phage discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.01610v1"
    },
    {
        "title": "A genome-scale deep learning model to predict gene expression changes of\n  genetic perturbations from multiplex biological networks",
        "authors": [
            "Lingmin Zhan",
            "Yuanyuan Zhang",
            "Yingdong Wang",
            "Aoyi Wang",
            "Caiping Cheng",
            "Jinzhong Zhao",
            "Wuxia Zhang",
            "Peng Lia",
            "Jianxin Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Systematic characterization of biological effects to genetic perturbation is\nessential to the application of molecular biology and biomedicine. However, the\nexperimental exhaustion of genetic perturbations on the genome-wide scale is\nchallenging. Here, we show that TranscriptionNet, a deep learning model that\nintegrates multiple biological networks to systematically predict\ntranscriptional profiles to three types of genetic perturbations based on\ntranscriptional profiles induced by genetic perturbations in the L1000 project:\nRNA interference (RNAi), clustered regularly interspaced short palindromic\nrepeat (CRISPR) and overexpression (OE). TranscriptionNet performs better than\nexisting approaches in predicting inducible gene expression changes for all\nthree types of genetic perturbations. TranscriptionNet can predict\ntranscriptional profiles for all genes in existing biological networks and\nincreases perturbational gene expression changes for each type of genetic\nperturbation from a few thousand to 26,945 genes. TranscriptionNet demonstrates\nstrong generalization ability when comparing predicted and true gene expression\nchanges on different external tasks. Overall, TranscriptionNet can systemically\npredict transcriptional consequences induced by perturbing genes on a\ngenome-wide scale and thus holds promise to systemically detect gene function\nand enhance drug development and target discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.02724v1"
    },
    {
        "title": "The use of next-generation sequencing in personalized medicine",
        "authors": [
            "Liya Popova",
            "Valerie J. Carabetta"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The revolutionary progress in development of next-generation sequencing (NGS)\ntechnologies has made it possible to deliver accurate genomic information in a\ntimely manner. Over the past several years, NGS has transformed biomedical and\nclinical research and found its application in the field of personalized\nmedicine. Here we discuss the rise of personalized medicine and the history of\nNGS. We discuss current applications and uses of NGS in medicine, including\ninfectious diseases, oncology, genomic medicine, and dermatology. We provide a\nbrief discussion of selected studies where NGS was used to respond to wide\nvariety of questions in biomedical research and clinical medicine. Finally, we\ndiscuss the challenges of implementing NGS into routine clinical use.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03688v1"
    },
    {
        "title": "Genetic diversity of barley accessions and their response under abiotic\n  stresses using different approaches",
        "authors": [
            "Djshwar Dhahir Lateef",
            "Nawroz Abdul-razzak Tahir"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  In this investigation, five separate experiments were carried out. The first\nexperiments were examined the molecular characteristics of 59 barley accessions\ncollected from different regions in Iraq using three different molecular\nmarkers (ISSR, CDDP, and Scot). A total of 391 amplified polymorphic bands were\ngenerated using forty-four ISSR, nine CDDP, and twelve Scot primers, which they\ntotally observed 255, 35, and 101 polymorphic bands respectively. The mean\nvalues of PIC for ISSR, CDDP, and Scot markers were 0.74, 0.63, and 0.80,\nrespectively, indicating the efficiency of the underlying markers in detecting\npolymorphic status among the studied barley accessions. Based on the respective\nmarkers, the barley accessions were classified and clustered into two main\ngroups using the UPGMA and population structure analysis. Results of claustral\nanalyses showed that the variation patterns corresponded with the geographical\ndistribution of barley accessions.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.14181v1"
    },
    {
        "title": "Just-DNA-Seq, open-source personal genomics platform: longevity science\n  for everyone",
        "authors": [
            "Kulaga Anton",
            "Borysova Olga",
            "Karmazin Alexey",
            "Koval Maria",
            "Usanov Nikolay",
            "Fedorova Alina",
            "Evfratov Sergey",
            "Pushkareva Malvina",
            "Ryangguk Kim",
            "Tacutu Robi"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Genomic data has become increasingly accessible to the general public with\nthe advent of companies offering whole genome sequencing at a relatively low\ncost. However, their reports are not verifiable due to a lack of crucial\ndetails and transparency: polygenic risk scores do not always mention all the\npolymorphisms involved. Simultaneously, tackling the manual investigation and\ninterpretation of data proves challenging for individuals lacking a background\nin genetics. Currently, there is no open-source or commercial solution that\nprovides comprehensive longevity reports surpassing a limited number of\npolymorphisms. Additionally, there are no ready-made, out-of-the-box solutions\navailable that require minimal expertise to generate reports independently. To\naddress these issues, we have developed the Just-DNA-Seq open-source genomic\nplatform. Just-DNA-Seq aims to provide a user-friendly solution to genome\nannotation by allowing users to upload their own VCF files and receive\nannotations of their genetic variants and polygenic risk scores related to\nlongevity. We also created GeneticsGenie custom GPT that can answer genetics\nquestions based on our modules. With the Just-DNA-Seq platform, we want to\nprovide full information regarding the genetics of long life:\ndisease-predisposing variants, that can reduce lifespan and manifest at\ndifferent age (cardiovascular, oncological, neurodegenerative diseases, etc.),\npro-longevity variants and longevity drug pharmacokinetics. In this research\narticle, we will discuss the features and capabilities of Just-DNA-Seq, and how\nit can benefit individuals looking to understand and improve their health. It's\ncrucial to note that the Just-DNA-Seq platform is exclusively intended for\nscientific and informational purposes and is not suitable for medical\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.19087v1"
    },
    {
        "title": "Navigating Eukaryotic Genome Annotation Pipelines: A Route Map to\n  BRAKER, Galba, and TSEBRA",
        "authors": [
            "Tomáš Brůna",
            "Lars Gabriel",
            "Katharina J. Hoff"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Annotating the structure of protein-coding genes represents a major challenge\nin the analysis of eukaryotic genomes. This task sets the groundwork for\nsubsequent genomic studies aimed at understanding the functions of individual\ngenes. BRAKER and Galba are two fully automated and containerized pipelines\ndesigned to perform accurate genome annotation. BRAKER integrates the\nGeneMark-ETP and AUGUSTUS gene finders, employing the TSEBRA combiner to attain\nhigh sensitivity and precision. BRAKER is adept at handling genomes of any\nsize, provided that it has access to both transcript expression sequencing data\nand an extensive protein database from the target clade. In particular, BRAKER\ndemonstrates high accuracy even with only one type of these extrinsic evidence\nsources, although it should be noted that accuracy diminishes for larger\ngenomes under such conditions. In contrast, Galba adopts a distinct methodology\nutilizing the outcomes of direct protein-to-genome spliced alignments using\nminiprot to generate training genes and evidence for gene prediction in\nAUGUSTUS. Galba has superior accuracy in large genomes if protein sequences are\nthe only source of evidence. This chapter provides practical guidelines for\nemploying both pipelines in the annotation of eukaryotic genomes, with a focus\non insect genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.19416v1"
    },
    {
        "title": "Guide to k-mer approaches for genomics across the tree of life",
        "authors": [
            "Katharine M. Jenike",
            "Lucía Campos-Domínguez",
            "Marilou Boddé",
            "José Cerca",
            "Christina N. Hodson",
            "Michael C. Schatz",
            "Kamil S. Jaron"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The wide array of currently available genomes display a wonderful diversity\nin size, composition and structure with many more to come thanks to several\nglobal biodiversity genomics initiatives starting in recent years. However,\nsequencing of genomes, even with all the recent advances, can still be\nchallenging for both technical (e.g. small physical size, contaminated samples,\nor access to appropriate sequencing platforms) and biological reasons (e.g.\ngermline restricted DNA, variable ploidy levels, sex chromosomes, or very large\ngenomes). In recent years, k-mer-based techniques have become popular to\novercome some of these challenges. They are based on the simple process of\ndividing the analysed sequences (e.g. raw reads or genomes) into a set of\nsub-sequences of length k, called k-mers. Despite this apparent simplicity,\nk-mer-based analysis allows for a rapid and intuitive assessment of complex\nsequencing datasets. Here, we provide the first comprehensive review to the\ntheoretical properties and practical applications of k-mers in biodiversity\ngenomics, serving as a reference manual for this powerful approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01519v1"
    },
    {
        "title": "A Systematic Overview of Single-Cell Transcriptomics Databases, their\n  Use cases, and Limitations",
        "authors": [
            "Mahnoor N. Gondal",
            "Saad Ur Rehman Shah",
            "Arul M. Chinnaiyan",
            "Marcin Cieslik"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Rapid advancements in high-throughput single-cell RNA-seq (scRNA-seq)\ntechnologies and experimental protocols have led to the generation of vast\namounts of genomic data that populates several online databases and\nrepositories. Here, we systematically examined large-scale scRNA-seq databases,\ncategorizing them based on their scope and purpose such as general,\ntissue-specific databases, disease-specific databases, cancer-focused\ndatabases, and cell type-focused databases. Next, we discuss the technical and\nmethodological challenges associated with curating large-scale scRNA-seq\ndatabases, along with current computational solutions. We argue that\nunderstanding scRNA-seq databases, including their limitations and assumptions,\nis crucial for effectively utilizing this data to make robust discoveries and\nidentify novel biological insights. Furthermore, we propose that bridging the\ngap between computational and wet lab scientists through user-friendly\nweb-based platforms is needed for democratizing access to single-cell data.\nThese platforms would facilitate interdisciplinary research, enabling\nresearchers from various disciplines to collaborate effectively. This review\nunderscores the importance of leveraging computational approaches to unravel\nthe complexities of single-cell data and offers a promising direction for\nfuture research in the field.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.10545v1"
    },
    {
        "title": "Heterogeneity analysis provides evidence for a genetically homogeneous\n  subtype of bipolar-disorder",
        "authors": [
            "Caroline C. McGrouther",
            "Aaditya V. Rangan",
            "Arianna Di Florio",
            "Jeremy A. Elman",
            "Nicholas J. Schork",
            "John Kelsoe"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Bipolar Disorder (BD) is a complex disease. It is heterogeneous, both at the\nphenotypic and genetic level, although the extent and impact of this\nheterogeneity is not fully understood. In this paper, we leverage recent\nadvances in heterogeneity analysis to look for genetically-driven subgroups\n(i.e., biclusters) within the broad phenotype of Bipolar Disorder. We first\napply this covariate-corrected biclustering algorithm to a cohort of 2524 BD\ncases and 4106 controls from the Bipolar Disease Research Network (BDRN) within\nthe Psychiatric Genomics Consortium (PGC). We find evidence of genetic\nheterogeneity delineating a statistically significant bicluster comprising a\nsubset of BD cases which exhibits a disease-specific pattern of\ndifferential-expression across a subset of SNPs. This disease-specific genetic\npattern (i.e., 'genetic subgroup') replicates across the remaining data-sets\ncollected by the PGC containing 5781/8289, 3581/7591, and 6825/9752\ncases/controls, respectively. This genetic subgroup (discovered without using\nany BD subtype information) was more prevalent in Bipolar type-I than in\nBipolar type-II. Our methodology has successfully identified a replicable\nhomogeneous genetic subgroup of bipolar disorder. This subgroup may represent a\ncollection of correlated genetic risk-factors for BDI. By investigating the\nsubgroup's bicluster-informed polygenic-risk-scoring (PRS), we find that the\ndisease-specific pattern highlighted by the bicluster can be leveraged to\neliminate noise from our GWAS analyses and improve risk prediction. This\nimprovement is particularly notable when using only a relatively small subset\nof the available SNPs, implying improved SNP replication. Though our primary\nfocus is only the analysis of disease-related signal, we also identify\nreplicable control-related heterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.00159v2"
    },
    {
        "title": "The Canadian VirusSeq Data Portal & Duotang: open resources for\n  SARS-CoV-2 viral sequences and genomic epidemiology",
        "authors": [
            "Erin E. Gill",
            "Baofeng Jia",
            "Carmen Lia Murall",
            "Raphaël Poujol",
            "Muhammad Zohaib Anwar",
            "Nithu Sara John",
            "Justin Richardsson",
            "Ashley Hobb",
            "Abayomi S. Olabode",
            "Alexandru Lepsa",
            "Ana T. Duggan",
            "Andrea D. Tyler",
            "Arnaud N'Guessan",
            "Atul Kachru",
            "Brandon Chan",
            "Catherine Yoshida",
            "Christina K. Yung",
            "David Bujold",
            "Dusan Andric",
            "Edmund Su",
            "Emma J. Griffiths",
            "Gary Van Domselaar",
            "Gordon W. Jolly",
            "Heather K. E. Ward",
            "Henrich Feher",
            "Jared Baker",
            "Jared T. Simpson",
            "Jaser Uddin",
            "Jiannis Ragoussis",
            "Jon Eubank",
            "Jörg H. Fritz",
            "José Héctor Gálvez",
            "Karen Fang",
            "Kim Cullion",
            "Leonardo Rivera",
            "Linda Xiang",
            "Matthew A. Croxen",
            "Mitchell Shiell",
            "Natalie Prystajecky",
            "Pierre-Olivier Quirion",
            "Rosita Bajari",
            "Samantha Rich",
            "Samira Mubareka",
            "Sandrine Moreira",
            "Scott Cain",
            "Steven G. Sutcliffe",
            "Susanne A. Kraemer",
            "Yann Joly",
            "Yelizar Alturmessov",
            "CPHLN consortium",
            "CanCOGeN consortium",
            "VirusSeq Data Portal Academic",
            "Health network",
            "Marc Fiume",
            "Terrance P. Snutch",
            "Cindy Bell",
            "Catalina Lopez-Correa",
            "Julie G. Hussin",
            "Jeffrey B. Joy",
            "Caroline Colijn",
            "Paul M. K. Gordon",
            "William W. L. Hsiao",
            "Art F. Y. Poon",
            "Natalie C. Knox",
            "Mélanie Courtot",
            "Lincoln Stein",
            "Sarah P. Otto",
            "Guillaume Bourque",
            "B. Jesse Shapiro",
            "Fiona S. L. Brinkman"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The COVID-19 pandemic led to a large global effort to sequence SARS-CoV-2\ngenomes from patient samples to track viral evolution and inform public health\nresponse. Millions of SARS-CoV-2 genome sequences have been deposited in global\npublic repositories. The Canadian COVID-19 Genomics Network (CanCOGeN -\nVirusSeq), a consortium tasked with coordinating expanded sequencing of\nSARS-CoV-2 genomes across Canada early in the pandemic, created the Canadian\nVirusSeq Data Portal, with associated data pipelines and procedures, to support\nthese efforts. The goal of VirusSeq was to allow open access to Canadian\nSARS-CoV-2 genomic sequences and enhanced, standardized contextual data that\nwere unavailable in other repositories and that meet FAIR standards (Findable,\nAccessible, Interoperable and Reusable). The Portal data submission pipeline\ncontains data quality checking procedures and appropriate acknowledgement of\ndata generators that encourages collaboration. Here we also highlight Duotang,\na web platform that presents genomic epidemiology and modeling analyses on\ncirculating and emerging SARS-CoV-2 variants in Canada. Duotang presents\ndynamic changes in variant composition of SARS-CoV-2 in Canada and by province,\nestimates variant growth, and displays complementary interactive\nvisualizations, with a text overview of the current situation. The VirusSeq\nData Portal and Duotang resources, alongside additional analyses and resources\ncomputed from the Portal (COVID-MVP, CoVizu), are all open-source and freely\navailable. Together, they provide an updated picture of SARS-CoV-2 evolution to\nspur scientific discussions, inform public discourse, and support communication\nwith and within public health authorities. They also serve as a framework for\nother jurisdictions interested in open, collaborative sequence data sharing and\nanalyses.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04734v1"
    },
    {
        "title": "Characterizing virulence differences in a parasitoid wasp through\n  comparative transcriptomic and proteomic",
        "authors": [
            "Samuel Gornard",
            "Pascaline Venon",
            "Florian Lasfont",
            "Thierry Balliau",
            "Laure Marie-Paule Kaiser-Arnauld",
            "Florence Mougel"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Background: Two strains of the endoparasitoid Cotesia typhae present a\ndifferential parasitism success on the host, Sesamia nonagrioides. One is\nvirulent on both permissive and resistant host populations, and the other only\non the permissive host. This interaction provides a very interesting frame for\nstudying virulence factors. Here, we used a combination of comparative\ntranscriptomic and proteomic analyses to unravel the molecular basis underlying\nvirulence differences between the strains.Results: First, we report that\nvirulence genes are mostly expressed during the nymphal stage of the\nparasitoid. Especially, proviral genes are broadly up-regulated at this stage,\nwhile their expression is only expected in the host. Parasitoid gene expression\nin the host increases with time, indicating the production of more virulence\nfactors. Secondly, comparison between strains reveals differences in venom\ncomposition, with 12 proteins showing differential abundance. Proviral\nexpression in the host displays a strong temporal variability, along with\ndifferential patterns between strains. Notably, a subset of proviral genes\nincluding protein-tyrosine phosphatases is specifically over-expressed in the\nresistant host parasitized by the less virulent strain, 24 hours after\nparasitism. This result particularly hints at host modulation of proviral\nexpression.Conclusions: This study sheds light on the temporal expression of\nvirulence factors of Cotesia typhae, both in the host and in the parasitoid. It\nalso identifies potential molecular candidates driving differences in\nparasitism success between two strains. Together, those findings provide a path\nfor further exploration of virulence mechanisms in parasitoid wasps, and offer\ninsights into host-parasitoid coevolution.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.07772v1"
    },
    {
        "title": "Accurate and efficient protein embedding using multi-teacher\n  distillation learning",
        "authors": [
            "Jiayu Shang",
            "Cheng Peng",
            "Yongxin Ji",
            "Jiaojiao Guan",
            "Dehan Cai",
            "Xubo Tang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Motivation: Protein embedding, which represents proteins as numerical\nvectors, is a crucial step in various learning-based protein\nannotation/classification problems, including gene ontology prediction,\nprotein-protein interaction prediction, and protein structure prediction.\nHowever, existing protein embedding methods are often computationally expensive\ndue to their large number of parameters, which can reach millions or even\nbillions. The growing availability of large-scale protein datasets and the need\nfor efficient analysis tools have created a pressing demand for efficient\nprotein embedding methods.\n  Results: We propose a novel protein embedding approach based on multi-teacher\ndistillation learning, which leverages the knowledge of multiple pre-trained\nprotein embedding models to learn a compact and informative representation of\nproteins. Our method achieves comparable performance to state-of-the-art\nmethods while significantly reducing computational costs and resource\nrequirements. Specifically, our approach reduces computational time by ~70\\%\nand maintains almost the same accuracy as the original large models. This makes\nour method well-suited for large-scale protein analysis and enables the\nbioinformatics community to perform protein embedding tasks more efficiently.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11735v1"
    },
    {
        "title": "Range-Limited Heaps' Law for Functional DNA Words in the Human Genome",
        "authors": [
            "Wentian Li",
            "Yannis Almirantis",
            "Astero Provata"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Heaps' or Herdan's law is a linguistic law describing the relationship\nbetween the vocabulary/dictionary size (type) and word counts (token) to be a\npower-law function. Its existence in genomes with certain definition of DNA\nwords is unclear partly because the dictionary size in genome could be much\nsmaller than that in a human language. We define a DNA word as a coding region\nin a genome that codes for a protein domain. Using human chromosomes and\nchromosome arms as individual samples, we establish the existence of Heaps' law\nin the human genome within limited range. Our definition of words in a genomic\nor proteomic context is different from other definitions such as\nover-represented k-mers which are much shorter in length. Although an\napproximate power-law distribution of protein domain sizes due to gene\nduplication and the related Zipf's law is well known, their translation to the\nHeaps' law in DNA words is not automatic. Several other animal genomes are\nshown herein also to exhibit range-limited Heaps' law with our definition of\nDNA words, though with various exponents. When tokens were randomly sampled and\nsample sizes reach to the maximum level, a deviation from the Heaps' law was\nobserved, but a quadratic regression in log-log type-token plot fits the data\nperfectly. Investigation of type-token plot and its regression coefficients\ncould provide an alternative narrative of reusage and redundancy of protein\ndomains as well as creation of new protein domains from a linguistic\nperspective.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.13825v2"
    },
    {
        "title": "Metadata-guided Feature Disentanglement for Functional Genomics",
        "authors": [
            "Alexander Rakowski",
            "Remo Monti",
            "Viktoriia Huryn",
            "Marta Lemanczyk",
            "Uwe Ohler",
            "Christoph Lippert"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  With the development of high-throughput technologies, genomics datasets\nrapidly grow in size, including functional genomics data. This has allowed the\ntraining of large Deep Learning (DL) models to predict epigenetic readouts,\nsuch as protein binding or histone modifications, from genome sequences.\nHowever, large dataset sizes come at a price of data consistency, often\naggregating results from a large number of studies, conducted under varying\nexperimental conditions. While data from large-scale consortia are useful as\nthey allow studying the effects of different biological conditions, they can\nalso contain unwanted biases from confounding experimental factors. Here, we\nintroduce Metadata-guided Feature Disentanglement (MFD) - an approach that\nallows disentangling biologically relevant features from potential technical\nbiases. MFD incorporates target metadata into model training, by conditioning\nweights of the model output layer on different experimental factors. It then\nseparates the factors into disjoint groups and enforces independence of the\ncorresponding feature subspaces with an adversarially learned penalty. We show\nthat the metadata-driven disentanglement approach allows for better model\nintrospection, by connecting latent features to experimental factors, without\ncompromising, or even improving performance in downstream tasks, such as\nenhancer prediction, or genetic variant discovery. The code for our\nimplemementation is available at https://github.com/HealthML/MFD\n",
        "pdf_link": "http://arxiv.org/pdf/2405.19057v1"
    },
    {
        "title": "pVACview: an interactive visualization tool for efficient neoantigen\n  prioritization and selection",
        "authors": [
            "Huiming Xia",
            "My Hoang",
            "Evelyn Schmidt",
            "Susanna Kiwala",
            "Joshua McMichael",
            "Zachary L. Skidmore",
            "Bryan Fisk",
            "Jonathan J. Song",
            "Jasreet Hundal",
            "Thomas Mooney",
            "Jason R. Walker",
            "S. Peter Goedegebuure",
            "Christopher A. Miller",
            "William E. Gillanders",
            "Obi L. Griffith",
            "Malachi Griffith"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Neoantigen targeting therapies including personalized vaccines have shown\npromise in the treatment of cancers. Accurate identification/prioritization of\nneoantigens is highly relevant to designing clinical trials, predicting\ntreatment response, and understanding mechanisms of resistance. With the advent\nof massively parallel sequencing technologies, it is now possible to predict\nneoantigens based on patient-specific variant information. However, numerous\nfactors must be considered when prioritizing neoantigens for use in\npersonalized therapies. Complexities such as alternative transcript\nannotations, various binding, presentation and immunogenicity prediction\nalgorithms, and variable peptide lengths/registers all potentially impact the\nneoantigen selection process. While computational tools generate numerous\nalgorithmic predictions for neoantigen characterization, results from these\npipelines are difficult to navigate and require extensive knowledge of the\nunderlying tools for accurate interpretation. Due to the intricate nature and\nnumber of salient neoantigen features, presenting all relevant information to\nfacilitate candidate selection for downstream applications is a difficult\nchallenge that current tools fail to address. We have created pVACview, the\nfirst interactive tool designed to aid in the prioritization and selection of\nneoantigen candidates for personalized neoantigen therapies. pVACview has a\nuser-friendly and intuitive interface where users can upload, explore, select\nand export their neoantigen candidates. The tool allows users to visualize\ncandidates using variant, transcript and peptide information. pVACview will\nallow researchers to analyze and prioritize neoantigen candidates with greater\nefficiency and accuracy in basic and translational settings. The application is\navailable as part of the pVACtools pipeline at pvactools.org and as an online\nserver at pvacview.org.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.06985v1"
    },
    {
        "title": "skandiver: a divergence-based analysis tool for identifying\n  intercellular mobile genetic elements",
        "authors": [
            "Xiaolei Brian Zhang",
            "Grace Oualline",
            "Jim Shaw",
            "Yun William Yu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Mobile genetic elements (MGEs) are as ubiquitous in nature as they are varied\nin type, ranging from viral insertions to transposons to incorporated plasmids.\nHorizontal transfer of MGEs across bacterial species may also pose a\nsignificant threat to global health due to their capability to harbour\nantibiotic resistance genes. However, despite cheap and rapid whole genome\nsequencing, the varied nature of MGEs makes it difficult to fully characterize\nthem, and existing methods for detecting MGEs often don't agree on what should\ncount. In this manuscript, we first define and argue in favor of a\ndivergence-based characterization of mobile-genetic elements. Using that\nparadigm, we present skandiver, a tool designed to efficiently detect MGEs from\nwhole genome assemblies without the need for gene annotation or markers.\nskandiver determines mobile elements via genome fragmentation, average\nnucleotide identity (ANI), and divergence time. By building on the scalable\nskani software for ANI computation, skandiver can query hundreds of complete\nassemblies against $>$65,000 representative genomes in a few minutes and 19 GB\nmemory, providing scalable and efficient method for elucidating mobile element\nprofiles in incomplete, uncharacterized genomic sequences. For isolated and\nintegrated large plasmids (>10kbp), skandiver's recall was 48\\% and 47\\%,\nMobileElementFinder was 59\\% and 17\\%, and geNomad was 86\\% and 32\\%,\nrespectively. For isolated large plasmids, skandiver's recall (48\\%) is lower\nthan state-of-the-art reference-based methods geNomad (86\\%) and\nMobileElementFinder (59\\%). However, skandiver achieves higher recall on\nintegrated plasmids and, unlike other methods, without comparing against a\ncurated database, making skandiver suitable for discovery of novel MGEs.\n  Availability: https://github.com/YoukaiFromAccounting/skandiver\n",
        "pdf_link": "http://arxiv.org/pdf/2406.12064v1"
    },
    {
        "title": "A mapping-free NLP-based technique for sequence search in Nanopore\n  long-reads",
        "authors": [
            "Tomasz Strzoda",
            "Lourdes Cruz-Garcia",
            "Mustafa Najim",
            "Christophe Badie",
            "Joanna Polanska"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  In unforeseen situations, such as nuclear power plant's or civilian radiation\naccidents, there is a need for effective and computationally inexpensive\nmethods to determine the expression level of a selected gene panel, allowing\nfor rough dose estimates in thousands of donors. The new generation in-situ\nmapper, fast and of low energy consumption, working at the level of single\nnanopore output, is in demand. We aim to create a sequence identification tool\nthat utilizes Natural Language Processing (NLP) techniques and ensures a high\nlevel of negative predictive value (NPV) compared to the classical approach.\nThe training dataset consisted of RNASeq data from 6 samples. Having tested\nmultiple NLP models, the best configuration analyses the entire sequence and\nuses a word length of 3 base pairs with one-word neighbor on each side. For the\nconsidered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and\nNPV 99.25%, compared to minimap2's performance in a cross-validation scenario.\nReducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to\n98.15%. Obtained NLP model, validated on an external independent genome\nsequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced\ndictionary. The salmon-estimated read counts differed from the classical\napproach on average by 3.48% for the complete dictionary and by 5.82% for the\nreduced one. We conclude that for long Oxford Nanopore reads, an NLP-based\napproach can successfully replace classical mapping in case of emergency. The\ndeveloped NLP model can be easily retrained to identify selected transcripts\nand/or work with various long-read sequencing techniques. Our results of the\nstudy clearly demonstrate the potential of applying techniques known from\nclassical text processing to nucleotide sequences and represent a significant\nadvancement in this field of science.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14187v1"
    },
    {
        "title": "Metagenomic analysis revealed significant changes in cattle rectum\n  microbiome and antimicrobial resistome under fescue toxicosis",
        "authors": [
            "Yihang Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Fescue toxicity causes reduced growth and reproductive issues in cattle\ngrazing endophyte-infected tall fescue. To characterize the gut microbiota and\nits response to fescue toxicosis, we collected fecal samples before and after a\n30-days toxic fescue seeds supplementation from eight Angus Simmental pregnant\ncows and heifers. We sequenced the 16 metagenomes using the whole-genome\nshotgun approach and generated 157 Gbp of metagenomic sequences. Through de\nnovo assembly and annotation, we obtained a 13.1 Gbp reference contig assembly\nand identified 22 million microbial genes for cattle rectum microbiota. We\ndiscovered a significant reduction of microbial diversity after toxic seed\ntreatment (P<0.01), suggesting dysbiosis of the microbiome. Six bacterial\nfamilies and 31 species are significantly increased in the fecal microbiota\n(P-adj<0.05), including members of the top abundant rumen core taxa. This\nglobal elevation of rumen microbes in the rectum microbiota suggests a\npotential impairment of rumen microbiota under fescue toxicosis. Among these,\nRuminococcaceae bacterium P7, an important species accounting for ~2% of rumen\nmicrobiota, was the most impacted with a 16-fold increase from 0.17% to 2.8% in\nfeces (P<0.01). We hypothesized that rumen Ruminococcaceae bacterium P7\nre-adapted to the large intestine environment under toxic fescue stress,\ncausing this dramatic increase in abundance. Functional enrichment analysis\nrevealed that the overrepresented pathways shifted from energy metabolism to\nantimicrobial resistance and DNA replication. In conclusion, we discovered\ndramatic microbiota alterations in composition, abundance, and functional\ncapacities under fescue toxicosis, and our results suggest Ruminococcaceae\nbacterium P7 as a potential biomarker for fescue toxicosis management.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.05055v1"
    },
    {
        "title": "Metagenomic analysis reveals shared and distinguishing features in horse\n  and donkey gut microbiome and maternal resemblance of the microbiota in\n  hybrid equids",
        "authors": [
            "Yihang Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Mammalian gut microbiomes are essential for host functions like digestion,\nimmunity, and nutrient utilization. This study examines the gut microbiome of\nhorses, donkeys, and their hybrids, mules and hinnies, to explore the role of\nmicrobiomes in hybrid vigor. We performed whole-genome sequencing on rectal\nmicrobiota from 18 equids, generating detailed microbiome assemblies. Our\nanalysis revealed significant differences between horse and donkey microbiomes,\nwith hybrids showing a pronounced maternal resemblance. Notably, Firmicutes\nwere more abundant in the horse-maternal group, while Fibrobacteres were richer\nin the donkey-maternal group, indicating distinct digestive processes.\nFunctional annotations indicated metabolic differences, such as protein\nsynthesis in horses and energy metabolism in donkeys. Machine learning\npredictions of probiotic species highlighted potential health benefits for each\nmaternal group. This study provides a high-resolution view of the equid gut\nmicrobiome, revealing significant taxonomic and metabolic differences\ninfluenced by maternal lineage, and offers insights into microbial\ncontributions to hybrid vigor.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.05076v1"
    },
    {
        "title": "PyamilySeq: A Python Tool for Interpretable Gene (Re)Clustering and\n  Pangenomic Inference Across Species and Genera",
        "authors": [
            "Nicholas J. Dimonaco"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  PyamilySeq is a Python-based tool designed for interpretable gene clustering\nand pangenomic inference, supporting analyses at both species and genus levels.\nIt facilitates the clustering of gene sequences into families based on sequence\nsimilarity using CD-HIT, and can take the output of tried-and-tested sequence\nclustering tools such as CD-HIT, BLAST, DIAMOND, and MMseqs2. PyamilySeq is\ndistinctive in its ability to integrate new sequences into existing clusters,\nproviding a robust framework for iterative analysis while preserving the\noriginal clusters, useful when reannotating genomes. In addition to the\nstandard Species mode which as with other tools performs core-gene analysis\nacross a species range, PyamilySeq can be run in Genus mode where it detects\nthe presence of gene families shared across multiple genera. These features\nenhance the tools applicability for ongoing and past genomic studies and\ncomparative analyses. PyamilySeq generates comprehensive outputs, including\ngene presence-absence matrices and aligned sequence data, enabling downstream\nanalysis and interpretation of the identified gene groups and pangenomic data.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19328v1"
    },
    {
        "title": "Are gene-by-environment interactions leveraged in multi-modality neural\n  networks for breast cancer prediction?",
        "authors": [
            "Monica Isgut",
            "Andrew Hornback",
            "Yunan Luo",
            "Asma Khimani",
            "Neha Jain",
            "May D. Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Polygenic risk scores (PRSs) can significantly enhance breast cancer risk\nprediction when combined with clinical risk factor data. While many studies\nhave explored the value-add of PRSs, little is known about the potential impact\nof gene-by-gene or gene-by-environment interactions towards enhancing the risk\ndiscrimination capabilities of multi-modal models combining PRSs with clinical\ndata. In this study, we integrated data on 318 individual genotype variants\nalong with clinical data in a neural network to explore whether gene-by-gene\n(i.e., between individual variants) and/or gene-by-environment (between\nclinical risk factors and variants) interactions could be leveraged jointly\nduring training to improve breast cancer risk prediction performance. We\nbenchmarked our approach against a baseline model combining traditional\nunivariate PRSs with clinical data in a logistic regression model and ran an\ninterpretability analysis to identify feature interactions.\n  While our model did not demonstrate improved performance over the baseline,\nwe discovered 248 (<1%) statistically significant gene-by-gene and\ngene-by-environment interactions out of the ~53.6k possible feature pairs, the\nmost contributory of which included rs6001930 (MKL1) and rs889312 (MAP3K1),\nwith age and menopause being the most heavily interacting non-genetic risk\nfactors. We also modeled the significant interactions as a network of highly\nconnected features, suggesting that potential higher-order interactions are\ncaptured by the model. Although gene-by-environment (or gene-by-gene)\ninteractions did not enhance breast cancer risk prediction performance in\nneural networks, our study provides evidence that these interactions can be\nleveraged by these models to inform their predictions. This study represents\nthe first application of neural networks to screen for interactions impacting\nbreast cancer risk using real-world data.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.20978v1"
    },
    {
        "title": "Integrating spatially-resolved transcriptomics data across tissues and\n  individuals: challenges and opportunities",
        "authors": [
            "Boyi Guo",
            "Wodan Ling",
            "Sang Ho Kwon",
            "Pratibha Panwar",
            "Shila Ghazanfar",
            "Keri Martinowich",
            "Stephanie C. Hicks"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Advances in spatially-resolved transcriptomics (SRT) technologies have\npropelled the development of new computational analysis methods to unlock\nbiological insights. As the cost of generating these data decreases, these\ntechnologies provide an exciting opportunity to create large-scale atlases that\nintegrate SRT data across multiple tissues, individuals, species, or phenotypes\nto perform population-level analyses. Here, we describe unique challenges of\nvarying spatial resolutions in SRT data, as well as highlight the opportunities\nfor standardized preprocessing methods along with computational algorithms\namenable to atlas-scale datasets leading to improved sensitivity and\nreproducibility in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.00367v1"
    },
    {
        "title": "Refinement of genetic variants needs attention",
        "authors": [
            "Omar Abdelwahab",
            "Davoud Torkamaneh"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Variant calling refinement is crucial for distinguishing true genetic\nvariants from technical artifacts in high-throughput sequencing data. Manual\nreview is time-consuming while heuristic filtering often lacks optimal\nsolutions. Traditional variant calling methods often struggle with accuracy,\nespecially in regions of low read coverage, leading to false-positive or\nfalse-negative calls. Here, we introduce VariantTransformer, a\nTransformer-based deep learning model, designed to automate variant calling\nrefinement directly from VCF files in low-coverage data (10-15X).\nVariantTransformer, trained on two million variants, including SNPs and short\nInDels, from low-coverage sequencing data, achieved an accuracy of 89.26% and a\nROC AUC of 0.88. When integrated into conventional variant calling pipelines,\nVariantTransformer outperformed traditional heuristic filters and approached\nthe performance of state-of-the-art AI-based variant callers like DeepVariant.\nComparative analysis demonstrated VariantTransformer's superiority in\nfunctionality, variant type coverage, training size, and input data type.\nVariantTransformer represents a significant advancement in variant calling\nrefinement for low-coverage genomic studies.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.00659v1"
    },
    {
        "title": "Insights, opportunities and challenges provided by large cell atlases",
        "authors": [
            "Martin Hemberg",
            "Federico Marini",
            "Shila Ghazanfar",
            "Ahmad Al Ajami",
            "Najla Abassi",
            "Benedict Anchang",
            "Bérénice A. Benayoun",
            "Yue Cao",
            "Ken Chen",
            "Yesid Cuesta-Astroz",
            "Zach DeBruine",
            "Calliope A. Dendrou",
            "Iwijn De Vlaminck",
            "Katharina Imkeller",
            "Ilya Korsunsky",
            "Alex R. Lederer",
            "Pieter Meysman",
            "Clint Miller",
            "Kerry Mullan",
            "Uwe Ohler",
            "Nikolaos Patikas",
            "Jonas Schuck",
            "Jacqueline HY Siu",
            "Timothy J. Triche Jr.",
            "Alex Tsankov",
            "Sander W. van der Laan",
            "Masanao Yajima",
            "Jean Yang",
            "Fabio Zanini",
            "Ivana Jelic"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The field of single-cell biology is growing rapidly and is generating large\namounts of data from a variety of species, disease conditions, tissues, and\norgans. Coordinated efforts such as CZI CELLxGENE, HuBMAP, Broad Institute\nSingle Cell Portal, and DISCO, allow researchers to access large volumes of\ncurated datasets. Although the majority of the data is from scRNAseq\nexperiments, a wide range of other modalities are represented as well. These\nresources have created an opportunity to build and expand the computational\nbiology ecosystem to develop tools necessary for data reuse, and for extracting\nnovel biological insights. Here, we highlight achievements made so far, areas\nwhere further development is needed, and specific challenges that need to be\novercome.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.06563v1"
    },
    {
        "title": "Comparison of algorithms used in single-cell transcriptomic data\n  analysis",
        "authors": [
            "Jafar Isbarov",
            "Elmir Mahammadov"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Single-cell analysis is an increasingly relevant approach in \"omics''\nstudies. In the last decade, it has been applied to various fields, including\ncancer biology, neuroscience, and, especially, developmental biology. This rise\nin popularity has been accompanied with creation of modern software,\ndevelopment of new pipelines and design of new algorithms. Many established\nalgorithms have also been applied with varying levels of effectiveness.\nCurrently, there is an abundance of algorithms for all steps of the general\nworkflow. While some scientists use ready-made pipelines (such as Seurat),\nmanual analysis is popular, too, as it allows more flexibility. Scientists who\nperform their own analysis face multiple options when it comes to the choice of\nalgorithms. We have used two different datasets to test some of the most\nwidely-used algorithms. In this paper, we are going to report the main\ndifferences between them, suggest a minimal number of algorithms for each step,\nand explain our suggestions. In certain stages, it is impossible to make a\nclear choice without further context. In these cases, we are going to explore\nthe major possibilities, and make suggestions for each one of them.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.12031v1"
    },
    {
        "title": "Superimposed Hi-C: A Solution Proposed for Identifying Single Cell's\n  Chromosomal Interactions",
        "authors": [
            "Jia Zhang",
            "Li Xiao",
            "Peng Qi",
            "Yaling Zeng",
            "Xumeng Chen",
            "Duan-fang Liao",
            "Kai Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Hi-C sequencing is widely used for analyzing chromosomal interactions. In\nthis study, we propose \"superimposed Hi-C\" which features paired EcoP15I sites\nin a linker to facilitate sticky-end ligation with target DNAs. Superimposed\nHi-C overcomes Hi-C's technical limitations, enabling the identification of\nsingle cell's chromosomal interactions.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.13039v1"
    },
    {
        "title": "HEK-Omics: The promise of omics to optimize HEK293 for recombinant\n  adeno-associated virus (rAAV) gene therapy manufacturing",
        "authors": [
            "Sai Guna Ranjan Gurazada",
            "Hannah M. Kennedy",
            "Richard D. Braatz",
            "Steven J. Mehrman",
            "Shawn W. Polson",
            "Irene T. Rombel"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Gene therapy is poised to transition from niche to mainstream medicine, with\nrecombinant adeno-associated virus (rAAV) as the vector of choice. However,\nthis requires robust, scalable, industrialized production to meet demand and\nprovide affordable patient access, which has thus far failed to materialize.\nClosing the chasm between demand and supply requires innovation in\nbiomanufacturing to achieve the essential step change in rAAV product yield and\nquality. Omics provides a rich source of mechanistic knowledge that can be\napplied to HEK293, the prevailing cell line for rAAV production. In this\nreview, the findings from a growing number of disparate studies that apply\ngenomics, epigenomics, transcriptomics, proteomics, and metabolomics to HEK293\nbioproduction are explored. Learnings from CHO-Omics, application of omics\napproaches to improve CHO bioproduction, provide context for the potential of\n\"HEK-Omics\" as a multiomics-informed approach providing actionable mechanistic\ninsights for improved transient and stable production of rAAV and other\nrecombinant products in HEK293.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.13374v1"
    },
    {
        "title": "BWT construction and search at the terabase scale",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Motivation: Burrows-Wheeler Transform (BWT) is a common component in\nfull-text indices. Initially developed for data compression, it is particularly\npowerful for encoding redundant sequences such as pangenome data. However, BWT\nconstruction is resource intensive and hard to be parallelized, and many\nmethods for querying large full-text indices only report exact matches or their\nsimple extensions. These limitations have hampered the biological applications\nof full-text indices.\n  Results: We developed ropebwt3 for efficient BWT construction and query.\nRopebwt3 indexed 320 assembled human genomes in 65 hours and indexed 7.3\nterabases of commonly studied bacterial assemblies in 26 days. This was\nachieved using up to 170 gigabytes of memory at the peak without working disk\nspace. Ropebwt3 can find maximal exact matches and inexact alignments under\naffine-gap penalties, and can retrieve similar local haplotypes matching a\nquery sequence. It demonstrates the feasibility of full-text indexing at the\nterabase scale.\n  Availability and implementation: https://github.com/lh3/ropebwt3\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00613v2"
    },
    {
        "title": "Advances in practical k-mer sets: essentials for the curious",
        "authors": [
            "Camille Marchet"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This paper provides a comprehensive survey of data structures for\nrepresenting k-mer sets, which are fundamental in high-throughput sequencing\nanalysis. It categorizes the methods into two main strategies: those using\nfingerprinting and hashing for compact storage, and those leveraging\nlexicographic properties for efficient representation. The paper reviews key\noperations supported by these structures, such as membership queries and\ndynamic updates, and highlights recent advancements in memory efficiency and\nquery speed. A companion paper explores colored k-mer sets, which extend these\nconcepts to integrate multiple datasets or genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05210v2"
    },
    {
        "title": "Advances in colored k-mer sets: essentials for the curious",
        "authors": [
            "Camille Marchet"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This paper provides a comprehensive review of recent advancements in\nk-mer-based data structures representing collections of several samples\n(sometimes called colored de Bruijn graphs) and their applications in\nlarge-scale sequence indexing and pangenomics. The review explores the\nevolution of k-mer set representations, highlighting the trade-offs between\nexact and inexact methods, as well as the integration of compression strategies\nand modular implementations. I discuss the impact of these structures on\npractical applications and describe recent utilization of these methods for\nanalysis. By surveying the state-of-the-art techniques and identifying emerging\ntrends, this work aims to guide researchers in selecting and developing methods\nfor large scale and reference-free genomic data. For a broader overview of\nk-mer set representations and foundational data structures, see the\naccompanying article on practical k-mer sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05214v2"
    },
    {
        "title": "Selecting Differential Splicing Methods: Practical Considerations",
        "authors": [
            "Ben J Draper",
            "Mark J Dunning",
            "David C James"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Alternative splicing is crucial in gene regulation, with significant\nimplications in clinical settings and biotechnology. This review article\ncompiles bioinformatics RNA-seq tools for investigating differential splicing;\noffering a detailed examination of their statistical methods, case\napplications, and benefits. A total of 22 tools are categorised by their\nstatistical family (parametric, non-parametric, and probabilistic) and level of\nanalysis (transcript, exon, and event). The central challenges in quantifying\nalternative splicing include correct splice site identification and accurate\nisoform deconvolution of transcripts. Benchmarking studies show no consensus on\ntool performance, revealing considerable variability across different\nscenarios. Tools with high citation frequency and continued developer\nmaintenance, such as DEXSeq and rMATS, are recommended for prospective\nresearchers. To aid in tool selection, a guide schematic is proposed based on\nvariations in data input and the required level of analysis. Additionally,\nadvancements in long-read RNA sequencing are expected to drive the evolution of\ndifferential splicing tools, reducing the need for isoform deconvolution and\nprompting further innovation.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05458v1"
    },
    {
        "title": "wgatools: an ultrafast toolkit for manipulating whole genome alignments",
        "authors": [
            "Wenjie Wei",
            "Songtao Gui",
            "Jian Yang",
            "Erik Garrison",
            "Jianbing Yan",
            "Hai-Jun Liu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Summary: With the rapid development of long-read sequencing technologies, the\nera of individual complete genomes is approaching. We have developed wgatools,\na cross-platform, ultrafast toolkit that supports a range of whole genome\nalignment (WGA) formats, offering practical tools for conversion, processing,\nstatistical evaluation, and visualization of alignments, thereby facilitating\npopulation-level genome analysis and advancing functional and evolutionary\ngenomics. Availability and Implementation: wgatools supports diverse formats\nand can process, filter, and statistically evaluate alignments, perform\nalignment-based variant calling, and visualize alignments both locally and\ngenome-wide. Built with Rust for efficiency and safe memory usage, it ensures\nfast performance and can handle large datasets consisting of hundreds of\ngenomes. wgatools is published as free software under the MIT open-source\nlicense, and its source code is freely available at\nhttps://github.com/wjwei-handsome/wgatools. Contact: weiwenjie@westlake.edu.cn\n(W.W.) or liuhaijun@yzwlab.cn (H.-J.L.).\n",
        "pdf_link": "http://arxiv.org/pdf/2409.08569v1"
    },
    {
        "title": "Allium Vegetables Intake and Digestive System Cancer Risk: A Study Based\n  on Mendelian Randomization, Network Pharmacology and Molecular Docking",
        "authors": [
            "Shuhao Li",
            "Jingwen Lou",
            "Yelina Mulatihan",
            "Yuhang Xiong",
            "Yao Li",
            "Qi Xu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Background: Allium vegetables (garlic and onion) are one of the flavorings in\npeople's daily diets. Observational studies suggest that intake of allium\nvegetables may be correlated with a lower incidence of digestive system\ncancers. However, the existence of a causal relationship is still controversial\ndue to confounding factors and reverse causation. Therefore, we explored the\ncausal relationship between intake of allium vegetables and digestive system\ncancers using Mendelian randomization approach. Methods: First, we performed\nMendelian randomization analyses using inverse variance weighting (IVW),\nweighted median, and MR-Egger approaches, and demonstrated the reliability of\nthe results in the sensitivity step. Second, Multivariable Mendelian\nrandomization was applied to adjust for smoking and alcohol consumption. Third,\nwe explored the molecular mechanisms behind the positive results through\nnetwork pharmacology and molecular docking methods. Results: The study suggests\nthat increased intake of garlic reduced gastric cancer risk. However, onion\nintake was not statistically associated with digestive system cancer.\nConclusion: Garlic may have a protective effect against gastric cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.11187v1"
    },
    {
        "title": "FlexLMM: a Nextflow linear mixed model framework for GWAS",
        "authors": [
            "Saul Pierotti",
            "Tomas Fitzgerald",
            "Ewan Birney"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Summary: Linear mixed models are a commonly used statistical approach in\ngenome-wide association studies when population structure is present. However,\nnaive permutations to empirically estimate the null distribution of a statistic\nof interest are not appropriate in the presence of population structure,\nbecause the samples are not exchangeable with each other. For this reason we\ndeveloped FlexLMM, a Nextflow pipeline that runs linear mixed models while\nallowing for flexibility in the definition of the exact statistical model to be\nused. FlexLMM can also be used to set a significance threshold via\npermutations, thanks to a two-step process where the population structure is\nfirst regressed out, and only then are the permutations performed. We envision\nthis pipeline will be particularly useful for researchers working on\nmulti-parental crosses among inbred lines of model organisms or farm animals\nand plants.\n  Availability and implementation: The source code and documentation for the\nFlexLMM is available at https://github.com/birneylab/flexlmm.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.01533v1"
    },
    {
        "title": "Annotation of protein-coding genes in 49 diatom genomes from the\n  Bacillariophyta clade",
        "authors": [
            "Natalia Nenasheva",
            "Clara Pitzschel",
            "Cynthia N. Webster",
            "Alex Hart",
            "Jill L. Wegrzyn",
            "Mia M. Bengtsson",
            "Katharina J. Hoff"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Diatoms, a major group of microalgae, play a critical role in global carbon\ncycling and primary production. Despite their ecological significance,\ncomprehensive genomic resources for diatoms are limited. To address this, we\nhave annotated previously unannotated genome assemblies of 49 diatom species.\nGenome assemblies were obtained from NCBI Datasets and processed for repeat\nelements using RepeatModeler2 and RepeatMasker. For gene prediction, BRAKER2\nwas employed in the absence of transcriptomic data, while BRAKER3 was utilized\nwhen transcriptome short read data were available from the Sequence Read\nArchive. The quality of genome assemblies and predicted protein sets was\nevaluated using BUSCO, ensuring high-quality genomic resources. Functional\nannotation was performed using EnTAP, providing insights into the biological\nroles of the predicted proteins. Our study enhances the genomic toolkit\navailable for diatoms, facilitating future research in diatom biology, ecology,\nand evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.05467v2"
    },
    {
        "title": "The Mitochondrial Genome of Cathaya argyrophylla Reaches 18.99 Mb:\n  Analysis of Super-Large Mitochondrial Genomes in Pinaceae",
        "authors": [
            "Kerui Huang",
            "Wenbo Xu",
            "Haoliang Hu",
            "Xiaolong Jiang",
            "Lei Sun",
            "Wenyan Zhao",
            "Binbin Long",
            "Shaogang Fan",
            "Zhibo Zhou",
            "Ping Mo",
            "Xiaocheng Jiang",
            "Jianhong Tian",
            "Aihua Deng",
            "Peng Xie",
            "Yun Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Mitochondrial genomes in the Pinaceae family are notable for their large size\nand structural complexity. In this study, we sequenced and analyzed the\nmitochondrial genome of Cathaya argyrophylla, an endangered and endemic\nPinaceae species, uncovering a genome size of 18.99 Mb, meaning the largest\nmitochondrial genome reported to date. To investigate the mechanisms behind\nthis exceptional size, we conducted comparative analyses with other Pinaceae\nspecies possessing both large and small mitochondrial genomes, as well as with\nother gymnosperms. We focused on repeat sequences, transposable element\nactivity, RNA editing events, chloroplast-derived sequence transfers (mtpts),\nand sequence homology with nuclear genomes. Our findings indicate that while\nCathaya argyrophylla and other extremely large Pinaceae mitochondrial genomes\ncontain substantial amounts of repeat sequences and show increased activity of\nLINEs and LTR retrotransposons, these factors alone do not fully account for\nthe genome expansion. Notably, we observed a significant incorporation of\nchloroplast-derived sequences in Cathaya argyrophylla and other large\nmitochondrial genomes, suggesting that extensive plastid-to-mitochondrial DNA\ntransfer may play a crucial role in genome enlargement. Additionally, large\nmitochondrial genomes exhibited distinct patterns of RNA editing and limited\nsimilarity with nuclear genomes compared to smaller genomes. These results\nsuggest that the massive mitochondrial genomes in Pinaceae are likely the\nresult of multiple contributing factors, including repeat sequences, transposon\nactivity, and extensive plastid sequence incorporation. Our study enhances the\nunderstanding of mitochondrial genome evolution in plants and provides valuable\ngenetic information for the conservation and study of Cathaya argyrophylla.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.07006v1"
    },
    {
        "title": "Zimin patterns in genomes",
        "authors": [
            "Nikol Chantzi",
            "Ioannis Mouratidis",
            "Ilias Georgakopoulos-Soares"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Zimin words are words that have the same prefix and suffix. They are\nunavoidable patterns, with all sufficiently large strings encompassing them.\nHere, we examine for the first time the presence of k-mers not containing any\nZimin patterns, defined hereafter as Zimin avoidmers, in the human genome. We\nreport that in the reference human genome all k-mers above 104 base-pairs\ncontain Zimin words. We find that Zimin avoidmers are most enriched in coding\nand Human Satellite 1 regions in the human genome. Zimin avoidmers display a\ndepletion of germline insertions and deletions relative to surrounding genomic\nareas. We also apply our methodology in the genomes of another eight model\norganisms from all three domains of life, finding large differences in their\nZimin avoidmer frequencies and their genomic localization preferences. We\nobserve that Zimin avoidmers exhibit the highest genomic density in prokaryotic\norganisms, with E. coli showing particularly high levels, while the lowest\ndensity is found in eukaryotic organisms, with D. rerio having the lowest.\nAmong the studied genomes the longest k-mer length at which Zimin avoidmers are\nobserved is that of S. cerevisiae at k-mer length of 115 base-pairs. We\nconclude that Zimin avoidmers display inhomogeneous distributions in organismal\ngenomes, have intricate properties including lower insertion and deletion\nrates, and disappear faster than the theoretical expected k-mer length, across\nthe organismal genomes studied.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.13004v1"
    },
    {
        "title": "Hierarchical Classification for Predicting Metastasis Using Elastic-Net\n  Regularization on Gene Expression Data",
        "authors": [
            "Benjamin Osafo Agyare",
            "Alec Chu",
            "Blessing Oloyede"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Metastasis is a leading cause of cancer-related mortality and remains\nchallenging to detect during early stages. Accurate identification of cancers\nlikely to metastasize can improve treatment strategies and patient outcomes.\nThis study leverages publicly available gene expression profiles from primary\ncancers, with and without distal metastasis, to build predictive models. We\nutilize elastic net regularization within a hierarchical classification\nframework to predict both the tissue of origin and the metastasis status of\nprimary tumors. Our elastic net-based hierarchical classification achieved a\ntissue-of-origin prediction accuracy of 97%, and a metastasis prediction\naccuracy of 90%. Notably, mitochondrial gene expression exhibited significant\nnegative correlations with metastasis, providing potential biological insights\ninto the underlying mechanisms of cancer progression.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.16741v2"
    },
    {
        "title": "Rawsamble: Overlapping and Assembling Raw Nanopore Signals using a\n  Hash-based Seeding Mechanism",
        "authors": [
            "Can Firtina",
            "Maximilian Mordig",
            "Harun Mustafa",
            "Sayan Goswami",
            "Nika Mansouri Ghiasi",
            "Stefano Mercogliano",
            "Furkan Eris",
            "Joël Lindegger",
            "Andre Kahles",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Raw nanopore signal analysis is a common approach in genomics to provide fast\nand resource-efficient analysis without translating the signals to bases (i.e.,\nwithout basecalling). However, existing solutions cannot interpret raw signals\ndirectly if a reference genome is unknown due to a lack of accurate mechanisms\nto handle increased noise in pairwise raw signal comparison. Our goal is to\nenable the direct analysis of raw signals without a reference genome. To this\nend, we propose Rawsamble, the first mechanism that can 1) identify regions of\nsimilarity between all raw signal pairs, known as all-vs-all overlapping, using\na hash-based search mechanism and 2) use these to construct genomes from\nscratch, called de novo assembly.\n  Our extensive evaluations across multiple genomes of varying sizes show that\nRawsamble provides a significant speedup (on average by 16.36x and up to\n41.59x) and reduces peak memory usage (on average by 11.73x and up to by\n41.99x) compared to a conventional genome assembly pipeline using the\nstate-of-the-art tools for basecalling (Dorado's fastest mode) and overlapping\n(minimap2) on a CPU. We find that 36.57% of overlapping pairs generated by\nRawsamble are identical to those generated by minimap2. Using the overlaps from\nRawsamble, we construct the first de novo assemblies directly from raw signals\nwithout basecalling. We show that we can construct contiguous assembly segments\n(unitigs) up to 2.7 million bases in length (half the genome length of E.\ncoli). We identify previously unexplored directions that can be enabled by\nfinding overlaps and constructing de novo assemblies. Rawsamble is available at\nhttps://github.com/CMU-SAFARI/RawHash. We also provide the scripts to fully\nreproduce our results on our GitHub page.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.17801v1"
    },
    {
        "title": "GATES: Graph Attention Network with Global Expression Fusion for\n  Deciphering Spatial Transcriptome Architectures",
        "authors": [
            "Xiongtao Xiao",
            "Xiaofeng Chen",
            "Feiyan Jiang",
            "Songming Zhang",
            "Wenming Cao",
            "Cheng Tan",
            "Zhangyang Gao",
            "Zhongshan Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Single-cell spatial transcriptomics (ST) offers a unique approach to\nmeasuring gene expression profiles and spatial cell locations simultaneously.\nHowever, most existing ST methods assume that cells in closer spatial proximity\nexhibit more similar gene expression patterns. Such assumption typically\nresults in graph structures that prioritize local spatial information while\noverlooking global patterns, limiting the ability to fully capture the broader\nstructural features of biological tissues. To overcome this limitation, we\npropose GATES (Graph Attention neTwork with global Expression fuSion), a novel\nmodel designed to capture structural details in spatial transcriptomics data.\nGATES first constructs an expression graph that integrates local and global\ninformation by leveraging both spatial proximity and gene expression\nsimilarity. The model then employs an autoencoder with adaptive attention to\nassign proper weights for neighboring nodes, enhancing its capability of\nfeature extraction. By fusing features of both the spatial and expression\ngraphs, GATES effectively balances spatial context with gene expression data.\nExperimental results across multiple datasets demonstrate that GATES\nsignificantly outperforms existing methods in identifying spatial domains,\nhighlighting its potential for analyzing complex biological tissues. Our code\ncan be accessed on GitHub at https://github.com/xiaoxiongtao/GATES.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.20159v1"
    },
    {
        "title": "Upcycling Human Excrement: The Gut Microbiome to Soil Microbiome Axis",
        "authors": [
            "Jeff Meilander",
            "Chloe Herman",
            "Andrew Manley",
            "Georgia Augustine",
            "Dawn Birdsell",
            "Evan Bolyen",
            "Kimberly R. Celona",
            "Hayden Coffey",
            "Jill Cocking",
            "Teddy Donoghue",
            "Alexis Draves",
            "Daryn Erickson",
            "Marissa Foley",
            "Liz Gehret",
            "Johannah Hagen",
            "Crystal Hepp",
            "Parker Ingram",
            "David John",
            "Katarina Kadar",
            "Paul Keim",
            "Victoria Lloyd",
            "Christina Osterink",
            "Victoria Queeney",
            "Diego Ramirez",
            "Antonio Romero",
            "Megan C. Ruby",
            "Jason W. Sahl",
            "Sydni Soloway",
            "Nathan E. Stone",
            "Shannon Trottier",
            "Kaleb Van Orden",
            "Alexis Painter",
            "Sam Wallace",
            "Larissa Wilcox",
            "Colin V. Wood",
            "Jaiden Yancey",
            "J. Gregory Caporaso"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Human excrement composting (HEC) is a sustainable strategy for human\nexcrement (HE) management that recycles nutrients and mitigates health risks\nwhile reducing reliance on freshwater, fossil fuels, and fertilizers. We\npresent a comprehensive microbial time series analysis of HEC and show that the\ninitial gut-like microbiome of HEC systems transitions to a microbiome similar\nto soil and traditional compost in fifteen biological replicates tracked weekly\nfor one year.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.04148v1"
    },
    {
        "title": "Perspective on recent developments and challenges in regulatory and\n  systems genomics",
        "authors": [
            "Julia Zeiltinger",
            "Sushmita Roy",
            "Ferhat Ay",
            "Anthony Mathelier",
            "Alejandra Medina-Rivera",
            "Shaun Mahony",
            "Saurabh Sinha",
            "Jason Ernst"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Predicting how genetic variation affects phenotypic outcomes at the\norganismal, cellular, and molecular levels requires deciphering the\ncis-regulatory code, the sequence rules by which non-coding regions regulate\ngenes. In this perspective, we discuss recent computational progress and\nchallenges towards solving this fundamental problem. We describe how\ncis-regulatory elements are mapped and how their sequence rules can be learned\nand interpreted with sequence-to-function neural networks, with the goal of\nidentifying genetic variants in human disease. We also discuss how studies of\nthe 3D chromatin organization could help identifying long-range regulatory\neffects and how current methods for mapping gene regulatory networks could\nbetter describe biological processes. We point out current gaps in knowledge\nalong with technical limitations and benchmarking challenges of computational\nmethods. Finally, we discuss newly emerging technologies, such as spatial\ntranscriptomics, and outline strategies for creating a more general model of\nthe cis-regulatory code that is more broadly applicable across cell types and\nindividuals.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.04363v1"
    },
    {
        "title": "Use of 3D chaos game representation to quantify DNA sequence similarity\n  with applications for hierarchical clustering",
        "authors": [
            "Stephanie Young",
            "Jerome Gilles"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  A 3D chaos game is shown to be a useful way for encoding DNA sequences. Since\nmatching subsequences in DNA converge in space in 3D chaos game encoding, a DNA\nsequence's 3D chaos game representation can be used to compare DNA sequences\nwithout prior alignment and without truncating or padding any of the sequences.\nTwo proposed methods inspired by shape-similarity comparison techniques show\nthat this form of encoding can perform as well as alignment-based techniques\nfor building phylogenetic trees. The first method uses the volume overlap of\nintersecting spheres and the second uses shape signatures by summarizing the\ncoordinates, oriented angles, and oriented distances of the 3D chaos game\ntrajectory. The methods are tested using: (1) the first exon of the beta-globin\ngene for 11 species, (2) mitochondrial DNA from four groups of primates, and\n(3) a set of synthetic DNA sequences. Simulations show that the proposed\nmethods produce distances that reflect the number of mutation events;\nadditionally, on average, distances resulting from deletion mutations are\ncomparable to those produced by substitution mutations.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05266v1"
    },
    {
        "title": "Leveraging genomic deep learning models for non-coding variant effect\n  prediction",
        "authors": [
            "Pooja Kathail",
            "Ayesha Bajwa",
            "Nilah M. Ioannidis"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The majority of genetic variants identified in genome-wide association\nstudies of complex traits are non-coding, and characterizing their function\nremains an important challenge in human genetics. Genomic deep learning models\nhave emerged as a promising approach to enable in silico prediction of variant\neffects. These include supervised sequence-to-activity models, which predict\ngenome-wide chromatin states or gene expression levels directly from DNA\nsequence, and self-supervised genomic language models. Here, we review progress\nin leveraging these models for non-coding variant effect prediction. We\ndescribe practical considerations for making such predictions and categorize\nthe types of ground truth data that have been used to evaluate deep\nlearning-based variant effect predictions, providing insight into the settings\nin which current models are most useful. We also discuss downstream\napplications of such models to understanding disease-relevant non-coding\nvariants. Our review highlights key considerations for practitioners and\nopportunities for future improvements in model development and evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11158v1"
    },
    {
        "title": "ukbFGSEA: an R Package for Applying Fast Preranked Gene Set Enrichment\n  Analysis to UK Biobank Exome Data",
        "authors": [
            "Pengjun Guo",
            "He Zhu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The Genebass dataset, released by Karczewski et al. (2022), provides a\ncomprehensive resource elucidating associations between genes and 4,529\nphenotypes based on nearly 400,000 exomes from the UK Biobank. This extensive\ndataset enables the evaluation of gene set enrichment across a wide range of\nphenotypes, facilitating the inference of associations between specified gene\nsets and phenotypic traits. Despite its potential, no established method for\napplying gene set enrichment analysis (GSEA) to Genebass data exists. To\naddress this gap, we propose utilizing fast pre-ranked gene set enrichment\nanalysis (FGSEA) as a novel approach to determine whether a specified set of\ngenes is significantly enriched in phenotypes within the UK Biobank. We\ndeveloped an R package, ukbFGSEA, to implement this analysis, completed with a\nhands-on tutorial. Our approach has been validated by analyzing gene sets\nassociated with autism spectrum disorder, developmental disorder, and\nneurodevelopmental disorders, demonstrating its capability to reveal\nestablished and novel associations.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.12769v1"
    },
    {
        "title": "gggenomes: effective and versatile visualizations for comparative\n  genomics",
        "authors": [
            "Thomas Hackl",
            "Markus Ankenbrand",
            "Bart van Adrichem",
            "David Wilkins",
            "Kristina Haslinger"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The effective visualization of genomic data is crucial for exploring and\ninterpreting complex relationships within and across genes and genomes. Despite\nadvances in developing dedicated bioinformatics software, common visualization\ntools often fail to efficiently integrate the diverse datasets produced in\ncomparative genomics, lack intuitive interfaces to construct complex plots and\nare missing functionalities to inspect the underlying data iteratively and at\nscale. Here, we introduce gggenomes, a versatile R package designed to overcome\nthese challenges by extending the widely used ggplot2 framework for comparative\ngenomics. gggenomes is available from CRAN and GitHub, accompanied by detailed\nand user-friendly documentation (https://thackl.github.io/gggenomes).\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13556v1"
    },
    {
        "title": "Evidence of epigenetic oncogenesis: a turning point in cancer research",
        "authors": [
            "Jean-Pascal Capp",
            "Benoît Aliaga",
            "Vera Pancaldi"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  In cancer research, the term epigenetics was used in the 1970s in its modern\nsense encompassing non-genetic events modifying the chromatin state, mainly to\noppose the emerging oncogene paradigm. However, starting from the establishment\nof this prominent concept, the importance of these epigenetic phenomena in\ncancer rarely led to questioning the causal role of genetic alterations. Only\nin the last 10 years, the accumulation of problematic data, better experimental\ntechnologies, and some ambitious models pushed the idea that epigenetics could\nbe at least as important as genetics in early oncogenesis. Until this year, a\ndirect demonstration of epigenetic oncogenesis was still lacking. Now Parreno,\nCavalli and colleagues, using a refined experimental model in the fruit fly\nDrosophila melanogaster, enforced the initiation of tumours solely by imposing\na transient loss of Polycomb repression, leading to a purely epigenetic\noncogenesis phenomenon. Despite a few caveats that we discuss, this pioneering\nwork represents a major breakpoint in cancer research that leads us to consider\nthe theoretical and conceptual implications on oncogenesis and to search for\nlinks between this artificial experimental model and naturally occurring\nprocesses, while revisiting cancer theories that were previously proposed as\nalternatives to the oncogene-centered paradigm.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.14130v1"
    },
    {
        "title": "An improved, high yield method for isolating nuclei from individual\n  zebrafish embryos for single-nucleus RNA sequencing",
        "authors": [
            "Clifford Rostomily",
            "Heidi Lee",
            "Amy Tresenrider",
            "Riza Daza",
            "Andrew Mullen",
            "Jay Shendure",
            "David Kimelman",
            "Cole Trapnell"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Zebrafish are an ideal system to study the effect(s) of chemical, genetic,\nand environmental perturbations on development due to their high fecundity and\nfast growth. Recently, single cell sequencing has emerged as a powerful tool to\nmeasure the effect of these perturbations at a whole embryo scale. These types\nof experiments rely on the ability to isolate nuclei from a large number of\nindividually barcoded zebrafish embryos in parallel. Here we report a method\nfor efficiently isolating high-quality nuclei from zebrafish embryos in a\n96-well plate format by bead homogenization in a lysis buffer. Through\nhead-to-head sciPlex-RNA-seq experiments, we demonstrate that this method\nrepresents a substantial improvement over enzymatic dissociation and that it is\ncompatible with a wide range of developmental stages.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.15309v1"
    },
    {
        "title": "Group-wise normalization in differential abundance analysis of\n  microbiome samples",
        "authors": [
            "Dylan Clark-Boucher",
            "Brent A Coull",
            "Harrison T Reeder",
            "Fenglei Wang",
            "Qi Sun",
            "Jacqueline R Starr",
            "Kyu Ha Lee"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  A key challenge in differential abundance analysis of microbial samples is\nthat the counts for each sample are compositional, resulting in biased\ncomparisons of the absolute abundance across study groups. Normalization-based\ndifferential abundance analysis methods rely on external normalization factors\nthat account for the compositionality by standardizing the counts onto a common\nnumerical scale. However, existing normalization methods have struggled at\nmaintaining the false discovery rate in settings where the variance or\ncompositional bias is large. This article proposes a novel framework for\nnormalization that can reduce bias in differential abundance analysis by\nre-conceptualizing normalization as a group-level task. We present two\nnormalization methods within the group-wise framework: group-wise relative log\nexpression (G-RLE) and fold-truncated sum scaling (FTSS). G-RLE and FTSS\nachieve higher statistical power for identifying differentially abundant taxa\nthan existing methods in model-based and synthetic data simulation settings,\nwhile maintaining the false discovery rate in challenging scenarios where\nexisting methods suffer. The best results are obtained from using FTSS\nnormalization with the differential abundance analysis method MetagenomeSeq.\nCode for implementing the methods and replicating the analysis can be found at\nour GitHub page\n(https://github.com/dclarkboucher/microbiome_groupwise_normalization).\n",
        "pdf_link": "http://arxiv.org/pdf/2411.15400v1"
    },
    {
        "title": "The Updated Genome Warehouse: Enhancing Data Value, Security, and\n  Usability to Address Data Expansion",
        "authors": [
            "Yingke Ma",
            "Xuetong Zhao",
            "Yaokai Jia",
            "Zhenxian Han",
            "Caixia Yu",
            "Zhuojing Fan",
            "Zhang Zhang",
            "Jingfa Xiao",
            "Wenming Zhao",
            "Yiming Bao",
            "Meili Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The Genome Warehouse (GWH), accessible at https://ngdc.cncb.ac.cn/gwh, is an\nextensively utilized public repository dedicated to the deposition, management\nand sharing of genome assembly sequences, annotations, and metadata. This paper\nhighlights noteworthy enhancements to the GWH since the 2021 version,\nemphasizing substantial advancements in web interfaces for data submission,\ndatabase functionality updates, and resource integration. Key updates include\nthe reannotation of released prokaryotic genomes, mirroring of genome resources\nfrom National Center for Biotechnology Information (NCBI) GenBank and RefSeq,\nintegration of Poxviridae sequences, implementation of an online batch\nsubmission system, enhancements to the quality control system, advanced search\ncapabilities, and the introduction of a controlled-access mechanism for human\ngenome data. These improvements collectively augment the ease and security of\ndata submission and access as well as genome data value, thereby fostering\nheightened convenience and utility for researchers in the genomic field.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.15467v1"
    },
    {
        "title": "How chromatin interactions shed light on interpreting non-coding genomic\n  variants: opportunities and future direc-tions",
        "authors": [
            "Yuheng Liang",
            "Sedigheh Abedini",
            "Nona Farbehi",
            "Hamid Alinejad-Rokny"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Genomic variants, including copy number variants (CNVs) and genome-wide\nassocia-tion study (GWAS) single nucleotide polymorphisms (SNPs), represent\nstructural alterations that influence genomic diversity and disease\nsusceptibility. While coding region variants have been extensively studied,\nnon-coding and regulatory variants present significant challenges due to their\npotential impacts on gene regulation, which are often obscured by the\ncomplexity of the ge-nome. Chromatin interactions, which organize the genome\nspatially and regulate gene expression through enhancer-promoter contacts,\npredominantly occur in non-coding regions. Notably, more than 90% of enhancers,\ncrucial for gene regulation, reside in these non-coding regions, underscor-ing\ntheir importance in interpreting the regulatory effects of CNVs and\nGWAS-associated SNPs. In this study, we integrate chromatin interaction data\nwith CNV and GWAS data to uncover the functional implications of non-coding\nvariants. By leveraging this integrated approach, we pro-vide new insights into\nhow structural variants and disease-associated SNPs disrupt regulatory\nnetworks, advancing our understanding of genetic complexity. These findings\noffer potential av-enues for personalized medicine by elucidating disease\nmechanisms and guiding therapeutic strategies tailored to individual genomic\nprofiles. This research underscores the critical role of chromatin interactions\nin revealing the regulatory consequences of non-coding variants, bridging the\ngap between genetic variation and phenotypic outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17956v1"
    },
    {
        "title": "MAFcounter: An efficient tool for counting the occurrences of k-mers in\n  MAF files",
        "authors": [
            "Michail Patsakis",
            "Kimonas Provatas",
            "Ioannis Mouratidis",
            "Ilias Georgakopoulos-Soares"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Motivation: With the rapid expansion of large-scale biological datasets, DNA\nand protein sequence alignments have become essential for comparative genomics\nand proteomics. These alignments facilitate the exploration of sequence\nsimilarity patterns, providing valuable insights into sequence conservation,\nevolutionary relationships and for functional analyses. Typically, sequence\nalignments are stored in formats such as the Multiple Alignment Format (MAF).\nCounting k-mer occurrences is a crucial task in many computational biology\napplications, but currently, there is no algorithm designed for k-mer counting\nin alignment files.\n  Results: We have developed MAFcounter, the first k-mer counter dedicated to\nalignment files. MAFcounter is multithreaded, fast, and memory efficient,\nenabling k-mer counting in DNA and protein sequence alignment files.\n  Availability: The MAFcounter package and its Python bindings are released\nunder GPL license as a multi-platform application and are available at:\nhttps://github.com/Georgakopoulos-Soares-lab/MAFcounter\n",
        "pdf_link": "http://arxiv.org/pdf/2411.19427v1"
    },
    {
        "title": "LLaMA-Gene: A General-purpose Gene Task Large Language Model Based on\n  Instruction Fine-tuning",
        "authors": [
            "Wang Liang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Building a general-purpose task model similar to ChatGPT has been an\nimportant research direction for gene large language models. Instruction\nfine-tuning is a key component in building ChatGPT, but existing instructions\nare primarily based on natural language. Natural language and gene sequences\nhave significant differences in tokenization and encoding. Therefore,\nconstructing a multilingual model that can handle both natural language and\ngene sequences is crucial for solving this problem.In this paper, we expand the\ncapabilities of the LLaMA large language model to include gene language. This\ninvolves expanding the vocabulary using the Byte Pair Encoding (BPE) method,\nspecifically tailored for DNA and protein sequences, and conducting further\npre-training on these sequences. We then convert various downstream gene task\ndata into a unified format for instruction fine-tuning and further fine-tune\nthe model on this data.Our study demonstrates that a mixed model of gene and\nnatural language, fine-tuned with instructions, achieves results comparable to\nthe current state-of-the-art (SOTA) in tasks such as gene classification and\ngene sequence interaction. This provides a promising direction for building a\nunified large language model for gene tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.00471v1"
    },
    {
        "title": "gghic: A Versatile R Package for Exploring and Visualizing 3D Genome\n  Organization",
        "authors": [
            "Minghao Jiang",
            "Duohui Jing",
            "Jason W. H. Wong"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Motivation: The three-dimensional (3D) organization of the genome plays a\ncritical role in regulating gene expression and maintaining cellular\nhomeostasis. Disruptions in this spatial organization can result in abnormal\nchromatin interactions, contributing to the development of various diseases\nincluding cancer. Advances in chromosome conformation capture technologies,\nsuch as Hi-C, have enabled researchers to study genome architecture at high\nresolution. However, the efficient visualization and interpretation of these\ncomplex datasets remain a major challenge, particularly when integrating\ngenomic annotations and inter-chromosomal interactions.\n  Results: We present gghic, an R package that extends the ggplot2 framework to\nenable intuitive and customizable visualization of genomic interaction data.\ngghic introduces novel layers for generating triangular heatmaps of chromatin\ninteractions and annotating them with features such as chromatin loops,\ntopologically associated domains (TADs), gene/transcript models, and data\ntracks (e.g., ChIP-seq signals). The package supports data from multiple\nchromosomes, facilitating the exploration of inter-chromosomal interactions.\nBuilt to integrate seamlessly with the R/Bioconductor ecosystem, gghic is\ncompatible with widely used genomic data formats, including HiCExperiment and\nGInteractions objects. We demonstrate the utility of gghic by replicating a\npublished figure showing a translocation event in T-cell acute lymphoblastic\nleukemia (T-ALL), highlighting its ability to integrate genomic annotations and\ngenerate publication-quality figures.\n  Availability and implementation: The R package can be accessed at\nhttps://github.com/jasonwong-lab/gghic and is distributed under the GNU General\nPublic License version 3.0.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.03005v1"
    },
    {
        "title": "Timestamp calibration for time-series single cell RNA-seq expression\n  data",
        "authors": [
            "Xiran Chen",
            "Sha Lin",
            "Xiaofeng Chen",
            "Weikai Li",
            "Yifei Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Timestamp automatic annotation (TAA) is a crucial procedure for analyzing\ntime-series ScRNA-seq data, as they unveil dynamic biological developments and\ncell regeneration process. However, current TAA methods heavily rely on manual\ntimestamps, often overlooking their reliability. This oversight can\nsignificantly degrade the performance of timestamp automatic annotation due to\nnoisy timestamps. Nevertheless, the current approach for addressing this issue\ntends to select less critical cleaned samples for timestamp calibration. To\ntackle this challenge, we have developed a novel timestamp calibration model\ncalled ScPace for handling noisy labeled time-series ScRNA-seq data. This\napproach incorporates a latent variable indicator within a base classifier\ninstead of probability sampling to detect noisy samples effectively. To\nvalidate our proposed method, we conducted experiments on both simulated and\nreal time-series ScRNA-seq datasets. Cross-validation experiments with\ndifferent artificial mislabeling rates demonstrate that ScPace outperforms\nprevious approaches. Furthermore, after calibrating the timestamps of the\noriginal time-series ScRNA-seq data using our method, we performed supervised\npseudotime analysis, revealing that ScPace enhances its performance\nsignificantly. These findings suggest that ScPace is an effective tool for\ntimestamp calibration by enabling reclassification and deletion of detected\nnoisy labeled samples while maintaining robustness across diverse ranges of\ntime-series ScRNA-seq datasets. The source code is available at\nhttps://github.com/OPUS-Lightphenexx/ScPace.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.03027v1"
    },
    {
        "title": "Approaches to studying virus pangenome variation graphs",
        "authors": [
            "Tim Downing"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Pangenome variation graphs (PVGs) allow for the representation of genetic\ndiversity in a more nuanced way than traditional reference-based approaches.\nHere we focus on how PVGs are a powerful tool for studying genetic variation in\nviruses, offering insights into the complexities of viral quasispecies,\nmutation rates, and population dynamics. PVGs allow for the representation of\ngenetic diversity in a more nuanced way than traditional reference-based\napproaches. PVGs originated in human genomics and hold great promise for viral\ngenomics. Previous work has been constrained by small sample sizes and\ngene-centric methods, PVGs enable a more comprehensive approach to studying\nviral diversity. Large viral genome collections should be used to make PVGs,\nwhich offer significant advantages: we outline accessible tools to achieve\nthis. This spans PVG construction, PVG file formats, PVG manipulation and\nanalysis, PVG visualisation, measuring PVG openness, and mapping reads to PVGs.\nAdditionally, the development of PVG-specific formats for mutation\nrepresentation and personalised PVGs that reflect specific research questions\nwill further enhance PVG applications. Although challenges remain, particularly\nin managing nested variants and optimising error detection, PVGs offer a\npromising direction for viral population genomics. These advances will enable\nmore accurate and comprehensive detection of viral mutations, contributing to a\ndeeper understanding of viral evolution and genotype-phenotype associations.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.05096v1"
    },
    {
        "title": "Emerging Challenges in Molecular Paleontology: Misapplication of\n  Environmental DNA Fragments and Misconception of Deamination as a Key\n  Criterion for In Situ DNA Identification",
        "authors": [
            "Wan-Qian Zhao",
            "Shu-Jie Zhang",
            "Zhan-Yong Guo",
            "Zeng-Yuan Tian",
            "Gang-Qiang Cao",
            "Mei-Jun Li",
            "Li-You Qiu",
            "Jin-Yu Yang",
            "Yong-Kai Wang",
            "Shu-Hui Zhang",
            "Zhi-Fang Zheng",
            "Min-Zhi Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This article critically examines the methodologies applied in ancient DNA\n(aDNA) research, particularly those developed by Dr. P\\\"a\\\"abo's team, which\nhave significantly influenced the field. The focus is on the challenges of\ndistinguishing original in situ DNA (oriDNA) from environmental DNA (eDNA)\ncontamination in fossil samples. Recent analyses indicate that even with\nrigorous extraction and sequencing protocols, a considerable amount of eDNA\nremains present, often misinterpreted as oriDNA. This misidentification risks\nthe accuracy of species ascription and evolutionary interpretations derived\nfrom fossil analyses. The paper explores fossil preservation's physical and\nchemical dynamics, which allow eDNA from similar and disparate species to\ninfiltrate bone matrices. We propose enhancements to methodological frameworks,\nsuch as broader BLAST database usage and stringent E-value criteria, to improve\nspecies-specific aDNA identification. Additionally, the article critiques the\nreliance on deamination patterns as a definitive marker for aDNA, suggesting a\nreevaluation of this criterion due to its inconsistency and the potential for\nmisleading sequencing results. Ultimately, our findings advocate for a more\ncautious and refined approach to aDNA research, ensuring more reliable and\nverifiable scientific outcomes\n",
        "pdf_link": "http://arxiv.org/pdf/2412.06378v1"
    },
    {
        "title": "Ancient DNA from 120-Million-Year-Old Lycoptera Fossils Reveals\n  Evolutionary Insights",
        "authors": [
            "Wan-Qian Zhao",
            "Zhan-Yong Guo",
            "Zeng-Yuan Tian",
            "Tong-Fu Su",
            "Gang-Qiang Cao",
            "Zi-Xin Qi",
            "Tian-Cang Qin",
            "Wei Zhou",
            "Jin-Yu Yang",
            "Ming-Jie Chen",
            "Xin-Ge Zhang",
            "Chun-Yan Zhou",
            "Chuan-Jia Zhu",
            "Meng-Fei Tang",
            "Di Wu",
            "Mei-Rong Song",
            "Yu-Qi Guo",
            "Li-You Qiu",
            "Fei Liang",
            "Mei-Jun Li",
            "Jun-Hui Geng",
            "Li-Juan Zhao",
            "Shu-Jie Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  High quality ancient DNA (aDNA) is essential for molecular paleontology. Due\nto DNA degradation and contamination by environmental DNA (eDNA), current\nresearch is limited to fossils less than 1 million years old. The study\nsuccessfully extracted DNA from Lycoptera davidi fossils from the Early\nCretaceous period, dating 120 million years ago. Using high-throughput\nsequencing, 1,258,901 DNA sequences were obtained. We established a rigorous\nprotocol known as the mega screen method. Using this method, we identified 243\noriginal in situ DNA (oriDNA) sequences, likely from the Lycoptera genome.\nThese sequences have an average length of over 100 base pairs and show no signs\nof deamination. Additionally, 10 transposase coding sequences were discovered,\nshedding light on a unique self-renewal mechanism in the genome. This study\nprovides valuable DNA data for understanding ancient fish evolution and\nadvances paleontological research.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.06521v1"
    },
    {
        "title": "DNA Fragments in Crude Oil Reveals Earth's Hidden History",
        "authors": [
            "Wan-Qian Zhao",
            "Zhan-Yong Guo",
            "Yu-Qi Guo",
            "Mei-Jun Li",
            "Gang-Qiang Cao",
            "Zeng-Yuan Tian",
            "Ran Chai",
            "Li-You Qiu",
            "Jin-Hua Zeng",
            "Xin-Ge Zhang",
            "Tian-Cang Qin",
            "Jin-Yu Yang",
            "Ming-Jie Chen",
            "Mei-Rong Song",
            "Fei Liang",
            "Jun-Hui Geng",
            "Chun-Yan Zhou",
            "Shu-Jie Zhang",
            "Li-Juan Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This groundbreaking research extracted DNA from petroleum using nanoparticle\naffinity bead technology, yielding 3,159,020 petroleum DNA (pDNA) sequences,\nprimarily environmental DNA. While most original in situ DNA (oriDNA) was lost,\nancient DNA (aDNA) from petroleum offers an important source of ecological and\nevolutionary information, surpassing traditional fossils. This study reveals\nthat oil, mainly sourced from algae and lower aquatic plants, now serves as a\nnew type of fossil, providing detailed insights into Earth's hidden history,\nincluding unclassified species and ancient events, revolutionizing petroleum\ngeology and paleontology.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.06550v1"
    },
    {
        "title": "VEPerform: a web resource for evaluating the performance of variant\n  effect predictors",
        "authors": [
            "Cindy Zhang",
            "Frederick P. Roth"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Computational variant effect predictors (VEPs) are providing increasingly\nstrong evidence to classify the pathogenicity of missense variants. Precision\nvs. recall analysis is useful in evaluating VEP performance, especially when\nadjusted for imbalanced test sets. Here, we describe VEPerform, a web-based\ntool for evaluating the performance of VEPs at the gene level using balanced\nprecision vs. recall curve (BPRC) analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10262v1"
    },
    {
        "title": "Artificial Intelligence for Central Dogma-Centric Multi-Omics:\n  Challenges and Breakthroughs",
        "authors": [
            "Lei Xin",
            "Caiyun Huang",
            "Hao Li",
            "Shihong Huang",
            "Yuling Feng",
            "Zhenglun Kong",
            "Zicheng Liu",
            "Siyuan Li",
            "Chang Yu",
            "Fei Shen",
            "Hao Tang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  With the rapid development of high-throughput sequencing platforms, an\nincreasing number of omics technologies, such as genomics, metabolomics, and\ntranscriptomics, are being applied to disease genetics research. However,\nbiological data often exhibit high dimensionality and significant noise, making\nit challenging to effectively distinguish disease subtypes using a single-omics\napproach. To address these challenges and better capture the interactions among\nDNA, RNA, and proteins described by the central dogma, numerous studies have\nleveraged artificial intelligence to develop multi-omics models for disease\nresearch. These AI-driven models have improved the accuracy of disease\nprediction and facilitated the identification of genetic loci associated with\ndiseases, thus advancing precision medicine. This paper reviews the\nmathematical definitions of multi-omics, strategies for integrating multi-omics\ndata, applications of artificial intelligence and deep learning in multi-omics,\nthe establishment of foundational models, and breakthroughs in multi-omics\ntechnologies, drawing insights from over 130 related articles. It aims to\nprovide practical guidance for computational biologists to better understand\nand effectively utilize AI-based multi-omics machine learning algorithms in the\ncontext of central dogma.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12668v1"
    },
    {
        "title": "Deep Learning in Proteomics Informatics: Applications, Challenges, and\n  Future Directions",
        "authors": [
            "Yindan Luo",
            "Jiaxin Cai"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Deep learning is an advanced technology that relies on large-scale data and\ncomplex models for feature extraction and pattern recognition. It has been\nwidely applied across various fields, including computer vision, natural\nlanguage processing, and speech recognition. In recent years, deep learning has\ndemonstrated significant potential in the realm of proteomics informatics,\nparticularly in deciphering complex biological information. The introduction of\nthis technology not only accelerates the processing speed of protein data but\nalso enhances the accuracy of predictions regarding protein structure and\nfunction. This provides robust support for both fundamental biology research\nand applied biotechnological studies. Currently, deep learning is primarily\nfocused on applications such as protein sequence analysis, three-dimensional\nstructure prediction, functional annotation, and the construction of protein\ninteraction networks. These applications offer numerous advantages to proteomic\nresearch. Despite its growing prevalence in this field, deep learning faces\nseveral challenges including data scarcity, insufficient model\ninterpretability, and computational complexity; these factors hinder its\nfurther advancement within proteomics. This paper comprehensively reviews the\napplications of deep learning in proteomics along with the challenges it\nencounters. The aim is to provide a systematic theoretical discussion and\npractical basis for research in this domain to facilitate ongoing development\nand innovation of deep learning technologies within proteomics.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.17349v1"
    },
    {
        "title": "Origin of $α$-satellite repeat arrays from mitochondrial molecular\n  fossils -- sequential insertion, expansion, and evolution in the nuclear\n  genome",
        "authors": [
            "Yihang Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Alpha satellite DNA is large tandem arrays of 150-400 bp units, and its\norigin remains an evolutionary mystery. In this research, we identified 1,545\nalpha-satellite-like (SatL) repeat units in the nuclear genome of jewel wasp\nNasonia vitripennis. Among them, thirty-nine copies of SatL were organized in\ntwo palindromic arrays in mitochondria, resulting in a 50% increase in the\ngenome size. Strikingly, genomic neighborhood analyses of 1,516 nuclear SatL\nrepeats revealed that they are located in NuMT (nuclear mitochondrial DNA)\nregions, and SatL phylogeny matched perfectly with mitochondrial genes and NuMT\npseudogenes. These results support that SatL arrays originated from ten\nindependent mitochondria insertion events into the nuclear genome within the\nlast 500,000 years, after divergence from its sister species N. giraulti.\nDramatic repeat GC-percent elevation (from 33.9% to 50.4%) is a hallmark of\nrapid SatL sequence evolution in mitochondria due to GC-biased gene conversion\nfacilitated by the palindromic sequence pairing of the two mitochondrial SatL\narrays. The nuclear SatL repeat arrays underwent substantial copy number\nexpansion, from 12-15 (SatL1) to over 400 copies (SatL4). The oldest SatL4B\narray consists of four types of repeat units derived from deletions in the\nAT-rich region of ancestral repeats, and complex high-order structures have\nevolved through duplications. We also discovered similar repeat insertions into\nthe nuclear genome of Muscidifurax, suggesting this mechanism can be common in\ninsects. This is the first report of the mitochondrial origin of nuclear\nsatellite sequences, and our findings shed new light on the origin and\nevolution of satellite DNA.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02284v2"
    },
    {
        "title": "Deep Learning-based Feature Discovery for Decoding Phenotypic Plasticity\n  in Pediatric High-Grade Gliomas Single-Cell Transcriptomics",
        "authors": [
            "Abicumaran Uthamacumaran"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  By use of complex network dynamics and graph-based machine learning, we\nidentified critical determinants of lineage-specific plasticity across the\nsingle-cell transcriptomics of pediatric high-grade glioma (pHGGs) subtypes:\nIDHWT glioblastoma and K27M-mutant glioma. Our study identified network\ninteractions regulating glioma morphogenesis via the tumor-immune\nmicroenvironment, including neurodevelopmental programs, calcium dynamics, iron\nmetabolism, metabolic reprogramming, and feedback loops between MAPK/ERK and\nWNT signaling. These relationships highlight the emergence of a hybrid spectrum\nof cellular states navigating a disrupted neuro-differentiation hierarchy. We\nidentified transition genes such as DKK3, NOTCH2, GATAD1, GFAP, and SEZ6L in\nIDHWT glioblastoma, and H3F3A, ANXA6, HES6/7, SIRT2, FXYD6, PTPRZ1, MEIS1,\nCXXC5, and NDUFAB1 in K27M subtypes. We also identified MTRNR2L1, GAPDH, IGF2,\nFKBP variants, and FXYD7 as transition genes that influence cell fate\ndecision-making across both subsystems. Our findings suggest pHGGs are\ndevelopmentally trapped in states exhibiting maladaptive behaviors, and hybrid\ncellular identities. In effect, tumor heterogeneity (metastability) and\nplasticity emerge as stress-response patterns to immune-inflammatory\nmicroenvironments and oxidative stress. Furthermore, we show that pHGGs are\nsteered by developmental trajectories from radial glia predominantly favoring\nneocortical cell fates, in telencephalon and prefrontal cortex (PFC)\ndifferentiation. By addressing underlying patterning processes and plasticity\nnetworks as therapeutic vulnerabilities, our findings provide precision\nmedicine strategies aimed at modulating glioma cell fates and overcoming\ntherapeutic resistance. We suggest transition therapy toward neuronal-like\nlineage differentiation as a potential therapy to help stabilize pHGG\nplasticity and aggressivity.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04181v1"
    },
    {
        "title": "Curated loci prime editing (cliPE) for accessible multiplexed assays of\n  variant effect (MAVEs)",
        "authors": [
            "Carina G Biar",
            "Nicholas Bodkin",
            "Gemma L Carvill",
            "Jeffrey D Calhoun"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Multiplexed assays of variant effect (MAVEs) perform simultaneous\ncharacterization of many variants. Prime editing has been recently adopted for\nintroducing many variants in their native genomic contexts. However, robust\nprotocols and standards are limited, preventing widespread uptake. Herein, we\ndescribe curated loci prime editing (cliPE) which is an accessible, low-cost\nexperimental pipeline to perform MAVEs using prime editing of a target gene, as\nwell as a companion Shiny app (pegRNA Designer) to rapidly and easily design\nuser-specific MAVE libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04822v1"
    },
    {
        "title": "Transcriptome signature for the identification of bevacizumab responders\n  in ovarian cancer",
        "authors": [
            "Olga Zolotareva",
            "Karen Legler",
            "Olga Tsoy",
            "Anna Esteve",
            "Alexey Sergushichev",
            "Vladimir Sukhov",
            "Jan Baumbach",
            "Kathrin Eylmann",
            "Minyue Qi",
            "Malik Alawi",
            "Stefan Kommoss",
            "Barbara Schmalfeldt",
            "Leticia Oliveira-Ferrer"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  The standard of care for ovarian cancer comprises cytoreductive surgery,\nfollowed by adjuvant platinum-based chemotherapy plus taxane therapy and\nmaintenance therapy with the antiangiogenic compound bevacizumab and/or a PARP\ninhibitor. Nevertheless, there is currently no clear clinical indication for\nthe use of bevacizumab, highlighting the urgent need for biomarkers to assess\nthe response to bevacizumab. In the present study, based on a novel RNA-seq\ndataset (n=181) and a previously published microarray-based dataset (n=377), we\nhave identified an expression signature potentially associated with benefit\nfrom bevacizumab addition and assumed to reflect cancer stemness acquisition\ndriven by activation of CTCFL. Patients with this signature demonstrated\nimproved overall survival when bevacizumab was added to standard chemotherapy\nin both novel (HR=0.41(0.23-0.74), adj.p-value=7.70e-03) and previously\npublished cohorts (HR=0.51(0.34-0.75), adj.p-value=3.25e-03), while no\nsignificant differences in survival explained by treatment were observed in\npatients negative for this signature. In addition to the CTCFL signature, we\nfound several other reproducible expression signatures which may also represent\nbiomarker candidates not related to established molecular subtypes of ovarian\ncancer and require further validation studies based on additional RNA-seq data.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04869v1"
    },
    {
        "title": "TopoLa: A Universal Framework to Enhance Cell Representations for\n  Single-cell and Spatial Omics through Topology-encoded Latent Hyperbolic\n  Geometry",
        "authors": [
            "Kai Zheng",
            "Shaokai Wang",
            "Yunpei Xu",
            "Qiming Lei",
            "Qichang Zhao",
            "Xiao Liang",
            "Qilong Feng",
            "Yaohang Li",
            "Min Li",
            "Jinhui Xu",
            "Jianxin Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Recent advances in cellular research demonstrate that scRNA-seq characterizes\ncellular heterogeneity, while spatial transcriptomics reveals the spatial\ndistribution of gene expression. Cell representation is the fundamental issue\nin the two fields. Here, we propose Topology-encoded Latent Hyperbolic Geometry\n(TopoLa), a computational framework enhancing cell representations by capturing\nfine-grained intercellular topological relationships. The framework introduces\na new metric, TopoLa distance (TLd), which quantifies the geometric distance\nbetween cells within latent hyperbolic space, capturing the network's\ntopological structure more effectively. With this framework, the cell\nrepresentation can be enhanced considerably by performing convolution on its\nneighboring cells. Performance evaluation across seven biological tasks,\nincluding scRNA-seq data clustering and spatial transcriptomics domain\nidentification, shows that TopoLa significantly improves the performance of\nseveral state-of-the-art models. These results underscore the generalizability\nand robustness of TopoLa, establishing it as a valuable tool for advancing both\nbiological discovery and computational methodologies.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08363v1"
    },
    {
        "title": "Evolutionary conservation of motif constituents within the yeast protein\n  interaction network",
        "authors": [
            "S. Wuchty",
            "Z. N. Oltvai",
            "A. -L. Barabasi"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  Understanding why some cellular components are conserved across species,\nwhile others evolve rapidly is a key question of modern biology. Here we\ndemonstrate that in S. cerevisiae proteins organized in cohesive patterns of\ninteractions are conserved to a significantly higher degree than those that do\nnot participate in such motifs. We find that the conservation of proteins\nwithin distinct topological motifs correlates with the motif's\ninter-connectedness and function and also depends on the structure of the\noverall interactome topology. These findings indicate that motifs may represent\nevolutionary conserved topological units of cellular networks molded in\naccordance with the specific biological function in which they participate.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0310024v1"
    },
    {
        "title": "Determinative degree and nucleotide sequence analysis by trianders",
        "authors": [
            "Diana Duplij",
            "Steven Duplij"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  A new version of DNA walks, where nucleotides are regarded unequal in their\ncontribution to a walk is introduced, which allows us to study thoroughly the\n\"fine structure\" of nucleotide sequences. The approach is based on the\nassumption that nucleotides have an inner abstract characteristics, the\ndeterminative degree, which reflects phenomenological properties of genetic\ncode and is adjusted to nucleotides physical properties. We consider each\nposition in codon independently, which gives three separate walks being\ncharacterized by different angles and lengths, and such an object is called\ntriander which reflects the \"strength\" of branch. A general method of\nidentification of DNA sequence \"by triander\", which can be treated as a unique\n\"genogram\", \"gene passport\" is proposed. The two- and three-dimensional\ntrianders are considered. The difference of sequence fine structure in genes\nand the intergenic space is shown. A clear triplet signal in coding locuses is\nfound which is absent in the intergenic space and is independent from the\nsequence length. The topological classification of trianders is presented which\ncan allow us to provide a detail working out signatures of functionally\ndifferent genomic regions.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0311014v2"
    },
    {
        "title": "Modularity \"for free\" in genome architecture?",
        "authors": [
            "Ricard V. Sole",
            "Pau Fernandez"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  Background: Recent models of genome-proteome evolution have shown that some\nof the key traits displayed by the global structure of cellular networks might\nbe a natural result of a duplication-diversification (DD) process. One of the\nconsequences of such evolution is the emergence of a small world architecture\ntogether with a scale-free distribution of interactions. Here we show that the\ndomain of parameter space were such structure emerges is related to a phase\ntransition phenomenon. At this transition point, modular architecture\nspontaneously emerges as a byproduct of the DD process.\n  Results: Although the DD models lack any functionality and are thus free from\nmeeting functional constraints, they show the observed features displayed by\nthe real proteome maps when tuned close to a sharp transition point separating\na highly connected graph from a disconnected system. Close to such boundary,\nthe maps are shown to display scale-free hierarchical organization, behave as\nsmall worlds and exhibit modularity.\n  Conclusions: It is conjectured that natural selection tuned the average\nconnectivity in such a way that the network reaches a sparse graph of\nconnections. One consequence of such scenario is that the scaling laws and the\nessential ingredients for building a modular net emerge for free close to such\ntransition.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0312032v1"
    },
    {
        "title": "Increasing biological complexity is positively correlated with the\n  relative genome-wide expansion of non-protein-coding DNA sequences",
        "authors": [
            "R. J. Taft",
            "J. S. Mattick"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Background: Prior to the current genomic era it was suggested that the number\nof protein-coding genes that an organism made use of was a valid measure of its\ncomplexity. It is now clear, however, that major incongruities exist and that\nthere is only a weak relationship between biological complexity and the number\nof protein coding genes. For example, using the protein-coding gene number as a\nbasis for evaluating biological complexity would make urochordates and insects\nless complex than nematodes, and humans less complex than rice. Results: We\nanalyzed the ratio of noncoding to total genomic DNA (ncDNA/tgDNA) for 85\nsequenced species and found that this ratio correlates well with increasing\nbiological complexity. The ncDNA/tgDNA ratio is generally contained within the\nbandwidth of 0.05-0.24 for prokaryotes, but rises to 0.26-0.52 in unicellular\neukaryotes, and to 0.62-0.985 for developmentally complex multicellular\norganisms. Significantly, prokaryotic species display a non-uniform species\ndistribution approaching the mean of 0.1177 ncDNA/tgDNA (p=1.58 x 10^-13), and\na nonlinear ncDNA/tgDNA relationship to genome size (r=0.15). Importantly, the\nncDNA/tgDNA ratio corrects for ploidy, and is not substantially affected by\nvariable loads of repetitive sequences. Conclusions: We suggest that the\nobserved noncoding DNA increases and compositional patterns are primarily a\nfunction of increased information content. It is therefore possible that\nintrons, intergenic sequences, repeat elements, and genomic DNA previously\nregarded as genetically inert may be far more important to the evolution and\nfunctional repertoire of complex organisms than has been previously\nappreciated.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0401020v1"
    },
    {
        "title": "Online tool for the discrimination of equi-distributions",
        "authors": [
            "Thorsten Poeschel",
            "Cornelius Froemmel",
            "Christoph Gille"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  For many applications one wishes to decide whether a certain set of numbers\noriginates from an equiprobability distribution or whether they are unequally\ndistributed. Distributions of relative frequencies may deviate significantly\nfrom the corresponding probability distributions due to finite sample effects.\nHence, it is not trivial to discriminate between an equiprobability\ndistribution and non-equally distributed probabilities when knowing only\nfrequencies. Based on analytical results we provide a software tool which\nallows to decide whether data correspond to an equiprobability distribution.\nThe tool is available at http://bioinf.charite.de/equifreq/. Its application is\ndemonstrated for the distribution of point mutations in coding genes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0401041v1"
    },
    {
        "title": "Functional Bias and Spatial Organization of Genes in Mutational Hot and\n  Cold Regions in the Human Genome",
        "authors": [
            "Jeffrey H. Chuang",
            "Hao Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  The neutral mutation rate is known to vary widely along human chromosomes,\nleading to mutational hot and cold regions. We provide evidence that categories\nof functionally-related genes reside preferentially in mutationally hot or cold\nregions, the size of which we have measured. Genes in hot regions are biased\ntoward extra-cellular communication (surface receptors, cell adhesion, immune\nresponse, etc.) while those in cold regions are biased toward essential\ncellular processes (gene regulation, RNA processing, protein modification,\netc.). From a selective perspective, this organization of genes could minimize\nthe mutational load on genes that need to be conserved and allow fast evolution\nfor genes that must frequently adapt. We also analyze the effect of gene\nduplication and chromosomal recombination, which contribute significantly to\nthese biases for certain categories of hot genes. Overall, our results show\nthat genes are located non-randomly with respect to hot and cold regions,\noffering the possibility that selection acts at the level of gene location in\nthe human genome.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0402006v1"
    },
    {
        "title": "Long-range correlation in the whole human genome",
        "authors": [
            "R. Mansilla",
            "N. Del Castillo",
            "T. Govezensky",
            "P. Miramontes",
            "M. Jose",
            "G. Coch"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  We calculate the mutual information function for each of the 24 chromosomes\nin the human genome. The same correlation pattern is observed regardless the\nindividual functional features of each chromosome. Moreover, correlations of\ndifferent scale length are detected depicting a multifractal scenario. This\nfact suggest a unique mechanism of structural evolution. We propose that such a\nmechanism could be an expansion-modification dynamical system.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0402043v1"
    },
    {
        "title": "Gene-history correlation and population structure",
        "authors": [
            "A. Eriksson",
            "B. Mehlig"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Correlation of gene histories in the human genome determines the patterns of\ngenetic variation (haplotype structure) and is crucial to understanding genetic\nfactors in common diseases. We derive closed analytical expressions for the\ncorrelation of gene histories in established demographic models for genetic\nevolution and show how to extend the analysis to more realistic (but more\ncomplicated) models of demographic structure. We identify two contributions to\nthe correlation of gene histories in divergent populations: linkage\ndisequilibrium, and differences in the demographic history of individuals in\nthe sample. These two factors contribute to correlations at different length\nscales: the former at small, and the latter at large scales. We show that\nrecent mixing events in divergent populations limit the range of correlations\nand compare our findings to empirical results on the correlation of gene\nhistories in the human genome.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0402047v2"
    },
    {
        "title": "Alternative Splicing and Genomic Stability",
        "authors": [
            "Kevin Cahill"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Alternative splicing allows an organism to make different proteins in\ndifferent cells at different times, all from the same gene. In a cell that uses\nalternative splicing, the total length of all the exons is much shorter than in\na cell that encodes the same set of proteins without alternative splicing. This\neconomical use of exons makes genes more stable during reproduction and\ndevelopment because a genome with a shorter exon length is more resistant to\nharmful mutations. Genomic stability may be the reason why higher vertebrates\nsplice alternatively. For a broad class of alternatively spliced genes, a\nformula is given for the increase in their stability.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0403039v2"
    },
    {
        "title": "Variations in Substitution Rate in Human and Mouse Genomes",
        "authors": [
            "H. H. von Grünberg",
            "M. Kollmann"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  We present a method to quantify spatial fluctuations of the substitution rate\non different length scales throughout genomes of eukaryotes. The fluctuations\non large length scales are found to be predominantly a consequence of a\ncoarse-graining effect of fluctuations on shorter length scales. This is\nverified for both the mouse and the human genome. We also found that both\nspecies show similar standard deviation of fluctuations even though their mean\nsubstitution rate differs by a factor of two. Our method furthermore allows to\ndetermine time-resolved substitution rate maps from which we can compute\nauto-correlation functions in order to quantify how fast the spatial\nfluctuations in substitution rate change in time.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0403044v1"
    },
    {
        "title": "Modulation of Base Specific Mutation and Recombination Rates Enables\n  Functional Adaptation within the Context of the Genetic Code",
        "authors": [
            "Taison Tan",
            "Leonard D. Bogarad",
            "Michael W. Deem"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  The persistence of life requires populations to adapt at a rate commensurate\nwith the dynamics of their environment. Successful populations that inhabit\nhighly variable environments have evolved mechanisms to increase the likelihood\nof successful adaptation. We introduce a $64 \\times 64$ matrix to quantify\nbase-specific mutation potential, analyzing four different replicative systems,\nerror-prone PCR, mouse antibodies, a nematode, and Drosophila. Mutational\ntendencies are correlated with the structural evolution of proteins. In systems\nunder strong selective pressure, mutational biases are shown to favor the\nadaptive search of space, either by base mutation or by recombination. Such\nadaptability is discussed within the context of the genetic code at the levels\nof replication and codon usage.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0404022v1"
    },
    {
        "title": "Scaling laws in the functional content of genomes: Fundamental constants\n  of evolution?",
        "authors": [
            "Erik van Nimwegen"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  With the number of fully-sequenced genomes now well over a hundred it has\nbecome possible to start investigating if there are any quantitative\nregularities in the genetic make-up of genomes. In (physics/0307001), I\noriginally showed that the numbers of genes in different functional categories\nscale as power laws in the total number of genes in the genome. In this chapter\nI revisit these results with more recent data and go into considerable more\ndepth regarding the implications of these scaling laws for our understanding of\nthe regulatory design of cells. In addition, I further develop the evolutionary\nmodel first proposed in (physics/0307001), which suggests that the exponents of\nthe observed scaling laws correspond to fundamental constants of the\nevolutionary process. In particular, I put forward an hypothesis for the\napproximately quadratic scaling of regulatory and signal transducing genes with\ngenome size.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0405022v1"
    },
    {
        "title": "Biological Profiling of Gene Groups utilizing Gene Ontology",
        "authors": [
            "Nils Blüthgen",
            "Karsten Brand",
            "Branka Čajavec",
            "Maciej Swat",
            "Hanspeter Herzel",
            "Dieter Beule"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Increasingly used high throughput experimental techniques, like DNA or\nprotein microarrays give as a result groups of interesting, e.g. differentially\nregulated genes which require further biological interpretation. With the\nsystematic functional annotation provided by the Gene Ontology the information\nrequired to automate the interpretation task is now accessible. However, the\ndetermination of statistical significant e.g. molecular functions within these\ngroups is still an open question. In answering this question, multiple testing\nissues must be taken into account to avoid misleading results. Here we present\na statistical framework that tests whether functions, processes or locations\ndescribed in the Gene Ontology are significantly enriched within a group of\ninteresting genes when compared to a reference group. First we define an exact\nanalytical expression for the expected number of false positives that allows us\nto calculate adjusted p-values to control the false discovery rate. Next, we\ndemonstrate and discuss the capabilities of our approach using publicly\navailable microarray data on cell-cycle regulated genes. Further, we analyze\nthe robustness of our framework with respect to the exact gene group\ncomposition and compare the performance with earlier approaches. The software\npackage GOSSIP implements our method and is made freely available at\nhttp://gossip.gene-groups.net/\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0407034v2"
    },
    {
        "title": "The Shift-Match Number and String Matching Probabilities for Binary\n  Sequences",
        "authors": [
            "A. H. Bilge",
            "A. Erzan",
            "D. Balcan"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  We define the ``shift-match number'' for a binary string and we compute the\nprobability of occurrence of a given string as a subsequence in longer strings\nin terms of its shift-match number. We thus prove that the string matching\nprobabilities depend not only on the length of shorter strings, but also on the\nequivalence class of the shorter string determined by its shift-match number.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0409023v1"
    },
    {
        "title": "Characterizing large scale base composition structures of genomes",
        "authors": [
            "Zhengqing Ouyang",
            "Jian Liu",
            "Zhen-Su She"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Intermittent density fluctuations of nucleotide molecules (adenine, guanine,\ncytosine and thymine) along DNA sequences are studied in the framework of a\nhierarchical structure (HS) model originally proposed for the study of fully\ndeveloped turbulence [She and Leque, Phys. Rev. Lett. 72}, 336 (1994)]. Large\nscale (10^3 < \\ell < 10^5 bp) base density fluctuation is shown to satisfy the\nHS similarity. The derived values of a HS parameter $\\beta$ from a large number\nof genome data (including Bacteria, Archaea, human chromosomes and viruses)\ncharacterize different biological properties such as strand symmetry,\nphylogenetic relations and horizontal gene transfer. It is suggested that the\nHS analysis offers a useful quantitative description for heterogeneity,\nsequence complexity and large scale structures of genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0409027v2"
    },
    {
        "title": "An Unusual 500,000 Bases Long Oscillation of Guanine and Cytosine\n  Content in Human Chromosome 21",
        "authors": [
            "Wentian Li",
            "Dirk Holste"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  An oscillation with a period of around 500 kb in guanine and cytosine content\n(GC%) is observed in the DNA sequence of human chromosome 21. This oscillation\nis localized in the rightmost one-eighth region of the chromosome, from 43.5 Mb\nto 46.5 Mb. Five cycles of oscillation are observed in this region with six\nGC-rich peaks and five GC-poor valleys. The GC-poor valleys comprise regions\nwith low density of CpG islands and, alternating between the two DNA strands,\nlow gene density regions. Consequently, the long-range oscillation of GC%\nresult in spacing patterns of both CpG island density, and to a lesser extent,\ngene densities.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0411015v1"
    },
    {
        "title": "Subtree power analysis finds optimal species for comparative genomics",
        "authors": [
            "Jon D. McAuliffe",
            "Michael I. Jordan",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Sequence comparison across multiple organisms aids in the detection of\nregions under selection. However, resource limitations require a prioritization\nof genomes to be sequenced. This prioritization should be grounded in two\nconsiderations: the lineal scope encompassing the biological phenomena of\ninterest, and the optimal species within that scope for detecting functional\nelements. We introduce a statistical framework for optimal species subset\nselection, based on maximizing power to detect conserved sites. In a study of\nvertebrate species, we show that the optimal species subset is not in general\nthe most evolutionarily diverged subset. Our results suggest that marsupials\nare prime sequencing candidates.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0412012v1"
    },
    {
        "title": "A Solvable Sequence Evolution Model and Genomic Correlations",
        "authors": [
            "Philipp W. Messer",
            "Peter F. Arndt",
            "Michael Lässig"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We study a minimal model for genome evolution whose elementary processes are\nsingle site mutation, duplication and deletion of sequence regions and\ninsertion of random segments. These processes are found to generate long-range\ncorrelations in the composition of letters as long as the sequence length is\ngrowing, i.e., the combined rates of duplications and insertions are higher\nthan the deletion rate. For constant sequence length, on the other hand, all\ninitial correlations decay exponentially. These results are obtained\nanalytically and by simulations. They are compared with the long-range\ncorrelations observed in genomic DNA, and the implications for genome evolution\nare discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501010v1"
    },
    {
        "title": "Are scale-free regulatory networks larger than random ones?",
        "authors": [
            "Miguel A. Fortuna",
            "Carlos J. Melian"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Network of packages with regulatory interactions (dependences and conflicts)\nfrom Debian GNU/Linux operating system is compiled and used as analogy of a\ngene regulatory network. Using a trace-back algorithm we assembly networks from\nthe potential pool of packages for both scale-free and exponential topology\nfrom real and a null model data, respectively. We calculate the maximum number\nof packages that can be functionally installed in the system (i.e., the active\nnetwork size). We show that scale-free regulatory networks allow a larger\nactive network size than random ones. Small genomes with scale-free regulatory\ntopology could allow much more functionality than large genomes with an\nexponential one, with implications on its dynamics, robustness and evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501027v1"
    },
    {
        "title": "tRNA-alike in Nanoarchaeum equitans ?",
        "authors": [
            "Bibekanand Mallick",
            "Jayprokas Chakrabarti",
            "Zhumur Ghosh",
            "Smarajit Das",
            "Satyabrata Sahoo"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The recent algorithm for five split tRNA-genes in N.equitans is new . It\nlocates missing tRNA-trp, tRNA-imet, tRNA-glu and tRNA-his . But the split\ntRNA-trp(CCA) solution is anomalous ; the tRNA-imet lacks cognition elements\nfor aminoacylation . In view therefore we present here alternate non-split\ncomposite solutions for tRNA-trp, tRNA-imet, tRNA-glu and tRNA-his .\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0504034v1"
    },
    {
        "title": "Weighted-Codon-Usage Based Phylogeny In Ectocarpales",
        "authors": [
            "Smarajit Das",
            "Jayprokas Chakrabarti",
            "Zhumur Ghosh",
            "Satyabrata Sahoo",
            "Bibekanand Mallick"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We analyse forty seven chloroplastid genes of the large subunit of RuBisCO,\nfrom the Algal order Ectocarpales, sourced from GenBank. Codon-usage weighted\nby the nucleotide base bias defines our score called the\nCodon-Impact-Parameter. This score is used to obtain phylogenetic relations\namongst the 47 Ectocarpales. We compare our classification with the ones done\nearlier.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0506003v1"
    },
    {
        "title": "Modeling genome evolution with a diffusion approximation of a\n  birth-and-death process",
        "authors": [
            "Georgy P. Karev",
            "Faina S. Berezovskaya",
            "Eugene V. Koonin"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  In our previous studies, we developed discrete-space Birth, Death and\nInnovation Models (BDIM) of genome evolution. These models explain the origin\nof the characteristic Pareto distribution of paralogous gene family sizes in\ngenomes, and model parameters that provide for the evolution of these\ndistributions within a realistic timeframe have been identified. Here we\ndevelop the diffusion version of BDIM whose dynamics is described by the\nFokker-Plank equation and the stationary solution could be any specified Pareto\nfunction. The diffusion models have time-dependent solutions of a special kind,\nnamely, the generalized self-similar solutions, which describe the transition\nfrom one stationary distribution of the system to another; this provides for\nthe possibility of examining the temporal dynamics of genome evolution.\nAnalysis of the generalized self-similar solutions of the diffusion BDIM\nreveals a biphasic curve of genome growth in which the initial, relatively\nshort, self-accelerating phase is followed by a prolonged phase of slow\ndeceleration. In biological terms, this regime of evolution can be tentatively\ninterpreted as a punctuated-equilibrium-like phenomenon such that whereby\nevolutionary transitions are accompanied by rapid gene amplification and\ninnovation, followed by slow relaxation to a new stationary state.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0507019v1"
    },
    {
        "title": "Simple stochastic birth and death models of genome evolution: Was there\n  enough time for us to evolve?",
        "authors": [
            "Georgy P. Karev",
            "Yuri I. Wolf",
            "Eugene V. Koonin"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We show that simple stochastic models of genome evolution lead to power law\nasymptotics of protein domain family size distribution. These models, called\nBirth, Death and Innovation Models (BDIM), represent a special class of\nbalanced birth-and-death processes, in which domain duplication and deletion\nrates are asymptotically equal up to the second order. The simplest, linear\nBDIM shows an excellent fit to the observed distributions of domain family size\nin diverse prokaryotic and eukaryotic genomes. However, the stochastic version\nof the linear BDIM explored here predicts that the actual size of large\nparalogous families is reached on an unrealistically long timescale. We show\nthat introduction of non-linearity, which might be interpreted as interaction\nof a particular order between individual family members, allows the model to\nachieve genome evolution rates that are much better compatible with the current\nestimates of the rates of individual duplication/loss events.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0507020v1"
    },
    {
        "title": "Parameters of proteome evolution from histograms of amino-acid sequence\n  identities of paralogous proteins",
        "authors": [
            "Jacob Bock Axelsen",
            "Koon-Kiu Yan",
            "Sergei Maslov"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The evolution of the full repertoire of proteins encoded in a given genome is\nmostly driven by gene duplications, deletions, and sequence modifications of\nexisting proteins. Indirect information about relative rates and other\nintrinsic parameters of these three basic processes is contained in the\nproteome-wide distribution of sequence identities of pairs of paralogous\nproteins. We introduce a simple mathematical framework based on a stochastic\nbirth-and-death model that allows one to extract some of this information and\napply it to the set of all pairs of paralogous proteins in seven model\norganisms. It was found that the histogram of sequence identities p generated\nby an all-to-all alignment of all protein sequences encoded in a genome is well\nfitted with a power-law form ~p^(-gamma) with the value of the exponent gamma\naround 4 for the majority of organisms used in this study. This implies that\nthe intra-protein variability of substitution rates is best described by the\nGamma-distribution with the exponent alpha ~ 0.33. We separately measure the\nshort-term (``raw'') duplication and deletion rates r*_dup, r*_del which\ninclude gene copies that will be removed soon after the duplication event and\ntheir dramatically reduced long-term counterparts r_dup, r_del. Systematic\ntrends of each of the four duplication/deletion rates with the total number of\ngenes in the genome were analyzed. All but the deletion rate of recent\nduplicates r*_del were shown to systematically increase with N_genes.\nAbnormally flat shapes of sequence identity histograms observed for yeast and\nhuman are consistent with lineages leading to these organisms undergoing one or\nmore whole-genome duplications.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0507032v2"
    },
    {
        "title": "On the Complexity of the Single Individual SNP Haplotyping Problem",
        "authors": [
            "Rudi Cilibrasi",
            "Leo van Iersel",
            "Steven Kelk",
            "John Tromp"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We present several new results pertaining to haplotyping. These results\nconcern the combinatorial problem of reconstructing haplotypes from incomplete\nand/or imperfectly sequenced haplotype fragments. We consider the complexity of\nthe problems Minimum Error Correction (MEC) and Longest Haplotype\nReconstruction (LHR) for different restrictions on the input data.\nSpecifically, we look at the gapless case, where every row of the input\ncorresponds to a gapless haplotype-fragment, and the 1-gap case, where at most\none gap per fragment is allowed. We prove that MEC is APX-hard in the 1-gap\ncase and still NP-hard in the gapless case. In addition, we question earlier\nclaims that MEC is NP-hard even when the input matrix is restricted to being\ncompletely binary. Concerning LHR, we show that this problem is NP-hard and\nAPX-hard in the 1-gap case (and thus also in the general case), but is\npolynomial time solvable in the gapless case.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0508012v2"
    },
    {
        "title": "Mathematical modeling of evolution of horizontally transferred genes",
        "authors": [
            "Artem S. Novozhilov",
            "Georgy P. Karev",
            "Eugene V. Koonin"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We describe a stochastic birth-and-death model of evolution of horizontally\ntransferred genes in microbial populations. The model is a generalization of\nthe stochastic model described by Berg and Kurland and includes five\nparameters: the rate of mutational inactivation, selection coefficient,\nimmigration rate (i.e., rate of arrival of a novel sequence from outside of the\nrecipient population), within-population horizontal transmission rate, and\npopulation size. The model of Berg and Kurland included four parameters,\nnamely, mutational inactivation, selection coefficient, population size, and\ntransmission rate. However, the effect of transmission was disregarded in the\ninterpretation of the results, and the overall conclusion was that horizontally\nacquired sequences can be fixed in a population only when they confer a\nsubstantial selective advantage onto the recipient and therefore are subject to\nstrong positive selection. By contrast, analysis of the present model in\ndifferent domains of parameter values shows that, as long as the rate of\nwithin-population horizontal transmission is comparable to the mutational\ninactivation rate and there is even a low rate of immigration, horizontally\nacquired sequences can be fixed in the population or at least persist for a\nlong time even when they are neutral or slightly deleterious. The available\nbiological data strongly suggest that intense within-population and even\nbetween-populations gene flows are realistic for at least some prokaryotic\nspecies and environments. Therefore our modeling results are compatible with\nthe notion of a pivotal role of horizontal gene transfer in the evolution of\nprokaryotes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0509010v1"
    },
    {
        "title": "Vector space of DNA genomic sequences on a Genetic Code Galois Field",
        "authors": [
            "Robersy Sanchez",
            "Eberto R Morgado",
            "Ricardo Grau"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  A new N-dimensional vector space of DNA sequences over the Galois field of\nthe 64 codons (GF(64)) was recently presented. Now, in order to include\ndeletions and insertions (indel mutations), we have defined a new Galois field\nover the set of elements X1X2X3 (C125), where Xi belong to {O, A, C, G, C}. We\nhave called this set, the extended triplet set and the elements X1X2X3, the\nextended triplets. The order of the bases is derived from the Z64-algebra of\nthe genetic code -recently published-. Starting from the natural bijection phi:\nGF(5^3)-> C125 between the polynomial representation of elements from GF(5^3)\nand the elements X1X2X3, a novel Galois field over the set of elements X1X2X3\nis defined. Taking the polynomial coefficients a0, a1, a2 belong to GF(5) and\nthe bijective function f: GF(5) ->{O, A, C, G, C}, where f(0) = O, f(1) = A,\nf(2) = C, f(3) = G, f(4) = U, bijection phi is induced such that phi(a0 + a1x +\na2x^2) = (f(a1), f(a2), f(a0)) = (X1X2X3). Next, by means of the bijection phi\nwe define sum \"+\" and product \"*\" operations in the set of codons C125, in such\na way that the resultant field (C125, +, *) turns isomorphic to the Galois\nField GF(5^3). This field allows the definition of a novel N-dimensional vector\nspace (S) over the field GF (5^3) on the set of all 125^N sequences of extended\ntriplets in which all possible DNA sequence alignments of length N are\nincluded. Here the \"classical gap\" produced by alignment algorithms corresponds\nto the neutral element \"O\". It is verified that the homologous (generalized)\nrecombination between two homologous DNA duplexes involving a reciprocal\nexchange of DNA sequences -e.g. between two chromosomes that carry the same\ngenetic loci- algebraically corresponds to the action of two automorphism pairs\n(or two translation pairs) over two paired DNA duplexes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0510029v1"
    },
    {
        "title": "Impact of Tandem Repeats on the Scaling of Nucleotide Sequences",
        "authors": [
            "Radhakrishnan Nagarajan",
            "Meenakshi Upreti"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Techniques such as detrended fluctuation analysis (DFA) and its extensions\nhave been widely used to determine the nature of scaling in nucleotide\nsequences. In this brief communication we show that tandem repeats which are\nubiquitous in nucleotide sequences can prevent reliable estimation of possible\nlong-range correlations. Therefore, it is important to investigate the presence\nof tandem repeats prior to scaling exponent estimation.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0510042v1"
    },
    {
        "title": "An Algorithm for Missing Value Estimation for DNA Microarray Data",
        "authors": [
            "Shmuel Friedland",
            "Mostafa Kaveh",
            "Amir Niknejad",
            "Hossein Zare"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Gene expression data matrices often contain missing expression values. In\nthis paper, we describe a new algorithm, named improved fixed rank\napproximation algorithm (IFRAA), for missing values estimations of the large\ngene expression data matrices. We compare the present algorithm with the two\nexisting and widely used methods for reconstructing missing entries for DNA\nmicroarray gene expression data: the Bayesian principal component analysis\n(BPCA) and the local least squares imputation method (LLS). The three\nalgorithms were applied to four microarray data sets and two synthetic low-rank\ndata matrices. Certain percentages of the elements of these data sets were\nrandomly deleted, and the three algorithms were used to recover them. In\nconclusion IFRAA appears to be the most reliable and accurate approach for\nrecovering missing DNA microarray gene expression data, or any other noisy data\nmatrices that are effectively low rank.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0510047v1"
    },
    {
        "title": "Gene expression analysis reveals a strong signature of an interferon\n  induced pathway in childhood lymphoblastic leukemia as well as in breast and\n  ovarian cancer",
        "authors": [
            "Uri Einav",
            "Yuval Tabach",
            "Gad Getz",
            "Assif Yitzhaky",
            "Ugur Ozbek",
            "Ninette Amariglio",
            "Shai Izraeli",
            "Gideon Rechavi",
            "Eytan Domany"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  On the basis of epidemiological studies, infection was suggested to play a\nrole in the etiology of human cancer. While for some cancers such a role was\nindeed demonstrated, there is no direct biological support for the role of\nviral pathogens in the pathogenesis of childhood leukemia. Using a novel\nbioinformatic tool, that alternates between clustering and standard statistical\nmethods of analysis, we performed a \"double blind\" search of published gene\nexpression data of subjects with different childhood ALL subtypes, looking for\nunanticipated partitions of patients, induced by unexpected groups of genes\nwith correlated expression. We discovered a group of about thirty genes,\nrelated to the interferon response pathway, whose expression levels divide the\nALL samples into two subgroups; high in 50, low in 285 patients. Leukemic\nsubclasses prevalent in early childhood (the age most susceptible to infection)\nare over-represented in the high expression subgroup. Similar partitions,\ninduced by the same genes, were found also in breast and ovarian cancer but not\nin lung cancer, prostate cancer and lymphoma. About 40% of breast cancer\nsamples expressed the \"interferon- related\" signature. It is of interested that\nseveral studies demonstrated MMTV-like sequences in about 40% of breast cancer\nsamples. Our discovery of an unanticipated strong signature of an interferon\ninduced pathway provides molecular support for a role for either inflammation\nor viral infection in the pathogenesis of childhood leukemia as well as breast\nand ovarian cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0511017v1"
    },
    {
        "title": "Correlation Statistics for cDNA Microarray Image Analysis",
        "authors": [
            "Radhakrishnan Nagarajan",
            "Meenakshi Upreti"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  In this report, correlation of the pixels comprising a microarray spot is\ninvestigated. Subsequently, correlation statistics namely: Pearson correlation\nand Spearman rank correlation are used to segment the foreground and background\nintensity of microarray spots. The performance of correlation-based\nsegmentation is compared to clustering-based (PAM, k-means) and seeded-region\ngrowing techniques (SPOT). It is shown that correlation-based segmentation is\nuseful in flagging poorly hybridized spots, thus minimizes false-positives. The\npresent study also raises the intriguing question of whether a change in\ncorrelation can be an indicator of differential gene expression.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0511030v1"
    },
    {
        "title": "Parametric inference of recombination in HIV genomes",
        "authors": [
            "Niko Beerenwinkel",
            "Colin N. Dewey",
            "Kevin M. Woods"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Recombination is an important event in the evolution of HIV. It affects the\nglobal spread of the pandemic as well as evolutionary escape from host immune\nresponse and from drug therapy within single patients. Comprehensive\ncomputational methods are needed for detecting recombinant sequences in large\ndatabases, and for inferring the parental sequences.\n  We present a hidden Markov model to annotate a query sequence as a\nrecombinant of a given set of aligned sequences. Parametric inference is used\nto determine all optimal annotations for all parameters of the model. We show\nthat the inferred annotations recover most features of established hand-curated\nannotations. Thus, parametric analysis of the hidden Markov model is feasible\nfor HIV full-length genomes, and it improves the detection and annotation of\nrecombinant forms.\n  All computational results, reference alignments, and C++ source code are\navailable at http://bio.math.berkeley.edu/recombination/.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0512019v1"
    },
    {
        "title": "Is the intrinsic disorder of proteins the cause of the scale-free\n  architecture of protein-protein interaction networks?",
        "authors": [
            "Santiago Schnell",
            "Santo Fortunato",
            "Sourav Roy"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  In protein-protein interaction networks certain topological properties appear\nto be recurrent: networks maps are considered scale-free. It is possible that\nthis topology is reflected in the protein structure. In this paper we\ninvestigate the role of protein disorder in the network topology. We find that\nthe disorder of a protein (or of its neighbors) is independent of its number of\nprotein-protein interactions. This result suggests that protein disorder does\nnot play a role in the scale-free architecture of protein networks.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0606029v1"
    },
    {
        "title": "Probabilistic Regulatory Networks: Modeling Genetic Networks",
        "authors": [
            "Maria A. Avino-Diaz",
            "Oscar Moreno"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  We describe here the new concept of $\\epsilon$-Homomorphisms of Probabilistic\nRegulatory Gene Networks(PRN). The $\\epsilon$-homomorphisms are special\nmappings between two probabilistic networks, that consider the algebraic action\nof the iteration of functions and the probabilistic dynamic of the two\nnetworks. It is proved here that the class of PRN, together with the\nhomomorphisms, form a category with products and coproducts. Projections are\nspecial homomorphisms, induced by invariant subnetworks. Here, it is proved\nthat an $\\epsilon$-homomorphism for 0 <$\\epsilon$< 1 produces simultaneous\nMarkov Chains in both networks, that permit to introduce the concepts of\n$\\epsilon$-isomorphism of Markov Chains, and similar networks.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0606032v1"
    },
    {
        "title": "Distance based Inference for Gene-Ontology Analysis of Microarray\n  Experiments",
        "authors": [
            "Alex Sanchez-Pla",
            "Miquel Salicru",
            "Jordi Ocanya"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  The increasing availability of high throughput data arising from gene\nexpression studies leads to the necessity of methods for summarizing the\navailable information. As annotation quality improves it is becoming common to\nrely on the Gene Ontology (GO) to build functional profiles that characterize a\nset of genes using the frequency of use of each GO term or group of terms in\nthe array. In this work we describe a statistical model for such profiles,\nprovide methods to compare profiles and develop inferential procedures to\nassess this comparison. An R-package implementing the methods is available.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0607026v1"
    },
    {
        "title": "Asterias: a parallelized web-based suite for the analysis of expression\n  and aCGH data",
        "authors": [
            "Andreu Alibes",
            "Edward R. Morrissey",
            "Andres Canada",
            "Oscar M. Rueda",
            "David Casado",
            "Patricio Yankilevich",
            "Ramon Diaz-Uriarte"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Asterias (\\url{http://www.asterias.info}) is an integrated collection of\nfreely-accessible web tools for the analysis of gene expression and aCGH data.\nMost of the tools use parallel computing (via MPI). Most of our applications\nallow the user to obtain additional information for user-selected genes by\nusing clickable links in tables and/or figures. Our tools include:\nnormalization of expression and aCGH data; converting between different types\nof gene/clone and protein identifiers; filtering and imputation; finding\ndifferentially expressed genes related to patient class and survival data;\nsearching for models of class prediction; using random forests to search for\nminimal models for class prediction or for large subsets of genes with\npredictive capacity; searching for molecular signatures and predictive genes\nwith survival data; detecting regions of genomic DNA gain or loss. The\ncapability to send results between different applications, access to additional\nfunctional information, and parallelized computation make our suite unique and\nexploit features only available to web-based applications.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0610039v1"
    },
    {
        "title": "Information Theory of Genomes",
        "authors": [
            "Dmitri V. Parkhomchuk"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Relation of genome sizes to organisms complexity is still described rather\nequivocally. Neither the number of genes (G-value), nor the total amount of DNA\n(C-value) correlates consistently with phenotype complexity. Using information\ntheory considerations we developed a model that allows a quantative estimate\nfor the amount of functional information in a genomic sequence. This model\neasily answers the long-standing question of why GC content is increased in\nfunctional regions. The model allows consistent estimate of genome\ncomplexities, resolving the major discrepancies of G- and C-values. For related\norganisms with similarly complex phenotypes, this estimate provides biological\ninsights into their niches complexities. This theoretical framework suggests\nthat biological information can rapidly evolve on demand from environment,\nmainly in non-coding genomic sequence and explains the role of duplications in\nthe evolution of biological information. Knowing the approximate amount of\nfunctionality in a genomic sequence is useful for many applications such as\nphylogenetics analyses, in-silico functional elements discovery or prioritising\ntargets for genotyping and sequencing.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0612038v2"
    },
    {
        "title": "An introduction to reconstructing ancestral genomes",
        "authors": [
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Recent advances in high-throughput genomics technologies have resulted in the\nsequencing of large numbers of (near) complete genomes. These genome sequences\nare being mined for important functional elements, such as genes. They are also\nbeing compared and contrasted in order to identify other functional sequences,\nsuch as those involved in the regulation of genes. In cases where DNA sequences\nfrom different organisms can be determined to have originated from a common\nancestor, it is natural to try to infer the an- cestral sequences. The\nreconstruction of ancestral genomes can lead to insights about genome\nevolution, and the origins and diversity of function. There are a number of\ninteresting foundational questions associated with reconstructing ancestral\ngenomes: Which statistical models for evolution should be used for making\ninferences about ancestral sequences? How should extant genomes be compared in\norder to facilitate ancestral reconstruction? Which portions of ancestral\ngenomes can be reconstructed reliably, and what are the limits of ancestral\nreconstruction? We discuss recent progress on some of these questions, offer\nsome of our own opinions, and highlight interesting mathematics, statistics,\nand computer science problems.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0612046v1"
    },
    {
        "title": "MicroRNAs preferentially target the genes with high transcriptional\n  regulation complexity",
        "authors": [
            "Qinghua Cui",
            "Zhenbao Yu",
            "Youlian Pan",
            "Enrico Purisima",
            "Edwin Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Over the past few years, microRNAs (miRNAs) have emerged as a new prominent\nclass of gene regulatory factors that negatively regulate expression of\napproximately one-third of the genes in animal genomes at post-transcriptional\nlevel. However, it is still unclear why some genes are regulated by miRNAs but\nothers are not, i.e. what principles govern miRNA regulation in animal genomes.\nIn this study, we systematically analyzed the relationship between\ntranscription factors (TFs) and miRNAs in gene regulation. We found that the\ngenes with more TF-binding sites have a higher probability of being targeted by\nmiRNAs and have more miRNA-binding sites on average. This observation reveals\nthat the genes with higher cis-regulation complexity are more coordinately\nregulated by TFs at the transcriptional level and by miRNAs at the\npost-transcriptional level. This is a potentially novel discovery of mechanism\nfor coordinated regulation of gene expression. Gene ontology analysis further\ndemonstrated that such coordinated regulation is more popular in the\ndevelopmental genes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0701001v1"
    },
    {
        "title": "A Pattern Discovery-Based Method for Detecting Multi-Locus Genetic\n  Association",
        "authors": [
            "Zhong Li",
            "Aris Floratos",
            "David Wang",
            "Andrea Califano"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Methods to effectively detect multi-locus genetic association are becoming\nincreasingly relevant in the genetic dissection of complex trait in humans.\nCurrent approaches typically consider a limited number of hypotheses, most of\nwhich are related to the effect of a single locus or of a relatively small\nnumber of neighboring loci on a chromosomal region. We have developed a novel\nmethod that is specifically designed to detect genetic association involving\nmultiple disease-susceptibility loci, possibly on different chromosomes. Our\napproach relies on the efficient discovery of patterns comprising spatially\nunrestricted polymorphic markers and on the use of appropriate test statistics\nto evaluate pattern-trait association. Power calculations using multi-locus\ndisease models demonstrate significant gain of power by using this method in\ndetecting multi-locus genetic association when compared to a standard single\nmarker analysis method. When analyzing a Schizophrenia dataset, we confirmed a\npreviously identified gene-gene interaction. In addition, a less conspicuous\nassociation involving different markers on the same two genes was also\nidentified, implicating genetic heterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0703038v1"
    },
    {
        "title": "Inverted and mirror repeats in model nucleotide sequences",
        "authors": [
            "Fabrizio Lillo",
            "Marco Spanó"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We analytically and numerically study the probabilistic properties of\ninverted and mirror repeats in model sequences of nucleic acids. We consider\nboth perfect and non-perfect repeats, i.e. repeats with mismatches and gaps.\nThe considered sequence models are independent identically distributed (i.i.d.)\nsequences, Markov processes and long range sequences. We show that the number\nof repeats in correlated sequences is significantly larger than in i.i.d.\nsequences and that this discrepancy increases exponentially with the repeat\nlength for long range sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/0705.2143v1"
    },
    {
        "title": "Power-law Signatures and Patchiness in Genechip Oligonucleotide\n  Microarrays",
        "authors": [
            "Radhakrishnan Nagarajan"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  . Genechip oligonucleotide microarrays have been used widely for\ntranscriptional profiling of a large number of genes in a given paradigm. Gene\nexpression estimation precedes biological inference and is given as a complex\ncombination of atomic entities on the array called probes. These probe\nintensities are further classified into perfect-match (PM) and mis-match (MM)\nprobes. While former is a measure of specific binding, the lat-ter is a measure\nof non-specific binding. The behavior of the MM probes has especially proven to\nbe elusive. The present study investigates qualita-tive similarities in the\ndistributional signatures and local correlation struc-tures/patchiness between\nthe PM and MM probe intensities. These qualita-tive similarities are\nestablished on publicly available microarrays generated across laboratories\ninvestigating the same paradigm. Persistence of these similarities across raw\nas well as background subtracted probe intensities is also investigated. The\nresults presented raise fundamental concerns in inter-preting Genechip\noligonucleotide microarray data.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.1152v2"
    },
    {
        "title": "Units of genetic transfer in prokaryotes",
        "authors": [
            "Cheong Xin Chan",
            "Robert G. Beiko",
            "Mark A. Ragan"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  The transfer of genetic materials across species (lateral genetic transfer,\nLGT) contributes to genomic and physiological innovation in prokaryotes. The\nextent of LGT in prokaryotes has been examined in a number of studies, but the\nunit of transfer has not been studied in a rigorous manner. Using a rigorous\nphylogenetic approach, we analysed the units of LGT within families of\nsingle-copy genes obtained from 144 fully sequenced prokaryote genomes. A total\nof 30.3% of these gene families show evidence of LGT. We found that the\ntransfer of gene fragments has been more frequent than the transfer of entire\ngenes, suggesting the extent of LGT has been underestimated. We found little\nfunctional bias between within-gene (fragmentary) and whole-gene\n(non-fragmentary) genetic transfer, but non-fragmentary transfer has been more\nfrequent into pathogens than into non-pathogens. As gene families that contain\nprobable paralogs were excluded from the current study, our results may still\nunderestimate the extent of LGT; nonetheless this is the most-comprehensive\nstudy to date of the unit of LGT among prokaryote genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.2027v2"
    },
    {
        "title": "Protein domains as units of genetic transfer",
        "authors": [
            "Cheong Xin Chan",
            "Robert G. Beiko",
            "Aaron E. Darling",
            "Mark A. Ragan"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Genomes evolve as modules. In prokaryotes (and some eukaryotes), genetic\nmaterial can be transferred between species and integrated into the genome via\nhomologous or illegitimate recombination. There is little reason to imagine\nthat the units of transfer correspond to entire genes; however, such units have\nnot been rigorously characterized. We examined fragmentary genetic transfers in\nsingle-copy gene families from 144 prokaryotic genomes and found that\nbreakpoints are located significantly closer to the boundaries of genomic\nregions that encode annotated structural domains of proteins than expected by\nchance, particularly when recombining sequences are more divergent. This\ncorrelation results from recombination events themselves and not from\ndifferential nucleotide substitution. We report the first systematic study\nrelating genetic recombination to structural features at the protein level.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.2030v2"
    },
    {
        "title": "Genetic transfer in Staphylococcus: a case study of 13 genomes",
        "authors": [
            "Cheong Xin Chan",
            "Robert G. Beiko",
            "Mark A. Ragan"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  The widespread presence of antibiotic resistance and virulence among\nStaphylococcus isolates has been attributed to lateral genetic transfer (LGT)\nbetween different strains or species. However, there has been very little study\nof the extent of LGT in Staphylococcus species using a phylogenetic approach,\nparticularly of the units of such genetic transfer. Here we report the first\nsystematic study of the units of genetic transfer in 13 Staphylococcus genomes,\nusing a rigorous phylogenetic approach. We found clear evidence of LGT in 26.1%\nof the 1354 homologous gene families examined, and possibly more in another\n17.9% of the total families. Within-gene and whole-gene transfer contribute\nalmost equally to the discordance of these gene families against a reference\nphylogeny. Comparing genetic transfer in single-copy and in multi-copy gene\nfamilies, we found little functional bias in cases of within-gene (fragmentary)\ngenetic transfer but substantial functional bias in cases of whole-gene\n(non-fragmentary) genetic transfer, and we observed a higher frequency of LGT\nin multi-copy gene families. Our results demonstrate that LGT and gene\nduplication play an important part among the factors that contribute to\nfunctional innovation in staphylococcal genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.2031v2"
    },
    {
        "title": "Two distinct logical types of network control in gene expression\n  profiles",
        "authors": [
            "Carsten Marr",
            "Marcel Geertz",
            "Marc-Thorsten Huett",
            "Georgi Muskhelishvili"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  In unicellular organisms such as bacteria the same acquired mutations\nbeneficial in one environment can be restrictive in another. However, evolving\nEscherichia coli populations demonstrate remarkable flexibility in adaptation.\nThe mechanisms sustaining genetic flexibility remain unclear. In E. coli the\ntranscriptional regulation of gene expression involves both dedicated\nregulators binding specific DNA sites with high affinity and also global\nregulators - abundant DNA architectural proteins of the bacterial chromoid\nbinding multiple low affinity sites and thus modulating the superhelical\ndensity of DNA. The first form of transcriptional regulation is dominantly\npairwise and specific, representing digitial control, while the second form is\n(in strength and distribution) continuous, representing analog control. Here we\nlook at the properties of effective networks derived from significant gene\nexpression changes under variation of the two forms of control and find that\nupon limitations of one type of control (caused e.g. by mutation of a global\nDNA architectural factor) the other type can compensate for compromised\nregulation. Mutations of global regulators significantly enhance the digital\ncontrol; in the presence of global DNA architectural proteins regulation is\nmostly of the analog type, coupling spatially neighboring genomic loci;\ntogether our data suggest that two logically distinct types of control are\nbalancing each other. By revealing two distinct logical types of control, our\napproach provides basic insights into both the organizational principles of\ntranscriptional regulation and the mechanisms buffering genetic flexibility. We\nanticipate that the general concept of distinguishing logical types of control\nwill apply to many complex biological networks.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.3156v1"
    },
    {
        "title": "Copy Number Variants and Segmental Duplications Show Different Formation\n  Signatures",
        "authors": [
            "Philip M. Kim",
            "Jan O. Korbel",
            "Xueying Chen",
            "Mark B. Gerstein"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  In addition to variation in terms of single nucleotide polymorphisms (SNPs),\nwhole regions ranging from several kilobases up to a megabase in length differ\nin copy number among individuals. These differences are referred to as Copy\nNumber Variants (CNVs) and extensive mapping of these is underway. Recent\nstudies have highlighted their great prevalence in the human genome. Segmental\nDuplications (SDs) are long (>1kb) stretches of duplicated DNA with high\nsequence identity. First, we analyzed the co-localization of SDs and find that\nSDs are significantly co-localized with each other, resulting in a power-law\ndistribution, which suggests a preferential attachment mechanism, i.e. existing\nSDs are likely to be involved in creating new ones nearby. Second, we look at\nthe relationship of CNVs/SDs with various types of repeats. We we find that the\npreviously recognized association of SDs with Alu elements is significantly\nstronger for older SDs and is sharply decreasing for younger ones. While it\nmight be expected that the patterns should be similar for SDs and CNVs, we\nfind, surprisingly, no association of CNVs with Alu elements. This trend is\nconsistent with the decreasing correlation between Alu elements and younger\nSDs, the activity of Alu elements has been decreasing and by now it they seem\nno longer active. Furthermore, we find a striking association of SDs with\nprocessed pseudogenes suggesting that they may also have mediated SD formation.\nMoreover, find strong association with microsatellites for both SDs and CNVs\nthat suggests a role for satellites in the formation of both.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.4200v1"
    },
    {
        "title": "In silico network topology-based prediction of gene essentiality",
        "authors": [
            "Joao Paulo Muller da Silva",
            "Marcio Luis Acencio",
            "Jose Carlos Merino Mombach",
            "Renata Vieira",
            "Jose Guliherme Camargo da Silva",
            "Ney Lemke",
            "Marialva Sinigaglia"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  The identification of genes essential for survival is important for the\nunderstanding of the minimal requirements for cellular life and for drug\ndesign. As experimental studies with the purpose of building a catalog of\nessential genes for a given organism are time-consuming and laborious, a\ncomputational approach which could predict gene essentiality with high accuracy\nwould be of great value. We present here a novel computational approach, called\nNTPGE (Network Topology-based Prediction of Gene Essentiality), that relies on\nnetwork topology features of a gene to estimate its essentiality. The first\nstep of NTPGE is to construct the integrated molecular network for a given\norganism comprising protein physical, metabolic and transcriptional regulation\ninteractions. The second step consists in training a decision tree-based\nmachine learning algorithm on known essential and non-essential genes of the\norganism of interest, considering as learning attributes the network topology\ninformation for each of these genes. Finally, the decision tree classifier\ngenerated is applied to the set of genes of this organism to estimate\nessentiality for each gene. We applied the NTPGE approach for discovering\nessential genes in Escherichia coli and then assessed its performance.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.4206v1"
    },
    {
        "title": "Thermodynamics of DNA loops with long-range correlated structural\n  disorder",
        "authors": [
            "Cédric Vaillant",
            "Benjamin Audit",
            "Alain Arnéodo"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We study the influence of a structural disorder on the thermodynamical\nproperties of 2D-elastic chains submitted to mechanical/topological constraint\nas loops. The disorder is introduced via a spontaneous curvature whose\ndistribution along the chain presents either no correlation or long-range\ncorrelations (LRC). The equilibrium properties of the one-loop system are\nderived numerically and analytically for weak disorder. LRC are shown to favor\nthe formation of small loop, larger the LRC, smaller the loop size. We use the\nmean first passage time formalism to show that the typical short time loop\ndynamics is superdiffusive in the presence of LRC. Potential biological\nimplications on nucleosome positioning and dynamics in eukaryotic chromatin are\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4398v1"
    },
    {
        "title": "A simple computational method for the identification of\n  disease-associated loci in complex, incomplete pedigrees",
        "authors": [
            "Gregory Leibon",
            "Daniel Rockmore",
            "Martin Pollak"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We present an approach, called the \"Shadow Method,\" for the identification of\ndisease loci from dense genetic marker maps in complex, potentially incomplete\npedigrees. \"Shadow\" is a simple method based on an analysis of the patterns of\nobligate meiotic recombination events in genotypic data. This method can be\napplied to any high density marker map and was specifically designed to exploit\nthe fact that extremely dense marker maps are becoming more readily available.\nWe also describe how to interpret and associate meaningful P-Values to the\nresults. Shadow has significant advantages over traditional parametric linkage\nanalysis methods in that it can be readily applied even in cases in which the\ntopology of a pedigree or pedigrees can only be partially determined. In\naddition, Shadow is robust to variability in a range of parameters and in\nparticular does not require prior knowledge of mode of inheritance, penetrance\nor clinical misdiagnosis rate. Shadow can be used for any SNP data, but is\nespecially effective when applied to dense samplings. Our primary example uses\ndata from Affymetrix 100k SNPChip samples in which we illustrate our approach\nby analyzing simulated data as well as genome-wide SNP data from two pedigrees\nwith inherited forms of kidney failure, one of which is compared with a typical\nLOD score analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.5625v1"
    },
    {
        "title": "Comparing a Menagerie of Models for Estimating Molecular Divergence\n  Times",
        "authors": [
            "Peter J Waddell"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Estimation of molecular evolutionary divergence times requires models of rate\nchange. These vary with regard to the assumption of what quantity is penalized.\nThe possibilities considered are the rate of evolution, the log of the rate of\nevolution and the inverse of the rate of evolution. These models also vary with\nregard to how time affects the expected variance of rate change. Here the\nalternatives are not at all, linearly with time and as the product of rate and\ntime. This results in a set of nine models, both random walks and Brownian\nmotion. A priori any of these models could be correct, yet different\nresearchers may well prefer, or simply use, one rather than the others. Another\nvariable is whether to use a scaling factor to take account of the variance of\nthe process of rate change being unknown and therefore avoid minimizing the\npenalty function with unrealistically large times. Here the difference these\nmodels and assumptions make on a tree of mammals, with the root fixed and with\na single internal node fixed, is measured. The similarity of models is measured\nas the correlation of their time estimates and visualized with a least squares\ntree. The fit of model to data is measured and Q-Q plots are shown. Comparing\nmodel estimates with each other, the age of clades within Laurasiatheria are\nseen to vary far more across models than those within Supraprimates (informally\ncalled Euarchontoglires). Especially problematic are the often-used fossil\ncalibrated nodes of horse/rhino and whale/hippo clashing with times within\nSupraprimates and in particular no fossil rodent teeth older than ~60 mybp. A\nscaling factor in addition to penalizing rate change is seen to yield\nconsistent relative time estimates irrespective of exactly where the\ncalibration point is placed.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.4332v1"
    },
    {
        "title": "Understanding Distal Transcriptional Regulation from Sequence Motif,\n  Network Inference and Interactome Perspectives",
        "authors": [
            "Arvind Rao",
            "Alfred O. Hero III",
            "David J. States",
            "James Douglas Engel"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Gene regulation in higher eukaryotes involves a complex interplay between the\ngene proximal promoter and distal genomic elements (such as enhancers) which\nwork in concert to drive spatio-temporal expression. The experimental\ncharacterization of gene regulatory elements is a very complex and\nresource-intensive process. One of the major goals in computational biology is\nthe \\textit{in-silico} annotation of previously uncharacterized elements using\nresults from the subset of known, annotated, regulatory elements.\n  The computational annotation of these hitherto uncharacterized regions would\nrequire an identification of features that have good predictive value for\nregulatory behavior.\n  In this work, we study transcriptional regulation as a problem in\nheterogeneous data integration, across sequence, expression and interactome\nlevel attributes. Using the example of the \\textit{Gata2} gene and its recently\ndiscovered urogenital enhancers \\cite{Khandekar2004} as a case study, we\nexamine the predictive value of various high throughput functional genomic\nassays in characterizing these enhancers and their regulatory role. Observing\nresults from the application of modern statistical learning methodologies for\neach of these data modalities, we propose a set of attributes that are most\ndiscriminatory in the localization and behavior of these enhancers.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.3180v1"
    },
    {
        "title": "An algebraic hypothesis about the primeval genetic code",
        "authors": [
            "Robersy Sanchez",
            "Ricardo Grau"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  A plausible architecture of an ancient genetic code is derived from an\nextended base triplet vector space over the Galois field of the extended base\nalphabet {D, G, A, U, C}, where the letter D represents one or more\nhypothetical bases with unspecific pairing. We hypothesized that the high\ndegeneration of a primeval genetic code with five bases and the gradual origin\nand improvements of a primitive DNA repair system could make possible the\ntransition from the ancient to the modern genetic code. Our results suggest\nthat the Watson-Crick base pairing and the non-specific base pairing of the\nhypothetical ancestral base D used to define the sum and product operations are\nenough features to determine the coding constraints of the primeval and the\nmodern genetic code, as well as, the transition from the former to the later.\nGeometrical and algebraic properties of this vector space reveal that the\npresent codon assignment of the standard genetic code could be induced from a\nprimeval codon assignment.Besides, the Fourier spectrum of the extended DNA\ngenome sequences derived from the multiple sequence alignment suggests that the\ncalled period-3 property of the present coding DNA sequences could also exist\nin the ancient coding DNA sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.1128v3"
    },
    {
        "title": "The C-value enigma and timing of the Cambrian explosion",
        "authors": [
            "Dirson Jian Li",
            "Shengli Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The Cambrian explosion is a grand challenge to science today and involves\nmultidisciplinary study. This event is generally believed as a result of\ngenetic innovations, environmental factors and ecological interactions, even\nthough there are many conflicts on nature and timing of metazoan origins. The\ncrux of the matter is that an entire roadmap of the evolution is missing to\ndiscern the biological complexity transition and to evaluate the critical role\nof the Cambrian explosion in the overall evolutionary context. Here we\ncalculate the time of the Cambrian explosion by an innovative and accurate\n\"C-value clock\"; our result (560 million years ago) quite fits the fossil\nrecords. We clarify that the intrinsic reason of genome evolution determined\nthe Cambrian explosion. A general formula for evaluating genome size of\ndifferent species has been found, by which major questions of the C-value\nenigma can be solved and the genome size evolution can be illustrated. The\nCambrian explosion is essentially a major transition of biological complexity,\nwhich corresponds to a turning point in genome size evolution. The observed\nmaximum prokaryotic complexity is just a relic of the Cambrian explosion and it\nis supervised by the maximum information storage capability in the observed\nuniverse. Our results open a new prospect of studying metazoan origins and\nmolecular evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.0108v1"
    },
    {
        "title": "Prediction of genomic properties and classification of life by protein\n  length distributions",
        "authors": [
            "Dirson Jian Li",
            "Shengli Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Much evolutionary information is stored in the fluctuations of protein length\ndistributions. The genome size and non-coding DNA content can be calculated\nbased only on the protein length distributions. So there is intrinsic\nrelationship between the coding DNA size and non-coding DNA size. According to\nthe correlations and quasi-periodicity of protein length distributions, we can\nclassify life into three domains. Strong evidences are found to support the\norder in the structures of protein length distributions.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.0205v1"
    },
    {
        "title": "Significance tests for comparing digital gene expression profiles",
        "authors": [
            "Leonardo Varuzza",
            "Arthur Gruber",
            "Carlos A. de B. Pereira"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Most of the statistical tests currently used to detect differentially\nexpressed genes are based on asymptotic results, and perform poorly for low\nexpression tags. Another problem is the common use of a single canonical cutoff\nfor the significance level (p-value) of all the tags, without taking into\nconsideration the type II error and the highly variable character of the sample\nsize of the tags.\n  This work reports the development of two significance tests for the\ncomparison of digital expression profiles, based on frequentist and Bayesian\npoints of view, respectively. Both tests are exact, and do not use any\nasymptotic considerations, thus producing more correct results for low\nfrequency tags than the chi-square test. The frequentist test uses a\ntag-customized critical level which minimizes a linear combination of type I\nand type II errors. A comparison of the Bayesian and the frequentist tests\nrevealed that they are linked by a Beta distribution function. These tests can\nbe used alone or in conjunction, and represent an improvement over the\ncurrently available methods for comparing digital profiles.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.3274v3"
    },
    {
        "title": "Lower Bounds for Optimal Alignments of Binary Sequences",
        "authors": [
            "Cynthia Vinzant"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  In parametric sequence alignment, optimal alignments of two sequences are\ncomputed as a function of the penalties for mismatches and spaces, producing\nmany different optimal alignments. Here we give a 3/(2^{7/3}\\pi^{2/3})n^{2/3}\n+O(n^{1/3} \\log n) lower bound on the maximum number of distinct optimal\nalignment summaries of length-n binary sequences. This shows that the upper\nbound given by Gusfield et. al. is tight over all alphabets, thereby disproving\nthe \"square root of n conjecture\". Thus the maximum number of distinct optimal\nalignment summaries (i.e. vertices of the alignment polytope) over all pairs of\nlength-n sequences is Theta(n^{2/3}).\n",
        "pdf_link": "http://arxiv.org/pdf/0807.0051v2"
    },
    {
        "title": "Number of natively unfolded proteins scales with genome size",
        "authors": [
            "Antonio Deiana",
            "Andrea Giansanti"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Natively unfolded proteins exist as an ensemble of flexible conformations\nlacking a well defined tertiary structure along a large portion of their\npolypeptide chain. Despite the absence of a stable configuration, they are\ninvolved in important cellular processes. In this work we used from three\nindicators of folding status, derived from the analysis of mean packing and\nmean contact energy of a protein sequence as well as from VSL2, a disorder\npredictor, and we combined them into a consensus score to identify natively\nunfolded proteins in several genomes from Archaea, Bacteria and Eukarya. We\nfound a high correlation among the number of predicted natively unfolded\nproteins and the number of proteins in the genomes. More specifically, the\nnumber of natively unfolded proteins scaled with the number of proteins in the\ngenomes, with exponent 1.81 +- 0.10. This scaling law may be important to\nunderstand the relation between the number of natively unfolded proteins and\ntheir roles in cellular processes.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1869v1"
    },
    {
        "title": "Universal Features in the Genome-level Evolution of Protein Domains",
        "authors": [
            "M. Cosentino Lagomarsino",
            "A. L. Sellerio",
            "P. D. Heijning",
            "B. Bassetti"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Protein domains are found on genomes with notable statistical distributions,\nwhich bear a high degree of similarity. Previous work has shown how these\ndistributions can be accounted for by simple models, where the main ingredients\nare probabilities of duplication, innovation, and loss of domains. However, no\none so far has addressed the issue that these distributions follow definite\ntrends depending on protein-coding genome size only. We present a stochastic\nduplication/innovation model, falling in the class of so-called Chinese\nRestaurant Processes, able to explain this feature of the data. Using only two\nuniversal parameters, related to a minimal number of domains and to the\nrelative weight of innovation to duplication, the model reproduces two\nimportant aspects: (a) the populations of domain classes (the sets, related to\nhomology classes, containing realizations of the same domain in different\nproteins) follow common power-laws whose cutoff is dictated by genome size, and\n(b) the number of domain families is universal and markedly sublinear in genome\nsize. An important ingredient of the model is that the innovation probability\ndecreases with genome size. We propose the possibility to interpret this as a\nglobal constraint given by the cost of expanding an increasingly complex\ninteractome.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.1898v1"
    },
    {
        "title": "Model of Genetic Variation in Human Social Networks",
        "authors": [
            "James H. Fowler",
            "Christopher T. Dawes",
            "Nicholas A. Christakis"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Social networks exhibit strikingly systematic patterns across a wide range of\nhuman contexts. While genetic variation accounts for a significant portion of\nthe variation in many complex social behaviors, the heritability of egocentric\nsocial network attributes is unknown. Here we show that three of these\nattributes (in-degree, transitivity, and centrality) are heritable. We then\ndevelop a \"mirror network\" method to test extant network models and show that\nnone accounts for observed genetic variation in human social networks. We\npropose an alternative \"Attract and Introduce\" model with two simple forms of\nheterogeneity that generates significant heritability as well as other\nimportant network features. We show that the model is well suited to real\nsocial networks in humans. These results suggest that natural selection may\nhave played a role in the evolution of social networks. They also suggest that\nmodeling intrinsic variation in network attributes may be important for\nunderstanding the way genes affect human behaviors and the way these behaviors\nspread from person to person.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.3089v4"
    },
    {
        "title": "Towards a core genome: pairwise similarity searches on interspecific\n  genomic data",
        "authors": [
            "Bradly J. Alicea",
            "Marcela A. Carvallo-Pinto",
            "Jorge L. M. Rodrigues"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The phenomenon of gene conservation is an interesting evolutionary problem\nrelated to speciation and adaptation. Conserved genes are acted upon in\nevolution in a way that preserves their function despite other structural and\nfunctional changes going on around them. The recent availability of\nwhole-genomic data from closely related species allows us to test the\nhypothesis that a core genome present in a hypothetical common ancestor is\ninherited by all sister taxa. Furthermore, this core genome should serve\nessential functions such as genetic regulation and cellular repair.\nWhole-genome sequences from three strains of bacteria (Shewanella sp.) were\nused in this analysis. The open reading frames (ORFs) for each identified and\nputative gene were used for each genome. Reciprocal Blast searches were\nconducted on all three genomes, which distilled a list of thousands of genes to\n68 genes that were identical across taxa. Based on functional annotation, these\ngenes were identified as housekeeping genes, which confirmed the original\nhypothesis. This method could be used in eukaryotes as well, in particular the\nrelationship between humans, chimps, and macaques.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.3353v1"
    },
    {
        "title": "Origin and evolution of the genetic code: The universal enigma",
        "authors": [
            "Eugene V. Koonin",
            "Artem S. Novozhilov"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The genetic code is nearly universal, and the arrangement of the codons in\nthe standard codon table is highly non-random. The three main concepts on\norigin and evolution of the code are the stereochemical theory; the coevolution\ntheory; and the error minimization theory. These theories are not mutually\nexclusive and are also compatible with the frozen accident hypothesis.\nMathematical analysis of the structure and possible evolutionary trajectories\nof the code shows that it is highly robust to translational error but there is\na huge number of more robust codes, so that the standard code potentially could\nevolve from a random code via a short sequence of codon series reassignments.\nThus, much of the evolution that led to the standard code can be interpreted as\na combination of frozen accident with selection for translational error\nminimization although contributions from coevolution of the code with metabolic\npathways and/or weak affinities between amino acids and nucleotide triplets\ncannot be ruled out. However, such scenarios for the code evolution are based\non formal schemes whose relevance to the actual primordial evolution is\nuncertain, so much caution in interpretation is necessary. A real understanding\nof the code's origin and evolution is likely to be attainable only in\nconjunction with a credible scenario for the evolution of the coding principle\nitself and the translation system.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.4749v2"
    },
    {
        "title": "Matrix genetics, part 4: cyclic changes of the genetic 8-dimensional\n  Yin-Yang-algebras and the algebraic models of physiological cycles",
        "authors": [
            "Sergey V. Petoukhov"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The article continues an analysis of the genetic 8-dimensional\nYin-Yang-algebra. This algebra was revealed in a course of matrix researches of\nstructures of the genetic code and it was described in the author's articles\narXiv:0803.3330 and arXiv:0805.4692. The article presents data about many kinds\nof cyclic permutations of elements of the genetic code in the genetic\n(8x8)-matrix [C A; U G](3) of 64 triplets, where C, A, U, G are letters of the\ngenetic alphabet. These cyclic permutations lead to such reorganizations of the\nmatrix form of presentation of the initial genetic Yin-Yang-algebra that arisen\nmatrices serve as matrix forms of presentations of new Yin-Yang-algebras as\nwell. They are connected algorithmically with Hadamard matrices. The discovered\nexistence of a hierarchy of the cyclic changes of types of genetic\nYin-Yang-algebras allows thinking about new algebraic-genetic models of cyclic\nprocesses in inherited biological systems including models of cyclic\nmetamorphoses of animals. These cycles of changes of the genetic 8-dimensional\nalgebras and of their 8-dimensional numeric systems have many analogies with\nfamous facts and doctrines of modern and ancient physiology, medicine, etc.\nThis viewpoint proposes that the famous idea by Pythagoras (about organization\nof natural systems in accordance with harmony of numerical systems) should be\ncombined with the idea of cyclic changes of Yin-Yang-numeric systems in\nconsidered cases. This second idea reminds of the ancient idea of cyclic\nchanges in nature. From such algebraic-genetic viewpoint, the notion of\nbiological time can be considered as a factor of coordinating these\nhierarchical ensembles of cyclic changes of types of the genetic\nmulti-dimensional algebras.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.2714v1"
    },
    {
        "title": "Classification of life by the mechanism of genome size evolution",
        "authors": [
            "Dirson Jian Li",
            "Shengli Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The classification of life should be based upon the fundamental mechanism in\nthe evolution of life. We found that the global relationships among species\nshould be circular phylogeny, which is quite different from the common sense\nbased upon phylogenetic trees. The genealogical circles can be observed clearly\naccording to the analysis of protein length distributions of contemporary\nspecies. Thus, we suggest that domains can be defined by distinguished\nphylogenetic circles, which are global and stable characteristics of living\nsystems. The mechanism in genome size evolution has been clarified; hence main\ncomponent questions on C-value enigma can be explained. According to the\ncorrelations and quasi-periodicity of protein length distributions, we can also\nclassify life into three domains.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3164v2"
    },
    {
        "title": "Biased exonization of transposed elements in duplicated genes: A lesson\n  from the TIF-IA gene",
        "authors": [
            "Maayan Amit",
            "Noa Sela",
            "Hadas Keren",
            "Zeev Melamed",
            "Inna Muler",
            "Noam Shomron",
            "Shai Izraeli",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Background: Gene duplication and exonization of intronic transposed elements\nare two mechanisms that enhance genomic diversity. We examined whether there is\nless selection against exonization of transposed elements in duplicated genes\nthan in single-copy genes. Results: Genome-wide analysis of exonization of\ntransposed elements revealed a higher rate of exonization within duplicated\ngenes relative to single-copy genes. The gene for TIF-IA, an RNA polymerase I\ntranscription initiation factor, underwent a humanoid-specific triplication,\nall three copies of the gene are active transcriptionally, although only one\ncopy retains the ability to generate the TIF-IA protein. Prior to TIF-IA\ntriplication, an Alu element was inserted into the first intron. In one of the\nnon-protein coding copies, this Alu is exonized. We identified a single point\nmutation leading to exonization in one of the gene duplicates. When this\nmutation was introduced into the TIF-IA coding copy, exonization was activated\nand the level of the protein-coding mRNA was reduced substantially. A very low\nlevel of exonization was detected in normal human cells. However, this\nexonization was abundant in most leukemia cell lines evaluated, although the\ngenomic sequence is unchanged in these cancerous cells compared to normal\ncells. Conclusion: The definition of the Alu element within the TIF-IA gene as\nan exon is restricted to certain types of cancers; the element is not exonized\nin normal human cells. These results further our understanding of the delicate\ninterplay between gene duplication and alternative splicing and of the\nmolecular evolutionary mechanisms leading to genetic innovations. This implies\nthe existence of purifying selection against exonization in single copy genes,\nwith duplicate genes free from such constrains.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3507v1"
    },
    {
        "title": "Transduplication resulted in the incorporation of two protein-coding\n  sequences into the Turmoil-1 transposable element of C. elegans",
        "authors": [
            "Noa Sela",
            "Adi Stern",
            "Wojciech Makalowski",
            "Tal Pupko",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Transposable elements may acquire unrelated gene fragments into their\nsequences in a process called transduplication. Transduplication of\nprotein-coding genes is common in plants, but is unknown of in animals. Here,\nwe report that the Turmoil-1 transposable element in C. elegans has\nincorporated two protein-coding sequences into its inverted terminal repeat\n(ITR) sequences. The ITRs of Turmoil-1 contain a conserved RNA recognition\nmotif (RRM) that originated from the rsp- 2 gene and a fragment from the\nprotein-coding region of the cpg-3 gene. We further report that an open reading\nframe specific to C. elegans may have been created as a result of a Turmoil-1\ninsertion. Mutations at the 5' splice site of this open reading frame may have\nreactivated the transduplicated RRM motif\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3508v1"
    },
    {
        "title": "Comparative analysis of transposed element insertion within human and\n  mouse genomes reveals Alu's unique role in shaping the human transcriptome",
        "authors": [
            "Noa Sela",
            "Britta Mersch",
            "Nurit Gal-Mark",
            "Galit Lev-Maor",
            "Agnes Hotz- Wagenblatt",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Background: Transposed elements (TEs) have a substantial impact on mammalian\nevolution and are involved in numerous genetic diseases. We compared the impact\nof TEs on the human transcriptome and the mouse transcriptome. Results: We\ncompiled a dataset of all TEs in the human and mouse genomes, identifying\n3,932,058 and 3,122,416 TEs, respectively. We than extracted TEs located within\nhuman and mouse genes and, surprisingly, we found that 60% of TEs in both human\nand mouse are located in intronic sequences, even though introns comprise only\n24% of the human genome. All TE families in both human and mouse can exonize.\nTE families that are shared between human and mouse exhibit the same percentage\nof TE exonization in the two species, but the exonization level of Alu, a\nprimatespecific retroelement, is significantly greater than that of other TEs\nwithin the human genome, leading to a higher level of TE exonization in human\nthan in mouse (1,824 exons compared with 506 exons, respectively). We detected\na primate-specific mechanism for intron gain, in which Alu insertion into an\nexon creates a new intron located in the 3' untranslated region (termed\n'intronization'). Finally, the insertion of TEs into the first and last exons\nof a gene is more frequent in human than in mouse, leading to longer exons in\nhuman. Conclusion: Our findings reveal many effects of TEs on these two\ntranscriptomes. These effects are substantially greater in human than in mouse,\nwhich is due to the presence of Alu elements in human.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3510v1"
    },
    {
        "title": "TranspoGene and microTranspoGene: transposed elements influence on the\n  transcriptome of seven vertebrates and invertebrates",
        "authors": [
            "Asaf Levy",
            "Noa Sela",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Transposed elements (TEs) are mobile genetic sequences. During the evolution\nof eukaryotes TEs were inserted into active protein-coding genes, affecting\ngene structure, expression and splicing patterns, and protein sequences.\nGenomic insertions of TEs also led to creation and expression of new functional\nnon-coding RNAs such as micro- RNAs. We have constructed the TranspoGene\ndatabase, which covers TEs located inside proteincoding genes of seven species:\nhuman, mouse, chicken, zebrafish, fruit fly, nematode and sea squirt. TEs were\nclassified according to location within the gene: proximal promoter TEs,\nexonized TEs (insertion within an intron that led to exon creation), exonic TEs\n(insertion into an existing exon) or intronic TEs. TranspoGene contains\ninformation regarding specific type and family of the TEs, genomic and mRNA\nlocation, sequence, supporting transcript accession and alignment to the TE\nconsensus sequence. The database also contains host gene specific data: gene\nname, genomic location, Swiss-Prot and RefSeq accessions, diseases associated\nwith the gene and splicing pattern. In addition, we created microTranspoGene: a\ndatabase of human, mouse, zebrafish and nematode TEderived microRNAs. The\nTranspoGene and micro- TranspoGene databases can be used by researchers\ninterested in the effect of TE insertion on the eukaryotic transcriptome.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3513v1"
    },
    {
        "title": "The Alternative Choice of Constitutive Exons throughout Evolution",
        "authors": [
            "Galit Lev-Maor",
            "Amir Goren",
            "Noa Sela",
            "Eddo Kim",
            "Hadas Keren",
            "Adi Doron-Faigenboim",
            "Shelly Leibman-Barak",
            "Tal Pupko",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Alternative cassette exons are known to originate from two processes\nexonization of intronic sequences and exon shuffling. Herein, we suggest an\nadditional mechanism by which constitutively spliced exons become alternative\ncassette exons during evolution. We compiled a dataset of orthologous exons\nfrom human and mouse that are constitutively spliced in one species but\nalternatively spliced in the other. Examination of these exons suggests that\nthe common ancestors were constitutively spliced. We show that relaxation of\nthe 59 splice site during evolution is one of the molecular mechanisms by which\nexons shift from constitutive to alternative splicing. This shift is associated\nwith the fixation of exonic splicing regulatory sequences (ESRs) that are\nessential for exon definition and control the inclusion level only after the\ntransition to alternative splicing. The effect of each ESR on splicing and the\ncombinatorial effects between two ESRs are conserved from fish to human. Our\nresults uncover an evolutionary pathway that increases transcriptome diversity\nby shifting exons from constitutive to alternative splicing\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3514v1"
    },
    {
        "title": "Intronic Alus Influence Alternative Splicing",
        "authors": [
            "Galit Lev-Maor",
            "Oren Ram",
            "Eddo Kim",
            "Noa Sela",
            "Amir Goren",
            "Erez Y Levanon",
            "Gil Ast"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Examination of the human transcriptome reveals higher levels of RNA editing\nthan in any other organism tested to date. This is indicative of extensive\ndouble-stranded RNA (dsRNA) formation within the human transcriptome. Most of\nthe editing sites are located in the primate-specific retrotransposed element\ncalled Alu. A large fraction of Alus are found in intronic sequences, implying\nextensive Alu-Alu dsRNA formation in mRNA precursors. Yet, the effect of these\nintronic Alus on splicing of the flanking exons is largely unknown. Here, we\nshow that more Alus flank alternatively spliced exons than constitutively\nspliced ones; this is especially notable for those exons that have changed\ntheir mode of splicing from constitutive to alternative during human evolution.\nThis implies that Alu insertions may change the mode of splicing of the\nflanking exons. Indeed, we demonstrate experimentally that two Alu elements\nthat were inserted into an intron in opposite orientation undergo base-pairing,\nas evident by RNA editing, and affect the splicing patterns of a downstream\nexon, shifting it from constitutive to alternative. Our results indicate the\nimportance of intronic Alus in influencing the splicing of flanking exons,\nfurther emphasizing the role of Alus in shaping of the human transcriptome\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3515v1"
    },
    {
        "title": "Phase transition in the genome evolution favours non-random distribution\n  of genes on chromosomes",
        "authors": [
            "Jakub Kowalski",
            "Wojciech Waga",
            "Marta Zawierta",
            "Stanislaw Cebrat"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  We have used the Monte Carlo based computer models to show that selection\npressure could affect the distribution of recombination hotspots along the\nchromosome. Close to critical crossover rate, where genomes may switch between\nthe Darwinian purifying selection or complementation of haplotypes, the\ndistribution of recombination events and the force of selection exerted on\ngenes affect the structure of chromosomes. The order of expression of gene s\nand their location on chromosome may decide about the extinction or survival of\ncompeting populations.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.0990v1"
    },
    {
        "title": "Darwinian purifying selection versus complementing strategy in Monte\n  Carlo simulations",
        "authors": [
            "Wojciech Waga",
            "Marta Zawierta",
            "Jakub Kowalski",
            "Stanislaw Cebrat"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Intragenomic recombination (crossover) is a very important evolutionary\nmechanism. The crossover events are not evenly distributed along the natural\nchromosomes. Monte Carlo simulations revealed that frequency of recombinations\ndecides about the strategy of chromosomes' and genomes' evolution. In large\npanmictic populations, under high recombination rate the Darwinian purifying\nselection operates keeping the fraction of defective genes at the relatively\nlow level. In small populations and under low recombination rate the strategy\nof complementing haplotypes seems to be more advantageous. Switching between\nthe two strategies has a character of phase transition - it depends on\ninbreeding coefficient and crossover rate. The critical recombination rate\ndepends also on the size of chromosome. It is also possible, that in one genome\nsome chromosomes could be under complementing while some other under purifying\nselection. Such situation stabilizes genome evolution and reproduction\nstrategy. It seems that this phenomenon can be responsible for the positive\ncorrelation between kinship and fecundity, recently found in the Islander\npopulation. When large population is forced to enter the complementing\nstrategy, the phenomenon of sympatric speciation is observed.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.1361v1"
    },
    {
        "title": "Evolution of the Age Structured Populations and Demography",
        "authors": [
            "Agnieszka Laszkiewicz",
            "Przemyslaw Biecek",
            "Katarzyna Bonkowska",
            "Stanislaw Cebrat"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  We describe the simulation method of modelling the population evolution using\nMonte Carlo based on the Penna model. Individuals in the populations are\nrepresented by their diploid genomes. Genes expressed after the minimum\nreproduction age are under a weaker selection pressure and accumulate more\nmutations than those expressed before the minimum reproduction age. The\ngenerated gradient of defective genes determines the ageing of individuals and\nage-structured populations are very similar to the natural, sexually\nreproducing populations. The genetic structure of a population depends on the\nway how the random death affects the population. The improvement of the medical\ncare and healthier life styles are responsible for the increasing of the life\nexpectancy of humans during the last century. Introducing a noise into the\nrelations between the genotype, phenotype, and environment, it is possible to\nsimulate some other effects, like the role of immunological systems and a\nmother care. One of the most interesting results was the evolution of sex\nchromosomes. Placing the male sex determinants on one chromosome of a pair of\nsex chromosomes is enough to condemn it for shrinking if the population is\npanmictic (random-mating is assumed). If males are indispensable for taking\ncare of their offspring and have to be faithful to their females, the male sex\nchromosome does not shrink.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.1464v1"
    },
    {
        "title": "To Understand Nature - Computer Modelling between Genetics and Evolution",
        "authors": [
            "Dorota Mackiewicz",
            "Stanislaw Cebrat"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  We have presented the basic knowledge on the structure of molecules coding\nthe genetic information, mechanisms of transfer of this information from DNA to\nproteins and phenomena connected with replication of DNA. In particular, we\nhave described the differences of mutational pressure connected with\nreplication of the leading and lagging DNA strands. We have shown how the\nasymmetric replication of DNA affects the structure of genomes, positions of\ngenes, their function and amino acid composition. Results of Monte Carlo\nsimulations of evolution of protein coding sequences have shown a specific role\nof genetic code in minimizing the effect of nucleotide substitutions on the\namino acid composition of proteins. The results of simulations were compared\nwith the results of analyses of genomic and proteomic data bases. This chapter\nis considered as an introduction to further chapters where chromosomes with\ngenes represented by nucleotide sequences were replaced by bitstrings with\nsingle bits representing genes.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.1465v1"
    },
    {
        "title": "MicroRNA Interaction network in human: implications of clustered\n  microRNA in biological pathways and genetic diseases",
        "authors": [
            "Sushmita Mookherjee",
            "Mithun Sinha",
            "Saikat Mukhopadhyay",
            "Nitai P. Bhattacharyya",
            "P. K. Mohanty"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  A novel group of small non-coding RNA, known as microRNA (miRNA) is predicted\nto regulate as high as 90% of the coding genes in human. The diversity and\nabundance of miRNA targets offer an enormous level of combinatorial\npossibilities and suggest that miRNAs and their targets form a complex\nregulatory network. In the present study, we analyzed 711 miRNAs and their 34,\n525 predicted targets in the miRBase database which generate a complex\nbipartite network having numerous numbers of genes forming the hub. Genes at\nthe hub (total 9877) are significantly over represented in genes with specific\nmolecular functions, biological processes and biological pathways as revealed\nfrom the analysis using PANTHER. We further construct a miRNA co-target network\nby linking every pair of miRNAs which co-target at least one gene. The weight\nof the link, which is taken to be the number of co-targets of the pair of\nmiRNAs vary widely, and we could erase several links while keeping the relevant\nfeatures of the network intact. The largest connected sub-graph, thus obtained,\ncontains 479 miRNAs. More than 75% of the miRNAs deregulated in 15 different\ndiseases collected from published data are found to be in this largest sub\ngraph. We further analyze this sub-graph to obtain 70 small clusters containing\ntotal 330 miRNAs of 479. We identified the biological pathways where the\nco-targeted genes in the clusters are significantly over- represented in\ncomparison to that obtained with that are not co-targeted by the miRNAs in the\ncluster. Using published data, we identified that specific clusters of miRNAs\nare associated with specific diseases by altering particular pathways. We\npropose that instead of single miRNA, clusters of miRNA that co-targets the\ngenes are important for the regulation of miRNA in diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.4211v1"
    },
    {
        "title": "Evolution of genomes in the hybridogenetic populations modelled by the\n  Penna model",
        "authors": [
            "Mateusz Kula",
            "Katarzyna Bonkowska",
            "Maria Ogielska",
            "Piotr Kierzkowski",
            "Anna Zalesna",
            "Stanislaw Cebrat"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Background: Hybridogenesis is a very interesting example of reproduction\nwhich seems to integrate the sexual and clonal processes in one system. In a\ncase of frogs, described in the paper, two parental species - Rana lessonae and\nRana ridibunda can form fertile hybrid individuals - Rana esculenta. Hybrid\nindividuals eliminate one parental haplotype from their germ line cells before\nmeiosis (end before recombination) which implicates clonal reproduction of the\nhaplotype transferred to the gametes. All three \"species\" are called \"complex\nspecies\". To study the evolution of genomes in the hybridogenetic fraction of\nthis complex species we have used the Monte Carlo based model rendering the age\nstructured populations. The model enables the analysis of distribution of\ndefective alleles in the individual genomes as well as in the genetic pool of\nthe whole populations.\n  Results: We have shown that longer isolation of hybrids' populations leads to\nthe speciation through emerging the specific sets of complementing haplotypes\nin their genetic pool. The fraction of defective alleles increases but the\ndefects are complemented in the heterozygous loci. Nevertheless, even small\nsupply of new hybrids generated by the two parental species or crossbreeding\nbetween hybrids and one of the parental species prevents the speciation and\nchanges the strategy of the genome evolution from the complementing to the\npurifying Darwinian selection.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.2960v1"
    },
    {
        "title": "PICS: Probabilistic Inference for ChIP-seq",
        "authors": [
            "Xuekui Zhang",
            "Gordon Robertson",
            "Martin Krzywinski",
            "Kaida Ning",
            "Arnaud Droit",
            "Steven Jones",
            "Raphael Gottardo"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  ChIP-seq, which combines chromatin immunoprecipitation with massively\nparallel short-read sequencing, can profile in vivo genome-wide transcription\nfactor-DNA association with higher sensitivity, specificity and spatial\nresolution than ChIP-chip. While it presents new opportunities for research,\nChIP-seq poses new challenges for statistical analysis that derive from the\ncomplexity of the biological systems characterized and the variability and\nbiases in its digital sequence data. We propose a method called PICS\n(Probabilistic Inference for ChIP-seq) for extracting information from ChIP-seq\naligned-read data in order to identify regions bound by transcription factors.\nPICS identifies enriched regions by modeling local concentrations of\ndirectional reads, and uses DNA fragment length prior information to\ndiscriminate closely adjacent binding events via a Bayesian hierarchical\nt-mixture model. Its per-event fragment length estimates also allow it to\nremove from analysis regions that have atypical lengths. PICS uses\npre-calculated, whole-genome read mappability profiles and a truncated\nt-distribution to adjust binding event models for reads that are missing due to\nlocal genome repetitiveness. It estimates uncertainties in model parameters\nthat can be used to define confidence regions on binding event locations and to\nfilter estimates. Finally, PICS calculates a per-event enrichment score\nrelative to a control sample, and can use a control sample to estimate a false\ndiscovery rate. We compared PICS to the alternative methods MACS, QuEST, and\nCisGenome, using published GABP and FOXA1 data sets from human cell lines, and\nfound that PICS' predicted binding sites were more consistent with\ncomputationally predicted binding motifs.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.3206v1"
    },
    {
        "title": "Reconstructing Spatiotemporal Gene Expression Data from Partial\n  Observations",
        "authors": [
            "Dustin A. Cartwright",
            "Siobhan M. Brady",
            "David A. Orlando",
            "Bernd Sturmfels",
            "Philip N. Benfey"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Developmental transcriptional networks in plants and animals operate in both\nspace and time. To understand these transcriptional networks it is essential to\nobtain whole-genome expression data at high spatiotemporal resolution.\nSubstantial amounts of spatial and temporal microarray expression data\npreviously have been obtained for the Arabidopsis root; however, these two\ndimensions of data have not been integrated thoroughly. Complicating this\nintegration is the fact that these data are heterogeneous and incomplete, with\nobserved expression levels representing complex spatial or temporal mixtures.\nGiven these partial observations, we present a novel method for reconstructing\nintegrated high resolution spatiotemporal data. Our method is based on a new\niterative algorithm for finding approximate roots to systems of bilinear\nequations.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4027v1"
    },
    {
        "title": "Finding large average submatrices in high dimensional data",
        "authors": [
            "Andrey A. Shabalin",
            "Victor J. Weigman",
            "Charles M. Perou",
            "Andrew B. Nobel"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  The search for sample-variable associations is an important problem in the\nexploratory analysis of high dimensional data. Biclustering methods search for\nsample-variable associations in the form of distinguished submatrices of the\ndata matrix. (The rows and columns of a submatrix need not be contiguous.) In\nthis paper we propose and evaluate a statistically motivated biclustering\nprocedure (LAS) that finds large average submatrices within a given real-valued\ndata matrix. The procedure operates in an iterative-residual fashion, and is\ndriven by a Bonferroni-based significance score that effectively trades off\nbetween submatrix size and average value. We examine the performance and\npotential utility of LAS, and compare it with a number of existing methods,\nthrough an extensive three-part validation study using two gene expression\ndatasets. The validation study examines quantitative properties of biclusters,\nbiological and clinical assessments using auxiliary information, and\nclassification of disease subtypes using bicluster membership. In addition, we\ncarry out a simulation study to assess the effectiveness and noise sensitivity\nof the LAS search procedure. These results suggest that LAS is an effective\nexploratory tool for the discovery of biologically relevant structures in high\ndimensional data. Software is available at https://genome.unc.edu/las/.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.1682v2"
    },
    {
        "title": "Identification and Query of Activated Gene Pathways in Disease\n  Progression",
        "authors": [
            "Arvind Rao",
            "Alfred O. Hero, III"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Disease occurs due to aberrant expression of genes and modulation of the\nbiological pathways along which they lie. Inference of activated gene pathways,\nusing gene expression data during disease progression, is an important problem.\nIn this work, we have developed a generalizable framework for the\nidentification of interacting pathways while incorporating biological realism,\nusing functional data analysis and manifold embedding techniques. Additionally,\nwe have also developed a new method to query for the differential co-ordinated\nactivity of any desired pathway during disease progression. The methods\ndeveloped in this work can be generalized to any conditions of interest.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.3198v2"
    },
    {
        "title": "Genome-Wide Survey of MicroRNA - Transcription Factor Feed-Forward\n  Regulatory Circuits in Human",
        "authors": [
            "Angela Re",
            "Davide Cora'",
            "Daniela Taverna",
            "Michele Caselle"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  In this work, we describe a computational framework for the genome-wide\nidentification and characterization of mixed\ntranscriptional/post-transcriptional regulatory circuits in humans. We\nconcentrated in particular on feed-forward loops (FFL), in which a master\ntranscription factor regulates a microRNA, and together with it, a set of joint\ntarget protein coding genes. The circuits were assembled with a two step\nprocedure. We first constructed separately the transcriptional and\npost-transcriptional components of the human regulatory network by looking for\nconserved over-represented motifs in human and mouse promoters, and 3'-UTRs.\nThen, we combined the two subnetworks looking for mixed feed-forward regulatory\ninteractions, finding a total of 638 putative (merged) FFLs. In order to\ninvestigate their biological relevance, we filtered these circuits using three\nselection criteria: (I) GeneOntology enrichment among the joint targets of the\nFFL, (II) independent computational evidence for the regulatory interactions of\nthe FFL, extracted from external databases, and (III) relevance of the FFL in\ncancer. Most of the selected FFLs seem to be involved in various aspects of\norganism development and differentiation. We finally discuss a few of the most\ninteresting cases in detail.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.4115v1"
    },
    {
        "title": "Exceptional error minimization in putative primordial genetic codes",
        "authors": [
            "Artem S. Novozhilov",
            "Eugene V. Koonin"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  We investigated the error-minimization properties of putative primordial\ncodes that consisted of 16 supercodons, with the third base being completely\nredundant, using a previously derived cost function and the error minimization\npercentage as the measure of a code's robustness to mistranslation. It is shown\nthat, when the 16-supercodon table is populated with 10 putative primordial\namino acids, inferred from the results of abiotic synthesis experiments and\nother evidence independent of the code evolution, and with minimal assumptions\nused to assign the remaining supercodons, the resulting 2-letter codes are\nnearly optimal in terms of the error minimization level. The results of the\ncomputational experiments with putative primordial genetic codes that contained\nonly two meaningful letters in all codons and encoded 10 to 16 amino acids\nindicate that such codes are likely to have been nearly optimal with respect to\nthe minimization of translation errors. This near-optimality could be the\noutcome of extensive early selection during the co-evolution of the code with\nthe primordial, error-prone translation system, or a result of a unique,\naccidental event. Under this hypothesis, the subsequent expansion of the code\nresulted in a decrease of the error minimization level that became sustainable\nowing to the evolution of a high-fidelity translation system.\n",
        "pdf_link": "http://arxiv.org/pdf/0908.3579v1"
    },
    {
        "title": "A Simpler Explanation to BAK1 Gene Variation in Aortic and Blood Tissues",
        "authors": [
            "Michel Eduardo Beleza Yamagishi"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  The explanation is that in aortic tissue (both diseased and nondiseased) a\nBAK1 pseudogene is expressed; while in the matching blood samples the actual\nBAK1 gene is expressed. This explanation was reached after we realized that\nBAK1 has two edited copies in human genome. These copies are probably BAK1\npseudogenes. One copy belongs to chromosome 11 (NG_005599.3) and the other to\nchromosome 20 (NC_000850.5). The first copy has frameshifts which means that\nprobably it does not express any functional protein; by other hand, the\nchromosome 20 copy has no frameshifts and what is more important contains all\nthe reported polymorphisms.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.2321v1"
    },
    {
        "title": "Two-Parameter Characterization of Chromosome-Scale Recombination Rate",
        "authors": [
            "Wentian Li",
            "Jan Freudenberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  The genome-wide recombination rate ($RR$) of a species is often described by\none parameter, the ratio between total genetic map length ($G$) and physical\nmap length ($P$), measured in centiMorgans per Megabase (cM/Mb). The value of\nthis parameter varies greatly between species, but the cause for these\ndifferences is not entirely clear. A constraining factor of overall $RR$ in a\nspecies, which may cause increased $RR$ for smaller chromosomes, is the\nrequirement of at least one chiasma per chromosome (or chromosome-arm) per\nmeiosis. In the present study, we quantify the relative excess of recombination\nevents on smaller chromosomes by a linear regression model, which relates the\ngenetic length of chromosomes to their physical length. We find for several\nspecies that the two-parameter regression, $G= G_0 + k \\cdot P$ provides a\nbetter characterization of the relationship between genetic and physical map\nlength than the one-parameter regression that runs through the origin. A\nnon-zero intercept ($G_0$) indicates a relative excess of recombination on\nsmaller chromosomes in a genome. Given $G_0$, the parameter $k$ predicts the\nincrease of genetic map length over the increase of physical map length. The\nobserved values of $G_0$ have a similar magnitude for diverse species, whereas\n$k$ varies by two orders of magnitude. The implications of this strategy for\nthe genetic maps of human, mouse, rat, chicken, honeybee, worm and yeast are\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.2682v1"
    },
    {
        "title": "Copy-number-variation and copy-number-alteration region detection by\n  cumulative plots",
        "authors": [
            "Wentian Li",
            "Annette Lee",
            "Peter K Gregersen"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Background: Regions with copy number variations (in germline cells) or copy\nnumber alteration (in somatic cells) are of great interest for human disease\ngene mapping and cancer studies. They represent a new type of mutation and are\nlarger-scaled than the single nucleotide polymorphisms. Using genotyping\nmicroarray for copy number variation detection has become standard, and there\nis a need for improving analysis methods. Results: We apply the cumulative plot\nto the detection of regions with copy number variation/alteration, on samples\ntaken from a chronic lymphocytic leukemia patient. Two sets of whole-genome\ngenotyping of 317k single nucleotide polymorphisms, one from the normal cell\nand another from the cancer cell, are analyzed. We demonstrate the utility of\ncumulative plot in detecting a 9Mb (9 x 10^6 bases) hemizygous deletion and 1Mb\nhomozygous deletion on chromosome 13. We also show the possibility to detect\nsmaller copy number variation/alteration regions below the 100kb range.\nConclusions: As a graphic tool, the cumulative plot is an intuitive and a\nscale-free (window-less) way for detecting copy number variation/alteration\nregions, especially when such regions are small.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.3129v1"
    },
    {
        "title": "Partial correlation analysis indicates causal relationships between\n  GC-content, exon density and recombination rate in the human genome",
        "authors": [
            "Jan Freudengerb",
            "Mingyi Wang",
            "Yaning Yang",
            "Wentian Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  {\\bf Background}: Several features are known to correlate with the GC-content\nin the human genome, including recombination rate, gene density and distance to\ntelomere. However, by testing for pairwise correlation only, it is impossible\nto distinguish direct associations from indirect ones and to distinguish\nbetween causes and effects. {\\bf Results}: We use partial correlations to\nconstruct partially directed graphs for the following four variables:\nGC-content, recombination rate, exon density and distance-to-telomere.\nRecombination rate and exon density are unconditionally uncorrelated, but\nbecome inversely correlated by conditioning on GC-content. This pattern\nindicates a model where recombination rate and exon density are two independent\ncauses of GC-content variation. {\\bf Conclusions}: Causal inference and\ngraphical models are useful methods to understand genome evolution and the\nmechanisms of isochore evolution in the human genome.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.3132v1"
    },
    {
        "title": "On the clustering of rare codons and its effect on translation",
        "authors": [
            "Lalit Ponnala"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  The presence of clusters of rare codons is known to negatively impact the\nefficiency and accuracy of protein production. In this paper, we demonstrate a\nstatistical method of identifying such clusters in the coding sequence of a\ngene. Using E. coli as our model organism, we show that genes having denser\nclusters tend to have lower protein yields.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.0429v1"
    },
    {
        "title": "GeneSupport Maximum Gene-Support Tree Approach to Species Phylogeny\n  Inference",
        "authors": [
            "Yunfeng Shan",
            "Xiu-Qing Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Summary: GeneSupport implements a genome-scale algorithm: Maximum\nGene-Support Tree to estimate species tree from gene trees based on multilocus\nsequences. It provides a new option for multiple genes to infer species tree.\nIt is incorporated into popular phylogentic program: PHYLIP package with the\nsame usage and user interface. It is suitable for phylogenetic methods such as\nmaximum parsimony, maximum likelihood, Baysian and neighbour-joining, which is\nused to reconstruct single gene trees firstly with a variety of phylogenetic\ninference programs.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.1953v1"
    },
    {
        "title": "Mechanics and Dynamics of X-Chromosome Pairing at X Inactivation",
        "authors": [
            "A. Scialdone",
            "M. Nicodemi"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  At the onset of X Chromosomes Inactivation, the vital process whereby female\nmammal cells equalize X products with respect to males, the X chromosomes are\ncolocalized along their Xic (X-Inactivation Center) regions. The mechanism\ninducing recognition and pairing of the X's remains, though, elusive. Starting\nfrom recent discoveries on the molecular factors and on the DNA sequences (the\nso-called ``pairing sites'') involved, we dissect the mechanical basis of Xic\ncolocalization by using a Statistical Physics model. We show that soluble DNA\nspecific binding molecules, as those experimentally identified, can be indeed\nsufficient to induce the spontaneous colocalization of the homologous\nchromosomes, but only when their concentration, or chemical affinity, rises\nabove a threshold value, as a consequence of a thermodynamic phase transition.\nWe derive the likelihood of pairing and its probability distribution.\nChromosome dynamics has two stages: an initial independent Brownian diffusion\nfollowed, after a characteristic time scale, by recognition and pairing.\nFinally, we investigate the effects of DNA deletion/insertions in the region of\npairing sites and compare model predictions to available experimental data.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.2436v1"
    },
    {
        "title": "Thermodynamic pathways to genome spatial organization in the cell\n  nucleus",
        "authors": [
            "Mario Nicodemi",
            "Antonella Prisco"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  The architecture of the eukaryotic genome is characterized by a high degree\nof spatial organization. Chromosomes occupy preferred territories correlated to\ntheir state of activity and, yet, displace their genes to interact with remote\nsites in complex patterns requiring the orchestration of a huge number of DNA\nloci and molecular regulators. Far from random, this organization serves\ncrucial functional purposes, but its governing principles remain elusive. By\ncomputer simulations of a Statistical Mechanics model, we show how\narchitectural patterns spontaneously arise from the physical interaction\nbetween soluble binding molecules and chromosomes via collective thermodynamics\nmechanisms. Chromosomes colocalize, loops and territories form and find their\nrelative positions as stable thermodynamic states. These are selected by\n\"thermodynamic switches\" which are regulated by concentrations/affinity of\nsoluble mediators and by number/location of their attachment sites along\nchromosomes. Our \"thermodynamic switch model\" of nuclear architecture, thus,\nexplains on quantitative grounds how well known cell strategies of upregulation\nof DNA binding proteins or modification of chromatin structure can dynamically\nshape the organization of the nucleus.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.2678v1"
    },
    {
        "title": "Mean-field methods in evolutionary duplication-innovation-loss models\n  for the genome-level repertoire of protein domains",
        "authors": [
            "A. Angelini",
            "A. Amato",
            "G. Bianconi",
            "B. Bassetti",
            "M. Cosentino Lagomarsino"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  We present a combined mean-field and simulation approach to different models\ndescribing the dynamics of classes formed by elements that can appear,\ndisappear or copy themselves. These models, related to a paradigm\nduplication-innovation model known as Chinese Restaurant Process, are devised\nto reproduce the scaling behavior observed in the genome-wide repertoire of\nprotein domains of all known species. In view of these data, we discuss the\nqualitative and quantitative differences of the alternative model formulations,\nfocusing in particular on the roles of element loss and of the specificity of\nempirical domain classes.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.4253v2"
    },
    {
        "title": "Modelling survival and allele complementation in the evolution of\n  genomes with polymorphic loci",
        "authors": [
            "S. Cebrat",
            "D. Stauffer",
            "J. S. Sa Martins",
            "S. Moss de Oliveira",
            "P. M. C. de Oliveira"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  We have simulated the evolution of sexually reproducing populations composed\nof individuals represented by diploid genomes. A series of eight bits formed an\nallele occupying one of 128 loci of one haploid genome (chromosome). The\nenvironment required a specific activity of each locus, this being the sum of\nthe activities of both alleles located at the corresponding loci on two\nchromosomes. This activity is represented by the number of bits set to zero. In\na constant environment the best fitted individuals were homozygous with\nalleles' activities corresponding to half of the environment requirement for a\nlocus (in diploid genome two alleles at corresponding loci produced a proper\nactivity). Changing the environment under a relatively low recombination rate\npromotes generation of more polymorphic alleles. In the heterozygous loci,\nalleles of different activities complement each other fulfilling the\nenvironment requirements. Nevertheless, the genetic pool of populations evolves\nin the direction of a very restricted number of complementing haplotypes and a\nfast changing environment kills the population. If simulations start with all\nloci heterozygous, they stay heterozygous for a long time.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0589v1"
    },
    {
        "title": "Evolutionary Placement of Short Sequence Reads",
        "authors": [
            "S. A. Berger",
            "A. Stamatakis"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  We present an Evolutionary Placement Algorithm (EPA) for the rapid assignment\nof sequence fragments (short reads) to branches of a given phylogenetic tree\nunder the Maximum Likelihood (ML) model. The accuracy of the algorithm is\nevaluated on several real-world data sets and compared to placement by\npair-wise sequence comparison, using edit distances and BLAST.\n  We test two versions of the placement algorithm, one slow and more accurate\nwhere branch length optimization is conducted for each short read insertion and\na faster version where the branch lengths are approximated at the insertion\nposition. For the slow version, additional heuristic techniques are explored\nthat almost yield the same run time as the fast version, with only a small loss\nof accuracy. When those additional heuristics are employed the run time of the\nmore accurate algorithm is comparable to that of a simple BLAST search for data\nsets with a high number of short query sequences. Moreover, the accuracy of the\nEvolutionary Placement Algorithm is significantly higher, in particular when\nthe taxon sampling of the reference topology is sparse or inadequate. Our\nalgorithm, which has been integrated into RAxML, therefore provides an equally\nfast but more accurate alternative to BLAST for phylogeny-aware analysis of\nshort-read sequence data.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.2852v1"
    },
    {
        "title": "Minimal Conflicting Sets for the Consecutive Ones Property in ancestral\n  genome reconstruction",
        "authors": [
            "Cedric Chauve",
            "Utz-Uwe Haus",
            "Tamon Stephen",
            "Vivija P. You"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  A binary matrix has the Consecutive Ones Property (C1P) if its columns can be\nordered in such a way that all 1's on each row are consecutive. A Minimal\nConflicting Set is a set of rows that does not have the C1P, but every proper\nsubset has the C1P. Such submatrices have been considered in comparative\ngenomics applications, but very little is known about their combinatorial\nstructure and efficient algorithms to compute them. We first describe an\nalgorithm that detects rows that belong to Minimal Conflicting Sets. This\nalgorithm has a polynomial time complexity when the number of 1's in each row\nof the considered matrix is bounded by a constant. Next, we show that the\nproblem of computing all Minimal Conflicting Sets can be reduced to the joint\ngeneration of all minimal true clauses and maximal false clauses for some\nmonotone boolean function. We use these methods on simulated data related to\nancestral genome reconstruction to show that computing Minimal Conflicting Set\nis useful in discriminating between true positive and false positive ancestral\nsyntenies. We also study a dataset of yeast genomes and address the reliability\nof an ancestral genome proposal of the Saccahromycetaceae yeasts.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.4196v1"
    },
    {
        "title": "Maximum entropy models for antibody diversity",
        "authors": [
            "Thierry Mora",
            "Aleksandra Walczak",
            "William Bialek",
            "Curtis G. Callan Jr"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Recognition of pathogens relies on families of proteins showing great\ndiversity. Here we construct maximum entropy models of the sequence repertoire,\nbuilding on recent experiments that provide a nearly exhaustive sampling of the\nIgM sequences in zebrafish. These models are based solely on pairwise\ncorrelations between residue positions, but correctly capture the higher order\nstatistical properties of the repertoire. Exploiting the interpretation of\nthese models as statistical physics problems, we make several predictions for\nthe collective properties of the sequence ensemble: the distribution of\nsequences obeys Zipf's law, the repertoire decomposes into several clusters,\nand there is a massive restriction of diversity due to the correlations. These\npredictions are completely inconsistent with models in which amino acid\nsubstitutions are made independently at each site, and are in good agreement\nwith the data. Our results suggest that antibody diversity is not limited by\nthe sequences encoded in the genome, and may reflect rapid adaptation to\nantigenic challenges. This approach should be applicable to the study of the\nglobal properties of other protein families.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.5175v1"
    },
    {
        "title": "Expectation-Maximization (EM) Algorithms for Mapping Short Reads\n  Illustrated with FAIRE data and the TP53-WRAP53 Gene Region",
        "authors": [
            "Peter J. Waddell",
            "Timothy Herston"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Huge numbers of short reads are being generated for mapping back to the\ngenome to discover the frequency of transcripts, miRNAs, DNAase hypersensitive\nsites, FAIRE regions, nucleosome occupancy, etc. Since these reads are\ntypically short (e.g., 36 base pairs) and since many eukaryotic genomes,\nincluding humans, have highly repetitive sequences then many of these reads map\nto two or more locations in the genome. Current mapping of these reads, grading\nthem according to 0, 1 or 2 mismatches wastes a great deal of information.\nThese short sequences are typically mapped with no account of the accuracy of\nthe sequence, even in company software when per base error rates are being\nreported by another part of the machine. Further, multiply mapping locations\nare frequently discarded altogether or allocated with no regard to where other\nreads are accumulating. Here we show how to combine probabilistic mapping of\nreads with an EM algorithm to iteratively improve the empirical likelihood of\nthe allocation of short reads. Mapping using LAST takes into account the per\nbase accuracy of the read, plus insertions and deletions, plus anticipated\noccasional errors or SNPs with respect to the parent genome. The probabilistic\nEM algorithm iteratively allocates reads based on the proportion of reads\nmapping within windows on the previous cycle, along with any prior information\non where the read best maps. The methods are illustrated with FAIRE ENCODE data\nlooking at the very important head-to-head gene combination of TP53 and WRAP\n53.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.5315v1"
    },
    {
        "title": "A new method for identifying vertebrates using only their mitochondrial\n  DNA",
        "authors": [
            "Nikesh S. Dattani"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  A new method for determining whether or not a mitrochondrial DNA (mtDNA)\nsequence belongs to a vertebrate is described and tested. This method only\nneeds the mtDNA sequence of the organism in question, and unlike alignment\nbased methods, it does not require it to be compared with anything else. The\nmethod is tested on all 1877 mtDNA sequences that were on NCBI's nucleotide\ndatabase on August 12, 2009, and works in 94.57% of the cases. Furthermore, all\norganisms on which this method failed are closely related phylogenetically in\ncomparison to all other organisms included in the study. A list of potential\nextensions to this method and open problems that emerge out of this study is\npresented at the end.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.0113v1"
    },
    {
        "title": "On Weight Matrix and Free Energy Models for Sequence Motif Detection",
        "authors": [
            "Qing Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The problem of motif detection can be formulated as the construction of a\ndiscriminant function to separate sequences of a specific pattern from\nbackground. In computational biology, motif detection is used to predict DNA\nbinding sites of a transcription factor (TF), mostly based on the weight matrix\n(WM) model or the Gibbs free energy (FE) model. However, despite the wide\napplications, theoretical analysis of these two models and their predictions is\nstill lacking. We derive asymptotic error rates of prediction procedures based\non these models under different data generation assumptions. This allows a\ntheoretical comparison between the WM-based and the FE-based predictions in\nterms of asymptotic efficiency. Applications of the theoretical results are\ndemonstrated with empirical studies on ChIP-seq data and protein binding\nmicroarray data. We find that, irrespective of underlying data generation\nmechanisms, the FE approach shows higher or comparable predictive power\nrelative to the WM approach when the number of observed binding sites used for\nconstructing a discriminant decision is not too small.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.0341v2"
    },
    {
        "title": "DNA-MATRIX a tool for DNA motif discovery and weight matrix construction",
        "authors": [
            "Chandra Prakash Singh",
            "Feroz Khan",
            "Sanjay Kumar Singh",
            "Durg Singh Chauhan"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  In computational molecular biology, gene regulatory binding sites prediction\nin whole genome remains a challenge for the researchers. Now a days, the genome\nwide regulatory binding site prediction tools required either direct pattern\nsequence or weight matrix. Although there are known transcription factor\nbinding sites databases available for genome wide prediction but no tool is\navailable which can construct different weight matrices as per need of user or\ntools available for large data set scanning by first aligning the input\nupstream or promoter sequences and than construct the matrices in different\nlevel and file format. Considering this, we developed a DNA MATRIX tool for\nsearching putative regulatory binding sites in gene upstream sequences. This\ntool uses the simple biological rule based heuristic algorithm for weight\nmatrix construction, which can be transformed into different formats after\nmotif alignment and therefore provides the possibility to identify the most\npotential conserved binding sites in the regulated genes. The user may\nconstruct and save specific weight or frequency matrices in different form and\nfile formats based on user based selection of conserved aligned block of short\nsequences ranges from 6 to 20 base pairs and prior nucleotide frequency before\nweight scoring.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.1984v2"
    },
    {
        "title": "How and where to look for tRNAs in Metazoan mitochondrial genomes, and\n  what you might find when you get there",
        "authors": [
            "David A. Morrison"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The ability to locate and annotate mitochondrial genes is an important\npractical issue, given the rapidly increasing number of mitogenomes appearing\nin the public databases. Unfortunately, tRNA genes in Metazoan mitochondria\nhave proved to be problematic because they often vary in number (genes missing\nor duplicated) and also in the secondary structure of the transcribed tRNAs (T\nor D arms missing). I have performed a series of comparative analyses of the\ntRNA genes of a broad range of Metazoan mitogenomes in order to address this\nissue. I conclude that no single computer program is necessarily capable of\nfinding all of the tRNA genes in any given mitogenome, and that use of both the\nARWEN and DOGMA programs is sometimes necessary because they produce\ncomplementary false negatives. There are apparently a very large number of\nerroneous annotations in the databased mitogenome sequences, including missed\ngenes, wrongly annotated locations, false complements, and inconsistent\ncriteria for assigning the 5' and 3' boundaries; and I have listed many of\nthese. The extent of overlap between genes is often greatly exaggerated due to\ninconsistent annotations, although notable overlaps involving tRNAs are\napparently real. Finally, three novel hypotheses were examined and found to\nhave support from the comparative analyses: (1) some organisms have mitogenomic\nlocations that simultaneously code for multiple tRNAs; (2) some organisms have\nmitogenomic locations that simultaneously code for tRNAs and proteins (but not\nrRNAs); and (3) one group of nematodes has several genes that code for tRNAs\nlacking both the D and T arms.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.3813v2"
    },
    {
        "title": "BAK1 Gene Variation: the doubts remain",
        "authors": [
            "Michel E. Beleza Yamagishi"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Dr. Hatchwell [2010] has proposed that the BAK1 gene variants were likely due\nto sequencing of a processed gene on chromosome 20. However, in response, Dr.\nGottlieb and co-authors [2010] have argued that \"some but not all of the\nsequence changes present in the BAK1 sequence of our abdominal aorta samples\nare also present in the chromosome 20 BAK1 sequence. However, all the AAA and\nAA cDNA samples are identical to each other and different from chromosome 20\nBAK1 sequence at amino acids 2 and 145\". I have been following this discussion\nbecause I have independently reached almost the same conclusion as Dr.\nHatchwell did [Yamagishi, 2009], and, unfortunately, the response from Dr.\nGottlieb and his co-authors seems to me to be unsatisfactory for the reasons\nlisted below\n",
        "pdf_link": "http://arxiv.org/pdf/1002.2506v1"
    },
    {
        "title": "CGHTRIMMER: Discretizing noisy Array CGH Data",
        "authors": [
            "Charalampos E. Tsourakakis",
            "David Tolliver",
            "Maria A. Tsiarli",
            "Stanley Shackney",
            "Russell Schwartz"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The development of cancer is largely driven by the gain or loss of subsets of\nthe genome, promoting uncontrolled growth or disabling defenses against it.\nIdentifying genomic regions whose DNA copy number deviates from the normal is\ntherefore central to understanding cancer evolution. Array-based comparative\ngenomic hybridization (aCGH) is a high-throughput technique for identifying DNA\ngain or loss by quantifying total amounts of DNA matching defined probes\nrelative to healthy diploid control samples. Due to the high level of noise in\nmicroarray data, however, interpretation of aCGH output is a difficult and\nerror-prone task.\n  In this work, we tackle the computational task of inferring the DNA copy\nnumber per genomic position from noisy aCGH data. We propose CGHTRIMMER, a\nnovel segmentation method that uses a fast dynamic programming algorithm to\nsolve for a least-squares objective function for copy number assignment.\nCGHTRIMMER consistently achieves superior precision and recall to leading\ncompetitors on benchmarks of synthetic data and real data from the Coriell cell\nlines. In addition, it finds several novel markers not recorded in the\nbenchmarks but plausibly supported in the oncology literature. Furthermore,\nCGHTRIMMER achieves superior results with run-times from 1 to 3 orders of\nmagnitude faster than its state-of-art competitors.\n  CGHTRIMMER provides a new alternative for the problem of aCGH discretization\nthat provides superior detection of fine-scale regions of gain or loss yet is\nfast enough to process very large data sets in seconds. It thus meets an\nimportant need for methods capable of handling the vast amounts of data being\naccumulated in high-throughput studies of tumor genetics.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4438v1"
    },
    {
        "title": "Markov Logic Networks in the Analysis of Genetic Data",
        "authors": [
            "Nikita A. Sakhanenko",
            "David J. Galas"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Complex, non-additive genetic interactions are common and can be critical in\ndetermining phenotypes. Genome-wide association studies (GWAS) and similar\nstatistical studies of linkage data, however, assume additive models of gene\ninteractions in looking for genotype-phenotype associations. These statistical\nmethods view the compound effects of multiple genes on a phenotype as a sum of\npartial influences of each individual gene and can often miss a substantial\npart of the heritable effect. Such methods do not use any biological knowledge\nabout underlying genotype-phenotype mechanisms. Modeling approaches from the AI\nfield that incorporate deterministic knowledge into models to perform\nstatistical analysis can be applied to include prior knowledge in genetic\nanalysis. We chose to use the most general such approach, Markov Logic Networks\n(MLNs), as a framework for combining deterministic knowledge with statistical\nanalysis. Using simple, logistic regression-type MLNs we have been able to\nreplicate the results of traditional statistical methods. Moreover, we show\nthat even with simple models we are able to go beyond finding independent\nmarkers linked to a phenotype by using joint inference that avoids an\nindependence assumption. The method is applied to genetic data on yeast\nsporulation, a phenotype governed by non-linear gene interactions. In addition\nto detecting all of the previously identified loci associated with sporulation,\nour method is able to identify four loci with small effects. Since their effect\non sporulation is small, these four loci were not detected with methods that do\nnot account for dependence between markers due to gene interactions. We show\nhow gene interactions can be detected using more complex models, which can be\nused as a general framework for incorporating systems biology with genetics.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.0902v1"
    },
    {
        "title": "Inference of Gene Predictor Set Using Boolean Satisfiability",
        "authors": [
            "Pey-Chang Kent Lin",
            "Sunil P Khatri"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The inference of gene predictors in the gene regulatory network has become an\nimportant research area in the genomics and medical disciplines. Accurate\npredicators are necessary for constructing the GRN model and to enable targeted\nbiological experiments that attempt to confirm or control the regulation\nprocess. In this paper, we implement a SAT-based algorithm to determine the\ngene predictor set from steady state gene expression data (attractor states).\nUsing the attractor states as input, the states are ordered into attractor\ncycles. For each attractor cycle ordering, all possible predictors are\nenumerated and a CNF expression is formulated which encodes these predictors\nand their biological constraints. Each CNF is explored using a SAT solver to\nfind candidate predictor sets. Statistical analysis of the results selects the\nmost likely predictor set of the GRN corresponding to the attractor data. We\ndemonstrate our algorithm on attractor state data from a melanoma study, and\npresent our predictor set results.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4812v1"
    },
    {
        "title": "Improving the recombination estimation method of Padhukasahasram et al\n  2006",
        "authors": [
            "Badri Padhukasahasram"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The accuracy of the recombination estimation method of Padhukasahasram et al.\n2006 can be improved by including additional informative summary statistics in\nthe rejection scheme and by simulating datasets under a fixed segregating sites\nmodel. A C++ program that outputs these summary statistics is freely available\nfrom my website.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.5533v8"
    },
    {
        "title": "Induction of microRNAs, mir-155, mir-222, mir-424 and mir-503, promotes\n  monocytic differentiation through combinatorial regulation",
        "authors": [
            "A. R. R. Forrest",
            "M. Kanamori-Katayama",
            "Y. Tomaru",
            "T. Lassmann",
            "N. Ninomiya",
            "Y. Takahashi",
            "M. J. L. de Hoon",
            "A. Kubosaki",
            "A. Kaiho",
            "M. Suzuki",
            "J. Yasuda",
            "J. Kawai",
            "Y. Hayashizaki",
            "D. A. Hume",
            "H. Suzuki"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Acute myeloid leukemia (AML) involves a block in terminal differentiation of\nthe myeloid lineage and uncontrolled proliferation of a progenitor state. Using\nphorbol myristate acetate (PMA), it is possible to overcome this block in THP-1\ncells (an M5-AML containing the MLL-MLLT3 fusion), resulting in differentiation\nto an adherent monocytic phenotype. As part of FANTOM4, we used microarrays to\nidentify 23 microRNAs that are regulated by PMA. We identify four PMA-induced\nmicro- RNAs (mir-155, mir-222, mir-424 and mir-503) that when overexpressed\ncause cell-cycle arrest and partial differentiation and when used in\ncombination induce additional changes not seen by any individual microRNA. We\nfurther characterize these prodifferentiative microRNAs and show that mir-155\nand mir-222 induce G2 arrest and apoptosis, respectively. We find mir-424 and\nmir-503 are derived from a polycistronic precursor mir-424-503 that is under\nrepression by the MLL-MLLT3 leukemogenic fusion. Both of these microRNAs\ndirectly target cell-cycle regulators and induce G1 cell-cycle arrest when\noverexpressed in THP-1. We also find that the pro-differentiative mir-424 and\nmir-503 downregulate the anti-differentiative mir-9 by targeting a site in its\nprimary transcript. Our study highlights the combinatorial effects of multiple\nmicroRNAs within cellular systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.2689v1"
    },
    {
        "title": "Microbiome profiling by Illumina sequencing of combinatorial\n  sequence-tagged PCR products",
        "authors": [
            "Gregory B. Gloor",
            "Ruben Hummelen",
            "Jean M. Macklaim",
            "Russell J. Dickson",
            "Andrew D. Fernandes",
            "Roderick MacPhee",
            "Gregor Reid"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  We developed a low-cost, high-throughput microbiome profiling method that\nuses combinatorial sequence tags attached to PCR primers that amplify the rRNA\nV6 region. Amplified PCR products are sequenced using an Illumina paired-end\nprotocol to generate millions of overlapping reads. Combinatorial sequence\ntagging can be used to examine hundreds of samples with far fewer primers than\nis required when sequence tags are incorporated at only a single end. The\nnumber of reads generated permitted saturating or near-saturating analysis of\nsamples of the vaginal microbiome. The large number of reads al- lowed an\nin-depth analysis of errors, and we found that PCR-induced errors composed the\nvast majority of non-organism derived species variants, an ob- servation that\nhas significant implications for sequence clustering of similar high-throughput\ndata. We show that the short reads are sufficient to assign organisms to the\ngenus or species level in most cases. We suggest that this method will be\nuseful for the deep sequencing of any short nucleotide region that is\ntaxonomically informative; these include the V3, V5 regions of the bac- terial\n16S rRNA genes and the eukaryotic V9 region that is gaining popularity for\nsampling protist diversity.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.5075v1"
    },
    {
        "title": "Succinct Data Structures for Assembling Large Genomes",
        "authors": [
            "Thomas C Conway",
            "Andrew J Bromage"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Motivation: Second generation sequencing technology makes it feasible for\nmany researches to obtain enough sequence reads to attempt the de novo assembly\nof higher eukaryotes (including mammals). De novo assembly not only provides a\ntool for understanding wide scale biological variation, but within human\nbio-medicine, it offers a direct way of observing both large scale structural\nvariation and fine scale sequence variation. Unfortunately, improvements in the\ncomputational feasibility for de novo assembly have not matched the\nimprovements in the gathering of sequence data. This is for two reasons: the\ninherent computational complexity of the problem, and the in-practice memory\nrequirements of tools.\n  Results: In this paper we use entropy compressed or succinct data structures\nto create a practical representation of the de Bruijn assembly graph, which\nrequires at least a factor of 10 less storage than the kinds of structures used\nby deployed methods. In particular we show that when stored succinctly, the de\nBruijn assembly graph for homo sapiens requires only 23 gigabytes of storage.\nMoreover, because our representation is entropy compressed, in the presence of\nsequencing errors it has better scaling behaviour asymptotically than\nconventional approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.2555v1"
    },
    {
        "title": "Integration of Differential Gene-combination Search and Gene Set\n  Enrichment Analysis: A General Approach",
        "authors": [
            "Gang Fang",
            "Michael Steinbach",
            "Chad L. Myers",
            "Vipin Kumar"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Gene Set Enrichment Analysis (GSEA) and its variations aim to discover\ncollections of genes that show moderate but coordinated differences in\nexpression. However, such techniques may be ineffective if many individual\ngenes in a phenotype-related gene set have weak discriminative power. A\npotential solution is to search for combinations of genes that are highly\ndifferentiating even when individual genes are not. Although such techniques\nhave been developed, these approaches have not been used with GSEA to any\nsignificant degree because of the large number of potential gene combinations\nand the heterogeneity of measures that assess the differentiation provided by\ngene groups of different sizes.\n  To integrate the search for differentiating gene combinations and GSEA, we\npropose a general framework with two key components: (A) a procedure that\nreduces the number of scores to be handled by GSEA to the number of genes by\nsummarizing the scores of the gene combinations involving a particular gene in\na single score, and (B) a procedure to integrate the heterogeneous scores from\ncombinations of different sizes and from different gene combination measures by\nmapping the scores to p-values. Experiments on four gene expression data sets\ndemonstrate that the integration of GSEA and gene combination search can\nenhance the power of traditional GSEA by discovering gene sets that include\ngenes with weak individual differentiation but strong joint discriminative\npower. Also, gene sets discovered by the integrative framework share several\ncommon biological processes and improve the consistency of the results among\nthree lung cancer data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.3474v1"
    },
    {
        "title": "The pattern and process of gene family evolution",
        "authors": [
            "Gergely J Szöllősi",
            "Vincent Daubin"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Large scale databases are available that contain homologous gene families\nconstructed from hundreds of complete genome sequences from across the three\ndomains of Life. Here we discuss approches of increasing complexity aimed at\nextracting information on the pattern and process of gene family evolution from\nsuch datasets. In particular, we consider models that invoke processes of gene\nbirth (duplication and transfer) and death (loss) to explain the evolution of\ngene families. First, we review birth-and-death models of family size evolution\nand their implications in light of the universal features of family size\ndistribution observed across different species and the three domains of life.\nSubsequently, we proceed to recent developments on models capable of more\ncompletely considering information in the sequences of homologous gene families\nthrough the probabilistic reconciliation of the phylogenetic histories of\nindividual genes with the phylogenetic history of the genomes in which they\nhave resided. To illustrate the methods and results presented, we use data from\nthe HOGENOM database, demonstrating that the distribution of homologous gene\nfamily sizes in the genomes of the Eukaryota, Archaea and Bacteria exhibit\nremarkably similar shapes. We shown that these distributions are best described\nby models of gene family size evolution where for individual genes the death\n(loss) rate is larger than the birth (duplication and transfer) rate, but new\nfamilies are continually supplied to the genome by a process of origination.\nFinally, we use probabilistic reconciliation methods to take into consideration\nadditional information from gene phylogenies, and find that, for prokaryotes,\nthe majority of birth events are the result of transfer.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.2331v1"
    },
    {
        "title": "Negative Example Aided Transcription Factor Binding Site Search",
        "authors": [
            "Chih Lee",
            "Chun-Hsi Huang"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Computational approaches to transcription factor binding site identification\nhave been actively researched for the past decade.\n  Negative examples have long been utilized in de novo motif discovery and have\nbeen shown useful in transcription factor binding site search as well.\n  However, understanding of the roles of negative examples in binding site\nsearch is still very limited.\n  We propose the 2-centroid and optimal discriminating vector methods, taking\ninto account negative examples. Cross-validation results on E. coli\ntranscription factors show that the proposed methods benefit from negative\nexamples, outperforming the centroid and position-specific scoring matrix\nmethods. We further show that our proposed methods perform better than a\nstate-of-the-art method. We characterize the proposed methods in the context of\nthe other compared methods and show that, coupled with motif subtype\nidentification, the proposed methods can be effectively applied to a wide range\nof transcription factors. Finally, we argue that the proposed methods are\nwell-suited for eukaryotic transcription factors as well.\n  Software tools are available at: http://biogrid.engr.uconn.edu/tfbs_search/.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.1234v1"
    },
    {
        "title": "Models for transcript quantification from RNA-Seq",
        "authors": [
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  RNA-Seq is rapidly becoming the standard technology for transcriptome\nanalysis. Fundamental to many of the applications of RNA-Seq is the\nquantification problem, which is the accurate measurement of relative\ntranscript abundances from the sequenced reads. We focus on this problem, and\nreview many recently published models that are used to estimate the relative\nabundances. In addition to describing the models and the different approaches\nto inference, we also explain how methods are related to each other. A key\nresult is that we show how inference with many of the models results in\nidentical estimates of relative abundances, even though model formulations can\nbe very different. In fact, we are able to show how a single general model\ncaptures many of the elements of previously published methods. We also review\nthe applications of RNA-Seq models to differential analysis, and explain why\naccurate relative transcript abundance estimates are crucial for downstream\nanalyses.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.3889v2"
    },
    {
        "title": "Diffusion-based DNA target colocalization by thermodynamic mechanisms",
        "authors": [
            "Antonio Scialdone",
            "Mario Nicodemi"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  In eukaryotic cell nuclei, a variety of DNA interactions with nuclear\nelements occur, which, in combination with intra- and inter- chromosomal\ncross-talks, shape a functional 3D architecture. In some cases they are\norganized by active, i.e. actin/myosin, motors. More often, however, they have\nbeen related to passive diffusion mechanisms. Yet, the crucial questions on how\nDNA loci recognize their target and are reliably shuttled to their destination\nby Brownian diffusion are still open. Here, we complement the current\nexperimental scenario by considering a physics model, in which the interaction\nbetween distant loci is mediated by diffusing bridging molecules. We show that,\nin such a system, the mechanism underlying target recognition and\ncolocalization is a thermodynamic switch-like process (a phase transition) that\nonly occurs if the concentration and affinity of binding molecules is above a\nthreshold, or else stable contacts are not possible. We also briefly discuss\nthe kinetics of this \"passive-shuttling\" process, as produced by random\ndiffusion of DNA loci and their binders, and derive predictions based on the\neffects of genomic modifications and deletions.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.0880v1"
    },
    {
        "title": "Population Fitness and Genetic Load of Single Nucleotide Polymorphisms\n  Affecting mRNA splicing",
        "authors": [
            "Peter Rogan",
            "Eliseos Mucaki"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Deleterious genetic variants can be evaluated as quantitative traits using\ninformation theory-based sequence analysis of recognition sites. To assess the\neffect of such variants, fitness and genetic load of SNPs which alter binding\nsite affinity are derived from changes in individual information and allele\nfrequencies. Human SNPs that alter mRNA splicing are partitioned according to\ntheir genetic load. SNPs with high genetic loads (>0.5) are common in the\ngenome and, in many instances, predicted effects are supported by gene\nexpression studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.0716v1"
    },
    {
        "title": "Codon Capture and Ambiguous Intermediate Scenarios of Genetic Code\n  Evolution",
        "authors": [
            "Tatsuro Yamashita",
            "Osamu Narikiyo"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Using the shape space of codons and tRNAs we give a physical description of\nthe genetic code evolution on the basis of the codon capture and ambiguous\nintermediate scenarios in a consistent manner. In the lowest dimensional\nversion of our description, a physical quantity, codon level is introduced. In\nterms of the codon levels two scenarios are typically classified into two\ndifferent routes of the evolutional process. In the case of the ambiguous\nintermediate scenario we perform an evolutional simulation implemented cost\nselection of amino acids and confirm a rapid transition of the code change.\nSuch rapidness reduces uncomfortableness of the non-unique translation of the\ncode at intermediate state that is the weakness of the scenario. In the case of\nthe codon capture scenario the survival against mutations under the mutational\npressure minimizing GC content in genomes is simulated and it is demonstrated\nthat cells which experience only neutral mutations survive.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.5123v1"
    },
    {
        "title": "SLIQ: Simple Linear Inequalities for Efficient Contig Scaffolding",
        "authors": [
            "Rajat S. Roy",
            "Kevin C. Chen",
            "Anirvan M. Sengupta",
            "Alexander Schliep"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Scaffolding is an important subproblem in \"de novo\" genome assembly in which\nmate pair data are used to construct a linear sequence of contigs separated by\ngaps. Here we present SLIQ, a set of simple linear inequalities derived from\nthe geometry of contigs on the line that can be used to predict the relative\npositions and orientations of contigs from individual mate pair reads and thus\nproduce a contig digraph. The SLIQ inequalities can also filter out unreliable\nmate pairs and can be used as a preprocessing step for any scaffolding\nalgorithm. We tested the SLIQ inequalities on five real data sets ranging in\ncomplexity from simple bacterial genomes to complex mammalian genomes and\ncompared the results to the majority voting procedure used by many other\nscaffolding algorithms. SLIQ predicted the relative positions and orientations\nof the contigs with high accuracy in all cases and gave more accurate position\npredictions than majority voting for complex genomes, in particular the human\ngenome. Finally, we present a simple scaffolding algorithm that produces linear\nscaffolds given a contig digraph. We show that our algorithm is very efficient\ncompared to other scaffolding algorithms while maintaining high accuracy in\npredicting both contig positions and orientations for real data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.1426v2"
    },
    {
        "title": "Polymorphic gene conferring susceptibility to insulin-dependent diabetes\n  mellitus typed by ps-resolved FRET on nonamplified genomic DNA",
        "authors": [
            "Luca Nardo",
            "Giovanna Tosi",
            "Maria Bondani",
            "Roberto S. Accolla",
            "Alessandra Andreoni"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  This work concerns the identification of the allelic sequences of the DQB1\ngene of the human leukocyte antigen system conferring susceptibility to the\ndevelopment of insulin-dependent diabetes mellitus (IDDM) in DNA samples with\nno need of PCR amplification. Our method is based on the time-resolved analysis\nof a F\\\"orster energy-transfer mechanism that occurs in a dual-labeled\nfluorescent probe specific for the base sequence of the allelic variant of\ninterest. Such an oligonucleotide probe is labeled, at the two ends, by a pair\nof chromophores that operate as donor and acceptor in a F\\\"orster resonant\nenergy-transfer. The donor fluorescence is quenched with an efficiency that is\nstrongly dependent on the donor-to-acceptor distance, hence on the\nconfiguration of the probe after hybridization with the DNA containing or not\nthe selected allelic sequence. By time-correlated single-photon counting,\nperformed with an excitation/detection system endowed with 30-ps resolution, we\nmeasure the time-resolved fluorescence decay of the donor and discriminate, by\nmeans of the decay time value, the DNA bearing the allele conferring\nsusceptibility to IDDM from the DNAs bearing any other sequence in the same\nregion of the DQB1 gene.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.2563v1"
    },
    {
        "title": "Global transposable characteristics in the yeast complete DNA sequence",
        "authors": [
            "Zuo-Bing Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Global transposable characteristics in the complete DNA sequence of the\nSaccharomyces cevevisiae yeast is determined by using the metric representation\nand recurrence plot methods. In the form of the correlation distance of\nnucleotide strings, 16 chromosome sequences of the yeast, which are divided\ninto 5 groups, display 4 kinds of the fundamental transposable characteristics:\na short period increasing, a long quasi-period increasing, a long major value\nand hardly relevant.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.2771v1"
    },
    {
        "title": "Segmenting DNA sequence into `words'",
        "authors": [
            "Wang Liang"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  This paper presents a novel method to segment/decode DNA sequences based on\nn-grams statistical language model. Firstly, we find the length of most DNA\n'words' is 12 to 15 bps by analyzing the genomes of 12 model species. Then we\ndesign an unsupervised probability based approach to segment the DNA sequences.\nThe benchmark of segmenting method is also proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.2518v4"
    },
    {
        "title": "CLEVER: Clique-Enumerating Variant Finder",
        "authors": [
            "Tobias Marschall",
            "Ivan Costa",
            "Stefan Canzar",
            "Markus Bauer",
            "Gunnar Klau",
            "Alexander Schliep",
            "Alexander Schönhuth"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Next-generation sequencing techniques have facilitated a large scale analysis\nof human genetic variation. Despite the advances in sequencing speeds, the\ncomputational discovery of structural variants is not yet standard. It is\nlikely that many variants have remained undiscovered in most sequenced\nindividuals. Here we present a novel internal segment size based approach,\nwhich organizes all, including also concordant reads into a read alignment\ngraph where max-cliques represent maximal contradiction-free groups of\nalignments. A specifically engineered algorithm then enumerates all max-cliques\nand statistically evaluates them for their potential to reflect insertions or\ndeletions (indels). For the first time in the literature, we compare a large\nrange of state-of-the-art approaches using simulated Illumina reads from a\nfully annotated genome and present various relevant performance statistics. We\nachieve superior performance rates in particular on indels of sizes 20--100,\nwhich have been exposed as a current major challenge in the SV discovery\nliterature and where prior insert size based approaches have limitations. In\nthat size range, we outperform even split read aligners. We achieve good\nresults also on real data where we make a substantial amount of correct\npredictions as the only tool, which complement the predictions of split-read\naligners. CLEVER is open source (GPL) and available from\nhttp://clever-sv.googlecode.com.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.0937v2"
    },
    {
        "title": "MALDIquant: a versatile R package for the analysis of mass spectrometry\n  data",
        "authors": [
            "Sebastian Gibb",
            "Korbinian Strimmer"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Summary: MALDIquant is an R package providing a complete and modular analysis\npipeline for quantitative analysis of mass spectrometry data. MALDIquant is\nspecifically designed with application in clinical diagnostics in mind and\nimplements sophisticated routines for importing raw data, preprocessing,\nnon-linear peak alignment, and calibration. It also handles technical\nreplicates as well as spectra with unequal resolution.\n  Availability: MALDIquant and its associated R packages readBrukerFlexData and\nreadMzXmlData are freely available from the R archive CRAN\n(http://cran.r-project.org). The software is distributed under the GNU General\nPublic License (version 3 or later) and is accompanied by example files and\ndata. Additional documentation is available from\nhttp://strimmerlab.org/software/maldiquant/.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.5885v3"
    },
    {
        "title": "The Chromatin Organization of an Eukaryotic Genome : Sequence Specific+\n  Statistical=Combinatorial (Extended Abstract)",
        "authors": [
            "Davide Corona",
            "Valeria Di Benedetto",
            "Raffaele Giancarlo",
            "Filippo Utro"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Nucleosome organization in eukaryotic genomes has a deep impact on gene\nfunction. Although progress has been recently made in the identification of\nvarious concurring factors influencing nucleosome positioning, it is still\nunclear whether nucleosome positions are sequence dictated or determined by a\nrandom process. It has been postulated for a long time that,in the proximity of\nTSS, a barrier determines the position of the +1 nucleosome and then geometric\nconstraints alter the random positioning process determining nucleosomal\nphasing. Such a pattern fades out as one moves away from the barrier to become\nagain a random positioning process. Although this statistical model is widely\naccepted,the molecular nature of the barrier is still unknown. Moreover,we are\nfar from the identification of a set of sequence rules able:to account for the\ngenome-wide nucleosome organization;to explain the nature of the barriers on\nwhich the statistical mechanism hinges;to allow for a smooth transition from\nsequence-dictated to statistical positioning and back. We show that sequence\ncomplexity,quantified via various methods, can be the rule able to at least\npartially account for all the above.In particular, we have conducted our\nanalyses on 4 high resolution nucleosomal maps of the model eukaryotes and\nfound that nucleosome depleted regions can be well distinguished from\nnucleosome enriched regions by sequence complexity measures.In particular, (a)\nthe depleted regions are less complex than the enriched ones, (b) around TSS\ncomplexity measures alone are in striking agreement with in vivo nucleosome\noccupancy,in particular precisely indicating the positions of the +1 and -1\nnucleosomes. Those findings indicate that the intrinsic richness of\nsubsequences within sequences plays a role in nucleosomal formation in genomes,\nand that sequence complexity constitutes the molecular nature of nucleosome\nbarrier.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.6010v1"
    },
    {
        "title": "Haplotype-based variant detection from short-read sequencing",
        "authors": [
            "Erik Garrison",
            "Gabor Marth"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The direct detection of haplotypes from short-read DNA sequencing data\nrequires changes to existing small-variant detection methods. Here, we develop\na Bayesian statistical framework which is capable of modeling multiallelic loci\nin sets of individuals with non-uniform copy number. We then describe our\nimplementation of this framework in a haplotype-based variant detector,\nFreeBayes.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.3907v2"
    },
    {
        "title": "A Quantitative Understanding of Human Sex Chromosomal Genes",
        "authors": [
            "Sk. Sarif Hassan",
            "Pabitra Pal Choudhury",
            "Antara Sengupta",
            "Binayak Sahu",
            "Rojalin Mishra",
            "Devendra Kumar Yadav",
            "Saswatee Panda",
            "Dharamveer Pradhan",
            "Shrusti Dash",
            "Gourav Pradhan"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  In the last few decades, the human allosomes are engrossed in an intensive\nattention among researchers. The allosomes are now already been sequenced and\nfound there are about 2000 and 78 genes in human X and Y chromosomes\nrespectively. The hemizygosity of the human X chromosome in males exposes\nrecessive disease alleles, and this phenomenon has prompted decades of\nintensive study of X-linked disorders. By contrast, the small size of the human\nY chromosome, and its prominent long-arm heterochromatic region suggested\nabsence of function beyond sex determination. But the present problem is to\naccomplish whether a given sequence of nucleotides i.e. a DNA is a Human X or Y\nchromosomal genes or not, without any biological experimental support. In our\nperspective, a proper quantitative understanding of these genes is required to\njustify or nullify whether a given sequence is a Human X or Y chromosomal gene.\nIn this paper, some of the X and Y chromosomal genes have been quantified in\ngenomic and proteomic level through Fractal Geometric and Mathematical\nMorphometric analysis. Using the proposed quantitative model, one can easily\nmake probable justification or deterministic nullification whether a given\nsequence of nucleotides is a probable Human X or Y chromosomal gene or not,\nwithout seeking any biological experiment. Of course, a further biological\nexperiment is essential to validate it as the probable Human X or Y chromosomal\ngene homologue. This study would enable Biologists to understand these genes in\nmore quantitative manner instead of their qualitative features.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.5289v2"
    },
    {
        "title": "ARISA data from the human gut microbiome can detect individual\n  differences observed by 454 sequencing regardless of binning strategy",
        "authors": [
            "Robert W. Reid",
            "Melanie D. Spencer",
            "Timothy J. Hamp",
            "Anthony A. Fodor"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  ARISA (Automated Ribosomal Intergenic Spacer Analysis) is a low-cost\ntechnique that allows for the rapid comparison of different microbial\nenvironments. In this study, we asked if a set of ARISA profiles can\ndistinguish human microbial environments from one another with the same\naccuracy as results generated from 454 high throughput DNA sequencing. Using a\nset of human microbial communities where the sequencing results cluster by\nsubject, we tested how choices made during ARISA data processing influence\nclustering. We found that choice of clustering methods had a profound effect\nwith Ward's clustering generating profiles the most similar to 454 sequencing.\nFactors such as bin size, using presence or absence calls and technical\nreplicate manipulation had a negligible effect on clustering. In fact, no\nestablished bin sizing method reported in the literature performed\nsignificantly different results than simply picking bin intervals at random. We\nconclude that in an analysis of ARISA data from an ecosystem of sufficient\ncomplexity to saturate bins, a careful choice of clustering algorithm is\nessential whereas differing strategies for choosing bins are likely to have a\nmuch less pronounced effect on the outcome of the analysis. As a tool for\ndistinguishing complex microbial communities, ARISA closely approximates the\nresults obtained from DNA sequencing at a fraction of the cost; however ARISA\nfails to reproduce the sequencing results perfectly.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.7017v1"
    },
    {
        "title": "Systematic transcriptome wide analysis of lncRNA-miRNA interactions",
        "authors": [
            "Saakshi Jalali",
            "Deeksha Bhartiya",
            "Vinod Scaria"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Long noncoding RNAs (lncRNAs) are a recently discovered class of non-protein\ncoding RNAs which have now increasingly been shown to be involved in a wide\nvariety of biological processes as regulatory molecules. Little is known\nregarding the regulatory interactions between noncoding RNA classes. Recent\nreports have suggested that lncRNAs could potentially interact with other\nnoncoding RNAs including miroRNAs (miRNAs) and modulate their regulatory role\nthrough interactions. We hypothesized that long noncoding RNAs could\nparticipate as a layer of regulatory interactions with miRNAs. The availability\nof genome-scale datasets for argonaute targets across human transcriptome has\nprompted us to reconstruct a genome-scale network of interactions between\nmiRNAs and lncRNAs.\n  We used well characterized experimental\nPhotoactivatable-Ribonucleoside-Enhanced Crosslinking and Immunoprecipitation\n(PAR-CLIP) datasets and the recent genome-wide annotations for lncRNAs in\npublic domain to construct a comprehensive transcriptome-wide map of miRNA\nregulatory elements. Comparative analysis revealed many of the miRNAs could\ntarget long noncoding RNAs, apart from the coding transcripts thus\nparticipating in a novel layer of regulatory interactions between noncoding RNA\nclasses. We also find the miRNA regulatory elements have a positional\npreference, clustering towards the 3' and 5' ends of the long noncoding\ntranscripts. We also further reconstruct a genome-wide map of miRNA\ninteractions with lncRNAs as well as messenger RNAs.\n  This analysis suggests widespread regulatory interactions between noncoding\nRNAs classes and suggests a novel functional role for lncRNAs. We also present\nthe first transcriptome scale study on lncRNA-miRNA interactions and the first\nreport of a genome-scale reconstruction of a noncoding RNA regulatory\ninteractome involving lncRNAs.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.0154v1"
    },
    {
        "title": "Size and location of radish 1 chromosome regions carrying the fertility\n  restorer Rfk1 gene in spring turnip rape",
        "authors": [
            "T. Niemelä",
            "M. Seppänen",
            "F. Badakshi",
            "V. M. Rokka",
            "J. S. Heslop-Harrison"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  In spring turnip rape (Brassica rapa L. spp. oleifera) the most promising F1\nhybrid system would be the Ogu-INRA CMS/Rf system. A Kosena fertility restorer\ngene Rfk1, homologue of the Ogura restorer gene Rfo, was successfully\ntransferred from oilseed rape into turnip rape and that restored the fertility\nin female lines carrying Ogura cms. The trait was, however, unstable in\nsubsequent generations. The physical localization of the radish chromosomal\nregion carrying the Rfk1 gene was investigated using 8 GISH (genomic in situ\nhybridization) and BAC-FISH (bacterial artificial chromosome fluorescence in\nsitu hybridization) methods. The metaphase chromosomes were hybridized using\nradish DNA as the genomic probe and BAC64 probe, which is linked with Rfo gene.\nBoth probes showed a signal in the chromosome spreads of the restorer line\n4021-2 Rfk of turnip rape but not in the negative control line 4021B. The GISH\nanalyses clearly showed that the turnip rape restorer plants were either\nmonosomic (2n=2x=20+1R) or disomic (2n=2x=20+2R) addition lines with one or two\ncopies of a single alien chromosome region originating from radish. In the\nBAC-FISH analysis, double dot signals were detected in sub-terminal parts of\nthe radish chromosome arms showing that the fertility restorer gene Rfk1 was\nlocated in this additional radish chromosome. Detected disomic addition lines\nwere found to be unstable for turnip rape hybrid production. Using the BAC-FISH\nanalysis, weak signals were sometimes visible in two chromosomes of turnip rape\nand a homologous region of Rfk1 in chromosome 9 of the B. rapa A genome was\nverified with BLAST analysis. In the future this homologous area in A genome\ncould be substituted with radish chromosome area carrying the Rfk1 gene.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.0440v1"
    },
    {
        "title": "Reverse Engineering Gene Interaction Networks Using the Phi-Mixing\n  Coefficient",
        "authors": [
            "Nitin Kumar Singh",
            "M. Eren Ahsen",
            "Shiva Mankala",
            "Hyun-Seok Kim",
            "Michael A. White",
            "M. Vidyasagar"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Constructing gene interaction networks (GINs) from high-throughput gene\nexpression data is an important and challenging problem in systems biology.\nExisting algorithms produce networks that either have undirected and unweighted\nedges, or else are constrained to contain no cycles, both of which are\nbiologically unrealistic. In the present paper we propose a new algorithm,\nbased on a concept from probability theory known as the phi-mixing coefficient,\nthat produces networks whose edges are weighted and directed, and are permitted\nto contain cycles. Because there is no \"ground truth\" for genome-wide networks\non a human scale, we analyzed the outcomes of several experiments on lung\ncancer, and matched the predictions from the inferred networks with\nexperimental results. Specifically, we inferred three networks (NSCLC,\nNeuro-endocrine NSCLC plus SCLC, and normal) from the gene expression\nmeasurements of 157 lung cancer and 59 normal cell lines, compared with the\noutcomes of siRNA screening of 19,000+ genes on 11 NSCLC cell lines, and\nanalyzed data from a ChIP-Seq experiment to determine putative downstream\ntargets of the lineage specific oncogenic transcription factor ASCL1. The\ninferred networks displayed a scale-free or power law behavior between the\ndegree of a node and the number of nodes with that degree. There was a strong\ncorrelation between the degree of a gene in the inferred NSCLC network and its\nessentiality for the survival of the cells. The inferred downstream\nneighborhood genes of ASCL1 in the SCLC network were significantly enriched by\nChIP-Seq determined putative target genes, while no such enrichment was found\nin the inferred NSCLC network.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.4066v2"
    },
    {
        "title": "Reevaluating Assembly Evaluations with Feature Response Curves: GAGE and\n  Assemblathons",
        "authors": [
            "Francesco Vezzi",
            "Giuseppe Narzisi",
            "Bud Mishra"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  In just the last decade, a multitude of bio-technologies and software\npipelines have emerged to revolutionize genomics. To further their central\ngoal, they aim to accelerate and improve the quality of de novo whole-genome\nassembly starting from short DNA reads. However, the performance of each of\nthese tools is contingent on the length and quality of the sequencing data, the\nstructure and complexity of the genome sequence, and the resolution and quality\nof long-range information. Furthermore, in the absence of any metric that\ncaptures the most fundamental \"features\" of a high-quality assembly, there is\nno obvious recipe for users to select the most desirable assembler/assembly.\nInternational competitions such as Assemblathons or GAGE tried to identify the\nbest assembler(s) and their features. Some what circuitously, the only\navailable approach to gauge de novo assemblies and assemblers relies solely on\nthe availability of a high-quality fully assembled reference genome sequence.\nStill worse, reference-guided evaluations are often both difficult to analyze,\nleading to conclusions that are difficult to interpret. In this paper, we\ncircumvent many of these issues by relying upon a tool, dubbed FRCbam, which is\ncapable of evaluating de novo assemblies from the read-layouts even when no\nreference exists. We extend the FRCurve approach to cases where lay-out\ninformation may have been obscured, as is true in many deBruijn-graph-based\nalgorithms. As a by-product, FRCurve now expands its applicability to a much\nwider class of assemblers -- thus, identifying higher-quality members of this\ngroup, their inter-relations as well as sensitivity to carefully selected\nfeatures, with or without the support of a reference sequence or layout for the\nreads. The paper concludes by reevaluating several recently conducted assembly\ncompetitions and the datasets that have resulted from them.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.1095v1"
    },
    {
        "title": "A phylogeny of birds based on over 1,500 loci collected by target\n  enrichment and high-throughput sequencing",
        "authors": [
            "John E. McCormack",
            "Michael G. Harvey",
            "Brant C. Faircloth",
            "Nicholas G. Crawford",
            "Travis C. Glenn",
            "Robb T. Brumfield"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Evolutionary relationships among birds in Neoaves, the clade comprising the\nvast majority of avian diversity, have vexed systematists due to the ancient,\nrapid radiation of numerous lineages. We applied a new phylogenomic approach to\nresolve relationships in Neoaves using target enrichment (sequence capture) and\nhigh-throughput sequencing of ultraconserved elements (UCEs) in avian genomes.\nWe collected sequence data from UCE loci for 32 members of Neoaves and one\noutgroup (chicken) and analyzed data sets that differed in their amount of\nmissing data. An alignment of 1,541 loci that allowed missing data was 87%\ncomplete and resulted in a highly resolved phylogeny with broad agreement\nbetween the Bayesian and maximum-likelihood (ML) trees. Although results from\nthe 100% complete matrix of 416 UCE loci were similar, the Bayesian and ML\ntrees differed to a greater extent in this analysis, suggesting that increasing\nfrom 416 to 1,541 loci led to increased stability and resolution of the tree.\nNovel results of our study include surprisingly close relationships between\nphenotypically divergent bird families, such as tropicbirds (Phaethontidae) and\nthe sunbittern (Eurypygidae) as well as between bustards (Otididae) and turacos\n(Musophagidae). This phylogeny bolsters support for monophyletic waterbird and\nlandbird clades and also strongly supports controversial results from previous\nstudies, including the sister relationship between passerines and parrots and\nthe non-monophyly of raptorial birds in the hawk and falcon families. Although\nsignificant challenges remain to fully resolving some of the deep relationships\nin Neoaves, especially among lineages outside the waterbirds and landbirds,\nthis study suggests that increased data will yield an increasingly resolved\navian phylogeny.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.1604v2"
    },
    {
        "title": "A 454 survey of the community composition and core microbiome of the\n  common bed bug, Cimex lectularius, reveals significant microbial community\n  structure across an urban landscape",
        "authors": [
            "Matthew Meriweather",
            "Sara Matthews",
            "Rita Rio",
            "Regina S Baucom"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Elucidating the spatial dynamic and core constituents of the microbial\ncommunities found in association with arthropod hosts is of crucial importance\nfor insects that may vector human or agricultural pathogens. The hematophagous\nCimex lectularius, known as the common bed bug, has made a recent resurgence in\nNorth America, as well as worldwide, potentially owing to increased travel and\nresistance to insecticides. A comprehensive survey of the bed bug microbiome\nhas not been performed to date, nor has an assessment of the spatial dynamics\nof its microbiome. Here we present a survey of bed bug microbial communities by\namplifying the V4-V6 hypervariable region of the 16S rDNA gene region followed\nby 454 Titanium sequencing using 31 individuals from eight natural populations\ncollected from residences in Cincinnati, OH. Across all samples, 97% of the\nmicrobial community is made up of two dominant OTUs identified as the\n{\\alpha}-proteobacterium Wolbachia and an unnamed {\\gamma}-proteobacterium from\nthe Enterobacteriaceae. Microbial communities varied among host populations for\nmeasures of community diversity and exhibited significant population structure.\nWe also uncovered a strong negative correlation in the abundance of the two\ndominant OTUs, suggesting they may fulfill similar roles as nutritional\nmutualists. This broad survey represents the most comprehensive assessment, to\ndate, of the microbes that associate with bed bugs, and uncovers evidence for\npotential antagonism between the two dominant members of the bed bug\nmicrobiome.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.3707v1"
    },
    {
        "title": "CGB: A UNIX shell program to create custom instances of the UCSC Genome\n  Browser",
        "authors": [
            "Vincenzo Forgetta",
            "Ken Dewar"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The UCSC Genome Browser is a popular tool for the exploration and analysis of\nreference genomes. Mirrors of the UCSC Genome Browser and its contents exist at\nmultiple geographic locations, and this mirror procedure has been modified to\nsupport genome sequences not maintained by UCSC and generated by individual\nresearchers. While straightforward, this procedure is lengthy and tedious and\nwould benefit from automation, especially when processing many genome\nsequences. We present a Unix shell program that facilitates the creation of\ncustom instances of the UCSC Genome Browser for genome sequences not being\nmaintained by UCSC. It automates many steps of the browser creation process,\nprovides password protection for each browser instance, and automates the\ncreation of basic annotation tracks. As an example we generate a custom UCSC\nGenome Browser for a bacterial genome obtained from a massively parallel\nsequencing platform.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.1607v1"
    },
    {
        "title": "Improved haplotyping of rare variants using next-generation sequence\n  data",
        "authors": [
            "Fouad Zakharia",
            "Carlos Bustamante"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Accurate identification of haplotypes in sequenced human genomes can provide\ninvaluable information about population demography and fine-scale correlations\nalong the genome, thus empowering both population genomic and medical\nassociation studies. Yet phasing unrelated individuals remains a challenging\nproblem. Incorporating available data from high throughput sequencing into\ntraditional statistical phasing approaches is a promising avenue to alleviate\nthese issues. We present a novel statistical method that expands on an existing\ngraphical haplotype reconstruction method (shapeIT) to incorporate phasing\ninformation from paired-end read data. The algorithm harnesses the haplotype\ngraph information estimated by shapeIT from genotypes across the population and\nrefines haplotype likelihoods for a given individual to be compatible with the\nsequencing data. Applying the method to HapMap individuals genotyped on the\nAffymetrix Axiom chip at 7,745,081 SNPs and on a trio sequenced by Complete\nGenomics, we found that the inclusion of paired end read data significantly\nimproved phasing, with reductions in switch error on the order of 4-15% against\nshapeIT across all panels. As expected, the improvements were found to be most\nsignificant at sites harboring rare variants; furthermore, we found that longer\nread sizes and higher throughput translated to greater decreases in switching\nerror, as did higher variance in the size of the insert separating the two\nreads--suggesting that multi-platform next generation sequencing may be\nexploited to yield particularly accurate haplotypes. Overall, the phasing\nimprovements afforded by this new method highlight the power of integrating\nsequencing read information and population genotype data for reconstructing\nhaplotypes in unrelated individuals.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.2049v1"
    },
    {
        "title": "Modelling Breakage-Fusion-Bridge Cycles as a Stochastic Paper Folding\n  Process",
        "authors": [
            "CD Greenman",
            "SL Cooke",
            "J Marshall",
            "MR Stratton",
            "PJ Campbell"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Breakage-Fusion-Bridge cycles in cancer arise when a broken segment of DNA is\nduplicated and an end from each copy joined together. This structure then\n`unfolds' into a new piece of palindromic DNA. This is one mechanism\nresponsible for the localised amplicons observed in cancer genome data. The\nprocess has parallels with paper folding sequences that arise when a piece of\npaper is folded several times and then unfolded. Here we adapt such methods to\nstudy the breakage-fusion-bridge structures in detail. We firstly consider\ndiscrete representations of this space with 2-d trees to demonstrate that there\nare 2^(n(n-1)/2) qualitatively distinct evolutions involving n\nbreakage-fusion-bridge cycles. Secondly we consider the stochastic nature of\nthe fold positions, to determine evolution likelihoods, and also describe how\namplicons become localised. Finally we highlight these methods by inferring the\nevolution of breakage-fusion-bridge cycles with data from primary tissue cancer\nsamples.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.2356v1"
    },
    {
        "title": "Intraspecific Comparative Genomics of Candida albicans Mitochondria\n  Reveals Non-Coding Regions Under Neutral Evolution",
        "authors": [
            "Thais F. Bartelli",
            "Renata C. Ferreira",
            "Arnaldo L. Colombo",
            "Marcelo R. S. Briones"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The opportunistic fungal pathogen Candida albicans causes serious hematogenic\nhospital acquired candidiasis with worldwide impact on public health. Because\nof its importance as a nosocomial etiologic agent, C. albicans genome has been\nlargely studied to identify intraspecific variation and several typing methods\nhave been developed to distinguish closely related strains. Mitochondrial DNA\ncan be useful for this purpose because, as compared to nuclear DNA, its higher\nmutational load and evolutionary rate readily reveals microvariants.\nAccordingly, we sequenced and assembled, with 8 fold coverage, the\nmitochondrial genomes of two C. albicans clinical isolates (L296 and L757) and\ncompared these sequences with the genome sequence of reference strain SC5314.\nThe genome alignment of 33,928 positions revealed 372 polymorphic sites being\n230 in coding and 142 in non-coding regions. Three intergenic regions located\nbetween genes tRNAGly/COX1, NAD3/COB and ssurRNA/NAD4L, named IG1, IG2 and IG3\nrespectively, which showed high number of neutral substitutions, were amplified\nand sequenced from 18 clinical isolates from different locations in Latin\nAmerica and 2 ATCC standard C. albicans strains. High variability of sequence\nand size were observed, ranging up to 56bp size difference and phylogenies\nbased on IG1, IG2 and IG3 revealed three groups. Insertions of up to 49bp were\nobserved exclusively in Argentinean strains relative to the other sequences\nwhich could suggest clustering by geographical polymorphism. Because of neutral\nevolution, high variability, easy isolation by PCR and full length sequencing\nthese mitochondrial intergenic regions can contribute with a novel perspective\nin molecular studies of C. albicans isolates, complementing well established\nmultilocus sequence typing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.6003v1"
    },
    {
        "title": "Detection of selective sweeps in cattle using genome-wide SNP data",
        "authors": [
            "Holly R. Ramey",
            "Jared E. Decker",
            "Stephanie D. McKay",
            "Megan M. Rolf",
            "Robert D. Schnabel",
            "Jeremy F. Taylor"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The domestication and subsequent selection by humans to create breeds of\ncattle undoubtedly altered the patterning of variation within their genomes.\nStrong selection to fix advantageous large-effect mutations underlying\ndomesticability, breed characteristics or productivity created selective sweeps\nin which variation was lost in the chromosomal region flanking the selected\nallele. Selective sweeps have been identified in the genomes of many species\nincluding humans, dogs, horses, and chickens. We attempt to identify regions of\nthe bovine genome that have been subjected to selective sweeps. Two datasets\nwere used for the discovery and validation of selective sweeps via the fixation\nof alleles at a series of contiguous SNP loci. BovineSNP50 data were used to\nidentify 28 putative sweep regions among 14 cattle breeds. Affymetrix BOS 1\nprescreening assay data for five breeds were used to identify 114 regions and\nvalidate 5 regions identified using the BovineSNP50 data. Many genes are\nlocated within these regions; however, phenotypes that we predict to have\nhistorically been under strong selection include horned-polled, coat color,\nstature, ear morphology, and behavior. The identified selective sweeps\nrepresent recent events associated with breed formation rather than ancient\nevents associated with domestication. No sweep regions were shared between\nindicine and taurine breeds reflecting their divergent selection histories. A\nprimary finding of this study is the sensitivity of results to assay\nresolution. Despite the bias towards common SNPs in the BovineSNP50 design,\nfalse positive sweep regions appear to be common due to the limited resolution\nof the assay. This assay design bias leads to the detection of breed-specific\nsweep regions, or regions shared by a small number of breeds, restricting the\nsuite of selected phenotypes detected to primarily those associated with breed\ncharacteristics.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.2300v1"
    },
    {
        "title": "Comment on \"Evidence of Abundant and Purifying Selection in Humans for\n  Recently Acquired Regulatory Functions\"",
        "authors": [
            "Nicolas Bray",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Ward and Kellis (Reports, September 5 2012) identify regulatory regions in\nthe human genome exhibiting lineage-specific constraint and estimate the extent\nof purifying selection. There is no statistical rationale for the examples they\nhighlight, and their estimates of the fraction of the genome under constraint\nare biased by arbitrary designations of completely constrained regions.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.3076v1"
    },
    {
        "title": "Integrating Prior Knowledge Into Prognostic Biomarker Discovery based on\n  Network Structure",
        "authors": [
            "Yupeng Cun",
            "Holger Fröhlich"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Background: Predictive, stable and interpretable gene signatures are\ngenerally seen as an important step towards a better personalized medicine.\nDuring the last decade various methods have been proposed for that purpose.\nHowever, one important obstacle for making gene signatures a standard tool in\nclinics is the typical low reproducibility of these signatures combined with\nthe difficulty to achieve a clear biological interpretation. For that purpose\nin the last years there has been a growing interest in approaches that try to\nintegrate information from molecular interaction networks. Results: We propose\na novel algorithm, called FrSVM, which integrates protein-protein interaction\nnetwork information into gene selection for prognostic biomarker discovery. Our\nmethod is a simple filter based approach, which focuses on central genes with\nlarge differences in their expression. Compared to several other competing\nmethods our algorithm reveals a significantly better prediction performance and\nhigher signature stability. More- over, obtained gene lists are highly enriched\nwith known disease genes and drug targets. We extendd our approach further by\nintegrating information on candidate disease genes and targets of disease\nassociated Transcript Factors (TFs).\n",
        "pdf_link": "http://arxiv.org/pdf/1212.3214v2"
    },
    {
        "title": "New g%AIC, g%AICc, g%BIC, and Power Divergence Fit Statistics Expose\n  Mating between Modern Humans, Neanderthals and other Archaics",
        "authors": [
            "Peter J. Waddell",
            "Xi Tan"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The purpose of this article is to look at how information criteria, such as\nAIC and BIC, relate to the g%SD fit criterion derived in Waddell et al. (2007,\n2010a). The g%SD criterion measures the fit of data to model based on a\nnormalized weighted root mean square percentage deviation between the observed\ndata and model estimates of the data, with g%SD = 0 being a perfectly fitting\nmodel. However, this criterion may not be adjusting for the number of\nparameters in the model comprehensively. Thus, its relationship to more\ntraditional measures for maximizing useful information in a model, including\nAIC and BIC, are examined. This results in an extended set of fit criteria\nincluding g%AIC and g%BIC. Further, a broader range of asymptotically most\npowerful fit criteria of the power divergence family, which includes maximum\nlikelihood (or minimum G^2) and minimum X^2 modeling as special cases, are used\nto replace the sum of squares fit criterion within the g%SD criterion. Results\nare illustrated with a set of genetic distances looking particularly at a range\nof Jewish populations, plus a genomic data set that looks at how Neanderthals\nand Denisovans are related to each other and modern humans. Evidence that Homo\nerectus may have left a significant fraction of its genome within the Denisovan\nis shown to persist with the new modeling criteria.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6820v1"
    },
    {
        "title": "Detecting Breakage Fusion Bridge cycles in tumor genomes -- an\n  algorithmic approach",
        "authors": [
            "Shay Zakov",
            "Marcus Kinsella",
            "Vineet Bafna"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Breakage-Fusion-Bridge (BFB) is a mechanism of genomic instability\ncharacterized by the joining and subsequent tearing apart of sister chromatids.\nWhen this process is repeated during multiple rounds of cell division, it leads\nto patterns of copy number increases of chromosomal segments as well as\nfold-back inversions where duplicated segments are arranged head-to-head. These\nstructural variations can then drive tumorigenesis.\n  BFB can be observed in progress using cytogenetic techniques, but generally\nBFB must be inferred from data like microarrays or sequencing collected after\nBFB has ceased. Making correct inferences from this data is not\nstraightforward, particularly given the complexity of some cancer genomes and\nBFB's ability to generate a wide range of rearrangement patterns.\n  Here we present algorithms to aid the interpretation of evidence for BFB. We\nfirst pose the BFB count vector problem: given a chromosome segmentation and\nsegment copy numbers, decide whether BFB can yield a chromosome with the given\nsegment counts. We present the first linear-time algorithm for the problem,\nimproving a previous exponential-time algorithm. We then combine this algorithm\nwith fold-back inversions to develop tests for BFB. We show that, contingent on\nassumptions about cancer genome evolution, count vectors and fold-back\ninversions are sufficient evidence for detecting BFB. We apply the presented\ntechniques to paired-end sequencing data from pancreatic tumors and confirm a\nprevious finding of BFB as well as identify a new chromosomal region likely\nrearranged by BFB cycles, demonstrating the practicality of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.2610v1"
    },
    {
        "title": "Does your gene need a background check? How genetic background impacts\n  the analysis of mutations, genes, and evolution",
        "authors": [
            "Chris H. Chandler",
            "Sudarshan Chari",
            "Ian Dworkin"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The premise of genetic analysis is that a causal link exists between\nphenotypic and allelic variation. Yet it has long been documented that mutant\nphenotypes are not a simple result of a single DNA lesion, but rather are due\nto interactions of the focal allele with other genes and the environment.\nAlthough an experimentally rigorous approach, focusing on individual mutations\nand isogenic control strains, has facilitated amazing progress within genetics\nand related fields, a glimpse back suggests that a vast complexity has been\nomitted from our current understanding of allelic effects. Armed with\ntraditional genetic analyses and the foundational knowledge they have provided,\nwe argue that the time and tools are ripe to return to the under-explored\naspects of gene function and embrace the context-dependent nature of genetic\neffects. We assert that a broad understanding of genetic effects and the\nevolutionary dynamics of alleles requires identifying how mutational outcomes\ndepend upon the wild-type genetic background. Furthermore, we discuss how best\nto exploit genetic background effects to broaden genetic research programs.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.2694v1"
    },
    {
        "title": "Transcript length mediates developmental timing of gene expression\n  across Drosophila",
        "authors": [
            "Carlo G. Artieri",
            "Hunter B. Fraser"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The time required to transcribe genes with long primary transcripts may limit\ntheir ability to be expressed in cells with short mitotic cycles, a phenomenon\ntermed intron delay. As such short cycles are a hallmark of the earliest stages\nof insect development, we used Drosophila developmental timecourse expression\ndata to test whether intron delay affects gene expression genome-wide, and to\ndetermine its consequences for the evolution of gene structure. We find that\nlong zygotically expressed, but not maternally deposited, genes show\nsubstantial delay in expression relative to their shorter counterparts and that\nthis delay persists over a substantial portion of the ~24 hours of\nembryogenesis. Patterns of RNA-seq coverage from the 5' and 3' ends of\ntranscripts show that this delay is consistent with their inability to\nterminate transcription, but not with transcriptional initiation-based\nregulatory control. Highly expressed zygotic genes are subject to purifying\nselection to maintain compact transcribed regions, allowing conservation of\nembryonic expression patterns across the Drosophila phylogeny. We propose that\nintron delay is an underappreciated physical mechanism affecting both patterns\nof expression as well as gene structure of many genes across Drosophila.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.4516v1"
    },
    {
        "title": "Characteristics of Intronic and Intergenic Human miRNAs and Features of\n  their Interaction with mRNA",
        "authors": [
            "Olga Berillo",
            "Assel Issabekova",
            "Mireille Regnier",
            "Anatoliy T. Ivashchenko"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Regulatory relationships of 686 intronic miRNA and 784 intergenic miRNAs with\nmRNAs of 51 intronic miRNA coding genes were established. Interaction features\nof studied miRNAs with 5'UTR, CDS and 3'UTR of mRNA of each gene were revealed.\nFunctional regions of mRNA were shown to be significantly heterogenous\naccording to the number of binding sites of miRNA and to the location density\nof these sites.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5093v1"
    },
    {
        "title": "Using Periodicity of Nucleotide Sequences",
        "authors": [
            "Rick B. Jenison"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Withdrawn by arXiv administrators due to content entirely plagiarized from\nother authors (not in arXiv).\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5273v2"
    },
    {
        "title": "Comprehensive evaluation of differential expression analysis methods for\n  RNA-seq data",
        "authors": [
            "Franck Rapaport",
            "Raya Khanin",
            "Yupu Liang",
            "Azra Krek",
            "Paul Zumbo",
            "Christopher E. Mason",
            "Nicholas D. Socci",
            "Doron Betel"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  High-throughput sequencing of RNA transcripts (RNA-seq) has become the method\nof choice for detection of differential expression (DE). Concurrent with the\ngrowing popularity of this technology there has been a significant research\neffort devoted towards understanding the statistical properties of this data\nand the development of analysis methods. We report on a comprehensive\nevaluation of the commonly used DE methods using the SEQC benchmark data set.\nWe evaluate a number of key features including: assessment of normalization,\naccuracy of DE detection, modeling of genes expressed in only one condition,\nand the impact of sequencing depth and number of replications on identifying DE\ngenes. We find significant differences among the methods with no single method\nconsistently outperforming the others. Furthermore, the performance of\narray-based approach is comparable to methods customized for RNA-seq data.\nPerhaps most importantly, our results demonstrate that increasing the number of\nreplicate samples provides significantly more detection power than increased\nsequencing depth.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5277v2"
    },
    {
        "title": "Statistical testing of shared genetic control for potentially related\n  traits",
        "authors": [
            "Chris Wallace"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Integration of data from genome-wide single nucleotide polymorphism (SNP)\nassociation studies of different traits should allow researchers to disentangle\nthe genetics of potentially related traits within individually associated\nregions. Formal statistical colocalisation testing of individual regions, which\nrequires selection of a set of SNPs summarizing the association in a region. We\nshow that the SNP selection method greatly affects type 1 error rates, with\npublished studies having used methods expected to result in substantially\ninflated type 1 error rates. We show that either avoiding variable selection\nand instead testing the most informative principal components or integrating\nover variable selection using Bayesian model averaging can lead to correct\ncontrol of type 1 error rates. Application to data from Graves' disease and\nHashimoto's thyroiditis reveals a common genetic signature across seven regions\nshared between the diseases, and indicates that in five of six regions\nassociated with Graves' disease and not Hashimoto's thyroiditis, this more\nlikely reflects genuine absence of association with the latter rather than lack\nof power. Our examination, by simulation, of the performance of colocalisation\ntests and associated software will foster more widespread adoption of formal\ncolocalisation testing. Given the increasing availability of large expression\nand genetic association data sets from disease-relevant tissue and purified\ncell populations, coupled with identification of regulatory sequences by\nprojects such as ENCODE, colocalisation analysis has the potential to reveal\nboth shared genetic signatures of related traits and causal disease genes and\ntissues.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5510v2"
    },
    {
        "title": "Accurate and robust genomic prediction of celiac disease using\n  statistical learning",
        "authors": [
            "Gad Abraham",
            "Jason A. Tye-Din",
            "Oneil G. Bhalala",
            "Adam Kowalczyk",
            "Justin Zobel",
            "Michael Inouye"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Practical application of genomic-based risk stratification to clinical\ndiagnosis is appealing yet performance varies widely depending on the disease\nand genomic risk score (GRS) method. Celiac disease (CD), a common\nimmune-mediated illness, is strongly genetically determined and requires\nspecific HLA haplotypes. HLA testing can exclude diagnosis but has low\nspecificity, providing little information suitable for clinical risk\nstratification. Using six European CD cohorts, we provide a proof-of-concept\nthat statistical learning approaches which simultaneously model all SNPs can\ngenerate robust and highly accurate predictive models based on genome-wide SNP\nprofiles. The high predictive capacity replicated both in cross-validation\nwithin each cohort (AUC of 0.87-0.89) and in independent replication across\ncohorts (AUC of 0.86-0.9), despite differences in ethnicity. The models\nexplained 30-35% of disease variance and up to $\\sim43\\%$ of heritability. The\nGRS's utility was assessed in different clinically relevant settings.\nComparable to HLA typing, the GRS can be used to identify individuals without\nCD with $\\geq99.6\\%$ negative predictive value however, unlike HLA typing,\npatients can also be stratified into categories of higher-risk for CD who would\nbenefit from more invasive and costly definitive testing. The GRS is flexible\nand its performance can be adapted to the clinical situation by adjusting the\nthreshold cut-off. Despite explaining a minority of disease heritability, our\nfindings indicate a predictive GRS provides clinically relevant information to\nimprove upon current diagnostic pathways for CD, and support further studies\nevaluating the clinical utility of this approach in CD and other complex\ndiseases.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.5948v3"
    },
    {
        "title": "On prediction of regulatory genes by analysis of C.elegans functional\n  networks",
        "authors": [
            "O. V. Valba",
            "S. K. Nechaev",
            "O. Vasieva"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Connectivity networks have recently become widely used in biology due to\nincreasing amounts of information on the physical and functional links between\nindividual proteins. This connectivity data provides valuable material for\nexpanding our knowledge far beyond the experimentally validated via\nmathematical analysis and theoretical predictions of new functional\ninteractions. In this paper we demonstrate an application of several algorithms\ndeveloped for the ranking of potential gene-expression regulators within the\ncontext of an associated network. We analyze how different types of\nconnectivity between genes and proteins affect the topology of the integral\nC.elegans functional network and thereby validate algorithmic performance. We\ndemonstrate the possible definition of co-expression gene clusters within a\nnetwork context from their specific motif distribution signatures. We also show\nthat the method based on the shortest path function (SPF) applied to gene\ninteractions sub-network of the co-expression gene cluster, efficiently\npredicts novel regulatory transcription factors (TFs). Simultaneous application\nof other methods, including only interactions with neighborhood genes, allows\nrapid ranking of potential regulators that could be functionally linked with\nthe group of co-expressed genes. Predicting functions of regulators for a\ncluster of ribosomal/mRNA metabolic genes we highlight a role of mRNA\ntranslation and decay in a longevity of organisms.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.3349v1"
    },
    {
        "title": "kdetrees: Nonparametric Estimation of Phylogenetic Tree Distributions",
        "authors": [
            "Grady Weyenberg",
            "Peter Huggins",
            "Christopher Schardl",
            "Daniel K Howe",
            "Ruriko Yoshida"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation: While the majority of gene histories found in a clade of\norganisms are expected to be generated by a common process (e.g. the coalescent\nprocess), it is well-known that numerous other coexisting processes (e.g.\nhorizontal gene transfers, gene duplication and subsequent\nneofunctionalization) will cause some genes to exhibit a history quite distinct\nfrom those of the majority of genes. Such \"outlying\" gene trees are considered\nto be biologically interesting and identifying these genes has become an\nimportant problem in phylogenetics.\n  Results: We propose and implement KDETREES, a nonparametric method of\nestimating distributions of phylogenetic trees, with the goal of identifying\ntrees which are significantly different from the rest of the trees in the\nsample. Our method compares favorably with a similar recently-published method,\nfeaturing an improvement of one polynomial order of computational complexity\n(to quadratic in the number of trees analyzed), with simulation studies\nsuggesting only a small penalty to classification accuracy. Application of\nKDETREES to a set of Apicomplexa genes identified several unreliable sequence\nalignments which had escaped previous detection, as well as a gene\nindependently reported as a possible case of horizontal gene transfer. We also\nanalyze a set of Epichloe genes, fungi symbiotic with grasses, successfully\nidentifying a contrived instance of paralogy.\n  Availability: Our method for estimating tree distributions and identifying\noutlying trees is implemented as the R package KDETREES, and is available for\ndownload from CRAN.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6422v3"
    },
    {
        "title": "Role of genetic polymorphisms in transgenerational inheritance in\n  budding yeast",
        "authors": [
            "Zuobin Zhu",
            "Qing Lu",
            "Dejian Yuan",
            "Yanke Li",
            "Xian Man",
            "Yueran Zhu",
            "Shi Huang"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Transgenerational inheritance of a trait is presumably affected by both\ngenetic and environmental factors but remains poorly understood. We studied the\neffect of genetic polymorphisms on transgenerational inheritance of yeast\nsegregants that were derived from a cross between a laboratory strain and a\nwild strain of Saccharomyces cerevisiae. For each SNP analyzed, the parental\nallele present in less than half of the segregants panel was called the minor\nallele (MA). We found a nonrandom distribution of MAs in the segregants,\nindicating natural selection. We compared segregants with high MA content (MAC)\nrelative to those with less and found a more dramatic shortening of the lag\nphase length for the high MAC group in response to 14 days of ethanol training.\nAlso, the short lag phase as acquired and epigenetically memorized by ethanol\ntraining was more dramatically lost after 7 days of recovery in ethanol free\nmedium for the high MAC group. Sodium chloride treatment produced similar\nobservations. Using public datasets, we found MAC linkage to mRNA expression of\nhundreds of genes. Finally, we found preferential effect of MAC on traits with\nhigh number of known additive quantitative trait loci (QTLs). These results\nprovide evidence for the slightly deleterious nature of most MAs and a lower\ncapacity to maintain inheritance of traits in individuals or cells with greater\nMAC, which have implications for disease prevention and treatment and the\n\"missing heritability\" problem in complex traits and diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.7276v3"
    },
    {
        "title": "A Model-Based Analysis of GC-Biased Gene Conversion in the Human and\n  Chimpanzee Genomes",
        "authors": [
            "John A. Capra",
            "Melissa J. Hubisz",
            "Dennis Kostka",
            "Katherine S. Pollard",
            "Adam Siepel"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  GC-biased gene conversion (gBGC) is a recombination-associated process that\nfavors the fixation of G/C alleles over A/T alleles. In mammals, gBGC is\nhypothesized to contribute to variation in GC content, rapidly evolving\nsequences, and the fixation of deleterious mutations, but its prevalence and\ngeneral functional consequences remain poorly understood. gBGC is difficult to\nincorporate into models of molecular evolution and so far has primarily been\nstudied using summary statistics from genomic comparisons. Here, we introduce a\nnew probabilistic model that captures the joint effects of natural selection\nand gBGC on nucleotide substitution patterns, while allowing for correlations\nalong the genome in these effects. We implemented our model in a computer\nprogram, called phastBias, that can accurately detect gBGC tracts ~1 kilobase\nor longer in simulated sequence alignments. When applied to real primate genome\nsequences, phastBias predicts gBGC tracts that cover roughly 0.3% of the human\nand chimpanzee genomes and account for 1.2% of human-chimpanzee nucleotide\ndifferences. These tracts fall in clusters, particularly in subtelomeric\nregions; they are enriched for recombination hotspots and fast-evolving\nsequences; and they display an ongoing fixation preference for G and C alleles.\nWe also find some evidence that they contribute to the fixation of deleterious\nalleles, including an enrichment for disease-associated polymorphisms. These\ntracts provide a unique window into historical recombination processes along\nthe human and chimpanzee lineages; they supply additional evidence of long-term\nconservation of megabase-scale recombination rates accompanied by rapid\nturnover of hotspots. Together, these findings shed new light on the\nevolutionary, functional, and disease implications of gBGC. The phastBias\nprogram and our predicted tracts are freely available.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.2170v1"
    },
    {
        "title": "The strength of genetic interactions scales weakly with the mutational\n  effects",
        "authors": [
            "Andrea Velenich",
            "Jeff Gore"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Genetic interactions pervade every aspect of biology, from evolutionary\ntheory where they determine the accessibility of evolutionary paths, to\nmedicine where they contribute to complex genetic diseases. Until very\nrecently, studies on epistatic interactions have been based on a handful of\nmutations, providing at best anecdotal evidence about the frequency and the\ntypical strength of genetic interactions. In this study we analyze the publicly\navailable Data Repository of Yeast Genetic INteractions (DRYGIN), which\ncontains the growth rates of over five million double gene knockout mutants. We\ndiscuss a geometric definition of epistasis which reveals a simple and\nsurprisingly weak scaling law for the characteristic strength of genetic\ninteractions as a function of the effects of the mutations being combined. We\nthen utilize this scaling to quantify the roughness of naturally occurring\nfitness landscapes. Finally, we show how the observed roughness differs from\nwhat is predicted by Fisher's geometric model of epistasis and discuss its\nconsequences on the evolutionary dynamics. Although epistatic interactions\nbetween specific genes remain largely unpredictable, the statistical properties\nof an ensemble of interactions can display conspicuous regularities and be\ndescribed by simple mathematical laws. By exploiting the amount of data\nproduced by modern high-throughput techniques it is now possible to thoroughly\ntest the predictions of theoretical models of genetic interactions and to build\ninformed computational models of evolution on realistic fitness landscapes.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4401v1"
    },
    {
        "title": "Genome wide identification of regulatory networks associated with\n  general cognitive ability using a normalized alignment free similarity\n  measure of promoter regions",
        "authors": [
            "Miriam Ruth Kantorovitz",
            "David Tcheng",
            "Michael I. Lerman",
            "Eric Jakobsson"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We show that a normalized alignment free similarity measure, called D2z, can\nbe used to detect potential regulatory relations for gene sets when little is\nknown about the regulatory elements involved. One scenario where such gene sets\narise is genome wide association studies (GWAS). In this work we consider a\ngene set from a GWAS on childhood general cognitive ability. We build a\nco-regulation network for the GWAS genes based on the D2z scores, which shows\npotential co-regulatory relationships between the genes as well as predict\nadditional genes that are likely to be part of the network. We found that the\nset of the predicted genes is enriched in genes associated with mental\nretardation and GO terms such as synapse and neuron development. In particular,\nwe found strong evidence of regulatory connection between the GWAS genes and\nCHL1, a gene known to be involved in mental retardation.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.1231v1"
    },
    {
        "title": "Probe region expression estimation for RNA-seq data for improved\n  microarray comparability",
        "authors": [
            "Karolis Uziela",
            "Antti Honkela"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Rapidly growing public gene expression databases contain a wealth of data for\nbuilding an unprecedentedly detailed picture of human biology and disease. This\ndata comes from many diverse measurement platforms that make integrating it all\ndifficult. Although RNA-sequencing (RNA-seq) is attracting the most attention,\nat present the rate of new microarray studies submitted to public databases far\nexceeds the rate of new RNA-seq studies. There is clearly a need for methods\nthat make it easier to combine data from different technologies. In this paper,\nwe propose a new method for processing RNA-seq data that yields gene expression\nestimates that are much more similar to corresponding estimates from microarray\ndata, hence greatly improving cross-platform comparability. The method we call\nPREBS is based on estimating the expression from RNA-seq reads overlapping the\nmicroarray probe regions, and processing these estimates with microarray\nsummarisation algorithm RMA. Using paired microarray and RNA-seq samples from\nTCGA LAML data set we show that PREBS expression estimates derived from RNA-seq\nare more similar to microarray-based expression estimates than those from other\nRNA-seq processing methods. In an experiment to retrieve paired microarray\nsamples from a database using an RNA-seq query sample, gene signatures defined\nbased on PREBS expression estimates were found to be much more accurate than\nthose from other methods. PREBS also allows new ways of using RNA-seq data,\nsuch as expression estimation for microarray probe sets. An implementation of\nthe proposed method is available in the Bioconductor package `prebs'.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.1698v2"
    },
    {
        "title": "Clusters of microRNAs emerge by new hairpins in existing transcripts",
        "authors": [
            "Antonio Marco",
            "Maria Ninova",
            "Matthew Ronshaugen",
            "Sam Griffiths-Jones"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Genetic linkage may result in the expression of multiple products from a\npolycistronic transcript, under the control of a single promoter. In animals,\nprotein-coding polycistronic transcripts are rare. However, microRNAs are\nfrequently clustered in the genomes of animals, and these clusters are often\ntranscribed as a single unit. The evolution of microRNA clusters has been the\nsubject of much speculation, and a selective advantage of clusters of\nfunctionally related microRNAs is often proposed. However, the origin of\nmicroRNA clusters has not been so far explored. Here we study the evolution of\nmicroRNA clusters in Drosophila melanogaster. We observed that the majority of\nmicroRNA clusters arose by the de novo formation of new microRNA-like hairpins\nin existing microRNA transcripts. Some clusters also emerged by tandem\nduplication of a single microRNA. Comparative genomics show that these clusters\nare unlikely to split or undergo rearrangements. We did not find any instances\nof clusters appearing by rearrangement of pre-existing microRNA genes. We\npropose a model for microRNA cluster evolution in which selection over one of\nthe microRNAs in the cluster interferes with the evolution of the other linked\nmicroRNAs. Our analysis suggests that the study of microRNAs and small RNAs\nmust consider linkage associations.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.2635v2"
    },
    {
        "title": "The influence of relatives on the efficiency and error rate of familial\n  searching",
        "authors": [
            "Rori V. Rohlfs",
            "Erin Murphy",
            "Yun S. Song",
            "Montgomery Slatkin"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We investigate the consequences of adopting the criteria used by the state of\nCalifornia, as described by Myers et al. (2011), for conducting familial\nsearches. We carried out a simulation study of randomly generated profiles of\nrelated and unrelated individuals with 13-locus CODIS genotypes and YFiler\nY-chromosome haplotypes, on which the Myers protocol for relative\nidentification was carried out. For Y-chromosome sharing first degree\nrelatives, the Myers protocol has a high probability (80 - 99%) of identifying\ntheir relationship. For unrelated individuals, there is a low probability that\nan unrelated person in the database will be identified as a first-degree\nrelative. For more distant Y-haplotype sharing relatives (half-siblings, first\ncousins, half-first cousins or second cousins) there is a substantial\nprobability that the more distant relative will be incorrectly identified as a\nfirst-degree relative. For example, there is a 3 - 18% probability that a first\ncousin will be identified as a full sibling, with the probability depending on\nthe population background. Although the California familial search policy is\nlikely to identify a first degree relative if his profile is in the database,\nand it poses little risk of falsely identifying an unrelated individual in a\ndatabase as a first-degree relative, there is a substantial risk of falsely\nidentifying a more distant Y-haplotype sharing relative in the database as a\nfirst-degree relative, with the consequence that their immediate family may\nbecome the target for further investigation. This risk falls disproportionately\non those ethnic groups that are currently overrepresented in state and federal\ndatabases.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.3160v2"
    },
    {
        "title": "Identifying cancer subtypes in glioblastoma by combining genomic,\n  transcriptomic and epigenomic data",
        "authors": [
            "Richard S. Savage",
            "Zoubin Ghahramani",
            "Jim E. Griffin",
            "Paul Kirk",
            "David L. Wild"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We present a nonparametric Bayesian method for disease subtype discovery in\nmulti-dimensional cancer data. Our method can simultaneously analyse a wide\nrange of data types, allowing for both agreement and disagreement between their\nunderlying clustering structure. It includes feature selection and infers the\nmost likely number of disease subtypes, given the data.\n  We apply the method to 277 glioblastoma samples from The Cancer Genome Atlas,\nfor which there are gene expression, copy number variation, methylation and\nmicroRNA data. We identify 8 distinct consensus subtypes and study their\nprognostic value for death, new tumour events, progression and recurrence. The\nconsensus subtypes are prognostic of tumour recurrence (log-rank p-value of\n$3.6 \\times 10^{-4}$ after correction for multiple hypothesis tests). This is\ndriven principally by the methylation data (log-rank p-value of $2.0 \\times\n10^{-3}$) but the effect is strengthened by the other 3 data types,\ndemonstrating the value of integrating multiple data types.\n  Of particular note is a subtype of 47 patients characterised by very low\nlevels of methylation. This subtype has very low rates of tumour recurrence and\nno new events in 10 years of follow up. We also identify a small gene\nexpression subtype of 6 patients that shows particularly poor survival\noutcomes. Additionally, we note a consensus subtype that showly a highly\ndistinctive data signature and suggest that it is therefore a biologically\ndistinct subtype of glioblastoma.\n  The code is available from https://sites.google.com/site/multipledatafusion/\n",
        "pdf_link": "http://arxiv.org/pdf/1304.3577v2"
    },
    {
        "title": "Genomic and phenotypic characterisation of a wild Medaka population:\n  Establishing an isogenic population genetic resource in fish",
        "authors": [
            "Mikhail Spivakov",
            "Thomas O. Auer",
            "Ravindra Peravali",
            "Ian Dunham",
            "Dirk Dolle",
            "Asao Fujiyama",
            "Atsushi Toyoda",
            "Tomoyuki Aizu",
            "Yohei Minakuchi",
            "Felix Loosli",
            "Kiyoshi Naruse",
            "Ewan Birney",
            "Joachim Wittbrodt"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background Oryzias latipes (Medaka) has been established as a vertebrate\ngenetic model for over a century, and has recently been rediscovered outside\nits native Japan. The power of new sequencing methods now makes it possible to\nreinvigorate Medaka genetics, in particular by establishing a near-isogenic\npanel derived from a single wild population. Results Here we characterise the\ngenomes of wild Medaka catches obtained from a single Southern Japanese\npopulation in Kiyosu as a precursor for the establishment of a near isogenic\npanel of wild lines. The population is free of significant detrimental\npopulation structure, and has advantageous linkage disequilibrium properties\nsuitable for establishment of the proposed panel. Analysis of morphometric\ntraits in five representative inbred strains suggests phenotypic mapping will\nbe feasible in the panel. In addition high throughput genome sequencing of\nthese Medaka strains confirms their evolutionary relationships on lines of\ngeographic separation and provides further evidence that there has been little\nsignificant interbreeding between the Southern and Northern Medaka population\nsince the Southern/Northern population split. The sequence data suggest that\nthe Southern Japanese Medaka existed as a larger older population which went\nthrough a relatively recent bottleneck around 10,000 years ago. In addition we\ndetect patterns of recent positive selection in the Southern population.\nConclusions These data indicate that the genetic structure of the Kiyosu Medaka\nsamples are suitable for the establishment of a vertebrate near isogenic panel\nand therefore inbreeding of 200 lines based on this population has commenced.\nProgress of this project can be tracked at\nhttp://www.ebi.ac.uk/birney-srv/medaka-ref-panel\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4515v2"
    },
    {
        "title": "XORRO: Rapid Paired-End Read Overlapper",
        "authors": [
            "Russell J. Dickson",
            "Gregory B. Gloor"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Background: Computational analysis of next-generation sequencing data is\noutpaced by data generation in many cases. In one such case, paired-end reads\ncan be produced from the Illumina sequencing method faster than they can be\noverlapped by downstream analysis. The advantages in read length and accuracy\nprovided by overlapping paired-end reads demonstrates the necessity for\nsoftware to efficiently solve this problem.\n  Results: XORRO is an extremely efficient paired-end read overlapping program.\nXORRO can overlap millions of short paired-end reads in a few minutes. It uses\n64-bit registers with a two bit alphabet to represent sequences and does\ncomparisons using low-level logical operations like XOR, AND, bitshifting and\npopcount.\n  Conclusions: As of the writing of this manuscript, XORRO provides the fastest\nsolution to the paired-end read overlap problem. XORRO is available for\ndownload at: sourceforge.net/projects/xorro-overlap/\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4620v1"
    },
    {
        "title": "On the Reproducibility of TCGA Ovarian Cancer MicroRNA Profiles",
        "authors": [
            "Ying-Wooi Wan",
            "Claire M. Mach",
            "Genevera Allen",
            "Matthew L. Anderson",
            "Zhandong Liu"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Dysregulated microRNA (miRNA) expression is a well-established feature of\nhuman cancer. However, the role of specific miRNAs in determining cancer\noutcomes remains unclear. Using Level 3 expression data from the Cancer Genome\nAtlas (TCGA), we identified 61 miRNAs that are associated with overall survival\nin 469 ovarian cancers profiled by microarray (p<0.01). We also identified 12\nmiRNAs that are associated with survival when miRNAs were profiled in the same\nspecimens using Next Generation Sequencing (miRNA-Seq) (p<0.01). Surprisingly,\nonly 1 miRNA transcript is associated with ovarian cancer survival in both\ndatasets. Our analyses indicate that this discrepancy is due to the fact that\nmiRNA levels reported by the two platforms correlate poorly, even after\ncorrecting for potential issues inherent to signal detection algorithms.\nFurther investigation is warranted.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.6966v2"
    },
    {
        "title": "Genetic Complexity in a Drosophila Model of Diabetes-Associated\n  Misfolded Human Proinsulin",
        "authors": [
            "Soo-Young Park",
            "Michael Z. Ludwig",
            "Natalia A. Tamarina",
            "Bin Z. He",
            "Sarah H. Carl",
            "Desiree A. Dickerson",
            "Levi Barse",
            "Bharath Arun",
            "Calvin Williams",
            "Cecelia M. Miles",
            "Louis H. Philipson",
            "Donald F. Steiner",
            "Graeme I. Bell",
            "Martin Kreitman"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Here we use Drosophila melanogaster to create a genetic model of human\npermanent neonatal diabetes mellitus and present experimental results\ndescribing dimensions of this complexity. The approach involves the transgenic\nexpression of a misfolded mutant of human preproinsulin, hINSC96Y, which is a\ncause of the disease. When expressed in fly imaginal discs, hINSC96Y causes a\nreduction of adult structures, including the eye, wing and notum. Eye imaginal\ndiscs exhibit defects in both the structure and arrangement of ommatidia. In\nthe wing, expression of hINSC96Y leads to ectopic expression of veins and\nmechano-sensory organs, indicating disruption of wild type signaling processes\nregulating cell fates. These readily measurable disease phenotypes are\nsensitive to temperature, gene dose and sex. Mutant (but not wild type)\nproinsulin expression in the eye imaginal disc induces IRE1-mediated Xbp1\nalternative splicing, a signal for endoplasmic reticulum stress response\nactivation, and produces global change in gene expression. Mutant hINS\ntransgene tester strains, when crossed to stocks from the Drosophila Genetic\nReference Panel produces F1 adults with a continuous range of disease\nphenotypes and large broad-sense heritability. Surprisingly, the severity of\nmutant hINS-induced disease in the eye is not correlated with that in the notum\nin these crosses, nor with eye reduction phenotypes caused by the expression of\ntwo dominant eye mutants acting in two different eye development pathways, Drop\n(Dr) or Lobe (L) when crossed into the same genetic backgrounds. The tissue\nspecificity of genetic variability for mutant hINS-induced disease thus has its\nown distinct signature. The genetic dominance of disease-specific phenotypic\nvariability makes this approach amenable to genome-wide association study\n(GWAS) in a simple F1 screen of natural variation.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.0025v1"
    },
    {
        "title": "Dynamic Transcript Profiling of Candida Albicans Infection in Zebrafish:\n  a Pathogen-Host Interaction Study",
        "authors": [
            "Yan Yu Chen",
            "Chun-Cheih Chao",
            "Fu-Chen Liu",
            "Po-Chen Hsu",
            "Hsueh-Fen Chen",
            "Shih-Chi Peng",
            "Yung-Jen Chuang",
            "Chung-Yu Lan",
            "Wen-Ping Hsieh",
            "David Shan Hill Wong"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Candida albicans is responsible for a number of life-threatening infections\nand causes considerable morbidity and mortality in immunocompromised patients.\nPrevious studies of C. albicans pathogenesis have suggested several steps must\noccur before virulent infection, including early adhesion, invasion, and late\ntissue damage. However, the mechanism that triggers C. albicans transformation\nfrom yeast to hyphae form during infection has yet to be fully elucidated. This\nstudy used a systems biology approach to investigate C. albicans infection in\nzebrafish. The surviving fish were sampled at different post-infection time\npoints to obtain time-lapsed, genome-wide transcriptomic data from both\norganisms, which were accompanied with in sync histological analyses. Principal\ncomponent analysis (PCA) was used to analyze the dynamic gene expression\nprofiles of significant variations in both C. albicans and zebrafish. The\nresults categorized C. albicans infection into three progressing phases:\nadhesion, invasion, and damage. Such findings were highly supported by the\ncorresponding histological analysis. Furthermore, the dynamic interspecies\ntranscript profiling revealed that C. albicans activated its filamentous\nformation during invasion and the iron scavenging functions during the damage\nphases, whereas zebrafish ceased its iron homeostasis function following\nmassive hemorrhage during the later stages of infection. This was followed by\nmassive hemorrhaging toward the end stage of infection. Most of the immune\nrelated genes were expressed as the infection progressed from invasion to the\ndamage phase. Such global, inter-species evidence of virulence-immune and iron\ncompetition dynamics during C. albicans infection could be crucial in\nunderstanding control fungal pathogenesis.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3312v1"
    },
    {
        "title": "Lineage specific reductions in genome size in salamanders are associated\n  with increased rates of mutation",
        "authors": [
            "John Herrick",
            "Bianca Sclavi"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Very low levels of genetic diversity have been reported in vertebrates with\nlarge genomes, notably salamanders and lungfish [1-3]. Interpreting differences\nin heterozygosity, which reflects genetic diversity in a population, is\ncomplicated because levels of heterozygosity vary widely between conspecific\npopulations, and correlate with many different physiological and demographic\nvariables such as body size and effective population size. Here we return to\nthe question of genetic variability in salamanders and report on the\nrelationship between evolutionary rates and genome sizes in five different\nsalamander families. We found that rates of evolution are exceptionally low in\nsalamanders as a group. Evolutionary rates are as low as those reported for\ncartilaginous fish, which have the slowest rates recorded so far in vertebrates\n[4]. We also found that, independent of life history, salamanders with the\nsmallest genomes (14 pg) are evolving at rates two to three times faster than\nsalamanders with the largest genomes (>50 pg). After accounting for\nevolutionary duration, we conclude that more recently evolved species have\ncorrespondingly smaller genomes compared to older taxa and concomitantly higher\nrates of mutation and evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.0798v2"
    },
    {
        "title": "Cell-cycle regulated transcription associates with DNA replication\n  timing in yeast and human",
        "authors": [
            "Hunter B. Fraser"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Eukaryotic DNA replication follows a specific temporal program, with some\ngenomic regions consistently replicating earlier than others, yet what\ndetermines this program is largely unknown. Highly transcribed regions have\nbeen observed to replicate in early S-phase in all plant and animal species\nstudied to date, but this relationship is thought to be absent from both\nbudding yeast and fission yeast. No association between cell-cycle regulated\ntranscription and replication timing has been reported for any species. Here I\nshow that in budding yeast, fission yeast, and human, the genes most highly\ntranscribed during S-phase replicate early, whereas those repressed in S-phase\nreplicate late. Transcription during other cell-cycle phases shows either the\nopposite correlation with replication timing, or no relation. The relationship\nis strongest near late-firing origins of replication, which is not consistent\nwith a previously proposed model -- that replication timing may affect\ntranscription -- and instead suggests a potential mechanism involving the\nrecruitment of limiting replication initiation factors during S-phase. These\nresults suggest that S-phase transcription may be an important determinant of\nDNA replication timing across eukaryotes, which may explain the\nwell-established association between transcription and replication timing.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.1985v1"
    },
    {
        "title": "Astrogenomics: big data, old problems, old solutions?",
        "authors": [
            "Aaron Golden",
            "S. George Djorgovski",
            "John M. Greally"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The ominous warnings of a `data deluge' in the life sciences from\nhigh-throughput DNA sequencing data are being supplanted by a second deluge, of\ncliches bemoaning our collective scientific fate unless we address the genomic\ndata `tsunami'. It is imperative that we explore the many facets of the genome,\nnot just sequence but also transcriptional and epigenetic variability,\nintegrating these observations in order to attain a genuine understanding of\nhow genes function, towards a goal of genomics-based personalized medicine.\nDetermining any individual's genomic properties requires comparison to many\nothers, sifting out the specific from the trends, requiring access to the many\nin order to yield information relevant to the few. This is the central big data\nchallenge in genomics that still requires some sort of resolution. Is there a\npractical, feasible way of directly connecting the scientific community to this\ndata universe? The best answer could be in the stars overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.3277v1"
    },
    {
        "title": "Sailfish: Alignment-free Isoform Quantification from RNA-seq Reads using\n  Lightweight Algorithms",
        "authors": [
            "Rob Patro",
            "Stephen M. Mount",
            "Carl Kingsford"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  RNA-seq has rapidly become the de facto technique to measure gene expression.\nHowever, the time required for analysis has not kept up with the pace of data\ngeneration. Here we introduce Sailfish, a novel computational method for\nquantifying the abundance of previously annotated RNA isoforms from RNA-seq\ndata. Sailfish entirely avoids mapping reads, which is a time-consuming step in\nall current methods. Sailfish provides quantification estimates much faster\nthan existing approaches (typically 20-times faster) without loss of accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.3700v1"
    },
    {
        "title": "Descriptive Statistics of the Genome: Phylogenetic Classification of\n  Viruses",
        "authors": [
            "Troy Hernandez",
            "Jie Yang"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The typical process for classifying and submitting a newly sequenced virus to\nthe NCBI database involves two steps. First, a BLAST search is performed to\ndetermine likely family candidates. That is followed by checking the candidate\nfamilies with the Pairwise Sequence Alignment tool for similar species. The\nsubmitter's judgement is then used to determine the most likely species\nclassification. The aim of this paper is to show that this process can be\nautomated into a fast, accurate, one-step process using the proposed\nalignment-free method and properly implemented machine learning techniques.\n  We present a new family of alignment-free vectorizations of the genome, the\ngeneralized vector, that maintains the speed of existing alignment-free methods\nwhile outperforming all available methods. This new alignment-free\nvectorization uses the frequency of genomic words (k-mers), as is done in the\ncomposition vector, and incorporates descriptive statistics of those k-mers'\npositional information, as inspired by the natural vector.\n  We analyze 5 different characterizations of genome similarity using\n$k$-nearest neighbor classification, and evaluate these on two collections of\nviruses totaling over 10,000 viruses. We show that our proposed method performs\nbetter than, or as well as, other methods at every level of the phylogenetic\nhierarchy.\n  The data and R code is available upon request.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.0408v2"
    },
    {
        "title": "Causes and Consequences of genetic background effects illuminated by\n  integrative genomic analysis",
        "authors": [
            "Christopher H. Chandler",
            "Sudarshan Chari",
            "David Tack",
            "Ian Dworkin"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The phenotypic consequences of individual mutations are modulated by the wild\ntype genetic background in which they occur.Although such background dependence\nis widely observed, we do not know whether general patterns across species and\ntraits exist, nor about the mechanisms underlying it. We also lack knowledge on\nhow mutations interact with genetic background to influence gene expression,\nand how this in turn mediates mutant phenotypes. Furthermore, how genetic\nbackground influences patterns of epistasis remains unclear. To investigate the\ngenetic basis and genomic consequences of genetic background dependence of the\nscallopedE3 allele on the Drosophila melanogaster wing, we generated multiple\nnovel genome level datasets from a mapping by introgression experiment and a\ntagged RNA gene expression dataset. In addition we used whole genome\nre-sequencing of the parental lines two commonly used laboratory strains to\npredict polymorphic transcription factor binding sites for SD. We integrated\nthese data with previously published genomic datasets from expression\nmicroarrays and a modifier mutation screen. By searching for genes showing a\ncongruent signal across multiple datasets, we were able to identify a robust\nset of candidate loci contributing to the background dependent effects of\nmutations in sd. We also show that the majority of background-dependent\nmodifiers previously reported are caused by higher-order epistasis, not\nquantitative non-complementation. These findings provide a useful foundation\nfor more detailed investigations of genetic background dependence in this\nsystem, and this approach is likely to prove useful in exploring the genetic\nbasis of other traits as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.0547v3"
    },
    {
        "title": "MOSAIK: A hash-based algorithm for accurate next-generation sequencing\n  read mapping",
        "authors": [
            "Wan-Ping Lee",
            "Michael Stromberg",
            "Alistair Ward",
            "Chip Stewart",
            "Erik Garrison",
            "Gabor T. Marth"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  This paper presents an accurate short-read mapper for next-generation\nsequencing data which is widely used in the 1000 Genomes Project, and human\nclinical and other species genome studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.1149v1"
    },
    {
        "title": "mTim: Rapid and accurate transcript reconstruction from RNA-Seq data",
        "authors": [
            "Georg Zeller",
            "Nico Goernitz",
            "Andre Kahles",
            "Jonas Behr",
            "Pramod Mudrakarta",
            "Soeren Sonnenburg",
            "Gunnar Raetsch"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Recent advances in high-throughput cDNA sequencing (RNA-Seq) technology have\nrevolutionized transcriptome studies. A major motivation for RNA-Seq is to map\nthe structure of expressed transcripts at nucleotide resolution. With accurate\ncomputational tools for transcript reconstruction, this technology may also\nbecome useful for genome (re-)annotation, which has mostly relied on de novo\ngene finding where gene structures are primarily inferred from the genome\nsequence. We developed a machine-learning method, called mTim (margin-based\ntranscript inference method) for transcript reconstruction from RNA-Seq read\nalignments that is based on discriminatively trained hidden Markov support\nvector machines. In addition to features derived from read alignments, it\nutilizes characteristic genomic sequences, e.g. around splice sites, to improve\ntranscript predictions. mTim inferred transcripts that were highly accurate and\nrelatively robust to alignment errors in comparison to those from Cufflinks, a\nwidely used transcript assembly method.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5211v1"
    },
    {
        "title": "The epigenome of evolving Drosophila neo-sex chromosomes: dosage\n  compensation and heterochromatin formation",
        "authors": [
            "Qi Zhou",
            "Christopher E. Ellison",
            "Vera B. Kaiser",
            "Artyom A. Alekseyenko",
            "Andrey A. Gorchakov",
            "Doris Bachtrog"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Drosophila Y chromosomes are composed entirely of silent heterochromatin,\nwhile male X chromosomes have highly accessible chromatin and are\nhypertranscribed due to dosage compensation. Here, we dissect the molecular\nmechanisms and functional pressures driving heterochromatin formation and\ndosage compensation of the recently formed neo-sex chromosomes of Drosophila\nmiranda. We show that the onset of heterochromatin formation on the neo-Y is\ntriggered by an accumulation of repetitive DNA. The neo-X has evolved partial\ndosage compensation and we find that diverse mutational paths have been\nutilized to establish several dozen novel binding consensus motifs for the\ndosage compensation complex on the neo-X, including simple point mutations at\npre-binding sites, insertion and deletion mutations, microsatellite expansions,\nor tandem amplification of weak binding sites. Spreading of these silencing or\nactivating chromatin modifications to adjacent regions results in massive\nmis-expression of neo-sex linked genes, and little correspondence between\nfunctionality of genes and their silencing on the neo-Y or dosage compensation\non the neo-X. Intriguingly, the genomic regions being targeted by the dosage\ncompensation complex on the neo-X and those becoming heterochromatic on the\nneo-Y show little overlap, possibly reflecting different propensities along the\nancestral chromosome to adopt active or repressive chromatin configurations.\nOur findings have broad implications for current models of sex chromosome\nevolution, and demonstrate how mechanistic constraints can limit evolutionary\nadaptations. Our study also highlights how evolution can follow predictable\ngenetic trajectories, by repeatedly acquiring the same 21-bp consensus motif\nfor recruitment of the dosage compensation complex, yet utilizing a diverse\narray of random mutational changes to attain the same phenotypic outcome.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.7072v1"
    },
    {
        "title": "A computational model for histone mark propagation reproduces the\n  distribution of heterochromatin in different human cell types",
        "authors": [
            "Veit Schwämmle",
            "Ole Nørregaard Jensen"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Chromatin is a highly compact and dynamic nuclear structure that consists of\nDNA and associated proteins. The main organizational unit is the nucleosome,\nwhich consists of a histone octamer with DNA wrapped around it. Histone\nproteins are implicated in the regulation of eukaryote genes and they carry\nnumerous reversible post-translational modifications that control DNA-protein\ninteractions and the recruitment of chromatin binding proteins.\nHeterochromatin, the transcriptionally inactive part of the genome, is densely\npacked and contains histone H3 that is methylated at Lys 9 (H3K9me). The\npropagation of H3K9me in nucleosomes along the DNA in chromatin is antagonizing\nby methylation of H3 Lysine 4 (H3K4me) and acetylations of several lysines,\nwhich is related to euchromatin and active genes. We show that the related\nhistone modifications form antagonized domains on a coarse scale. These histone\nmarks are assumed to be initiated within distinct nucleation sites in the DNA\nand to propagate bi-directionally. We propose a simple computer model that\nsimulates the distribution of heterochromatin in human chromosomes. The\nsimulations are in agreement with previously reported experimental observations\nfrom two different human cell lines. We reproduced different types of barriers\nbetween heterochromatin and euchromatin providing a unified model for their\nfunction. The effect of changes in the nucleation site distribution and of\npropagation rates were studied. The former occurs mainly with the aim of\n(de-)activation of single genes or gene groups and the latter has the power of\ncontrolling the transcriptional programs of entire chromosomes. Generally, the\nregulatory program of gene transcription is controlled by the distribution of\nnucleation sites along the DNA string.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.7157v1"
    },
    {
        "title": "Application of compressed sensing to genome wide association studies and\n  genomic selection",
        "authors": [
            "Shashaank Vattikuti",
            "James J. Lee",
            "Christopher C. Chang",
            "Stephen D. H. Hsu",
            "Carson C. Chow"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We show that the signal-processing paradigm known as compressed sensing (CS)\nis applicable to genome-wide association studies (GWAS) and genomic selection\n(GS). The aim of GWAS is to isolate trait-associated loci, whereas GS attempts\nto predict the phenotypic values of new individuals on the basis of training\ndata. CS addresses a problem common to both endeavors, namely that the number\nof genotyped markers often greatly exceeds the sample size. We show using CS\nmethods and theory that all loci of nonzero effect can be identified (selected)\nusing an efficient algorithm, provided that they are sufficiently few in number\n(sparse) relative to sample size. For heritability h2 = 1, there is a sharp\nphase transition to complete selection as the sample size is increased. For\nheritability values less than one, complete selection can still occur although\nthe transition is smoothed. The transition boundary is only weakly dependent on\nthe total number of genotyped markers. The crossing of a transition boundary\nprovides an objective means to determine when true effects are being recovered;\nwe discuss practical methods for detecting the boundary. For h2 = 0.5, we find\nthat a sample size that is thirty times the number of nonzero loci is\nsufficient for good recovery.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.2264v3"
    },
    {
        "title": "SMaSH: A Benchmarking Toolkit for Human Genome Variant Calling",
        "authors": [
            "Ameet Talwalkar",
            "Jesse Liptrap",
            "Julie Newcomb",
            "Christopher Hartl",
            "Jonathan Terhorst",
            "Kristal Curtis",
            "Ma'ayan Bresler",
            "Yun S. Song",
            "Michael I. Jordan",
            "David Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation: Computational methods are essential to extract actionable\ninformation from raw sequencing data, and to thus fulfill the promise of\nnext-generation sequencing technology. Unfortunately, computational tools\ndeveloped to call variants from human sequencing data disagree on many of their\npredictions, and current methods to evaluate accuracy and computational\nperformance are ad-hoc and incomplete. Agreement on benchmarking variant\ncalling methods would stimulate development of genomic processing tools and\nfacilitate communication among researchers.\n  Results: We propose SMaSH, a benchmarking methodology for evaluating human\ngenome variant calling algorithms. We generate synthetic datasets, organize and\ninterpret a wide range of existing benchmarking data for real genomes, and\npropose a set of accuracy and computational performance metrics for evaluating\nvariant calling methods on this benchmarking data. Moreover, we illustrate the\nutility of SMaSH to evaluate the performance of some leading single nucleotide\npolymorphism (SNP), indel, and structural variant calling algorithms.\n  Availability: We provide free and open access online to the SMaSH toolkit,\nalong with detailed documentation, at smash.cs.berkeley.edu.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.8420v2"
    },
    {
        "title": "Mapping of the Influenza-A Hemagglutinin Serotypes Evolution by the\n  ISSCOR Method",
        "authors": [
            "Jan P. Radomski",
            "Piotr P. Slonimski",
            "Włodzimierz Zagórski-Ostoja",
            "Piotr Borowicz"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Analyses and visualizations by the ISSCOR method of influenza virus\nhemagglutinin genes of different A-subtypes revealed some rather striking\ntemporal relationships between groups of individual gene subsets. Based on\nthese findings we consider application of the ISSCOR-PCA method for analyses of\nlarge sets of homologous genes to be a worthwhile addition to a toolbox of\ngenomics - allowing for a rapid diagnostics of trends, and ultimately even\naiding an early warning of newly emerging epidemiological threats.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1870v1"
    },
    {
        "title": "The hemagglutinin mutation E391K of pandemic 2009 influenza revisited",
        "authors": [
            "Jan P. Radomski",
            "Piotr Płoński",
            "Włodzimierz Zagórski-Ostoja"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Phylogenetic analyses based on small to moderately sized sets of sequential\ndata lead to overestimating mutation rates in influenza hemagglutinin (HA) by\nat least an order of magnitude. Two major underlying reasons are: the\nincomplete lineage sorting, and a possible absence in the analyzed sequences\nset some of key missing ancestors. Additionally, during neighbor joining tree\nreconstruction each mutation is considered equally important, regardless of its\nnature. Here we have implemented a heuristic method optimizing site dependent\nfactors weighting differently 1st, 2nd, and 3rd codon position mutations,\nallowing to extricate incorrectly attributed sub-clades. The least squares\nregression analysis of distribution of frequencies for all mutations observed\non a partially disentangled tree for a large set of unique 3243 HA sequences,\nalong all nucleotide positions, was performed for all mutations as well as for\nnon-equivalent amino acid mutations: in both cases demonstrating almost flat\ngradients, with a very slight downward slope towards the 3'-end positions. The\nmean mutation rates per sequence per year were 3.83*10^-4 for the all\nmutations, and 9.64*10^-5 for the non-equivalent ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1910v1"
    },
    {
        "title": "Structuring research methods and data with the Research Object model:\n  genomics workflows as a case study",
        "authors": [
            "Kristina M. Hettne",
            "Harish Dharuri",
            "Jun Zhao",
            "Katherine Wolstencroft",
            "Khalid Belhajjame",
            "Stian Soiland-Reyes",
            "Eleni Mina",
            "Mark Thompson",
            "Don Cruickshank",
            "Lourdes Verdes-Montenegro",
            "Julian Garrido",
            "David de Roure",
            "Oscar Corcho",
            "Graham Klyne",
            "Reinout van Schouwen",
            "Peter A. C. 't Hoen",
            "Sean Bechhofer",
            "Carole Goble",
            "Marco Roos"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  One of the main challenges for biomedical research lies in the\ncomputer-assisted integrative study of large and increasingly complex\ncombinations of data in order to understand molecular mechanisms. The\npreservation of the materials and methods of such computational experiments\nwith clear annotations is essential for understanding an experiment, and this\nis increasingly recognized in the bioinformatics community. Our assumption is\nthat offering means of digital, structured aggregation and annotation of the\nobjects of an experiment will provide necessary meta-data for a scientist to\nunderstand and recreate the results of an experiment. To support this we\nexplored a model for the semantic description of a workflow-centric Research\nObject (RO), where an RO is defined as a resource that aggregates other\nresources, e.g., datasets, software, spreadsheets, text, etc. We applied this\nmodel to a case study where we analysed human metabolite variation by\nworkflows.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.2789v3"
    },
    {
        "title": "Evolution at two levels of gene expression in yeast",
        "authors": [
            "Carlo G. Artieri",
            "Hunter B. Fraser"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Despite the greater functional importance of protein levels, our knowledge of\ngene expression evolution is based almost entirely on studies of mRNA levels.\nIn contrast, our understanding of how translational regulation evolves has\nlagged far behind. Here we have applied ribosome profiling - which measures\nboth global mRNA levels and their translation rates - to two species of\nSaccharomyces yeast and their interspecific hybrid in order to assess the\nrelative contributions of changes in mRNA abundance and translation to\nregulatory evolution. We report that both cis and trans-acting regulatory\ndivergence in translation are abundant, affecting at least 35% of genes. The\nmajority of translational divergence acts to buffer changes in mRNA abundance,\nsuggesting a widespread role for stabilizing selection acting across regulatory\nlevels. Nevertheless, we observe evidence of lineage-specific selection acting\non a number of yeast functional modules, including instances of reinforcing\nselection acting at both levels of regulation. Finally, we also uncover\nmultiple instances of stop-codon readthrough that are conserved between\nspecies. Our analysis reveals the under-appreciated complexity of\npost-transcriptional regulatory divergence and indicates that partitioning the\nsearch for the locus of selection into the binary categories of 'coding' vs.\n'regulatory' may overlook a significant source of selection, acting at multiple\nregulatory levels along the path from genotype to phenotype.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.7140v1"
    },
    {
        "title": "BayMeth: Improved DNA methylation quantification for affinity capture\n  sequencing data using a flexible Bayesian approach",
        "authors": [
            "Andrea Riebler",
            "Mirco Menigatti",
            "Jenny Z. Song",
            "Aaron L. Statham",
            "Clare Stirzaker",
            "Nadiya Mahmud",
            "Charles A. Mein",
            "Susan J. Clark",
            "Mark D. Robinson"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  DNA methylation (DNAme) is a critical component of the epigenetic regulatory\nmachinery and aberrations in DNAme patterns occur in many diseases, such as\ncancer. Mapping and understanding DNAme profiles offers considerable promise\nfor reversing the aberrant states. There are several approaches to analyze\nDNAme, which vary widely in cost, resolution and coverage. Affinity capture and\nhigh-throughput sequencing of methylated DNA strike a good balance between the\nhigh cost of whole genome bisulphite sequencing (WGBS) and the low coverage of\nmethylation arrays. However, existing methods cannot adequately differentiate\nbetween hypomethylation patterns and low capture efficiency, and do not offer\nflexibility to integrate copy number variation (CNV). Furthermore, no\nuncertainty estimates are provided, which may prove useful for combining data\nfrom multiple protocols or propagating into downstream analysis. We propose an\nempirical Bayes framework that uses a fully methylated (i.e. SssI treated)\ncontrol sample to transform observed read densities into regional methylation\nestimates. In our model, inefficient capture can be distinguished from low\nmethylation levels by means of larger posterior variances. Furthermore, we can\nintegrate CNV by introducing a multiplicative offset into our Poisson model\nframework. Notably, our model offers analytic expressions for the mean and\nvariance of the methylation level and thus is fast to compute. Our algorithm\noutperforms existing approaches in terms of bias, mean-squared error and\ncoverage probabilities as illustrated on multiple reference datasets. Although\nour method provides advantages even without the SssI-control, considerable\nimprovement is achieved by its incorporation. Our method can be applied to\nmethylated DNA affinity enrichment assays (e.g MBD-seq, MeDIP-seq) and a\nsoftware implementation is available in the Bioconductor Repitools package.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3115v1"
    },
    {
        "title": "In silico Proteome Cleavage Reveals Iterative Digestion Strategy for\n  High Sequence Coverage",
        "authors": [
            "Jesse G. Meyer"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  In the post-genome era, biologists have sought to measure the complete\ncomplement of proteins, termed proteomics. Currently, the most effective method\nto measure the proteome is with shotgun, or bottom-up, proteomics, in which the\nproteome is digested into peptides that are identified followed by protein\ninference. Despite continuous improvements to all steps of the shotgun\nproteomics workflow, observed proteome coverage is often low; some proteins are\nidentified by a single peptide sequence. Complete proteome sequence coverage\nwould allow comprehensive characterization of RNA splicing variants and all\npost translational modifications, which would drastically improve the accuracy\nof biological models. There are many reasons for the sequence coverage deficit,\nbut ultimately peptide length determines sequence observability. Peptides that\nare too short are lost because they match many protein sequences and their true\norigin is ambiguous. The maximum observable peptide length is determined by\nseveral analytical challenges. This paper explores computationally how peptide\nlengths produced from several common proteome digestion methods limit\nobservable proteome coverage. Iterative proteome cleavage strategies are also\nexplored. These simulations reveal that maximized proteome coverage can be\nachieved by use of an iterative digestion protocol involving multiple proteases\nand chemical cleavages that theoretically allow 91.1% proteome coverage.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1794v1"
    },
    {
        "title": "The Cure: Making a game of gene selection for breast cancer survival\n  prediction",
        "authors": [
            "Benjamin M. Good",
            "Salvatore Loguercio",
            "Obi L. Griffith",
            "Max Nanis",
            "Chunlei Wu",
            "Andrew I. Su"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation: Molecular signatures for predicting breast cancer prognosis could\ngreatly improve care through personalization of treatment. Computational\nanalyses of genome-wide expression datasets have identified such signatures,\nbut these signatures leave much to be desired in terms of accuracy,\nreproducibility and biological interpretability. Methods that take advantage of\nstructured prior knowledge (e.g. protein interaction networks) show promise in\nhelping to define better signatures but most knowledge remains unstructured.\n  Crowdsourcing via scientific discovery games is an emerging methodology that\nhas the potential to tap into human intelligence at scales and in modes\npreviously unheard of. Here, we developed and evaluated a game called The Cure\non the task of gene selection for breast cancer survival prediction. Our\ncentral hypothesis was that knowledge linking expression patterns of specific\ngenes to breast cancer outcomes could be captured from game players. We\nenvisioned capturing knowledge both from the players prior experience and from\ntheir ability to interpret text related to candidate genes presented to them in\nthe context of the game.\n  Results: Between its launch in Sept. 2012 and Sept. 2013, The Cure attracted\nmore than 1,000 registered players who collectively played nearly 10,000 games.\nGene sets assembled through aggregation of the collected data clearly\ndemonstrated the accumulation of relevant expert knowledge. In terms of\npredictive accuracy, these gene sets provided comparable performance to gene\nsets generated using other methods including those used in commercial tests.\nThe Cure is available at http://genegames.org/cure/\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3632v1"
    },
    {
        "title": "Genetic Analysis of Transformed Phenotypes",
        "authors": [
            "Nicolo Fusi",
            "Christoph Lippert",
            "Neil D. Lawrence",
            "Oliver Stegle"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Linear mixed models (LMMs) are a powerful and established tool for studying\ngenotype-phenotype relationships. A limiting assumption of LMMs is that the\nresiduals are Gaussian distributed, a requirement that rarely holds in\npractice. Violations of this assumption can lead to false conclusions and\nlosses in power, and hence it is common practice to pre-process the phenotypic\nvalues to make them Gaussian, for instance by applying logarithmic or other\nnon-linear transformations. Unfortunately, different phenotypes require\ndifferent specific transformations, and choosing a \"good\" transformation is in\ngeneral challenging and subjective. Here, we present an extension of the LMM\nthat estimates an optimal transformation from the observed data. In extensive\nsimulations and applications to real data from human, mouse and yeast we show\nthat using such optimal transformations lead to increased power in genome-wide\nassociation studies and higher accuracy in heritability estimates and phenotype\npredictions.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.5447v2"
    },
    {
        "title": "Target enrichment of ultraconserved elements from arthropods provides a\n  genomic perspective on relationships among Hymenoptera",
        "authors": [
            "Brant C. Faircloth",
            "Michael G. Branstetter",
            "Noor D. White",
            "Seán G. Brady"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Gaining a genomic perspective on phylogeny requires the collection of data\nfrom many putatively independent loci collected across the genome. Among\ninsects, an increasingly common approach to collecting this class of data\ninvolves transcriptome sequencing, because few insects have high-quality genome\nsequences available; assembling new genomes remains a limiting factor; the\ntranscribed portion of the genome is a reasonable, reduced subset of the genome\nto target; and the data collected from transcribed portions of the genome are\nsimilar in composition to the types of data with which biologists have\ntraditionally worked (e.g., exons). However, molecular techniques requiring RNA\nas a template are limited to using very high quality source materials, which\nare often unavailable from a large proportion of biologically important insect\nsamples. Recent research suggests that DNA-based target enrichment of conserved\ngenomic elements offers another path to collecting phylogenomic data across\ninsect taxa, provided that conserved elements are present in and can be\ncollected from insect genomes. Here, we identify a large set (n$=$1510) of\nultraconserved elements (UCE) shared among the insect order Hymenoptera. We use\nin silico analyses to show that these loci accurately reconstruct relationships\namong genome-enabled Hymenoptera, and we design a set of baits for enriching\nthese loci that researchers can use with DNA templates extracted from a variety\nof sources. We use our UCE bait set to enrich an average of 721 UCE loci from\n30 hymenopteran taxa, and we use these UCE loci to reconstruct phylogenetic\nrelationships spanning very old ($\\geq$220 MYA) to very young ($\\leq$1 MYA)\ndivergences among hymenopteran lineages. In contrast to a recent study\naddressing hymenopteran phylogeny using transcriptome data, we found ants to be\nsister to all remaining aculeate lineages with complete support.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0413v2"
    },
    {
        "title": "Fast construction of FM-index for long sequence reads",
        "authors": [
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Summary: We present a new method to incrementally construct the FM-index for\nboth short and long sequence reads, up to the size of a genome. It is the first\nalgorithm that can build the index while implicitly sorting the sequences in\nthe reverse (complement) lexicographical order without a separate sorting step.\nThe implementation is among the fastest for indexing short reads and the only\none that practically works for reads of averaged kilobases in length.\n  Availability and implementation: https://github.com/lh3/ropebwt2\n  Contact: hengli@broadinstitute.org\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0426v1"
    },
    {
        "title": "Nanopore Sequencing of the phi X 174 genome",
        "authors": [
            "Andrew H. Laszlo",
            "Ian M. Derrington",
            "Brian C. Ross",
            "Henry Brinkerhoff",
            "Andrew Adey",
            "Ian C. Nova",
            "Jonathan M. Craig",
            "Kyle W. Langford",
            "Jenny Mae Samson",
            "Riza Daza",
            "Kenji Doering",
            "Jay Shendure",
            "Jens H. Gundlach"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Nanopore sequencing of DNA is a single-molecule technique that may achieve\nlong reads, low cost, and high speed with minimal sample preparation and\ninstrumentation. Here, we build on recent progress with respect to nanopore\nresolution and DNA control to interpret the procession of ion current levels\nobserved during the translocation of DNA through the pore MspA. As\napproximately four nucleotides affect the ion current of each level, we\nmeasured the ion current corresponding to all 256 four-nucleotide combinations\n(quadromers). This quadromer map is highly predictive of ion current levels of\npreviously unmeasured sequences derived from the bacteriophage phi X 174\ngenome. Furthermore, we show nanopore sequencing reads of phi X 174 up to 4,500\nbases in length that can be unambiguously aligned to the phi X 174 reference\ngenome, and demonstrate proof-of-concept utility with respect to hybrid genome\nassembly and polymorphism detection. All methods and data are made fully\navailable.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.4214v2"
    },
    {
        "title": "Determination of Nonlinear Genetic Architecture using Compressed Sensing",
        "authors": [
            "Chiu Man Ho",
            "Stephen D. H. Hsu"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  We introduce a statistical method that can reconstruct nonlinear genetic\nmodels (i.e., including epistasis, or gene-gene interactions) from\nphenotype-genotype (GWAS) data. The computational and data resource\nrequirements are similar to those necessary for reconstruction of linear\ngenetic models (or identification of gene-trait associations), assuming a\ncondition of generalized sparsity, which limits the total number of gene-gene\ninteractions. An example of a sparse nonlinear model is one in which a typical\nlocus interacts with several or even many others, but only a small subset of\nall possible interactions exist. It seems plausible that most genetic\narchitectures fall in this category. Our method uses a generalization of\ncompressed sensing (L1-penalized regression) applied to nonlinear functions of\nthe sensing matrix. We give theoretical arguments suggesting that the method is\nnearly optimal in performance, and demonstrate its effectiveness on broad\nclasses of nonlinear genetic models using both real and simulated human\ngenomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.6583v2"
    },
    {
        "title": "Misassembly Detection using Paired-End Sequence Reads and Optical\n  Mapping Data",
        "authors": [
            "Martin D. Muggli",
            "Simon J. Puglisi",
            "Roy Ronen",
            "Christina Boucher"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  A crucial problem in genome assembly is the discovery and correction of\nmisassembly errors in draft genomes. We develop a method that will enhance the\nquality of draft genomes by identifying and removing misassembly errors using\npaired short read sequence data and optical mapping data. We apply our method\nto various assemblies of the loblolly pine and Francisella tularensis genomes.\nOur results demonstrate that we detect more than 54% of extensively\nmisassembled contigs and more than 60% of locally misassembed contigs in an\nassembly of Francisella tularensis, and between 31% and 100% of extensively\nmisassembled contigs and between 57% and 73% of locally misassembed contigs in\nthe assemblies of loblolly pine. MISSEQUEL can be downloaded at\nhttp://www.cs.colostate.edu/seq/.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.5890v1"
    },
    {
        "title": "Dynamic Model for RNA-seq Data Analysis",
        "authors": [
            "Lerong Li",
            "Momiao Xiong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  The newly developed deep-sequencing technologies make it possible to acquire\nboth quantitative and qualitative information regarding transcript biology. By\nmeasuring messenger RNA levels for all genes in a sample, RNA-seq provides an\nattractive option to characterize the global changes in transcription. RNA-seq\nis becoming the widely used platform for gene expression profiling. However,\nreal transcription signals in the RNA-seq data are confounded with measurement\nand sequencing errors, and other random biological/technical variation. How to\nappropriately take the variability due to errors and sequencing technology\nvariation into account is essential issue in the RNA-seq data analysis. To\nextract biologically useful transcription process from the RNA-seq data, we\npropose to use the second ODE for modeling the RNA-seq data. We use\ndifferential principal analysis to develop statistical methods for estimation\nof location-varying coefficients of the ODE. We validate the accuracy of the\nODE model to fit the RNA-seq data by prediction analysis and 5 fold cross\nvalidation. We find the accuracy of the second ODE model to predict the gene\nexpression level across the gene is very high and the second ODE model to fit\nthe RNA-seq data very well. To further evaluate the performance of the ODE\nmodel for RNA-seq data analysis, we used the location-varying coefficients of\nthe second ODE as features to classify the normal and tumor cells. We\ndemonstrate that even using the ODE model for single gene we can achieve high\nclassification accuracy. We also conduct response analysis to investigate how\nthe transcription process respond to the perturbation of the external signals\nand identify dozens of genes that are related to cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.1746v1"
    },
    {
        "title": "Transcriptomic and metabolomic analysis of copper stress acclimation in\n  Ectocarpus siliculosus highlights signaling and tolerance mechanisms in brown\n  algae",
        "authors": [
            "Andrés Ritter",
            "Simon M Dittami",
            "Sophie Goulitquer",
            "Juan A Correa",
            "Catherine Boyen",
            "Philippe Potin",
            "Thierry Tonon"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Brown algae are sessile macro-organisms of great ecological relevance in\ncoastal ecosystems. They evolved independently from land plants and other\nmulticellular lineages, and therefore hold several original ontogenic and\nmetabolic features. Most brown algae grow along the coastal zone where they\nface frequent environmental changes, including exposure to toxic levels of\nheavy metals such as copper (Cu). We carried out large-scale transcriptomic and\nmetabolomic analyses to decipher the short-term acclimation of the brown algal\nmodel E. siliculosus to Cu stress, and compared these data to results known for\nother abiotic stressors. This comparison demonstrates that Cu induces oxidative\nstress in E. siliculosus as illustrated by the transcriptomic overlap between\nCu and H2O2 treatments. The common response to Cu and H2O2 consisted in the\nactivation of the oxylipin and the repression of inositol signaling pathways,\ntogether with the regulation of genes coding for several\ntranscription-associated proteins. Concomitantly, Cu stress specifically\nactivated a set of genes coding for orthologs of ABC transporters, a P1B-type\nATPase, ROS detoxification systems such as a vanadium-dependent\nbromoperoxidase, and induced an increase of free fatty acid contents. Finally\nwe observed, as a common abiotic stress mechanism, the activation of autophagic\nprocesses on one hand and the repression of genes involved in nitrogen\nassimilation on the other hand. Comparisons with data from green plants\nindicate that some processes involved in Cu and oxidative stress response are\nconserved across these two distant lineages. At the same time the high number\nof yet uncharacterized brown alga-specific genes induced in response to copper\nstress underlines the potential to discover new components and molecular\ninteractions unique to these organisms. Of particular interest for future\nresearch is the potential cross-talk between reactive oxygen species (ROS)-,\nmyo-inositol-, and oxylipin signaling.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.02001v1"
    },
    {
        "title": "Of Protein Size and Genomes",
        "authors": [
            "N. S. Santos-Magalhaes",
            "H. M. de Oliveira"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  An approach for approximately calculating the number of genes in a genome is\npresented, which takes into account the average protein length expected for the\nspecies. A number of virus, bacterial and eukaryotic genomes are scrutinized.\nGenome figures are presented, which support the average protein size of a\nspecies as a criterion for assessing life complexity. The human gene\ndistribution in the 23 chromosomes is investigated emphasizing the genomic\nrate, the mean 'exon' length, and the mean 'exons per gene'. It is shown that\nstoring all genes of a single human definitely requires less than 12 MB.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.03732v1"
    },
    {
        "title": "AMAS: optimizing the partition and filtration of adaptive seeds to speed\n  up read mapping",
        "authors": [
            "Ngoc Hieu Tran",
            "Xin Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Background: Identifying all possible mapping locations of next-generation\nsequencing (NGS) reads is highly essential in several applications such as\nprediction of genomic variants or protein binding motifs located in repeat\nregions, isoform expression quantification, metagenomics analysis, etc.\nHowever, this task is very time-consuming and majority of mapping tools only\nfocus on one or a few best mapping locations. Results: We propose AMAS, an\nalignment tool specialized in identifying all possible mapping locations of NGS\nreads in a reference sequence. AMAS features an effective use of adaptive seeds\nto speed up read mapping while preserving sensitivity. Specifically, an index\nis designed to pre-store the locations of adaptive seeds in the reference\nsequence, efficiently reducing the time for seed matching and partitioning. An\naccurate filtration of adaptive seeds is further applied to substantially\ntighten the candidate alignment space. As a result, AMAS runs several times\nfaster than other state-of-the-art read mappers while achieving similar\naccuracy. Conclusions: AMAS provides a valuable resource to speed up the\nimportant yet time-consuming task of identifying all mapping locations of NGS\nreads. AMAS is implemented in C++ based on the SeqAn library and is freely\navailable at https://sourceforge.net/projects/ngsamas/. Keywords:\nnext-generation sequencing, read mapping, sequence alignment, adaptive seeds,\nseed partition, filtration\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05041v1"
    },
    {
        "title": "Differential protein expression and peak selection in mass spectrometry\n  data by binary discriminant analysis",
        "authors": [
            "Sebastian Gibb",
            "Korbinian Strimmer"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Motivation: Proteomic mass spectrometry analysis is becoming routine in\nclinical diagnostics, for example to monitor cancer biomarkers using blood\nsamples. However, differential proteomics and identification of peaks relevant\nfor class separation remains challenging.\n  Results: Here, we introduce a simple yet effective approach for identifying\ndifferentially expressed proteins using binary discriminant analysis. This\napproach works by data-adaptive thresholding of protein expression values and\nsubsequent ranking of the dichotomized features using a relative entropy\nmeasure. Our framework may be viewed as a generalization of the `peak\nprobability contrast' approach of Tibshirani et al. (2004) and can be applied\nboth in the two-group and the multi-group setting.\n  Our approach is computationally inexpensive and shows in the analysis of a\nlarge-scale drug discovery test data set equivalent prediction accuracy as a\nrandom forest. Furthermore, we were able to identify in the analysis of mass\nspectrometry data from a pancreas cancer study biological relevant and\nstatistically predictive marker peaks unrecognized in the original study.\n  Availability: The methodology for binary discriminant analysis is implemented\nin the R package binda, which is freely available under the GNU General Public\nLicense (version 3 or later) from CRAN at URL\nhttp://cran.r-project.org/web/packages/binda/ . R scripts reproducing all\ndescribed analyzes are available from the web page\nhttp://strimmerlab.org/software/binda/ .\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07959v2"
    },
    {
        "title": "Differential Evolution Approach to Detect Recent Admixture",
        "authors": [
            "Konstantin Kozlov",
            "Dmitry Chebotarov",
            "Mehedi Hassan",
            "Martin Triska",
            "Petr Triska",
            "Pavel Flegontov",
            "Tatiana Tatarinova"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The genetic structure of human populations is extraordinarily complex and of\nfundamental importance to studies of anthropology, evolution, and medicine.\n  As increasingly many individuals are of mixed origin, there is an unmet need\nfor tools that can infer multiple origins. Misclassification of such\nindividuals can lead to incorrect and costly misinterpretations of genomic\ndata, primarily in disease studies and drug trials.\n  We present an advanced tool to infer ancestry that can identify the\nbiogeographic origins of highly mixed individuals.\n  reAdmix is an online tool available at\nhttp://chcb.saban-chla.usc.edu/reAdmix/.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.02117v1"
    },
    {
        "title": "Correlations between promoter activity and its nucleotide positions in\n  spacing region",
        "authors": [
            "Jingwei Li",
            "Yunxin Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Transcription is one of the essential processes for cells to read genetic\ninformation encoded in genes, which is initiated by the binding of RNA\npolymerase to related promoter. Experiments have found that the nucleotide\nsequence of promoter has great influence on gene expression strength, or\npromoter activity. In synthetic biology, one interesting question is how we can\nsynthesize a promoter with given activity, and which positions of promoter\nsequence are important for determining its activity. In this study, based on\nrecent experimental data, correlations between promoter activity and its\nsequence positions are analyzed by various methods. Our results show that,\nexcept nucleotides in the two highly conserved regions, $-35$ box and $-10$\nbox, influences of nucleotides in other positions are also not neglectable. For\nexample, modifications of nucleotides around position $-19$ in spacing region\nmay change promoter activity in a large scale. The results of this study might\nbe helpful to our understanding of biophysical mechanism of gene transcription,\nand may also be helpful to the design of synthetic cell factory.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.03550v1"
    },
    {
        "title": "Analysis of whole mitogenomes from ancient samples",
        "authors": [
            "Gloria G. Fortes",
            "Johanna L. A. Paijmans"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Ancient mitochondrial DNA has been used in a wide variety of palaeontological\nand archaeological studies, ranging from population dynamics of extinct species\nto patterns of domestication. Most of these studies have traditionally been\nbased on the analysis of short fragments from the mitochondrial control region,\nanalysed using PCR coupled with Sanger sequencing. With the introduction of\nhigh-throughput sequencing, as well as new enrichment technologies, the\nrecovery of full mitochondrial genomes (mitogenomes) from ancient specimens has\nbecome significantly less complicated. Here we present a protocol to build\nancient extracts into Illumina high-throughput sequencing libraries, and\nsubsequent Agilent array-based capture to enrich for the desired mitogenome.\nBoth are based on previously published protocols, with the introduction of\nseveral improvements aimed to increase the recovery of short DNA fragments,\nwhile keeping the cost and effort requirements low. This protocol was designed\nfor enrichment of mitochondrial DNA in ancient or degraded samples. However,\nthe protocols can be easily adapted for using for building libraries for\nshotgun-sequencing of whole genomes, or enrichment of other genomic regions.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05074v2"
    },
    {
        "title": "Generalized Hultman Numbers and Cycle Structures of Breakpoint Graphs",
        "authors": [
            "Nikita Alexeev",
            "Anna Pologova",
            "Max A. Alekseyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genome rearrangements can be modeled as $k$-breaks, which break a genome at k\npositions and glue the resulting fragments in a new order. In particular,\nreversals, translocations, fusions, and fissions are modeled as $2$-breaks, and\ntranspositions are modeled as $3$-breaks. While $k$-break rearrangements for\n$k>3$ have not been observed in evolution, they are used in cancer genomics to\nmodel chromothripsis, a catastrophic event of multiple breakages happening\nsimultaneously in a genome. It is known that the $k$-break distance between two\ngenomes (i.e., the minimum number of $k$-breaks required to transform one\ngenome into the other) can be computed in terms of cycle lengths in the\nbreakpoint graph of these genomes.\n  In the current work, we address the combinatorial problem of enumerating\ngenomes at a given $k$-break distance from a fixed unichromosomal genome. More\ngenerally, we enumerate genome pairs, whose breakpoint graph has a given\ndistribution of cycle lengths. We further show how our enumeration can be used\nfor uniform sampling of random genomes at a given $k$-break distance, and\ndescribe its connection to various combinatorial objects such as Bell\npolynomials.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05285v3"
    },
    {
        "title": "Joint Inference of Genome Structure and Content in Heterogeneous Tumour\n  Samples",
        "authors": [
            "Andrew McPherson",
            "Andrew Roth",
            "Gavin Ha",
            "Sohrab P. Shah",
            "Cedric Chauve",
            "S. Cenk Sahinalp"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  For a genomically unstable cancer, a single tumour biopsy will often contain\na mixture of competing tumour clones. These tumour clones frequently differ\nwith respect to their genomic content (copy number of each gene) and structure\n(order of genes on each chromosome). Modern bulk genome sequencing mixes the\nsignals of tumour clones and contaminating normal cells, complicating inference\nof genomic content and structure. We propose a method to unmix tumour and\ncontaminating normal signals and jointly predict genomic structure and content\nof each tumour clone. We use genome graphs to represent tumour clones, and\nmodel the likelihood of the observed reads given clones and mixing proportions.\nOur use of haplotype blocks allows us to accurately measure allele specific\nread counts, and infer allele specific copy number for each clone. The proposed\nmethod is a heuristic local search based on applying incremental, locally\noptimal modifications of the genome graphs. Using simulated data, we show that\nour method predicts copy counts and gene adjacencies with reasonable accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.03080v2"
    },
    {
        "title": "Improved Core Genes Prediction for Constructing well-supported\n  Phylogenetic Trees in large sets of Plant Species",
        "authors": [
            "Bassam AlKindy",
            "Huda Al-Nayyef",
            "Christophe Guyeux",
            "Jean-François Couchot",
            "Michel Salomon",
            "Jacques M. Bahi"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The way to infer well-supported phylogenetic trees that precisely reflect the\nevolutionary process is a challenging task that completely depends on the way\nthe related core genes have been found. In previous computational biology\nstudies, many similarity based algorithms, mainly dependent on calculating\nsequence alignment matrices, have been proposed to find them. In these kinds of\napproaches, a significantly high similarity score between two coding sequences\nextracted from a given annotation tool means that one has the same genes. In a\nprevious work article, we presented a quality test approach (QTA) that improves\nthe core genes quality by combining two annotation tools (namely NCBI, a\npartially human-curated database, and DOGMA, an efficient annotation algorithm\nfor chloroplasts). This method takes the advantages from both sequence\nsimilarity and gene features to guarantee that the core genome contains correct\nand well-clustered coding sequences (\\emph{i.e.}, genes). We then show in this\narticle how useful are such well-defined core genes for biomolecular\nphylogenetic reconstructions, by investigating various subsets of core genes at\nvarious family or genus levels, leading to subtrees with strong bootstraps that\nare finally merged in a well-supported supertree.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06110v1"
    },
    {
        "title": "Recombinant transfer in the basic genome of E. coli",
        "authors": [
            "Purushottam Dixit",
            "Tin Yau Pang",
            "F. William Studier",
            "Sergei Maslov"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  An approximation to the ~4 Mbp basic genome shared by 32 strains of E. coli\nrepresenting six evolutionary groups has been derived and analyzed\ncomputationally. A multiple-alignment of the 32 complete genome sequences was\nfiltered to remove mobile elements and identify the most reliable ~90% of the\naligned length of each of the resulting 496 basic-genome pairs. Patterns of\nsingle-bp mutations (SNPs) in aligned pairs distinguish clonally inherited\nregions from regions where either genome has acquired DNA fragments from\ndiverged genomes by homologous recombination since their last common ancestor.\nSuch recombinant transfer is pervasive across the basic genome, mostly between\ngenomes in the same evolutionary group, and generates many unique mosaic\npatterns. The six least-diverged genome-pairs have one or two recombinant\ntransfers of length ~40-115 kbp (and few if any other transfers), each\ncontaining one or more gene clusters known to confer strong selective advantage\nin some environments. Moderately diverged genome-pairs (0.4-1% SNPs ) show\nmosaic patterns of interspersed clonal and recombinant regions of varying\nlengths throughout the basic genome, whereas more highly diverged pairs within\nan evolutionary group or pairs between evolutionary groups having >1.3% SNPs\nhave few clonal matches longer than a few kbp. Many recombinant transfers\nappear to incorporate fragments of the entering DNA produced by restriction\nsystems of the recipient cell. A simple computational model can closely fit the\ndata. Most recombinant transfers seem likely to be due to generalized\ntransduction by co-evolving populations of phages, which could efficiently\ndistribute variability throughout bacterial genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.03972v1"
    },
    {
        "title": "End-to-End Optimization of High Throughput DNA Sequencing",
        "authors": [
            "Eliza O'Reilly",
            "Francois Baccelli",
            "Gustavo de Veciana",
            "Haris Vikalo"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  At the core of high throughput DNA sequencing platforms lies a bio-physical\nsurface process that results in a random geometry of clusters of homogenous\nshort DNA fragments typically hundreds of base pairs long - bridge\namplification. The statistical properties of this random process and length of\nthe fragments are critical as they affect the information that can be\nsubsequently extracted, i.e., density of successfully inferred DNA fragment\nreads. The ensemble of overlapping DNA fragment reads are then used to\ncomputationally reconstruct the much longer target genome sequence, e.g,\nranging from hundreds of thousands to billions of base pairs. The success of\nthe reconstruction in turn depends on having a sufficiently large ensemble of\nDNA fragments that are sufficiently long. In this paper using stochastic\ngeometry we model and optimize the end-to-end process linking and partially\ncontrolling the statistics of the physical processes to the success of the\ncomputational step. This provides, for the first time, a framework capturing\nsalient features of such sequencing platforms that can be used to study cost,\nperformance or sensitivity of the sequencing process.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02930v1"
    },
    {
        "title": "Estimating Reproducibility in Genome-Wide Association Studies",
        "authors": [
            "Wei Jiang",
            "Jing-Hao Xue",
            "Weichuan Yu"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genome-wide association studies (GWAS) are widely used to discover genetic\nvariants associated with diseases. To control false positives, all findings\nfrom GWAS need to be verified with additional evidences, even for associations\ndiscovered from a high power study. Replication study is a common verification\nmethod by using independent samples. An association is regarded as true\npositive with a high confidence when it can be identified in both primary study\nand replication study. Currently, there is no systematic study on the behavior\nof positives in the replication study when the positive results of primary\nstudy are considered as the prior information.\n  In this paper, two probabilistic measures named Reproducibility Rate (RR) and\nFalse Irreproducibility Rate (FIR) are proposed to quantitatively describe the\nbehavior of primary positive associations (i.e. positive associations\nidentified in the primary study) in the replication study. RR is a conditional\nprobability measuring how likely a primary positive association will also be\npositive in the replication study. This can be used to guide the design of\nreplication study, and to check the consistency between the results of primary\nstudy and those of replication study. FIR, on the contrary, measures how likely\na primary positive association may still be a true positive even when it is\nnegative in the replication study. This can be used to generate a list of\npotentially true associations in the irreproducible findings for further\nscrutiny. The estimation methods of these two measures are given. Simulation\nresults and real experiments show that our estimation methods have high\naccuracy and good prediction performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.06715v1"
    },
    {
        "title": "Combining exome and gene expression datasets in one graphical model of\n  disease to empower the discovery of disease mechanisms",
        "authors": [
            "Aziz M. Mezlini",
            "Fabio Fuligni",
            "Adam Shlien",
            "Anna Goldenberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Identifying genes associated with complex human diseases is one of the main\nchallenges of human genetics and computational medicine. To answer this\nquestion, millions of genetic variants get screened to identify a few of\nimportance. To increase the power of identifying genes associated with diseases\nand to account for other potential sources of protein function aberrations, we\npropose a novel factor-graph based model, where much of the biological\nknowledge is incorporated through factors and priors. Our extensive simulations\nshow that our method has superior sensitivity and precision compared to\nvariant-aggregating and differential expression methods. Our integrative\napproach was able to identify important genes in breast cancer, identifying\ngenes that had coding aberrations in some patients and regulatory abnormalities\nin others, emphasizing the importance of data integration to explain the\ndisease in a larger number of patients.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.07527v1"
    },
    {
        "title": "The Bulk and The Tail of Minimal Absent Words in Genome Sequences",
        "authors": [
            "Erik Aurell",
            "Nicolas Innocenti",
            " Hai-Jun-Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Minimal absent words (MAW) of a genomic sequence are subsequences that are\nabsent themselves but the subwords of which are all present in the sequence.\nThe characteristic distribution of genomic MAWs as a function of their length\nhas been observed to be qualitatively similar for all living organisms, the\nbulk being rather short, and only relatively few being long. It has been an\nopen issue whether the reason behind this phenomenon is statistical or reflects\na biological mechanism, and what biological information is contained in absent\nwords. In this work we demonstrate that the bulk can be described by a\nprobabilistic model of sampling words from random sequences, while the tail of\nlong MAWs is of biological origin. We introduce the novel concept of a core of\na minimal absent word, which are sequences present in the genome and closest to\na given MAW. We show that in bacteria and yeast the cores of the longest MAWs,\nwhich exist in two or more copies, are located in highly conserved regions the\nmost prominent example being ribosomal RNAs (rRNAs). We also show that while\nthe distribution of the cores of long MAWs is roughly uniform over these\ngenomes on a coarse-grained level, on a more detailed level it is strongly\nenhanced in 3' untranslated regions (UTRs) and, to a lesser extent, also in 5'\nUTRs. This indicates that MAWs and associated MAW cores correspond to\nfine-tuned evolutionary relationships, and suggest that they can be more widely\nused as markers for genomic complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.05188v1"
    },
    {
        "title": "Pathway Tools version 28.0: Integrated Software for Pathway/Genome\n  Informatics and Systems Biology",
        "authors": [
            "Peter D. Karp",
            "Suzanne M. Paley",
            "Markus Krummenacker",
            "Anamika Kothari",
            "Peter E. Midford",
            "Pallavi Subhraveti",
            "Austin Swart",
            "Lisa Moore",
            "Ron Caspi"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Pathway Tools is a bioinformatics software environment with a broad set of\ncapabilities. The software provides genome-informatics tools such as a genome\nbrowser, sequence alignments, a genome-variant analyzer, and\ncomparative-genomics operations. It offers metabolic-informatics tools, such as\nmetabolic reconstruction, quantitative metabolic modeling, prediction of\nreaction atom mappings, and metabolic route search. Pathway Tools also provides\nregulatory-informatics tools, such as the ability to represent and visualize a\nwide range of regulatory interactions. The software creates and manages a type\nof organism-specific database called a Pathway/Genome Database (PGDB), which\nthe software enables database curators to interactively edit. It supports web\npublishing of PGDBs and provides a large number of query, visualization, and\nomics-data analysis tools. Scientists around the world have created more than\n45,000 PGDBs by using Pathway Tools, many of which are curated databases for\nimportant model organisms. Those PGDBs can be exchanged using a peer-to-peer\ndatabase-sharing system called the PGDB Registry.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.03964v5"
    },
    {
        "title": "RECKONER: Read Error Corrector Based on KMC",
        "authors": [
            "Maciej Dlugosz",
            "Sebastian Deorowicz"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: Next-generation sequencing tools have enabled producing of huge\namount of genomic information at low cost. Unfortunately, presence of\nsequencing errors in such data affects quality of downstream analyzes. Accuracy\nof them can be improved by performing error correction. Because of huge amount\nof such data correction algorithms have to: be fast, memory-frugal, and provide\nhigh accuracy of error detection and elimination for variously-sized organisms.\n  Results: We introduce a new algorithm for genomic data correction, capable of\nprocessing eucaryotic 300 Mbp-genome-size, high error-rated data using less\nthan 4 GB of RAM in less than 40 minutes on 16-core CPU. The algorithm allows\nto correct sequencing data at better or comparable level than competitors. This\nwas achieved by using very robust KMC~2 $k$-mer counter, new method of\nerroneous regions correction based on both $k$-mer counts and FASTQ quality\nindicators as well as careful optimization. Availability: Program is freely\navailable at http://sun.aei.posl.pl/REFRESH/reckoner. Contact:\nsebastian.deorowicz@polsl.pl\n",
        "pdf_link": "http://arxiv.org/pdf/1602.03086v1"
    },
    {
        "title": "Malignant field signature analysis in biopsy samples at diagnosis\n  identifies lethal disease in patients with localized Gleason 6 and 7 prostate\n  cancer",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Overtreatment of early-stage low-risk prostate cancer (PC) patients\nrepresents a significant problem in disease management and has socio-economic\nimplications. Development of genetic and molecular markers of clinically\nsignificant disease in patients diagnosed with low grade localized PC would\nhave a major impact in disease management. A gene expression signature (GES) is\nreported for lethal PC in biopsy specimens obtained at the time of diagnosis\nfrom patients with Gleason 6 and Gleason 7 tumors in a Swedish watchful waiting\ncohort with up to 30 years follow-up. A 98-genes GES identified 89 and 100\npercent of all death events 4 years after diagnosis in G7 and G6 patients,\nrespectively; at 6 years follow-up, 83 and 100 percent of all deaths events\nwere captured. Remarkably, the 98-genes GES appears to perform successfully in\npatients stratification with as little as 2% of cancer cells in a specimen,\nstrongly indicating that it captures a malignant field effect in prostates\nharboring cancer cells of different degrees of aggressiveness. In G6 and G7\ntumors from PC patients of age 65 or younger, GES identified 86 percent of all\ndeath events during the entire follow-up period. In G6 and G7 tumors from PC\npatients of age 70 or younger, GES identified 90 percent of all death events 6\nyears after diagnosis. Classification performance of the reported in this study\n98-genes GES of lethal PC appeared suitable to meet design and feasibility\nrequirements of a prospective 4 to 6 years clinical trial, which is essential\nfor regulatory approval of diagnostic and prognostic tests in clinical setting.\nProspectively validated GES of lethal PC in biopsy specimens of G6 and G7\ntumors will help physicians to identify, at the time of diagnosis, patients who\nshould be considered for exclusion from active surveillance programs and who\nwould most likely benefit from immediate curative interventions.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.06504v1"
    },
    {
        "title": "metaSPAdes: a new versatile de novo metagenomics assembler",
        "authors": [
            "Sergey Nurk",
            "Dmitry Meleshko",
            "Anton Korobeynikov",
            "Pavel Pevzner"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  While metagenomics has emerged as a technology of choice for analyzing\nbacterial populations, assembly of metagenomic data remains difficult thus\nstifling biological discoveries. metaSPAdes is a new assembler that addresses\nthe challenge of metagenome analysis and capitalizes on computational ideas\nthat proved to be useful in assemblies of single cells and highly polymorphic\ndiploid genomes. We benchmark metaSPAdes against other state-of-the-art\nmetagenome assemblers across diverse da-tasets and demonstrate that it results\nin high-quality assemblies.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.03071v2"
    },
    {
        "title": "Efficient Index Maintenance Under Dynamic Genome Modification",
        "authors": [
            "Nitish Gupta",
            "Komal Sanjeev",
            "Tim Wall",
            "Carl Kingsford",
            "Rob Patro"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Efficient text indexing data structures have enabled large-scale genomic\nsequence analysis and are used to help solve problems ranging from assembly to\nread mapping. However, these data structures typically assume that the\nunderlying reference text is static and will not change over the course of the\nqueries being made. Some progress has been made in exploring how certain text\nindices, like the suffix array, may be updated, rather than rebuilt from\nscratch, when the underlying reference changes. Yet, these update operations\ncan be complex in practice, difficult to implement, and give fairly pessimistic\nworst-case bounds. We present a novel data structure, SkipPatch, for\nmaintaining a k-mer-based index over a dynamically changing genome. SkipPatch\npairs a hash-based k-mer index with an indexable skip list that is used to\nefficiently maintain the set of edits that have been applied to the original\ngenome. SkipPatch is practically fast, significantly outperforming the dynamic\nextended suffix array in terms of update and query speed.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.03132v1"
    },
    {
        "title": "Accurate, Fast and Lightweight Clustering of de novo Transcriptomes\n  using Fragment Equivalence Classes",
        "authors": [
            "Avi Srivastava",
            "Hirak Sarkar",
            "Laraib Malik",
            "Rob Patro"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: De novo transcriptome assembly of non-model organisms is the\nfirst major step for many RNA-seq analysis tasks. Current methods for de novo\nassembly often report a large number of contiguous sequences (contigs), which\nmay be fractured and incomplete sequences instead of full-length transcripts.\nDealing with a large number of such contigs can slow and complicate downstream\nanalysis.\n  Results :We present a method for clustering contigs from de novo\ntranscriptome assemblies based upon the relationships exposed by multi-mapping\nsequencing fragments. Specifically, we cast the problem of clustering contigs\nas one of clustering a sparse graph that is induced by equivalence classes of\nfragments that map to subsets of the transcriptome. Leveraging recent\ndevelopments in efficient read mapping and transcript quantification, we have\ndeveloped RapClust, a tool implementing this approach that is capable of\naccurately clustering most large de novo transcriptomes in a matter of minutes,\nwhile simultaneously providing accurate estimates of expression for the\nresulting clusters. We compare RapClust against a number of tools commonly used\nfor de novo transcriptome clustering. Using de novo assemblies of organisms for\nwhich reference genomes are available, we assess the accuracy of these\ndifferent methods in terms of the quality of the resulting clusterings, and the\nconcordance of differential expression tests with those based on ground truth\nclusters. We find that RapClust produces clusters of comparable or better\nquality than existing state-of-the-art approaches, and does so substantially\nfaster. RapClust also confers a large benefit in terms of space usage, as it\nproduces only succinct intermediate files - usually on the order of a few\nmegabytes - even when processing hundreds of millions of reads.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.03250v1"
    },
    {
        "title": "Variational inference for rare variant detection in deep, heterogeneous\n  next-generation sequencing data",
        "authors": [
            "Fan Zhang",
            "Patrick Flaherty"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The detection of rare variants is important for understanding the genetic\nheterogeneity in mixed samples. Recently, next-generation sequencing (NGS)\ntechnologies have enabled the identification of single nucleotide variants\n(SNVs) in mixed samples with high resolution. Yet, the noise inherent in the\nbiological processes involved in next-generation sequencing necessitates the\nuse of statistical methods to identify true rare variants. We propose a novel\nBayesian statistical model and a variational expectation-maximization (EM)\nalgorithm to estimate non-reference allele frequency (NRAF) and identify SNVs\nin heterogeneous cell populations. We demonstrate that our variational EM\nalgorithm has comparable sensitivity and specificity compared with a Markov\nChain Monte Carlo (MCMC) sampling inference algorithm, and is more\ncomputationally efficient on tests of low coverage ($27\\times$ and $298\\times$)\ndata. Furthermore, we show that our model with a variational EM inference\nalgorithm has higher specificity than many state-of-the-art algorithms. In an\nanalysis of a directed evolution longitudinal yeast data set, we are able to\nidentify a time-series trend in non-reference allele frequency and detect novel\nvariants that have not yet been reported. Our model also detects the emergence\nof a beneficial variant earlier than was previously shown, and a pair of\nconcomitant variants.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04280v2"
    },
    {
        "title": "Effects of initial telomere length distribution on senescence onset and\n  heterogeneity",
        "authors": [
            "Sarah Eugène",
            "Thibault Bourgeron",
            "Zhou Xu"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Replicative senescence, induced by telomere shortening, exhibits considerable\nasynchrony and heterogeneity, the origins of which remain unclear. Here, we\nformally study how telomere shortening mechanisms impact on senescence kinetics\nand define two regimes of senescence, depending on the initial telomere length\nvariance. We provide analytical solutions to the model, highlighting a\nnon-linear relationship between senescence onset and initial telomere length\ndistribution. This study reveals the complexity of the collective behavior of\ntelomeres as they shorten, leading to senescence heterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.06842v2"
    },
    {
        "title": "Genomic data analysis in tree spaces",
        "authors": [
            "Sakellarios Zairis",
            "Hossein Khiabanian",
            "Andrew J. Blumberg",
            "Raul Rabadan"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Recently, an elegant approach in phylogenetics was introduced by\nBillera-Holmes-Vogtmann that allows a systematic comparison of different\nevolutionary histories using the metric geometry of tree spaces. In many\nproblem settings one encounters heavily populated phylogenetic trees, where the\nlarge number of leaves encumbers visualization and analysis in the relevant\nevolutionary moduli spaces. To address this issue, we introduce tree\ndimensionality reduction, a structured approach to reducing large phylogenetic\ntrees to a distribution of smaller trees. We prove a stability theorem ensuring\nthat small perturbations of the large trees are taken to small perturbations of\nthe resulting distributions.\n  We then present a series of four biologically motivated applications to the\nanalysis of genomic data, spanning cancer and infectious disease. The first\nquantifies how chemotherapy can disrupt the evolution of common leukemias. The\nsecond examines a link between geometric information and the histologic grade\nin relapsed gliomas, where longer relapse branches were specific to high grade\nglioma. The third concerns genetic stability of xenograft models of cancer,\nwhere heterogeneity at the single cell level increased with later mouse\npassages. The last studies genetic diversity in seasonal influenza A virus. We\napply tree dimensionality reduction to 24 years of longitudinally collected\nH3N2 hemagglutinin sequences, generating distributions of smaller trees\nspanning between three and five seasons. A negative correlation is observed\nbetween the influenza vaccine effectiveness during a season and the variance of\nthe distributions produced using preceding seasons' sequence data. We also show\nhow tree distributions relate to antigenic clusters and choice of influenza\nvaccine. Our formalism exposes links between viral genomic data and clinical\nobservables such as vaccine selection and efficacy.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.07503v1"
    },
    {
        "title": "Core-genome scaffold comparison reveals the prevalence that inversion\n  events are associated with pairs of inverted repeats",
        "authors": [
            "Dan Wang",
            "Shuaicheng Li",
            "Fei Guo",
            "Lusheng Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: Genome rearrangement plays an important role in evolutionary\nbiology and has profound impacts on phenotype in organisms ranging from\nmicrobes to humans. The mechanisms for genome rearrangement events remain\nunclear. Lots of comparisons have been conducted among different species. To\nreveal the mechanisms for rearrangement events, comparison of different\nindividuals/strains within the same species or genus (pan-genomes) is more\nhelpful since they are much closer to each other. Results: We study the\nmechanism for inversion events via core-genome scaffold comparison of different\nstrains within the same species. We focus on two kinds of bacteria, Pseudomonas\naeruginosa and Escherichia coli, and investigate the inversion events among\ndifferent strains of the same specie. We find an interesting phenomenon that\nlong (larger than 10,000 bp) inversion regions are flanked by a pair of\nInverted Repeats (IRs) (with lengths ranging from 385 bp to 27476 bp) which are\noften Insertion Sequences (ISs).This mechanism can also explain why the\nbreakpoint reuses for inversion events happen. We study the prevalence of the\nphenomenon and find that it is a major mechanism for inversions. The other\nobservation is that for different rearrangement events such as transposition\nand inverted block interchange, the two ends of the swapped regions are also\nassociated with repeats so that after the rearrangement operations the two ends\nof the swapped regions remain unchanged. To our knowledge, this is the first\ntime such a phenomenon is reported for transposition event.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.02375v1"
    },
    {
        "title": "Chaos in DNA Evolution",
        "authors": [
            "Jacques M. Bahi",
            "Christophe Guyeux",
            "Antoine Perasso"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  In this paper, we explain why the chaotic model (CM) of Bahi and Michel\n(2008) accurately simulates gene mutations over time. First, we demonstrate\nthat the CM model is a truly chaotic one, as defined by Devaney. Then, we show\nthat mutations occurring in gene mutations have the same chaotic dynamic, thus\nmaking the use of chaotic models relevant for genome evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.05832v1"
    },
    {
        "title": "Assessment of P-value variability in the current replicability crisis",
        "authors": [
            "Olga A. Vsevolozhskaya",
            "Gabriel Ruiz",
            "Dmitri V. Zaykin"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Increased availability of data and accessibility of computational tools in\nrecent years have created unprecedented opportunities for scientific research\ndriven by statistical analysis. Inherent limitations of statistics impose\nconstrains on reliability of conclusions drawn from data but misuse of\nstatistical methods is a growing concern. Significance, hypothesis testing and\nthe accompanying P-values are being scrutinized as representing most widely\napplied and abused practices. One line of critique is that P-values are\ninherently unfit to fulfill their ostensible role as measures of scientific\nhypothesis's credibility. It has also been suggested that while P-values may\nhave their role as summary measures of effect, researchers underappreciate the\ndegree of randomness in the P-value. High variability of P-values would suggest\nthat having obtained a small P-value in one study, one is, nevertheless, likely\nto obtain a much larger P-value in a similarly powered replication study. Thus,\n\"replicability of P-value\" is itself questionable. To characterize P-value\nvariability one can use prediction intervals whose endpoints reflect the likely\nspread of P-values that could have been obtained by a replication study.\nUnfortunately, the intervals currently in use, the P-intervals, are based on\nunrealistic implicit assumptions. Namely, P-intervals are constructed with the\nassumptions that imply substantial chances of encountering large values of\neffect size in an observational study, which leads to bias. As an alternative\nto P-intervals, we develop a method that gives researchers flexibility by\nproviding them with the means to control these assumptions. Unlike endpoints of\nP-intervals, endpoints of our intervals are directly interpreted as\nprobabilistic bounds for replication P-values and are resistant to selection\nbias contingent upon approximate prior knowledge of the effect size\ndistribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.01664v3"
    },
    {
        "title": "The more you test, the more you find: Smallest P-values become\n  increasingly enriched with real findings as more tests are conducted",
        "authors": [
            "Olga A. Vsevolozhskaya",
            "Chia-Ling Kuo",
            "Gabriel Ruiz",
            "Luda Diatchenko",
            "Dmitri V. Zaykin"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Increasing accessibility of data to researchers makes it possible to conduct\nmassive amounts of statistical testing. Rather than follow a carefully crafted\nset of scientific hypotheses with statistical analysis, researchers can now\ntest many possible relations and let P-values or other statistical summaries\ngenerate hypotheses for them. Genetic epidemiology field is an illustrative\ncase in this paradigm shift. Driven by technological advances, testing a\nhandful of genetic variants in relation to a health outcome has been abandoned\nin favor of agnostic screening of the entire genome, followed by selection of\ntop hits, e.g., by selection of genetic variants with the smallest association\nP-values. At the same time, nearly total lack of replication of claimed\nassociations that has been shaming the field turned to a flow of reports whose\nfindings have been robustly replicating. Researchers may have adopted better\nstatistical practices by learning from past failures, but we suggest that a\nsteep increase in the amount of statistical testing itself is an important\nfactor. Regardless of whether statistical significance has been reached, an\nincreased number of tested hypotheses leads to enrichment of smallest P-values\nwith genuine associations. In this study, we quantify how the expected\nproportion of genuine signals (EPGS) among top hits changes with an increasing\nnumber of tests. When the rate of occurrence of genuine signals does not\ndecrease too sharply to zero as more tests are performed, the smallest P-values\nare increasingly more likely to represent genuine associations in studies with\nmore tests.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.01788v1"
    },
    {
        "title": "A Quadratically Regularized Functional Canonical Correlation Analysis\n  for Identifying the Global Structure of Pleiotropy with NGS Data",
        "authors": [
            "Nan Lin",
            "Yun Zhu",
            "Ruzong Fan",
            "Momiao Xiong"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Investigating the pleiotropic effects of genetic variants can increase\nstatistical power, provide important information to achieve deep understanding\nof the complex genetic structures of disease, and offer powerful tools for\ndesigning effective treatments with fewer side effects. However, the current\nmultiple phenotype association analysis paradigm lacks breadth (number of\nphenotypes and genetic variants jointly analyzed at the same time) and depth\n(hierarchical structure of phenotype and genotypes). A key issue for high\ndimensional pleiotropic analysis is to effectively extract informative internal\nrepresentation and features from high dimensional genotype and phenotype data.\nTo explore multiple levels of representations of genetic variants, learn their\ninternal patterns involved in the disease development, and overcome critical\nbarriers in advancing the development of novel statistical methods and\ncomputational algorithms for genetic pleiotropic analysis, we proposed a new\nframework referred to as a quadratically regularized functional CCA (QRFCCA)\nfor association analysis which combines three approaches: (1) quadratically\nregularized matrix factorization, (2) functional data analysis and (3)\ncanonical correlation analysis (CCA). Large-scale simulations show that the\nQRFCCA has a much higher power than that of the nine competing statistics while\nretaining the appropriate type 1 errors. To further evaluate performance, the\nQRFCCA and nine other statistics are applied to the whole genome sequencing\ndataset from the TwinsUK study. We identify a total of 79 genes with rare\nvariants and 67 genes with common variants significantly associated with the 46\ntraits using QRFCCA. The results show that the QRFCCA substantially outperforms\nthe nine other statistics.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.04902v1"
    },
    {
        "title": "Even better correction of genome sequencing data",
        "authors": [
            "Maciej Dlugosz",
            "Sebastian Deorowicz",
            "Marek Kokot"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We introduce an improved version of RECKONER, an error corrector for Illumina\nwhole genome sequencing data. By modifying its workflow we reduce the\ncomputation time even 10 times. We also propose a new method of determination\nof $k$-mer length, the key parameter of $k$-spectrum-based family of\ncorrectors. The correction algorithms are examined on huge data sets, i.e.,\nhuman and maize genomes for both Illumina HiSeq and MiSeq instruments.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.00690v1"
    },
    {
        "title": "OncoScore: a novel, Internet-based tool to assess the oncogenic\n  potential of genes",
        "authors": [
            "Rocco Piazza",
            "Daniele Ramazzotti",
            "Roberta Spinelli",
            "Alessandra Pirola",
            "Luca De Sano",
            "Pierangelo Ferrari",
            "Vera Magistroni",
            "Nicoletta Cordani",
            "Nitesh Sharma",
            "Carlo Gambacorti-Passerini"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The complicated, evolving landscape of cancer mutations poses a formidable\nchallenge to identify cancer genes among the large lists of mutations typically\ngenerated in NGS experiments. The ability to prioritize these variants is\ntherefore of paramount importance. To address this issue we developed\nOncoScore, a text-mining tool that ranks genes according to their association\nwith cancer, based on available biomedical literature. Receiver operating\ncharacteristic curve and the area under the curve (AUC) metrics on manually\ncurated datasets confirmed the excellent discriminating capability of OncoScore\n(OncoScore cut-off threshold = 21.09; AUC = 90.3%, 95% CI: 88.1-92.5%),\nindicating that OncoScore provides useful results in cases where an efficient\nprioritization of cancer-associated genes is needed.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.05692v2"
    },
    {
        "title": "Insular microbiogeography",
        "authors": [
            "James H. Kaufman",
            "Christopher A. Elkins",
            "Matthew Davis",
            "Allison M Weis",
            "Bihua C. Huang",
            "Mark K Mammel",
            "Isha R. Patel",
            "Kristen L. Beck",
            "Stefan Edlund",
            "David Chambliss",
            "Simone Bianco",
            "Mark Kunitomi",
            "Bart C. Weimer"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The diversity revealed by large scale genomics in microbiology is calling\ninto question long held beliefs about genome stability, evolutionary rate, even\nthe definition of a species. MacArthur and Wilson's theory of insular\nbiogeography provides an explanation for the diversity of macroscopic animal\nand plant species as a consequence of the associated hierarchical web of\nspecies interdependence. We report a large scale study of microbial diversity\nthat reveals that the cumulative number of genes discovered increases with the\nnumber of genomes studied as a simple power law. This result is demonstrated\nfor three different genera comparing over 15,000 isolates. We show that this\npower law is formally related to the MacArthur-Wilson exponent, suggesting the\nemerging diversity of microbial genotypes arises because the scale independent\nbehavior first reported by MacArthur and Wilson extends down to the scale of\nmicrobes and their genes. Assessing the depth of available whole genome\nsequences implies a dynamically changing core genome, suggesting that\ntraditional taxonomic classifications should be replaced with a quasispecies\nmodel that captures the diversity and dynamic exchange of genes. We report\nSpecies population \"clouds\" in a defined microbiome, with scale invariance\nextending down to the level of single-nucleotide polymorphisms (SNPs).\n",
        "pdf_link": "http://arxiv.org/pdf/1703.07454v1"
    },
    {
        "title": "cyTRON and cyTRON/JS: two Cytoscape-based applications for the inference\n  of cancer evolution models",
        "authors": [
            "Lucrezia Patruno",
            "Edoardo Galimberti",
            "Daniele Ramazzotti",
            "Giulio Caravagna",
            "Luca De Sano",
            "Marco Antoniotti",
            "Alex Graudenzi"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The increasing availability of sequencing data of cancer samples is fueling\nthe development of algorithmic strategies to investigate tumor heterogeneity\nand infer reliable models of cancer evolution. We here build up on previous\nworks on cancer progression inference from genomic alteration data, to deliver\ntwo distinct Cytoscape-based applications, which allow to produce, visualize\nand manipulate cancer evolution models, also by interacting with public genomic\nand proteomics databases. In particular, we here introduce cyTRON, a\nstand-alone Cytoscape app, and cyTRON/JS, a web application which employs the\nfunctionalities of Cytoscape/JS.\n  cyTRON was developed in Java; the code is available at\nhttps://github.com/BIMIB-DISCo/cyTRON and on the Cytoscape App Store\nhttp://apps.cytoscape.org/apps/cytron. cyTRON/JS was developed in JavaScript\nand R; the source code of the tool is available at\nhttps://github.com/BIMIB-DISCo/cyTRON-js and the tool is accessible from\nhttps://bimib.disco.unimib.it/cytronjs/welcome.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03067v2"
    },
    {
        "title": "DeepMetabolism: A Deep Learning System to Predict Phenotype from Genome\n  Sequencing",
        "authors": [
            "Weihua Guo",
            "You Xu",
            "Xueyang Feng"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Life science is entering a new era of petabyte-level sequencing data.\nConverting such big data to biological insights represents a huge challenge for\ncomputational analysis. To this end, we developed DeepMetabolism, a\nbiology-guided deep learning system to predict cell phenotypes from\ntranscriptomics data. By integrating unsupervised pre-training with supervised\ntraining, DeepMetabolism is able to predict phenotypes with high accuracy\n(PCC>0.92), high speed (<30 min for >100 GB data using a single GPU), and high\nrobustness (tolerate up to 75% noise). We envision DeepMetabolism to bridge the\ngap between genotype and phenotype and to serve as a springboard for\napplications in synthetic biology and precision medicine.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03094v1"
    },
    {
        "title": "IGoR: a tool for high-throughput immune repertoire analysis",
        "authors": [
            "Quentin Marcou",
            "Thierry Mora",
            "Aleksandra M Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  High throughput immune repertoire sequencing is promising to lead to new\nstatistical diagnostic tools for medicine and biology. Successful\nimplementations of these methods require a correct characterization, analysis\nand interpretation of these datasets. We present IGoR -- a new comprehensive\ntool that takes B or T-cell receptors sequence reads and quantitatively\ncharacterizes the statistics of receptor generation from both cDNA and gDNA. It\nprobabilistically annotates sequences and its modular structure can investigate\nmodels of increasing biological complexity for different organisms. For B-cells\nIGoR returns the hypermutation statistics, which we use to reveal\nco-localization of hypermutations along the sequence. We demonstrate that IGoR\noutperforms existing tools in accuracy and estimate the sample sizes needed for\nreliable repertoire characterization.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.08246v1"
    },
    {
        "title": "Predicting potential treatments for complex diseases based on miRNA and\n  tissue specificity",
        "authors": [
            "Liang Yu",
            "Jin Zhao",
            "Lin Gao"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Drug repositioning, that is finding new uses for existing drugs to treat more\npatients. Cumulative studies demonstrate that the mature miRNAs as well as\ntheir precursors can be targeted by small molecular drugs. At the same time,\nhuman diseases result from the disordered interplay of tissue- and cell\nlineage-specific processes. However, few computational researches predict\ndrug-disease potential relationships based on miRNA data and tissue\nspecificity. Therefore, based on miRNA data and the tissue specificity of\ndiseases, we propose a new method named as miTS to predict the potential\ntreatments for diseases. Firstly, based on miRNAs data, target genes and\ninformation of FDA approved drugs, we evaluate the relationships between miRNAs\nand drugs in the tissue-specific PPI network. Then, we construct a tripartite\nnetwork: drug-miRNA-disease Finally, we obtain the potential drug-disease\nassociations based on the tripartite network. In this paper, we take breast\ncancer as case study and focus on the top-30 predicted drugs. 25 of them\n(83.3%) are found having known connections with breast cancer in CTD benchmark\nand the other 5 drugs are potential drugs for breast cancer. We further\nevaluate the 5 newly predicted drugs from clinical records, literature mining,\nKEGG pathways enrichment analysis and overlapping genes between enriched\npathways. For each of the 5 new drugs, strongly supported evidences can be\nfound in three or more aspects. In particular, Regorafenib has 15 overlapping\nKEGG pathways with breast cancer and their p-values are all very small. In\naddition, whether in the literature curation or clinical validation,\nRegorafenib has a strong correlation with breast cancer. All the facts show\nthat Regorafenib is likely to be a truly effective drug, worthy of our further\nstudy. It further follows that our method miTS is effective and practical for\npredicting new drug indications.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.01502v1"
    },
    {
        "title": "Bacterial protein interaction networks: connectivity is ruled by gene\n  conservation, essentiality and function",
        "authors": [
            "Maddalena Dilucca",
            "Giulio Cimini",
            "Andrea Giansanti"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Protein-protein interaction (PPI) networks are the backbone of all processes\nin living cells. In this work we relate conservation, essentiality and\nfunctional repertoire of a gene to the connectivity $k$ (i.e., the number of\ninteraction links) of the corresponding protein in the PPI network. On a set of\n42 bacterial genomes of different sizes, and with reasonably separated\nevolutionary trajectories, we investigate three issues: i) whether the\ndistribution of connectivities changes between PPI subnetworks of essential and\nnonessential genes; ii) how gene conservation, measured both by the\nevolutionary retention index (ERI) and by evolutionary pressures, is related to\nthe the connectivity of the corresponding protein; iii) how PPI connectivities\nare modulated by evolutionary and functional relationships, as represented by\nthe Clusters of Orthologous Genes (COGs). We show that conservation,\nessentiality and functional specialisation of genes constrain the connectivity\nof the corresponding proteins in bacterial PPI networks. In particular, we\nisolate a core of highly connected proteins (with connectivities $k\\ge40$),\nwhich is ubiquitous among the species considered here -- though mostly visible\nin the degree distributions of bacteria with small genomes (less than 1000\ngenes). The genes that belong to this highly connected core are conserved,\nessential and, in most cases, belong to the COG cluster J, related to ribosomal\nfunctions and to the processing of genetic information.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.02299v3"
    },
    {
        "title": "Warp: a method for neural network interpretability applied to gene\n  expression profiles",
        "authors": [
            "Trofimov Assya",
            "Lemieux Sebastien",
            "Perreault Claude"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We show a proof of principle for warping, a method to interpret the inner\nworking of neural networks in the context of gene expression analysis. Warping\nis an efficient way to gain insight to the inner workings of neural nets and\nmake them more interpretable. We demonstrate the ability of warping to recover\nmeaningful information for a given class on a samplespecific individual basis.\nWe found warping works well in both linearly and nonlinearly separable\ndatasets. These encouraging results show that warping has a potential to be the\nanswer to neural networks interpretability in computational biology.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04988v1"
    },
    {
        "title": "Learning mutational graphs of individual tumour evolution from\n  single-cell and multi-region sequencing data",
        "authors": [
            "Daniele Ramazzotti",
            "Alex Graudenzi",
            "Luca De Sano",
            "Marco Antoniotti",
            "Giulio Caravagna"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Background. A large number of algorithms is being developed to reconstruct\nevolutionary models of individual tumours from genome sequencing data. Most\nmethods can analyze multiple samples collected either through bulk multi-region\nsequencing experiments or the sequencing of individual cancer cells. However,\nrarely the same method can support both data types.\n  Results. We introduce TRaIT, a computational framework to infer mutational\ngraphs that model the accumulation of multiple types of somatic alterations\ndriving tumour evolution. Compared to other tools, TRaIT supports multi-region\nand single-cell sequencing data within the same statistical framework, and\ndelivers expressive models that capture many complex evolutionary phenomena.\nTRaIT improves accuracy, robustness to data-specific errors and computational\ncomplexity compared to competing methods.\n  Conclusions. We show that the application of TRaIT to single-cell and\nmulti-region cancer datasets can produce accurate and reliable models of\nsingle-tumour evolution, quantify the extent of intra-tumour heterogeneity and\ngenerate new testable experimental hypotheses.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.01076v2"
    },
    {
        "title": "GRIM-Filter: Fast Seed Location Filtering in DNA Read Mapping Using\n  Processing-in-Memory Technologies",
        "authors": [
            "Jeremie S. Kim",
            "Damla Senol Cali",
            "Hongyi Xin",
            "Donghyuk Lee",
            "Saugata Ghose",
            "Mohammed Alser",
            "Hasan Hassan",
            "Oguz Ergin",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Motivation: Seed location filtering is critical in DNA read mapping, a\nprocess where billions of DNA fragments (reads) sampled from a donor are mapped\nonto a reference genome to identify genomic variants of the donor.\nState-of-the-art read mappers 1) quickly generate possible mapping locations\nfor seeds (i.e., smaller segments) within each read, 2) extract reference\nsequences at each of the mapping locations, and 3) check similarity between\neach read and its associated reference sequences with a\ncomputationally-expensive algorithm (i.e., sequence alignment) to determine the\norigin of the read. A seed location filter comes into play before alignment,\ndiscarding seed locations that alignment would deem a poor match. The ideal\nseed location filter would discard all poor match locations prior to alignment\nsuch that there is no wasted computation on unnecessary alignments.\n  Results: We propose a novel seed location filtering algorithm, GRIM-Filter,\noptimized to exploit 3D-stacked memory systems that integrate computation\nwithin a logic layer stacked under memory layers, to perform\nprocessing-in-memory (PIM). GRIM-Filter quickly filters seed locations by 1)\nintroducing a new representation of coarse-grained segments of the reference\ngenome, and 2) using massively-parallel in-memory operations to identify read\npresence within each coarse-grained segment. Our evaluations show that for a\nsequence alignment error tolerance of 0.05, GRIM-Filter 1) reduces the false\nnegative rate of filtering by 5.59x--6.41x, and 2) provides an end-to-end read\nmapper speedup of 1.81x--3.65x, compared to a state-of-the-art read mapper\nemploying the best previous seed location filtering algorithm.\n  Availability: The code is available online at:\nhttps://github.com/CMU-SAFARI/GRIM\n",
        "pdf_link": "http://arxiv.org/pdf/1711.01177v1"
    },
    {
        "title": "Comprehensive overview and assessment of miRNA target prediction tools\n  in human and drosophila melanogaster",
        "authors": [
            "Muniba Faiza",
            "Khushnuma Tanveer",
            "Saman Fatihi",
            "Yonghua Wang",
            "Khalid Raza"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  MicroRNAs (miRNAs) are small non-coding RNAs that control gene expression at\nthe post-transcriptional level through complementary base pairing with the\ntarget mRNA, leading to mRNA degradation and blocking translation process. Any\ndysfunctions of these small regulatory molecules have been linked with the\ndevelopment and progression of several diseases. Therefore, it is necessary to\nreliably predict potential miRNA targets. A large number of computational\nprediction tools have been developed which provide a faster way to find\nputative miRNA targets, but at the same time their results are often\ninconsistent. Hence, finding a reliable, functional miRNA target is still a\nchallenging task. Also, each tool is equipped with different algorithms, and it\nis difficult for the biologists to know which tool is the best choice for their\nstudy. This paper briefly describes fundamental of miRNA target prediction\nalgorithms, discuss frequently used prediction tools, and further, the\nperformance of frequently used prediction tools have been assessed using\nexperimentally validated high confident mature miRNAs and their targets for two\norganisms Human and Drosophila Melanogaster. Both Drosophila Melanogaster and\nHuman supported miRNA target prediction tools have been evaluated separately to\nfind out best performing tool for each of these two organisms. In the human\ndataset, TargetScan showed the best results amongst the other predictors\nfollowed by the miRmap and microT, whereas in the D. Melanogaster dataset,\nMicroT tool showed the best performance followed by the TargetScan in the\ncomparison of other tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.01632v1"
    },
    {
        "title": "Evaluating deep variational autoencoders trained on pan-cancer gene\n  expression",
        "authors": [
            "Gregory P. Way",
            "Casey S. Greene"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Cancer is a heterogeneous disease with diverse molecular etiologies and\noutcomes. The Cancer Genome Atlas (TCGA) has released a large compendium of\nover 10,000 tumors with RNA-seq gene expression measurements. Gene expression\ncaptures the diverse molecular profiles of tumors and can be interrogated to\nreveal differential pathway activations. Deep unsupervised models, including\nVariational Autoencoders (VAE) can be used to reveal these underlying patterns.\nWe compare a one-hidden layer VAE to two alternative VAE architectures with\nincreased depth. We determine the additional capacity marginally improves\nperformance. We train and compare the three VAE architectures to other\ndimensionality reduction techniques including principal components analysis\n(PCA), independent components analysis (ICA), non-negative matrix factorization\n(NMF), and analysis of gene expression by denoising autoencoders (ADAGE). We\ncompare performance in a supervised learning task predicting gene inactivation\npan-cancer and in a latent space analysis of high grade serous ovarian cancer\n(HGSC) subtypes. We do not observe substantial differences across algorithms in\nthe classification task. VAE latent spaces offer biological insights into HGSC\nsubtype biology.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.04828v1"
    },
    {
        "title": "Fast ordered sampling of DNA sequence variants",
        "authors": [
            "Anthony J. Greenberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Explosive growth in the amount of genomic data is matched by increasing power\nof consumer-grade computers. Even applications that require powerful servers\ncan be quickly tested on desktop or laptop machines if we can generate\nrepresentative samples from large data sets. I describe a fast and\nmemory-efficient implementation of an on-line sampling method developed for\ntape drives 30 years ago. Focusing on genotype files, I test the performance of\nthis technique on modern solid-state and spinning hard drives, and show that it\nperforms well compared to a simple sampling scheme. I illustrate its utility by\ndeveloping a method to quickly estimate genome-wide patterns of linkage\ndisequilibrium (LD) decay with distance. I provide open-source software that\nsamples loci from several variant format files, a separate program that\nperforms LD decay estimates, and a C++ library that lets developers incorporate\nthese methods into their own projects.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.06325v1"
    },
    {
        "title": "Interpretable Convolutional Neural Networks for Effective Translation\n  Initiation Site Prediction",
        "authors": [
            "Jasper Zuallaert",
            "Mijung Kim",
            "Yvan Saeys",
            "Wesley De Neve"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Thanks to rapidly evolving sequencing techniques, the amount of genomic data\nat our disposal is growing increasingly large. Determining the gene structure\nis a fundamental requirement to effectively interpret gene function and\nregulation. An important part in that determination process is the\nidentification of translation initiation sites. In this paper, we propose a\nnovel approach for automatic prediction of translation initiation sites,\nleveraging convolutional neural networks that allow for automatic feature\nextraction. Our experimental results demonstrate that we are able to improve\nthe state-of-the-art approaches with a decrease of 75.2% in false positive rate\nand with a decrease of 24.5% in error rate on chosen datasets. Furthermore, an\nin-depth analysis of the decision-making process used by our predictive model\nshows that our neural network implicitly learns biologically relevant features\nfrom scratch, without any prior knowledge about the problem at hand, such as\nthe Kozak consensus sequence, the influence of stop and start codons in the\nsequence and the presence of donor splice site patterns. In summary, our\nfindings yield a better understanding of the internal reasoning of a\nconvolutional neural network when applying such a neural network to genomic\ndata.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09558v1"
    },
    {
        "title": "GIFT: Guided and Interpretable Factorization for Tensors - An\n  Application to Large-Scale Multi-platform Cancer Analysis",
        "authors": [
            "Jungwoo Lee",
            "Sejoon Oh",
            "Lee Sael"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Given multi-platform genome data with prior knowledge of functional gene\nsets, how can we extract interpretable latent relationships between patients\nand genes? More specifically, how can we devise a tensor factorization method\nwhich produces an interpretable gene factor matrix based on gene set\ninformation while maintaining the decomposition quality and speed? We propose\nGIFT, a Guided and Interpretable Factorization for Tensors. GIFT provides\ninterpretable factor matrices by encoding prior knowledge as a regularization\nterm in its objective function. Experiment results demonstrate that GIFT\nproduces interpretable factorizations with high scalability and accuracy, while\nother methods lack interpretability. We apply GIFT to the PanCan12 dataset, and\nGIFT reveals significant relations between cancers, gene sets, and genes, such\nas influential gene sets for specific cancer (e.g., interferon-gamma response\ngene set for ovarian cancer) or relations between cancers and genes (e.g., BRCA\ncancer - APOA1 gene and OV, UCEC cancers - BST2 gene).\n",
        "pdf_link": "http://arxiv.org/pdf/1801.02769v1"
    },
    {
        "title": "Deep Learning for Genomics: A Concise Overview",
        "authors": [
            "Tianwei Yue",
            "Yuanxin Wang",
            "Longxiang Zhang",
            "Chunming Gu",
            "Haoru Xue",
            "Wenping Wang",
            "Qi Lyu",
            "Yujie Dun"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Advancements in genomic research such as high-throughput sequencing\ntechniques have driven modern genomic studies into \"big data\" disciplines. This\ndata explosion is constantly challenging conventional methods used in genomics.\nIn parallel with the urgent demand for robust algorithms, deep learning has\nsucceeded in a variety of fields such as vision, speech, and text processing.\nYet genomics entails unique challenges to deep learning since we are expecting\nfrom deep learning a superhuman intelligence that explores beyond our knowledge\nto interpret the genome. A powerful deep learning model should rely on\ninsightful utilization of task-specific knowledge. In this paper, we briefly\ndiscuss the strengths of different deep learning models from a genomic\nperspective so as to fit each particular task with a proper deep architecture,\nand remark on practical considerations of developing modern deep learning\narchitectures for genomics. We also provide a concise review of deep learning\napplications in various aspects of genomic research, as well as pointing out\npotential opportunities and obstacles for future genomics applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.00810v4"
    },
    {
        "title": "IntLIM: Integration using Linear Models of metabolomics and gene\n  expression data",
        "authors": [
            "Jalal K. Siddiqui",
            "Elizabeth Baskin",
            "Mingrui Liu",
            "Carmen Z. Cantemir-Stone",
            "Bofei Zhang",
            "Russell Bonneville",
            "Joseph P. McElroy",
            "Kevin R. Coombes",
            "Ewy A. Mathé"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Integration of transcriptomic and metabolomic data improves functional\ninterpretation of disease-related metabolomic phenotypes, and facilitates\ndiscovery of putative metabolite biomarkers and gene targets. For this reason,\nthese data are increasingly collected in large cohorts, driving a need for the\ndevelopment of novel methods for their integration. Of note,\nclinical/translational studies typically provide snapshot gene and metabolite\nprofiles and, oftentimes, most metabolites are not identified. Thus, in these\ntypes of studies, pathway/network approaches that take into account the\ncomplexity of gene-metabolite relationships may neither be applicable nor\nreadily uncover novel relationships. With this in mind, we propose a simple\nlinear modeling approach to capture phenotype-specific gene-metabolite\nassociations, with the assumption that co-regulation patterns reflect\nfunctionally related genes and metabolites. The proposed linear model,\nmetabolite ~ gene + phenotype + gene:phenotype, specifically evaluates whether\ngene-metabolite relationships differ by phenotype, by testing whether the\nrelationship in one phenotype is significantly different from the relationship\nin another phenotype (via an interaction gene:phenotype p-value). Interaction\np-values for all possible gene-metabolite pairs are computed and significant\npairs are clustered by the directionality of associations. We implemented our\napproach as an R package, IntLIM, which includes a user-friendly Shiny app. We\napplied IntLIM to two published datasets, collected in NCI-60 cell lines and in\nhuman breast tumor and non-tumor tissue. We demonstrate that IntLIM captures\nrelevant tumor-specific gene-metabolite associations involved in cancer-related\npathways. and also uncover novel relationships that could be tested\nexperimentally. The IntLIM R package is publicly available in GitHub\n(https://github.com/mathelab/IntLIM).\n",
        "pdf_link": "http://arxiv.org/pdf/1802.10588v1"
    },
    {
        "title": "Gene Co-expression Network analysis of Lung Squamous Cell Carcinoma data",
        "authors": [
            "Md-Nafiz Hamid"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  We performed a gene co-expression analysis on Lung Squamous Cell Carcinoma\ndata to find modules (groups) of genes that may highly impact the growth of\nthese type of tumors. Additionally, we used cancer survival data to relate\nmodules to prognostic significance in terms of survival time. Analysis on\nRNA-seq data revealed modules which are significant in gene enrichment\nanalysis. Specifically, two genes - RFC4 and ECT2 - have been found to be\nsignificant in terms of survival time. We also performed a second gene\nco-expression analysis on a second dataset of microarray data, and many\nsignificant genes found in this analysis could also be found in the RNA-seq\ndata implying that these genes might indeed play a crucial role in Lung\nSquamous Cancer. All the R code for the analysis can be found at:\n\\url{https://github.com/nafizh/Gene_coexpression_analysis_lung_cancer}\n",
        "pdf_link": "http://arxiv.org/pdf/1804.01217v1"
    },
    {
        "title": "Classification of large DNA methylation datasets for identifying cancer\n  drivers",
        "authors": [
            "Fabrizio Celli",
            "Fabio Cumbo",
            "Emanuel Weitschek"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  DNA methylation is a well-studied genetic modification crucial to regulate\nthe functioning of the genome. Its alterations play an important role in\ntumorigenesis and tumor-suppression. Thus, studying DNA methylation data may\nhelp biomarker discovery in cancer. Since public data on DNA methylation become\nabundant, and considering the high number of methylated sites (features)\npresent in the genome, it is important to have a method for efficiently\nprocessing such large datasets. Relying on big data technologies, we propose\nBIGBIOCL an algorithm that can apply supervised classification methods to\ndatasets with hundreds of thousands of features. It is designed for the\nextraction of alternative and equivalent classification models through\niterative deletion of selected features. We run experiments on DNA methylation\ndatasets extracted from The Cancer Genome Atlas, focusing on three tumor types:\nbreast, kidney, and thyroid carcinomas. We perform classifications extracting\nseveral methylated sites and their associated genes with accurate performance.\nResults suggest that BIGBIOCL can perform hundreds of classification iterations\non hundreds of thousands of features in few hours. Moreover, we compare the\nperformance of our method with other state-of-the-art classifiers and with a\nwide-spread DNA methylation analysis method based on network analysis. Finally,\nwe are able to efficiently compute multiple alternative classification models\nand extract, from DNA-methylation large datasets, a set of candidate genes to\nbe further investigated to determine their active role in cancer. BIGBIOCL,\nresults of experiments, and a guide to carry on new experiments are freely\navailable on GitHub.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04839v1"
    },
    {
        "title": "Joint Analysis of Individual-level and Summary-level GWAS Data by\n  Leveraging Pleiotropy",
        "authors": [
            "Mingwei Dai",
            "Xiang Wan",
            "Hao Peng",
            "Yao Wang",
            "Yue Liu",
            "Jin Liu",
            "Zongben Xu",
            "Can Yang"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  A large number of recent genome-wide association studies (GWASs) for complex\nphenotypes confirm the early conjecture for polygenicity, suggesting the\npresence of large number of variants with only tiny or moderate effects.\nHowever, due to the limited sample size of a single GWAS, many associated\ngenetic variants are too weak to achieve the genome-wide significance. These\nundiscovered variants further limit the prediction capability of GWAS.\nRestricted access to the individual-level data and the increasing availability\nof the published GWAS results motivate the development of methods integrating\nboth the individual-level and summary-level data. How to build the connection\nbetween the individual-level and summary-level data determines the efficiency\nof using the existing abundant summary-level resources with limited\nindividual-level data, and this issue inspires more efforts in the existing\narea.\n  In this study, we propose a novel statistical approach, LEP, which provides a\nnovel way of modeling the connection between the individual-level data and\nsummary-level data. LEP integrates both types of data by \\underline{LE}veraing\n\\underline{P}leiotropy to increase the statistical power of risk variants\nidentification and the accuracy of risk prediction. The algorithm for parameter\nestimation is developed to handle genome-wide-scale data. Through comprehensive\nsimulation studies, we demonstrated the advantages of LEP over the existing\nmethods. We further applied LEP to perform integrative analysis of Crohn's\ndisease from WTCCC and summary statistics from GWAS of some other diseases,\nsuch as Type 1 diabetes, Ulcerative colitis and Primary biliary cirrhosis. LEP\nwas able to significantly increase the statistical power of identifying risk\nvariants and improve the risk prediction accuracy from 63.39\\% ($\\pm$ 0.58\\%)\nto 68.33\\% ($\\pm$ 0.32\\%) using about 195,000 variants.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.11011v1"
    },
    {
        "title": "A Markovian genomic concatenation model guided by persymmetric matrices",
        "authors": [
            "Andrew G. Hart",
            "M. Sobottka"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The aim of this work is to provide a rigorous mathematical analysis of a\nstochastic concatenation model presented by Sobottka and Hart (2011) which\nallows approximation of the first-order stochastic structure in bacterial DNA\nby means of a stationary Markov chain. Two probabilistic constructions that\nrigorously formalize the model are presented. Necessary and sufficient\nconditions for a Markov chain to be generated by the model are given, as well\nas the theoretical background needed for designing new algorithms for\nstatistical analyses of real bacterial genomes. It is shown that the model\nencompasses the Markov chains satisfying intra-strand parity, a property\nobserved in most DNA sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.02231v2"
    },
    {
        "title": "Bivariate Causal Discovery and its Applications to Gene Expression and\n  Imaging Data Analysis",
        "authors": [
            "Rong Jiao",
            "Nan Lin",
            "Zixin Hu",
            "David A Bennett",
            "Li Jin",
            "Momiao Xiong"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The mainstream of research in genetics, epigenetics and imaging data analysis\nfocuses on statistical association or exploring statistical dependence between\nvariables. Despite their significant progresses in genetic research,\nunderstanding the etiology and mechanism of complex phenotypes remains elusive.\nUsing association analysis as a major analytical platform for the complex data\nanalysis is a key issue that hampers the theoretic development of genomic\nscience and its application in practice. Causal inference is an essential\ncomponent for the discovery of mechanical relationships among complex\nphenotypes. Many researchers suggest making the transition from association to\ncausation. Despite its fundamental role in science, engineering and\nbiomedicine, the traditional methods for causal inference require at least\nthree variables. However, quantitative genetic analysis such as QTL, eQTL,\nmQTL, and genomic-imaging data analysis requires exploring the causal\nrelationships between two variables. This paper will focus on bivariate causal\ndiscovery. We will introduce independence of cause and mechanism (ICM) as a\nbasic principle for causal inference, algorithmic information theory and\nadditive noise model (ANM) as major tools for bivariate causal discovery.\nLarge-scale simulations will be performed to evaluate the feasibility of the\nANM for bivariate causal discovery. To further evaluate their performance for\ncausal inference, the ANM will be applied to the construction of gene\nregulatory networks. Also, the ANM will be applied to trait-imaging data\nanalysis to illustrate three scenarios: presence of both causation and\nassociation, presence of association while absence of causation, and presence\nof causation, while lack of association between two variables.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.04164v1"
    },
    {
        "title": "Pan-Cancer Epigenetic Biomarker Selection from Blood Samples Using SAS",
        "authors": [
            "Xi Chen",
            "Jin Xie",
            "Qingcong Yuan"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  A key focus in current cancer research is the discovery of cancer biomarkers\nthat allow earlier detection with high accuracy and lower costs for both\npatients and hospitals. Blood samples have long been used as a health status\nindicator, but DNA methylation signatures in blood have not been fully\nappreciated in cancer research. Historically, analysis of cancer has been\nconducted directly with the patient's tumor or related tissues. Such analyses\nallow physicians to diagnose a patient's health and cancer status; however,\nphysicians must observe certain symptoms that prompt them to use biopsies or\nimaging to verify the diagnosis. This is a post-hoc approach. Our study will\nfocus on epigenetic information for cancer detection, specifically information\nabout DNA methylation in human peripheral blood samples in cancer discordant\nmonozygotic twin-pairs. This information might be able to help us detect cancer\nmuch earlier, before the first symptom appears. Several other types of\nepigenetic data can also be used, but here we demonstrate the potential of\nblood DNA methylation data as a biomarker for pan-cancer using SAS 9.3 and SAS\nEM. We report that 55 methylation CpG sites measurable in blood samples can be\nused as biomarkers for early cancer detection and classification.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.09203v1"
    },
    {
        "title": "Figure 1 Theory Meets Figure 2 Experiments in the Study of Gene\n  Expression",
        "authors": [
            "Rob Phillips",
            "Nathan M. Belliveau",
            "Griffin Chure",
            "Hernan G. Garcia",
            "Manuel Razo-Mejia",
            "Clarissa Scholes"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  It is tempting to believe that we now own the genome. The ability to read and\nre-write it at will has ushered in a stunning period in the history of science.\nNonetheless, there is an Achilles heel exposed by all of the genomic data that\nhas accrued: we still don't know how to interpret it. Many genes are subject to\nsophisticated programs of transcriptional regulation, mediated by DNA sequences\nthat harbor binding sites for transcription factors which can up- or\ndown-regulate gene expression depending upon environmental conditions. This\ngives rise to an input-output function describing how the level of expression\ndepends upon the parameters of the regulated gene { for instance, on the number\nand type of binding sites in its regulatory sequence. In recent years, the\nability to make precision measurements of expression, coupled with the ability\nto make increasingly sophisticated theoretical predictions, have enabled an\nexplicit dialogue between theory and experiment that holds the promise of\ncovering this genomic Achilles heel. The goal is to reach a predictive\nunderstanding of transcriptional regulation that makes it possible to calculate\ngene expression levels from DNA regulatory sequence. This review focuses on the\ncanonical simple repression motif to ask how well the models that have been\nused to characterize it actually work. We consider a hierarchy of increasingly\nsophisticated experiments in which the minimal parameter set learned at one\nlevel is applied to make quantitative predictions at the next. We show that\nthese careful quantitative dissections provide a template for a predictive\nunderstanding of the many more complex regulatory arrangements found across all\ndomains of life.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11627v1"
    },
    {
        "title": "CAMIRADA: Cancer microRNA association discovery algorithm, a case study\n  on breast cancer",
        "authors": [
            "Sepideh Shamsizadeh",
            "Sama Goliaei",
            "Zahra Razaghi Moghadam"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In recent studies, non-coding protein RNAs have been identified as microRNA\nthat can be used as biomarkers for early diagnosis and treatment of cancer,\nthat decrease mortality in cancer. A microRNA may target hundreds or thousands\nof genes and a gene may regulate several microRNAs, so determining which\nmicroRNA is associated with which cancer is a big challenge. Many computational\nmethods have been performed to detect micoRNAs association with cancer, but\nmore effort is needed with higher accuracy. Increasing research has shown that\nrelationship between microRNAs and TFs play a significant role in the diagnosis\nof cancer. Therefore, we developed a new computational framework (CAMIRADA) to\nidentify cancer-related microRNAs based on the relationship between microRNAs\nand disease genes (DG) in the protein network, the functional relationships\nbetween microRNAs and Transcription Factors (TF) on the co-expression network,\nand the relationship between microRNAs and the Differential Expression Gene\n(DEG) on co-expression network. The CAMIRADA was applied to assess breast\ncancer data from two HMDD and miR2Disease databases. In this study, the AUC for\nthe 65 microRNAs of the top of the list was 0.95, which was more accurate than\nthe similar methods used to detect microRNAs associated with the cancer artery.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.01854v1"
    },
    {
        "title": "Gene family amplification facilitates adaptation in freshwater Unionid\n  bivalve Megalonaias nervosa",
        "authors": [
            "Rebekah L. Rogers",
            "Stephanie L. Grizzard",
            "James E. Titus-McQuillan",
            "Katherine Bockrath",
            "Sagar Patel",
            "John P. Wares",
            "Jeffrey T. Garner",
            "Cathy C. Moore"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  As organisms are faced with intense rapidly changing selective pressures, new\ngenetic material is required to facilitate adaptation. Among sources of genetic\nnovelty, gene duplications and transposable elements (TEs) offer new genes or\nnew regulatory patterns that can facilitate evolutionary change. With advances\nin genome sequencing it is possible to gain a broader view of how gene family\nproliferation and TE content evolve in non-model species when populations\nbecome threatened. Freshwater bivalves (Unionidae) currently face severe\nanthropogenic challenges. Over 70% of species in the United States are\nthreatened, endangered or extinct due to pollution, damming of waterways, and\noverfishing. We have created a reference genome for M. nervosa to determine how\ngenome content has evolved in the face of these widespread environmental\nchallenges. We observe a burst of recent transposable element proliferation\ncausing a 382 Mb expansion in genome content. Gene family expansion is common,\nwith a duplication rate of 1.16 x 10^-8 per gene per generation. Cytochrome\nP450, ABC transporters, Hsp70 genes, von Willebrand proteins, chitin metabolism\ngenes, mitochondria eating proteins, and opsin gene families have experienced\nsignificantly greater amplification and show signatures of selection. We use\nevolutionary theory to assess the relative contribution of SNPs and\nduplications in evolutionary change. Estimates suggest that gene family\nevolution may offer an exceptional substrate of genetic variation in M.\nnervosa, with Psgv=0.185 compared with Psgv=0.067 for single nucleotide\nchanges. Hence, we suggest that gene family evolution is a source of \"hopeful\nmonsters\" within the genome that facilitate adaptation.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.00131v2"
    },
    {
        "title": "Haplotype-resolved de novo assembly with phased assembly graphs",
        "authors": [
            "Haoyu Cheng",
            "Gregory T Concepcion",
            "Xiaowen Feng",
            "Haowen Zhang",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Haplotype-resolved de novo assembly is the ultimate solution to the study of\nsequence variations in a genome. However, existing algorithms either collapse\nheterozygous alleles into one consensus copy or fail to cleanly separate the\nhaplotypes to produce high-quality phased assemblies. Here we describe hifiasm,\na new de novo assembler that takes advantage of long high-fidelity sequence\nreads to faithfully represent the haplotype information in a phased assembly\ngraph. Unlike other graph-based assemblers that only aim to maintain the\ncontiguity of one haplotype, hifiasm strives to preserve the contiguity of all\nhaplotypes. This feature enables the development of a graph trio binning\nalgorithm that greatly advances over standard trio binning. On three human and\nfive non-human datasets, including California redwood with a $\\sim$30-gigabase\nhexaploid genome, we show that hifiasm frequently delivers better assemblies\nthan existing tools and consistently outperforms others on haplotype-resolved\nassembly.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01237v1"
    },
    {
        "title": "Revisiting the Neutral Dynamics Derived Limiting Guanine-Cytosine\n  Content Using the Human De Novo Point Mutation Data",
        "authors": [
            "Wentian Li",
            "Yannis Almirantis",
            "Astero Provata"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  We revisit the topic of human genome guanine-cytosine content under neutral\nevolution. For this study, the de novo mutation data within human is used to\nestimate mutational rate instead of using base substitution data between\nrelated species. We then define a new measure of mutation bias which separate\nthe de novo mutation counts from the background guanine-cytosine content\nitself, making comparison between different datasets easier. We derive a new\nformula for calculating limiting guanine-cytosine content by separating\nCpG-involved mutational events as an independent variable. Using the formula\nwhen CpG-involved mutations are considered, the guanine-cytosine content drops\nless severely in the limit of neutral dynamics. We provide evidence, under\ncertain assumptions, that an isochore-like structure might remain as a limiting\nconfiguration of the neutral mutational dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01781v1"
    },
    {
        "title": "Host immune response driving SARS-CoV-2 evolution",
        "authors": [
            "Rui Wang",
            "Yuta Hozumi",
            "Yong-Hui Zheng",
            "Changchuan Yin",
            "Guo-Wei Wei"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The transmission and evolution of severe acute respiratory syndrome\ncoronavirus 2 (SARS-CoV-2) are of paramount importance to the controlling and\ncombating of coronavirus disease 2019 (COVID-19) pandemic. Currently, near\n15,000 SARS-CoV-2 single mutations have been recorded, having a great\nramification to the development of diagnostics, vaccines, antibody therapies,\nand drugs. However, little is known about SARS-CoV-2 evolutionary\ncharacteristics and general trend. In this work, we present a comprehensive\ngenotyping analysis of existing SARS-CoV-2 mutations. We reveal that host\nimmune response via APOBEC and ADAR gene editing gives rise to near 65\\% of\nrecorded mutations. Additionally, we show that children under age five and the\nelderly may be at high risk from COVID-19 because of their overreacting to the\nviral infection. Moreover, we uncover that populations of Oceania and Africa\nreact significantly more intensively to SARS-CoV-2 infection than those of\nEurope and Asia, which may explain why African Americans were shown to be at\nincreased risk of dying from COVID-19, in addition to their high risk of\ngetting sick from COVID-19 caused by systemic health and social inequities.\nFinally, our study indicates that for two viral genome sequences of the same\norigin, their evolution order may be determined from the ratio of mutation type\nC$>$T over T$>$C.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.07488v2"
    },
    {
        "title": "Collective regulation by non-coding RNA",
        "authors": [
            "J. M. Deutsch"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  We study genetic networks that produce many species of non-coding RNA\nmolecules that are present at a moderate density, as typically exists in the\ncell. The associations of the many species of these RNA are modeled physically,\ntaking into account the equilibrium constants between bound and unbound states.\nBy including the pair-wise binding of the many RNA species, the network becomes\nhighly interconnected and shows different properties than the usual type of\ngenetic network. It shows much more robustness to mutation, and also rapid\nevolutionary adaptation in an environment that oscillates in time. This\nprovides a possible explanation for the weak evolutionary constraints seen in\nmuch of the non-coding RNA that has been studied.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.1899v1"
    },
    {
        "title": "Accurate Liability Estimation Improves Power in Ascertained Case Control\n  Studies",
        "authors": [
            "Omer Weissbrod",
            "Christoph Lippert",
            "Dan Geiger",
            "David Heckerman"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Linear mixed models (LMMs) have emerged as the method of choice for\nconfounded genome-wide association studies. However, the performance of LMMs in\nnon-randomly ascertained case-control studies deteriorates with increasing\nsample size. We propose a framework called LEAP (Liability Estimator As a\nPhenotype, https://github.com/omerwe/LEAP) that tests for association with\nestimated latent values corresponding to severity of phenotype, and demonstrate\nthat this can lead to a substantial power increase.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.2448v3"
    },
    {
        "title": "Scalable Genomics with R and Bioconductor",
        "authors": [
            "Michael Lawrence",
            "Martin Morgan"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  This paper reviews strategies for solving problems encountered when analyzing\nlarge genomic data sets and describes the implementation of those strategies in\nR by packages from the Bioconductor project. We treat the scalable processing,\nsummarization and visualization of big genomic data. The general ideas are well\nestablished and include restrictive queries, compression, iteration and\nparallel computing. We demonstrate the strategies by applying Bioconductor\npackages to the detection and analysis of genetic variants from a whole genome\nsequencing experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.2864v1"
    },
    {
        "title": "Understanding genomic alterations in cancer genomes using an integrative\n  network approach",
        "authors": [
            "Edwin Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  In recent years, cancer genome sequencing and other high-throughput studies\nof cancer genomes have generated many notable discoveries. In this review,\nNovel genomic alteration mechanisms, such as chromothripsis (chromosomal\ncrisis) and kataegis (mutation storms), and their implications for cancer are\ndiscussed. Genomic alterations spur cancer genome evolution. Thus, the\nrelationship between cancer clonal evolution and cancer stems cells is\ncommented. The key question in cancer biology concerns how these genomic\nalterations support cancer development and metastasis in the context of\nbiological functioning. Thus far, efforts such as pathway analysis have\nimproved the understanding of the functional contributions of genetic mutations\nand DNA copy number variations to cancer development, progression and\nmetastasis. However, the known pathways correspond to a small fraction,\nplausibly 5-10%, of somatic mutations and genes with an altered copy number. To\ndevelop a comprehensive understanding of the function of these genomic\nalterations in cancer, an integrative network framework is proposed and\ndiscussed. Finally, the challenges and the directions of studying cancer omic\ndata using an integrative network approach are commented.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.3263v1"
    },
    {
        "title": "Sensitivity of mRNA Translation",
        "authors": [
            "Gilad Poker",
            "Michael Margaliot",
            "Tamir Tuller"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Using the dynamic mean-field approximation of the totally asymmetric simple\nexclusion process (TASEP), we investigate the effect of small changes in the\ninitiation, exit, and elongation rates along the mRNA strand on the steady\nstate protein translation rate. We focus on two special cases where exact\nclosed-form expressions for the translation rate sensitivity can be derived. We\ndiscuss the ramifications of our results in the context of functional genomics,\nmolecular evolution, and synthetic biology.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.5399v1"
    },
    {
        "title": "Integrating alignment-based and alignment-free sequence similarity\n  measures for biological sequence classification",
        "authors": [
            "Ivan Borozan",
            "Stuart Watt",
            "Vincent Ferretti"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Alignment-based sequence similarity searches, while accurate for some type of\nsequences, can produce incorrect results when used on more divergent but\nfunctionally related sequences that have undergone the sequence rearrangements\nobserved in many bacterial and viral genomes. Here, we propose a classification\nmodel that exploits the complementary nature of alignment-based and\nalignment-free similarity measures with the aim to improve the accuracy with\nwhich DNA and protein sequences are characterized. Our model classifies\nsequences using a combined sequence similarity score calculated by adaptively\nweighting the contribution of different sequence similarity measures. Weights\nare determined independently for each sequence in the test set and reflect the\ndiscriminatory ability of individual similarity measures in the training set.\nSince the similarity between some sequences is determined more accurately with\none type of measure rather than another, our classifier allows different sets\nof weights to be associated with different sequences. Using five different\nsimilarity measures we show that our model significantly improves the\nclassification accuracy over the current composition and alignment based\nmodels, when predicting the taxonomic lineage for both short viral sequence\nfragments and complete viral sequences. We also show that our model can be used\neffectively for the classification of reads from a real metagenome dataset as\nwell as protein sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.5721v2"
    },
    {
        "title": "Statistics of shared components in complex component systems",
        "authors": [
            "Andrea Mazzolini",
            "Marco Gherardi",
            "Michele Caselle",
            "Marco Cosentino Lagomarsino",
            "Matteo Osella"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Many complex systems are modular. Such systems can be represented as\n\"component systems\", i.e., sets of elementary components, such as LEGO bricks\nin LEGO sets. The bricks found in a LEGO set reflect a target architecture,\nwhich can be built following a set-specific list of instructions. In other\ncomponent systems, instead, the underlying functional design and constraints\nare not obvious a priori, and their detection is often a challenge of both\nscientific and practical importance, requiring a clear understanding of\ncomponent statistics. Importantly, some quantitative invariants appear to be\ncommon to many component systems, most notably a common broad distribution of\ncomponent abundances, which often resembles the well-known Zipf's law. Such\n\"laws\" affect in a general and non-trivial way the component statistics,\npotentially hindering the identification of system-specific functional\nconstraints or generative processes. Here, we specifically focus on the\nstatistics of shared components, i.e., the distribution of the number of\ncomponents shared by different system-realizations, such as the common bricks\nfound in different LEGO sets. To account for the effects of component\nheterogeneity, we consider a simple null model, which builds\nsystem-realizations by random draws from a universe of possible components.\nUnder general assumptions on abundance heterogeneity, we provide analytical\nestimates of component occurrence, which quantify exhaustively the statistics\nof shared components. Surprisingly, this simple null model can positively\nexplain important features of empirical component-occurrence distributions\nobtained from data on bacterial genomes, LEGO sets, and book chapters. Specific\narchitectural features and functional constraints can be detected from\noccurrence patterns as deviations from these null predictions, as we show for\nthe illustrative case of the \"core\" genome in bacteria.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.08356v2"
    },
    {
        "title": "LOGAN: High-Performance GPU-Based X-Drop Long-Read Alignment",
        "authors": [
            "Alberto Zeni",
            "Giulia Guidi",
            "Marquita Ellis",
            "Nan Ding",
            "Marco D. Santambrogio",
            "Steven Hofmeyr",
            "Aydın Buluç",
            "Leonid Oliker",
            "Katherine Yelick"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Pairwise sequence alignment is one of the most computationally intensive\nkernels in genomic data analysis, accounting for more than 90% of the runtime\nfor key bioinformatics applications. This method is particularly expensive for\nthird-generation sequences due to the high computational cost of analyzing\nsequences of length between 1Kb and 1Mb. Given the quadratic overhead of exact\npairwise algorithms for long alignments, the community primarily relies on\napproximate algorithms that search only for high-quality alignments and stop\nearly when one is not found. In this work, we present the first GPU\noptimization of the popular X-drop alignment algorithm, that we named LOGAN.\nResults show that our high-performance multi-GPU implementation achieves up to\n181.6 GCUPS and speed-ups up to 6.6x and 30.7x using 1 and 6 NVIDIA Tesla V100,\nrespectively, over the state-of-the-art software running on two IBM Power9\nprocessors using 168 CPU threads, with equivalent accuracy. We also demonstrate\na 2.3x LOGAN speed-up versus ksw2, a state-of-art vectorized algorithm for\nsequence alignment implemented in minimap2, a long-read mapping software. To\nhighlight the impact of our work on a real-world application, we couple LOGAN\nwith a many-to-many long-read alignment software called BELLA, and demonstrate\nthat our implementation improves the overall BELLA runtime by up to 10.6x.\nFinally, we adapt the Roofline model for LOGAN and demonstrate that our\nimplementation is near-optimal on the NVIDIA Tesla V100s.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.05200v1"
    },
    {
        "title": "Comparing copy-number profiles under multi-copy amplifications and\n  deletions",
        "authors": [
            "Garance Cordonnier",
            "Manuel Lafond"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  During cancer progression, malignant cells accumulate somatic mutations that\ncan lead to genetic aberrations. In particular, evolutionary events akin to\nsegmental duplications or deletions can alter the copy-number profile (CNP) of\na set of genes in a genome. Our aim is to compute the evolutionary distance\nbetween two cells for which only CNPs are known. This asks for the minimum\nnumber of segmental amplifications and deletions to turn one CNP into another.\nThis was recently formalized into a model where each event is assumed to alter\na copy-number by $1$ or $-1$, even though these events can affect large\nportions of a chromosome. We propose a general cost framework where an event\ncan modify the copy-number of a gene by larger amounts. We show that any cost\nscheme that allows segmental deletions of arbitrary length makes computing the\ndistance strongly NP-hard. We then devise a factor $2$ approximation algorithm\nfor the problem when copy-numbers are non-zero and provide an implementation\ncalled \\textsf{cnp2cnp}. We evaluate our approach experimentally by\nreconstructing simulated cancer phylogenies from the pairwise distances\ninferred by \\textsf{cnp2cnp} and compare it against two other alternatives,\nnamely the \\textsf{MEDICC} distance and the Euclidean distance. The\nexperimental results show that our distance yields more accurate phylogenies on\naverage than these alternatives if the given CNPs are error-free, but that the\n\\textsf{MEDICC} distance is slightly more robust against error in the data. In\nall cases, our experiments show that either our approach or the \\textsf{MEDICC}\napproach should preferred over the Euclidean distance.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.11271v1"
    },
    {
        "title": "Faster exact Markovian probability functions for motif occurrences: a\n  DFA-only approach",
        "authors": [
            "Paolo Ribeca",
            "Emanuele Raineri"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  Background: The computation of the statistical properties of motif\noccurrences has an obviously relevant practical application: for example,\npatterns that are significantly over- or under-represented in the genome are\ninteresting candidates for biological roles. However, the problem is\ncomputationally hard; as a result, virtually all the existing pipelines use\nfast but approximate scoring functions, in spite of the fact that they have\nbeen shown to systematically produce incorrect results. A few interesting exact\napproaches are known, but they are very slow and hence not practical in the\ncase of realistic sequences. Results: We give an exact solution, solely based\non deterministic finite-state automata (DFAs), to the problem of finding not\nonly the p-value, but the whole relevant part of the Markovian probability\ndistribution function of a motif in a biological sequence. In particular, the\ntime complexity of the algorithm in the most interesting regimes is far better\nthan that of Nuel (2006), which was the fastest similar exact algorithm known\nto date; in many cases, even approximate methods are outperformed. Conclusions:\nDFAs are a standard tool of computer science for the study of patterns, but so\nfar they have been sparingly used in the study of biological motifs. Previous\nworks do propose algorithms involving automata, but there they are used\nrespectively as a first step to build a Finite Markov Chain Imbedding (FMCI),\nor to write a generating function: whereas we only rely on the concept of DFA\nto perform the calculations. This innovative approach can realistically be used\nfor exact statistical studies of very long genomes and protein sequences, as we\nillustrate with some examples on the scale of the human genome.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.3675v1"
    },
    {
        "title": "A new DNA alignment method based on inverted index",
        "authors": [
            "Wang Liang",
            "Zhao KaiYong"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  This paper presents a novel DNA sequences alignment method based on inverted\nindex. Now most large scale information retrieval system are all use inverted\nindex as the basic data structure. But its application in DNA sequence\nalignment is still not found. This paper just discuss such applications. Three\nmain problems, DNA segmenting, long DNA query search, DNA search ranking\nalgorithm and evaluation method are detailed respectively. This research\npresents a new avenue to build more effective DNA alignment methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0194v1"
    },
    {
        "title": "Statistical data mining for symbol associations in genomic databases",
        "authors": [
            "Bernard Ycart",
            "Frédéric Pont",
            "Jean-Jacques Fournié"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  A methodology is proposed to automatically detect significant symbol\nassociations in genomic databases. A new statistical test is proposed to assess\nthe significance of a group of symbols when found in several genesets of a\ngiven database. Applied to symbol pairs, the thresholded p-values of the test\ndefine a graph structure on the set of symbols. The cliques of that graph are\nsignificant symbol associations, linked to a set of genesets where they can be\nfound. The method can be applied to any database, and is illustrated MSigDB C2\ndatabase. Many of the symbol associations detected in C2 or in non-specific\nselections did correspond to already known interactions. On more specific\nselections of C2, many previously unkown symbol associations have been\ndetected. These associations unveal new candidates for gene or protein\ninteractions, needing further investigation for biological evidence.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.1337v2"
    },
    {
        "title": "DuctApe: a suite for the analysis and correlation of genomic and\n  OmnilogTM Phenotype Microarray data",
        "authors": [
            "Marco Galardini",
            "Alessio Mengoni",
            "Emanuele G. Biondi",
            "Roberto Semeraro",
            "Alessandro Florio",
            "Marco Bazzicalupo",
            "Anna Benedetti",
            "Stefano Mocali"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Addressing the functionality of genomes is one of the most important and\nchallenging tasks of today's biology. In particular the ability to link\ngenotypes to corresponding phenotypes is of interest in the reconstruction and\nbiotechnological manipulation of metabolic pathways. Over the last years, the\nOmniLogTM Phenotype Microarray (PM) technology has been used to address many\nspecific issues related to the metabolic functionality of microorganisms.\nHowever, computational tools that could directly link PM data with the gene(s)\nof interest followed by the extraction of information on genephenotype\ncorrelation are still missing. Here we present DuctApe, a suite that allows the\nanalysis of both genomic sequences and PM data, to find metabolic differences\namong PM experiments and to correlate them with KEGG pathways and gene\npresence/absence patterns. As example, an application of the program to four\nbacterial datasets is presented. The source code and tutorials are available at\nhttp://combogenomics.github.io/DuctApe/.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.4276v3"
    },
    {
        "title": "The relationships among GC content, nucleosome occupancy, and exon size",
        "authors": [
            "Liya Wang",
            "Lincoln Stein",
            "Doreen Ware"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  The average size of internal translated exons, ranging from 120 to 165 nt\nacross metazoans, is approximately the size of the typical mononucleosome (147\nnt). Genome-wide study has also shown that nucleosome occupancy is\nsignificantly higher in exons than in introns, which might indicate that the\nevolution of exon size is related to its nucleosome occupancy. By grouping\nexons by the GC contents of their flanking introns, we show that the average\nexon size is positively correlated with its GC content. Using the sequencing\ndata from direct mapping of Homo sapiens nucleosomes with limited nuclease\ndigestion, we show that the level of nucleosome occupancy is also positively\ncorrelated with the exon GC content in a similar fashion. We then demonstrated\nthat exon size is positively correlated with their nucleosome occupancy. The\nstrong correlation between exon size and the nucleosome occupancy suggests that\nchromatin organization may be related to the evolution of exon sizes.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2487v2"
    },
    {
        "title": "VSEAMS: A pipeline for variant set enrichment analysis using summary\n  GWAS data identifies IKZF3, BATF and ESRRA as key transcription factors in\n  type 1 diabetes",
        "authors": [
            "Oliver S Burren",
            "Hui Guo",
            "Chris Wallace"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Motivation: Genome-wide association studies (GWAS) have identified many loci\nimplicated in disease susceptibility. Integration of GWAS summary statistics (p\nvalues) and functional genomic datasets should help to elucidate mechanisms.\nResults: We describe the extension of a previously described non-parametric\nmethod to test whether GWAS signals are enriched in functionally defined loci\nto a situation where only GWAS p values are available. The approach is\nimplemented in VSEAMS, a freely available software pipeline. We use VSEAMS to\nintegrate functional gene sets defined via transcription factor knock down\nexperiments with GWAS results for type 1 diabetes and find variant set\nenrichment in gene sets associated with IKZF3, BATF and ESRRA. IKZF3 lies in a\nknown T1D susceptibility region, whilst BATF and ESRRA overlap other immune\ndisease susceptibility regions, validating our approach and suggesting novel\navenues of research for type 1 diabetes. Availability and implementation:\nVSEAMS is available for download http://github.com/ollyburren/vseams.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4482v1"
    },
    {
        "title": "Detecting somatic mutations in genomic sequences by means of\n  Kolmogorov-Arnold analysis",
        "authors": [
            "V. G. Gurzadyan",
            "H. Yan",
            "G. Vlahovic",
            "A. Kashin",
            "P. Killela",
            "Z. Reitman",
            "S. Sargsyan",
            "G. Yegorian",
            "G. Milledge",
            "B. Vlahovic"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The Kolmogorov-Arnold stochasticity parameter technique is applied for the\nfirst time to the study of cancer genome sequencing, to reveal mutations. Using\ndata generated by next generation sequencing technologies, we have analyzed the\nexome sequences of brain tumor patients with matched tumor and normal blood. We\nshow that mutations contained in sequencing data can be revealed using this\ntechnique thus providing a new methodology for determining subsequences of\ngiven length containing mutations i.e. its value differs from those of\nsubsequences without mutations. A potential application for this technique\ninvolves simplifying the procedure of finding segments with mutations, speeding\nup genomic research, and accelerating its implementation in clinical\ndiagnostic. Moreover, the prediction of a mutation associated to a family of\nfrequent mutations in numerous types of cancers based purely on the value of\nthe Kolmogorov function, indicates that this applied marker may recognize\ngenomic sequences that are in extremely low abundance and can be used in\nrevealing new types of mutations.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.04080v1"
    },
    {
        "title": "Evaluation of the Number of Different Genomes on Medium and\n  Identification of Known Genomes Using Composition Spectra Approach",
        "authors": [
            "Valery Kirzhner",
            "Zeev Volkovich"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The article presents the theoretical foundations of the algorithm for\ncalculating the number of different genomes in the medium under study and of\ntwo algorithms for determining the presence of a particular (known) genome in\nthis medium. The approach is based on the analysis of the compositional spectra\nof subsequently sequenced samples of the medium. The theoretical estimations\nrequired for the implementation of the algorithms are obtained.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.06159v1"
    },
    {
        "title": "A New Approach for Scalable Analysis of Microbial Communities",
        "authors": [
            "Ehsaneddin Asgari",
            "Kiavash Garakani",
            "Mohammad R. K Mofrad"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Microbial communities play important roles in the function and maintenance of\nvarious biosystems, ranging from human body to the environment. Current methods\nfor analysis of microbial communities are typically based on taxonomic\nphylogenetic alignment using 16S rRNA metagenomic or Whole Genome Sequencing\ndata. In typical characterizations of microbial communities, studies deal with\nbillions of micobial sequences, aligning them to a phylogenetic tree. We\nintroduce a new approach for the efficient analysis of microbial communities.\nOur new reference-free analysis tech- nique is based on n-gram sequence\nanalysis of 16S rRNA data and reduces the processing data size dramatically (by\n105 fold), without requiring taxonomic alignment. The proposed approach is\napplied to characterize phenotypic microbial community differ- ences in\ndifferent settings. Specifically, we applied this approach in classification of\nmicrobial com- munities across different body sites, characterization of oral\nmicrobiomes associated with healthy and diseased individuals, and\nclassification of microbial communities longitudinally during the develop- ment\nof infants. Different dimensionality reduction methods are introduced that\noffer a more scalable analysis framework, while minimizing the loss in\nclassification accuracies. Among dimensionality re- duction techniques, we\npropose a continuous vector representation for microbial communities, which can\nwidely be used for deep learning applications in microbial informatics.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.00397v1"
    },
    {
        "title": "iCorr : Complex correlation method to detect origin of replication in\n  prokaryotic and eukaryotic genomes",
        "authors": [
            "Shubham Kundal",
            "Raunak Lohiya",
            "Kushal Shah"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Computational prediction of origin of replication (ORI) has been of great\ninterest in bioinformatics and several methods including GC Skew, Z curve,\nauto-correlation etc. have been explored in the past. In this paper, we have\nextended the auto-correlation method to predict ORI location with much higher\nresolution for prokaryotes. The proposed complex correlation method (iCorr)\nconverts the genome sequence into a sequence of complex numbers by mapping the\nnucleotides to {+1,-1,+i,-i} instead of {+1,-1} used in the auto-correlation\nmethod (here, 'i' is square root of -1). Thus, the iCorr method uses\ninformation about the positions of all the four nucleotides unlike the earlier\nauto-correlation method which uses the positional information of only one\nnucleotide. Also, this earlier method required visual inspection of the\nobtained graphs to identify the location of origin of replication. The proposed\niCorr method does away with this need and is able to identify the origin\nlocation simply by picking the peak in the iCorr graph. The iCorr method also\nworks for a much smaller segment size compared to the earlier auto-correlation\nmethod, which can be very helpful in experimental validation of the\ncomputational predictions. We have also developed a variant of the iCorr method\nto predict ORI location in eukaryotes and have tested it with the\nexperimentally known origin locations of S. cerevisiae with an average accuracy\nof 71.76%.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.00707v2"
    },
    {
        "title": "Cell-to-cell variability and robustness in S-phase duration from genome\n  replication kinetics",
        "authors": [
            "Qing Zhang",
            "Federico Bassetti",
            "Marco Gherardi",
            "Marco Cosentino Lagomarsino"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Genome replication, a key process for a cell, relies on stochastic initiation\nby replication origins, causing a variability of replication timing from cell\nto cell. While stochastic models of eukaryotic replication are widely\navailable, the link between the key parameters and overall replication timing\nhas not been addressed systematically.We use a combined analytical and\ncomputational approach to calculate how positions and strength of many origins\nlead to a given cell-to-cell variability of total duration of the replication\nof a large region, a chromosome or the entire genome.Specifically, the total\nreplication timing can be framed as an extreme-value problem, since it is due\nto the last region that replicates in each cell. Our calculations identify two\nregimes based on the spread between characteristic completion times of all\ninter-origin regions of a genome. For widely different completion times, timing\nis set by the single specific region that is typically the last to replicate in\nall cells. Conversely, when the completion time of all regions are\ncomparable,an extreme-value estimate shows that the cell-to-cell variability of\ngenome replication timing has universal properties. Comparison with available\ndata shows that the replication program of three yeast species falls in this\nextreme-value regime.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.08038v2"
    },
    {
        "title": "Variant tolerant read mapping using min-hashing",
        "authors": [
            "Jens Quedenfeld",
            "Sven Rahmann"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  DNA read mapping is a ubiquitous task in bioinformatics, and many tools have\nbeen developed to solve the read mapping problem. However, there are two trends\nthat are changing the landscape of readmapping: First, new sequencing\ntechnologies provide very long reads with high error rates (up to 15%). Second,\nmany genetic variants in the population are known, so the reference genome is\nnot considered as a single string over ACGT, but as a complex object containing\nthese variants. Most existing read mappers do not handle these new\ncircumstances appropriately.\n  We introduce a new read mapper prototype called VATRAM that considers\nvariants. It is based on Min-Hashing of q-gram sets of reference genome\nwindows. Min-Hashing is one form of locality sensitive hashing. The variants\nare directly inserted into VATRAMs index which leads to a fast mapping process.\nOur results show that VATRAM achieves better precision and recall than\nstate-of-the-art read mappers like BWA under certain cirumstances. VATRAM is\nopen source and can be accessed at\nhttps://bitbucket.org/Quedenfeld/vatram-src/.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.01703v2"
    },
    {
        "title": "Prior Knowledge based mutation prioritization towards causal variant\n  finding in rare disease",
        "authors": [
            "Vasundhara Dehiya",
            "Jaya Thomas",
            "Lee Sael"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  How do we determine the mutational effects in exome sequencing data with\nlittle or no statistical evidence? Can protein structural information fill in\nthe gap of not having enough statistical evidence? In this work, we answer the\ntwo questions with the goal towards determining pathogenic effects of rare\nvariants in rare disease. We take the approach of determining the importance of\npoint mutation loci focusing on protein structure features. The proposed\nstructure-based features contain information about geometric, physicochemical,\nand functional information of mutation loci and those of structural neighbors\nof the loci. The performance of the structure-based features trained on 80\\% of\nHumDiv and tested on 20\\% of HumDiv and on ClinVar datasets showed high levels\nof discernibility in the mutation's pathogenic or benign effects: F score of\n0.71 and 0.68 respectively using multi-layer perceptron. Combining structure-\nand sequence-based feature further improve the accuracy: F score of 0.86\n(HumDiv) and 0.75 (ClinVar). Also, careful examination of the rare variants in\nrare diseases cases showed that structure-based features are important in\ndiscerning importance of variant loci.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.03399v1"
    },
    {
        "title": "Incorporating Biological Knowledge with Factor Graph Neural Network for\n  Interpretable Deep Learning",
        "authors": [
            "Tianle Ma",
            "Aidong Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  While deep learning has achieved great success in many fields, one common\ncriticism about deep learning is its lack of interpretability. In most cases,\nthe hidden units in a deep neural network do not have a clear semantic meaning\nor correspond to any physical entities. However, model interpretability and\nexplainability are crucial in many biomedical applications. To address this\nchallenge, we developed the Factor Graph Neural Network model that is\ninterpretable and predictable by combining probabilistic graphical models with\ndeep learning. We directly encode biological knowledge such as Gene Ontology as\na factor graph into the model architecture, making the model transparent and\ninterpretable. Furthermore, we devised an attention mechanism that can capture\nmulti-scale hierarchical interactions among biological entities such as genes\nand Gene Ontology terms. With parameter sharing mechanism, the unrolled Factor\nGraph Neural Network model can be trained with stochastic depth and generalize\nwell. We applied our model to two cancer genomic datasets to predict target\nclinical variables and achieved better results than other traditional machine\nlearning and deep learning models. Our model can also be used for gene set\nenrichment analysis and selecting Gene Ontology terms that are important to\ntarget clinical variables.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.00537v1"
    },
    {
        "title": "DOT: Gene-set analysis by combining decorrelated association statistics",
        "authors": [
            "Olga A Vsevolozhskaya",
            "Min Shi",
            "Fengjiao Hu",
            "Dmitri V Zaykin"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Historically, the majority of statistical association methods have been\ndesigned assuming availability of SNP-level information. However, modern\ngenetic and sequencing data present new challenges to access and sharing of\ngenotype-phenotype datasets, including cost management, difficulties in\nconsolidation of records across research groups, etc. These issues make methods\nbased on SNP-level summary statistics for a joint analysis of variants in a\ngroup particularly appealing. The most common form of combining statistics is a\nsum of SNP-level squared scores, possibly weighted, as in burden tests for rare\nvariants. The overall significance of the resulting statistic is evaluated\nusing its distribution under the null hypothesis. Here, we demonstrate that\nthis basic approach can be substantially improved by decorrelating scores prior\nto their addition, resulting in remarkable power gains in situations that are\nmost commonly encountered in practice; namely, under heterogeneity of effect\nsizes and diversity between pairwise LD. In these situations, the power of the\ntraditional test, based on the added squared scores, quickly reaches a ceiling,\nas the number of variants increases. Thus, the traditional approach does not\nbenefit from information potentially contained in any additional SNPs, while\nour decorrelation by orthogonal transformation (DOT) method yields steady gain\nin power. We present theoretical and computational analyses of both approaches,\nand reveal causes behind sometimes dramatic difference in their respective\npowers. We showcase DOT by analyzing breast cancer data, in which our method\nstrengthened levels of previously reported associations and implied the\npossibility of multiple new alleles that jointly confer breast cancer risk.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.02321v2"
    },
    {
        "title": "Unsupervised Representation Learning of DNA Sequences",
        "authors": [
            "Vishal Agarwal",
            "N Jayanth Kumar Reddy",
            "Ashish Anand"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Recently several deep learning models have been used for DNA sequence based\nclassification tasks. Often such tasks require long and variable length DNA\nsequences in the input. In this work, we use a sequence-to-sequence autoencoder\nmodel to learn a latent representation of a fixed dimension for long and\nvariable length DNA sequences in an unsupervised manner. We evaluate both\nquantitatively and qualitatively the learned latent representation for a\nsupervised task of splice site classification. The quantitative evaluation is\ndone under two different settings. Our experiments show that these\nrepresentations can be used as features or priors in closely related tasks such\nas splice site classification. Further, in our qualitative analysis, we use a\nmodel attribution technique Integrated Gradients to infer significant sequence\nsignatures influencing the classification accuracy. We show the identified\nsplice signatures resemble well with the existing knowledge.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.03087v1"
    },
    {
        "title": "Nested partitions from hierarchical clustering statistical validation",
        "authors": [
            "Christian Bongiorno",
            "Salvatore Miccichè",
            "Rosario N. Mantegna"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  We develop a greedy algorithm that is fast and scalable in the detection of a\nnested partition extracted from a dendrogram obtained from hierarchical\nclustering of a multivariate series. Our algorithm provides a $p$-value for\neach clade observed in the hierarchical tree. The $p$-value is obtained by\ncomputing a number of bootstrap replicas of the dissimilarity matrix and by\nperforming a statistical test on each difference between the dissimilarity\nassociated with a given clade and the dissimilarity of the clade of its parent\nnode. We prove the efficacy of our algorithm with a set of benchmarks generated\nby using a hierarchical factor model. We compare the results obtained by our\nalgorithm with those of Pvclust. Pvclust is a widely used algorithm developed\nwith a global approach originally motivated by phylogenetic studies. In our\nnumerical experiments we focus on the role of multiple hypothesis test\ncorrection and on the robustness of the algorithms to inaccuracy and errors of\ndatasets. We also apply our algorithm to a reference empirical dataset. We\nverify that our algorithm is much faster than Pvclust algorithm and has a\nbetter scalability both in the number of elements and in the number of records\nof the investigated multivariate set. Our algorithm provides a hierarchically\nnested partition in much shorter time than currently widely used algorithms\nallowing to perform a statistically validated cluster analysis detection in\nvery large systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.06908v1"
    },
    {
        "title": "Applied Category Theory for Genomics -- An Initiative",
        "authors": [
            "Yanying Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The ultimate secret of all lives on earth is hidden in their genomes -- a\ntotality of DNA sequences. We currently know the whole genome sequence of many\norganisms, while our understanding of the genome architecture on a systematic\nlevel remains rudimentary. Applied category theory opens a promising way to\nintegrate the humongous amount of heterogeneous informations in genomics, to\nadvance our knowledge regarding genome organization, and to provide us with a\ndeep and holistic view of our own genomes. In this work we explain why applied\ncategory theory carries such a hope, and we move on to show how it could\nactually do so, albeit in baby steps. The manuscript intends to be readable to\nboth mathematicians and biologists, therefore no prior knowledge is required\nfrom either side.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.02822v1"
    },
    {
        "title": "ProDOMA: improve PROtein DOMAin classification for third-generation\n  sequencing reads using deep learning",
        "authors": [
            "Du Nan",
            "Jiayu Shang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Motivation: With the development of third-generation sequencing technologies,\npeople are able to obtain DNA sequences with lengths from 10s to 100s of kb.\nThese long reads allow protein domain annotation without assembly, thus can\nproduce important insights into the biological functions of the underlying\ndata. However, the high error rate in third-generation sequencing data raises a\nnew challenge to established domain analysis pipelines. The state-of-the-art\nmethods are not optimized for noisy reads and have shown unsatisfactory\naccuracy of domain classification in third-generation sequencing data. New\ncomputational methods are still needed to improve the performance of domain\nprediction in long noisy reads. Results: In this work, we introduce ProDOMA, a\ndeep learning model that conducts domain classification for third-generation\nsequencing reads. It uses deep neural networks with 3-frame translation\nencoding to learn conserved features from partially correct translations. In\naddition, we formulate our problem as an open-set problem and thus our model\ncan reject unrelated DNA reads such as those from noncoding regions. In the\nexperiments on simulated reads of protein coding sequences and real reads from\nthe human genome, our model outperforms HMMER and DeepFam on protein domain\nclassification. In summary, ProDOMA is a useful end-to-end protein domain\nanalysis tool for long noisy reads without relying on error correction.\nAvailability: The source code and the trained model are freely available at\nhttps://github.com/strideradu/ProDOMA. Contact: yannisun@cityu.edu.hk\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12591v1"
    },
    {
        "title": "Distilled Single Cell Genome Sequencing and De Novo Assembly for Sparse\n  Microbial Communities",
        "authors": [
            "Zeinab Taghavi",
            "Narjes S. Movahedi",
            "Sorin Draghici",
            "Hamidreza Chitsaz"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Identification of every single genome present in a microbial sample is an\nimportant and challenging task with crucial applications. It is challenging\nbecause there are typically millions of cells in a microbial sample, the vast\nmajority of which elude cultivation. The most accurate method to date is\nexhaustive single cell sequencing using multiple displacement amplification,\nwhich is simply intractable for a large number of cells. However, there is hope\nfor breaking this barrier as the number of different cell types with distinct\ngenome sequences is usually much smaller than the number of cells.\n  Here, we present a novel divide and conquer method to sequence and de novo\nassemble all distinct genomes present in a microbial sample with a sequencing\ncost and computational complexity proportional to the number of genome types,\nrather than the number of cells. The method is implemented in a tool called\nSqueezambler. We evaluated Squeezambler on simulated data. The proposed divide\nand conquer method successfully reduces the cost of sequencing in comparison\nwith the naive exhaustive approach.\n  Availability: Squeezambler and datasets are available under\nhttp://compbio.cs.wayne.edu/software/squeezambler/.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.0062v2"
    },
    {
        "title": "Adaptive reference-free compression of sequence quality scores",
        "authors": [
            "Lilian Janin",
            "Giovanna Rosone",
            "Anthony J. Cox"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation:\n  Rapid technological progress in DNA sequencing has stimulated interest in\ncompressing the vast datasets that are now routinely produced. Relatively\nlittle attention has been paid to compressing the quality scores that are\nassigned to each sequence, even though these scores may be harder to compress\nthan the sequences themselves. By aggregating a set of reads into a compressed\nindex, we find that the majority of bases can be predicted from the sequence of\nbases that are adjacent to them and hence are likely to be less informative for\nvariant calling or other applications. The quality scores for such bases are\naggressively compressed, leaving a relatively small number at full resolution.\nSince our approach relies directly on redundancy present in the reads, it does\nnot need a reference sequence and is therefore applicable to data from\nmetagenomics and de novo experiments as well as to resequencing data.\n  Results:\n  We show that a conservative smoothing strategy affecting 75% of the quality\nscores above Q2 leads to an overall quality score compression of 1 bit per\nvalue with a negligible effect on variant calling. A compression of 0.68 bit\nper quality value is achieved using a more aggressive smoothing strategy, again\nwith a very small effect on variant calling.\n  Availability:\n  Code to construct the BWT and LCP-array on large genomic data sets is part of\nthe BEETL library, available as a github respository at\nhttp://git@github.com:BEETL/BEETL.git .\n",
        "pdf_link": "http://arxiv.org/pdf/1305.0159v1"
    },
    {
        "title": "Response to No gene-specific optimization of mutation rate in\n  Escherichia coli",
        "authors": [
            "Inigo Martincorena",
            "Nicholas M. Luscombe"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  In a letter published in Molecular Biology Evolution [10], Chen and Zhang\nargue that the variation of the mutation rate along the Escherichia coli genome\nthat we recently reported [3] cannot be evolutionarily optimised. To support\nthis claim they first attempt to calculate the selective advantage of a local\nreduction in the mutation rate and conclude that it is not strong enough to be\nfavoured by selection. Second, they analyse the distribution of 166 mutations\nfrom a wild-type E. coli K12 MG1655 strain and 1,346 mutations from a\nrepair-deficient strain, and claim to find a positive association between\ntranscription and mutation rate rather than the negative association that we\nreported. Here we respond to this communication. Briefly, we explain how the\nlong-standing theory of mutation-modifier alleles supports the evolution of\nlocal mutation rates within a genome by mechanisms acting on sufficiently large\nregions of a genome, which is consistent with our original observations [3,4].\nWe then explain why caution must be exercised when comparing mutations from\nrepair deficient strains to data from wild-type strains, as different\nmutational processes dominate these conditions. Finally, a reanalysis of the\ndata used by Zhang and Chen with an alternative expression dataset reveals that\ntheir conclussions are unreliable.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.1436v2"
    },
    {
        "title": "Turtle: Identifying frequent k-mers with cache-efficient algorithms",
        "authors": [
            "Rajat Shuvro Roy",
            "Debashish Bhattacharya",
            "Alexander Schliep"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Counting the frequencies of k-mers in read libraries is often a first step in\nthe analysis of high-throughput sequencing experiments. Infrequent k-mers are\nassumed to be a result of sequencing errors. The frequent k-mers constitute a\nreduced but error-free representation of the experiment, which can inform read\nerror correction or serve as the input to de novo assembly methods. Ideally,\nthe memory requirement for counting should be linear in the number of frequent\nk-mers and not in the, typically much larger, total number of k-mers in the\nread library.\n  We present a novel method that balances time, space and accuracy requirements\nto efficiently extract frequent k-mers even for high coverage libraries and\nlarge genomes such as human. Our method is designed to minimize cache-misses in\na cache-efficient manner by using a Pattern-blocked Bloom filter to remove\ninfrequent k-mers from consideration in combination with a novel\nsort-and-compact scheme, instead of a Hash, for the actual counting. While this\nincreases theoretical complexity, the savings in cache misses reduce the\nempirical running times. A variant can resort to a counting Bloom filter for\neven larger savings in memory at the expense of false negatives in addition to\nthe false positives common to all Bloom filter based approaches. A comparison\nto the state-of-the-art shows reduced memory requirements and running times.\nNote that we also provide the first competitive method to count k-mers up to\nsize 64.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.1861v1"
    },
    {
        "title": "featureCounts: An efficient general-purpose program for assigning\n  sequence reads to genomic features",
        "authors": [
            "Yang Liao",
            "Gordon K Smyth",
            "Wei Shi"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Next-generation sequencing technologies generate millions of short sequence\nreads, which are usually aligned to a reference genome. In many applications,\nthe key information required for downstream analysis is the number of reads\nmapping to each genomic feature, for example to each exon or each gene. The\nprocess of counting reads is called read summarization. Read summarization is\nrequired for a great variety of genomic analyses but has so far received\nrelatively little attention in the literature. We present featureCounts, a read\nsummarization program suitable for counting reads generated from either RNA or\ngenomic DNA sequencing experiments. featureCounts implements highly efficient\nchromosome hashing and feature blocking techniques. It is considerably faster\nthan existing methods (by an order of magnitude for gene-level summarization)\nand requires far less computer memory. It works with either single or\npaired-end reads and provides a wide range of options appropriate for different\nsequencing applications. featureCounts is available under GNU General Public\nLicense as part of the Subread (http://subread.sourceforge.net) or Rsubread\n(http://www.bioconductor.org) software packages.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.3347v2"
    },
    {
        "title": "Reverse vaccinology in Plasmodium falciparum 3D7",
        "authors": [
            "Raul Isea",
            "Rafael Mayo-Garcia",
            "Silvia Restrepo"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  A timely immunization can be effective against certain diseases and can save\nthousands of lives. However, for some diseases it has been difficult, so far,\nto develop an efficient vaccine. Malaria, a tropical disease caused by a\nparasite of the genus Plasmodium, is one example. Bioinformatics has opened the\nway to new lines of experimental investigation One example is reverse\nvaccinology that aims to identify antigens that are capable of generating an\nimmune response in a given organism using in silico studies. In this study we\napplied a reverse vaccinology methodology using a bioinformatics pipeline. We\nobtained 45 potential linear B cells consensus epitopes from the whole genome\nof P. falciparum 3D7 that can be used as candidates for malaria vaccines. The\ndirect implication of the results obtained is to open the way to experimentally\nvalidate more epitopes to increase the efficiency of the available treatments\nagainst malaria and to explore the methodology in other diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.01692v1"
    },
    {
        "title": "Mouse T cell repertoires as statistical ensembles: overall\n  characterization and age dependence",
        "authors": [
            "Zachary Sethna",
            "Yuval Elhanati",
            "Crissy S. Dudgeon",
            "Curtis G. Callan Jr.",
            "Arnold Levine",
            "Thierry Mora",
            "Aleksandra M. Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The ability of the adaptive immune system to respond to arbitrary pathogens\nstems from the broad diversity of immune cell surface receptors (TCRs). This\ndiversity originates in a stochastic DNA editing process (VDJ recombination)\nthat acts each time a new immune cell is created from a stem cell. By analyzing\nT cell sequence repertoires taken from the blood and thymus of mice of\ndifferent ages, we quantify the significant changes in this process that occur\nin development from embryo to young adult. We find a rapid increase with age in\nthe number of random insertions in the VDJ recombination process, leading to a\ndramatic increase in diversity. Since the blood accumulates thymic output over\ntime, blood repertoires are mixtures of different statistical recombination\nprocesses and, by unraveling the mixture statistics, we can obtain a clear\npicture of the time evolution of the early immune system. Sequence repertoire\nanalysis also allows us to detect the effect of selection on the output of the\nVDJ recombination process. The effects we find are nearly identical between\nthymus and blood, suggesting that they mainly reflect selection for proper\nfolding of the TCR receptor protein.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.03119v1"
    },
    {
        "title": "CLEAR: Coverage-based Limiting-cell Experiment Analysis for RNA-seq",
        "authors": [
            "Logan A Walker",
            "Michael G Sovic",
            "Chi-Ling Chiang",
            "Eileen Hu",
            "Jiyeon K Denninger",
            "Xi Chen",
            "Elizabeth D Kirby",
            "John C Byrd",
            "Natarajan Muthusamy",
            "Ralf Bundschuh",
            "Pearlly Yan"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Direct cDNA preamplification protocols developed for single-cell RNA-seq have\nenabled transcriptome profiling of precious clinical samples and rare cells\nwithout sample pooling or RNA extraction. Currently, there is no algorithm\noptimized to reveal and remove noisy transcripts in limiting-cell RNA-seq\n(lcRNA-seq) data for downstream analyses. Herein, we present CLEAR, a workflow\nthat identifies reliably quantifiable transcripts in lcRNA-seq data for\ndifferentially expressed gene (DEG) analysis. Libraries at three input amounts\nof FACS-derived CD5+ and CD5- cells from a chronic lymphocytic leukemia patient\nwere used to develop CLEAR. When using CLEAR transcripts vs. using all\ntranscripts, downstream analyses revealed more shared transcripts across\ndifferent input RNA amounts, improved Principal Component Analysis (PCA)\nseparation, and yielded more DEGs between cell types. As proof-of-principle,\nCLEAR was applied to an in-house lcRNA-seq dataset and two public datasets.\nWhen imputation is used, CLEAR is also adaptable to large clinical studies and\nfor single cell analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.03142v2"
    },
    {
        "title": "Deep SNP: An End-to-end Deep Neural Network with Attention-based\n  Localization for Break-point Detection in SNP Array Genomic data",
        "authors": [
            "Hamid Eghbal-zadeh",
            "Lukas Fischer",
            "Niko Popitsch",
            "Florian Kromp",
            "Sabine Taschner-Mandl",
            "Khaled Koutini",
            "Teresa Gerber",
            "Eva Bozsaky",
            "Peter F. Ambros",
            "Inge M. Ambros",
            "Gerhard Widmer",
            "Bernhard A. Moser"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Diagnosis and risk stratification of cancer and many other diseases require\nthe detection of genomic breakpoints as a prerequisite of calling copy number\nalterations (CNA). This, however, is still challenging and requires\ntime-consuming manual curation. As deep-learning methods outperformed classical\nstate-of-the-art algorithms in various domains and have also been successfully\napplied to life science problems including medicine and biology, we here\npropose Deep SNP, a novel Deep Neural Network to learn from genomic data.\nSpecifically, we used a manually curated dataset from 12 genomic single\nnucleotide polymorphism array (SNPa) profiles as truth-set and aimed at\npredicting the presence or absence of genomic breakpoints, an indicator of\nstructural chromosomal variations, in windows of 40,000 probes. We compare our\nresults with well-known neural network models as well as Rawcopy though this\ntool is designed to predict breakpoints and in addition genomic segments with\nhigh sensitivity. We show, that Deep SNP is capable of successfully predicting\nthe presence or absence of a breakpoint in large genomic windows and\noutperforms state-of-the-art neural network models. Qualitative examples\nsuggest that integration of a localization unit may enable breakpoint detection\nand prediction of genomic segments, even if the breakpoint coordinates were not\nprovided for network training. These results warrant further evaluation of\nDeepSNP for breakpoint localization and subsequent calling of genomic segments.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.08840v1"
    },
    {
        "title": "Scalable optimal Bayesian classification of single-cell trajectories\n  under regulatory model uncertainty",
        "authors": [
            "Ehsan Hajiramezanali",
            "Mahdi Imani",
            "Ulisses Braga-Neto",
            "Xiaoning Qian",
            "Edward R Dougherty"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Single-cell gene expression measurements offer opportunities in deriving\nmechanistic understanding of complex diseases, including cancer. However, due\nto the complex regulatory machinery of the cell, gene regulatory network (GRN)\nmodel inference based on such data still manifests significant uncertainty. The\ngoal of this paper is to develop optimal classification of single-cell\ntrajectories accounting for potential model uncertainty. Partially-observed\nBoolean dynamical systems (POBDS) are used for modeling gene regulatory\nnetworks observed through noisy gene-expression data. We derive the exact\noptimal Bayesian classifier (OBC) for binary classification of single-cell\ntrajectories. The application of the OBC becomes impractical for large GRNs,\ndue to computational and memory requirements. To address this, we introduce a\nparticle-based single-cell classification method that is highly scalable for\nlarge GRNs with much lower complexity than the optimal solution. The\nperformance of the proposed particle-based method is demonstrated through\nnumerical experiments using a POBDS model of the well-known T-cell large\ngranular lymphocyte (T-LGL) leukemia network with noisy time-series\ngene-expression data.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.03188v1"
    },
    {
        "title": "Assembly ASM291031v2 (Genbank: GCA_002910315.2) identified as assembly\n  of the Northern Dolly Varden (Salvelinus malma malma) genome, and not the\n  Arctic char (S. alpinus) genome",
        "authors": [
            "S. V. Shedko"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  To date, twelve complete genomes representing eleven species belonging to six\ngenera have been sequenced in salmonids. For the genus Salvelinus, it was\nsupposed to sequence the genome of Arctic char, one of the most variable\nspecies of vertebrate animals. Sequencing was carried out (Christensen et al.,\n2018) using the tissues of the female IW2-2015 obtained from the company\nengaged in industrial aquaculture of chars - Icy Waters Ltd. The company\nexploits two of its own broodstocks - NL and TR, originating from the chars\nfrom the Nauyuk Lake and the Tree River (Nunavut, Canada). Since the complete\nmitochondrial genome of the female IW2-2015 was absent in the published\nassembly ASM291031v2, we determined its type and complete sequence from the\nsequence read archives taken from Genbank. It was found that the female's\nmitogenome belongs to the BERING haplogroup, which is characteristic of\nNorthern Dolly Varden S. malma malma. Analysis of other unlinked diagnostic\nloci encoded by nuclear DNA (ITS1, RAG1, SFO-12, SFO-18, SMM-21) also revealed\ndistinctive characters of Northern Dolly Varden in female IW2-2015. It was\nconcluded that the genomic assembly ASM291031v2 was obtained not from an\nindividual of Arctic char S. alpinus, but from an individual of a related\nspecies - Northern Dolly Varden S. malma malma. The identical to the IW2-2015\nfemale characteristics of diagnostic loci were found in other individuals from\nthe broodstock TR. Apparently, the broodstock TR is entirely a strain derived\nfrom Northern Dolly Varden. Since assembly ASM291031v2 was obtained from a\nspecimen originated from the marginal population of Northern Dolly Varden (Tree\nR.) isolated from the main range of the species and with some traces of\nintrogressive hybridization, this assembly can hardly be considered as a\ndescription of a typical genome of S. malma malma.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.02474v2"
    },
    {
        "title": "AirLift: A Fast and Comprehensive Technique for Remapping Alignments\n  between Reference Genomes",
        "authors": [
            "Jeremie S. Kim",
            "Can Firtina",
            "Meryem Banu Cavlak",
            "Damla Senol Cali",
            "Mohammed Alser",
            "Nastaran Hajinazar",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  AirLift is the first read remapping tool that enables users to quickly and\ncomprehensively map a read set, that had been previously mapped to one\nreference genome, to another similar reference. Users can then quickly run a\ndownstream analysis of read sets for each latest reference release. Compared to\nthe state-of-the-art method for remapping reads (i.e., full mapping), AirLift\nreduces the overall execution time to remap read sets between two reference\ngenome versions by up to 27.4x. We validate our remapping results with GATK and\nfind that AirLift provides high accuracy in identifying ground truth SNP/INDEL\nvariants\n  AirLift source code and readme describing how to reproduce our results are\navailable at https://github.com/CMU-SAFARI/AirLift.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.08735v5"
    },
    {
        "title": "A Robust and Precise ConvNet for small non-coding RNA classification\n  (RPC-snRC)",
        "authors": [
            "Muhammad Nabeel Asima",
            "Muhammad Imran Malik",
            "Andreas Dengela",
            "Sheraz Ahmed"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Functional or non-coding RNAs are attracting more attention as they are now\npotentially considered valuable resources in the development of new drugs\nintended to cure several human diseases. The identification of drugs targeting\nthe regulatory circuits of functional RNAs depends on knowing its family, a\ntask which is known as RNA sequence classification. State-of-the-art small\nnoncoding RNA classification methodologies take secondary structural features\nas input. However, in such classification, feature extraction approaches only\ntake global characteristics into account and completely oversight co-relative\neffect of local structures. Furthermore secondary structure based approaches\nincorporate high dimensional feature space which proves computationally\nexpensive. This paper proposes a novel Robust and Precise ConvNet (RPC-snRC)\nmethodology which classifies small non-coding RNAs sequences into their\nrelevant families by utilizing the primary sequence of RNAs. RPC-snRC\nmethodology learns hierarchical representation of features by utilizing\npositioning and occurrences information of nucleotides. To avoid exploding and\nvanishing gradient problems, we use an approach similar to DenseNet in which\ngradient can flow straight from subsequent layers to previous layers. In order\nto assess the effectiveness of deeper architectures for small non-coding RNA\nclassification, we also adapted two ResNet architectures having different\nnumber of layers. Experimental results on a benchmark small non-coding RNA\ndataset show that our proposed methodology does not only outperform existing\nsmall non-coding RNA classification approaches with a significant performance\nmargin of 10% but it also outshines adapted ResNet architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.11356v1"
    },
    {
        "title": "Transform-Domain Classification of Human Cells based on DNA Methylation\n  Datasets",
        "authors": [
            "Xueyuan Zhao",
            "Dario Pompili"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  A novel method to classify human cells is presented in this work based on the\ntransform-domain method on DNA methylation data. DNA methylation profile\nvariations are observed in human cells with the progression of disease stages,\nand the proposal is based on this DNA methylation variation to classify normal\nand disease cells including cancer cells. The cancer cell types investigated in\nthis work cover hepatocellular (sample size n = 40), colorectal (n = 44), lung\n(n = 70) and endometrial (n = 87) cancer cells. A new pipeline is proposed\nintegrating the DNA methylation intensity measurements on all the CpG islands\nby the transformation of Walsh-Hadamard Transform (WHT). The study reveals the\nthree-step properties of the DNA methylation transform-domain data and the step\nvalues of association with the cell status. Further assessments have been\ncarried out on the proposed machine learning pipeline to perform classification\nof the normal and cancer tissue cells. A number of machine learning classifiers\nare compared for whole sequence and WHT sequence classification based on public\nWhole-Genome Bisulfite Sequencing (WGBS) DNA methylation datasets. The\nWHT-based method can speed up the computation time by more than one order of\nmagnitude compared with whole original sequence classification, while\nmaintaining comparable classification accuracy by the selected machine learning\nclassifiers. The proposed method has broad applications in expedited disease\nand normal human cell classifications by the epigenome and genome datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.13167v1"
    },
    {
        "title": "A guided network propagation approach to identify disease genes that\n  combines prior and new information",
        "authors": [
            "Borislav H. Hristov",
            "Bernard Chazelle",
            "Mona Singh"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  A major challenge in biomedical data science is to identify the causal genes\nunderlying complex genetic diseases. Despite the massive influx of genome\nsequencing data, identifying disease-relevant genes remains difficult as\nindividuals with the same disease may share very few, if any, genetic variants.\nProtein-protein interaction networks provide a means to tackle this\nheterogeneity, as genes causing the same disease tend to be proximal within\nnetworks. Previously, network propagation approaches have spread signal across\nthe network from either known disease genes or genes that are newly putatively\nimplicated in the disease (e.g., found to be mutated in exome studies or linked\nvia genome-wide association studies). Here we introduce a general framework\nthat considers both sources of data within a network context. Specifically, we\nuse prior knowledge of disease-associated genes to guide random walks initiated\nfrom genes that are newly identified as perhaps disease-relevant. In\nlarge-scale testing across 24 cancer types, we demonstrate that our approach\nfor integrating both prior and new information not only better identifies\ncancer driver genes than using either source of information alone but also\nreadily outperforms other state-of-the-art network-based approaches. To\ndemonstrate the versatility of our approach, we also apply it to genome-wide\nassociation data to identify genes functionally relevant for several complex\ndiseases. Overall, our work suggests that guided network propagation approaches\nthat utilize both prior and new data are a powerful means to identify disease\ngenes.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.06135v1"
    },
    {
        "title": "Finer Metagenomic Reconstruction via Biodiversity Optimization",
        "authors": [
            "Simon Foucart",
            "David Koslicki"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  When analyzing communities of microorganisms from their sequenced DNA, an\nimportant task is taxonomic profiling: enumerating the presence and relative\nabundance of all organisms, or merely of all taxa, contained in the sample.\nThis task can be tackled via compressive-sensing-based approaches, which favor\ncommunities featuring the fewest organisms among those consistent with the\nobserved DNA data. Despite their successes, these parsimonious approaches\nsometimes conflict with biological realism by overlooking organism\nsimilarities. Here, we leverage a recently developed notion of biological\ndiversity that simultaneously accounts for organism similarities and retains\nthe optimization strategy underlying compressive-sensing-based approaches. We\ndemonstrate that minimizing biological diversity still produces sparse\ntaxonomic profiles and we experimentally validate superiority to existing\ncompressive-sensing-based approaches. Despite showing that the objective\nfunction is almost never convex and often concave, generally yielding NP-hard\nproblems, we exhibit ways of representing organism similarities for which\nminimizing diversity can be performed via a sequence of linear programs\nguaranteed to decrease diversity. Better yet, when biological similarity is\nquantified by $k$-mer co-occurrence (a popular notion in bioinformatics),\nminimizing diversity actually reduces to one linear program that can utilize\nmultiple $k$-mer sizes to enhance performance. In proof-of-concept experiments,\nwe verify that the latter procedure can lead to significant gains when\ntaxonomically profiling a metagenomic sample, both in terms of reconstruction\naccuracy and computational performance. Reproducible code is available at\nhttps://github.com/dkoslicki/MinimizeBiologicalDiversity.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.08717v1"
    },
    {
        "title": "Computational modelling in single-cell cancer genomics: methods and\n  future directions",
        "authors": [
            "Allen W Zhang",
            "Kieran R Campbell"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Single-cell technologies have revolutionized biomedical research by enabling\nscalable measurement of the genome, transcriptome, and proteome of multiple\nsystems at single-cell resolution. Now widely applied to cancer models, these\nassays offer new insights into tumour heterogeneity, which underlies cancer\ninitiation, progression, and relapse. However, the large quantities of\nhigh-dimensional, noisy data produced by single-cell assays can complicate data\nanalysis, obscuring biological signals with technical artefacts. In this review\narticle, we outline the major challenges in analyzing single-cell cancer\ngenomics data and survey the current computational tools available to tackle\nthese. We further outline unsolved problems that we consider major\nopportunities for future methods development to help interpret the vast\nquantities of data being generated.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01549v1"
    },
    {
        "title": "Cell Type Identification from Single-Cell Transcriptomic Data via\n  Semi-supervised Learning",
        "authors": [
            "Xishuang Dong",
            "Shanta Chowdhury",
            "Uboho Victor",
            "Xiangfang Li",
            "Lijun Qian"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Cell type identification from single-cell transcriptomic data is a common\ngoal of single-cell RNA sequencing (scRNAseq) data analysis. Neural networks\nhave been employed to identify cell types from scRNAseq data with high\nperformance. However, it requires a large mount of individual cells with\naccurate and unbiased annotated types to build the identification models.\nUnfortunately, labeling the scRNAseq data is cumbersome and time-consuming as\nit involves manual inspection of marker genes. To overcome this challenge, we\npropose a semi-supervised learning model to use unlabeled scRNAseq cells and\nlimited amount of labeled scRNAseq cells to implement cell identification.\nFirstly, we transform the scRNAseq cells to \"gene sentences\", which is inspired\nby similarities between natural language system and gene system. Then genes in\nthese sentences are represented as gene embeddings to reduce data sparsity.\nWith these embeddings, we implement a semi-supervised learning model based on\nrecurrent convolutional neural networks (RCNN), which includes a shared\nnetwork, a supervised network and an unsupervised network. The proposed model\nis evaluated on macosko2015, a large scale single-cell transcriptomic dataset\nwith ground truth of individual cell types. It is observed that the proposed\nmodel is able to achieve encouraging performance by learning on very limited\namount of labeled scRNAseq cells together with a large number of unlabeled\nscRNAseq cells.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.03994v1"
    },
    {
        "title": "Degradation of 2-mercaptobenzothizaole in microbial electrolysis cells:\n  intermediates, toxicity, and microbial communities",
        "authors": [
            "M. Isabel San-Martin",
            "Adrian Escapaa",
            "Raul M. Alonso",
            "Moises Canle",
            "Antonio Moran"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The compound 2-mercaptobenzothizaole (MBT) has been frequently detected in\nwastewater and surface water and is a potential threat to both aquatic\norganisms and human health (its mutagenic potential has been demonstrated).\nThis study investigated the degradation routes of MBT in the anode of a\nmicrobial electrolysis cell (MEC) and the involved microbial communities. The\nresults indicated that graphene-modified anodes promoted the presence of more\nenriched, developed, and specific communities compared to bare anodes.\nMoreover, consecutive additions of the OH substituent to the benzene ring of\nMBT were only detected in the reactor equipped with the graphene-treated\nelectrode. Both phenomena, together with the application of an external\nvoltage, may be related to the larger reduction of biotoxicity observed in the\nMEC equipped with graphene-modified anodes (46.2 eqtox/m3 to 27.9 eqtox/m3).\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06336v1"
    },
    {
        "title": "Merging 1D and 3D genomic information: Challenges in modelling and\n  validation",
        "authors": [
            "Alessandra Merlotti",
            "Angelo Rosa",
            "Daniel Remondini"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genome organization in eukaryotes during interphase stems from the delicate\nbalance between non-random correlations present in the DNA polynucleotide\nlinear sequence and the physico/chemical reactions which shape continuously the\nform and structure of DNA and chromatin inside the nucleus of the cell. It is\nnow clear that these mechanisms have a key role in important processes like\ngene regulation, yet the detailed ways they act simultaneously and, eventually,\ncome to influence each other even across very different length-scales remain\nlargely unexplored. In this paper, we recapitulate some of the main results\nconcerning gene regulatory and physical mechanisms, in relation to the\ninformation encoded in the 1D sequence and the 3D folding structure of DNA. In\nparticular, we stress how reciprocal crossfeeding between 1D and 3D models may\nprovide original insight into how these complex processes work and influence\neach other.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06755v1"
    },
    {
        "title": "Exploring nervous system transcriptomes during embryogenesis and\n  metamorphosis in Xenopus tropicalis using EST analysis",
        "authors": [
            "Ana C Fierro",
            "Raphaël Thuret",
            "Laurent Coen",
            "Muriel Perron",
            "Barbara A Demeneix",
            "Maurice Wegnez",
            "Gabor Gyapay",
            "Jean Weissenbach",
            "Patrick Wincker",
            "André Mazabraud",
            "Nicolas Pollet"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Xenopus tropicalis is an anuran amphibian species used as model in vertebrate\ncomparative genomics. It provides the same advantages as Xenopus laevis but is\ndiploid and has a smaller genome of 1.7 Gbp. Therefore X. tropicalis is more\namenable to systematic transcriptome surveys. We initiated a large-scale\npartial cDNA sequencing project to provide a functional genomics resource on\ngenes expressed in the nervous system during early embryogenesis and\nmetamorphosis in X. tropicalis. A gene index was defined and analysed after the\ncollection of over 48,785 high quality sequences. Partial cDNA sequences were\nobtained from an embryonic head and retina library (30,272 sequences) and from\na metamorphic brain and spinal cord library (27,602 sequences). These ESTs are\nestimated to represent 9,693 transcripts derived from an estimated 6,000 genes.\nAn estimated 46% of these cDNA sequences contain their start codon. Further\nannotation included Gene Ontology functional classification, InterPro domain\nanalysis, alternative splicing and non-coding RNA identification. Gene\nexpression profiles were derived from EST counts and used to define transcripts\nspecific to metamorphic stages of development. Moreover, these ESTs allowed\nidentification of a set of 225 polymorphic microsatellites that can be used as\ngenetic markers. These cDNA sequences permit in silico cloning of numerous\ngenes and will facilitate studies aimed at deciphering the roles of cognate\ngenes expressed in the nervous system during neural development and\nmetamorphosis. The genomic resources developed to study X. tropicalis biology\nwill accelerate exploration of amphibian physiology and genetics.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.0567v1"
    },
    {
        "title": "Identifying differentially expressed transcripts from RNA-seq data with\n  biological variation",
        "authors": [
            "Peter Glaus",
            "Antti Honkela",
            "Magnus Rattray"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Motivation: High-throughput sequencing enables expression analysis at the\nlevel of individual transcripts. The analysis of transcriptome expression\nlevels and differential expression estimation requires a probabilistic approach\nto properly account for ambiguity caused by shared exons and finite read\nsampling as well as the intrinsic biological variance of transcript expression.\n  Results: We present BitSeq (Bayesian Inference of Transcripts from Sequencing\ndata), a Bayesian approach for estimation of transcript expression level from\nRNA-seq experiments. Inferred relative expression is represented by Markov\nchain Monte Carlo (MCMC) samples from the posterior probability distribution of\na generative model of the read data. We propose a novel method for differential\nexpression analysis across replicates which propagates uncertainty from the\nsample-level model while modelling biological variance using an\nexpression-level-dependent prior. We demonstrate the advantages of our method\nusing simulated data as well as an RNA-seq dataset with technical and\nbiological replication for both studied conditions.\n  Availability: The implementation of the transcriptome expression estimation\nand differential expression analysis, BitSeq, has been written in C++.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0863v2"
    },
    {
        "title": "Slow evolution of vertebrates with large genomes",
        "authors": [
            "Bianca Sclavi",
            "John Herrick"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Darwin introduced the concept of the \"living fossil\" to describe species\nbelonging to lineages that have experienced little evolutionary change, and\nsuggested that species in more slowly evolving lineages are more prone to\nextinction (1). Recent studies revealed that some living fossils such as the\nlungfish are indeed evolving more slowly than other vertebrates (2, 3). The\nreason for the slower rate of evolution in these lineages remains unclear, but\nthe same observations suggest a possible genome size effect on rates of\nevolution. Genome size (C-value) in vertebrates varies over 200 fold ranging\nfrom pufferfish (0.4 pg) to lungfish (132.8 pg) (4). Variation in genome size\nand architecture is a fundamental cellular adaptation that remains poorly\nunderstood (5). C-value is correlated with several allometric traits such as\nbody size and developmental rates in many, but not all, organisms (6, 7). To\ndate, no consensus exists concerning the mechanisms driving genome size\nevolution or the effect that genome size has on species traits such as\nevolutionary rates (8-12). In the following we show that: 1) within the same\nrange of divergence times, genetic diversity decreases as genome size increases\nand 2) average rates of molecular evolution decline with increasing genome size\nin vertebrates. Together, these observations indicate that genome size is an\nimportant factor influencing rates of speciation and extinction.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.2214v2"
    },
    {
        "title": "New alphabet-dependent morphological transition in a random RNA\n  alignment",
        "authors": [
            "O. V. Valba",
            "M. V. Tamm",
            "S. K. Nechaev"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  We study the fraction $f$ of nucleotides involved in the formation of a\ncactus--like secondary structure of random heteropolymer RNA--like molecules.\nIn the low--temperature limit we study this fraction as a function of the\nnumber $c$ of different nucleotide species. We show, that with changing $c$,\nthe secondary structures of random RNAs undergo a morphological transition:\n$f(c)\\to 1$ for $c \\le c_{\\rm cr}$ as the chain length $n$ goes to infinity,\nsignaling the formation of a virtually \"perfect\" gapless secondary structure;\nwhile $f(c)<1$ for $c>c_{\\rm cr}$, what means that a non-perfect structure with\ngaps is formed. The strict upper and lower bounds $2 \\le c_{\\rm cr} \\le 4$ are\nproven, and the numerical evidence for $c_{\\rm cr}$ is presented. The relevance\nof the transition from the evolutional point of view is discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.5410v3"
    },
    {
        "title": "Transposable element sequence evolution is influenced by gene context",
        "authors": [
            "Anna-Sophie Fiston-Lavier",
            "Charles E. Vejnar",
            "Hadi Quesneville"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Background: Transposable elements (TEs) in eukaryote genomes are\nquantitatively the main components affecting genome size, structure and\nexpression. The dynamics of their insertion and deletion depend on diverse\nfactors varying in strength and nature along the genome. We address here how TE\nsequence evolution is affected by neighboring genes and the chromatin status\n(euchromatin or heterochromatin) at their insertion site. Results: We estimated\nages of TE sequences in Arabidopsis thaliana, and found that they depend on the\ndistance to the nearest genes: TEs located close to genes are older than those\nthat are more distant. Consequently, TE sequences in heterochromatic regions,\nwhich are gene-poor regions, are surprisingly younger and longer than that\nelsewhere. Conclusions: We provide evidence for biased TE age distribution\nclose or near to genes. Interestingly, TE sequences in euchromatin and those in\nheterochromatin evolve at different rates, and as a result, could explain that\nTE sequences in heterochromatin tend to be younger and longer. Then, we revisit\nmodels of TE sequence dynamics and point out differences for TE-rich genomes,\nsuch as maize and wheat, compared to TE-poor genomes such as fly and A.\nthaliana.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.0176v2"
    },
    {
        "title": "Balancing noise and plasticity in eukaryotic gene expression",
        "authors": [
            "Djordje Bajić",
            "Juan F. Poyatos"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Coupling the control of expression stochasticity (noise) to the ability of\nexpression change (plasticity) can alter gene function and influence\nadaptation. A number of factors, such as transcription re-initiation, strong\nchromatin regulation or genome neighboring organization, underlie this\ncoupling. However, these factors do not necessarily combine in equivalent ways\nand strengths in all genes. Can we identify then alternative architectures that\nmodulate in distinct ways the linkage of noise and plasticity? Here we first\nshow that strong chromatin regulation, commonly viewed as a source of coupling,\ncan lead to plasticity without noise. The nature of this regulation is relevant\ntoo, with plastic but noiseless genes being subjected to general activators\nwhereas plastic and noisy genes experience more specific repression.\nContrarily, in genes exhibiting poor transcriptional control, it is\ntranslational efficiency what separates noise from plasticity, a pattern\nrelated to transcript length. This additionally implies that genome neighboring\norganization -as modifier- appears only effective in highly plastic genes. In\nthis class, we confirm bidirectional promoters (bipromoters) as a configuration\ncapable to reduce coupling by abating noise but also reveal an important\ntrade-off, since bipromoters also decrease plasticity. This presents ultimately\na paradox between intergenic distances and modulation, with short intergenic\ndistances both associated and disassociated to noise at different plasticity\nlevels. Balancing the coupling among different types of expression variability\nappears as a potential shaping force of genome regulation and organization.\nThis is reflected in the use of different control strategies at genes with\ndifferent sets of functional constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2278v1"
    },
    {
        "title": "Analysis of central Hox protein types across bilaterian clades: On the\n  origin of central Hox proteins from an Antennapedia/Hox7-like ancestor",
        "authors": [
            "Stefanie D. Hueber",
            "Michael A. Djordjevic",
            "Helen Gunter",
            "Jens Rauch",
            "Georg F. Weiller",
            "Tancred Frickey"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Hox proteins are one of the best studied sets of transcription factors in\ndevelopmental biology. They are major determinants for establishing\nmorphological differences along the anterior-posterior axis of animals and are\ngenerally regarded as highly conserved in function. This view is based on\nexperiments comparing a few (anterior) Hox proteins, however, the extent to\nwhich central or abdominal Hox proteins share sequence features or functions\nremains largely unexplored. To shed light on the origin and functional\ndivergence of the central Hox proteins, we combine a powerful bioinformatics\ntool (CLANS) with a large-scale phylogeny of species. CLANS is used to\ndifferentiate between the various types of central Hox protein sequences, while\nthe phylogeny provides an evolutionary context to the analysis. The combination\nof both enables us to infer the relative timepoint at which a given central Hox\nprotein type arose. We identify seven distinct central Hox protein sequence\ntypes, only one of which is common to all protostome and deuterostome clades\n(Antp/Hox7). Together, these results lead us to suggest reevaluating the\nusefulness of the increasingly depicted synteny-based classification scheme\nthat assumes a one-to-one orthology between protostome and deuterostome central\nHox proteins. Instead, we propose that the use of sequence-based classification\nschemes able to resolve the central and posterior Hox proteins provides a more\npromising and biologically meaningful alternative to resolving these groups.\nThis analysis, which provides a unique overview of the Hox protein sequence\ntypes present across protostomes and deuterostomes as well as a relative dating\nfor the emergence of the central Hox protein types, provides a crucial clue to\nilluminate how and when the distinct developmental blueprints for organisms\nevolved within the evolutionarily immensely successful bilaterian lineage.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2529v1"
    },
    {
        "title": "Methods for scoring the collective effect of SNPs: Minor alleles of\n  common SNPs quantitatively affect traits/diseases and are under both positive\n  and negative selection",
        "authors": [
            "Dejian Yuan",
            "Zuobin Zhu",
            "Xiaohua Tan",
            "Jie Liang",
            "Ceng Zeng",
            "Jiegen Zhang",
            "Jun Chen",
            "Long Ma",
            "Ayca Dogan",
            "Gudrun Brockmann",
            "Oliver Goldmann",
            "Eva Medina",
            "Amanda D. Rice",
            "Richard W. Moyer",
            "Xian Man",
            "Ke Yi",
            "Yanke Li",
            "Qing Lu",
            "Yimin Huang",
            "Dapeng Wang",
            "Jun Yu",
            "Hui Guo",
            "Kun Xia",
            "Shi Huang"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Most common SNPs are popularly assumed to be neutral. We here developed novel\nmethods to examine in animal models and humans whether extreme amount of minor\nalleles (MAs) carried by an individual may represent extreme trait values and\ncommon diseases. We analyzed panels of genetic reference populations and\nidentified the MAs in each panel and the MA content (MAC) that each strain\ncarried. We also analyzed 21 published GWAS datasets of human diseases and\nidentified the MAC of each case or control. MAC was nearly linearly linked to\nquantitative variations in numerous traits in model organisms, including life\nspan, tumor susceptibility, learning and memory, sensitivity to alcohol and\nanti-psychotic drugs, and two correlated traits poor reproductive fitness and\nstrong immunity. Similarly, in Europeans or European Americans, enrichment of\nMAs of fast but not slow evolutionary rate was linked to autoimmune and\nnumerous other diseases, including type 2 diabetes, Parkinson's disease,\npsychiatric disorders, alcohol and cocaine addictions, cancer, and less life\nspan. Therefore, both high and low MAC correlated with extreme values in many\ntraits, indicating stabilizing selection on most MAs. The methods here are\nbroadly applicable and may help solve the missing heritability problem in\ncomplex traits and diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2911v2"
    },
    {
        "title": "Chimeric protein complexes in hybrid species generate novel evolutionary\n  phenotypes",
        "authors": [
            "Elzbieta M. Piatkowska",
            "David Knight",
            "Daniela Delneri"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Hybridization between species is an important mechanism for the origin of\nnovel lineages and adaptation to new environments. Increased allelic variation\nand modification of the transcriptional network are the two recognized forces\ncurrently deemed to be responsible for the phenotypic properties seen in\nhybrids. However, since the majority of the biological functions in a cell are\ncarried out by protein complexes, inter-specific protein assemblies therefore\nrepresent another important source of natural variation upon which evolutionary\nforces can act. Here we studied the composition of six protein complexes in two\ndifferent Saccharomyces \"sensu strictu\" hybrids, to understand whether chimeric\ninteractions can be freely formed in the cell in spite of species-specific\nco-evolutionary forces, and whether the different types of complexes cause a\nchange in hybrid fitness. The protein assemblies were isolated from the hybrids\nvia affinity chromatography and identified via mass spectrometry. We found\nevidence of spontaneous chimericity for four of the six protein assemblies\ntested and we showed that different types of complexes can cause a variety of\nphenotypes in selected environments. In the case of TRP2/TRP3 complex, the\neffect of such chimeric formation resulted in the fitness advantage of the\nhybrid in an environment lacking tryptophan, while only one type of parental\ncombination of the MBF complex could confer viability to the hybrid under\nrespiratory conditions. This study provides empirical evidence that chimeric\nprotein complexes can freely assemble in cells and reveals a new mechanism to\ngenerate phenotypic novelty and plasticity in hybrids to complement the genomic\ninnovation resulting from gene duplication. The ability to exchange orthologous\nmembers has also important implications for the adaptation and subsequent\ngenome evolution of the hybrids in terms of pattern of gene loss.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.4254v1"
    },
    {
        "title": "repgenHMM: a dynamic programming tool to infer the rules of immune\n  receptor generation from sequence data",
        "authors": [
            "Yuval Elhanati",
            "Quentin Marcou",
            "Thierry Mora",
            "Aleksandra M. Walczak"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The diversity of the immune repertoire is initially generated by random\nrearrangements of the receptor gene during early T and B cell development.\nRearrangement scenarios are composed of random events -- choices of gene\ntemplates, base pair deletions and insertions -- described by probability\ndistributions. Not all scenarios are equally likely, and the same receptor\nsequence may be obtained in several different ways. Quantifying the\ndistribution of these rearrangements is an essential baseline for studying the\nimmune system diversity. Inferring the properties of the distributions from\nreceptor sequences is a computationally hard problem, requiring enumerating\nevery possible scenario for every sampled receptor sequence. We present a\nHidden Markov model, which accounts for all plausible scenarios that can\ngenerate the receptor sequences. We developed and implemented a method based on\nthe Baum-Welch algorithm that can efficiently infer the parameters for the\ndifferent events of the rearrangement process. We tested our software tool on\nsequence data for both the alpha and beta chains of the T cell receptor. To\ntest the validity of our algorithm, we also generated synthetic sequences\nproduced by a known model, and confirmed that its parameters could be\naccurately inferred back from the sequences. The inferred model can be used to\ngenerate synthetic sequences, to calculate the probability of generation of any\nreceptor sequence, as well as the theoretical diversity of the repertoire. We\nestimate this diversity to be $\\approx 10^{23}$ for human T cells. The model\ngives a baseline to investigate the selection and dynamics of immune\nrepertoires.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.00107v1"
    },
    {
        "title": "Negative selection maintains transcription factor binding motifs in\n  human cancer",
        "authors": [
            "I. E. Vorontsov",
            "I. V. Kulakovskiy",
            "G. Khimulya",
            "E. N. Lukianova",
            "D. D. Nikolaeva",
            "I. A. Eliseeva",
            "V. J. Makeev"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Somatic mutations in cancer cells affect various genomic elements disrupting\nimportant cell functions. In particular, mutations in DNA binding sites\nrecognized by transcription factors can alter regulator binding affinities and\nexpression of target genes. A number of promoter mutations have been linked\nwith an increased risk of cancer, mutations in binding sites of selected\ntranscription factors have been found under positive selection. However,\nnegative selection of mutations in coding regions is elusive and significance\nof negative selection in non-coding regions remains controversial.\n  Here we present analysis of transcription factors with binding sites\nco-localized with non-coding variants. To avoid statistical bias we account for\nmutation signatures of different cancer types. For many transcription factors,\nincluding multiple members of FOX, HOX, and NR families, we show that human\ncancers accumulate fewer mutations than expected by chance that increase or\ndecrease affinity of binding motifs. Such conservation of motifs is even more\nexhibited in DNase accessible regions.\n  Our data demonstrate negative selection against binding sites alterations and\nsuggest that this selection pressure protects cancer cells from rewiring of\nregulatory circuits. Further analysis of transcription factors and the\nrespective conserved binding motifs can reveal cell regulatory pathways crucial\nfor the survivability of various human cancers.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.02842v1"
    },
    {
        "title": "Hot RAD: A Tool for Analysis of Next-Gen RAD Tag Data",
        "authors": [
            "Lauren A. Assour",
            "Nicholas LaRosa",
            "Scott J. Emrich"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Restriction site Associated DNA (RAD) tagging (also known as RAD-seq, etc.)\nis an emerging method for analyzing an organism's genome without completely\nsequencing it. This can be applied to a non-model organism without a reference\ngenome, though this creates the problem of how to begin data analysis on\nunmapped and unannotated reads. Our program, Hot RAD, presents a\nstraightforward and easy-to-use method to take raw Illumina data that has been\nRAD tagged and produce consensus contigs or sequence stacks using a distributed\nframework, creating a basis on which to begin analyzing an organism's DNA. The\nGUI (graphical user interface) element of our tool makes it easy for those not\nfamiliar with the command line to take raw sequence files and produce usable\ndata in a timely manner.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.06754v1"
    },
    {
        "title": "Commet: comparing and combining multiple metagenomic datasets",
        "authors": [
            "Maillet Nicolas",
            "Collet Guillaume",
            "Vanier Thomas",
            "Lavenier Dominique",
            "Pierre Peterlongo"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Metagenomics offers a way to analyze biotopes at the genomic level and to\nreach functional and taxonomical conclusions. The bio-analyzes of large\nmetagenomic projects face critical limitations: complex metagenomes cannot be\nassembled and the taxonomical or functional annotations are much smaller than\nthe real biological diversity. This motivated the development of de novo\nmetagenomic read comparison approaches to extract information contained in\nmetagenomic datasets.\n  However, these new approaches do not scale up large metagenomic projects, or\ngenerate an important number of large intermediate and result files. We\nintroduce Commet (\"COmpare Multiple METagenomes\"), a method that provides\nsimilarity overview between all datasets of large metagenomic projects.\n  Directly from non-assembled reads, all against all comparisons are performed\nthrough an efficient indexing strategy. Then, results are stored as bit\nvectors, a compressed representation of read files, that can be used to further\ncombine read subsets by common logical operations. Finally, Commet computes a\nclusterization of metagenomic datasets, which is visualized by dendrogram and\nheatmaps.\n  Availability: http://github.com/pierrepeterlongo/commet\n",
        "pdf_link": "http://arxiv.org/pdf/1511.08317v1"
    },
    {
        "title": "MetaScope - Fast and accurate identification of microbes in metagenomic\n  sequencing data",
        "authors": [
            "Benjamin Buchfink",
            "Daniel H. Huson",
            "Chao Xie"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  MetaScope is a fast and accurate tool for analyzing (host-associated)\nmetagenome datasets. Sequence alignment of reads against the host genome (if\nrequested) and against microbial Genbank is performed using a new DNA aligner\ncalled SASS. The output of SASS is processed so as to assign all microbial\nreads to taxa and genes, using a new weighted version of the LCA algorithm.\nMetaScope is the winner of the 2013 DTRA software challenge entitled \"Identify\nOrganisms from a Stream of DNA Sequences\".\n",
        "pdf_link": "http://arxiv.org/pdf/1511.08753v1"
    },
    {
        "title": "Testing for differential abundance in compositional counts data, with\n  application to microbiome studies",
        "authors": [
            "Barak Brill",
            "Amnon Amir",
            "Ruth Heller"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Identifying which taxa in our microbiota are associated with traits of\ninterest is important for advancing science and health. However, the\nidentification is challenging because the measured vector of taxa counts (by\namplicon sequencing) is compositional, so a change in the abundance of one\ntaxon in the microbiota induces a change in the number of sequenced counts\nacross all taxa. The data is typically sparse, with zero counts present either\ndue to biological variance or limited sequencing depth (technical zeros). For\nlow abundance taxa, the chance for technical zeros is non-negligible. We show\nthat existing methods designed to identify differential abundance for\ncompositional data may have an inflated number of false positives due to\nimproper handling of the zero counts. We introduce a novel non-parametric\napproach which provides valid inference even when the fraction of zero counts\nis substantial. Our approach uses a set of reference taxa that are\nnon-differentially abundant, which can be estimated from the data or from\noutside information. We show the usefulness of our approach via simulations, as\nwell as on three different data sets: a Crohn's disease study, the Human\nMicrobiome Project, and an experiment with 'spiked-in' bacteria.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.08937v5"
    },
    {
        "title": "MinCall - MinION end2end convolutional deep learning basecaller",
        "authors": [
            "Neven Miculinić",
            "Marko Ratković",
            "Mile Šikić"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The Oxford Nanopore Technologies's MinION is the first portable DNA\nsequencing device. It is capable of producing long reads, over 100 kBp were\nreported. However, it has significantly higher error rate than other methods.\nIn this study, we present MinCall, an end2end basecaller model for the MinION.\nThe model is based on deep learning and uses convolutional neural networks\n(CNN) in its implementation. For extra performance, it uses cutting edge deep\nlearning techniques and architectures, batch normalization and Connectionist\nTemporal Classification (CTC) loss. The best performing deep learning model\nachieves 91.4% median match rate on E. Coli dataset using R9 pore chemistry and\n1D reads.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.10337v1"
    },
    {
        "title": "Generating protein sequences from antibiotic resistance genes data using\n  Generative Adversarial Networks",
        "authors": [
            "Prabal Chhibbar",
            "Arpit Joshi"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  We introduce a method to generate synthetic protein sequences which are\npredicted to be resistant to certain antibiotics. We did this using 6,023 genes\nthat were predicted to be resistant to antibiotics in the intestinal region of\nthe human gut and were fed as input to a Wasserstein generative adversarial\nnetwork (W-GAN) model a variant to the original generative adversarial model\nwhich has been known to perform efficiently when it comes to mimicking the\ndistribution of the real data in order to generate new data which is similar in\nstyle to the original data which was fed as the training data\n",
        "pdf_link": "http://arxiv.org/pdf/1904.13240v1"
    },
    {
        "title": "A community-based transcriptomics classification and nomenclature of\n  neocortical cell types",
        "authors": [
            "Rafael Yuste",
            "Michael Hawrylycz",
            "Nadia Aalling",
            "Detlev Arendt",
            "Ruben Armananzas",
            "Giorgio Ascoli",
            "Concha Bielza",
            "Vahid Bokharaie",
            "Tobias Bergmann",
            "Irina Bystron",
            "Marco Capogna",
            "Yoonjeung Chang",
            "Ann Clemens",
            "Christiaan de Kock",
            "Javier DeFelipe",
            "Sandra Dos Santos",
            "Keagan Dunville",
            "Dirk Feldmeyer",
            "Richard Fiath",
            "Gordon Fishell",
            "Angelica Foggetti",
            "Xuefan Gao",
            "Parviz Ghaderi",
            "Onur Gunturkun",
            "Vanessa Jane Hall",
            "Moritz Helmstaedter",
            "Suzana Herculano-Houzel",
            "Markus Hilscher",
            "Hajime Hirase",
            "Jens Hjerling-Leffler",
            "Rebecca Hodge",
            "Z. Josh Huang",
            "Rafiq Huda",
            "Yuan Juan",
            "Konstantin Khodosevich",
            "Ole Kiehn",
            "Henner Koch",
            "Eric Kuebler",
            "Malte Kuhnemund",
            "Pedro Larranaga",
            "Boudewijn Lelieveldt",
            "Emma Louise Louth",
            "Jan Lui",
            "Huibert Mansvelder",
            "Oscar Marin",
            "Julio Martínez-Trujillo",
            "Homeira Moradi",
            "Natalia Goriounova",
            "Alok Mohapatra",
            "Maiken Nedergaard",
            "Pavel Němec",
            "Netanel Ofer",
            "Ulrich Pfisterer",
            "Samuel Pontes",
            "William Redmond",
            "Jean Rossier",
            "Joshua Sanes",
            "Richard Scheuermann",
            "Esther Serrano Saiz",
            "Peter Somogyi",
            "Gábor Tamás",
            "Andreas Tolias",
            "Maria Tosches",
            "Miguel Turrero Garcia",
            "Argel Aguilar-Valles",
            "Hermany Munguba",
            "Christian Wozny",
            "Thomas Wuttke",
            "Liu Yong",
            "Hongkui Zeng",
            "Ed S. Lein"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  To understand the function of cortical circuits it is necessary to classify\ntheir underlying cellular diversity. Traditional attempts based on comparing\nanatomical or physiological features of neurons and glia, while productive,\nhave not resulted in a unified taxonomy of neural cell types. The recent\ndevelopment of single-cell transcriptomics has enabled, for the first time,\nsystematic high-throughput profiling of large numbers of cortical cells and the\ngeneration of datasets that hold the promise of being complete, accurate and\npermanent. Statistical analyses of these data have revealed the existence of\nclear clusters, many of which correspond to cell types defined by traditional\ncriteria, and which are conserved across cortical areas and species. To\ncapitalize on these innovations and advance the field, we, the Copenhagen\nConvention Group, propose the community adopts a transcriptome-based taxonomy\nof the cell types in the adult mammalian neocortex. This core classification\nshould be ontological, hierarchical and use a standardized nomenclature. It\nshould be configured to flexibly incorporate new data from multiple approaches,\ndevelopmental stages and a growing number of species, enabling improvement and\nrevision of the classification. This community-based strategy could serve as a\ncommon foundation for future detailed analysis and reverse engineering of\ncortical circuits and serve as an example for cell type classification in other\nparts of the nervous system and other organs.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.03083v1"
    },
    {
        "title": "Gene ologs: a categorical framework for Gene Ontology",
        "authors": [
            "Yanying Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Gene Ontology (GO) is the most important resource for gene function\nannotation. It provides a way to unify biological knowledge across different\nspecies via a dynamic and controlled vocabulary. GO is now widely represented\nin the Semantic Web standard Web Ontology Language (OWL). OWL renders a rich\nlogic constructs to GO but also has its limitations. On the other hand, olog is\na different language for ontology and it is based on category theory. Due to\nits solid mathematical background, olog can be rigorously formulated yet\nconsiderably expressive. These advantages make ologs complementary, if not\nbetter than, OWL. We therefore think it worthwhile to adopt ologs for GO and\ntook an initial step in this work.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11210v1"
    },
    {
        "title": "Computational prediction of replication sites in DNA sequences using\n  complex number representation",
        "authors": [
            "Shubham Kundal",
            "Raunak Lohiya",
            "Hritik Bansal",
            "Shreya Johri",
            "Varuni Sarwal",
            "Kushal Shah"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Computational prediction of origin of replication (ORI) has been of great\ninterest in bioinformatics and several methods including GC-skew,\nauto-correlation etc. have been explored in the past. In this paper, we have\nextended the auto-correlation method to predict ORI location with much higher\nresolution for prokaryotes and eukaryotes, which can be very helpful in\nexperimental validation of the computational predictions. The proposed complex\ncorrelation method (iCorr) converts the genome sequence into a sequence of\ncomplex numbers by mapping the nucleotides to {+1,-1,+i,-i} instead of {+1,-1}\nused in the auto-correlation method (here, i is square root of -1). Thus, the\niCorr method exploits the complete spatial information about the positions of\nall the four nucleotides unlike the earlier auto-correlation method which uses\nthe positional information of only one nucleotide. Also, the earlier\nauto-correlation method required visual inspection of the obtained graphs to\nidentify the location of origin of replication. The proposed iCorr method does\naway with this need and is able to identify the origin location simply by\npicking the peak in the iCorr graph.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.13751v1"
    },
    {
        "title": "ItLnc-BXE: a Bagging-XGBoost-ensemble method with multiple features for\n  identification of plant lncRNAs",
        "authors": [
            "Guangyan Zhang",
            "Ziru Liu",
            "Jichen Dai",
            "Zilan Yu",
            "Shuai Liu",
            "Wen Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Motivation: Since long non-coding RNAs (lncRNAs) have involved in a wide\nrange of functions in cellular and developmental processes, an increasing\nnumber of methods have been proposed for distinguishing lncRNAs from coding\nRNAs. However, most of the existing methods are designed for lncRNAs in animal\nsystems, and only a few methods focus on the plant lncRNA identification.\nDifferent from lncRNAs in animal systems, plant lncRNAs have distinct\ncharacteristics. It is desirable to develop a computational method for accurate\nand robust identification of plant lncRNAs. Results: Herein, we present a plant\nlncRNA identification method ItLnc-BXE, which utilizes multiple features and\nthe ensemble learning strategy. First, a diversity of lncRNA features is\ncollected and filtered by feature selection to represent RNA transcripts. Then,\nseveral base learners are trained and further combined into a single\nmeta-learner by ensemble learning, and thus an ItLnc-BXE model is constructed.\nItLnc-BXE models are evaluated on datasets of six plant species, the results\nshow that ItLnc-BXE outperforms other state-of-the-art plant lncRNA\nidentification methods, achieving better and robust performances (AUC>95.91%).\nWe also perform some experiments about cross-species lncRNA identification, and\nthe results indicate that dicots-based and monocots-based models can be used to\naccurately identify lncRNAs in lower plant species, such as mosses and algae.\nAvailability: source codes are available at\nhttps://github.com/BioMedicalBigDataMiningLab/ItLnc-BXE. Contact:\nzhangwen@mail.hzau.edu.cn (or) zhangwen@whu.edu.cn Supplementary information:\nSupplementary data are available at Bioinformatics online.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.00185v2"
    },
    {
        "title": "Analysis of Genomic and Transcriptomic Variations as Prognostic\n  Signature for Lung Adenocarcinoma",
        "authors": [
            "Talip Zengin",
            "Tuğba Önal-Süzek"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Lung cancer is the leading cause of the largest number of deaths worldwide\nand lung adenocarcinoma (LUAD) is the most common form of lung cancer. In this\nstudy, we carried out an integrated meta-analysis of the mutations including\nsingle-nucleotide variations (SNVs), the copy number variations (CNVs), RNA-seq\nand clinical data of patients with LUAD downloaded from The Cancer Genome Atlas\n(TCGA). We integrated significant SNV and CNV genes, differentially expressed\ngenes (DEGs) and the DEGs in active subnetworks to construct a prognosis\nsignature. Cox proportional hazards model (LOOCV) with Lasso penalty was used\nto identify the best gene signature among different gene categories. The\npatients in both training and test data were clustered into high-risk and\nlow-risk groups by using risk scores of the patients calculated based on\nselected gene signature. We generated a 12-gene signature (DEPTOR, ZBTB16,\nBCHE, MGLL, MASP2, TNNI2, RAPGEF3, SGK2, MYO1A, CYP24A1, PODXL2, CCNA1) for\noverall survival prediction. The survival time of high-risk and low-risk groups\nwas significantly different. This 12-gene signature could predict prognosis and\nthey are potential predictors for the survival of the patients with LUAD.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.00511v2"
    },
    {
        "title": "Combining human cell line transcriptome analysis and Bayesian inference\n  to build trustworthy machine learning models for prediction of animal\n  toxicity in drug development",
        "authors": [
            "Laura-Jayne Gardiner",
            "Anna Paola Carrieri",
            "Jenny Wilshaw",
            "Stephen Checkley",
            "Edward O Pyzer-Knapp",
            "Ritesh Krishna"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Biomedical data, particularly in the field of genomics, has characteristics\nwhich make it challenging for machine learning applications - it can be sparse,\nhigh dimensional and noisy. Biomedical applications also present challenges to\nmodel selection - whilst powerful, accurate predictions are necessary, they\nalone are not sufficient for a model to be deemed useful. Due to the nature of\nthe predictions, a model must also be trustworthy and transparent, empowering a\npractitioner with confidence that its use is appropriate and reliable. In this\npaper, we propose that this can be achieved through the use of judiciously\nbuilt feature sets coupled with Bayesian models, specifically Gaussian\nprocesses. We apply Gaussian processes to drug discovery, using inexpensive\ntranscriptomic profiles from human cell lines to predict animal kidney and\nliver toxicity after treatment with specific chemical compounds. This approach\nhas the potential to reduce invasive and expensive animal testing during\nclinical trials if in vitro human cell line analysis can accurately predict\nmodel animal phenotypes. We compare results across a range of feature sets and\nmodels, to highlight model importance for medical applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.04374v2"
    },
    {
        "title": "The 3D genome shapes the regulatory code of developmental genes",
        "authors": [
            "Julien Mozziconacci",
            "Mélody Merle",
            "Annick Lesne"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  We revisit the notion of gene regulatory code in embryonic development in the\nlight of recent findings about genome spatial organisation. By analogy with the\ngenetic code, we posit that the concept of code can only be used if the\ncorresponding adaptor can clearly be identified. An adaptor is here defined as\nan intermediary physical entity mediating the correspondence between codewords\nand objects in a gratuitous and evolvable way. In the context of the gene\nregulatory code, the encoded objects are the gene expression levels, while the\nconcentrations of specific transcription factors in the cell nucleus provide\nthe codewords. The notion of code is meaningful in the absence of direct\nphysicochemical relationships between the objects and the codewords, when the\nmediation by an adaptor is required. We propose that a plausible adaptor for\nthis code is the gene domain, that is, the genome segment delimited by\ntopological insulators and comprising the gene and its enhancer regulatory\nsequences. We review recent evidences, based on genome-wide chromosome\nconformation capture experiments, showing that preferential contact domains\nfound in metazoan genomes are the physical traces of gene domains. Accordingly,\ngenome 3D folding plays a direct role in shaping the developmental gene\nregulatory code.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.04779v1"
    },
    {
        "title": "Learning from Data-Rich Problems: A Case Study on Genetic Variant\n  Calling",
        "authors": [
            "Ren Yi",
            "Pi-Chuan Chang",
            "Gunjan Baid",
            "Andrew Carroll"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Next Generation Sequencing can sample the whole genome (WGS) or the 1-2% of\nthe genome that codes for proteins called the whole exome (WES). Machine\nlearning approaches to variant calling achieve high accuracy in WGS data, but\nthe reduced number of training examples causes training with WES data alone to\nachieve lower accuracy. We propose and compare three different data\naugmentation strategies for improving performance on WES data: 1) joint\ntraining with WES and WGS data, 2) warmstarting the WES model from a WGS model,\nand 3) joint training with the sequencing type specified. All three approaches\nshow improved accuracy over a model trained using just WES data, suggesting the\nability of models to generalize insights from the greater WGS data while\nretaining performance on the specialized WES problem. These data augmentation\napproaches may apply to other problem areas in genomics, where several\nspecialized models would each see only a subset of the genome.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05151v2"
    },
    {
        "title": "Random Forest as a Tumour Genetic Marker Extractor",
        "authors": [
            "Raquel Pérez-Arnal",
            "Dario Garcia-Gasulla",
            "David Torrents",
            "Ferran Parés",
            "Ulises Cortés",
            "Jesús Labarta",
            "Eduard Ayguadé"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Finding tumour genetic markers is essential to biomedicine due to their\nrelevance for cancer detection and therapy development. In this paper, we\nexplore a recently released dataset of chromosome rearrangements in 2,586\ncancer patients, where different sorts of alterations have been detected. Using\na Random Forest classifier, we evaluate the relevance of several features (some\ndirectly available in the original data, some engineered by us) related to\nchromosome rearrangements. This evaluation results in a set of potential tumour\ngenetic markers, some of which are validated in the bibliography, while others\nare potentially novel.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.11471v1"
    },
    {
        "title": "A Systematic Review of Mutations Associated with Isoniazid Resistance\n  Points to Lower Diagnostic Sensitivity for Common Mutations and Increased\n  Incidence of Uncommon Mutations in Clinical Strains of Mycobacterium\n  tuberculosis",
        "authors": [
            "Siavash Valafar"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Molecular testing is rapidly becoming integral to the global tuberculosis\n(TB) control effort. Uncommon mechanisms of resistance can escape detection by\nthese platforms and lead to the development of Multi-Drug Resistant (MDR)\nstrains. This article is a systematic review of published articles that\nreported isoniazid (INH) resistance-conferring mutations between September-2013\nand December-2019. The aims were to catalogue mutations associated with INH\nresistance, estimate their global prevalence and co-occurrence, and their\nutility in molecular diagnostics. The genes commonly associated with INH\nresistance, katG, inhA, fabG1, and the intergenic region oxyR-ahpC were\nconsidered in this review. In total, 52 articles were included describing 5,632\nINHR clinical isolates from 31 countries. The three most frequently mutated\nloci continue to be katG315 (4,100), inhA-15 (786), and inhA-8 (105). However,\nthe diagnostic value of inhA-8 is far lower than previously thought, only\nappearing in 25 (0.4%) INHR isolates that lacked a mutation at the first two\nloci. Importantly, of the four katG loci recommended by the previous systematic\nreview for diagnostics, only katG315 was observed in our INHR isolates. This\nindicates continued evolution and regional differences in INH resistance. We\nhave identified 58 loci (common to both systematic reviews) in three genomic\nregions as a reliable basis for molecular diagnostics. We also report 49 new\nloci associated with INH resistance. Including all observed mutations provides\na cumulative sensitivity of 85.1%. The most disconcerting is the remaining\n14.9% of isolates that harbor an unknown mechanism of resistance, will escape\nmolecular detection, and likely convert to MDR-TB, further complicating\ntreatment. Integrating the information cataloged in this and other similar\nstudies into current diagnostic tools is essential for combating the emergence\nof MDR-TB.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.00443v1"
    },
    {
        "title": "A Public Website for the Automated Assessment and Validation of\n  SARS-CoV-2 Diagnostic PCR Assays",
        "authors": [
            "Po-E Li",
            "Adán Myers y Gutiérrez",
            "Karen Davenport",
            "Mark Flynn",
            "Bin Hu",
            "Chien-Chi Lo",
            "Elais Player Jackson",
            "Migun Shakya",
            "Yan Xu",
            "Jason Gans",
            "Patrick S. G. Chain"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Summary: Polymerase chain reaction-based assays are the current gold standard\nfor detecting and diagnosing SARS-CoV-2. However, as SARS-CoV-2 mutates, we\nneed to constantly assess whether existing PCR-based assays will continue to\ndetect all known viral strains. To enable the continuous monitoring of\nSARS-CoV-2 assays, we have developed a web-based assay validation algorithm\nthat checks existing PCR-based assays against the ever-expanding genome\ndatabases for SARS-CoV-2 using both thermodynamic and edit-distance metrics.\nThe assay screening results are displayed as a heatmap, showing the number of\nmismatches between each detection and each SARS-CoV-2 genome sequence. Using a\nmismatch threshold to define detection failure, assay performance is summarized\nwith the true positive rate (recall) to simplify assay comparisons.\nAvailability: https://covid19.edgebioinformatics.org/#/assayValidation.\nContact: Jason Gans (jgans@lanl.gov) and Patrick Chain (pchain@lanl.gov)\n",
        "pdf_link": "http://arxiv.org/pdf/2006.04566v1"
    },
    {
        "title": "Functional modules from variable genes: Leveraging percolation to\n  analyze noisy, high-dimensional data",
        "authors": [
            "Steffen Werner",
            "W Mathijs Rozemuller",
            "Annabel Ebbing",
            "Anna Alemany",
            "Joleen Traets",
            "Jeroen S. van Zon",
            "Alexander van Oudenaarden",
            "Hendrik C. Korswagen",
            "Greg J. Stephens",
            "Thomas S. Shimizu"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  While measurement advances now allow extensive surveys of gene activity\n(large numbers of genes across many samples), interpretation of these data is\noften confounded by noise -- expression counts can differ strongly across\nsamples due to variation of both biological and experimental origin.\nComplimentary to perturbation approaches, we extract functionally related\ngroups of genes by analyzing the standing variation within a sampled\npopulation. To distinguish biologically meaningful patterns from\nuninterpretable noise, we focus on correlated variation and develop a novel\ndensity-based clustering approach that takes advantage of a percolation\ntransition generically arising in random, uncorrelated data. We apply our\napproach to two contrasting RNA sequencing data sets that sample individual\nvariation -- across single cells of fission yeast and whole animals of C.\nelegans worms -- and demonstrate robust applicability and versatility in\nrevealing correlated gene clusters of diverse biological origin, including cell\ncycle phase, development/reproduction, tissue-specific functions, and feeding\nhistory. Our technique exploits generic features of noisy high-dimensional data\nand is applicable, beyond gene expression, to feature-rich data that sample\npopulation-level variability in the presence of noise.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06767v1"
    },
    {
        "title": "SimpleChrome: Encoding of Combinatorial Effects for Predicting Gene\n  Expression",
        "authors": [
            "Wei Cheng",
            "Ghulam Murtaza",
            "Aaron Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Due to recent breakthroughs in state-of-the-art DNA sequencing technology,\ngenomics data sets have become ubiquitous. The emergence of large-scale data\nsets provides great opportunities for better understanding of genomics,\nespecially gene regulation. Although each cell in the human body contains the\nsame set of DNA information, gene expression controls the functions of these\ncells by either turning genes on or off, known as gene expression levels. There\nare two important factors that control the expression level of each gene: (1)\nGene regulation such as histone modifications can directly regulate gene\nexpression. (2) Neighboring genes that are functionally related to or interact\nwith each other that can also affect gene expression level. Previous efforts\nhave tried to address the former using Attention-based model. However,\naddressing the second problem requires the incorporation of all potentially\nrelated gene information into the model. Though modern machine learning and\ndeep learning models have been able to capture gene expression signals when\napplied to moderately sized data, they have struggled to recover the underlying\nsignals of the data due to the nature of the data's higher dimensionality. To\nremedy this issue, we present SimpleChrome, a deep learning model that learns\nthe latent histone modification representations of genes. The features learned\nfrom the model allow us to better understand the combinatorial effects of\ncross-gene interactions and direct gene regulation on the target gene\nexpression. The results of this paper show outstanding improvements on the\npredictive capabilities of downstream models and greatly relaxes the need for a\nlarge data set to learn a robust, generalized neural network. These results\nhave immediate downstream effects in epigenomics research and drug development.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.08671v2"
    },
    {
        "title": "Co-evolution between Codon Usage and Protein-Protein Interaction in\n  Bacteria",
        "authors": [
            "Maddalena Dilucca",
            "Giulio Cimini",
            "Sergio Forcelloni",
            "Andrea Giansanti"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  We study the correlation between the codon usage bias of genetic sequences\nand the network features of protein-protein interaction (PPI) in bacterial\nspecies. We use PCA techniques in the space of codon bias indices to show that\ngenes with similar patterns of codon usage have a significantly higher\nprobability that their encoded proteins are functionally connected and\ninteracting. Importantly, this signal emerges when multiple aspects of codon\nbias are taken into account at the same time. The present study extends our\nprevious observations on E.Coli over a wide set of 34 bacteria. These findings\ncould allow for future investigations on the possible effects of codon bias on\nthe topology of the PPI network, with the aim of improving existing\nbioinformatics methods for predicting protein interactions.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10717v1"
    },
    {
        "title": "OmiEmbed: a unified multi-task deep learning framework for multi-omics\n  data",
        "authors": [
            "Xiaoyu Zhang",
            "Yuting Xing",
            "Kai Sun",
            "Yike Guo"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  High-dimensional omics data contains intrinsic biomedical information that is\ncrucial for personalised medicine. Nevertheless, it is challenging to capture\nthem from the genome-wide data due to the large number of molecular features\nand small number of available samples, which is also called 'the curse of\ndimensionality' in machine learning. To tackle this problem and pave the way\nfor machine learning aided precision medicine, we proposed a unified multi-task\ndeep learning framework named OmiEmbed to capture biomedical information from\nhigh-dimensional omics data with the deep embedding and downstream task\nmodules. The deep embedding module learnt an omics embedding that mapped\nmultiple omics data types into a latent space with lower dimensionality. Based\non the new representation of multi-omics data, different downstream task\nmodules were trained simultaneously and efficiently with the multi-task\nstrategy to predict the comprehensive phenotype profile of each sample.\nOmiEmbed support multiple tasks for omics data including dimensionality\nreduction, tumour type classification, multi-omics integration, demographic and\nclinical feature reconstruction, and survival prediction. The framework\noutperformed other methods on all three types of downstream tasks and achieved\nbetter performance with the multi-task strategy comparing to training them\nindividually. OmiEmbed is a powerful and unified framework that can be widely\nadapted to various application of high-dimensional omics data and has a great\npotential to facilitate more accurate and personalised clinical decision\nmaking.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02669v2"
    },
    {
        "title": "Bacteriophage classification for assembled contigs using Graph\n  Convolutional Network",
        "authors": [
            "Jiayu Shang",
            "Jingzhe Jiang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: Bacteriophages (aka phages), which mainly infect bacteria, play\nkey roles in the biology of microbes. As the most abundant biological entities\non the planet, the number of discovered phages is only the tip of the iceberg.\nRecently, many new phages have been revealed using high throughput sequencing,\nparticularly metagenomic sequencing. Compared to the fast accumulation of\nphage-like sequences, there is a serious lag in taxonomic classification of\nphages. High diversity, abundance, and limited known phages pose great\nchallenges for taxonomic analysis. In particular, alignment-based tools have\ndifficulty in classifying fast accumulating contigs assembled from metagenomic\ndata. Results: In this work, we present a novel semi-supervised learning model,\nnamed PhaGCN, to conduct taxonomic classification for phage contigs. In this\nlearning model, we construct a knowledge graph by combining the DNA sequence\nfeatures learned by convolutional neural network (CNN) and protein sequence\nsimilarity gained from gene-sharing network. Then we apply graph convolutional\nnetwork (GCN) to utilize both the labeled and unlabeled samples in training to\nenhance the learning ability. We tested PhaGCN on both simulated and real\nsequencing data. The results clearly show that our method competes favorably\nagainst available phage classification tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03746v2"
    },
    {
        "title": "Efficient construction of the extended BWT from grammar-compressed DNA\n  sequencing reads",
        "authors": [
            "Diego Diaz-Dominguez annd Gonzalo Navarro"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We present an algorithm for building the extended BWT (eBWT) of a string\ncollection from its grammar-compressed representation. Our technique exploits\nthe string repetitions captured by the grammar to boost the computation of the\neBWT. Thus, the more repetitive the collection is, the lower are the resources\nwe use per input symbol. We rely on a new grammar recently proposed at DCC'21\nwhose nonterminals serve as building blocks for inducing the eBWT. A relevant\napplication for this idea is the construction of self-indexes for analyzing\nsequencing reads -- massive and repetitive string collections of raw genomic\ndata. Self-indexes have become increasingly popular in Bioinformatics as they\ncan encode more information in less space. Our efficient eBWT construction\nopens the door to perform accurate bioinformatic analyses on more massive\nsequence datasets, which are not tractable with current eBWT construction\ntechniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03961v1"
    },
    {
        "title": "Data-driven design of targeted gene panels for estimating immunotherapy\n  biomarkers",
        "authors": [
            "Jacob R. Bradley",
            "Timothy I. Cannings"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We introduce a novel data-driven framework for the design of targeted gene\npanels for estimating exome-wide biomarkers in cancer immunotherapy. Our first\ngoal is to develop a generative model for the profile of mutation across the\nexome, which allows for gene- and variant type-dependent mutation rates. Based\non this model, we then propose a new procedure for estimating biomarkers such\nas tumour mutation burden and tumour indel nurden. Our approach allows the\npractitioner to select a targeted gene panel of a prespecified size, and then\nconstruct an estimator that only depends on the selected genes. Alternatively,\nthe practitioner may apply our method to make predictions based on an existing\ngene panel, or to augment a gene panel to a given size. We demonstrate the\nexcellent performance of our proposal using data from three non-small cell lung\ncancer studies, as well as data from six other cancer types.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.04296v3"
    },
    {
        "title": "Cancer Gene Profiling through Unsupervised Discovery",
        "authors": [
            "Enzo Battistella",
            "Maria Vakalopoulou",
            "Roger Sun",
            "Théo Estienne",
            "Marvin Lerousseau",
            "Sergey Nikolaev",
            "Emilie Alvarez Andres",
            "Alexandre Carré",
            "Stéphane Niyoteka",
            "Charlotte Robert",
            "Nikos Paragios",
            "Eric Deutsch"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Precision medicine is a paradigm shift in healthcare relying heavily on\ngenomics data. However, the complexity of biological interactions, the large\nnumber of genes as well as the lack of comparisons on the analysis of data,\nremain a tremendous bottleneck regarding clinical adoption. In this paper, we\nintroduce a novel, automatic and unsupervised framework to discover\nlow-dimensional gene biomarkers. Our method is based on the LP-Stability\nalgorithm, a high dimensional center-based unsupervised clustering algorithm,\nthat offers modularity as concerns metric functions and scalability, while\nbeing able to automatically determine the best number of clusters. Our\nevaluation includes both mathematical and biological criteria. The recovered\nsignature is applied to a variety of biological tasks, including screening of\nbiological pathways and functions, and characterization relevance on tumor\ntypes and subtypes. Quantitative comparisons among different distance metrics,\ncommonly used clustering methods and a referential gene signature used in the\nliterature, confirm state of the art performance of our approach. In\nparticular, our signature, that is based on 27 genes, reports at least $30$\ntimes better mathematical significance (average Dunn's Index) and 25% better\nbiological significance (average Enrichment in Protein-Protein Interaction)\nthan those produced by other referential clustering methods. Finally, our\nsignature reports promising results on distinguishing immune inflammatory and\nimmune desert tumors, while reporting a high balanced accuracy of 92% on tumor\ntypes classification and averaged balanced accuracy of 68% on tumor subtypes\nclassification, which represents, respectively 7% and 9% higher performance\ncompared to the referential signature.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07713v1"
    },
    {
        "title": "Sequencing by Emergence: Modeling and Estimation",
        "authors": [
            "Nicholas Boyd",
            "Samuel Woodhouse",
            "Kalim Mir"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Sequencing by Emergence (SEQE) is a new single-molecule nucleic acid\n(DNA/RNA) sequencing technology that estimates sequence as an emergent property\nof the binding and localization of a repertoire of short oligonucleotide\nprobes. SEQE promises to deliver accurate, ultra-long, haplotype-phased reads\nat the whole genome-scale for very low cost within 10 minutes. The data SEQE\ngenerates requires entirely new inference techniques. In this paper we\nintroduce a probabilistic model of the SEQE measurement process and an\nalgorithm that estimates sequence by solving a convex relaxation of the\ncorresponding maximum likelihood problem. We demonstrate the effectiveness of\nour algorithm on a variety of simulated datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.10477v2"
    },
    {
        "title": "GateKeeper-GPU: Fast and Accurate Pre-Alignment Filtering in Short Read\n  Mapping",
        "authors": [
            "Zülal Bingöl",
            "Mohammed Alser",
            "Onur Mutlu",
            "Ozcan Ozturk",
            "Can Alkan"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  At the last step of short read mapping, the candidate locations of the reads\non the reference genome are verified to compute their differences from the\ncorresponding reference segments using sequence alignment algorithms.\nCalculating the similarities and differences between two sequences is still\ncomputationally expensive since approximate string matching techniques\ntraditionally inherit dynamic programming algorithms with quadratic time and\nspace complexity. We introduce GateKeeper-GPU, a fast and accurate\npre-alignment filter that efficiently reduces the need for expensive sequence\nalignment. GateKeeper-GPU provides two main contributions: first, improving the\nfiltering accuracy of GateKeeper (a lightweight pre-alignment filter), and\nsecond, exploiting the massive parallelism provided by the large number of GPU\nthreads of modern GPUs to examine numerous sequence pairs rapidly and\nconcurrently. By reducing the work, GateKeeper-GPU provides an acceleration of\n2.9x to sequence alignment and up to 1.4x speedup to the end-to-end execution\ntime of a comprehensive read mapper (mrFAST). GateKeeper-GPU is available at\nhttps://github.com/BilkentCompGen/GateKeeper-GPU.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.14978v3"
    },
    {
        "title": "Comprehensive analysis of gene expression profiles to radiation exposure\n  reveals molecular signatures of low-dose radiation response",
        "authors": [
            "Xihaier Luo",
            "Sean McCorkle",
            "Gilchan Park",
            "Vanessa Lopez-Marrero",
            "Shinjae Yoo",
            "Edward R. Dougherty",
            "Xiaoning Qian",
            "Francis J. Alexander",
            "Byung-Jun Yoon"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  There are various sources of ionizing radiation exposure, where medical\nexposure for radiation therapy or diagnosis is the most common human-made\nsource. Understanding how gene expression is modulated after ionizing radiation\nexposure and investigating the presence of any dose-dependent gene expression\npatterns have broad implications for health risks from radiotherapy, medical\nradiation diagnostic procedures, as well as other environmental exposure. In\nthis paper, we perform a comprehensive pathway-based analysis of gene\nexpression profiles in response to low-dose radiation exposure, in order to\nexamine the potential mechanism of gene regulation underlying such responses.\nTo accomplish this goal, we employ a statistical framework to determine whether\na specific group of genes belonging to a known pathway display coordinated\nexpression patterns that are modulated in a manner consistent with the\nradiation level. Findings in our study suggest that there exist complex yet\nconsistent signatures that reflect the molecular response to radiation\nexposure, which differ between low-dose and high-dose radiation.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01769v1"
    },
    {
        "title": "Graph Contrastive Learning for Multi-omics Data",
        "authors": [
            "Nishant Rajadhyaksha",
            "Aarushi Chitkara"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Advancements in technologies related to working with omics data require novel\ncomputation methods to fully leverage information and help develop a better\nunderstanding of human diseases. This paper studies the effects of introducing\ngraph contrastive learning to help leverage graph structure and information to\nproduce better representations for downstream classification tasks for\nmulti-omics datasets. We present a learnining framework named Multi-Omics Graph\nContrastive Learner(MOGCL) which outperforms several aproaches for integrating\nmulti-omics data for supervised learning tasks. We show that pre-training graph\nmodels with a contrastive methodology along with fine-tuning it in a supervised\nmanner is an efficient strategy for multi-omics data classification.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02242v1"
    },
    {
        "title": "Unsupervised ensemble-based phenotyping helps enhance the\n  discoverability of genes related to heart morphology",
        "authors": [
            "Rodrigo Bonazzola",
            "Enzo Ferrante",
            "Nishant Ravikumar",
            "Yan Xia",
            "Bernard Keavney",
            "Sven Plein",
            "Tanveer Syeda-Mahmood",
            "Alejandro F Frangi"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Recent genome-wide association studies (GWAS) have been successful in\nidentifying associations between genetic variants and simple cardiac parameters\nderived from cardiac magnetic resonance (CMR) images. However, the emergence of\nbig databases including genetic data linked to CMR, facilitates investigation\nof more nuanced patterns of shape variability. Here, we propose a new framework\nfor gene discovery entitled Unsupervised Phenotype Ensembles (UPE). UPE builds\na redundant yet highly expressive representation by pooling a set of phenotypes\nlearned in an unsupervised manner, using deep learning models trained with\ndifferent hyperparameters. These phenotypes are then analyzed via (GWAS),\nretaining only highly confident and stable associations across the ensemble. We\napply our approach to the UK Biobank database to extract left-ventricular (LV)\ngeometric features from image-derived three-dimensional meshes. We demonstrate\nthat our approach greatly improves the discoverability of genes influencing LV\nshape, identifying 11 loci with study-wide significance and 8 with suggestive\nsignificance. We argue that our approach would enable more extensive discovery\nof gene associations with image-derived phenotypes for other organs or image\nmodalities.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02916v1"
    },
    {
        "title": "HQAlign: Aligning nanopore reads for SV detection using current-level\n  modeling",
        "authors": [
            "Dhaivat Joshi",
            "Suhas Diggavi",
            "Mark J. P. Chaisson",
            "Sreeram Kannan"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Motivation: Detection of structural variants (SV) from the alignment of\nsample DNA reads to the reference genome is an important problem in\nunderstanding human diseases. Long reads that can span repeat regions, along\nwith an accurate alignment of these long reads play an important role in\nidentifying novel SVs. Long read sequencers such as nanopore sequencing can\naddress this problem by providing very long reads but with high error rates,\nmaking accurate alignment challenging. Many errors induced by nanopore\nsequencing have a bias because of the physics of the sequencing process and\nproper utilization of these error characteristics can play an important role in\ndesigning a robust aligner for SV detection problems. In this paper, we design\nand evaluate HQAlign, an aligner for SV detection using nanopore sequenced\nreads. The key ideas of HQAlign include (i) using basecalled nanopore reads\nalong with the nanopore physics to improve alignments for SVs (ii)\nincorporating SV specific changes to the alignment pipeline (iii) adapting\nthese into existing state-of-the-art long read aligner pipeline, minimap2\n(v2.24), for efficient alignments.\n  Results: We show that HQAlign captures about 4%-6% complementary SVs across\ndifferent datasets which are missed by minimap2 alignments while having a\nstandalone performance at par with minimap2 for real nanopore reads data. For\nthe common SV calls between HQAlign and minimap2, HQAlign improves the start\nand the end breakpoint accuracy for about 10%-50% of SVs across different\ndatasets. Moreover, HQAlign improves the alignment rate to 89.35% from minimap2\n85.64% for nanopore reads alignment to recent telomere-to-telomere CHM13\nassembly, and it improves to 86.65% from 83.48% for nanopore reads alignment to\nGRCh37 human genome.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.03834v1"
    },
    {
        "title": "Optirank: classification for RNA-Seq data with optimal ranking reference\n  genes",
        "authors": [
            "Paola Malsot",
            "Filipe Martins",
            "Didier Trono",
            "Guillaume Obozinski"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Classification algorithms using RNA-Sequencing (RNA-Seq) data as input are\nused in a variety of biological applications. By nature, RNA-Seq data is\nsubject to uncontrolled fluctuations both within and especially across\ndatasets, which presents a major difficulty for a trained classifier to\ngeneralize to an external dataset. Replacing raw gene counts with the rank of\ngene counts inside an observation has proven effective to mitigate this\nproblem. However, the rank of a feature is by definition relative to all other\nfeatures, including highly variable features that introduce noise in the\nranking. To address this problem and obtain more robust ranks, we propose a\nlogistic regression model, optirank, which learns simultaneously the parameters\nof the model and the genes to use as a reference set in the ranking. We show\nthe effectiveness of this method on simulated data. We also consider real\nclassification tasks, which present different kinds of distribution shifts\nbetween train and test data. Those tasks concern a variety of applications,\nsuch as cancer of unknown primary classification, identification of specific\ngene signatures, and determination of cell type in single-cell RNA-Seq\ndatasets. On those real tasks, optirank performs at least as well as the\nvanilla logistic regression on classical ranks, while producing sparser\nsolutions. In addition, to increase the robustness against dataset shifts, we\npropose a multi-source learning scheme and demonstrate its effectiveness when\nused in combination with rank-based classifiers.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.04653v1"
    },
    {
        "title": "Deep Learning for Reference-Free Geolocation for Poplar Trees",
        "authors": [
            "Cai W. John",
            "Owen Queen",
            "Wellington Muchero",
            "Scott J. Emrich"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  A core task in precision agriculture is the identification of climatic and\necological conditions that are advantageous for a given crop. The most succinct\napproach is geolocation, which is concerned with locating the native region of\na given sample based on its genetic makeup. Here, we investigate genomic\ngeolocation of Populus trichocarpa, or poplar, which has been identified by the\nUS Department of Energy as a fast-rotation biofuel crop to be harvested\nnationwide. In particular, we approach geolocation from a reference-free\nperspective, circumventing the need for compute-intensive processes such as\nvariant calling and alignment. Our model, MashNet, predicts latitude and\nlongitude for poplar trees from randomly-sampled, unaligned sequence fragments.\nWe show that our model performs comparably to Locator, a state-of-the-art\nmethod based on aligned whole-genome sequence data. MashNet achieves an error\nof 34.0 km^2 compared to Locator's 22.1 km^2. MashNet allows growers to quickly\nand efficiently identify natural varieties that will be most productive in\ntheir growth environment based on genotype. This paper explores geolocation for\nprecision agriculture while providing a framework and data source for further\ndevelopment by the machine learning community.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13387v1"
    },
    {
        "title": "The parameters of Menzerath-Altmann law in genomes",
        "authors": [
            "Jaume Baixeries",
            "Antoni Hernandez-Fernandez",
            "Nuria Forns",
            "Ramon Ferrer-i-Cancho"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The relationship between the size of the whole and the size of the parts in\nlanguage and music is known to follow Menzerath-Altmann law at many levels of\ndescription (morphemes, words, sentences...). Qualitatively, the law states\nthat larger the whole, the smaller its parts, e.g., the longer a word (in\nsyllables) the shorter its syllables (in letters or phonemes). This patterning\nhas also been found in genomes: the longer a genome (in chromosomes), the\nshorter its chromosomes (in base pairs). However, it has been argued recently\nthat mean chromosome length is trivially a pure power function of chromosome\nnumber with an exponent of -1. The functional dependency between mean\nchromosome size and chromosome number in groups of organisms from three\ndifferent kingdoms is studied. The fit of a pure power function yields\nexponents between -1.6 and 0.1. It is shown that an exponent of -1 is unlikely\nfor fungi, gymnosperm plants, insects, reptiles, ray-finned fishes and\namphibians. Even when the exponent is very close to -1, adding an exponential\ncomponent is able to yield a better fit with regard to a pure power-law in\nplants, mammals, ray-finned fishes and amphibians. The parameters of\nMenzerath-Altmann law in genomes deviate significantly from a power law with a\n-1 exponent with the exception of birds and cartilaginous fishes.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1746v3"
    },
    {
        "title": "arrayMap: A Reference Resource for Genomic Copy Number Imbalances in\n  Human Malignancies",
        "authors": [
            "Haoyang Cai",
            "Nitin Kumar",
            "Michael Baudis"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Background: The delineation of genomic copy number abnormalities (CNAs) from\ncancer samples has been instrumental for identification of tumor suppressor\ngenes and oncogenes and proven useful for clinical marker detection. An\nincreasing number of projects have mapped CNAs using high-resolution microarray\nbased techniques. So far, no single resource does provide a global collection\nof readily accessible oncoge- nomic array data.\n  Methodology/Principal Findings: We here present arrayMap, a curated reference\ndatabase and bioinformatics resource targeting copy number profiling data in\nhuman cancer. The arrayMap database provides a platform for meta-analysis and\nsystems level data integration of high-resolution oncogenomic CNA data. To\ndate, the resource incorporates more than 40,000 arrays in 224 cancer types\nextracted from several resources, including the NCBI's Gene Expression Omnibus\n(GEO), EBIs ArrayExpress (AE), The Cancer Genome Atlas (TCGA), publication\nsupplements and direct submissions. For the majority of the included datasets,\nprobe level and integrated visualization facilitate gene level and genome wide\ndata re- view. Results from multi-case selections can be connected to\ndownstream data analysis and visualization tools.\n  Conclusions/Significance: To our knowledge, currently no data source provides\nan extensive collection of high resolution oncogenomic CNA data which readily\ncould be used for genomic feature mining, across a representative range of\ncancer entities. arrayMap represents our effort for providing a long term\nplatform for oncogenomic CNA data independent of specific platform\nconsiderations or specific project dependence. The online database can be\naccessed at http://www.arraymap.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.2677v1"
    },
    {
        "title": "Rank discriminants for predicting phenotypes from RNA expression",
        "authors": [
            "Bahman Afsari",
            "Ulisses M. Braga-Neto",
            "Donald Geman"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Statistical methods for analyzing large-scale biomolecular data are\ncommonplace in computational biology. A notable example is phenotype prediction\nfrom gene expression data, for instance, detecting human cancers,\ndifferentiating subtypes and predicting clinical outcomes. Still, clinical\napplications remain scarce. One reason is that the complexity of the decision\nrules that emerge from standard statistical learning impedes biological\nunderstanding, in particular, any mechanistic interpretation. Here we explore\ndecision rules for binary classification utilizing only the ordering of\nexpression among several genes; the basic building blocks are then two-gene\nexpression comparisons. The simplest example, just one comparison, is the TSP\nclassifier, which has appeared in a variety of cancer-related discovery\nstudies. Decision rules based on multiple comparisons can better accommodate\nclass heterogeneity, and thereby increase accuracy, and might provide a link\nwith biological mechanism. We consider a general framework (\"rank-in-context\")\nfor designing discriminant functions, including a data-driven selection of the\nnumber and identity of the genes in the support (\"context\"). We then specialize\nto two examples: voting among several pairs and comparing the median expression\nin two groups of genes. Comprehensive experiments assess accuracy relative to\nother, more complex, methods, and reinforce earlier observations that simple\nclassifiers are competitive.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1490v3"
    },
    {
        "title": "Universality splitting in distribution of number of miRNA co-targets",
        "authors": [
            "Mahashweta Basu",
            "Nitai P. Bhattacharyya",
            "P. K. Mohanty"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  In a recent work [arXiv:1307.1382] it was pointed out that the link-weight\ndistribution of microRNA (miRNA) co-target network of a wide class of species\nare universal up to scaling. The number cell types, widely accepted as a\nmeasure of complexity, turns out to be proportional to these scale-factor. In\nthis article we discuss additional universal features of these networks and\nshow that, this universality splits if one considers distribution of number of\ncommon targets of three or more number of miRNAs. These distributions for\ndifferent species can be collapsed onto two distinct set of universal\nfunctions, revealing the fact that the species which appeared in early\nevolution have different complexity measure compared to those appeared late.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4055v1"
    },
    {
        "title": "Landscape of standing variation for tandem duplications in Drosophila\n  yakuba and Drosophila simulans",
        "authors": [
            "Rebekah L. Rogers",
            "Julie M. Cridland",
            "Ling Shao",
            "Tina T. Hu",
            "Peter Andolfatto",
            "Kevin R. Thornton"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  We have used whole genome paired-end Illumina sequence data to identify\ntandem duplications in 20 isofemale lines of D. yakuba, and 20 isofemale lines\nof D. simulans and performed genome wide validation with PacBio long molecule\nsequencing. We identify 1,415 tandem duplications that are segregating in D.\nyakuba as well as 975 duplications in D. simulans, indicating greater variation\nin D. yakuba. Additionally, we observe high rates of secondary deletions at\nduplicated sites, with 8% of duplicated sites in D. simulans and 17% of sites\nin D. yakuba modified with deletions. These secondary deletions are consistent\nwith the action of the large loop mismatch repair system acting to remove\npolymorphic tandem duplication, resulting in rapid dynamics of gain and loss in\nduplicated alleles and a richer substrate of genetic novelty than has been\npreviously reported. Most duplications are present in only single strains,\nsuggesting deleterious impacts are common. D. simulans shows larger numbers of\nwhole gene duplications in comparison to larger proportions of gene fragments\nin D. yakuba. D. simulans displays an excess of high frequency variants on the\nX chromosome, consistent with adaptive evolution through duplications on the D.\nsimulans X or demographic forces driving duplicates to high frequency. We\nidentify 78 chimeric genes in D. yakuba and 38 chimeric genes in D. simulans,\nas well as 143 cases of recruited non-coding sequence in D. yakuba and 96 in D.\nsimulans, in agreement with rates of chimeric gene origination in D.\nmelanogaster. Together, these results suggest that tandem duplications often\nresult in complex variation beyond whole gene duplications that offers a rich\nsubstrate of standing variation that is likely to contribute both to\ndetrimental phenotypes and disease, as well as to adaptive evolutionary change.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.7371v2"
    },
    {
        "title": "A Simple Data-Adaptive Probabilistic Variant Calling Model",
        "authors": [
            "Steve Hoffmann",
            "Peter F. Stadler",
            "Korbinian Strimmer"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Background: Several sources of noise obfuscate the identification of single\nnucleotide variation (SNV) in next generation sequencing data. For instance,\nerrors may be introduced during library construction and sequencing steps. In\naddition, the reference genome and the algorithms used for the alignment of the\nreads are further critical factors determining the efficacy of variant calling\nmethods. It is crucial to account for these factors in individual sequencing\nexperiments.\n  Results: We introduce a simple data-adaptive model for variant calling. This\nmodel automatically adjusts to specific factors such as alignment errors. To\nachieve this, several characteristics are sampled from sites with low mismatch\nrates, and these are used to estimate empirical log-likelihoods. These\nlikelihoods are then combined to a score that typically gives rise to a mixture\ndistribution. From these we determine a decision threshold to separate\npotentially variant sites from the noisy background.\n  Conclusions: In simulations we show that our simple proposed model is\ncompetitive with frequently used much more complex SNV calling algorithms in\nterms of sensitivity and specificity. It performs specifically well in cases\nwith low allele frequencies. The application to next-generation sequencing data\nreveals stark differences of the score distributions indicating a strong\ninfluence of data specific sources of noise. The proposed model is specifically\ndesigned to adjust to these differences.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5251v3"
    },
    {
        "title": "Pervasive variation of transcription factor orthologs contributes to\n  regulatory network evolution",
        "authors": [
            "Shilpa Nadimpalli",
            "Anton V. Persikov",
            "Mona Singh"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Differences in transcriptional regulatory networks underlie much of the\nphenotypic variation observed across organisms. Changes to cis-regulatory\nelements are widely believed to be the predominant means by which regulatory\nnetworks evolve, yet examples of regulatory network divergence due to\ntranscription factor (TF) variation have also been observed. To systematically\nascertain the extent to which TFs contribute to regulatory divergence, we\nanalyzed the evolution of the largest class of metazoan TFs, Cys2-His2 zinc\nfinger (C2H2-ZF) TFs, across 12 Drosophila species spanning ~45 million years\nof evolution. Remarkably, we uncovered that a significant fraction of all\nC2H2-ZF 1-to-1 orthologs in flies exhibit variations that can affect their\nDNA-binding specificities. In addition to loss and recruitment of C2H2-ZF\ndomains, we found diverging DNA-contacting residues in ~47% of domains shared\nbetween D. melanogaster and the other fly species. These diverging\nDNA-contacting residues, found in ~66% of the D. melanogaster C2H2-ZF genes in\nour analysis and corresponding to ~24% of all annotated D. melanogaster TFs,\nshow evidence of functional constraint: they tend to be conserved across\nphylogenetic clades and evolve slower than other diverging residues. These same\nvariations were rarely found as polymorphisms within a population of D.\nmelanogaster flies, indicating their rapid fixation. The predicted\nspecificities of these dynamic domains gradually change across phylogenetic\ndistances, suggesting stepwise evolutionary trajectories for TF divergence.\nFurther, whereas proteins with conserved C2H2-ZF domains are enriched in\ndevelopmental functions, those with varying domains exhibit no functional\nenrichments. Our work suggests that a subset of highly dynamic and largely\nunstudied TFs are a likely source of regulatory variation in Drosophila and\nother metazoans.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.0320v1"
    },
    {
        "title": "Statistical distributions and entropy considerations in gene codes",
        "authors": [
            "Krystyna Lukierska-Walasek",
            "Krzysztof Topolski",
            "Krzysztof Trojanowski"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  In our paper selected linguistic features of genomes to study the statistics\nof the gene codes are considered. We present the information theory from which\nit follows that if the system is described by distributions of hyperbolic type\nit leads to the possibility of entropy loss and stability. We show that the\nhistograms of gene lengths are similar to that of language words. We show the\ncorrespondence between presented theory and results for the number of\nreplicated genes and replicated fragments of genes in genomes for Borelia\nburgdorferi, Escherichia coli and Saccharomyces cerevisiae S288c.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2269v1"
    },
    {
        "title": "Giant Viruses of the Kutch Desert",
        "authors": [
            "Csaba Kerepesi",
            "Vince Grolmusz"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  The Kutch desert (Great Rann of Kutch, Gujarat, India) is a unique ecosystem:\nin the larger part of the year it is a hot, salty desert that is flooded\nregularly in the Indian monsoon season. In the dry season, the crystallized\nsalt deposits form the \"white desert\" in large regions. The first metagenomic\nanalysis of the soil samples of Kutch was published in 2013, and the data was\ndeposited in the NCBI Sequence Read Archive. The sequences were analyzed at the\nsame time phylogenetically for prokaryotes, especially for bacterial taxa.\n  In the present work, we are searching for the DNA sequences of the recently\ndiscovered giant viruses in the soil samples of the Kutch desert. Since most\ngiant viruses were discovered in biofilms in industrial cooling towers, ocean\nwater and freshwater ponds, we were surprised to find their DNA sequences in\nthe soil samples of a seasonally very hot and arid, salty environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.1278v2"
    },
    {
        "title": "Second-generation PLINK: rising to the challenge of larger and richer\n  datasets",
        "authors": [
            "Christopher C. Chang",
            "Carson C. Chow",
            "Laurent C. A. M. Tellier",
            "Shashaank Vattikuti",
            "Shaun M. Purcell",
            "James J. Lee"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  PLINK 1 is a widely used open-source C/C++ toolset for genome-wide\nassociation studies (GWAS) and research in population genetics. However, the\nsteady accumulation of data from imputation and whole-genome sequencing studies\nhas exposed a strong need for even faster and more scalable implementations of\nkey functions. In addition, GWAS and population-genetic data now frequently\ncontain probabilistic calls, phase information, and/or multiallelic variants,\nnone of which can be represented by PLINK 1's primary data format.\n  To address these issues, we are developing a second-generation codebase for\nPLINK. The first major release from this codebase, PLINK 1.9, introduces\nextensive use of bit-level parallelism, O(sqrt(n))-time/constant-space\nHardy-Weinberg equilibrium and Fisher's exact tests, and many other algorithmic\nimprovements. In combination, these changes accelerate most operations by 1-4\norders of magnitude, and allow the program to handle datasets too large to fit\nin RAM. This will be followed by PLINK 2.0, which will introduce (a) a new data\nformat capable of efficiently representing probabilities, phase, and\nmultiallelic variants, and (b) extensions of many functions to account for the\nnew types of information.\n  The second-generation versions of PLINK will offer dramatic improvements in\nperformance and compatibility. For the first time, users without access to\nhigh-end computing resources can perform several essential analyses of the\nfeature-rich and very large genetic datasets coming into use.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.4803v1"
    },
    {
        "title": "Genetic Studies of Physiological Traits with Their Application to Sleep\n  Apnea",
        "authors": [
            "D. Y. Lee",
            "C. Hanis",
            "G. I. Bell",
            "D. A. Aguilar",
            "S. Redline",
            "J. Below",
            "M. M. Xiong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Advances of modern sensing and sequencing technologies generate a deluge of\nhigh dimensional space-temporal physiological and next-generation sequencing\n(NGS) data. Physiological traits are observed either as continuous random\nfunctions, or on a dense grid and referred to as function-valued traits. Both\nphysiological and NGS data are highly correlated data with their inherent\norder, spacing, and functional nature which are ignored by traditional\nsummary-based univariate and multivariate regression methods designed for\nquantitative genetic analysis of scalar trait and common variants. To capture\nmorphological and dynamic features of the data and utilize their dependent\nstructure, we propose a functional linear model (FLM) in which a trait curve is\nmodeled as a response function, the genetic variation in a genomic region or\ngene is modeled as a functional predictor, and the genetic effects are modeled\nas a function of both time and genomic position (FLMF) for genetic analysis of\nfunction-valued trait with both GWAS and NGS data. By extensive simulations, we\ndemonstrate that the FLMF has the correct type 1 error rates and much higher\npower to detect association than the existing methods. The FLMF is applied to\nsleep data from Starr County health studies where oxygen saturation were\nmeasured in 22,670 seconds on average for 833 individuals. We found 65 genes\nthat were significantly associated with oxygen saturation functional trait with\nP-values ranging from 2.40E-06 to 2.53E-21. The results clearly demonstrate\nthat the FLMF substantially outperforms the traditional genetic models with\nscalar trait.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.7363v1"
    },
    {
        "title": "Ecological patterns of genome size variation and the origin of species\n  in salamanders",
        "authors": [
            "Bianca Sclavi",
            "John Herrick"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Salamanders (urodela) have among the largest vertebrate genomes, ranging in\nsize from 10 to over 80 pg. The urodela are divided into ten extant families\neach with a characteristic range in genome size. Although changes in genome\nsize often occur randomly and in the absence of selection pressure, non-random\npatterns of genome size variation are evident among specific vertebrate\nlineages. Here we report that genome size in salamander families varies\ninversely with species richness and other ecological factors: clades that began\nradiating earlier (older crown age) tend to have smaller genomes, higher levels\nof diversity and larger geographical ranges. These observations support the\nhypothesis that urodel families with larger genomes either have a lower\npropensity to diversify or are more vulnerable to extinction than families with\nsmaller genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.03782v2"
    },
    {
        "title": "Using runs of homozygosity to detect genomic regions associated with\n  susceptibility to infectious and metabolic diseases in dairy cows under\n  intensive farming conditions",
        "authors": [
            "Filippo Biscarini",
            "Stefano Biffani",
            "Nicola Morandi",
            "Ezequiel L. Nicolazzi",
            "Alessandra Stella"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Runs of homozygosity (ROH) are contiguous stretches of homozygous genome\nwhich likely reflect transmission from common ances- tors and can be used to\ntrack the inheritance of haplotypes of interest. In the present paper, ROH were\nextracted from 50K SNPs and used to detect regions of the genome associated\nwith susceptibility to diseases in a population of 468 Holstein-Frisian cows.\nDiagnosed diseases were categorised as infectious diseases, metabolic\nsyndromes, mastitis, reproductive diseases and locomotive disorders. ROH\nassociated with infectious diseases, mastitis and locomotive disorders were\nfound on BTA 12. A long region of homozygosity linked with metabolic syndromes,\ninfectious and reproductive diseases was detected on BTA 15, disclosing complex\nrelationships between immunity, metabolism and functional disorders. ROH\nassociated with infectious and reproductive diseases, mastitis and metabolic\nsyndromes were observed on chromosomes 3, 5, 7, 13 and 18. Previous studies\nreported QTLs for milk production traits on all of these regions, thus\nsubstantiating the known negative relationship between selection for milk\nproduction and health in dairy cattle.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.07062v1"
    },
    {
        "title": "Aligning 415 519 proteins in less than two hours on PC",
        "authors": [
            "Sebastin Deorowicz",
            "Agnieszka Debudaj-Grabysz",
            "Adam Gudys"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Rapid development of modern sequencing platforms enabled an unprecedented\ngrowth of protein families databases. The abundance of sets composed of\nhundreds of thousands sequences is a great challenge for multiple sequence\nalignment algorithms. In the article we introduce FAMSA, a new progressive\nalgorithm designed for fast and accurate alignment of thousands of protein\nsequences. Its features include the utilisation of longest common subsequence\nmeasure for determining pairwise similarities, a novel method of gap costs\nevaluation, and a new iterative refinement scheme. Importantly, its\nimplementation is highly optimised and parallelised to make the most of modern\ncomputer platforms. Thanks to the above, quality indicators, namely\nsum-of-pairs and total-column scores, show FAMSA to be superior to competing\nalgorithms like Clustal Omega or MAFFT for datasets exceeding a few thousand of\nsequences. The quality does not compromise time and memory requirements which\nare an order of magnitude lower than that of existing solutions. For example, a\nfamily of 415 519 sequences was analysed in less than two hours and required\nonly 8GB of RAM.\n  FAMSA is freely available at http://sun.aei.polsl.pl/REFRESH/famsa.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.06958v1"
    },
    {
        "title": "Higher order methylation features for clustering and prediction in\n  epigenomic studies",
        "authors": [
            "Chantriolnt-Andreas Kapourani",
            "Guido Sanguinetti"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: DNA methylation is an intensely studied epigenetic mark, yet its\nfunctional role is incompletely understood. Attempts to quantitatively\nassociate average DNA methylation to gene expression yield poor correlations\noutside of the well-understood methylation-switch at CpG islands.\n  Results: Here we use probabilistic machine learning to extract higher order\nfeatures associated with the methylation profile across a defined region. These\nfeatures quantitate precisely notions of shape of a methylation profile,\ncapturing spatial correlations in DNA methylation across genomic regions. Using\nthese higher order features across promoter-proximal regions, we are able to\nconstruct a powerful machine learning predictor of gene expression,\nsignificantly improving upon the predictive power of average DNA methylation\nlevels. Furthermore, we can use higher order features to cluster\npromoter-proximal regions, showing that five major patterns of methylation\noccur at promoters across different cell lines, and we provide evidence that\nmethylation beyond CpG islands may be related to regulation of gene expression.\nOur results support previous reports of a functional role of spatial\ncorrelations in methylation patterns, and provide a mean to quantitate such\nfeatures for downstream analyses.\n  Availability: https://github.com/andreaskapou/BPRMeth\n",
        "pdf_link": "http://arxiv.org/pdf/1603.08386v1"
    },
    {
        "title": "A machine learning approach to drug repositioning based on drug\n  expression profiles: Applications to schizophrenia and depression/anxiety\n  disorders",
        "authors": [
            "Kai Zhao",
            "Hon-Cheong So"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Development of new medications is a very lengthy and costly process. Finding\nnovel indications for existing drugs, or drug repositioning, can serve as a\nuseful strategy to shorten the development cycle. In this study, we present an\napproach to drug discovery or repositioning by predicting indication for a\nparticular disease based on expression profiles of drugs, with a focus on\napplications in psychiatry. Drugs that are not originally indicated for the\ndisease but with high predicted probabilities serve as good candidates for\nrepurposing. This framework is widely applicable to any chemicals or drugs with\nexpression profiles measured, even if the drug targets are unknown. It is also\nhighly flexible as virtually any supervised learning algorithms can be used. We\napplied this approach to identify repositioning opportunities for schizophrenia\nas well as depression and anxiety disorders. We applied various\nstate-of-the-art machine learning (ML) approaches for prediction, including\ndeep neural networks, support vector machines (SVM), elastic net, random forest\nand gradient boosted machines. The performance of the five approaches did not\ndiffer substantially, with SVM slightly outperformed the others. However,\nmethods with lower predictive accuracy can still reveal literature-supported\ncandidates that are of different mechanisms of actions. As a further\nvalidation, we showed that the repositioning hits are enriched for psychiatric\nmedications considered in clinical trials. Notably, many top repositioning hits\nare supported by previous preclinical or clinical studies. Finally, we propose\nthat ML approaches may provide a new avenue to explore drug mechanisms via\nexamining the variable importance of gene features.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.03014v2"
    },
    {
        "title": "Mass-spectrometry of single mammalian cells quantifies proteome\n  heterogeneity during cell differentiation",
        "authors": [
            "Bogdan Budnik",
            "Ezra Levy",
            "Guillaume Harmange",
            "Nikolai Slavov"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Cellular heterogeneity is important to biological processes, including cancer\nand development. However, proteome heterogeneity is largely unexplored because\nof the limitations of existing methods for quantifying protein levels in single\ncells. To alleviate these limitations, we developed Single Cell ProtEomics by\nMass Spectrometry (SCoPE-MS), and validated its ability to identify distinct\nhuman cancer cell types based on their proteomes. We used SCoPE-MS to quantify\nover a thousand proteins in differentiating mouse embryonic stem (ES) cells.\nThe single-cell proteomes enabled us to deconstruct cell populations and infer\nprotein abundance relationships. Comparison between single-cell proteomes and\ntranscriptomes indicated coordinated mRNA and protein covariation. Yet many\ngenes exhibited functionally concerted and distinct regulatory patterns at the\nmRNA and the protein levels, suggesting that post-transcriptional regulatory\nmechanisms contribute to proteome remodeling during lineage specification,\nespecially for developmental genes. SCoPE-MS is broadly applicable to measuring\nproteome configurations of single cells and linking them to functional\nphenotypes, such as cell type and differentiation potentials.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.00598v1"
    },
    {
        "title": "RASSA: Resistive Pre-Alignment Accelerator for Approximate DNA Long Read\n  Mapping",
        "authors": [
            "Roman Kaplan",
            "Leonid Yavits",
            "Ran Ginosar"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  DNA read mapping is a computationally expensive bioinformatics task, required\nfor genome assembly and consensus polishing. It requires to find the\nbest-fitting location for each DNA read on a long reference sequence. A novel\nresistive approximate similarity search accelerator, RASSA, exploits charge\ndistribution and parallel in-memory processing to reflect a mismatch count\nbetween DNA sequences. RASSA implementation of DNA long read pre-alignment\noutperforms the state-of-art solution, minimap2, by 16-77x with comparable\naccuracy and provides two orders of magnitude higher throughput than\nGateKeeper, a short-read pre-alignment hardware architecture implemented in\nFPGA.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01127v3"
    },
    {
        "title": "Data Lakes, Clouds and Commons: A Review of Platforms for Analyzing and\n  Sharing Genomic Data",
        "authors": [
            "Robert L. Grossman"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Data commons collate data with cloud computing infrastructure and commonly\nused software services, tools and applications to create biomedical resources\nfor the large-scale management, analysis, harmonization, and sharing of\nbiomedical data. Over the past few years, data commons have been used to\nanalyze, harmonize and share large scale genomics datasets. Data ecosystems can\nbe built by interoperating multiple data commons. It can be quite labor\nintensive to curate, import and analyze the data in a data commons. Data lakes\nprovide an alternative to data commons and simply provide access to data, with\nthe data curation and analysis deferred until later and delegated to those that\naccess the data. We review software platforms for managing, analyzing and\nsharing genomic data, with an emphasis on data commons, but also covering data\necosystems and data lakes.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01699v2"
    },
    {
        "title": "Cancer classification and pathway discovery using non-negative matrix\n  factorization",
        "authors": [
            "Zexian Zeng",
            "Andy Vo",
            "Chengsheng Mao",
            "Susan E Clare",
            "Seema A Khan",
            "Yuan Luo"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Extracting genetic information from a full range of sequencing data is\nimportant for understanding diseases. We propose a novel method to effectively\nexplore the landscape of genetic mutations and aggregate them to predict cancer\ntype. We used multinomial logistic regression, nonsmooth non-negative matrix\nfactorization (nsNMF), and support vector machine (SVM) to utilize the full\nrange of sequencing data, aiming at better aggregating genetic mutations and\nimproving their power in predicting cancer types. Specifically, we introduced a\nclassifier to distinguish cancer types using somatic mutations obtained from\nwhole-exome sequencing data. Mutations were identified from multiple cancers\nand scored using SIFT, PP2, and CADD, and grouped at the individual gene level.\nThe nsNMF was then applied to reduce dimensionality and to obtain coefficient\nand basis matrices. A feature matrix was derived from the obtained matrices to\ntrain a classifier for cancer type classification with the SVM model. We have\ndemonstrated that the classifier was able to distinguish the cancer types with\nreasonable accuracy. In five-fold cross-validations using mutation counts as\nfeatures, the average prediction accuracy was 77.1% (SEM=0.1%), significantly\noutperforming baselines and outperforming models using mutation scores as\nfeatures. Using the factor matrices derived from the nsNMF, we identified\nmultiple genes and pathways that are significantly associated with each cancer\ntype. This study presents a generic and complete pipeline to study the\nassociations between somatic mutations and cancers. The discovered genes and\npathways associated with each cancer type can lead to biological insights. The\nproposed method can be adapted to other studies for disease classification and\npathway discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.10681v2"
    },
    {
        "title": "The long non-coding RNA HOTAIR is transcriptionally activated by HOXA9\n  and is an independent prognostic marker in patients with malignant glioma",
        "authors": [
            "Ana Xavier-Magalhães",
            "Céline Gonçalves",
            "Anne Fogli",
            "Tatiana Lourenço",
            "Marta Pojo",
            "Bruno Pereira",
            "Miguel Rocha",
            "Maria Lopes",
            "Inês Crespo",
            "Olinda Rebelo",
            "Herminio Tão",
            "João Lima",
            "Ricardo Moreira",
            "Afonso Pinto",
            "Chris Jones",
            "Rui Reis",
            "Joseph Costello",
            "Philippe Arnaud",
            "Nuno Sousa",
            "Bruno Costa"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The lncRNA HOTAIR has been implicated in several human cancers. Here, we\nevaluated the molecular alterations and upstream regulatory mechanisms of\nHOTAIR in glioma, the most common primary brain tumors, and its clinical\nrelevance. HOTAIR gene expression, methylation, copy-number and prognostic\nvalue were investigated in human gliomas integrating data from online datasets\nand our cohorts. High levels of HOTAIR were associated with higher grades of\nglioma, particularly IDH wild-type cases. Mechanistically, HOTAIR was\noverexpressed in a gene dosage-independent manner, while DNA methylation levels\nof particular CpGs in HOTAIR locus were associated with HOTAIR expression\nlevels in GBM clinical specimens and cell lines. Concordantly, the\ndemethylating agent 5-Aza-2'-deoxycytidine affected HOTAIR transcriptional\nlevels in a cell line-dependent manner. Importantly, HOTAIR was frequently\nco-expressed with HOXA9 in high-grade gliomas from TCGA, Oncomine, and our\nPortuguese and French datasets. Integrated in silico analyses, chromatin\nimmunoprecipitation, and qPCR data showed that HOXA9 binds directly to the\npromoter of HOTAIR. Clinically, GBM patients with high HOTAIR expression had a\nsignificantly reduced overall survival, independently of other prognostic\nvariables. In summary, this work reveals HOXA9 as a novel direct regulator of\nHOTAIR, and establishes HOTAIR as an independent prognostic marker, providing\nnew therapeutic opportunities to treat this highly aggressive cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.03943v1"
    },
    {
        "title": "Imprinting control regions (ICRs) are marked by mono-allelic bivalent\n  chromatin when transcriptionally inactive",
        "authors": [
            "Stéphanie Maupetit-Méhouas",
            "Bertille Montibus",
            "David Nury",
            "Chiharu Tayama",
            "Michel Wassef",
            "Satya Kota",
            "Anne Fogli",
            "Fabiana Cerqueira Campos",
            "Kenichiro Hata",
            "Robert Feil",
            "Raphaël Margueron",
            "Kazuhiko Nakabayashi",
            "Franck Court",
            "Philippe Arnaud"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Parental allele-specific expression of imprinted genes is mediated by\nimprinting control regions (ICRs) that are constitutively marked by DNA\nmethylation imprints on the maternal or paternal allele. Mono-allelic DNA\nmethylation is strictly required for the process of imprinting and has to be\nfaithfully maintained during the entire lifespan. While the regulation of DNA\nmethylation itself is well understood, the mechanisms whereby the opposite\nallele remains unmethylated are unclear. Here, we show that in the mouse, at\nmaternally methylated ICRs, the paternal allele, which is constitutively\nassociated with H3K4me2/3, is marked by default by H3K27me3 when these ICRs are\ntranscriptionally inactive, leading to the formation of a bivalent chromatin\nsignature. Our data suggest that at ICRs, chromatin bivalency has a protective\nrole by ensuring that DNA on the paternal allele remains unmethylated and\nprotected against spurious and unscheduled gene expression. Moreover , they\nprovide the proof of concept that, beside pluripotent cells, chromatin\nbivalency is the default state of transcriptionally inactive CpG island\npromoters , regardless of the developmental stage, thereby contributing to\nprotect cell identity.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.03952v1"
    },
    {
        "title": "An annotated list of bivalent chromatin regions in human ES cells: a new\n  tool for cancer epigenetic research",
        "authors": [
            "Franck Court",
            "Philippe Arnaud"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  CpG islands (CGI) marked by bivalent chromatin in stem cells are believed to\nbe more prone to aberrant DNA methylation in tumor cells. The robustness and\ngenome-wide extent of this instructive program in different cancer types remain\nto be determined. To address this issue we developed a user-friendly approach\nto integrate the stem cell chromatin signature in customized DNA methylation\nanalyses. We used publicly available ChIP-sequencing datasets of several human\nembryonic stem cell (hESC) lines to determine the extent of bivalent chromatin\ngenome-wide. We then created annotated lists of high-confidence bivalent,\nH3K4me3-only and H3K27me3-only chromatin regions. The main features of bivalent\nregions included localization in CGI/promoters, depletion in retroelements and\nenrichment in specific histone modifications, including the poorly\ncharacterized H3K23me2 mark. Moreover, bivalent promoters could be classified\nin three clusters based on PRC2 and PolII complexes occupancy. Genes with\nbivalent promoters of the PRC2-defined cluster displayed the lowest expression\nupon differentiation. As proof-of-concept, we assessed the DNA methylation\npattern of eight types of tumors and confirmed that aberrant cancer-associated\nDNA hypermethylation preferentially targets CGI characterized by bivalent\nchromatin in hESCs. We also found that such aberrant DNA hypermethylation\naffected particularly bivalent CGI/promoters associated with genes that tend to\nremain repressed upon differentiation. Strikingly, bivalent CGI were the most\naffected by aberrant DNA hypermethylation in both CpG Island Methylator\nPhenotype-positive (CIMP+) and CIMP-negative tumors, suggesting that, besides\ntranscriptional silencing in the pre-tumorigenic cells, the bivalent chromatin\nsignature in hESCs is a key determinant of the instructive program for aberrant\nDNA methylation.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.03954v1"
    },
    {
        "title": "Prediction of Signal Sequences in Abiotic Stress Inducible Genes from\n  Main Crops by Association Rule Mining",
        "authors": [
            "Un-Hyang Ho",
            "Hye-Ok Kong"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  It is important to study on genes affecting to growing environment of main\ncrops. Especially the recognition problem of promoter region, which is the\nproblem to predict whether DNA sequences contain promoter regions or not, is\nprior to find abiotic stress-inducible genes. Studies on predicting promoter\nsequences in DNA sequences have been studied by traditional pattern matching\nmethods and machine learning methods in biology and computer science.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07269v1"
    },
    {
        "title": "FindeR: Accelerating FM-Index-based Exact Pattern Matching in Genomic\n  Sequences through ReRAM technology",
        "authors": [
            "Farzaneh Zokaee",
            "Mingzhe Zhang",
            "Lei Jiang"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Genomics is the critical key to enabling precision medicine, ensuring global\nfood security and enforcing wildlife conservation. The massive genomic data\nproduced by various genome sequencing technologies presents a significant\nchallenge for genome analysis. Because of errors from sequencing machines and\ngenetic variations, approximate pattern matching (APM) is a must for practical\ngenome analysis. Recent work proposes FPGA, ASIC and even\nprocess-in-memory-based accelerators to boost the APM throughput by\naccelerating dynamic-programming-based algorithms (e.g., Smith-Waterman).\nHowever, existing accelerators lack the efficient hardware acceleration for the\nexact pattern matching (EPM) that is an even more critical and essential\nfunction widely used in almost every step of genome analysis including\nassembly, alignment, annotation and compression.\n  State-of-the-art genome analysis adopts the FM-Index that augments the\nspace-efficient BWT with additional data structures permitting fast EPM\noperations. But the FM-Index is notorious for poor spatial locality and massive\nrandom memory accesses. In this paper, we propose a ReRAM-based\nprocess-in-memory architecture, FindeR, to enhance the FM-Index EPM search\nthroughput in genomic sequences. We build a reliable and energy-efficient\nHamming distance unit to accelerate the computing kernel of FM-Index search\nusing commodity ReRAM chips without introducing extra CMOS logic. We further\narchitect a full-fledged FM-Index search pipeline and improve its search\nthroughput by lightweight scheduling on the NVDIMM. We also create a system\nlibrary for programmers to invoke FindeR to perform EPMs in genome analysis.\nCompared to state-of-the-art accelerators, FindeR improves the FM-Index search\nthroughput by $83\\%\\sim 30K\\times$ and throughput per Watt by $3.5\\times\\sim\n42.5K\\times$.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04965v2"
    },
    {
        "title": "Genome-wide Causation Studies of Complex Diseases",
        "authors": [
            "Rong Jiao",
            "Xiangning Chen",
            "Eric Boerwinkle",
            "Momiao Xiong"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Despite significant progress in dissecting the genetic architecture of\ncomplex diseases by genome-wide association studies (GWAS), the signals\nidentified by association analysis may not have specific pathological relevance\nto diseases so that a large fraction of disease causing genetic variants is\nstill hidden. Association is used to measure dependence between two variables\nor two sets of variables. Genome-wide association studies test association\nbetween a disease and SNPs (or other genetic variants) across the genome.\nAssociation analysis may detect superficial patterns between disease and\ngenetic variants. Association signals provide limited information on the causal\nmechanism of diseases. The use of association analysis as a major analytical\nplatform for genetic studies of complex diseases is a key issue that hampers\ndiscovery of the mechanism of diseases, calling into question the ability of\nGWAS to identify loci underlying diseases. It is time to move beyond\nassociation analysis toward techniques enabling the discovery of the underlying\ncausal genetic strctures of complex diseases. To achieve this, we propose a\nconcept of a genome-wide causation studies (GWCS) as an alternative to GWAS and\ndevelop additive noise models (ANMs) for genetic causation analysis. Type I\nerror rates and power of the ANMs to test for causation are presented. We\nconduct GWCS of schizophrenia. Both simulation and real data analysis show that\nthe proportion of the overlapped association and causation signals is small.\nThus, we hope that our analysis will stimulate discussion of GWAS and GWCS.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.07789v1"
    },
    {
        "title": "Constructing Semi-Directed Level-1 Phylogenetic Networks from Quarnets",
        "authors": [
            "Sophia Huebler",
            "Rachel Morris",
            "Joseph Rusinko",
            "Yifei Tao"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  We introduce two algorithms for reconstructing semi-directed level-1\nphylogenetic networks from their complete set of 4-leaf subnetworks, known as\nquarnets. The first algorithm, the sequential method, begins with a single\nquarnet and adds on one leaf at a time until all leaves have been placed. The\nsecond algorithm, the cherry-blob method, functions similarly to cherry-picking\nalgorithms for phylogenetic trees by identifying exterior network structures\nfrom the quarnets.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.00048v1"
    },
    {
        "title": "Noncoding RNAs serve as the deadliest regulators for cancer",
        "authors": [
            "Anyou Wang",
            "Hai Rong"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Cancer is one of the leading causes of human death. Many efforts have made to\nunderstand its mechanism and have further identified many proteins and DNA\nsequence variations as suspected targets for therapy. However, drugs targeting\nthese targets have low success rates, suggesting the basic mechanism still\nremains unclear. Here, we develop a computational software combining Cox\nproportional-hazards model and stability-selection to unearth an overlooked,\nyet the most important cancer drivers hidden in massive data from The Cancer\nGenome Atlas (TCGA), including 11,574 RNAseq samples and clinic data.\nGenerally, noncoding RNAs primarily regulate cancer deaths and work as the\ndeadliest cancer inducers and repressors, in contrast to proteins as\nconventionally thought. Especially, processed-pseudogenes serve as the primary\ncancer inducers, while lincRNA and antisense RNAs dominate the repressors.\nStrikingly, noncoding RNAs serves as the universal strongest regulators for all\ncancer types although personal clinic variables such as alcohol and smoking\nsignificantly alter cancer genome. Furthermore, noncoding RNAs also work as\ncentral hubs in cancer regulatory network and as biomarkers to discriminate\ncancer types. Therefore, noncoding RNAs overall serve as the deadliest cancer\nregulators, which refreshes the basic concept of cancer mechanism and builds a\nnovel basis for cancer research and therapy. Biological functions of\npseudogenes have rarely been recognized. Here we reveal them as the most\nimportant cancer drivers for all cancer types from big data, breaking a wall to\nexplore their biological potentials.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.03934v1"
    },
    {
        "title": "Accelerating the Understanding of Life's Code Through Better Algorithms\n  and Hardware Design",
        "authors": [
            "Mohammed H K Alser"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Calculating the similarities between a pair of genomic sequences is one of\nthe most fundamental computational steps in genomic analysis. This step --\ncalled sequence alignment -- is the computational bottleneck because: (1) it is\nimplemented using quadratic-time dynamic programming algorithms and (2) the\nmajority of candidate locations in the reference genome do not align with a\ngiven read due to high dissimilarity. Calculating the alignment of such\nincorrect candidate locations consumes an overwhelming majority of a modern\nread mapper's execution time.\n  In this thesis, we introduce four new algorithms (GateKeeper, Shouji, MAGNET,\nand SneakySnake) that function as a pre-alignment step and aim to filter out\nmost incorrect candidate locations. The first key idea of our pre-alignment\nfilters is to provide high filtering accuracy by correctly detecting all\nsimilar segments shared between two sequences. The second key idea is to\nexploit the massively parallel architecture of modern FPGAs for accelerating\nour filtering algorithms. We also develop an efficient CPU implementation of\nthe SneakySnake algorithm for commodity desktops and servers. We evaluate the\nbenefits and downsides of our pre-alignment filtering approach in detail using\n12 real datasets. In our evaluation, we demonstrate that our hardware\npre-alignment filters show two to three orders of magnitude speedup over their\nequivalent CPU implementations. We also demonstrate that integrating our\nhardware pre-alignment filters with the state-of-the-art read aligners reduces\nthe aligner's execution time by up to 21.5x. Finally, we show that efficient\nCPU implementation of pre-alignment filtering still provides significant\nbenefits. We show that SneakySnake on average reduces the execution time of the\nbest performing CPU-based read aligners Edlib and Parasail, by up to 43x and\n57.9x, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.03936v1"
    },
    {
        "title": "Fast Processing and Querying of 170TB of Genomics Data via a Repeated\n  And Merged BloOm Filter (RAMBO)",
        "authors": [
            "Gaurav Gupta",
            "Minghao Yan",
            "Benjamin Coleman",
            "Bryce Kille",
            "R. A. Leo Elworth",
            "Tharun Medini",
            "Todd Treangen",
            "Anshumali Shrivastava"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  DNA sequencing, especially of microbial genomes and metagenomes, has been at\nthe core of recent research advances in large-scale comparative genomics. The\ndata deluge has resulted in exponential growth in genomic datasets over the\npast years and has shown no sign of slowing down. Several recent attempts have\nbeen made to tame the computational burden of sequence search on these terabyte\nand petabyte-scale datasets, including raw reads and assembled genomes.\nHowever, no known implementation provides both fast query and construction\ntime, keeps the low false-positive requirement, and offers cheap storage of the\ndata structure. We propose a data structure for search called RAMBO (Repeated\nAnd Merged BloOm Filter) which is significantly faster in query time than\nstate-of-the-art genome indexing methods- COBS (Compact bit-sliced signature\nindex), Sequence Bloom Trees, HowDeSBT, and SSBT. Furthermore, it supports\ninsertion and query process parallelism, cheap updates for streaming inputs,\nhas a zero false-negative rate, a low false-positive rate, and a small index\nsize. RAMBO converts the search problem into set membership testing among $K$\ndocuments. Interestingly, it is a count-min sketch type arrangement of a\nmembership testing utility (Bloom Filter in our case). The simplicity of the\nalgorithm and embarrassingly parallel architecture allows us to stream and\nindex a 170TB whole-genome sequence dataset in a mere 9 hours on a cluster of\n100 nodes while competing methods require weeks.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.04358v4"
    },
    {
        "title": "Incorporating biological structure into machine learning models in\n  biomedicine",
        "authors": [
            "Jake Crawford",
            "Casey S. Greene"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In biomedical applications of machine learning, relevant information often\nhas a rich structure that is not easily encoded as real-valued predictors.\nExamples of such data include DNA or RNA sequences, gene sets or pathways, gene\ninteraction or coexpression networks, ontologies, and phylogenetic trees. We\nhighlight recent examples of machine learning models that use structure to\nconstrain model architecture or incorporate structured data into model\ntraining. For machine learning in biomedicine, where sample size is limited and\nmodel interpretability is critical, incorporating prior knowledge in the form\nof structured data can be particularly useful. The area of research would\nbenefit from performant open source implementations and independent\nbenchmarking efforts.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.06738v1"
    },
    {
        "title": "Technology dictates algorithms: Recent developments in read alignment",
        "authors": [
            "Mohammed Alser",
            "Jeremy Rotman",
            "Kodi Taraszka",
            "Huwenbo Shi",
            "Pelin Icer Baykal",
            "Harry Taegyun Yang",
            "Victor Xue",
            "Sergey Knyazev",
            "Benjamin D. Singer",
            "Brunilda Balliu",
            "David Koslicki",
            "Pavel Skums",
            "Alex Zelikovsky",
            "Can Alkan",
            "Onur Mutlu",
            "Serghei Mangul"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Massively parallel sequencing techniques have revolutionized biological and\nmedical sciences by providing unprecedented insight into the genomes of humans,\nanimals, and microbes. Modern sequencing platforms generate enormous amounts of\ngenomic data in the form of nucleotide sequences or reads. Aligning reads onto\nreference genomes enables the identification of individual-specific genetic\nvariants and is an essential step of the majority of genomic analysis\npipelines. Aligned reads are essential for answering important biological\nquestions, such as detecting mutations driving various human diseases and\ncomplex traits as well as identifying species present in metagenomic samples.\nThe read alignment problem is extremely challenging due to the large size of\nanalyzed datasets and numerous technological limitations of sequencing\nplatforms, and researchers have developed novel bioinformatics algorithms to\ntackle these difficulties. Importantly, computational algorithms have evolved\nand diversified in accordance with technological advances, leading to todays\ndiverse array of bioinformatics tools. Our review provides a survey of\nalgorithmic foundations and methodologies across 107 alignment methods\npublished between 1988 and 2020, for both short and long reads. We provide\nrigorous experimental evaluation of 11 read aligners to demonstrate the effect\nof these underlying algorithms on speed and efficiency of read aligners. We\nseparately discuss how longer read lengths produce unique advantages and\nlimitations to read alignment techniques. We also discuss how general alignment\nalgorithms have been tailored to the specific needs of various domains in\nbiology, including whole transcriptome, adaptive immune repertoire, and human\nmicrobiome studies.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.00110v3"
    },
    {
        "title": "Genotyping coronavirus SARS-CoV-2: methods and implications",
        "authors": [
            "Changchuan Yin"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The emerging global infectious COVID-19 coronavirus disease by novel Severe\nAcute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) presents critical threats\nto global public health and the economy since it was identified in late\nDecember 2019 in China. The virus has gone through various pathways of\nevolution. For understanding the evolution and transmission of SARS-CoV-2,\ngenotyping of virus isolates is of great importance. We present an accurate\nmethod for effectively genotyping SARS-CoV-2 viruses using complete genomes.\nThe method employs the multiple sequence alignments of the genome isolates with\nthe SARS-CoV-2 reference genome. The SNP genotypes are then measured by Jaccard\ndistances to track the relationship of virus isolates. The genotyping analysis\nof SARS-CoV-2 isolates from the globe reveals that specific multiple mutations\nare the predominated mutation type during the current epidemic. Our method\nserves a promising tool for monitoring and tracking the epidemic of pathogenic\nviruses in their gradual and local genetic variations. The genotyping analysis\nshows that the genes encoding the S proteins and RNA polymerase, RNA primase,\nand nucleoprotein, undergo frequent mutations. These mutations are critical for\nvaccine development in disease control.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.10965v1"
    },
    {
        "title": "Genomics-guided molecular maps of coronavirus targets in human cells: a\n  path toward the repurposing of existing drugs to mitigate the pandemic",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Human genes required for SARS-CoV-2 entry into human cells, ACE2 and FURIN,\nwere employed as baits to build genomics-guided maps of up-stream regulatory\nelements, their expression and functions in human body, including\npathophysiologically-relevant cell types. Genes acting as repressors and\nactivators of the ACE2 and FURIN genes were identified based on the analyses of\ngene silencing and overexpression experiments as well as relevant transgenic\nmouse models. Panels of repressors (VDR; GATA5; SFTPC; HIF1a) and activators\n(HMGA2; INSIG1) were then employed to identify existing drugs that could be\nrepurposed to mitigate the coronavirus infection. Present analyses identify\nVitamin D and Quercetin as promising pandemic mitigation agents. Gene\nexpression profiles of Vitamin D and Quercetin activities and their established\nsafety records as over-the-counter medicinal substances suggest that they may\nrepresent viable candidates for further assessment and considerations of their\npotential as coronavirus pandemic mitigation agents. Notably, gene set\nenrichment analyses and expression profiling experiments identify multiple\ndrugs, most notably testosterone, dexamethasone, and doxorubicin, smoking, and\nmany disease conditions that appear to act as putative coronavirus\ninfection-promoting agents. Discordant patterns of Testosterone versus\nEstradiol impacts on SCARS-CoV-2 targets suggest a plausible molecular\nexplanation of the apparently higher male mortality during coronavirus\npandemic.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.13665v1"
    },
    {
        "title": "Computational Performance of a Germline Variant Calling Pipeline for\n  Next Generation Sequencing",
        "authors": [
            "Jie Liu",
            "Xiaotian Wu",
            "Kai Zhang",
            "Bing Liu",
            "Renyi Bao",
            "Xiao Chen",
            "Yiran Cai",
            "Yiming Shen",
            "Xinjun He",
            "Jun Yan",
            "Weixing Ji"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  With the booming of next generation sequencing technology and its\nimplementation in clinical practice and life science research, the need for\nfaster and more efficient data analysis methods becomes pressing in the field\nof sequencing. Here we report on the evaluation of an optimized germline\nmutation calling pipeline, HummingBird, by assessing its performance against\nthe widely accepted BWA-GATK pipeline. We found that the HummingBird pipeline\ncan significantly reduce the running time of the primary data analysis for\nwhole genome sequencing and whole exome sequencing while without significantly\nsacrificing the variant calling accuracy. Thus, we conclude that expansion of\nsuch software usage will help to improve the primary data analysis efficiency\nfor next generation sequencing.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.00991v1"
    },
    {
        "title": "Characterizing Halloumi cheese bacterial communities through metagenomic\n  analysis",
        "authors": [
            "Eleni Kamilari",
            "Dimitrios A. Anagnostopoulos",
            "Photis Papademas",
            "Andreas Kamilaris",
            "Dimitris Tsaltas"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Halloumi is a semi hard cheese produced in Cyprus for centuries and its\npopularity has significantly risen over the past years. High throughput\nsequencing (HTS) was applied in the present research to characterize\ntraditional Cyprus Halloumi bacterial diversity. Eighteen samples made by\ndifferent milk mixtures and produced in different areas of the country were\nanalyzed, to reveal that Halloumi microbiome was mainly comprised by lactic\nacid bacteria (LAB), including Lactobacillus, Leuconostoc, and Pediococcus, as\nwell as halophilic bacteria, such as Marinilactibacillus and Halomonas.\nAdditionally, spore forming bacteria and spoilage bacteria, were also detected.\nHalloumi produced with the traditional method, had significantly richer\nbacterial diversity compared to Halloumi produced with the industrial method.\nVariations detected among the bacterial communities highlight the contribution\nof the initial microbiome that existed in milk and survived pasteurization, as\nwell as factors associated with Halloumi manufacturing conditions, in the final\nmicrobiota composition shaping. Identification and characterization of Halloumi\nmicrobiome provides an additional, useful tool to characterize its typicity and\nprobably safeguard it from fraud products that may appear in the market. Also,\nit may assist producers to further improve its quality and guarantee consumers\nsafety.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01710v1"
    },
    {
        "title": "PolyLinkR: A linkage-sensitive gene set enrichment R package",
        "authors": [
            "Raymond Tobler",
            "Angad Johar",
            "Christian Huber",
            "Yassine Souilmi"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  We introduce PolyLinkR, an R package for gene set enrichment analysis that\nimplements a novel null-model that accounts for linkage disequilibrium between\ngenes belonging to the same gene set - a potential cause of false positives\nthat is often not controlled for in similar tools. Our benchmarks show that\nPolyLinkR has improved performance compared to two similar tools, achieving\ncomparable power to detect enriched gene sets while producing less than one\nfalsely detected gene set on average, even at high genetic clustering levels\nand nominal false discovery rates of 20%.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.03224v1"
    },
    {
        "title": "Computational Drug Repositioning and Elucidation of Mechanism of Action\n  of Compounds against SARS-CoV-2",
        "authors": [
            "Francesco Napolitano",
            "Gennaro Gambardella",
            "Diego Carrella",
            "Xin Gao",
            "Diego di Bernardo"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The COVID-19 crisis called for rapid reaction from all the fields of\nbiomedical research. Traditional drug development involves time consuming\npipelines that conflict with the urgence of identifying effective therapies\nduring a health and economic emergency. Drug repositioning, that is the\ndiscovery of new clinical applications for drugs already approved for different\ntherapeutic contexts, could provide an effective shortcut to bring COVID-19\ntreatments to the bedside in a timely manner. Moreover, computational\napproaches can help accelerate the process even further. Here we present the\napplication of computational drug repositioning tools based on transcriptomics\ndata to identify drugs that are potentially able to counteract SARS-CoV-2\ninfection, and also to provide insights on their mode of action. We believe\nthat mucolytics and HDAC inhibitors warrant further investigation. In addition,\nwe found that the DNA Mismatch repair pathway is strongly modulated by drugs\nwith experimental in vitro activity against SARS-CoV-2 infection. Both full\nresults and methods are publicly available.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.07697v2"
    },
    {
        "title": "Addressing Ancestry Disparities in Genomic Medicine: A Geographic-aware\n  Algorithm",
        "authors": [
            "Daniel Mas Montserrat",
            "Arvind Kumar",
            "Carlos Bustamante",
            "Alexander Ioannidis"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  With declining sequencing costs a promising and affordable tool is emerging\nin cancer diagnostics: genomics. By using association studies, genomic variants\nthat predispose patients to specific cancers can be identified, while by using\ntumor genomics cancer types can be characterized for targeted treatment.\nHowever, a severe disparity is rapidly emerging in this new area of precision\ncancer diagnosis and treatment planning, one which separates a few genetically\nwell-characterized populations (predominantly European) from all other global\npopulations. Here we discuss the problem of population-specific genetic\nassociations, which is driving this disparity, and present a novel\nsolution--coordinate-based local ancestry--for helping to address it. We\ndemonstrate our boosting-based method on whole genome data from divergent\ngroups across Africa and in the process observe signals that may stem from the\ntranscontinental Bantu-expansion.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.12053v1"
    },
    {
        "title": "Decoding SARS-CoV-2 transmission, evolution and ramification on COVID-19\n  diagnosis, vaccine, and medicine",
        "authors": [
            "Rui Wang",
            "Yuta Hozumi",
            "Changchuan Yin",
            "Guo-Wei Wei"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Tremendous effort has been given to the development of diagnostic tests,\npreventive vaccines, and therapeutic medicines for coronavirus disease 2019\n(COVID-19) caused by severe acute respiratory syndrome coronavirus 2\n(SARS-CoV-2). Much of this development has been based on the reference genome\ncollected on January 5, 2020. Based on the genotyping of 6156 genome samples\ncollected up to April 24, 2020, we report that SARS-CoV-2 has had 4459\nalarmingly mutations which can be clustered into five subtypes. We introduce\nmutation ratio and mutation $h$-index to characterize the protein\nconservativeness and unveil that SARS-CoV-2 envelope protein, main protease,\nand endoribonuclease protein are relatively conservative, while SARS-CoV-2\nnucleocapsid protein, spike protein, and papain-like protease are relatively\nnon-conservative. In particular, the nucleocapsid protein has more than half\nits genes changed in the past few months, signaling devastating impacts on the\nongoing development of COVID-19 diagnosis, vaccines, and drugs.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.14114v1"
    },
    {
        "title": "Computational methods for cancer driver discovery: A survey",
        "authors": [
            "Vu Viet Hoang Pham",
            "Lin Liu",
            "Cameron Bracken",
            "Gregory Goodall",
            "Jiuyong Li",
            "Thuc Duy Le"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Motivation: Uncovering the genomic causes of cancer, known as cancer driver\ngenes, is a fundamental task in biomedical research. Cancer driver genes drive\nthe development and progression of cancer, thus identifying cancer driver genes\nand their regulatory mechanism is crucial to the design of cancer treatment and\nintervention. Many computational methods, which take the advantages of computer\nscience and data science, have been developed to utilise multiple types of\ngenomic data to reveal cancer drivers and their regulatory mechanism behind\ncancer development and progression. Due to the complexity of the mechanistic\ninsight of cancer genes in driving cancer and the fast development of the\nfield, it is necessary to have a comprehensive review about the current\ncomputational methods for discovering different types of cancer drivers.\nResults: We survey computational methods for identifying cancer drivers from\ngenomic data. We categorise the methods into three groups, methods for single\ndriver identification, methods for driver module identification, and methods\nfor identifying personalised cancer drivers. We also conduct a case study to\ncompare the performance of the current methods. We further analyse the\nadvantages and limitations of the current methods, and discuss the challenges\nand future directions of the topic. In addition, we investigate the resources\nfor discovering and validating cancer drivers in order to provide a one-stop\nreference of the tools to facilitate cancer driver discovery. The ultimate goal\nof the paper is to help those interested in the topic to establish a solid\nbackground to carry out further research in the field.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.00887v1"
    },
    {
        "title": "Approximate Search for Known Gene Clusters in New Genomes Using PQ-Trees",
        "authors": [
            "G. R. Zimerman",
            "D. Svetlitsky",
            "M. Zehavi",
            "M. Ziv-Ukelson"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  We define a new problem in comparative genomics, denoted PQ-Tree Search, that\ntakes as input a PQ-tree $T$ representing the known gene orders of a gene\ncluster of interest, a gene-to-gene substitution scoring function $h$, integer\nparameters $d_T$ and $d_S$, and a new genome $S$. The objective is to identify\nin $S$ approximate new instances of the gene cluster that could vary from the\nknown gene orders by genome rearrangements that are constrained by $T$, by gene\nsubstitutions that are governed by $h$, and by gene deletions and insertions\nthat are bounded from above by $d_T$ and $d_S$, respectively. We prove that the\nPQ-Tree Search problem is NP-hard and propose a parameterized algorithm that\nsolves the optimization variant of PQ-Tree Search in $O^*(2^{\\gamma})$ time,\nwhere $\\gamma$ is the maximum degree of a node in $T$ and $O^*$ is used to hide\nfactors polynomial in the input size. The algorithm is implemented as a search\ntool, denoted PQFinder, and applied to search for instances of chromosomal gene\nclusters in plasmids, within a dataset of 1,487 prokaryotic genomes. We report\non 29 chromosomal gene clusters that are rearranged in plasmids, where the\nrearrangements are guided by the corresponding PQ-tree. One of these results,\ncoding for a heavy metal efflux pump, is further analysed to exemplify how\nPQFinder can be harnessed to reveal interesting new structural variants of\nknown gene clusters. The code for the tool as well as all the data needed to\nreconstruct the results are publicly available on GitHub\n(github.com/GaliaZim/PQFinder).\n",
        "pdf_link": "http://arxiv.org/pdf/2007.03589v1"
    },
    {
        "title": "i6mA-CNN: a convolution based computational approach towards\n  identification of DNA N6-methyladenine sites in rice genome",
        "authors": [
            "Ruhul Amin",
            "Chowdhury Rafeed Rahman",
            "Md. Sadrul Islam Toaha",
            "Swakkhar Shatabda"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  DNA N6-methylation (6mA) in Adenine nucleotide is a post replication\nmodification and is responsible for many biological functions. Experimental\nmethods for genome wide 6mA site detection is an expensive and manual labour\nintensive process. Automated and accurate computational methods can help to\nidentify 6mA sites in long genomes saving significant time and money. Our study\ndevelops a convolutional neural network based tool i6mA-CNN capable of\nidentifying 6mA sites in the rice genome. Our model coordinates among multiple\ntypes of features such as PseAAC inspired customized feature vector, multiple\none hot representations and dinucleotide physicochemical properties. It\nachieves area under the receiver operating characteristic curve of 0.98 with an\noverall accuracy of 0.94 using 5 fold cross validation on benchmark dataset.\nFinally, we evaluate our model on two other plant genome 6mA site\nidentification datasets besides rice. Results suggest that our proposed tool is\nable to generalize its ability of 6mA site identification on plant genomes\nirrespective of plant species. Web tool for this research can be found at:\nhttps://cutt.ly/Co6KuWG. Supplementary data (benchmark dataset, independent\ntest dataset, comparison purpose dataset, trained model, physicochemical\nproperty values, attention mechanism details for motif finding) are available\nat https://cutt.ly/PpDdeDH.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.10458v2"
    },
    {
        "title": "Characterizing SARS-CoV-2 mutations in the United States",
        "authors": [
            "Rui Wang",
            "Jiahui Chen",
            "Kaifu Gao",
            "Yuta Hozumi",
            "Changchuan Yin",
            "Guo-Wei Wei"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has been\nmutating since it was first sequenced in early January 2020. The genetic\nvariants have developed into a few distinct clusters with different properties.\nSince the United States (US) has the highest number of viral infected patients\nglobally, it is essential to understand the US SARS-CoV-2. Using genotyping,\nsequence-alignment, time-evolution, $k$-means clustering, protein-folding\nstability, algebraic topology, and network theory, we reveal that the US\nSARS-CoV-2 has four substrains and five top US SARS-CoV-2 mutations were first\ndetected in China (2 cases), Singapore (2 cases), and the United Kingdom (1\ncase). The next three top US SARS-CoV-2 mutations were first detected in the\nUS. These eight top mutations belong to two disconnected groups. The first\ngroup consisting of 5 concurrent mutations is prevailing, while the other group\nwith three concurrent mutations gradually fades out. Our analysis suggests that\nfemale immune systems are more active than those of males in responding to\nSARS-CoV-2 infections. We identify that one of the top mutations,\n27964C$>$T-(S24L) on ORF8, has an unusually strong gender dependence. Based on\nthe analysis of all mutations on the spike protein, we further uncover that\nthree of four US SASR-CoV-2 substrains become more infectious. Our study calls\nfor effective viral control and containing strategies in the US.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.12692v1"
    },
    {
        "title": "Deep Neural Network: An Efficient and Optimized Machine Learning\n  Paradigm for Reducing Genome Sequencing Error",
        "authors": [
            "Ferdinand Kartriku",
            "Robert Sowah",
            "Charles Saah"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genomic data I used in many fields but, it has become known that most of the\nplatforms used in the sequencing process produce significant errors. This means\nthat the analysis and inferences generated from these data may have some errors\nthat need to be corrected. On the two main types of genome errors -\nsubstitution and indels - our work is focused on correcting indels. A deep\nlearning approach was used to correct the errors in sequencing the chosen\ndataset\n",
        "pdf_link": "http://arxiv.org/pdf/2010.03420v1"
    },
    {
        "title": "Survival prediction and risk estimation of Glioma patients using mRNA\n  expressions",
        "authors": [
            "Navodini Wijethilake",
            "Dulani Meedeniya",
            "Charith Chitraranjan",
            "Indika Perera"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Gliomas are lethal type of central nervous system tumors with a poor\nprognosis. Recently, with the advancements in the micro-array technologies\nthousands of gene expression related data of glioma patients are acquired,\nleading for salient analysis in many aspects. Thus, genomics are been emerged\ninto the field of prognosis analysis. In this work, we identify survival\nrelated 7 gene signature and explore two approaches for survival prediction and\nrisk estimation. For survival prediction, we propose a novel probabilistic\nprogramming based approach, which outperforms the existing traditional machine\nlearning algorithms. An average 4 fold accuracy of 74% is obtained with the\nproposed algorithm. Further, we construct a prognostic risk model for risk\nestimation of glioma patients. This model reflects the survival of glioma\npatients, with high risk for low survival patients.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.00659v1"
    },
    {
        "title": "Stratification of Systemic Lupus Erythematosus Patients Using Gene\n  Expression Data to Reveal Expression of Distinct Immune Pathways",
        "authors": [
            "Aditi Deokar"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Systemic lupus erythematosus (SLE) is the tenth leading cause of death in\nfemales 15-24 years old in the US. The diversity of symptoms and immune\npathways expressed in SLE patients causes difficulties in treating SLE as well\nas in new clinical trials. This study used unsupervised learning on gene\nexpression data from adult SLE patients to separate patients into clusters. The\ndimensionality of the gene expression data was reduced by three separate\nmethods (PCA, UMAP, and a simple linear autoencoder) and the results from each\nof these methods were used to separate patients into six clusters with k-means\nclustering.\n  The clusters revealed three separate immune pathways in the SLE patients that\ncaused SLE. These pathways were: (1) high interferon levels, (2) high\nautoantibody levels, and (3) dysregulation of the mitochondrial apoptosis\npathway. The first two pathways have been extensively studied in SLE. However,\nmitochondrial apoptosis has not been investigated before to the best of our\nknowledge as a standalone cause of SLE, independent of autoantibody production,\nindicating that mitochondrial proteins could lead to a new set of therapeutic\ntargets for SLE in future research.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.05143v1"
    },
    {
        "title": "The MAPT gene is differentially methylated in the progressive\n  supranuclear palsy brain",
        "authors": [
            "Vincent Huin",
            "Vincent Deramecourt",
            "Dominique Caparros-Lefebvre",
            "Claude-Alain Maurage",
            "Charles Duyckaerts",
            "Eniko Kovari",
            "Florence Pasquier",
            "Valérie Buée-Scherrer",
            "Julien Labreuche",
            "Hélène Behal",
            "Luc Buée",
            "Claire-Marie Dhaenens",
            "Bernard Sablonnière"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Background: Progressive supranuclear palsy (PSP) is a rare neurodegenerative\ndisease causing parkinsonian symptoms. Altered DNA methylation of the\nmicrotubule-associated protein tau gene correlates with the expression changes\nin Alzheimer's disease and Parkinson's disease brains. However, few studies\nexamine the sequences beyond the constitutive promoter.Objectives: Because\nactivating different microtubule associated protein tau gene control regions\nvia methylation might regulate the differential tau expression constituting the\nspecific signatures of individual tauopathies, we compared methylation of a\ncandidate promoter, intron 0.Methods: We assessed DNA methylation in the brains\nof patients with different tauopathies (35 Alzheimer's disease, 10 corticobasal\ndegeneration, and 18 PSP) and 19 controls by intron 0 pyrosequencing. We also\nevaluated methylation in an independent cohort of 11 PSP cases and 12 controls.\nFrontal (affected by tau pathology) and occipital (unaffected) cortices were\nanalyzed.Results: In the initial samples, one CpG island site in intron 0\n(CpG1) showed significant hypomethylation in PSP-affected frontal cortices when\ncompared with controls (p = 0.022). Such hypomethylation was observed in\nreplicate samples, but not in occipital cortices or other tauopathies. PSP and\ncontrol samples (combining the initial and replicate samples) remained\nsignificantly different after adjustment for potential confounding factors\n(age, H1/H1 diplotype; p = 0.0005). PSP-affected tissues exhibited\nmicrotubule-associated protein tau RNA hyperexpression when compared with\ncontrols (p = 0.004), although no correlation with CpG1 methylation was\nobserved.Conclusions: This exploratory study suggests that regions other than\nthe constitutive promoter may be involved in microtubule-associated protein tau\ngene regulation in tauopathies and that intron 0 hypomethylation may be a\nspecific epigenetic signature of PSP. These preliminary findings require\nconfirmation.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10447v1"
    },
    {
        "title": "Using ontology embeddings for structural inductive bias in gene\n  expression data analysis",
        "authors": [
            "Maja Trębacz",
            "Zohreh Shams",
            "Mateja Jamnik",
            "Paul Scherer",
            "Nikola Simidjievski",
            "Helena Andres Terre",
            "Pietro Liò"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Stratifying cancer patients based on their gene expression levels allows\nimproving diagnosis, survival analysis and treatment planning. However, such\ndata is extremely highly dimensional as it contains expression values for over\n20000 genes per patient, and the number of samples in the datasets is low. To\ndeal with such settings, we propose to incorporate prior biological knowledge\nabout genes from ontologies into the machine learning system for the task of\npatient classification given their gene expression data. We use ontology\nembeddings that capture the semantic similarities between the genes to direct a\nGraph Convolutional Network, and therefore sparsify the network connections. We\nshow this approach provides an advantage for predicting clinical targets from\nhigh-dimensional low-sample data.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10998v1"
    },
    {
        "title": "Topological Data Analysis of copy number alterations in cancer",
        "authors": [
            "Stefan Groha",
            "Caroline Weis",
            "Alexander Gusev",
            "Bastian Rieck"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Identifying subgroups and properties of cancer biopsy samples is a crucial\nstep towards obtaining precise diagnoses and being able to perform personalized\ntreatment of cancer patients. Recent data collections provide a comprehensive\ncharacterization of cancer cell data, including genetic data on copy number\nalterations (CNAs). We explore the potential to capture information contained\nin cancer genomic information using a novel topology-based approach that\nencodes each cancer sample as a persistence diagram of topological features,\ni.e., high-dimensional voids represented in the data. We find that this\ntechnique has the potential to extract meaningful low-dimensional\nrepresentations in cancer somatic genetic data and demonstrate the viability of\nsome applications on finding substructures in cancer data as well as comparing\nsimilarity of cancer types.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.11070v2"
    },
    {
        "title": "A robust and generalizable immune-relatedsignature for sepsis\n  diagnostics",
        "authors": [
            "Yueran Yang",
            "Yu Zhang",
            "Shuai Li",
            "Xubin Zheng",
            "Man-Hon Wong",
            "Kwong-Sak Leung",
            "Lixin Cheng"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  High-throughput sequencing can detect tens of thousands of genes in parallel,\nproviding opportunities for improving the diagnostic accuracy of multiple\ndiseases including sepsis, which is an aggressive inflammatory response to\ninfection that can cause organ failure and death. Early screening of sepsis is\nessential in clinic, but no effective diagnostic biomarkers are available yet.\nHere, we present a novel method, Recurrent Logistic Regression, to identify\ndiagnostic biomarkers for sepsis from the blood transcriptome data. A panel\nincluding five immune-related genes, LRRN3, IL2RB, FCER1A, TLR5, and S100A12,\nare determined as diagnostic biomarkers (LIFTS) for sepsis. LIFTS discriminates\npatients with sepsis from normal controls in high accuracy (AUROC = 0.9959 on\naverage; IC = [0.9722-1.0]) on nine validation cohorts across three independent\nplatforms, which outperforms existing markers. Our analysis determined an\naccurate prediction model and reproducible transcriptome biomarkers that can\nlay a foundation for clinical diagnostic tests and biological mechanistic\nstudies.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.11343v3"
    },
    {
        "title": "Large-scale machine learning-based phenotyping significantly improves\n  genomic discovery for optic nerve head morphology",
        "authors": [
            "Babak Alipanahi",
            "Farhad Hormozdiari",
            "Babak Behsaz",
            "Justin Cosentino",
            "Zachary R. McCaw",
            "Emanuel Schorsch",
            "D. Sculley",
            "Elizabeth H. Dorfman",
            "Sonia Phene",
            "Naama Hammel",
            "Andrew Carroll",
            "Anthony P. Khawaja",
            "Cory Y. McLean"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genome-wide association studies (GWAS) require accurate cohort phenotyping,\nbut expert labeling can be costly, time-intensive, and variable. Here we\ndevelop a machine learning (ML) model to predict glaucomatous optic nerve head\nfeatures from color fundus photographs. We used the model to predict vertical\ncup-to-disc ratio (VCDR), a diagnostic parameter and cardinal endophenotype for\nglaucoma, in 65,680 Europeans in the UK Biobank (UKB). A GWAS of ML-based VCDR\nidentified 299 independent genome-wide significant (GWS; $P\\leq5\\times10^{-8}$)\nhits in 156 loci. The ML-based GWAS replicated 62 of 65 GWS loci from a recent\nVCDR GWAS in the UKB for which two ophthalmologists manually labeled images for\n67,040 Europeans. The ML-based GWAS also identified 92 novel loci,\nsignificantly expanding our understanding of the genetic etiologies of glaucoma\nand VCDR. Pathway analyses support the biological significance of the novel\nhits to VCDR, with select loci near genes involved in neuronal and synaptic\nbiology or known to cause severe Mendelian ophthalmic disease. Finally, the\nML-based GWAS results significantly improve polygenic prediction of VCDR and\nprimary open-angle glaucoma in the independent EPIC-Norfolk cohort.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.13012v1"
    },
    {
        "title": "Deep Unsupervised Identification of Selected SNPs between Adapted\n  Populations on Pool-seq Data",
        "authors": [
            "Julia Siekiera",
            "Stefan Kramer"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The exploration of selected single nucleotide polymorphisms (SNPs) to\nidentify genetic diversity between different sequencing population pools\n(Pool-seq) is a fundamental task in genetic research. As underlying sequence\nreads and their alignment are error-prone and univariate statistical solutions\nonly take individual positions of the genome into account, the identification\nof selected SNPs remains a challenging process. Deep learning models like\nconvolutional neural networks (CNNs) are able to consider large input areas in\ntheir decisions. We suggest an unsupervised pipeline to be independent of a\nrarely known ground truth. We train a supervised discriminator CNN to\ndistinguish alignments from different populations and utilize the model for\nunsupervised SNP calling by applying explainable artificial intelligence\nmethods. Our proposed multivariate method is based on two main assumptions: We\nassume (i) that instances having a high predictive certainty of being\ndistinguishable are likely to contain genetic variants, and (ii) that selected\nSNPs are located at regions with input features having the highest influence on\nthe model's decision process. We directly compare our method with statistical\nresults on two different Pool-seq datasets and show that our solution is able\nto extend statistical results.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00004v1"
    },
    {
        "title": "Segmentation and genome annotation algorithms",
        "authors": [
            "Maxwell W Libbrecht",
            "Rachel CW Chan",
            "Michael M Hoffman"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Segmentation and genome annotation (SAGA) algorithms are widely used to\nunderstand genome activity and gene regulation. These algorithms take as input\nepigenomic datasets, such as chromatin immunoprecipitation-sequencing\n(ChIP-seq) measurements of histone modifications or transcription factor\nbinding. They partition the genome and assign a label to each segment such that\npositions with the same label exhibit similar patterns of input data. SAGA\nalgorithms discover categories of activity such as promoters, enhancers, or\nparts of genes without prior knowledge of known genomic elements. In this\nsense, they generally act in an unsupervised fashion like clustering\nalgorithms, but with the additional simultaneous function of segmenting the\ngenome. Here, we review the common methodological framework that underlies\nthese methods, review variants of and improvements upon this basic framework,\ncatalogue existing large-scale reference annotations, and discuss the outlook\nfor future work.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00688v1"
    },
    {
        "title": "Computer Architecture-Aware Optimisation of DNA Analysis Systems",
        "authors": [
            "Hasindu Gamaarachchi"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  DNA sequencing is revolutionising the field of medicine. DNA sequencers, the\nmachines which perform DNA sequencing, have evolved from the size of a fridge\nto that of a mobile phone over the last two decades. The cost of sequencing a\nhuman genome also has reduced from billions of dollars to hundreds of dollars.\nDespite these improvements, DNA sequencers output hundreds or thousands of\ngigabytes of data that must be analysed on computers to discover meaningful\ninformation with biological implications. Unfortunately, the analysis\ntechniques have not kept the pace with rapidly improving sequencing\ntechnologies. Consequently, even today, the process of DNA analysis is\nperformed on high-performance computers, just as it was a couple of decades\nago. Such high-performance computers are not portable. Consequently, the full\nutility of an ultra-portable sequencer for sequencing in-the-field or at the\npoint-of-care is limited by the lack of portable lightweight analytic\ntechniques. This thesis proposes computer architecture-aware optimisation of\nDNA analysis software. DNA analysis software is inevitably convoluted due to\nthe complexity associated with biological data. Modern computer architectures\nare also complex. Performing architecture-aware optimisations requires the\nsynergistic use of knowledge from both domains, (i.e, DNA sequence analysis and\ncomputer architecture). This thesis aims to draw the two domains together. In\nthis thesis, gold-standard DNA sequence analysis workflows are systematically\nexamined for algorithmic components that cause performance bottlenecks.\nIdentified bottlenecks are resolved through architecture-aware optimisations at\ndifferent levels, i.e., memory, cache, register and processor. The optimised\nsoftware tools are used in complete end-to-end analysis workflows and their\nefficacy is demonstrated by running on prototypical embedded systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05012v1"
    },
    {
        "title": "Feature reduction for machine learning on molecular features: The\n  GeneScore",
        "authors": [
            "Alexander Denker",
            "Anastasia Steshina",
            "Theresa Grooss",
            "Frank Ueckert",
            "Sylvia Nürnberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We present the GeneScore, a concept of feature reduction for Machine Learning\nanalysis of biomedical data. Using expert knowledge, the GeneScore integrates\ndifferent molecular data types into a single score. We show that the GeneScore\nis superior to a binary matrix in the classification of cancer entities from\nSNV, Indel, CNV, gene fusion and gene expression data. The GeneScore is a\nstraightforward way to facilitate state-of-the-art analysis, while making use\nof the available scientific knowledge on the nature of molecular data features\nused.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05546v1"
    },
    {
        "title": "Motif Identification using CNN-based Pairwise Subsequence Alignment\n  Score Prediction",
        "authors": [
            "Ethan Jacob Moyer",
            "Anup Das"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  A common problem in bioinformatics is related to identifying gene regulatory\nregions marked by relatively high frequencies of motifs, or deoxyribonucleic\nacid sequences that often code for transcription and enhancer proteins.\nPredicting alignment scores between subsequence k-mers and a given motif\nenables the identification of candidate regulatory regions in a gene, which\ncorrespond to the transcription of these proteins. We propose a one-dimensional\n(1-D) Convolution Neural Network trained on k-mer formatted sequences\ninterspaced with the given motif pattern to predict pairwise alignment scores\nbetween the consensus motif and subsequence k-mers. Our model consists of\nfifteen layers with three rounds of a one-dimensional convolution layer, a\nbatch normalization layer, a dense layer, and a 1-D maximum pooling layer. We\ntrain the model using mean squared error loss on four different data sets each\nwith a different motif pattern randomly inserted in DNA sequences: the first\nthree data sets have zero, one, and two mutations applied on each inserted\nmotif, and the fourth data set represents the inserted motif as a\nposition-specific probability matrix. We use a novel proposed metric in order\nto evaluate the model's performance, $S_{\\alpha}$, which is based on the\nJaccard Index. We use 10-fold cross validation to evaluate out model. Using\n$S_{\\alpha}$, we measure the accuracy of the model by identifying the 15\nhighest-scoring 15-mer indices of the predicted scores that agree with that of\nthe actual scores within a selected $\\alpha$ region. For the best performing\ndata set, our results indicate on average 99.3% of the top 15 motifs were\nidentified correctly within a one base pair stride ($\\alpha = 1$) in the out of\nsample data. To the best of our knowledge, this is a novel approach that\nillustrates how data formatted in an intelligent way can be extrapolated using\nmachine learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.08385v1"
    },
    {
        "title": "Reply: Early-onset phenotype of bi-allelic GRN mutations",
        "authors": [
            "Vincent Huin",
            "Mathieu Barbier",
            "Alexandra Durr",
            "Isabelle Le Ber"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We would like to reply to Neuray et al. who report a series of five new\npatients from four unrelated families with bi-allelic mutations of GRN. Their\nwork nicely completes the few existing reports of similar cases, and refers to\nour recent publication describing six homozygous GRN pathogenic variant\ncarriers with divergent phenotypes and ages at onset (Huin et al., 2020). In\nsummary, the Letter from Neuray et al., reports valuable findings that lead to\nbetter define CLN11 due to bi-allelic GRN pathogenic variants. Despite the\nsmall sample number that does not allow statistical analysis, the authors\nunderlined the occurrence of cognitive deterioration and epilepsy. Further\nstudy of the CLN11 families with functional brain imaging and\nneuropsychological examinations may be highly informative for the understanding\nand the clinical characterization of this rare disease.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.08651v1"
    },
    {
        "title": "Peptipedia: a comprehensive database for peptide research supported by\n  Assembled predictive models and Data Mining approaches",
        "authors": [
            "Cristofer Quiroz",
            "Yasna Barrera Saavedra",
            "Benjamín Armijo-Galdames",
            "Juan Amado-Hinojosa",
            "Álvaro Olivera-Nappa",
            "Anamaria Sanchez-Daza",
            "David Medina-Ortiz"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: Peptides have attracted the attention in this century due to\ntheir remarkable therapeutic properties. Computational tools are being\ndeveloped to take advantage of existing information, encapsulating knowledge\nand making it available in a simple way for general public use. However, these\nare property-specific redundant data systems, and usually do not display the\ndata in a clear way. In some cases, information download is not even possible.\nThis data needs to be available in a simple form for drug design and other\nbiotechnological applications.\n  Results: We developed Peptipedia, a user-friendly database and web\napplication to search, characterise and analyse peptide sequences. Our tool\nintegrates the information from thirty previously reported databases, making it\nthe largest repository of peptides with recorded activities so far. Besides, we\nimplemented a variety of services to increase our tool's usability. The\nsignificant differences of our tools with other existing alternatives becomes a\nsubstantial contribution to develop biotechnological and bioengineering\napplications for peptides.\n  Availability: Peptipedia is available for non-commercial use as an\nopen-access software, licensed under the GNU General Public License, version\nGPL 3.0. The web platform is publicly available at pesb2.cl/peptipedia. Both\nthe source code and sample datasets are available in the GitHub repository\nhttps://github.com/CristoferQ/PeptideDatabase.\n  Contact: david.medina@cebib.cl, ana.sanchez@ing.uchile.cl\n",
        "pdf_link": "http://arxiv.org/pdf/2101.12210v1"
    },
    {
        "title": "White paper: The Helix Pathogenicity Prediction Platform",
        "authors": [
            "Bas Vroling",
            "Stephan Heijl"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  In this white paper we introduce Helix, an AI based solution for missense\npathogenicity prediction. With recent advances in the sequencing of human\ngenomes, massive amounts of genetic data have become available. This has\nshifted the burden of labor for genetic diagnostics and research from the\ngathering of data to its interpretation. Helix presents a state of the art\nplatform for the prediction of pathogenicity in human missense variants. In\naddition to offering best-in-class predictive performance, Helix offers a\nplatform that allows researchers to analyze and interpret variants in depth\nthat can be accessed at helixlabs.ai.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.01033v2"
    },
    {
        "title": "SimCD: Simultaneous Clustering and Differential expression analysis for\n  single-cell transcriptomic data",
        "authors": [
            "Seyednami Niyakan",
            "Ehsan Hajiramezanali",
            "Shahin Boluki",
            "Siamak Zamani Dadaneh",
            "Xiaoning Qian"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Single-Cell RNA sequencing (scRNA-seq) measurements have facilitated\ngenome-scale transcriptomic profiling of individual cells, with the hope of\ndeconvolving cellular dynamic changes in corresponding cell sub-populations to\nbetter understand molecular mechanisms of different development processes.\nSeveral scRNA-seq analysis methods have been proposed to first identify cell\nsub-populations by clustering and then separately perform differential\nexpression analysis to understand gene expression changes. Their corresponding\nstatistical models and inference algorithms are often designed disjointly. We\ndevelop a new method -- SimCD -- that explicitly models cell heterogeneity and\ndynamic differential changes in one unified hierarchical gamma-negative\nbinomial (hGNB) model, allowing simultaneous cell clustering and differential\nexpression analysis for scRNA-seq data. Our method naturally defines cell\nheterogeneity by dynamic expression changes, which is expected to help achieve\nbetter performances on the two tasks compared to the existing methods that\nperform them separately. In addition, SimCD better models dropout (zero\ninflation) in scRNA-seq data by both cell- and gene-level factors and obviates\nthe need for sophisticated pre-processing steps such as normalization, thanks\nto the direct modeling of scRNA-seq count data by the rigorous hGNB model with\nan efficient Gibbs sampling inference algorithm. Extensive comparisons with the\nstate-of-the-art methods on both simulated and real-world scRNA-seq count data\ndemonstrate the capability of SimCD to discover cell clusters and capture\ndynamic expression changes. Furthermore, SimCD helps identify several known\ngenes affected by food deprivation in hypothalamic neuron cell subtypes as well\nas some new potential markers, suggesting the capability of SimCD for\nbio-marker discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.01512v1"
    },
    {
        "title": "Unlocking capacities of viral genomics for the COVID-19 pandemic\n  response",
        "authors": [
            "Sergey Knyazev",
            "Karishma Chhugani",
            "Varuni Sarwal",
            "Ram Ayyala",
            "Harman Singh",
            "Smruthi Karthikeyan",
            "Dhrithi Deshpande",
            "Zoia Comarova",
            "Angela Lu",
            "Yuri Porozov",
            "Aiping Wu",
            "Malak Abedalthagafi",
            "Shivashankar Nagaraj",
            "Adam Smith",
            "Pavel Skums",
            "Jason Ladner",
            "Tommy Tsan-Yuk Lam",
            "Nicholas Wu",
            "Alex Zelikovsky",
            "Rob Knight",
            "Keith Crandall",
            "Serghei Mangul"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  More than any other infectious disease epidemic, the COVID-19 pandemic has\nbeen characterized by the generation of large volumes of viral genomic data at\nan incredible pace due to recent advances in high-throughput sequencing\ntechnologies, the rapid global spread of SARS-CoV-2, and its persistent threat\nto public health. However, distinguishing the most epidemiologically relevant\ninformation encoded in these vast amounts of data requires substantial effort\nacross the research and public health communities. Studies of SARS-CoV-2\ngenomes have been critical in tracking the spread of variants and understanding\nits epidemic dynamics, and may prove crucial for controlling future epidemics\nand alleviating significant public health burdens. Together, genomic data and\nbioinformatics methods enable broad-scale investigations of the spread of\nSARS-CoV-2 at the local, national, and global scales and allow researchers the\nability to efficiently track the emergence of novel variants, reconstruct\nepidemic dynamics, and provide important insights into drug and vaccine\ndevelopment and disease control. Here, we discuss the tremendous opportunities\nthat genomics offers to unlock the effective use of SARS-CoV-2 genomic data for\nefficient public health surveillance and guiding timely responses to COVID-19.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.14005v3"
    },
    {
        "title": "DRIVE: Machine Learning to Identify Drivers of Cancer with\n  High-Dimensional Genomic Data & Imputed Labels",
        "authors": [
            "Adnan Akbar",
            "Andrey Solovyev",
            "John W Cassidy",
            "Nirmesh Patel",
            "Harry W Clifford"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Identifying the mutations that drive cancer growth is key in clinical\ndecision making and precision oncology. As driver mutations confer selective\nadvantage and thus have an increased likelihood of occurrence, frequency-based\nstatistical models are currently favoured. These methods are not suited to\nrare, low frequency, driver mutations. The alternative approach to address this\nis through functional-impact scores, however methods using this approach are\nhighly prone to false positives. In this paper, we propose a novel combination\nmethod for driver mutation identification, which uses the power of both\nstatistical modelling and functional-impact based methods. Initial results show\nthis approach outperforms the state-of-the-art methods in terms of precision,\nand provides comparable performance in terms of area under receiver operating\ncharacteristic curves (AU-ROC). We believe that data-driven systems based on\nmachine learning, such as these, will become an integral part of precision\noncology in the near future.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00469v1"
    },
    {
        "title": "Comparison of machine learning and deep learning techniques in promoter\n  prediction across diverse species",
        "authors": [
            "Nikita Bhandari",
            "Satyajeet Khare",
            "Rahee Walambe",
            "Ketan Kotecha"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Gene promoters are the key DNA regulatory elements positioned around the\ntranscription start sites and are responsible for regulating gene transcription\nprocess. Various alignment-based, signal-based and content-based approaches are\nreported for the prediction of promoters. However, since all promoter sequences\ndo not show explicit features, the prediction performance of these techniques\nis poor. Therefore, many machine learning and deep learning models have been\nproposed for promoter prediction. In this work, we studied methods for vector\nencoding and promoter classification using genome sequences of three distinct\nhigher eukaryotes viz. yeast (Saccharomyces cerevisiae), A. thaliana (plant)\nand human (Homo sapiens). We compared one-hot vector encoding method with\nfrequency-based tokenization (FBT) for data pre-processing on 1-D Convolutional\nNeural Network (CNN) model. We found that FBT gives a shorter input dimension\nreducing the training time without affecting the sensitivity and specificity of\nclassification. We employed the deep learning techniques, mainly CNN and\nrecurrent neural network with Long Short Term Memory (LSTM) and random forest\n(RF) classifier for promoter classification at k-mer sizes of 2, 4 and 8. We\nfound CNN to be superior in classification of promoters from non-promoter\nsequences (binary classification) as well as species-specific classification of\npromoter sequences (multiclass classification). In summary, the contribution of\nthis work lies in the use of synthetic shuffled negative dataset and\nfrequency-based tokenization for pre-processing. This study provides a\ncomprehensive and generic framework for classification tasks in genomic\napplications and can be extended to various classification problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07659v1"
    },
    {
        "title": "GapPredict: A Language Model for Resolving Gaps in Draft Genome\n  Assemblies",
        "authors": [
            "Eric Chen",
            "Justin Chu",
            "Jessica Zhang",
            "Rene L. Warren",
            "Inanc Birol"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Short-read DNA sequencing instruments can yield over 1e+12 bases per run,\ntypically composed of reads 150 bases long. Despite this high throughput, de\nnovo assembly algorithms have difficulty reconstructing contiguous genome\nsequences using short reads due to both repetitive and difficult-to-sequence\nregions in these genomes. Some of the short read assembly challenges are\nmitigated by scaffolding assembled sequences using paired-end reads. However,\nunresolved sequences in these scaffolds appear as \"gaps\". Here, we introduce\nGapPredict, a tool that uses a character-level language model to predict\nunresolved nucleotides in scaffold gaps. We benchmarked GapPredict against the\nstate-of-the-art gap-filling tool Sealer, and observed that the former can fill\n65.6% of the sampled gaps that were left unfilled by the latter, demonstrating\nthe practical utility of deep learning approaches to the gap-filling problem in\ngenome sequence assembly.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10552v2"
    },
    {
        "title": "Predicting the hosts of prokaryotic viruses using GCN-based\n  semi-supervised learning",
        "authors": [
            "Jiayu Shang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: Prokaryotic viruses, which infect bacteria and archaea, are the\nmost abundant and diverse biological entities in the biosphere. To understand\ntheir regulatory roles in various ecosystems and to harness the potential of\nbacteriophages for use in therapy, more knowledge of viral-host relationships\nis required. High-throughput sequencing and its application to the microbiome\nhave offered new opportunities for computational approaches for predicting\nwhich hosts particular viruses can infect. However, there are two main\nchallenges for computational host prediction. First, the empirically known\nvirus-host relationships are very limited. Second, although sequence similarity\nbetween viruses and their prokaryote hosts have been used as a major feature\nfor host prediction, the alignment is either missing or ambiguous in many\ncases. Thus, there is still a need to improve the accuracy of host prediction.\nResults: In this work, we present a semi-supervised learning model, named\nHostG, to conduct host prediction for novel viruses. We construct a knowledge\ngraph by utilizing both virus-virus protein similarity and virus-host DNA\nsequence similarity. Then graph convolutional network (GCN) is adopted to\nexploit viruses with or without known hosts in training to enhance the learning\nability. During the GCN training, we minimize the expected calibrated error\n(ECE) to ensure the confidence of the predictions. We tested HostG on both\nsimulated and real sequencing data and compared its performance with other\nstate-of-the-art methods specifcally designed for virus host classification\n(VHM-net, WIsH, PHP, HoPhage, RaFAH, vHULK, and VPF-Class). Conclusion: HostG\noutperforms other popular methods, demonstrating the efficacy of using a\nGCN-based semi-supervised learning approach. A particular advantage of HostG is\nits ability to predict hosts from new taxa.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.13570v3"
    },
    {
        "title": "DNA-GCN: Graph convolutional networks for predicting DNA-protein binding",
        "authors": [
            "Yuhang Guo",
            "Xiao Luo",
            "Liang Chen",
            "Minghua Deng"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Predicting DNA-protein binding is an important and classic problem in\nbioinformatics. Convolutional neural networks have outperformed conventional\nmethods in modeling the sequence specificity of DNA-protein binding. However,\nnone of the studies has utilized graph convolutional networks for motif\ninference. In this work, we propose to use graph convolutional networks for\nmotif inference. We build a sequence k-mer graph for the whole dataset based on\nk-mer co-occurrence and k-mer sequence relationship and then learn DNA Graph\nConvolutional Network (DNA-GCN) for the whole dataset. Our DNA-GCN is\ninitialized with a one-hot representation for all nodes, and it then jointly\nlearns the embeddings for both k-mers and sequences, as supervised by the known\nlabels of sequences. We evaluate our model on 50 datasets from ENCODE. DNA-GCN\nshows its competitive performance compared with the baseline model. Besides, we\nanalyze our model and design several different architectures to help fit\ndifferent datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.01836v1"
    },
    {
        "title": "There are no valid points of criticism in Tyshkovskiy and Panchin's\n  response (10.1002/bies.202000325) to our paper \"The genetic structure of\n  SARS-CoV-2 does not rule out a laboratory origin\" (DOI:\n  10.1002/bies.202000240)",
        "authors": [
            "Yuri Deigin",
            "Rossana Segreto"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Tyshkovskiy and Panchin have recently published a commentary on our paper in\nwhich they outline several \"points of disagreement with the Segreto/Deigin\nhypothesis\". As our paper is titled \"The genetic structure of SARS-CoV-2 does\nnot rule out a laboratory origin\", points of disagreement should provide\nevidence that rules out a laboratory origin. However, Tyshkovskiy and Panchin\nprovide no such evidence and instead attempt to criticize our arguments that\nhighlight aspects of SARS-CoV-2 that could be consistent with the lab leak\nhypothesis. Strikingly, Tyshkovskiy and Panchin's main point of criticism is\nbased on a false premise that we have claimed RaTG13 to be a direct progenitor\nof SARS-CoV-2, and their other points of criticism are either incorrect or\nirrelevant to our hypotheses. Thus, the genetic structure of SARS-CoV-2 remains\nconsistent with both natural or laboratory origin, which means that both the\nzoonotic and the lab leak hypothesis need to be investigated equally\nthoroughly.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.02020v2"
    },
    {
        "title": "DEMETER: Efficient simultaneous curation of genome-scale reconstructions\n  guided by experimental data and refined gene annotations",
        "authors": [
            "Almut Heinken",
            "Stefanía Magnúsdóttir",
            "Ronan M. T. Fleming",
            "Ines Thiele"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: Manual curation of genome-scale reconstructions is laborious, yet\nexisting automated curation tools typically do not take species-specific\nexperimental data and manually refined genome annotations into account.\nResults: We developed DEMETER, a COBRA Toolbox extension that enables the\nefficient simultaneous refinement of thousands of draft genome-scale\nreconstructions while ensuring adherence to the quality standards in the field,\nagreement with available experimental data, and refinement of pathways based on\nmanually refined genome annotations. Availability: DEMETER and tutorials are\navailable at https://github.com/opencobra/cobratoolbox.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06638v1"
    },
    {
        "title": "GPA-Tree: Statistical Approach for Functional-Annotation-Tree-Guided\n  Prioritization of GWAS Results",
        "authors": [
            "Aastha Khatiwada",
            "Bethany J. Wolf",
            "Ayse Selen Yilmaz",
            "Paula S. Ramos",
            "Maciej Pietrzak",
            "Andrew Lawson",
            "Kelly J. Hunt",
            "Hang J. Kim",
            "Dongjun Chung"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: In spite of great success of genome-wide association studies\n(GWAS), multiple challenges still remain. First, complex traits are often\nassociated with many single nucleotide polymorphisms (SNPs), each with small or\nmoderate effect sizes. Second, our understanding of the functional mechanisms\nthrough which genetic variants are associated with complex traits is still\nlimited. To address these challenges, we propose GPA-Tree and it simultaneously\nimplements association mapping and identifies key combinations of functional\nannotations related to risk-associated SNPs by combining a decision tree\nalgorithm with a hierarchical modeling framework. Results: First, we\nimplemented simulation studies to evaluate the proposed GPA-Tree method and\ncompared its performance with existing statistical approaches. The results\nindicate that GPA-Tree outperforms existing statistical approaches in detecting\nrisk-associated SNPs and identifying the true combinations of functional\nannotations with high accuracy. Second, we applied GPA-Tree to a systemic lupus\nerythematosus (SLE) GWAS and functional annotation data including GenoSkyline\nand GenoSkylinePlus. The results from GPA-Tree highlight the dysregulation of\nblood immune cells, including but not limited to primary B, memory helper T,\nregulatory T, neutrophils and CD8+ memory T cells in SLE. These results\ndemonstrate that GPA-Tree can be a powerful tool that improves association\nmapping while facilitating understanding of the underlying genetic architecture\nof complex traits and potential mechanisms linking risk-associated SNPs with\ncomplex traits.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06877v1"
    },
    {
        "title": "MetaCache-GPU: Ultra-Fast Metagenomic Classification",
        "authors": [
            "Robin Kobus",
            "André Müller",
            "Daniel Jünger",
            "Christian Hundt",
            "Bertil Schmidt"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The cost of DNA sequencing has dropped exponentially over the past decade,\nmaking genomic data accessible to a growing number of scientists. In\nbioinformatics, localization of short DNA sequences (reads) within large\ngenomic sequences is commonly facilitated by constructing index data structures\nwhich allow for efficient querying of substrings. Recent metagenomic\nclassification pipelines annotate reads with taxonomic labels by analyzing\ntheir $k$-mer histograms with respect to a reference genome database. CPU-based\nindex construction is often performed in a preprocessing phase due to the\nrelatively high cost of building irregular data structures such as hash maps.\nHowever, the rapidly growing amount of available reference genomes establishes\nthe need for index construction and querying at interactive speeds. In this\npaper, we introduce MetaCache-GPU -- an ultra-fast metagenomic short read\nclassifier specifically tailored to fit the characteristics of CUDA-enabled\naccelerators. Our approach employs a novel hash table variant featuring\nefficient minhash fingerprinting of reads for locality-sensitive hashing and\ntheir rapid insertion using warp-aggregated operations. Our performance\nevaluation shows that MetaCache-GPU is able to build large reference databases\nin a matter of seconds, enabling instantaneous operability, while popular\nCPU-based tools such as Kraken2 require over an hour for index construction on\nthe same data. In the context of an ever-growing number of reference genomes,\nMetaCache-GPU is the first metagenomic classifier that makes analysis pipelines\nwith on-demand composition of large-scale reference genome sets practical. The\nsource code is publicly available at https://github.com/muellan/metacache .\n",
        "pdf_link": "http://arxiv.org/pdf/2106.08150v1"
    },
    {
        "title": "Active feature selection discovers minimal gene sets for classifying\n  cell types and disease states with single-cell mRNA-seq data",
        "authors": [
            "Xiaoqiao Chen",
            "Sisi Chen",
            "Matt Thomson"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Sequencing costs currently prohibit the application of single-cell mRNA-seq\nto many biological and clinical analyses. Targeted single-cell mRNA-sequencing\nreduces sequencing costs by profiling reduced gene sets that capture biological\ninformation with a minimal number of genes. Here, we introduce an active\nlearning method (ActiveSVM) that identifies minimal but highly-informative gene\nsets that enable the identification of cell-types, physiological states, and\ngenetic perturbations in single-cell data using a small number of genes. Our\nactive feature selection procedure generates minimal gene sets from single-cell\ndata through an iterative cell-type classification task where misclassified\ncells are examined at each round of analysis to identify maximally informative\ngenes through an `active' support vector machine (ActiveSVM) classifier. By\nfocusing computational resources on misclassified cells, ActiveSVM scales to\nanalyze data sets with over a million single cells. We demonstrate that\nActiveSVM feature selection identifies gene sets that enable ~90% cell-type\nclassification accuracy across a variety of data sets including cell atlas and\ndisease characterization data sets. The method generalizes to reveal genes that\nrespond to genetic perturbations and to identify region specific gene\nexpression patterns in spatial transcriptomics data. The discovery of small but\nhighly informative gene sets should enable substantial reductions in the number\nof measurements necessary for application of single-cell mRNA-seq to clinical\ntests, therapeutic discovery, and genetic screens.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.08317v2"
    },
    {
        "title": "BUSCO update: novel and streamlined workflows along with broader and\n  deeper phylogenetic coverage for scoring of eukaryotic, prokaryotic, and\n  viral genomes",
        "authors": [
            "Mosè Manni",
            "Matthew R Berkeley",
            "Mathieu Seppey",
            "Felipe A Simao",
            "Evgeny M Zdobnov"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Methods for evaluating the quality of genomic and metagenomic data are\nessential to aid genome assembly and to correctly interpret the results of\nsubsequent analyses. BUSCO estimates the completeness and redundancy of\nprocessed genomic data based on universal single-copy orthologs. Here we\npresent new functionalities and major improvements of the BUSCO software, as\nwell as the renewal and expansion of the underlying datasets in sync with the\nOrthoDB v10 release. Among the major novelties, BUSCO now enables phylogenetic\nplacement of the input sequence to automatically select the most appropriate\ndataset for the assessment, allowing the analysis of metagenome-assembled\ngenomes of unknown origin. A newly-introduced genome workflow increases the\nefficiency and runtimes especially on large eukaryotic genomes. BUSCO is the\nonly tool capable of assessing both eukaryotic and prokaryotic species, and can\nbe applied to various data types, from genome assemblies and metagenomic bins,\nto transcriptomes and gene sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.11799v1"
    },
    {
        "title": "SnakeLines: integrated set of computational pipelines for sequencing\n  reads",
        "authors": [
            "Jaroslav Budis",
            "Werner Krampl",
            "Marcel Kucharik",
            "Rastislav Hekel",
            "Adrian Goga",
            "Michal Lichvar",
            "David Smolak",
            "Miroslav Bohmer",
            "Andrej Balaz",
            "Frantisek Duris",
            "Juraj Gazdarica",
            "Katarina Soltys",
            "Jan Turna",
            "Jan Radvanszky",
            "Tomas Szemes"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: With the rapid growth of massively parallel sequencing\ntechnologies, still more laboratories are utilizing sequenced DNA fragments for\ngenomic analyses. Interpretation of sequencing data is, however, strongly\ndependent on bioinformatics processing, which is often too demanding for\nclinicians and researchers without a computational background. Another problem\nrepresents the reproducibility of computational analyses across separated\ncomputational centers with inconsistent versions of installed libraries and\nbioinformatics tools.\n  Results: We propose an easily extensible set of computational pipelines,\ncalled SnakeLines, for processing sequencing reads; including mapping,\nassembly, variant calling, viral identification, transcriptomics, metagenomics,\nand methylation analysis. Individual steps of an analysis, along with methods\nand their parameters can be readily modified in a single configuration file.\nProvided pipelines are embedded in virtual environments that ensure isolation\nof required resources from the host operating system, rapid deployment, and\nreproducibility of analysis across different Unix-based platforms.\n  Conclusion: SnakeLines is a powerful framework for the automation of\nbioinformatics analyses, with emphasis on a simple set-up, modifications,\nextensibility, and reproducibility.\n  Keywords: Computational pipeline, framework, massively parallel sequencing,\nreproducibility, virtual environment\n",
        "pdf_link": "http://arxiv.org/pdf/2106.13649v1"
    },
    {
        "title": "Machine learning for plant microRNA prediction: A systematic review",
        "authors": [
            "Shyaman Jayasundara",
            "Sandali Lokuge",
            "Puwasuru Ihalagedara",
            "Damayanthi Herath"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  MicroRNAs (miRNAs) are endogenous small non-coding RNAs that play an\nimportant role in post-transcriptional gene regulation. However, the\nexperimental determination of miRNA sequence and structure is both expensive\nand time-consuming. Therefore, computational and machine learning-based\napproaches have been adopted to predict novel microRNAs. With the involvement\nof data science and machine learning in biology, multiple research studies have\nbeen conducted to find microRNAs with different computational methods and\ndifferent miRNA features. Multiple approaches are discussed in detail\nconsidering the learning algorithm/s used, features considered, dataset/s used\nand the criteria used in evaluations. This systematic review focuses on the\nmachine learning methods developed for miRNA identification in plants. This\nwill help researchers to gain a detailed idea about past studies and identify\nnovel paths that solve drawbacks occurred in past studies. Our findings\nhighlight the need for plant-specific computational methods for miRNA\nidentification.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.15159v1"
    },
    {
        "title": "The Power of Word-Frequency Based Alignment-Free Functions: a\n  Comprehensive Large-scale Experimental Analysis -- Version 3",
        "authors": [
            "Giuseppe Cattaneo",
            "Umberto Ferraro Petrillo",
            "Raffaele Giancarlo",
            "Francesco Palini",
            "Chiara Romualdi"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: Alignment-free (AF) distance/similarity functions are a key tool\nfor sequence analysis. Experimental studies on real datasets abound and, to\nsome extent, there are also studies regarding their control of false positive\nrate (Type I error). However, assessment of their power, i.e., their ability to\nidentify true similarity, has been limited to some members of the D2 family by\nexperimental studies on short sequences, not adequate for current applications,\nwhere sequence lengths may vary considerably. Such a State of the Art is\nmethodologically problematic, since information regarding a key feature such as\npower is either missing or limited. Results: By concentrating on a\nrepresentative set of word-frequency based AF functions, we perform the first\ncoherent and uniform evaluation of the power, involving also Type I error for\ncompleteness. Two Alternative models of important genomic features (CIS\nRegulatory Modules and Horizontal Gene Transfer), a wide range of sequence\nlengths from a few thousand to millions, and different values of k have been\nused. As a result, we provide a characterization of those AF functions that is\nnovel and informative. Indeed, we identify weak and strong points of each\nfunction considered, which may be used as a guide to choose one for analysis\ntasks. Remarkably, of the fifteen functions that we have considered, only four\nstand out, with small differences between small and short sequence length\nscenarios. Finally, in order to encourage the use of our methodology for\nvalidation of future AF functions, the Big Data platform supporting it is\npublic.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.15531v3"
    },
    {
        "title": "Assessing putative bias in prediction of anti-microbial resistance from\n  real-world genotyping data under explicit causal assumptions",
        "authors": [
            "Mattia Prosperi",
            "Simone Marini",
            "Christina Boucher",
            "Jiang Bian"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Whole genome sequencing (WGS) is quickly becoming the customary means for\nidentification of antimicrobial resistance (AMR) due to its ability to obtain\nhigh resolution information about the genes and mechanisms that are causing\nresistance and driving pathogen mobility. By contrast, traditional phenotypic\n(antibiogram) testing cannot easily elucidate such information. Yet development\nof AMR prediction tools from genotype-phenotype data can be biased, since\nsampling is non-randomized. Sample provenience, period of collection, and\nspecies representation can confound the association of genetic traits with AMR.\nThus, prediction models can perform poorly on new data with sampling\ndistribution shifts. In this work -- under an explicit set of causal\nassumptions -- we evaluate the effectiveness of propensity-based rebalancing\nand confounding adjustment on AMR prediction using genotype-phenotype AMR data\nfrom the Pathosystems Resource Integration Center (PATRIC). We select bacterial\ngenotypes (encoded as k-mer signatures, i.e. DNA fragments of length k),\ncountry, year, species, and AMR phenotypes for the tetracycline drug class,\npreparing test data with recent genomes coming from a single country. We test\nboosted logistic regression (BLR) and random forests (RF) with/without\nbias-handling. On 10,936 instances, we find evidence of species, location and\nyear imbalance with respect to the AMR phenotype. The crude versus\nbias-adjusted change in effect of genetic signatures on AMR varies but only\nmoderately (selecting the top 20,000 out of 40+ million k-mers). The area under\nthe receiver operating characteristic (AUROC) of the RF (0.95) is comparable to\nthat of BLR (0.94) on both out-of-bag samples from bootstrap and the external\ntest (n=1,085), where AUROCs do not decrease. We observe a 1%-5% gain in AUROC\nwith bias-handling compared to the sole use of genetic signatures. ...\n",
        "pdf_link": "http://arxiv.org/pdf/2107.03383v2"
    },
    {
        "title": "Abordagem probabilística para análise de confiabilidade de dados\n  gerados em sequenciamentos multiplex na plataforma ABI SOLiD",
        "authors": [
            "Fabio M. F. Lobato",
            "Carlos D. N. Damasceno",
            "Péricles L. Machado",
            "Nandamudi L. Vijaykumar",
            "André R. dos Santos",
            "Sylvain H. Darnet",
            "André N. A. Gonçalves",
            "Dayse O. de Alencar",
            "Ádamo L. de Santana"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The next-generation sequencers such as Illumina and SOLiD platforms generate\na large amount of data, commonly above 10 Gigabytes of text files.\nParticularly, the SOLiD platform allows the sequencing of multiple samples in a\nsingle run, called multiplex run, through a tagging system called Barcode. This\nfeature requires a computational process for separation of the data sample\nbecause the sequencer provides a mixture of all samples in a single output.\nThis process must be secure to avoid any harm that may scramble further\nanalysis. In this context, realized the need to develop a probabilistic model\ncapable of assigning a degree of confidence in the marking system used in\nmultiplex sequencing. The results confirmed the adequacy of the model obtained,\nwhich allows, among other things, to guide a process of filtering the data and\nevaluation of the sequencing protocol used.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.13537v2"
    },
    {
        "title": "Spliced Leader Trapping Reveals Widespread Alternative Splicing Patterns\n  in the Highly Dynamic Transcriptome of Trypanosoma brucei",
        "authors": [
            "Daniel Nilsson",
            "Kapila Gunasekera",
            "Jan Mani",
            "Magne Osteras",
            "Laurent Farinelli",
            "Loic Baerlocher",
            "Isabel Roditi",
            "Torsten Ochsenreiter"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Trans-splicing of leader sequences onto the 59ends of mRNAs is a widespread\nphenomenon in protozoa, nematodes and some chordates. Using parallel sequencing\nwe have developed a method to simultaneously map 59splice sites and analyze the\ncorresponding gene expression profile, that we term spliced leader trapping\n(SLT). The method can be applied to any organism with a sequenced genome and\ntrans-splicing of a conserved leader sequence. We analyzed the expression\nprofiles and splicing patterns of bloodstream and insect forms of the parasite\nTrypanosoma brucei. We detected the 59splice sites of 85% of the annotated\nprotein-coding genes and, contrary to previous reports, found up to 40% of\ntranscripts to be differentially expressed. Furthermore, we discovered more\nthan 2500 alternative splicing events, many of which appear to be\nstage-regulated. Based on our findings we hypothesize that alternatively\nspliced transcripts present a new means of regulating gene expression and could\npotentially contribute to protein diversity in the parasite. The entire dataset\ncan be accessed online at TriTrypDB or through: http://splicer.unibe.ch/.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12386v1"
    },
    {
        "title": "Computational methods for differentially expressed gene analysis from\n  RNA-Seq: an overview",
        "authors": [
            "Juliana Costa-Silva",
            "Douglas S. Domingues",
            "David Menotti",
            "Mariangela Hungria",
            "Fabricio M Lopes"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The analysis of differential gene expression from RNA-Seq data has become a\nstandard for several research areas mainly involving bioinformatics. The steps\nfor the computational analysis of these data include many data types and file\nformats, and a wide variety of computational tools that can be applied alone or\ntogether as pipelines. This paper presents a review of differential expression\nanalysis pipeline, addressing its steps and the respective objectives, the\nprincipal methods available in each step and their properties, bringing an\noverview in an organized way in this context. In particular, this review aims\nto address mainly the aspects involved in the differentially expressed gene\n(DEG) analysis from RNA sequencing data (RNA-Seq), considering the\ncomputational methods and its properties. In addition, a timeline of the\nevolution of computational methods for DEG is presented and discussed, as well\nas the relationships existing between the main computational tools are\npresented by an interaction network. A discussion on the challenges and gaps in\nDEG analysis is also highlighted in this review.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.03625v1"
    },
    {
        "title": "Spike2Vec: An Efficient and Scalable Embedding Approach for COVID-19\n  Spike Sequences",
        "authors": [
            "Sarwan Ali",
            "Murray Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  With the rapid global spread of COVID-19, more and more data related to this\nvirus is becoming available, including genomic sequence data. The total number\nof genomic sequences that are publicly available on platforms such as GISAID is\ncurrently several million, and is increasing with every day. The availability\nof such \\emph{Big Data} creates a new opportunity for researchers to study this\nvirus in detail. This is particularly important with all of the dynamics of the\nCOVID-19 variants which emerge and circulate. This rich data source will give\nus insights on the best ways to perform genomic surveillance for this and\nfuture pandemic threats, with the ultimate goal of mitigating or eliminating\nsuch threats. Analyzing and processing the several million genomic sequences is\na challenging task. Although traditional methods for sequence classification\nare proven to be effective, they are not designed to deal with these specific\ntypes of genomic sequences. Moreover, most of the existing methods also face\nthe issue of scalability. Previous studies which were tailored to coronavirus\ngenomic data proposed to use spike sequences (corresponding to a subsequence of\nthe genome), rather than using the complete genomic sequence, to perform\ndifferent machine learning (ML) tasks such as classification and clustering.\nHowever, those methods suffer from scalability issues. In this paper, we\npropose an approach called Spike2Vec, an efficient and scalable feature vector\nrepresentation for each spike sequence that can be used for downstream ML\ntasks. Through experiments, we show that Spike2Vec is not only scalable on\nseveral million spike sequences, but also outperforms the baseline models in\nterms of prediction accuracy, F1 score, etc.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.05019v4"
    },
    {
        "title": "FUNKI: Interactive functional footprint-based analysis of omics data",
        "authors": [
            "Rosa Hernansaiz-Ballesteros",
            "Christian H. Holland",
            "Aurelien Dugourd",
            "Julio Saez-Rodriguez"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: Omics data, such as transcriptomics or phosphoproteomics, are\nbroadly used to get a snap-shot of the molecular status of cells. In\nparticular, changes in omics can be used to estimate the activity of pathways,\ntranscription factors and kinases based on known regulated targets, that we\ncall footprints. Then the molecular paths driving these activities can be\nestimated using causal reasoning on large signaling networks. Results: We have\ndeveloped FUNKI, a FUNctional toolKIt for footprint analysis. It provides a\nuser-friendly interface for an easy and fast analysis of several omics data,\neither from bulk or single-cell experiments. FUNKI also features different\noptions to visualise the results and run post-analyses, and is mirrored as a\nscripted version in R. Availability: FUNKI is a free and open-source\napplication built on R and Shiny, available in GitHub at\nhttps://github.com/saezlab/ShinyFUNKI under GNU v3.0 license and accessible\nalso in https://saezlab.shinyapps.io/funki/ Contact: pub.saez@uni-heidelberg.de\nSupplementary information: We provide data examples within the app, as well as\nextensive information about the different variables to select, the results, and\nthe different plots in the help page.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.05796v1"
    },
    {
        "title": "Squash root microbiome transplants and metagenomic inspection for in\n  situ arid adaptations",
        "authors": [
            "Cristóbal Hernández-Álvarez",
            "Felipe García-Oliva",
            "Rocío Cruz-Ortega",
            "Miguel F. Romero",
            "Hugo R. Barajas",
            "Daniel Piñero",
            "Luis D. Alcaraz"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Arid zones contain a diverse set of microbes capable of survival under dry\nconditions, some of which can form relationships with plants under drought\nstress conditions to improve plant health. We studied squash (Cucurbita pepo\nL.) root microbiome under historically arid and humid sites, both in situ and\nperforming a common garden experiment. Plants were grown in soils from sites\nwith different drought levels, using in situ collected soils as the microbial\nsource. We described and analyzed bacterial diversity by 16S rRNA gene\nsequencing (N=48) from the soil, rhizosphere, and endosphere. Proteobacteria\nwere the most abundant phylum present in humid and arid samples, while\nActinobacteriota abundance was higher in arid ones. The Beta-diversity analyses\nshowed split microbiomes between arid and humid microbiomes, and aridity and\nsoil pH levels could explain it. These differences between humid and arid\nmicrobiomes were maintained in the common garden experiment, showing that it is\npossible to transplant in situ diversity to the greenhouse. We detected a total\nof 1009 bacterial genera; 199 exclusively associated with roots under arid\nconditions. With shotgun metagenomic sequencing of rhizospheres (N=6), we\nidentified 2969 protein families in the squash core metagenome and found an\nincreased number of exclusively protein families from arid (924) than humid\nsamples (158). We found arid conditions enriched genes involved in protein\ndegradation and folding, oxidative stress, compatible solute synthesis, and ion\npumps associated with osmotic regulation. Plant phenotyping allowed us to\ncorrelate bacterial communities with plant growth. Our study revealed that it\nis possible to evaluate microbiome diversity ex-situ and identify critical\nspecies and genes involved in plant-microbe interactions in historically arid\nlocations.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.07521v1"
    },
    {
        "title": "Nipah virus vector sequences in COVID-19 patient samples sequenced by\n  the Wuhan Institute of Virology",
        "authors": [
            "Steven C. Quay",
            "Daoyu Zhang",
            "Adrian Jones",
            "Yuri Deigin"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We report the detection of Nipah virus in an infectious clone format, a\nBSL4-level pathogen and CDC-designated Bioterrorism Agent, in raw RNA-Seq\nsequencing reads deposited by the Wuhan Institute of Virology (WIV) produced\nfrom five December 2019 patients infected with SARS-CoV-2. Research involving\nNipah infectious clones has never been reported to have occured at the WIV.\nThese patient samples have been previously reported to contain reads from\nseveral other viruses: Influenza A, Spodoptera frugiperda rhabdovirus and\nNipah. Previous authors have interpreted the presence of these virus sequences\nas indicative of co-infections of the patients in question by these pathogens\nor laboratory contamination. However, our analysis shows that NiV genes are\nencapsulated in synthetic vectors, which we infer was for assembly of a NiV\ninfectious clone. In particular, we document the finding of internal N, P-V-W-C\nand L protein coding sequences as well as coverage of the G and F genes.\nFurthermore, the format of Hepatitis D virus ribozyme and T7 terminator\ndownstream of the 5-prime end of the NiV sequence is consistent with truncation\nrequired at the end of the genome for a full length infectious clone. This\nindicates that research at WIV was being conducted on an assembled NiV\ninfectious clone. Contamination of patient sequencing reads by an infectious\nNiV clone of the highly pathogenic Bangladesh strain could indicate a\nsignificant breach of BSL-4 protocols. We call on WIV to explain the purpose of\nthis research on infectious clones of Nipah Virus, the full chronology of this\nwork, and to explain how and at what stage of sample preparation this\ncontamination occurred.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.09112v1"
    },
    {
        "title": "Genomic prediction: progress and perspectives for rice improvement",
        "authors": [
            "Jérôme Bartholomé",
            "Parthiban Thathapalli Prakash",
            "Joshua N. Cobb"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Genomic prediction can be a powerful tool to achieve greater rates of genetic\ngain for quantitative traits if thoroughly integrated into a breeding strategy.\nIn rice as in other crops, the interest in genomic prediction is very strong\nwith a number of studies addressing multiple aspects of its use, ranging from\nthe more conceptual to the more practical. In this chapter, we review the\nliterature on rice (Oryza sativa) and summarize important considerations for\nthe integration of genomic prediction in breeding programs. The irrigated\nbreeding program at the International Rice Research Institute is used as a\nconcrete example on which we provide data and R scripts to reproduce the\nanalysis but also to highlight practical challenges regarding the use of\npredictions. The adage: \"To someone with a hammer, everything looks like a\nnail\" describes a common psychological pitfall that sometimes plagues the\nintegration and application of new technologies to a discipline. We have\ndesigned this chapter to help rice breeders avoid that pitfall and appreciate\nthe benefits and limitations of applying genomic prediction, as it is not\nalways the best approach nor the first step to increasing the rate of genetic\ngain in every context.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14781v1"
    },
    {
        "title": "A mixture model for determining SARS-Cov-2 variant composition in pooled\n  samples",
        "authors": [
            "Renan Valieris",
            "Rodrigo Drummond",
            "Alexandre Defelicibus",
            "Emannuel Dias-Neto",
            "Rafael A. Rosales",
            "Israel Tojal da Silva"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Despite of the fast development of highly effective vaccines to control the\ncurrent COVID$-$19 pandemic, the unequal distribution and availability of these\nvaccines worldwide and the number of people infected in the world lead to the\ncontinuous emergence of SARS-CoV-2 (Severe Acute Respiratory Syndrome\ncoronavirus 2) variants of concern. It is likely that real-time genomic\nsurveillance will be continuously needed as an unceasing monitoring tool,\nnecessary to follow the spillover of the disease spread and the evolution of\nthe virus. In this context, new genomic variants of SARS-CoV-2 that may emerge\nas a response to selective pressure, including variants refractory to current\nvaccines, makes genomic surveillance programs tools of utmost importance. Here\npropose a statistical model for the estimation of the relative frequencies of\nSARS-CoV-2 variants in pooled samples. This model is built by considering a\npreviously defined selection of genomic polymorphisms that characterize\nSARS-CoV-2 variants. The methods described here support both raw sequencing\nreads for polymorphisms-based markers calling and predefined markers in the VCF\nformat. Results obtained by using simulated data show that our method is quite\neffective in recovering the correct variant proportions. Further, results\nobtained by considering longitudinal data from wastewater samples of two\nlocations in Switzerland agree well with those describing the epidemiological\nevolution of COVID-19 variants in clinical samples of these locations. Our\nresults show that the described method can be a valuable tool for tracking the\nproportions of SARS-CoV-2 variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.01117v1"
    },
    {
        "title": "An Information-Theoretic Framework for Identifying Age-Related Genes\n  Using Human Dermal Fibroblast Transcriptome Data",
        "authors": [
            "Salman Mohamadi",
            "Donald Adjeroh"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Investigation of age-related genes is of great importance for multiple\npurposes, for instance, improving our understanding of the mechanism of ageing,\nincreasing life expectancy, age prediction, and other healthcare applications.\nIn his work, starting with a set of 27,142 genes, we develop an\ninformation-theoretic framework for identifying genes that are associated with\naging by applying unsupervised and semi-supervised learning techniques on human\ndermal fibroblast gene expression data. First, we use unsupervised learning and\napply information-theoretic measures to identify key features for effective\nrepresentation of gene expression values in the transcriptome data. Using the\nidentified features, we perform clustering on the data. Finally, we apply\nsemi-supervised learning on the clusters using different distance measures to\nidentify novel genes that are potentially associated with aging. Performance\nassessment for both unsupervised and semi-supervised methods show the\neffectiveness of the framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.02595v1"
    },
    {
        "title": "Human Age Estimation from Gene Expression Data using Artificial Neural\n  Networks",
        "authors": [
            "Salman Mohamadi",
            "Gianfranco. Doretto",
            "Nasser M. Nasrabadi",
            "Donald A. Adjeroh"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The study of signatures of aging in terms of genomic biomarkers can be\nuniquely helpful in understanding the mechanisms of aging and developing models\nto accurately predict the age. Prior studies have employed gene expression and\nDNA methylation data aiming at accurate prediction of age. In this line, we\npropose a new framework for human age estimation using information from human\ndermal fibroblast gene expression data. First, we propose a new spatial\nrepresentation as well as a data augmentation approach for gene expression\ndata. Next in order to predict the age, we design an architecture of neural\nnetwork and apply it to this new representation of the original and augmented\ndata, as an ensemble classification approach. Our experimental results suggest\nthe superiority of the proposed framework over state-of-the-art age estimation\nmethods using DNA methylation and gene expression data.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.02692v2"
    },
    {
        "title": "Machine Learning for Genomic Data",
        "authors": [
            "Akankshita Dash"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  This report explores the application of machine learning techniques on short\ntimeseries gene expression data. Although standard machine learning algorithms\nwork well on longer time-series', they often fail to find meaningful insights\nfrom fewer timepoints. In this report, we explore model-based clustering\ntechniques. We combine popular unsupervised learning techniques like K-Means,\nGaussian Mixture Models, Bayesian Networks, Hidden Markov Models with the\nwell-known Expectation Maximization algorithm. K-Means and Gaussian Mixture\nModels are fairly standard, while Hidden Markov Model and Bayesian Networks\nclustering are more novel ideas that suit time-series gene expression data.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.08507v1"
    },
    {
        "title": "Interpreting multi-variate models with setPCA",
        "authors": [
            "Nordine Aouni",
            "Luc Linders",
            "David Robinson",
            "Len Vandelaer",
            "Jessica Wiezorek",
            "Geetesh Gupta",
            "Rachel Cavill"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Principal Component Analysis (PCA) and other multi-variate models are often\nused in the analysis of \"omics\" data. These models contain much information\nwhich is currently neither easily accessible nor interpretable. Here we present\nan algorithmic method which has been developed to integrate this information\nwith existing databases of background knowledge, stored in the form of known\nsets (for instance genesets or pathways). To make this accessible we have\nproduced a Graphical User Interface (GUI) in Matlab which allows the overlay of\nknown set information onto the loadings plot and thus improves the\ninterpretability of the multi-variate model. For each known set the optimal\nconvex hull, covering a subset of elements from the known set, is found through\na search algorithm and displayed. In this paper we discuss two main topics; the\ndetails of the search algorithm for the optimal convex hull for this problem\nand the GUI interface which is freely available for download for academic use.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09138v1"
    },
    {
        "title": "Analysing high-throughput sequencing data in Python with HTSeq 2.0",
        "authors": [
            "Givanna H Putri",
            "Simon Anders",
            "Paul Theodor Pyl",
            "John E Pimanda",
            "Fabio Zanini"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Summary: HTSeq 2.0 provides a more extensive API including a new\nrepresentation for sparse genomic data, enhancements in htseq-count to suit\nsingle cell omics, a new script for data using cell and molecular barcodes,\nimproved documentation, testing and deployment, bug fixes, and Python 3\nsupport. Availability and implementation: HTSeq 2.0 is released as an\nopen-source software under the GNU General Public Licence and available from\nthe Python Package Index at https://pypi.python.org/pypi/HTSeq. The source code\nis available on Github at https://github.com/htseq/htseq. Contact:\nfabio.zanini@unsw.edu.au\n",
        "pdf_link": "http://arxiv.org/pdf/2112.00939v1"
    },
    {
        "title": "Contrastive Cycle Adversarial Autoencoders for Single-cell Multi-omics\n  Alignment and Integration",
        "authors": [
            "Xuesong Wang",
            "Zhihang Hu",
            "Tingyang Yu",
            "Ruijie Wang",
            "Yumeng Wei",
            "Juan Shu",
            "Jianzhu Ma",
            "Yu Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Muilti-modality data are ubiquitous in biology, especially that we have\nentered the multi-omics era, when we can measure the same biological object\n(cell) from different aspects (omics) to provide a more comprehensive insight\ninto the cellular system. When dealing with such multi-omics data, the first\nstep is to determine the correspondence among different modalities. In other\nwords, we should match data from different spaces corresponding to the same\nobject. This problem is particularly challenging in the single-cell multi-omics\nscenario because such data are very sparse with extremely high dimensions.\nSecondly, matched single-cell multi-omics data are rare and hard to collect.\nFurthermore, due to the limitations of the experimental environment, the data\nare usually highly noisy. To promote the single-cell multi-omics research, we\novercome the above challenges, proposing a novel framework to align and\nintegrate single-cell RNA-seq data and single-cell ATAC-seq data. Our approach\ncan efficiently map the above data with high sparsity and noise from different\nspaces to a low-dimensional manifold in a unified space, making the downstream\nalignment and integration straightforward. Compared with the other\nstate-of-the-art methods, our method performs better in both simulated and real\nsingle-cell data. The proposed method is helpful for the single-cell\nmulti-omics research. The improvement for integration on the simulated data is\nsignificant.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.03266v2"
    },
    {
        "title": "Lerna: Transformer Architectures for Configuring Error Correction Tools\n  for Short- and Long-Read Genome Sequencing",
        "authors": [
            "Atul Sharma",
            "Pranjal Jain",
            "Ashraf Mahgoub",
            "Zihan Zhou",
            "Kanak Mahadik",
            "Somali Chaterji"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Sequencing technologies are prone to errors, making error correction (EC)\nnecessary for downstream applications. EC tools need to be manually configured\nfor optimal performance. We find that the optimal parameters (e.g., k-mer size)\nare both tool- and dataset-dependent. Moreover, evaluating the performance\n(i.e., Alignment-rate or Gain) of a given tool usually relies on a reference\ngenome, but quality reference genomes are not always available. We introduce\nLerna for the automated configuration of k-mer-based EC tools. Lerna first\ncreates a language model (LM) of the uncorrected genomic reads; then,\ncalculates the perplexity metric to evaluate the corrected reads for different\nparameter choices. Next, it finds the one that produces the highest alignment\nrate without using a reference genome. The fundamental intuition of our\napproach is that the perplexity metric is inversely correlated with the quality\nof the assembly after error correction. Results: First, we show that the best\nk-mer value can vary for different datasets, even for the same EC tool. Second,\nwe show the gains of our LM using its component attention-based transformers.\nWe show the model's estimation of the perplexity metric before and after error\ncorrection. The lower the perplexity after correction, the better the k-mer\nsize. We also show that the alignment rate and assembly quality computed for\nthe corrected reads are strongly negatively correlated with the perplexity,\nenabling the automated selection of k-mer values for better error correction,\nand hence, improved assembly quality. Additionally, we show that our\nattention-based models have significant runtime improvement for the entire\npipeline -- 18X faster than previous works, due to parallelizing the attention\nmechanism and the use of JIT compilation for GPU inferencing.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10068v1"
    },
    {
        "title": "Epistatic models predict mutable sites in SARS-CoV-2 proteins and\n  epitopes",
        "authors": [
            "Juan Rodriguez-Rivas",
            "Giancarlo Croce",
            "Maureen Muscat",
            "Martin Weigt"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The emergence of new variants of SARS-CoV-2 is a major concern given their\npotential impact on the transmissibility and pathogenicity of the virus as well\nas the efficacy of therapeutic interventions. Here, we predict the mutability\nof all positions in SARS-CoV-2 protein domains to forecast the appearance of\nunseen variants. Using sequence data from other coronaviruses, pre-existing to\nSARS-CoV-2, we build statistical models that do not only capture amino-acid\nconservation but more complex patterns resulting from epistasis. We show that\nthese models are notably superior to conservation profiles in estimating the\nalready observable SARS-CoV-2 variability. In the receptor binding domain of\nthe spike protein, we observe that the predicted mutability correlates well\nwith experimental measures of protein stability and that both are reliable\nmutability predictors (ROC AUC ~0.8). Most interestingly, we observe an\nincreasing agreement between our model and the observed variability as more\ndata become available over time, proving the anticipatory capacity of our\nmodel. When combined with data concerning the immune response, our approach\nidentifies positions where current variants of concern are highly\noverrepresented. These results could assist studies on viral evolution, future\nviral outbreaks and, in particular, guide the exploration and anticipation of\npotentially harmful future SARS-CoV-2 variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10093v1"
    },
    {
        "title": "High Expression of CDK1 and NDC80 Predicts Poor Prognosis of Bladder\n  Cancer",
        "authors": [
            "S. Sajedeh Mousavi",
            "Mohammad Jalil Zorriehzahra"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: Bladder cancer is the 10th most common cancer worldwide, and its\nprevalence is increasing, especially in developing countries. Objective: In the\npresent study, we employed gene expression profiles from the GSE163209 data set\nin the GEO database to identify potential molecular and genetic markers in BC\npatients. Methods: The data set comprised 217 samples, with 113 stage Ta tumor\ntissue samples and 104 stage T1 tumor tissue samples. The top 766 genes were\nchosen. P.value<0.0001 and |logFC|=1 was used to change the cutoff criteria for\ndefining DEGs. Moreover, the MCODE plugin and cytoHubba plugin were employed to\nproduce a module and detect 20 hub genes in these DEGs. We used GO and KEGG\npathway enrichment analyses to get a better understanding of these DEGs.\nResults: The KEGG pathway enrichment results indicated that the top genes were\nmainly involved: Systemic lupus erythematosus, Alcoholism, and Viral\ncarcinogenesis. SLE activation in the renal glomeruli could explain the\nconnection between this disease's route and bladder cancer, and according to\nour results and previous researches, heavy alcohol intake can increase the risk\nof BC in males and particular populations. Conclusion: According to our hub\ngenes, we can consider CDK1 and NDC80 as bladder cancer biomarkers. Not much\nresearch has been done on the effect of this gene on bladder cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.13273v1"
    },
    {
        "title": "A Boolean Algebra for Genetic Variants",
        "authors": [
            "Jonathan K. Vis",
            "Mark A. Santcroos",
            "Walter A. Kosters",
            "Jeroen F. J. Laros"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Beyond identifying genetic variants, we introduce a set of Boolean relations\nthat allows for a comprehensive classification of the relations for every pair\nof variants by taking all minimal alignments into account. We present an\nefficient algorithm to compute these relations, including a novel way of\nefficiently computing all minimal alignments within the best theoretical\ncomplexity bounds. We show that for variants of the CFTR gene in dbSNP these\nrelations are common and many non-trivial. Ultimately, we present an approach\nfor the storing and indexing of variants in the context of a database that\nenables efficient querying for all these relations.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.14494v2"
    },
    {
        "title": "GenShare: Sharing Accurate Differentially-Private Statistics for Genomic\n  Datasets with Dependent Tuples",
        "authors": [
            "Nour Almadhoun Alserr",
            "Ozgur Ulusoy",
            "Erman Ayday",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: Cutting the cost of DNA sequencing technology led to a quantum\nleap in the availability of genomic data. While sharing genomic data across\nresearchers is an essential driver of advances in health and biomedical\nresearch, the sharing process is often infeasible due to data privacy concerns.\nDifferential privacy is one of the rigorous mechanisms utilized to facilitate\nthe sharing of aggregate statistics from genomic datasets without disclosing\nany private individual-level data. However, differential privacy can still\ndivulge sensitive information about the dataset participants due to the\ncorrelation between dataset tuples. Results: Here, we propose GenShare model\nbuilt upon Laplace-perturbation-mechanism-based DP to introduce a\nprivacy-preserving query-answering sharing model for statistical genomic\ndatasets that include dependency due to the inherent correlations between\ngenomes of individuals (i.e., family ties). We demonstrate our privacy\nimprovement over the state-of-the-art approaches for a range of practical\nqueries including cohort discovery, minor allele frequency, and chi^2\nassociation tests. With a fine-grained analysis of sensitivity in the Laplace\nperturbation mechanism and considering joint distributions, GenShare results\nnear-achieve the formal privacy guarantees permitted by the theory of\ndifferential privacy as the queries that computed over independent tuples (only\nup to 6% differences). GenShare ensures that query results are as accurate as\ntheoretically guaranteed by differential privacy. For empowering the advances\nin different scientific and medical research areas, GenShare presents a path\ntoward an interactive genomic data sharing system when the datasets include\nparticipants with familial relationships.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.15109v1"
    },
    {
        "title": "CHERRY: a Computational metHod for accuratE pRediction of\n  virus-pRokarYotic interactions using a graph encoder-decoder model",
        "authors": [
            "Jiayu Shang",
            "Yanni Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Prokaryotic viruses, which infect bacteria and archaea, are key players in\nmicrobial communities. Predicting the hosts of prokaryotic viruses helps\ndecipher the dynamic relationship between microbes. Experimental methods for\nhost prediction cannot keep pace with the fast accumulation of sequenced\nphages. Thus, there is a need for computational host prediction. Despite some\npromising results, computational host prediction remains a challenge because of\nthe limited known interactions and the sheer amount of sequenced phages by\nhigh-throughput sequencing technologies. The state-of-the-art methods can only\nachieve 43\\% accuracy at the species level. In this work, we formulate host\nprediction as link prediction in a knowledge graph that integrates multiple\nprotein and DNA-based sequence features. Our implementation named CHERRY can be\napplied to predict hosts for newly discovered viruses and to identify viruses\ninfecting targeted bacteria. We demonstrated the utility of CHERRY for both\napplications and compared its performance with 11 popular host prediction\nmethods. To our best knowledge, CHERRY has the highest accuracy in identifying\nvirus-prokaryote interactions. It outperforms all the existing methods at the\nspecies level with an accuracy increase of 37\\%. In addition, CHERRY's\nperformance on short contigs is more stable than other tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01018v2"
    },
    {
        "title": "Modeling Homophily in Dynamic Networks with Application to HIV Molecular\n  Surveillance",
        "authors": [
            "V. DeGruttola",
            "M. Nakazawa",
            "J. Liu",
            "X. Tu",
            "S. Little",
            "S. Mehta"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  This paper describes a novel approach to modeling homphily, i.e. the tendency\nof nodes that share (or differ in) certain attributes to be linked; we consider\ndynamic networks in which nodes can be added over time but not removed. Our\napplication is to HIV genetic linkage analysis that has been used to\ninvestigate HIV transmission dynamics. In this setting, two HIV sequences from\ndifferent persons with HIV (PWH) are said to be linked if the genetic distance\nbetween these sequences is less than a given threshold. Such linkage suggests\nthat that the nodes representing the two infected PWH, are close to each other\nin a transmission network; such proximity would imply that either one of the\ninfected people directly transmitted the virus to the other or indirectly\ntransmitted it through a small number of intermediaries. These viral genetic\nlinkage networks are dynamic in the sense that, over time, a group or cluster\nof genetically linked viral sequences may increase in size as new people are\ninfected by those in the cluster either directly or through intermediaries. Our\napproach makes use of a logistic model to describe homophily with regard to\ndemographic and behavioral characteristics that is we investigate whether\nsimilarities (or differences) between PWH in these characteristics impacts the\nprobability that their sequences are be linked. Such analyses provide\ninformation about HIV transmission dynamics within a population.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.04231v1"
    },
    {
        "title": "Multiple Genome Analytics Framework: The Case of All SARS-CoV-2 Complete\n  Variants",
        "authors": [
            "Konstantinos Xylogiannopoulos"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Pattern detection and string matching are fundamental problems in computer\nscience and the accelerated expansion of bioinformatics and computational\nbiology have made them a core topic for both disciplines. The SARS-CoV-2\npandemic has made such problems more demanding with hundreds or thousands of\nnew genome variants discovered every week, because of constant mutations, and\nthere is a desperate need for fast and accurate analyses. The requirement for\ncomputational tools for genomic analyses, such as sequence alignment, is very\nimportant, although, in most cases the resources and computational power\nrequired are enormous. The presented Multiple Genome Analytics Framework\ncombines data structures and algorithms, specifically built for text mining and\npattern detection, that can help to efficiently address several computational\nbiology and bioinformatics problems concurrently with minimal resources. A\nsingle execution of advanced algorithms, with space and time complexity\nO(nlogn), is enough to acquire knowledge on all repeated patterns that exist in\nmultiple genome sequences and this information can be used from other\nmeta-algorithms for further meta-analyses. The potential of the proposed\nframework is demonstrated with the analysis of more than 300,000 SARS-CoV-2\ngenome sequences and the detection of all repeated patterns with length up to\n60 nucleotides in these sequences. These results have been used to provide\nanswers to questions such as common patterns among all variants, sequence\nalignment, palindromes and tandem repeats detection, different organism genome\ncomparisons, polymerase chain reaction primers detection, etc.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.05198v1"
    },
    {
        "title": "Identifying OCRs in cfDNA WGS Data by Correlation Clustering",
        "authors": [
            "Farshad Noravesh",
            "Fahimeh Palizban"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  In the recent decade, the emergence of liquid biopsy has significantly\nimproved cancer monitoring and detection. Dying cells, including those\noriginating from tumors, shed their DNA into the bloodstream and contribute to\na pool of circulating fragments called cell-free DNA (cfDNA). Identifying the\ntissue origin of these DNA fragments from their epigenetic features has\nimplications in various clinical contexts. Open chromatin regions (OCRs) are\nimportant epigenetic features of DNA that reflect cell types of origin.\nProfiling these features by DNase-seq, ATAC-seq, and histone ChIP-seq provides\ninsights into tissue-specific and disease-specific regulatory mechanisms.\nIntegration of genomic and epigenomic features for cancer detection by liquid\nbiopsy has previously been reported. However, many multimodal analyses require\nlarge amounts of cfDNA input and/or multiple types of experiments to cover the\ngenomic and epigenomic aspects of a single sample which is cost and time\nprohibitive. Thus, methods that capture genomic and epigenomic profiles in a\nsingle experiment type with low input requirements are of importance.\nPredicting OCRs from whole genome sequencing (WGS) data is one such approach.\nHere, we applied a correlation clustering algorithm to predict OCRs. We used\nlocal sequencing depth as input to our algorithm. Multiple processing steps\nwere then applied as follows: count normalization, discrete Fourier transform\nconversion, graph construction, graph cut optimization by linear programming,\nand clustering. To validate the proposed method, we compared the output of our\npredictions (OCR vs. non-OCR) with previously validated open chromatin regions\nrelated to human blood samples of the ATAC-db. The percentage of overlap\nbetween them is greater than 67%.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09618v2"
    },
    {
        "title": "SeqMapPDB: A Standalone Pipeline to Identify Representative Structures\n  of Protein Sequences and Mapping Residue Indices in Real-Time at Proteome\n  Scale",
        "authors": [
            "Boshen Wang",
            "Xue Lei",
            "Wei Tian",
            "Alan Perez-Rathke",
            "Yan-Yuan Tseng",
            "Jie Liang"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Motivation: 3D structures of proteins provide rich information for\nunderstanding their biochemical roles. Identifying the representative protein\nstructures for protein sequences is essential for analysis of proteins at\nproteome scale. However, there are technical difficulties in identifying the\nrepresentative structure of a given protein sequence and providing accurate\nmapping of residue indices. Existing databases of mapping between structures\nand sequences are usually static that are not suitable for studying proteomes\nwith frequent gene model revisions. They often do not provide reliable and\nconsistent representative structures that maximizes sequence coverage.\nFurthermore, proteins isomers are usually not properly resolved. Results: To\novercome these difficulties, we have developed a computational pipeline called\nSeqMapPDB to provide high-quality representative PDB structures of given\nsequences. It provides mapping to structures that fully cover the sequences\nwhen available, or to the set of partial non-overlapping structural domains\nthat maximally cover the query sequence. The residue indices are accurate\nmapped and isomeric proteins are resolved. SeqMapPDB is efficient and can\nrapidly carry out proteome-wide mapping to the selected version of reference\ngenomes in real-time. Furthermore, SeqMapPDB provides the flexibility of a\nstand-alone pipeline for large scale mapping of in-house sequence and structure\ndata. Availability: Our method is available at\nhttps://bitbucket.org/lianglabuic/seqmappdb with GNU GPL license.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.11551v2"
    },
    {
        "title": "A New String Edit Distance and Applications",
        "authors": [
            "Taylor Petty",
            "Jan Hannig",
            "Tunde I Huszar",
            "Hari Iyer"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  String edit distances have been used for decades in applications ranging from\nspelling correction and web search suggestions to DNA analysis. Most string\nedit distances are variations of the Levenshtein distance and consider only\nsingle-character edits. In forensic applications polymorphic genetic markers\nsuch as short tandem repeats (STRs) are used. At these repetitive motifs the\nDNA copying errors consist of more than just single base differences. More\noften the phenomenon of ``stutter'' is observed, where the number of repeated\nunits differs (by whole units) from the template. To adapt the Levenshtein\ndistance to be suitable for forensic applications where DNA sequence similarity\nis of interest, a generalized string edit distance is defined that accommodates\nthe addition or deletion of whole motifs in addition to single-nucleotide\nedits. A dynamic programming implementation is developed for computing this\ndistance between sequences. The novelty of this algorithm is in handling the\ncomplex interactions that arise between multiple- and single-character edits.\nForensic examples illustrate the purpose and use of the Restricted Forensic\nLevenshtein (RFL) distance measure, but applications extend to sequence\nalignment and string similarity in other biological areas, as well as dynamic\nprogramming algorithms more broadly.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06138v3"
    },
    {
        "title": "Enriching and Characterizing T-Cell Repertoires from 3' Barcoded\n  Single-Cell Whole Transcriptome Amplification Products",
        "authors": [
            "Tasneem Jivanjee",
            "Samira Ibrahim",
            "Sarah K. Nyquist",
            "G. James Gatter",
            "Joshua D. Bromley",
            "Swati Jaiswal",
            "Bonnie Berger",
            "Samuel M. Behar",
            "J. Christopher Love",
            "Alex K. Shalek"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Antigen-specific T cells play an essential role in immunoregulation and\ndiseases such as cancer. Characterizing the T cell receptor (TCR) sequences\nthat encode T cell specificity is critical for elucidating the antigenic\ndeterminants of immunological diseases and designing therapeutic remedies.\nHowever, methods of obtaining single-cell TCR sequencing data are labor and\ncost intensive, requiring cell sorting and full length single-cell\nRNA-sequencing (scRNA-seq). New high-throughput 3' cell-barcoding scRNA-seq\nmethods can simplify and scale this process; however, they do not routinely\ncapture TCR sequences during library preparation and sequencing. While 5'\ncell-barcoding scRNA-seq methods can be used to examine TCR repertoire at\nsingle-cell resolution, it requires specialized reagents which cannot be\napplied to samples previously processed using 3' cell-barcoding methods. Here,\nwe outline a method for sequencing TCR$\\alpha$ and TCR$\\beta$ transcripts from\nsamples already processed using 3' cell-barcoding scRNA-seq platforms, ensuring\nTCR recovery at a single-cell resolution. In short, a fraction of the 3'\nbarcoded whole transcriptome amplification (WTA) product typically used to\ngenerate a massively parallel 3' scRNA-seq library is enriched for TCR\ntranscripts using biotinylated probes, and further amplified using the same\nuniversal primer sequence from WTA. Primer extension using TCR V-region primers\nand targeted PCR amplification results in a 3' barcoded single-cell\nCDR3-enriched library that can be sequenced with custom sequencing primers.\nCoupled with 3' scRNA-seq of the same WTA, this method enables simultaneous\nanalysis of single-cell transcriptomes and TCR sequences which can help\ninterpret inherent heterogeneity among antigen-specific T cells and salient\ndisease biology. This method can be adapted to enrich other transcripts of\ninterest from 3' and 5' barcoded WTA libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.11266v1"
    },
    {
        "title": "Inference of B cell clonal families using heavy/light chain pairing\n  information",
        "authors": [
            "Duncan K. Ralph",
            "Frederick A. Matsen IV"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Next generation sequencing of B cell receptor (BCR) repertoires has become a\nubiquitous tool for understanding the antibody-mediated immune response: it is\nnow common to have large volumes of sequence data coding for both the heavy and\nlight chain subunits of the BCR. However, until the recent development of high\nthroughput methods of preserving heavy/light chain pairing information, these\nsamples contained no explicit information on which heavy chain sequence pairs\nwith which light chain sequence. One of the first steps in analyzing such BCR\nrepertoire samples is grouping sequences into clonally related families, where\neach stems from a single rearrangement event. Many methods of accomplishing\nthis have been developed, however, none so far has taken full advantage of the\nnewly-available pairing information. This information can dramatically improve\nclustering performance, especially for the light chain. The light chain has\ntraditionally been challenging for clonal family inference because of its low\ndiversity and consequent abundance of non-clonal families with\nindistinguishable naive rearrangements. Here we present a method of\nincorporating this pairing information into the clustering process in order to\narrive at a more accurate partition of the data into clonally related families.\nWe also demonstrate two methods of fixing imperfect pairing information, which\nmay allow for simplified sample preparation and increased sequencing depth.\nFinally, we describe several other improvements to the partis software package\n(https://github.com/psathyrella/partis).\n",
        "pdf_link": "http://arxiv.org/pdf/2203.11367v2"
    },
    {
        "title": "rfPhen2Gen: A machine learning based association study of brain imaging\n  phenotypes to genotypes",
        "authors": [
            "Muhammad Ammar Malik",
            "Alexander S. Lundervold",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Imaging genetic studies aim to find associations between genetic variants and\nimaging quantitative traits. Traditional genome-wide association studies (GWAS)\nare based on univariate statistical tests, but when multiple traits are\nanalyzed together they suffer from a multiple-testing problem and from not\ntaking into account correlations among the traits. An alternative approach to\nmulti-trait GWAS is to reverse the functional relation between genotypes and\ntraits, by fitting a multivariate regression model to predict genotypes from\nmultiple traits simultaneously. However, current reverse genotype prediction\napproaches are mostly based on linear models. Here, we evaluated random forest\nregression (RFR) as a method to predict SNPs from imaging QTs and identify\nbiologically relevant associations. We learned machine learning models to\npredict 518,484 SNPs using 56 brain imaging QTs. We observed that genotype\nregression error is a better indicator of permutation p-value significance than\ngenotype classification accuracy. SNPs within the known Alzheimer disease (AD)\nrisk gene APOE had lowest RMSE for lasso and random forest, but not ridge\nregression. Moreover, random forests identified additional SNPs that were not\nprioritized by the linear models but are known to be associated with\nbrain-related disorders. Feature selection identified well-known brain regions\nassociated with AD,like the hippocampus and amygdala, as important predictors\nof the most significant SNPs. In summary, our results indicate that non-linear\nmethods like random forests may offer additional insights into\nphenotype-genotype associations compared to traditional linear multi-variate\nGWAS methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00067v1"
    },
    {
        "title": "SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features\n  Learning from a Language Model",
        "authors": [
            "Yikang Zhang",
            "Xiaomin Chu",
            "Yelu Jiang",
            "Hongjie Wu",
            "Lijun Quan"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  A large number of inorganic and organic compounds are able to bind DNA and\nform complexes, among which drug-related molecules are important. Chromatin\naccessibility changes not only directly affects drug-DNA interactions, but also\npromote or inhibit the expression of critical genes associated with drug\nresistance by affecting the DNA binding capacity of TFs and transcriptional\nregulators. However, Biological experimental techniques for measuring it are\nexpensive and time consuming. In recent years, several kinds of computational\nmethods have been proposed to identify accessible regions of the genome.\nExisting computational models mostly ignore the contextual information of bases\nin gene sequences. To address these issues, we proposed a new solution named\nSemanticCAP. It introduces a gene language model which models the context of\ngene sequences, thus being able to provide an effective representation of a\ncertain site in gene sequences. Basically, we merge the features provided by\nthe gene language model into our chromatin accessibility model. During the\nprocess, we designed some methods to make feature fusion smoother. Compared\nwith other systems under public benchmarks, our model proved to have better\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.02130v2"
    },
    {
        "title": "A structural model of genome-wide association studies",
        "authors": [
            "Christopher Salahub"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  A structural genetic model incorporating a modern understanding of the genome\nand common practice in genome-wide association studies is derived\nmathematically. The model shows the Haldane map distance as a direct\nconsequence of the structure of the genome. An expression for genetic\ncorrelation is derived under the model and compared to data resulting from the\nBSB mouse cross. A correlation test plot is introduced for this comparison and\nshows the close agreement of the model and empirical results. Noteworthy\ndepartures in this plot indicate regions which warrant further investigation.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10391v1"
    },
    {
        "title": "DiMA: Sequence Diversity Dynamics Analyser for Viruses",
        "authors": [
            "Shan Tharanga",
            "Eyyub Selim Unlu",
            "Yongli Hu",
            "Muhammad Farhan Sjaugi",
            "Muhammet A. Celik",
            "Hilal Hekimoglu",
            "Olivo Miotto",
            "Muhammed Miran Oncel",
            "Asif M. Khan"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Sequence diversity is one of the major challenges in the design of\ndiagnostic, prophylactic and therapeutic interventions against viruses. DiMA is\na novel tool that is big data-ready and designed to facilitate the dissection\nof sequence diversity dynamics for viruses. DiMA stands out from other\ndiversity analysis tools by offering various unique features. DiMA provides a\nquantitative overview of sequence (nucleotide/protein) diversity by use of\nShannon's entropy corrected for size bias, applied via a user-defined k-mer\nsliding window to an input alignment file, and each k-mer position is dissected\nto various diversity motifs. The motifs are defined based on the probability of\ndistinct sequences at a given k-mer position, whereby an index is the\npredominant sequence, while all the others are (total) variants to the index.\nThe total variants are sub-classified into the major (most common) variant,\nminor variants (occurring more than once and of frequency lower than the\nmajor), and the unique (singleton) variants. DiMA allows user-defined, sequence\nmetadata enrichment for analyses of the motifs. The application of DiMA was\ndemonstrated for the alignment data of the relatively conserved Spike protein\n(2,106,985 sequences) of severe acute respiratory syndrome coronavirus 2\n(SARS-CoV-2) and the relatively highly diverse Pol protein (3,874) of human\nimmunodeficiency virus-1 (HIV-1). The tool is publicly available as a web\nserver (https://dima.bezmialem.edu.tr), as a Python library (via PyPi) and as a\ncommand line client (Via GitHub).\n",
        "pdf_link": "http://arxiv.org/pdf/2205.13915v2"
    },
    {
        "title": "Intra-strand symmetries and asymmetries in bacterial DNA: Evolutive\n  features or relics of primordial genomes?",
        "authors": [
            "Marcelo Sobottka"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  In this work we analyze some models used to explain the origins of\nintra-strand parity and strand compositional asymmetries in bacterial genomes.\nDue to the particular way that these two features emerge in bacterial DNA, we\nperformed our analysis from the perspective that they are complementary\nphenomena that should be addressed together. Although most of the models for\nthese features try to explain them as consequence of evolutionary mechanisms,\nrecently it was proposed that they could be `relics' of some primordial genome\nthat were conserved thorough out the genome evolution. We shall pay special\nattention to the S-H model, which is, up to the date, the unique model proposed\nas a possible explanation for intra-strand parity and strand compositional\nasymmetries in primordial genomes as mere consequence of randomness under\nchemical/physical constraints. In particular, we shall discuss possible\ndirections to test some of the hypotheses of the S-H model, and we will present\na possible formulation of the S-H model as an evolutive model too.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00610v1"
    },
    {
        "title": "Learning to Untangle Genome Assembly with Graph Convolutional Networks",
        "authors": [
            "Lovro Vrček",
            "Xavier Bresson",
            "Thomas Laurent",
            "Martin Schmitz",
            "Mile Šikić"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  A quest to determine the complete sequence of a human DNA from telomere to\ntelomere started three decades ago and was finally completed in 2021. This\naccomplishment was a result of a tremendous effort of numerous experts who\nengineered various tools and performed laborious manual inspection to achieve\nthe first gapless genome sequence. However, such method can hardly be used as a\ngeneral approach to assemble different genomes, especially when the assembly\nspeed is critical given the large amount of data. In this work, we explore a\ndifferent approach to the central part of the genome assembly task that\nconsists of untangling a large assembly graph from which a genomic sequence\nneeds to be reconstructed. Our main motivation is to reduce human-engineered\nheuristics and use deep learning to develop more generalizable reconstruction\ntechniques. Precisely, we introduce a new learning framework to train a graph\nconvolutional network to resolve assembly graphs by finding a correct path\nthrough them. The training is supervised with a dataset generated from the\nresolved CHM13 human sequence and tested on assembly graphs built using real\nhuman PacBio HiFi reads. Experimental results show that a model, trained on\nsimulated graphs generated solely from a single chromosome, is able to\nremarkably resolve all other chromosomes. Moreover, the model outperforms\nhand-crafted heuristics from a state-of-the-art \\textit{de novo} assembler on\nthe same graphs. Reconstructed chromosomes with graph networks are more\naccurate on nucleotide level, report lower number of contigs, higher genome\nreconstructed fraction and NG50/NGA50 assessment metrics.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00668v1"
    },
    {
        "title": "First large-scale genomic prediction in the honey bee",
        "authors": [
            "Richard Bernstein",
            "Manuel Du",
            "Zhipei G. Du",
            "Anja S. Strauss",
            "Andreas Hoppe",
            "Kaspar Bienefeld"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Genomic selection has increased genetic gain in several livestock species,\nbut due to the complicated genetics and reproduction biology not yet in honey\nbees. Recently, 2 970 queens were genotyped to gather a reference population.\nFor the application of genomic selection in honey bees, this study analyses the\npredictive ability and bias of pedigree-based and genomic breeding values for\nhoney yield, three workability traits and two traits for resistance against the\nparasite Varroa destructor. For breeding value estimation, we use a honey\nbee-specific model with maternal and direct effects, to account for the\ncontributions of the workers and the queen of a colony to the phenotypes. We\nconducted a validation for the last generation and a five-fold\ncross-validation. In the validation for the last generation, the predictive\nability of pedigree-based estimated breeding values was 0.06 for honey yield,\nand ranged from 0.2 to 0.41 for the workability traits. The inclusion of\ngenomic marker data improved these predictive abilities to 0.11 for honey\nyield, and a range from 0.22 to 0.44 for the workability traits. The inclusion\nof genomic data did not improve the predictive ability for the disease related\ntraits. Traits with high heritability for maternal effects compared to the\nheritability for direct effects showed the most promising results. Across all\ntraits, the bias with genomic methods was close to the bias with pedigree-based\nBLUP. The results show that genomic selection can successfully be applied to\nhoney bees.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.07397v1"
    },
    {
        "title": "Fast sequence to graph alignment using the graph wavefront algorithm",
        "authors": [
            "Haowen Zhang",
            "Shiqi Wu",
            "Srinivas Aluru",
            "Heng Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Motivation: A pan-genome graph represents a collection of genomes and encodes\nsequence variations between them. It is a powerful data structure for studying\nmultiple similar genomes. Sequence-to-graph alignment is an essential step for\nthe construction and the analysis of pan-genome graphs. However, existing\nalgorithms incur runtime proportional to the product of sequence length and\ngraph size, making them inefficient for aligning long sequences against large\ngraphs. Results: We propose the graph wavefront alignment algorithm (Gwfa), a\nnew method for aligning a sequence to a sequence graph. Although the worst-case\ntime complexity of Gwfa is the same as the existing algorithms, it is designed\nto run faster for closely matching sequences, and its runtime in practice often\nincreases only moderately with the edit distance of the optimal alignment. On\nfour real datasets, Gwfa is up to four orders of magnitude faster than other\nexact sequence-to-graph alignment algorithms. We also propose a graph pruning\nheuristic on top of Gwfa, which can achieve an additional $\\sim$10-fold speedup\non large graphs. Availability: Gwfa code is accessible at\nhttps://github.com/lh3/gwfa.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.13574v1"
    },
    {
        "title": "Benchmarking Machine Learning Robustness in Covid-19 Genome Sequence\n  Classification",
        "authors": [
            "Sarwan Ali",
            "Bikram Sahoo",
            "Alexander Zelikovskiy",
            "Pin-Yu Chen",
            "Murray Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The rapid spread of the COVID-19 pandemic has resulted in an unprecedented\namount of sequence data of the SARS-CoV-2 genome -- millions of sequences and\ncounting. This amount of data, while being orders of magnitude beyond the\ncapacity of traditional approaches to understanding the diversity, dynamics,\nand evolution of viruses is nonetheless a rich resource for machine learning\n(ML) approaches as alternatives for extracting such important information from\nthese data. It is of hence utmost importance to design a framework for testing\nand benchmarking the robustness of these ML models.\n  This paper makes the first effort (to our knowledge) to benchmark the\nrobustness of ML models by simulating biological sequences with errors. In this\npaper, we introduce several ways to perturb SARS-CoV-2 genome sequences to\nmimic the error profiles of common sequencing platforms such as Illumina and\nPacBio. We show from experiments on a wide array of ML models that some\nsimulation-based approaches are more robust (and accurate) than others for\nspecific embedding methods to certain adversarial attacks to the input\nsequences. Our benchmarking framework may assist researchers in properly\nassessing different ML models and help them understand the behavior of the\nSARS-CoV-2 virus or avoid possible future pandemics.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.08898v1"
    },
    {
        "title": "Bugs as Features (Part I): Concepts and Foundations for the\n  Compositional Data Analysis of the Microbiome-Gut-Brain Axis",
        "authors": [
            "Thomaz F. S. Bastiaanssen",
            "Thomas P. Quinn",
            "Amy Loughman"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  There has been a growing acknowledgement of the involvement of the gut\nmicrobiome - the collection of microbes that reside in our gut - in regulating\nour mood and behaviour. This phenomenon is referred to as the\nmicrobiome-gut-brain axis. While our techniques to measure the presence and\nabundance of these microbes have been steadily improving, the analysis of\nmicrobiome data is non-trivial.\n  Here, we present a perspective on the concepts and foundations of data\nanalysis and interpretation of microbiome experiments with a focus on the\nmicrobiome-gut-brain axis domain. We give an overview of foundational\nconsiderations prior to commencing analysis alongside the core microbiome\nanalysis approaches of alpha diversity, beta diversity, differential feature\nabundance and functional inference. We emphasize the compositional data\nanalysis (CoDA) paradigm.\n  Further, this perspective features an extensive and heavily annotated\nmicrobiome analysis in R in the supplementary materials, as a resource for new\nand experienced bioinformaticians alike.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.12475v3"
    },
    {
        "title": "Knowledge-Driven Mechanistic Enrichment of the Preeclampsia Ignorome",
        "authors": [
            "Tiffany J. Callahan",
            "Adrianne L. Stefanski",
            "Jin-Dong Kim",
            "William A. Baumgartner Jr.",
            "Jordan M. Wyrwa",
            "Lawrence E. Hunter"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Preeclampsia is a leading cause of maternal and fetal morbidity and\nmortality. Currently, the only definitive treatment of preeclampsia is delivery\nof the placenta, which is central to the pathogenesis of the disease.\nTranscriptional profiling of human placenta from pregnancies complicated by\npreeclampsia has been extensively performed to identify differentially\nexpressed genes (DEGs). The decisions to investigate DEGs experimentally are\nbiased by many factors, causing many DEGs to remain uninvestigated. A set of\nDEGs which are associated with a disease experimentally, but which have no\nknown association to the disease in the literature are known as the ignorome.\nPreeclampsia has an extensive body of scientific literature, a large pool of\nDEG data, and only one definitive treatment. Tools facilitating knowledge-based\nanalyses, which are capable of combining disparate data from many sources in\norder to suggest underlying mechanisms of action, may be a valuable resource to\nsupport discovery and improve our understanding of this disease. In this work\nwe demonstrate how a biomedical knowledge graph (KG) can be used to identify\nnovel preeclampsia molecular mechanisms. Existing open source biomedical\nresources and publicly available high-throughput transcriptional profiling data\nwere used to identify and annotate the function of currently uninvestigated\npreeclampsia-associated DEGs. Experimentally investigated genes associated with\npreeclampsia were identified from PubMed abstracts using text-mining\nmethodologies. The relative complement of the text-mined- and\nmeta-analysis-derived lists were identified as the uninvestigated\npreeclampsia-associated DEGs (n=445), i.e., the preeclampsia ignorome. Using\nthe KG to investigate relevant DEGs revealed 53 novel clinically relevant and\nbiologically actionable mechanistic associations.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.14294v2"
    },
    {
        "title": "Genome-wide nucleotide-resolution model of single-strand break site\n  reveals species evolutionary hierarchy",
        "authors": [
            "Sheng Xu",
            "Junkang Wei",
            "Yu Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Single-strand breaks (SSBs) are the major DNA damage in the genome arising\nspontaneously as the outcome of genotoxins and intermediates of DNA\ntransactions. SSBs play a crucial role in various biological processes and show\na non-random distribution in the genome. Several SSB detection approaches such\nas S1 END-seq and SSiNGLe-ILM emerged to characterize the genomic landscape of\nSSB with nucleotide resolution. However, these sequencing-based methods are\ncostly and unfeasible for large-scale analysis of diverse species. Thus, we\nproposed the first computational approach, SSBlazer, which is an explainable\nand scalable deep learning framework for genome-wide nucleotide-resolution SSB\nsite prediction. We demonstrated that SSBlazer can accurately predict SSB sites\nand sufficiently alleviate false positives by constructing an imbalanced\ndataset to simulate the realistic SSB distribution. The model interpretation\nanalysis reveals that SSBlazer captures the pattern of individual CpG in\ngenomic context and the motif of TGCC in the center region as critical\nfeatures. Besides, SSBlazer is a lightweight model with robust cross-species\ngeneralization ability in the cross-species evaluation, which enables the\nlarge-scale genome-wide application in diverse species. Strikingly, the\nputative SSB genomic landscapes of 216 vertebrates reveal a negative\ncorrelation between SSB frequency and evolutionary hierarchy, suggesting that\nthe genome tends to be integrity during evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.09813v1"
    },
    {
        "title": "CustOmics: A versatile deep-learning based strategy for multi-omics\n  integration",
        "authors": [
            "Hakim Benkirane",
            "Yoann Pradat",
            "Stefan Michiels",
            "Paul-Henry Cournède"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Recent advances in high-throughput sequencing technologies have enabled the\nextraction of multiple features that depict patient samples at diverse and\ncomplementary molecular levels. The generation of such data has led to new\nchallenges in computational biology regarding the integration of\nhigh-dimensional and heterogeneous datasets that capture the interrelationships\nbetween multiple genes and their functions. Thanks to their versatility and\nability to learn synthetic latent representations of complex data, deep\nlearning methods offer promising perspectives for integrating multi-omics data.\nThese methods have led to the conception of many original architectures that\nare primarily based on autoencoder models. However, due to the difficulty of\nthe task, the integration strategy is fundamental to take full advantage of the\nsources' particularities without losing the global trends. This paper presents\na novel strategy to build a customizable autoencoder model that adapts to the\ndataset used in the case of high-dimensional multi-source integration. We will\nassess the impact of integration strategies on the latent representation and\ncombine the best strategies to propose a new method, CustOmics\n(https://github.com/HakimBenkirane/CustOmics). We focus here on the integration\nof data from multiple omics sources and demonstrate the performance of the\nproposed method on test cases for several tasks such as classification and\nsurvival analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05485v1"
    },
    {
        "title": "SGC: A semi-supervised pipeline for gene clustering using self-training\n  approach in gene co-expression networks",
        "authors": [
            "Niloofar Aghaieabiane",
            "Ioannis Koutis"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  A widely used approach for extracting information from gene expression data\nemploy the construction of a gene co-expression network and the subsequent\napplication of algorithms that discover network structure. In particular, a\ncommon goal is the computational discovery of gene clusters, commonly called\nmodules. When applied on a novel gene expression dataset, the quality of the\ncomputed modules can be evaluated automatically, using Gene Ontology\nenrichment, a method that measures the frequencies of Gene Ontology terms in\nthe computed modules and evaluates their statistical likelihood. In this work\nwe propose SGC a novel pipeline for gene clustering based on relatively recent\nseminal work in the mathematics of spectral network theory. SGC consists of\nmultiple novel steps that enable the computation of highly enriched modules in\nan unsupervised manner. But unlike all existing frameworks, it further\nincorporates a novel step that leverages Gene Ontology information in a\nsemi-supervised clustering method that further improves the quality of the\ncomputed modules. Comparing with already well-known existing frameworks, we\nshow that SGC results in higher enrichment in real data. In particular, in 12\nreal gene expression datasets, SGC outperforms in all except one.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.10545v1"
    },
    {
        "title": "BioKlustering: a web app for semi-supervised learning of maximally\n  imbalanced genomic data",
        "authors": [
            "Samuel Ozminkowski",
            "Yuke Wu",
            "Hailey Bruzzone",
            "Liule Yang",
            "Zhiwen Xu",
            "Luke Selberg",
            "Chunrong Huang",
            "Helena Jaramillo-Mesa",
            "Claudia Solis-Lemus"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Summary: Accurate phenotype prediction from genomic sequences is a highly\ncoveted task in biological and medical research. While machine-learning holds\nthe key to accurate prediction in a variety of fields, the complexity of\nbiological data can render many methodologies inapplicable. We introduce\nBioKlustering, a user-friendly open-source and publicly available web app for\nunsupervised and semi-supervised learning specialized for cases when sequence\nalignment and/or experimental phenotyping of all classes are not possible.\nAmong its main advantages, BioKlustering 1) allows for maximally imbalanced\nsettings of partially observed labels including cases when only one class is\nobserved, which is currently prohibited in most semi-supervised methods, 2)\ntakes unaligned sequences as input and thus, allows learning for widely diverse\nsequences (impossible to align) such as virus and bacteria, 3) is easy to use\nfor anyone with little or no programming expertise, and 4) works well with\nsmall sample sizes.\n  Availability and Implementation: BioKlustering\n(https://bioklustering.wid.wisc.edu) is a freely available web app implemented\nwith Django, a Python-based framework, with all major browsers supported. The\nweb app does not need any installation, and it is publicly available and\nopen-source (https://github.com/solislemuslab/bioklustering).\n",
        "pdf_link": "http://arxiv.org/pdf/2209.11730v3"
    },
    {
        "title": "Deep learning forward and reverse primer design to detect SARS-CoV-2\n  emerging variants",
        "authors": [
            "Hanyu Wang",
            "Emmanuel K. Tsinda",
            "Anthony J. Dunn",
            "Francis Chikweto",
            "Nusreen Ahmed",
            "Emanuela Pelosi",
            "Alain B. Zemkoho"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Surges that have been observed at different periods in the number of COVID-19\ncases are associated with the emergence of multiple SARS-CoV-2 (Severe Acute\nRespiratory Virus) variants. The design of methods to support laboratory\ndetection are crucial in the monitoring of these variants. Hence, in this\npaper, we develop a semi-automated method to design both forward and reverse\nprimer sets to detect SARS-CoV-2 variants. To proceed, we train deep\nConvolution Neural Networks (CNNs) to classify labelled SARS-CoV-2 variants and\nidentify partial genomic features needed for the forward and reverse Polymerase\nChain Reaction (PCR) primer design. Our proposed approach supplements existing\nones while promoting the emerging concept of neural network assisted primer\ndesign for PCR. Our CNN model was trained using a database of SARS-CoV-2\nfull-length genomes from GISAID and tested on a separate dataset from NCBI,\nwith 98\\% accuracy for the classification of variants. This result is based on\nthe development of three different methods of feature extraction, and the\nselected primer sequences for each SARS-CoV-2 variant detection (except\nOmicron) were present in more than 95 \\% of sequences in an independent set of\n5000 same variant sequences, and below 5 \\% in other independent datasets with\n5000 sequences of each variant. In total, we obtain 22 forward and reverse\nprimer pairs with flexible length sizes (18-25 base pairs) with an expected\namplicon length ranging between 42 and 3322 nucleotides. Besides the feature\nappearance, in-silico primer checks confirmed that the identified primer pairs\nare suitable for accurate SARS-CoV-2 variant detection by means of PCR tests.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.13591v1"
    },
    {
        "title": "Application of Deep Learning on Single-Cell RNA-sequencing Data\n  Analysis: A Review",
        "authors": [
            "Matthew Brendel",
            "Chang Su",
            "Zilong Bai",
            "Hao Zhang",
            "Olivier Elemento",
            "Fei Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Single-cell RNA-sequencing (scRNA-seq) has become a routinely used technique\nto quantify the gene expression profile of thousands of single cells\nsimultaneously. Analysis of scRNA-seq data plays an important role in the study\nof cell states and phenotypes, and has helped elucidate biological processes,\nsuch as those occurring during development of complex organisms and improved\nour understanding of disease states, such as cancer, diabetes, and COVID, among\nothers. Deep learning, a recent advance of artificial intelligence that has\nbeen used to address many problems involving large datasets, has also emerged\nas a promising tool for scRNA-seq data analysis, as it has a capacity to\nextract informative, compact features from noisy, heterogeneous, and\nhigh-dimensional scRNA-seq data to improve downstream analysis. The present\nreview aims at surveying recently developed deep learning techniques in\nscRNA-seq data analysis, identifying key steps within the scRNA-seq data\nanalysis pipeline that have been advanced by deep learning, and explaining the\nbenefits of deep learning over more conventional analysis tools. Finally, we\nsummarize the challenges in current deep learning approaches faced within\nscRNA-seq data and discuss potential directions for improvements in deep\nalgorithms for scRNA-seq data analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.05677v1"
    },
    {
        "title": "Fast genomic optical map assembly algorithm using binary representation",
        "authors": [
            "Przemysław Stawczyk",
            "Robert Nowak"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Reducing the cost of sequencing genomes provided by next-generation\nsequencing technologies has greatly increased the number of genomic projects.\nAs a result, there is a growing need for better assembly and assembly\nvalidation methods. One promising idea is to use heterogeneous data in assembly\nprojects. Optical Mapping (OM) is beneficial in validating genomic assemblies,\ncorrection and scaffolding. Single raw OM read describes a DNA molecule's long\nfragment, up to 1Mbp. Raw OM data from the same genome could be assembled to\ncreate consensus maps that span an entire chromosome.\n  The assembly process is computationally hard because of the large number of\nerrors in input data.\n  This work describes a new algorithm and computer program to assemble OM reads\nwithout a reference genome. In our algorithm, we explored binary representation\nfor genome maps. We focused on the efficiency of data structures and algorithms\nand scale on parallel platforms. The algorithm consists of several steps, of\nwhich the most important are : (1) conversion of the restriction maps into\nbinary strings, (2) detection of overlaps between restriction maps, (3)\ndetermining the layout of restriction maps set, (4) creation of consensus\ngenomic maps. Our algorithm deals with optical mapping data with low error\nlevels but fails with high-level error reads.\n  We developed a software library, console application and module for Python\nlanguage. The approach presented in this paper proved to be faster than a\ndynamic programming approach and performed well on error-free data. It could be\nused as a step of \\textit{de~novo} assembly pipelines or to detect\nmisassemblies.The software is freely available in a public repository under GNU\nLGPL v3 license (https://sourceforge.net/p/binary-genome-maps/code).\n",
        "pdf_link": "http://arxiv.org/pdf/2210.06865v1"
    },
    {
        "title": "Challenging targets or describing mismatches? A comment on Common Decoy\n  Distribution by Madej et al",
        "authors": [
            "Lucas Etourneau",
            "Thomas Burger"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  In their recent article, Madej et al. 1 proposed an original way to solve the\nrecurrent issue of controlling for the false discovery rate (FDR) in\npeptide-spectrum-match (PSM) validation. Briefly, they proposed to derive a\nsingle precise distribution of decoy matches termed the Common Decoy\nDistribution (CDD) and to use it to control for FDR during a target-only\nsearch. Conceptually, this approach is appealing as it takes the best of two\nworlds, i.e., decoy-based approaches (which leverage a large-scale collection\nof empirical mismatches) and decoy-free approaches (which are not subject to\nthe randomness of decoy generation while sparing an additional database\nsearch). Interestingly, CDD also corresponds to a middle-of-the-road approach\nin statistics with respect to the two main families of FDR control procedures:\nAlthough historically based on estimating the falsepositive distribution, FDR\ncontrol has recently been demonstrated to be possible thanks to competition\nbetween the original variables (in proteomics, target sequences) and their\nfictional counterparts (in proteomics, decoys). Discriminating between these\ntwo theoretical trends is of prime importance for computational proteomics. In\naddition to highlighting why proteomics was a source of inspiration for\ntheoretical biostatistics, it provides practical insights into the improvements\nthat can be made to FDR control methods used in proteomics, including CDD.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.08815v1"
    },
    {
        "title": "Graph Coloring via Neural Networks for Haplotype Assembly and Viral\n  Quasispecies Reconstruction",
        "authors": [
            "Hansheng Xue",
            "Vaibhav Rajan",
            "Yu Lin"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Understanding genetic variation, e.g., through mutations, in organisms is\ncrucial to unravel their effects on the environment and human health. A\nfundamental characterization can be obtained by solving the haplotype assembly\nproblem, which yields the variation across multiple copies of chromosomes.\nVariations among fast evolving viruses that lead to different strains (called\nquasispecies) are also deciphered with similar approaches. In both these cases,\nhigh-throughput sequencing technologies that provide oversampled mixtures of\nlarge noisy fragments (reads) of genomes, are used to infer constituent\ncomponents (haplotypes or quasispecies). The problem is harder for polyploid\nspecies where there are more than two copies of chromosomes. State-of-the-art\nneural approaches to solve this NP-hard problem do not adequately model\nrelations among the reads that are important for deconvolving the input signal.\nWe address this problem by developing a new method, called NeurHap, that\ncombines graph representation learning with combinatorial optimization. Our\nexperiments demonstrate substantially better performance of NeurHap in real and\nsynthetic datasets compared to competing approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.12158v1"
    },
    {
        "title": "Efficient Cavity Searching for Gene Network of Influenza A Virus",
        "authors": [
            "Junjie Li",
            "Jietong Zhao",
            "Yanqing Su",
            "Jiahao Shen",
            "Yaohua Liu",
            "Xinyue Fan",
            "Zheng Kou"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  High order structures (cavities and cliques) of the gene network of influenza\nA virus reveal tight associations among viruses during evolution and are key\nsignals that indicate viral cross-species infection and cause pandemics. As\nindicators for sensing the dynamic changes of viral genes, these higher order\nstructures have been the focus of attention in the field of virology. However,\nthe size of the viral gene network is usually huge, and searching these\nstructures in the networks introduces unacceptable delay. To mitigate this\nissue, in this paper, we propose a simple-yet-effective model named HyperSearch\nbased on deep learning to search cavities in a computable complex network for\ninfluenza virus genetics. Extensive experiments conducted on a public influenza\nvirus dataset demonstrate the effectiveness of HyperSearch over other advanced\ndeep-learning methods without any elaborated model crafting. Moreover,\nHyperSearch can finish the search works in minutes while 0-1 programming takes\ndays. Since the proposed method is simple and easy to be transferred to other\ncomplex networks, HyperSearch has the potential to facilitate the monitoring of\ndynamic changes in viral genes and help humans keep up with the pace of virus\nmutations.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02935v1"
    },
    {
        "title": "Learning Causal Representations of Single Cells via Sparse Mechanism\n  Shift Modeling",
        "authors": [
            "Romain Lopez",
            "Nataša Tagasovska",
            "Stephen Ra",
            "Kyunghyn Cho",
            "Jonathan K. Pritchard",
            "Aviv Regev"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Latent variable models such as the Variational Auto-Encoder (VAE) have become\na go-to tool for analyzing biological data, especially in the field of\nsingle-cell genomics. One remaining challenge is the interpretability of latent\nvariables as biological processes that define a cell's identity. Outside of\nbiological applications, this problem is commonly referred to as learning\ndisentangled representations. Although several disentanglement-promoting\nvariants of the VAE were introduced, and applied to single-cell genomics data,\nthis task has been shown to be infeasible from independent and identically\ndistributed measurements, without additional structure. Instead, recent methods\npropose to leverage non-stationary data, as well as the sparse mechanism shift\nassumption in order to learn disentangled representations with a causal\nsemantic. Here, we extend the application of these methodological advances to\nthe analysis of single-cell genomics data with genetic or chemical\nperturbations. More precisely, we propose a deep generative model of\nsingle-cell gene expression data for which each perturbation is treated as a\nstochastic intervention targeting an unknown, but sparse, subset of latent\nvariables. We benchmark these methods on simulated single-cell data to evaluate\ntheir performance at latent units recovery, causal target identification and\nout-of-domain generalization. Finally, we apply those approaches to two\nreal-world large-scale gene perturbation data sets and find that models that\nexploit the sparse mechanism shift hypothesis surpass contemporary methods on a\ntransfer learning task. We implement our new model and benchmarks using the\nscvi-tools library, and release it as open-source software at\nhttps://github.com/Genentech/sVAE.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03553v4"
    },
    {
        "title": "DNA Methylation in hypoxia in Mycobacterium tuberculosis",
        "authors": [
            "Nayada Pandee",
            "Prasert Auewarakul",
            "Chanati Jantrachotechatchawan"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Tuberculosis is one of the most lethal contagious diseases caused by\nMycobacterium tuberculosis (MTB), in many cases, the infected did not show any\nsymptoms, because the bacilli entered the dormant stage in granulomas. The\ndormant stage of MTB is also associated with higher resistance to drugs and the\nimmune system. Among multiple epigenetic regulations critical to MTB stress\nresponses, DNA methylation is necessary for the survival of MTB in hypoxic\nconditions, which is a common stress event during granuloma formation. This\nreview gathers previous findings and demonstrates a meta-analysis by collecting\nhypoxia gene expression data from several articles and perform association\nanalysis between those genes and methylation site profiles across whole genomes\nof representative strains pf lineage 2 and 4. While more data is required for\nmore conclusive support, our results suggest that methylation sites in the\npossible promoter regions may induce differential gene regulation in hypoxia.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.04817v1"
    },
    {
        "title": "Efficient HLA imputation from sequential SNPs data by Transformer",
        "authors": [
            "Kaho Tanaka",
            "Kosuke Kato",
            "Naoki Nonaka",
            "Jun Seita"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Human leukocyte antigen (HLA) genes are associated with a variety of\ndiseases, however direct typing of HLA is time and cost consuming. Thus various\nimputation methods using sequential SNPs data have been proposed based on\nstatistical or deep learning models, e.g. CNN-based model, named DEEP*HLA.\nHowever, imputation efficiency is not sufficient for in frequent alleles and a\nlarge size of reference panel is required. Here, we developed a\nTransformer-based model to impute HLA alleles, named \"HLA Reliable IMputatioN\nby Transformer (HLARIMNT)\" to take advantage of sequential nature of SNPs data.\nWe validated the performance of HLARIMNT using two different reference panels;\nPan-Asian reference panel (n = 530) and Type 1 Diabetes Genetics Consortium\n(T1DGC) reference panel (n = 5,225), as well as the mixture of those two panels\n(n = 1,060). HLARIMNT achieved higher accuracy than DEEP*HLA by several\nindices, especially for infrequent alleles. We also varied the size of data\nused for training, and HLARIMNT imputed more accurately among any size of\ntraining data. These results suggest that Transformer-based model may impute\nefficiently not only HLA types but also any other gene types from sequential\nSNPs data.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.06430v1"
    },
    {
        "title": "Knowledge distillation for fast and accurate DNA sequence correction",
        "authors": [
            "Anastasiya Belyaeva",
            "Joel Shor",
            "Daniel E. Cook",
            "Kishwar Shafin",
            "Daniel Liu",
            "Armin Töpfer",
            "Aaron M. Wenger",
            "William J. Rowell",
            "Howard Yang",
            "Alexey Kolesnikov",
            "Cory Y. McLean",
            "Maria Nattestad",
            "Andrew Carroll",
            "Pi-Chuan Chang"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Accurate genome sequencing can improve our understanding of biology and the\ngenetic basis of disease. The standard approach for generating DNA sequences\nfrom PacBio instruments relies on HMM-based models. Here, we introduce\nDistilled DeepConsensus - a distilled transformer-encoder model for sequence\ncorrection, which improves upon the HMM-based methods with runtime constraints\nin mind. Distilled DeepConsensus is 1.3x faster and 1.5x smaller than its\nlarger counterpart while improving the yield of high quality reads (Q30) over\nthe HMM-based method by 1.69x (vs. 1.73x for larger model). With improved\naccuracy of genomic sequences, Distilled DeepConsensus improves downstream\napplications of genomic sequence analysis such as reducing variant calling\nerrors by 39% (34% for larger model) and improving genome assembly quality by\n3.8% (4.2% for larger model). We show that the representations learned by\nDistilled DeepConsensus are similar between faster and slower models.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.09862v1"
    },
    {
        "title": "iEnhancer-ELM: improve enhancer identification by extracting\n  position-related multiscale contextual information based on enhancer language\n  models",
        "authors": [
            "Jiahao Li",
            "Zhourun Wu",
            "Wenhao Lin",
            "Jiawei Luo",
            "Jun Zhang",
            "Qingcai Chen",
            "Junjie Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Motivation: Enhancers are important cis-regulatory elements that regulate a\nwide range of biological functions and enhance the transcription of target\ngenes. Although many feature extraction methods have been proposed to improve\nthe performance of enhancer identification, they cannot learn position-related\nmultiscale contextual information from raw DNA sequences.\n  Results: In this article, we propose a novel enhancer identification method\n(iEnhancer-ELM) based on BERT-like enhancer language models. iEnhancer-ELM\ntokenizes DNA sequences with multi-scale k-mers and extracts contextual\ninformation of different scale k-mers related with their positions via an\nmulti-head attention mechanism. We first evaluate the performance of different\nscale k-mers, then ensemble them to improve the performance of enhancer\nidentification. The experimental results on two popular benchmark datasets show\nthat our model outperforms stateof-the-art methods. We further illustrate the\ninterpretability of iEnhancer-ELM. For a case study, we discover 30 enhancer\nmotifs via a 3-mer-based model, where 12 of motifs are verified by STREME and\nJASPAR, demonstrating our model has a potential ability to unveil the\nbiological mechanism of enhancer.\n  Availability and implementation: The models and associated code are available\nat https://github.com/chen-bioinfo/iEnhancer-ELM\n  Contact: junjiechen@hit.edu.cn\n  Supplementary information: Supplementary data are available at Bioinformatics\nAdvances online.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01495v2"
    },
    {
        "title": "Shared Differential Clustering across Single-cell RNA Sequencing\n  Datasets with the Hierarchical Dirichlet Process",
        "authors": [
            "Jinlu Liu",
            "Sara Wade",
            "Natalia Bochkina"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Single-cell RNA sequencing (scRNA-seq) is powerful technology that allows\nresearchers to understand gene expression patterns at the single-cell level.\nHowever, analysing scRNA-seq data is challenging due to issues and biases in\ndata collection. In this work, we construct an integrated Bayesian model that\nsimultaneously addresses normalization, imputation and batch effects and also\nnonparametrically clusters cells into groups across multiple datasets. A Gibbs\nsampler based on a finite-dimensional approximation of the HDP is developed for\nposterior inference.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.02505v3"
    },
    {
        "title": "A Critical Review of the Impact of Candidate Copy Number Variants on\n  Autism Spectrum Disorders",
        "authors": [
            "Seyedeh Sedigheh Abedini",
            "Shiva Akhavan",
            "Julian Heng",
            "Roohallah Alizadehsani",
            "Iman Dehzangi",
            "Denis C. Bauer",
            "Hamid Rokny"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Autism spectrum disorder (ASD) is a heterogeneous neurodevelopmental disorder\n(NDD) that is caused by genetic, epigenetic, and environmental factors. Recent\nadvances in genomic analysis have uncovered numerous candidate genes with\ncommon and/or rare mutations that increase susceptibility to ASD. In addition,\nthere is increasing evidence that copy number variations (CNVs), single\nnucleotide polymorphisms (SNPs), and unusual de novo variants negatively affect\nneurodevelopment pathways in various ways. The overall rate of copy number\nvariants found in patients with autism is 10%-20%, of which 3%-7% can be\ndetected cytogenetically. Although the role of submicroscopic CNVs in ASD has\nbeen studied recently, their association with genomic loci and genes has not\nbeen properly studied. In this review, we focus on 47 ASD-associated CNV\nregions and their related genes. Here, we identify 1,632 protein-coding genes\nand long non-coding RNAs (lncRNAs) within these regions. Among them, 552 are\nsignificantly expressed in the brain. Using a list of ASD-associated genes from\nSFARI, we detect 17 regions containing at least one known ASD-associated\nprotein-coding genes. Of the remaining 30 regions, we identify 24 regions\ncontaining at least one protein-coding genes with brain-enriched expression and\nnervous system phenotype in mouse mutant and one lncRNAs with both\nbrain-enriched expression and upregulation in iPSC to neuron differentiation.\nOur analyses highlight the diversity of genetic lesions of CNV regions that\ncontribute to ASD and provide new genetic evidence that lncRNA genes may\ncontribute to etiology of ASD. In addition, the discovered CNVs will be a\nvaluable resource for diagnostic facilities, therapeutic strategies, and\nresearch in terms of variation priority.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03211v2"
    },
    {
        "title": "DDeMON: Ontology-based function prediction by Deep Learning from Dynamic\n  Multiplex Networks",
        "authors": [
            "Jan Kralj",
            "Blaž Škrlj",
            "Živa Ramšak",
            "Nada Lavrač",
            "Kristina Gruden"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Biological systems can be studied at multiple levels of information,\nincluding gene, protein, RNA and different interaction networks levels. The\ngoal of this work is to explore how the fusion of systems' level information\nwith temporal dynamics of gene expression can be used in combination with\nnon-linear approximation power of deep neural networks to predict novel gene\nfunctions in a non-model organism potato \\emph{Solanum tuberosum}. We propose\nDDeMON (Dynamic Deep learning from temporal Multiplex Ontology-annotated\nNetworks), an approach for scalable, systems-level inference of function\nannotation using time-dependent multiscale biological information. The proposed\nmethod, which is capable of considering billions of potential links between the\ngenes of interest, was applied on experimental gene expression data and the\nbackground knowledge network to reliably classify genes with unknown function\ninto five different functional ontology categories, linked to the experimental\ndata set. Predicted novel functions of genes were validated using extensive\nprotein domain search approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03907v1"
    },
    {
        "title": "A Multimodal Graph Neural Network Framework of Cancer Molecular Subtype\n  Classification",
        "authors": [
            "Bingjun Li",
            "Sheida Nabavi"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The recent development of high-throughput sequencing creates a large\ncollection of multi-omics data, which enables researchers to better investigate\ncancer molecular profiles and cancer taxonomy based on molecular subtypes.\nIntegrating multi-omics data has been proven to be effective for building more\nprecise classification models. Current multi-omics integrative models mainly\nuse early fusion by concatenation or late fusion based on deep neural networks.\nDue to the nature of biological systems, graphs are a better representation of\nbio-medical data. Although few graph neural network (GNN) based multi-omics\nintegrative methods have been proposed, they suffer from three common\ndisadvantages. One is most of them use only one type of connection, either\ninter-omics or intra-omic connection; second, they only consider one kind of\nGNN layer, either graph convolution network (GCN) or graph attention network\n(GAT); and third, most of these methods lack testing on a more complex cancer\nclassification task. We propose a novel end-to-end multi-omics GNN framework\nfor accurate and robust cancer subtype classification. The proposed model\nutilizes multi-omics data in the form of heterogeneous multi-layer graphs that\ncombines both inter-omics and intra-omic connections from established\nbiological knowledge. The proposed model incorporates learned graph features\nand global genome features for accurate classification. We test the proposed\nmodel on TCGA Pan-cancer dataset and TCGA breast cancer dataset for molecular\nsubtype and cancer subtype classification, respectively. The proposed model\noutperforms four current state-of-the-art baseline models in multiple\nevaluation metrics. The comparative analysis of GAT-based models and GCN-based\nmodels reveals that GAT-based models are preferred for smaller graphs with less\ninformation and GCN-based models are preferred for larger graphs with extra\ninformation.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12838v2"
    },
    {
        "title": "Single-Cell Multimodal Prediction via Transformers",
        "authors": [
            "Wenzhuo Tang",
            "Hongzhi Wen",
            "Renming Liu",
            "Jiayuan Ding",
            "Wei Jin",
            "Yuying Xie",
            "Hui Liu",
            "Jiliang Tang"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The recent development of multimodal single-cell technology has made the\npossibility of acquiring multiple omics data from individual cells, thereby\nenabling a deeper understanding of cellular states and dynamics. Nevertheless,\nthe proliferation of multimodal single-cell data also introduces tremendous\nchallenges in modeling the complex interactions among different modalities. The\nrecently advanced methods focus on constructing static interaction graphs and\napplying graph neural networks (GNNs) to learn from multimodal data. However,\nsuch static graphs can be suboptimal as they do not take advantage of the\ndownstream task information; meanwhile GNNs also have some inherent limitations\nwhen deeply stacking GNN layers. To tackle these issues, in this work, we\ninvestigate how to leverage transformers for multimodal single-cell data in an\nend-to-end manner while exploiting downstream task information. In particular,\nwe propose a scMoFormer framework which can readily incorporate external domain\nknowledge and model the interactions within each modality and cross modalities.\nExtensive experiments demonstrate that scMoFormer achieves superior performance\non various benchmark datasets. Remarkably, scMoFormer won a Kaggle silver medal\nwith the rank of 24/1221 (Top 2%) without ensemble in a NeurIPS 2022\ncompetition. Our implementation is publicly available at Github.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00233v3"
    },
    {
        "title": "Resource saving taxonomy classification with k-mer distributions and\n  machine learning",
        "authors": [
            "Wolfgang Fuhl",
            "Susanne Zabel",
            "Kay Nieselt"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Modern high throughput sequencing technologies like metagenomic sequencing\ngenerate millions of sequences which have to be classified based on their\ntaxonomic rank. Modern approaches either apply local alignment and comparison\nto existing data sets like MMseqs2 or use deep neural networks as it is done in\nDeepMicrobes and BERTax. Alignment-based approaches are costly in terms of\nruntime, especially since databases get larger and larger. For the deep\nlearning-based approaches, specialized hardware is necessary for a computation,\nwhich consumes large amounts of energy. In this paper, we propose to use\n$k$-mer distributions obtained from DNA as features to classify its taxonomic\norigin using machine learning approaches like the subspace $k$-nearest\nneighbors algorithm, neural networks or bagged decision trees. In addition, we\npropose a feature space data set balancing approach, which allows reducing the\ndata set for training and improves the performance of the classifiers. By\ncomparing performance, time, and memory consumption of our approach to those of\nstate-of-the-art algorithms (BERTax and MMseqs2) using several datasets, we\nshow that our approach improves the classification on the genus level and\nachieves comparable results for the superkingdom and phylum level.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FTaxonomyClassification&mode=list\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06154v1"
    },
    {
        "title": "LRDB: LSTM Raw data DNA Base-caller based on long-short term models in\n  an active learning environment",
        "authors": [
            "Ahmad Rezaei",
            "Mahdi Taheri",
            "Ali Mahani",
            "Sebastian Magierowski"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The first important step in extracting DNA characters is using the output\ndata of MinION devices in the form of electrical current signals. Various\ncutting-edge base callers use this data to detect the DNA characters based on\nthe input. In this paper, we discuss several shortcomings of prior base callers\nin the case of time-critical applications, privacy-aware design, and the\nproblem of catastrophic forgetting. Next, we propose the LRDB model, a\nlightweight open-source model for private developments with a better\nread-identity (0.35% increase) for the target bacterial samples in the paper.\nWe have limited the extent of training data and benefited from the transfer\nlearning algorithm to make the active usage of the LRDB viable in critical\napplications. Henceforth, less training time for adapting to new DNA samples\n(in our case, Bacterial samples) is needed. Furthermore, LRDB can be modified\nconcerning the user constraints as the results show a negligible accuracy loss\nin case of using fewer parameters. We have also assessed the noise-tolerance\nproperty, which offers about a 1.439% decline in accuracy for a 15dB noise\ninjection, and the performance metrics show that the model executes in a medium\nspeed range compared with current cutting-edge models.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08915v1"
    },
    {
        "title": "Studying Limits of Explainability by Integrated Gradients for Gene\n  Expression Models",
        "authors": [
            "Myriam Bontonou",
            "Anaïs Haget",
            "Maria Boulougouri",
            "Jean-Michel Arbona",
            "Benjamin Audit",
            "Pierre Borgnat"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Understanding the molecular processes that drive cellular life is a\nfundamental question in biological research. Ambitious programs have gathered a\nnumber of molecular datasets on large populations. To decipher the complex\ncellular interactions, recent work has turned to supervised machine learning\nmethods. The scientific questions are formulated as classical learning problems\non tabular data or on graphs, e.g. phenotype prediction from gene expression\ndata. In these works, the input features on which the individual predictions\nare predominantly based are often interpreted as indicative of the cause of the\nphenotype, such as cancer identification. Here, we propose to explore the\nrelevance of the biomarkers identified by Integrated Gradients, an\nexplainability method for feature attribution in machine learning. Through a\nmotivating example on The Cancer Genome Atlas, we show that ranking features by\nimportance is not enough to robustly identify biomarkers. As it is difficult to\nevaluate whether biomarkers reflect relevant causes without known ground truth,\nwe simulate gene expression data by proposing a hierarchical model based on\nLatent Dirichlet Allocation models. We also highlight good practices for\nevaluating explanations for genomics data and propose a direction to derive\nmore insights from these explanations.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11336v1"
    },
    {
        "title": "Transcriptomics-based matching of drugs to diseases with deep learning",
        "authors": [
            "Yannis Papanikolaou",
            "Francesco Tuveri",
            "Misa Ogura",
            "Daniel O'Donovan"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In this work we present a deep learning approach to conduct hypothesis-free,\ntranscriptomics-based matching of drugs for diseases. Our proposed neural\nnetwork architecture is trained on approved drug-disease indications, taking as\ninput the relevant disease and drug differential gene expression profiles, and\nlearns to identify novel indications. We assemble an evaluation dataset of\ndisease-drug indications spanning 68 diseases and evaluate in silico our\napproach against the most widely used transcriptomics-based matching baselines,\nCMap and the Characteristic Direction. Our results show a more than 200%\nimprovement over both baselines in terms of standard retrieval metrics. We\nfurther showcase our model's ability to capture different genes' expressions\ninteractions among drugs and diseases. We provide our trained models, data and\ncode to predict with them at https://github.com/healx/dgem-nn-public.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11695v1"
    },
    {
        "title": "The status of the human gene catalogue",
        "authors": [
            "Paulo Amaral",
            "Silvia Carbonell-Sala",
            "Francisco M. De La Vega",
            "Tiago Faial",
            "Adam Frankish",
            "Thomas Gingeras",
            "Roderic Guigo",
            "Jennifer L Harrow",
            "Artemis G. Hatzigeorgiou",
            "Rory Johnson",
            "Terence D. Murphy",
            "Mihaela Pertea",
            "Kim D. Pruitt",
            "Shashikant Pujar",
            "Hazuki Takahashi",
            "Igor Ulitsky",
            "Ales Varabyou",
            "Christine A. Wells",
            "Mark Yandell",
            "Piero Carninci",
            "Steven L. Salzberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Scientists have been trying to identify all of the genes in the human genome\nsince the initial draft of the genome was published in 2001. Over the\nintervening years, much progress has been made in identifying protein-coding\ngenes, and the estimated number has shrunk to fewer than 20,000, although the\nnumber of distinct protein-coding isoforms has expanded dramatically. The\ninvention of high-throughput RNA sequencing and other technological\nbreakthroughs have led to an explosion in the number of reported non-coding RNA\ngenes, although most of them do not yet have any known function. A combination\nof recent advances offers a path forward to identifying these functions and\ntowards eventually completing the human gene catalogue. However, much work\nremains to be done before we have a universal annotation standard that includes\nall medically significant genes, maintains their relationships with different\nreference genomes, and describes clinically relevant genetic variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.13996v1"
    },
    {
        "title": "On de novo Bridging Paired-end RNA-seq Data",
        "authors": [
            "Xiang Li",
            "Mingfu Shao"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The high-throughput short-reads RNA-seq protocols often produce paired-end\nreads, with the middle portion of the fragments being unsequenced. We explore\nif the full-length fragments can be computationally reconstructed from the\nsequenced two ends in the absence of the reference genome - a problem here we\nrefer to as de novo bridging. Solving this problem provides longer, more\ninformative RNA-seq reads, and benefits downstream RNA-seq analysis such as\ntranscript assembly, expression quantification, and splicing differential\nanalysis. However, de novo bridging is a challenging and complicated task owing\nto alternative splicing, transcript noises, and sequencing errors. It remains\nunclear if the data provides sufficient information for accurate bridging, let\nalone efficient algorithms that determine the true bridges. Methods have been\nproposed to bridge paired-end reads in the presence of reference genome (called\nreference-based bridging), but the algorithms are far away from scaling for de\nnovo bridging as the underlying compacted de Bruijn graph(cdBG) used in the\nlatter task often contains millions of vertices and edges. We designed a new\ntruncated Dijkstra's algorithm for this problem, and proposed a novel algorithm\nthat reuses the shortest path tree to avoid running the truncated Dijkstra's\nalgorithm from scratch for all vertices for further speeding up. These\ninnovative techniques result in scalable algorithms that can bridge all\npaired-end reads in a cdBG with millions of vertices. Our experiments showed\nthat paired-end RNA-seq reads can be accurately bridged to a large extent. The\nresulting tool is freely available at\nhttps://github.com/Shao-Group/rnabridge-denovo.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.15594v1"
    },
    {
        "title": "Revolutionizing Single Cell Analysis: The Power of Large Language Models\n  for Cell Type Annotation",
        "authors": [
            "Zehua Zeng",
            "Hongwu Du"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In recent years, single cell RNA sequencing has become a widely used\ntechnique to study cellular diversity and function. However, accurately\nannotating cell types from single cell data has been a challenging task, as it\nrequires extensive knowledge of cell biology and gene function. The emergence\nof large language models such as ChatGPT and New Bing in 2023 has\nrevolutionized this process by integrating the scientific literature and\nproviding accurate annotations of cell types. This breakthrough enables\nresearchers to conduct literature reviews more efficiently and accurately, and\ncan potentially uncover new insights into cell type annotation. By using\nChatGPT to annotate single cell data, we can relate rare cell type to their\nfunction and reveal specific differentiation trajectories of cell subtypes that\nwere previously overlooked. This can have important applications in\nunderstanding cancer progression, mammalian development, and stem cell\ndifferentiation, and can potentially lead to the discovery of key cells that\ninterrupt the differentiation pathway and solve key problems in the life\nsciences. Overall, the future of cell type annotation in single cell data looks\npromising and the Large Language model will be an important milestone in the\nhistory of single cell analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02697v1"
    },
    {
        "title": "ViralVectors: Compact and Scalable Alignment-free Virome Feature\n  Generation",
        "authors": [
            "Sarwan Ali",
            "Prakash Chourasia",
            "Zahra Tayebi",
            "Babatunde Bello",
            "Murray Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The amount of sequencing data for SARS-CoV-2 is several orders of magnitude\nlarger than any virus. This will continue to grow geometrically for SARS-CoV-2,\nand other viruses, as many countries heavily finance genomic surveillance\nefforts. Hence, we need methods for processing large amounts of sequence data\nto allow for effective yet timely decision-making. Such data will come from\nheterogeneous sources: aligned, unaligned, or even unassembled raw nucleotide\nor amino acid sequencing reads pertaining to the whole genome or regions (e.g.,\nspike) of interest. In this work, we propose \\emph{ViralVectors}, a compact\nfeature vector generation from virome sequencing data that allows effective\ndownstream analysis. Such generation is based on \\emph{minimizers}, a type of\nlightweight \"signature\" of a sequence, used traditionally in assembly and read\nmapping -- to our knowledge, the first use minimizers in this way. We validate\nour approach on different types of sequencing data: (a) 2.5M SARS-CoV-2 spike\nsequences (to show scalability); (b) 3K Coronaviridae spike sequences (to show\nrobustness to more genomic variability); and (c) 4K raw WGS reads sets taken\nfrom nasal-swab PCR tests (to show the ability to process unassembled reads).\nOur results show that ViralVectors outperforms current benchmarks in most\nclassification and clustering tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02891v2"
    },
    {
        "title": "Assessing the Reproducibility of Machine-learning-based Biomarker\n  Discovery in Parkinson's Disease",
        "authors": [
            "Ali Amelia",
            "Lourdes Pena-Castillo",
            "Hamid Usefi"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Genome-Wide Association Studies (GWAS) help identify genetic variations in\npeople with diseases such as Parkinson's disease (PD), which are less common in\nthose without the disease. Thus, GWAS data can be used to identify genetic\nvariations associated with the disease. Feature selection and machine learning\napproaches can be used to analyze GWAS data and identify potential disease\nbiomarkers. However, GWAS studies have technical variations that affect the\nreproducibility of identified biomarkers, such as differences in genotyping\nplatforms and selection criteria for individuals to be genotyped. To address\nthis issue, we collected five GWAS datasets from the database of Genotypes and\nPhenotypes (dbGaP) and explored several data integration strategies. We\nevaluated the agreement among different strategies in terms of the Single\nNucleotide Polymorphisms (SNPs) that were identified as potential PD\nbiomarkers. Our results showed a low concordance of biomarkers discovered using\ndifferent datasets or integration strategies. However, we identified fifty SNPs\nthat were identified at least twice, which could potentially serve as novel PD\nbiomarkers. These SNPs are indirectly linked to PD in the literature but have\nnot been directly associated with PD before. These findings open up new\npotential avenues of investigation.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.03239v1"
    },
    {
        "title": "UNADON: Transformer-based model to predict genome-wide chromosome\n  spatial position",
        "authors": [
            "Muyu Yang",
            "Jian Ma"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The spatial positioning of chromosomes relative to functional nuclear bodies\nis intertwined with genome functions such as transcription. However, the\nsequence patterns and epigenomic features that collectively influence chromatin\nspatial positioning in a genome-wide manner are not well understood. Here, we\ndevelop a new transformer-based deep learning model called UNADON, which\npredicts the genome-wide cytological distance to a specific type of nuclear\nbody, as measured by TSA-seq, using both sequence features and epigenomic\nsignals. Evaluations of UNADON in four cell lines (K562, H1, HFFc6, HCT116)\nshow high accuracy in predicting chromatin spatial positioning to nuclear\nbodies when trained on a single cell line. UNADON also performed well in an\nunseen cell type. Importantly, we reveal potential sequence and epigenomic\nfactors that affect large-scale chromatin compartmentalization to nuclear\nbodies. Together, UNADON provides new insights into the principles between\nsequence features and large-scale chromatin spatial localization, which has\nimportant implications for understanding nuclear structure and function.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.13230v2"
    },
    {
        "title": "Data navigation on the ENCODE portal",
        "authors": [
            "Meenakshi S. Kagda",
            "Bonita Lam",
            "Casey Litton",
            "Corinn Small",
            "Cricket A. Sloan",
            "Emma Spragins",
            "Forrest Tanaka",
            "Ian Whaling",
            "Idan Gabdank",
            "Ingrid Youngworth",
            "J. Seth Strattan",
            "Jason Hilton",
            "Jennifer Jou",
            "Jessica Au",
            "Jin-Wook Lee",
            "Kalina Andreeva",
            "Keenan Graham",
            "Khine Lin",
            "Matt Simison",
            "Otto Jolanki",
            "Paul Sud",
            "Pedro Assis",
            "Philip Adenekan",
            "Eric Douglas",
            "Mingjie Li",
            "Pedro Assis",
            "Keenan Graham",
            "Paul Sud",
            "Stuart Miyasato",
            "Weiwei Zhong",
            "Yunhai Luo",
            "Zachary Myers",
            "J. Michael Cherry",
            "Benjamin C. Hitz"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Spanning two decades, the Encyclopaedia of DNA Elements (ENCODE) is a\ncollaborative research project that aims to identify all the functional\nelements in the human and mouse genomes. To best serve the scientific\ncommunity, all data generated by the consortium is shared through a web-portal\n(https://www.encodeproject.org/) with no access restrictions. The fourth and\nfinal phase of the project added a diverse set of new samples (including those\nassociated with human disease), and a wide range of new assays aimed at\ndetection, characterization and validation of functional genomic elements. The\nENCODE data portal hosts results from over 23,000 functional genomics\nexperiments, over 800 functional elements characterization experiments\n(including in vivo transgenic enhancer assays, reporter assays and CRISPR\nscreens) along with over 60,000 results of computational and integrative\nanalyses (including imputations, predictions and genome annotations). The\nENCODE Data Coordination Center (DCC) is responsible for development and\nmaintenance of the data portal, along with the implementation and utilisation\nof the ENCODE uniform processing pipelines to generate uniformly processed\ndata. Here we report recent updates to the data portal. Specifically, we have\ncompletely redesigned the home page, improved search interface, added several\nnew pages to highlight collections of biologically related data (deeply\nprofiled cell lines, immune cells, Alzheimer's Disease, RNA-Protein\ninteractions, degron matrix and a matrix of experiments organised by human\ndonors), added single-cell experiments, and enhanced the cart interface for\nvisualisation and download of user-selected datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00006v2"
    },
    {
        "title": "Generalizability of PRS313 for breast cancer risk amongst non-Europeans\n  in a Los Angeles biobank",
        "authors": [
            "Helen Shang",
            "Yi Ding",
            "Vidhya Venkateswaran",
            "Kristin Boulier",
            "Nikhita Kathuria-Prakash",
            "Parisa Boodaghi Malidarreh",
            "Jacob M. Luber",
            "Bogdan Pasaniuc"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Polygenic risk scores (PRS) summarize the combined effect of common risk\nvariants and are associated with breast cancer risk in patients without\nidentifiable monogenic risk factors. One of the most well-validated PRSs in\nbreast cancer to date is PRS313, which was developed from a Northern European\nbiobank but has shown attenuated performance in non-European ancestries. We\nfurther investigate the generalizability of the PRS313 for American women of\nEuropean (EA), African (AFR), Asian (EAA), and Latinx (HL) ancestry within one\ninstitution with a singular EHR system, genotyping platform, and quality\ncontrol process. We found that the PRS313 achieved overlapping Areas under the\nROC Curve (AUCs) in females of Lantix (AUC, 0.68; 95 CI, 0.65-0.71) and\nEuropean ancestry (AUC, 0.70; 95 CI, 0.69-0.71) but lower AUCs for the AFR and\nEAA populations (AFR: AUC, 0.61; 95 CI, 0.56-0.65; EAA: AUC, 0.64; 95 CI,\n0.60-0.680). While PRS313 is associated with Hormone Positive (HR+) disease in\nEuropean Americans (OR, 1.42; 95 CI, 1.16-1.64), for Latinx females, it may be\ninstead associated with Human Epidermal Growth Factor Receptor 2 (HER2+)\ndisease (OR, 2.52; 95 CI, 1.35-4.70) although due to small numbers, additional\nstudies are needed. In summary, we found that PRS313 was significantly\nassociated with breast cancer but with attenuated accuracy in women of African\nand Asian descent within a singular health system in Los Angeles. Our work\nfurther highlights the need for additional validation in diverse cohorts prior\nto clinical implementation of polygenic risk scores.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.03893v1"
    },
    {
        "title": "Fuzzy Gene Selection and Cancer Classification Based on Deep Learning\n  Model",
        "authors": [
            "Mahmood Khalsan",
            "Mu Mu",
            "Eman Salih Al-Shamery",
            "Lee Machado",
            "Suraj Ajit",
            "Michael Opoku Agyeman"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Machine learning (ML) approaches have been used to develop highly accurate\nand efficient applications in many fields including bio-medical science.\nHowever, even with advanced ML techniques, cancer classification using gene\nexpression data is still complicated because of the high dimensionality of the\ndatasets employed. We developed a new fuzzy gene selection technique (FGS) to\nidentify informative genes to facilitate cancer classification and reduce the\ndimensionality of the available gene expression data. Three feature selection\nmethods (Mutual Information, F-ClassIf, and Chi-squared) were evaluated and\nemployed to obtain the score and rank for each gene. Then, using Fuzzification\nand Defuzzification methods to obtain the best single score for each gene,\nwhich aids in the identification of significant genes. Our study applied the\nfuzzy measures to six gene expression datasets including four Microarray and\ntwo RNA-seq datasets for evaluating the proposed algorithm. With our\nFGS-enhanced method, the cancer classification model achieved 96.5%,96.2%,96%,\nand 95.9% for accuracy, precision, recall, and f1-score respectively, which is\nsignificantly higher than 69.2% accuracy, 57.8% precision, 66% recall, and\n58.2% f1-score when the standard MLP method was used. In examining the six\ndatasets that were used, the proposed model demonstrates it's capacity to\nclassify cancer effectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.04883v1"
    },
    {
        "title": "Bugs as Features (Part II): A Perspective on Enriching\n  Microbiome-Gut-Brain Axis Analyses",
        "authors": [
            "Thomaz F. S. Bastiaanssen",
            "Thomas P. Quinn",
            "Amy Loughman"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The microbiome-gut-brain-axis field is multidisciplinary, benefiting from the\nexpertise of microbiology, ecology, psychiatry, computational biology, and\nepidemiology amongst other disciplines. As the field matures and moves beyond a\nbasic demonstration of its relevance, it is critical that study design and\nanalysis are robust and foster reproducibility.\n  In this companion piece to Bugs as Features (part I), we present techniques\nfrom adjacent and disparate fields to enrich and inform the analysis of\nmicrobiome-gut-brain-axis data. Emerging techniques built specifically for the\nmicrobiome-gut-brain axis are also demonstrated. All of these methods are\ncontextualised to inform several common challenges: how do we establish\ncausality? How can we integrate data from multiple 'omics techniques? How might\nwe account for the dynamicism of host-microbiome interactions?\n  This perspective is offered to experienced and emerging microbiome scientists\nalike, to assist with these questions and others, at the study conception,\ndesign, analysis and interpretation stages of research.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11703v2"
    },
    {
        "title": "On Selecting Distance Metrics in $n$-Dimensional Normed Vector Spaces of\n  Cells: A Novel Criterion and Similarity Measure Towards Efficient and\n  Accurate Omics Analysis",
        "authors": [
            "Okezue Bell",
            "Arthur Lee",
            "Elizabeth Engle"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Single-cell omics enable the profiles of cells, which contain large numbers\nof biological features, to be quantified. Cluster analysis, a dimensionality\nreduction process, is used to reduce the dimensions of the data to make it\ncomputationally tractable. In these analyses, cells are represented as vectors\nin $n$-Dimensional space, where each dimension corresponds to a certain cell\nfeature. The distance between cells is used as a surrogate measure of\nsimilarity, providing insight into the cell's state, function, and genetic\nmechanisms. However, as cell profiles are clustered in 3D or higher-dimensional\nspace, it remains unknown which distance metric provides the most accurate\nspatiotemporal representation of similarity, limiting the interpretability of\nthe data. I propose and prove a generalized proposition and set of corollaries\nthat serve as a criterion to determine which of the standard distance measures\nis most accurate for conveying cell profile heterogeneity. Each distance method\nis evaluated via statistical, geometric, and topological proofs, which are\nformalized into a set of criteria. In this paper, I present the putative,\nfirst-ever method to elect the most accurate and precise distance metrics with\nany profiling modality, which are determined to be the Wasserstein distance and\ncosine similarity metrics, respectively, in general cases. I also identify\nspecial cases in which the criterion may select non-standard metrics. Combining\nthe metric properties selected by the criterion, I develop a novel, custom,\noptimal distance metric that demonstrates superior computational efficiency,\npeak annotation, motif identification, and footprinting for transcription\nfactor binding sites when compared with leading methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.09243v2"
    },
    {
        "title": "Heat shock proteins may be a missing link between febrile infection and\n  cancer tumor rejection via autoantigen molecular mimicry",
        "authors": [
            "Amin Zia"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Numerous epidemiological studies suggest febrile infections could confer\nlong-term immunity to certain types of cancers, though the precise mechanisms\nfor this phenomenon remain unclear. Systemic heat-shock responses to fever may\nbe key to understanding the overlapping outcomes of immune responses to\ninfection and cancer. To investigate this hypothesis, we performed epitope\ndiscovery between heat-shock proteins (HSP) and cancer-associated antigens\n(CAA) and annotated the results with experimentally validated epitopes in the\nImmune Epitope Database (IEDB) (Vita et al., 2019). Further, epitopes were\nmatched with their homologs in human pathogens. Results identified 94 epitopes\nshared between HSPs and CAAs, with experimental evidence of presentation at MHC\nmolecules and with high homology to several epitopes of human pathogens. The\nidentified epitopes can be used as candidates for designing cancer vaccines.\nThey may also be used to identify autoreactive antibodies or TCR specificities\nthat, as antibody drugs and cell therapies, would reproduce the effect of\nfebrile infection in conferring cancer immunity. Our results support the\nhypothesis that the loss of self-tolerance to HSPs during febrile infection\nconfers tumor immunity through molecular mimicry.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.13582v1"
    },
    {
        "title": "DNAGPT: A Generalized Pre-trained Tool for Versatile DNA Sequence\n  Analysis Tasks",
        "authors": [
            "Daoan Zhang",
            "Weitong Zhang",
            "Yu Zhao",
            "Jianguo Zhang",
            "Bing He",
            "Chenchen Qin",
            "Jianhua Yao"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Pre-trained large language models demonstrate potential in extracting\ninformation from DNA sequences, yet adapting to a variety of tasks and data\nmodalities remains a challenge. To address this, we propose DNAGPT, a\ngeneralized DNA pre-training model trained on over 200 billion base pairs from\nall mammals. By enhancing the classic GPT model with a binary classification\ntask (DNA sequence order), a numerical regression task (guanine-cytosine\ncontent prediction), and a comprehensive token language, DNAGPT can handle\nversatile DNA analysis tasks while processing both sequence and numerical data.\nOur evaluation of genomic signal and region recognition, mRNA abundance\nregression, and artificial genomes generation tasks demonstrates DNAGPT's\nsuperior performance compared to existing models designed for specific\ndownstream tasks, benefiting from pre-training using the newly designed model\nstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.05628v3"
    },
    {
        "title": "regulAS: A Bioinformatics Tool for the Integrative Analysis of\n  Alternative Splicing Regulome using RNA-Seq data",
        "authors": [
            "Sofya Lipnitskaya"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The regulAS software package is a bioinformatics tool designed to support\ncomputational biology researchers in investigating regulatory mechanisms of\nsplicing alterations through integrative analysis of large-scale RNA-Seq data\nfrom cancer and healthy human donors, characterized by TCGA and GTEx projects.\nThis technical report provides a comprehensive overview of regulAS, focusing on\nits core functionality, basic modules, experiment configuration, further\nextensibility and customisation.\n  The core functionality of regulAS enables the automation of computational\nexperiments, efficient results storage and processing, and streamlined workflow\nmanagement. Integrated basic modules extend regulAS with features such as\nRNA-Seq data retrieval from the public multi-omics UCSC Xena data repository,\npredictive modeling and feature ranking capabilities using the scikit-learn\npackage, and flexible reporting generation for analysing gene expression\nprofiles and relevant modulations of alternative splicing aberrations across\ntissues and cancer types. Experiment configuration is handled through YAML\nfiles with the Hydra and OmegaConf libraries, offering a user-friendly\napproach. Additionally, regulAS allows for the development and integration of\ncustom modules to handle specialized tasks.\n  In conclusion, regulAS provides an automated solution for alternative\nsplicing and cancer biology studies, enhancing efficiency, reproducibility, and\ncustomization of experimental design, while the extensibility of the pipeline\nenables researchers to further tailor the software package to their specific\nneeds. Source code is available under the MIT license at\nhttps://github.com/slipnitskaya/regulAS.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.08800v1"
    },
    {
        "title": "ProtiGeno: a prokaryotic short gene finder using protein language models",
        "authors": [
            "Tony Tu",
            "Gautham Krishna",
            "Amirali Aghazadeh"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Prokaryotic gene prediction plays an important role in understanding the\nbiology of organisms and their function with applications in medicine and\nbiotechnology. Although the current gene finders are highly sensitive in\nfinding long genes, their sensitivity decreases noticeably in finding shorter\ngenes (<180 nts). The culprit is insufficient annotated gene data to identify\ndistinguishing features in short open reading frames (ORFs). We develop a deep\nlearning-based method called ProtiGeno, specifically targeting short\nprokaryotic genes using a protein language model trained on millions of evolved\nproteins. In systematic large-scale experiments on 4,288 prokaryotic genomes,\nwe demonstrate that ProtiGeno predicts short coding and noncoding genes with\nhigher accuracy and recall than the current state-of-the-art gene finders. We\ndiscuss the predictive features of ProtiGeno and possible limitations by\nvisualizing the three-dimensional structure of the predicted short genes. Data,\ncodes, and models are available at https://github.com/tonytu16/protigeno.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.10343v1"
    },
    {
        "title": "Vector Embeddings by Sequence Similarity and Context for Improved\n  Compression, Similarity Search, Clustering, Organization, and Manipulation of\n  cDNA Libraries",
        "authors": [
            "Daniel H. Um",
            "David A. Knowles",
            "Gail E. Kaiser"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  This paper demonstrates the utility of organized numerical representations of\ngenes in research involving flat string gene formats (i.e., FASTA/FASTQ5).\nFASTA/FASTQ files have several current limitations, such as their large file\nsizes, slow processing speeds for mapping and alignment, and contextual\ndependencies. These challenges significantly hinder investigations and tasks\nthat involve finding similar sequences. The solution lies in transforming\nsequences into an alternative representation that facilitates easier clustering\ninto similar groups compared to the raw sequences themselves. By assigning a\nunique vector embedding to each short sequence, it is possible to more\nefficiently cluster and improve upon compression performance for the string\nrepresentations of cDNA libraries. Furthermore, through learning alternative\ncoordinate vector embeddings based on the contexts of codon triplets, we can\ndemonstrate clustering based on amino acid properties. Finally, using this\nsequence embedding method to encode barcodes and cDNA sequences, we can improve\nthe time complexity of the similarity search by coupling vector embeddings with\nan algorithm that determines the proximity of vectors in Euclidean space; this\nallows us to perform sequence similarity searches in a quicker and more modular\nfashion.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.05118v1"
    },
    {
        "title": "ensemblQueryR: fast, flexible and high-throughput querying of Ensembl LD\n  API endpoints in R",
        "authors": [
            "Aine Fairbrother-Browne",
            "Sonia García-Ruiz",
            "Regina H Reynolds",
            "Mina Ryten",
            "Alan Hodgkinson"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  We present ensemblQueryR, a package providing an R interface to the Ensembl\nREST API that facilitates flexible, fast, user-friendly and R workflow\nintegrable querying of Ensembl REST API linkage disequilibrium (LD) endpoints,\noptimised for high-throughput querying. ensemblQueryR achieves this through\nfunctions that are intuitive and amenable to custom code integration, use of\nfamiliar R object types as inputs and outputs, code optimisation and optional\nparallelisation functionality. For each LD endpoint, ensemblQueryR provides two\nfunctions, permitting both single-query and multi-query modes of operation. The\nmulti-query functions are optimised for large query sizes and provide optional\nparallelisation to leverage available computational resources and minimise\nprocessing time. We demonstrate that ensemblQueryR has improved performance in\nterms of random access memory (RAM) usage and speed, delivering a 10-fold speed\nincrease over analogous software whilst using a third of the RAM. Finally,\nensemblQueryR is near-agnostic to operating system and computational\narchitecture through availability of Docker and singularity images, making this\ntool widely accessible to the scientific community.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.06792v1"
    },
    {
        "title": "Generalising sequence models for epigenome predictions with tissue and\n  assay embeddings",
        "authors": [
            "Jacob Deasy",
            "Ron Schwessinger",
            "Ferran Gonzalez",
            "Stephen Young",
            "Kim Branson"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Sequence modelling approaches for epigenetic profile prediction have recently\nexpanded in terms of sequence length, model size, and profile diversity.\nHowever, current models cannot infer on many experimentally feasible tissue and\nassay pairs due to poor usage of contextual information, limiting $\\textit{in\nsilico}$ understanding of regulatory genomics. We demonstrate that strong\ncorrelation can be achieved across a large range of experimental conditions by\nintegrating tissue and assay embeddings into a Contextualised Genomic Network\n(CGN). In contrast to previous approaches, we enhance long-range sequence\nembeddings with contextual information in the input space, rather than\nexpanding the output space. We exhibit the efficacy of our approach across a\nbroad set of epigenetic profiles and provide the first insights into the effect\nof genetic variants on epigenetic sequence model training. Our general approach\nto context integration exceeds state of the art in multiple settings while\nemploying a more rigorous validation procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.11671v1"
    },
    {
        "title": "XVir: A Transformer-Based Architecture for Identifying Viral Reads from\n  Cancer Samples",
        "authors": [
            "Shorya Consul",
            "John Robertson",
            "Haris Vikalo"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  It is estimated that approximately 15% of cancers worldwide can be linked to\nviral infections. The viruses that can cause or increase the risk of cancer\ninclude human papillomavirus, hepatitis B and C viruses, Epstein-Barr virus,\nand human immunodeficiency virus, to name a few. The computational analysis of\nthe massive amounts of tumor DNA data, whose collection is enabled by the\nrecent advancements in sequencing technologies, have allowed studies of the\npotential association between cancers and viral pathogens. However, the high\ndiversity of oncoviral families makes reliable detection of viral DNA difficult\nand thus, renders such analysis challenging. In this paper, we introduce XVir,\na data pipeline that relies on a transformer-based deep learning architecture\nto reliably identify viral DNA present in human tumors. In particular, XVir is\ntrained on genomic sequencing reads from viral and human genomes and may be\nused with tumor sequence information to find evidence of viral DNA in human\ncancers. Results on semi-experimental data demonstrate that XVir is capable of\nachieving high detection accuracy, generally outperforming state-of-the-art\ncompeting methods while being more compact and less computationally demanding.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.14769v1"
    },
    {
        "title": "BRCA Gene Mutations in dbSNP: A Visual Exploration of Genetic Variants",
        "authors": [
            "Woowon Jang",
            "Shiwoo Koak",
            "Jiwon Im",
            "Utku Ozbulak",
            "Joris Vankerschaver"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  BRCA genes, comprising BRCA1 and BRCA2 play indispensable roles in preserving\ngenomic stability and facilitating DNA repair mechanisms. The presence of\ngermline mutations in these genes has been associated with increased\nsusceptibility to various cancers, notably breast and ovarian cancers. Recent\nadvancements in cost-effective sequencing technologies have revolutionized the\nlandscape of cancer genomics, leading to a notable rise in the number of\nsequenced cancer patient genomes, enabling large-scale computational studies.\nIn this study, we delve into the BRCA mutations in the dbSNP, housing an\nextensive repository of 41,177 and 44,205 genetic mutations for BRCA1 and\nBRCA2, respectively. Employing meticulous computational analysis from an\numbrella perspective, our research unveils intriguing findings pertaining to a\nnumber of critical aspects. Namely, we discover that the majority of BRCA\nmutations in dbSNP have unknown clinical significance. We find that, although\nexon 11 for both genes contains the majority of the mutations and may seem as\nif it is a mutation hot spot, upon analyzing mutations per base pair, we find\nthat all exons exhibit similar levels of mutations. Investigating mutations\nwithin introns, while we observe that the recorded mutations are generally\nuniformly distributed, almost all of the pathogenic mutations in introns are\nlocated close to splicing regions (at the beginning or the end). In addition to\nthe findings mentioned earlier, we have also made other discoveries concerning\nmutation types and the level of confidence in observations within the dbSNP\ndatabase.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.00311v1"
    },
    {
        "title": "Blind Biological Sequence Denoising with Self-Supervised Set Learning",
        "authors": [
            "Nathan Ng",
            "Ji Won Park",
            "Jae Hyeon Lee",
            "Ryan Lewis Kelly",
            "Stephen Ra",
            "Kyunghyun Cho"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Biological sequence analysis relies on the ability to denoise the imprecise\noutput of sequencing platforms. We consider a common setting where a short\nsequence is read out repeatedly using a high-throughput long-read platform to\ngenerate multiple subreads, or noisy observations of the same sequence.\nDenoising these subreads with alignment-based approaches often fails when too\nfew subreads are available or error rates are too high. In this paper, we\npropose a novel method for blindly denoising sets of sequences without directly\nobserving clean source sequence labels. Our method, Self-Supervised Set\nLearning (SSSL), gathers subreads together in an embedding space and estimates\na single set embedding as the midpoint of the subreads in both the latent and\nsequence spaces. This set embedding represents the \"average\" of the subreads\nand can be decoded into a prediction of the clean sequence. In experiments on\nsimulated long-read DNA data, SSSL methods denoise small reads of $\\leq 6$\nsubreads with 17% fewer errors and large reads of $>6$ subreads with 8% fewer\nerrors compared to the best baseline. On a real dataset of antibody sequences,\nSSSL improves over baselines on two self-supervised metrics, with a significant\nimprovement on difficult small reads that comprise over 60% of the test set. By\naccurately denoising these reads, SSSL promises to better realize the potential\nof high-throughput DNA sequencing data for downstream scientific applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01670v1"
    },
    {
        "title": "RawHash2: Mapping Raw Nanopore Signals Using Hash-Based Seeding and\n  Adaptive Quantization",
        "authors": [
            "Can Firtina",
            "Melina Soysal",
            "Joël Lindegger",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Summary: Raw nanopore signals can be analyzed while they are being generated,\na process known as real-time analysis. Real-time analysis of raw signals is\nessential to utilize the unique features that nanopore sequencing provides,\nenabling the early stopping of the sequencing of a read or the entire\nsequencing run based on the analysis. The state-of-the-art mechanism, RawHash,\noffers the first hash-based efficient and accurate similarity identification\nbetween raw signals and a reference genome by quickly matching their hash\nvalues. In this work, we introduce RawHash2, which provides major improvements\nover RawHash, including a more sensitive quantization and chaining\nimplementation, weighted mapping decisions, frequency filters to reduce\nambiguous seed hits, minimizers for hash-based sketching, and support for the\nR10.4 flow cell version and various data formats such as POD5 and SLOW5.\nCompared to RawHash, RawHash2 provides better F1 accuracy (on average by 10.57%\nand up to 20.25%) and better throughput (on average by 4.0x and up to 9.9x)\nthan RawHash. Availability and Implementation: RawHash2 is available at\nhttps://github.com/CMU-SAFARI/RawHash. We also provide the scripts to fully\nreproduce our results on our GitHub page.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.05771v5"
    },
    {
        "title": "Embed-Search-Align: DNA Sequence Alignment using Transformer Models",
        "authors": [
            "Pavan Holur",
            "K. C. Enevoldsen",
            "Shreyas Rajesh",
            "Lajoyce Mboning",
            "Thalia Georgiou",
            "Louis-S. Bouchard",
            "Matteo Pellegrini",
            "Vwani Roychowdhury"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  DNA sequence alignment involves assigning short DNA reads to the most\nprobable locations on an extensive reference genome. This process is crucial\nfor various genomic analyses, including variant calling, transcriptomics, and\nepigenomics. Conventional methods, refined over decades, tackle this challenge\nin 2 steps: genome indexing followed by efficient search to locate likely\npositions for given reads. Building on the success of Large Language Models in\nencoding text into embeddings, where the distance metric captures semantic\nsimilarity, recent efforts have explored whether the same Transformer\narchitecture can produce embeddings for DNA sequences. Such models have shown\nearly promise in classifying short DNA sequences, such as detecting\ncoding/non-coding regions, and enhancer, promoter sequences. However,\nperformance at sequence classification tasks does not translate to sequence\nalignment, where it is necessary to search across the genome to align each\nread, a significantly longer-range task. We bridge this gap by framing the\nSequence Alignment task for Transformer models as an \"Embed-Search-Align\" task.\nIn this framework, a novel Reference-Free DNA Embedding model generates\nembeddings of reads and reference fragments, which are projected into a shared\nvector space where the read-fragment distance is used as a surrogate for\nalignment. Technical contributions include: (1) Contrastive loss for\nself-supervised training of DNA sequence representations, facilitating rich\nreference-free, sequence-level embeddings, and (2) a DNA vector store to enable\nsearch across fragments on a global scale. DNA-ESA is 99% accurate when\naligning 250-length reads onto a human genome (3gb), rivaling conventional\nmethods such as Bowtie and BWA-Mem. DNA-ESA exceeds the performance of 6\nTransformer model baselines such as Nucleotide Transformer, Hyena-DNA, and\nshows task transfer across chromosomes and species.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.11087v6"
    },
    {
        "title": "A comprehensive comparison of tools for fitting mutational signatures",
        "authors": [
            "Matúš Medo",
            "Charlotte K. Y. Ng",
            "Michaela Medová"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Mutational signatures connect characteristic mutational patterns in the\ngenome with biological or chemical processes that take place in cancers.\nAnalysis of mutational signatures can help elucidate tumor evolution,\nprognosis, and therapeutic strategies. Although tools for extracting mutational\nsignatures de novo have been extensively benchmarked, a similar effort is\nlacking for tools that fit known mutational signatures to a given catalog of\nmutations. We fill this gap by comprehensively evaluating twelve signature\nfitting tools on synthetic mutational catalogs with empirically-driven\nsignature weights corresponding to eight cancer types. On average,\nSigProfilerSingleSample and SigProfilerAssignment/MuSiCal perform best for\nsmall and large numbers of mutations per sample, respectively. We further show\nthat ad hoc constraining the list of reference signatures is likely to produce\ninferior results. Evaluation of real mutational catalogs suggests that the\nactivity of signatures that are absent in the reference catalog poses\nconsiderable problems to all evaluated tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.01562v2"
    },
    {
        "title": "RawAlign: Accurate, Fast, and Scalable Raw Nanopore Signal Mapping via\n  Combining Seeding and Alignment",
        "authors": [
            "Joël Lindegger",
            "Can Firtina",
            "Nika Mansouri Ghiasi",
            "Mohammad Sadrosadati",
            "Mohammed Alser",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Nanopore sequencers generate raw electrical signals representing the contents\nof a biological sequence molecule passing through the nanopore. These signals\ncan be analyzed directly, avoiding basecalling entirely. We observe that while\nexisting proposals for raw signal analysis typically do well in all metrics for\nsmall genomes (e.g., viral genomes), they all perform poorly for large genomes\n(e.g., the human genome). Our goal is to analyze raw nanopore signals in an\naccurate, fast, and scalable manner. To this end, we propose RawAlign, the\nfirst work to integrate fine-grained signal alignment into the state-of-the-art\nraw signal mapper. To enable accurate, fast, and scalable mapping with\nalignment, RawAlign implements three algorithmic improvements and hardware\nacceleration via a vectorized implementation of fine-grained alignment.\nTogether, these significantly reduce the overhead of typically computationally\nexpensive fine-grained alignment. Our extensive evaluations on different use\ncases and various datasets show RawAlign provides 1) the most accurate mapping\nfor large genomes and 2) and on-par performance compared to RawHash (between\n0.80x-1.08x), while achieving better performance than UNCALLED and Sigmap by on\naverage (geo. mean) 2.83x and 2.06x, respectively. Availability:\nhttps://github.com/CMU-SAFARI/RawAlign.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.05037v2"
    },
    {
        "title": "LitSumm: Large language models for literature summarisation of\n  non-coding RNAs",
        "authors": [
            "Andrew Green",
            "Carlos Ribas",
            "Nancy Ontiveros-Palacios",
            "Sam Griffiths-Jones",
            "Anton I. Petrov",
            "Alex Bateman",
            "Blake Sweeney"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Curation of literature in life sciences is a growing challenge. The continued\nincrease in the rate of publication, coupled with the relatively fixed number\nof curators worldwide presents a major challenge to developers of biomedical\nknowledgebases. Very few knowledgebases have resources to scale to the whole\nrelevant literature and all have to prioritise their efforts.\n  In this work, we take a first step to alleviating the lack of curator time in\nRNA science by generating summaries of literature for non-coding RNAs using\nlarge language models (LLMs). We demonstrate that high-quality, factually\naccurate summaries with accurate references can be automatically generated from\nthe literature using a commercial LLM and a chain of prompts and checks. Manual\nassessment was carried out for a subset of summaries, with the majority being\nrated extremely high quality.\n  We apply our tool to a selection of over 4,600 ncRNAs and make the generated\nsummaries available via the RNAcentral resource. We conclude that automated\nliterature summarization is feasible with the current generation of LLMs,\nprovided careful prompting and automated checking are applied.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03056v4"
    },
    {
        "title": "An Investigation of Hepatitis B Virus Genome using Markov Models",
        "authors": [
            " Khadijeh",
            " Jahanian",
            "Elnaz Shalbafian",
            "Morteza Saberi",
            "Roohallah Alizadehsani",
            "Iman Dehzangi"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The human genome encodes a family of editing enzymes known as APOBEC3\n(apolipoprotein B mRNA editing enzyme, catalytic polypeptide-like 3). Several\nfamily members, such as APO-BEC3G, APOBEC3F, and APOBEC3H haplotype II, exhibit\nactivity against viruses such as HIV. These enzymes induce C-to-U mutations in\nthe negative strand of viral genomes, resulting in multiple G-to-A changes,\ncommonly referred to as 'hypermutation.' Mutations catalyzed by these enzymes\nare sequence context-dependent in the HIV genome; for instance, APOBEC3G\npreferen-tially mutates G within GG, TGG, and TGGG contexts, while other\nmembers mutate G within GA, TGA, and TGAA contexts. However, the same sequence\ncontext has not been explored in relation to these enzymes and HBV. In this\nstudy, our objective is to identify the mutational footprint of APOBEC3 enzymes\nin the HBV genome. To achieve this, we employ a multivariable data analytics\ntechnique to investigate motif preferences and potential sequence hierarchies\nof mutation by APOBEC3 enzymes using full genome HBV sequences from a diverse\nrange of naturally infected patients. This approach allows us to distinguish\nbetween normal and hypermutated sequences based on the representation of mono-\nto tetra-nucleotide motifs. Additionally, we aim to identify motifs associated\nwith hypermutation induced by different APOBEC3 enzymes in HBV genomes. Our\nanalyses reveal that either APOBEC3 enzymes are not active against HBV, or the\ninduction of G-to-A mutations by these enzymes is not sequence\ncontext-dependent in the HBV genome.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06699v1"
    },
    {
        "title": "To Transformers and Beyond: Large Language Models for the Genome",
        "authors": [
            "Micaela E. Consens",
            "Cameron Dufault",
            "Michael Wainberg",
            "Duncan Forster",
            "Mehran Karimzadeh",
            "Hani Goodarzi",
            "Fabian J. Theis",
            "Alan Moses",
            "Bo Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In the rapidly evolving landscape of genomics, deep learning has emerged as a\nuseful tool for tackling complex computational challenges. This review focuses\non the transformative role of Large Language Models (LLMs), which are mostly\nbased on the transformer architecture, in genomics. Building on the foundation\nof traditional convolutional neural networks and recurrent neural networks, we\nexplore both the strengths and limitations of transformers and other LLMs for\ngenomics. Additionally, we contemplate the future of genomic modeling beyond\nthe transformer architecture based on current trends in research. The paper\naims to serve as a guide for computational biologists and computer scientists\ninterested in LLMs for genomic data. We hope the paper can also serve as an\neducational introduction and discussion for biologists to a fundamental shift\nin how we will be analyzing genomic data in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.07621v1"
    },
    {
        "title": "Attention-based Multi-task Learning for Base Editor Outcome Prediction",
        "authors": [
            "Amina Mollaysa",
            "Ahmed Allam",
            "Michael Krauthammer"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Human genetic diseases often arise from point mutations, emphasizing the\ncritical need for precise genome editing techniques. Among these, base editing\nstands out as it allows targeted alterations at the single nucleotide level.\nHowever, its clinical application is hindered by low editing efficiency and\nunintended mutations, necessitating extensive trial-and-error experimentation\nin the laboratory. To speed up this process, we present an attention-based\ntwo-stage machine learning model that learns to predict the likelihood of all\npossible editing outcomes for a given genomic target sequence. We further\npropose a multi-task learning schema to jointly learn multiple base editors\n(i.e. variants) at once. Our model's predictions consistently demonstrated a\nstrong correlation with the actual experimental results on multiple datasets\nand base editor variants. These results provide further validation for the\nmodels' capacity to enhance and accelerate the process of refining base editing\ndesigns.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.07636v2"
    },
    {
        "title": "Heteroskedasticity as a Signature of Association for Age-Related Genes",
        "authors": [
            "Salman Mohamadi",
            "Donald A. Adjeroh"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Human aging is a process controlled by both genetics and environment. Many\nstudies have been conducted to identify a subset of genes related to aging from\nthe human genome. Biologists implicitly categorize age-related genes into genes\nthat cause aging and genes that are influenced by aging, which resulted in both\ncausal inference and inference of associations studies. While inference of\nassociation is better explored, causal inference and computational causal\ninference, remains less explored. In this work, we are primarily motivated to\ntackle the problem of identifying genes associated with aging, while having a\nbrief look into genes with probable causal relations, both from a computational\nperspective. Specifically, we form a set of hypotheses and accordingly,\nintroduce a data-tailored framework for inference. First we perform linear\nmodeling on the expression values of age-related genes, and then examine the\npresence of heteroskedastic properties in the residual of the model. We\nevaluate this framework and our results suggest that, 1) presence of\nheteroskedasticity in these residuals is a potential signature of association\nfor age-related genes, and 2) consistent heteroskedasticity along the human\nlife span could imply some sort of causality. To our knowledge, along with\nidentifying age-associated genes, this is the first work to propose a framework\nfor computational causal inference on age-related genes, using a dataset of\nhuman dermal fibroblast gene expression data. Hence the results of our simple,\nyet effective approach can be used not only to assess future age-related genes,\nbut also as a possible criterion to select new associative or potential causal\ngenes with respect to aging.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09411v1"
    },
    {
        "title": "Sweetwater: An interpretable and adaptive autoencoder for efficient\n  tissue deconvolution",
        "authors": [
            "Jesus de la Fuente",
            "Naroa Legarra",
            "Guillermo Serrano",
            "Irene Marin-Goni",
            "Aintzane Diaz-Mazkiaran",
            "Markel Benito Sendin",
            "Ana Garcia Osta",
            "Krishna R. Kalari",
            "Carlos Fernandez-Granda",
            "Idoia Ochoa",
            "Mikel Hernaez"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Single-cell RNA-sequencing (scRNA-seq) stands as a powerful tool for\ndeciphering cellular heterogeneity and exploring gene expression profiles at\nhigh resolution. However, its high cost renders it impractical for extensive\nsample cohorts within routine clinical care, hindering its broader\napplicability. Hence, many methodologies have recently arised to estimate cell\ntype proportions from bulk RNA-seq samples (known as deconvolution methods).\nHowever, they have several limitations: Many depend on selecting a robust\nscRNA-seq reference dataset, which is often challenging. Secondly, building\nreliable pseudobulk samples requires determining the optimal number of genes or\ncells involved in the simulated data generation process, which has not been\nstudied in depth. Moreover, pseudobulk and bulk RNA-seq samples often exhibit\ndistribution shifts. Finally, most modern deconvolution approaches behave as a\nblack box, and the underlying mechanisms of the deconvolution task are still\nunknown, which can compromise the reliability of the results. In this work, we\npresent Sweetwater, an adaptive and interpretable autoencoder able to\nefficiently deconvolve bulk RNA-seq and microarray samples leveraging multiple\nclasses of reference data, such as scRNA-seq and single-nuclei RNA-seq.\nMoreover, it can be trained on a mixture of FACS-sorted FASTQ files, which we\nnewly propose to use as this reduces platform-specific biases and may\npotentially outperform single-cell-based references. Also, we demonstrate that\nSweetwater effectively uncovers biologically meaningful patterns during the\ntraining process, increasing the reliability of the results. Sweetwater is\navailable at https://github.com/ubioinformat/Sweetwater, and we anticipate will\nfacilitate and expedite the accurate examination of high-throughput clinical\ndata across diverse applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.11991v2"
    },
    {
        "title": "BEND: Benchmarking DNA Language Models on biologically meaningful tasks",
        "authors": [
            "Frederikke Isa Marin",
            "Felix Teufel",
            "Marc Horlacher",
            "Dennis Madsen",
            "Dennis Pultz",
            "Ole Winther",
            "Wouter Boomsma"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The genome sequence contains the blueprint for governing cellular processes.\nWhile the availability of genomes has vastly increased over the last decades,\nexperimental annotation of the various functional, non-coding and regulatory\nelements encoded in the DNA sequence remains both expensive and challenging.\nThis has sparked interest in unsupervised language modeling of genomic DNA, a\nparadigm that has seen great success for protein sequence data. Although\nvarious DNA language models have been proposed, evaluation tasks often differ\nbetween individual works, and might not fully recapitulate the fundamental\nchallenges of genome annotation, including the length, scale and sparsity of\nthe data. In this study, we introduce BEND, a Benchmark for DNA language\nmodels, featuring a collection of realistic and biologically meaningful\ndownstream tasks defined on the human genome. We find that embeddings from\ncurrent DNA LMs can approach performance of expert methods on some tasks, but\nonly capture limited information about long-range features. BEND is available\nat https://github.com/frederikkemarin/BEND.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12570v4"
    },
    {
        "title": "Dynamic Programming Algorithms for Discovery of Antibiotic Resistance in\n  Microbial Genomes",
        "authors": [
            "Manal Helal",
            "Vitali Sintchenko"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The translation of comparative genomics into clinical decision support tools\noften depends on the quality of sequence alignments. However, currently used\nmethods of multiple sequence alignments suffer from significant biases and\nproblems with aligning diverged sequences. The objective of this study was to\ndevelop and test a new multiple sequence alignment (MSA) algorithm suitable for\nthe high-throughput comparative analysis of different microbial genomes. This\nalgorithm employs an innovative tensor indexing method for partitioning the\ndynamic programming hyper-cube space for parallel processing. We have used the\nclinically relevant task of identifying regions that determine resistance to\nantibiotics to test the new algorithm and to compare its performance with\nexisting MSA methods. The new method \"mmDst\" performed better than existing MSA\nalgorithms for more divergent sequences because it employs a simultaneous\nalignment scoring recurrence, which effectively approximated the score for edge\nmissing cell scores that fall outside the scoring region.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17538v1"
    },
    {
        "title": "Linear normalised hash function for clustering gene sequences and\n  identifying reference sequences from multiple sequence alignments",
        "authors": [
            "Manal Helal",
            "Fanrong Kong",
            "Sharon C-A Chen",
            "Fei Zhou",
            "Dominic E Dwyer",
            "John Potter",
            "Vitali Sintchenko"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The aim of this study was to develop a method that would identify the cluster\ncentroids and the optimal number of clusters for a given sensitivity level and\ncould work equally well for the different sequence datasets. A novel method\nthat combines the linear mapping hash function and multiple sequence alignment\n(MSA) was developed. This method takes advantage of the already sorted by\nsimilarity sequences from the MSA output, and identifies the optimal number of\nclusters, clusters cut-offs, and clusters centroids that can represent\nreference gene vouchers for the different species. The linear mapping hash\nfunction can map an already ordered by similarity distance matrix to indices to\nreveal gaps in the values around which the optimal cut-offs of the different\nclusters can be identified. The method was evaluated using sets of closely\nrelated (16S rRNA gene sequences of Nocardia species) and highly variable (VP1\ngenomic region of Enterovirus 71) sequences and outperformed existing\nunsupervised machine learning clustering methods and dimensionality reduction\nmethods. This method does not require prior knowledge of the number of clusters\nor the distance between clusters, handles clusters of different sizes and\nshapes, and scales linearly with the dataset. The combination of MSA with the\nlinear mapping hash function is a computationally efficient way of gene\nsequence clustering and can be a valuable tool for the assessment of\nsimilarity, clustering of different microbial genomes, identifying reference\nsequences, and for the study of evolution of bacteria and viruses.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17964v1"
    },
    {
        "title": "Defining Reference Sequences for Nocardia Species by Similarity and\n  Clustering Analyses of 16S rRNA Gene Sequence Data",
        "authors": [
            "Manal Helal",
            "Fanrong Kong",
            "Sharon C. A. Chen",
            "Michael Bain",
            "Richard Christen",
            "Vitali Sintchenko"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The intra- and inter-species genetic diversity of bacteria and the absence of\n'reference', or the most representative, sequences of individual species\npresent a significant challenge for sequence-based identification. The aims of\nthis study were to determine the utility, and compare the performance of\nseveral clustering and classification algorithms to identify the species of 364\nsequences of 16S rRNA gene with a defined species in GenBank, and 110 sequences\nof 16S rRNA gene with no defined species, all within the genus Nocardia. A\ntotal of 364 16S rRNA gene sequences of Nocardia species were studied. In\naddition, 110 16S rRNA gene sequences assigned only to the Nocardia genus level\nat the time of submission to GenBank were used for machine learning\nclassification experiments. Different clustering algorithms were compared with\na novel algorithm or the linear mapping (LM) of the distance matrix. Principal\nComponents Analysis was used for the dimensionality reduction and\nvisualization. Results: The LM algorithm achieved the highest performance and\nclassified the set of 364 16S rRNA sequences into 80 clusters, the majority of\nwhich (83.52%) corresponded with the original species. The most representative\n16S rRNA sequences for individual Nocardia species have been identified as\n'centroids' in respective clusters from which the distances to all other\nsequences were minimized; 110 16S rRNA gene sequences with identifications\nrecorded only at the genus level were classified using machine learning\nmethods. Simple kNN machine learning demonstrated the highest performance and\nclassified Nocardia species sequences with an accuracy of 92.7% and a mean\nfrequency of 0.578.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17965v1"
    },
    {
        "title": "High Performance Multiple Sequence Alignment Algorithms for Comparison\n  of Microbial Genomes",
        "authors": [
            "Manal Helal",
            "Hossam El-Gindy",
            "Bruno Gaeta",
            "Vitali Sinchenko"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Advances in gene sequencing have enabled in silico analyses of microbial\ngenomes and have led to the revision of concepts of microbial taxonomy and\nevolution. We explore deficiencies in existing multiple sequence global\nalignment algorithms and introduce a new indexing scheme to partition the\ndynamic programming algorithm hypercube scoring tensor over processors based on\nthe dependency between partitions to be scored in parallel. The performance of\nalgorithms is compared in the study of rpoB gene sequences of Mycoplasma\nspecies.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.02994v1"
    },
    {
        "title": "Interpretable Online Network Dictionary Learning for Inferring\n  Long-Range Chromatin Interactions",
        "authors": [
            "Vishal Rana",
            "Jianhao Peng",
            "Chao Pan",
            "Hanbaek Lyu",
            "Albert Cheng",
            "Minji Kim",
            "Olgica Milenkovic"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Dictionary learning (DL) is commonly used in computational biology to tackle\nubiquitous clustering problems due to its conceptual simplicity and relatively\nlow computational complexity. However, DL algorithms produce results that lack\ninterpretability and are not optimized for large-scale graph-structured data.\nWe propose a novel DL algorithm called online convex network dictionary\nlearning (online cvxNDL) that can handle extremely large datasets and enables\nthe interpretation of dictionary elements, which serve as cluster\nrepresentatives, through convex combinations of real measurements. Moreover,\nthe algorithm can be applied to network-structured data via specialized\nsubnetwork sampling techniques.\n  To demonstrate the utility of our approach, we apply cvxNDL on 3D-genome\nRNAPII ChIA-Drop data to identify important long-range interaction patterns.\nChIA-Drop probes higher-order interactions, and produces hypergraphs whose\nnodes represent genomic fragments. The hyperedges represent observed physical\ncontacts. Our hypergraph model analysis creates an interpretable dictionary of\nlong-range interaction patterns that accurately represent global chromatin\nphysical contact maps. Using dictionary information, one can also associate the\ncontact maps with RNA transcripts and infer cellular functions.\n  Our results offer two key insights. First, we demonstrate that online cvxNDL\nretains the accuracy of classical DL methods while simultaneously ensuring\nunique interpretability and scalability. Second, we identify distinct\ncollections of proximal and distal interaction patterns involving chromatin\nelements shared by related processes across different chromosomes, as well as\npatterns unique to specific chromosomes. To associate the dictionary elements\nwith biological properties of the corresponding chromatin regions, we employ\nGene Ontology enrichment analysis and perform RNA coexpression studies.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.10519v1"
    },
    {
        "title": "Preparing to Integrate Generative Pretrained Transformer Series 4 models\n  into Genetic Variant Assessment Workflows: Assessing Performance, Drift, and\n  Nondeterminism Characteristics Relative to Classifying Functional Evidence in\n  Literature",
        "authors": [
            "Samuel J. Aronson",
            "Kalotina Machini",
            "Jiyeon Shin",
            "Pranav Sriraman",
            "Sean Hamill",
            "Emma R. Henricks",
            "Charlotte Mailly",
            "Angie J. Nottage",
            "Sami S. Amr",
            "Michael Oates",
            "Matthew S. Lebo"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Background. Large Language Models (LLMs) hold promise for improving genetic\nvariant literature review in clinical testing. We assessed Generative\nPretrained Transformer 4's (GPT-4) performance, nondeterminism, and drift to\ninform its suitability for use in complex clinical processes. Methods. A\n2-prompt process for classification of functional evidence was optimized using\na development set of 45 articles. The prompts asked GPT-4 to supply all\nfunctional data present in an article related to a variant or indicate that no\nfunctional evidence is present. For articles indicated as containing functional\nevidence, a second prompt asked GPT-4 to classify the evidence into pathogenic,\nbenign, or intermediate/inconclusive categories. A final test set of 72\nmanually classified articles was used to test performance. Results. Over a\n2.5-month period (Dec 2023-Feb 2024), we observed substantial differences in\nintraday (nondeterminism) and across day (drift) results, which lessened after\n1/18/24. This variability is seen within and across models in the GPT-4 series,\naffecting different performance statistics to different degrees. Twenty runs\nafter 1/18/24 identified articles containing functional evidence with 92.2%\nsensitivity, 95.6% positive predictive value (PPV) and 86.3% negative\npredictive value (NPV). The second prompt's identified pathogenic functional\nevidence with 90.0% sensitivity, 74.0% PPV and 95.3% NVP and for benign\nevidence with 88.0% sensitivity, 76.6% PPV and 96.9% NVP. Conclusion.\nNondeterminism and drift within LLMs must be assessed and monitored when\nintroducing LLM based functionality into clinical workflows. Failing to do this\nassessment or accounting for these challenges could lead to incorrect or\nmissing information that is critical for patient care. The performance of our\nprompts appears adequate to assist in article prioritization but not in\nautomated decision making.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.13521v2"
    },
    {
        "title": "GenoCraft: A Comprehensive, User-Friendly Web-Based Platform for\n  High-Throughput Omics Data Analysis and Visualization",
        "authors": [
            "Yingzhou Lu",
            "Minjie Shen",
            "Ling Yue",
            "Chenhao Li",
            "Lulu Chen",
            "Fan Meng",
            "Xiao Wang",
            "David Herrington",
            "Yue Wang",
            "Yue Zhao",
            "Tianfan Fu",
            "Capucine Van Rechem"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The surge in high-throughput omics data has reshaped the landscape of\nbiological research, underlining the need for powerful, user-friendly data\nanalysis and interpretation tools. This paper presents GenoCraft, a web-based\ncomprehensive software solution designed to handle the entire pipeline of omics\ndata processing. GenoCraft offers a unified platform featuring advanced\nbioinformatics tools, covering all aspects of omics data analysis. It\nencompasses a range of functionalities, such as normalization, quality control,\ndifferential analysis, network analysis, pathway analysis, and diverse\nvisualization techniques. This software makes state-of-the-art omics data\nanalysis more accessible to a wider range of users. With GenoCraft, researchers\nand data scientists have access to an array of cutting-edge bioinformatics\ntools under a user-friendly interface, making it a valuable resource for\nmanaging and analyzing large-scale omics data. The API with an interactive web\ninterface is publicly available at https://genocraft.stanford. edu/. We also\nrelease all the codes in https://github.com/futianfan/GenoCraft.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14249v3"
    },
    {
        "title": "Large Language Models in Plant Biology",
        "authors": [
            "Hilbert Yuen In Lam",
            "Xing Er Ong",
            "Marek Mutwil"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Large Language Models (LLMs), such as ChatGPT, have taken the world by storm\nand have passed certain forms of the Turing test. However, LLMs are not limited\nto human language and analyze sequential data, such as DNA, protein, and gene\nexpression. The resulting foundation models can be repurposed to identify the\ncomplex patterns within the data, resulting in powerful, multi-purpose\nprediction tools able to explain cellular systems. This review outlines the\ndifferent types of LLMs and showcases their recent uses in biology. Since LLMs\nhave not yet been embraced by the plant community, we also cover how these\nmodels can be deployed for the plant kingdom.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.02789v1"
    },
    {
        "title": "Interpretable deep learning in single-cell omics",
        "authors": [
            "Manoj M Wagle",
            "Siqu Long",
            "Carissa Chen",
            "Chunlei Liu",
            "Pengyi Yang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Recent developments in single-cell omics technologies have enabled the\nquantification of molecular profiles in individual cells at an unparalleled\nresolution. Deep learning, a rapidly evolving sub-field of machine learning,\nhas instilled a significant interest in single-cell omics research due to its\nremarkable success in analysing heterogeneous high-dimensional single-cell\nomics data. Nevertheless, the inherent multi-layer nonlinear architecture of\ndeep learning models often makes them `black boxes' as the reasoning behind\npredictions is often unknown and not transparent to the user. This has\nstimulated an increasing body of research for addressing the lack of\ninterpretability in deep learning models, especially in single-cell omics data\nanalyses, where the identification and understanding of molecular regulators\nare crucial for interpreting model predictions and directing downstream\nexperimental validations. In this work, we introduce the basics of single-cell\nomics technologies and the concept of interpretable deep learning. This is\nfollowed by a review of the recent interpretable deep learning models applied\nto various single-cell omics research. Lastly, we highlight the current\nlimitations and discuss potential future directions. We anticipate this review\nto bring together the single-cell and machine learning research communities to\nfoster future development and application of interpretable deep learning in\nsingle-cell omics research.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.06823v1"
    },
    {
        "title": "Machine Learning-Based Analysis of Ebola Virus' Impact on Gene\n  Expression in Nonhuman Primates",
        "authors": [
            "Mostafa Rezapour",
            "Muhammad Khalid Khan Niazi",
            "Hao Lu",
            "Aarthi Narayanan",
            "Metin Nafi Gurcan"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This study introduces the Supervised Magnitude-Altitude Scoring (SMAS)\nmethodology, a machine learning-based approach, for analyzing gene expression\ndata obtained from nonhuman primates (NHPs) infected with Ebola virus (EBOV).\nWe utilize a comprehensive dataset of NanoString gene expression profiles from\nEbola-infected NHPs, deploying the SMAS system for nuanced host-pathogen\ninteraction analysis. SMAS effectively combines gene selection based on\nstatistical significance and expression changes, employing linear classifiers\nsuch as logistic regression to accurately differentiate between RT-qPCR\npositive and negative NHP samples. A key finding of our research is the\nidentification of IFI6 and IFI27 as critical biomarkers, demonstrating\nexceptional predictive performance with 100% accuracy and Area Under the Curve\n(AUC) metrics in classifying various stages of Ebola infection. Alongside IFI6\nand IFI27, genes, including MX1, OAS1, and ISG15, were significantly\nupregulated, highlighting their essential roles in the immune response to EBOV.\nOur results underscore the efficacy of the SMAS method in revealing complex\ngenetic interactions and response mechanisms during EBOV infection. This\nresearch provides valuable insights into EBOV pathogenesis and aids in\ndeveloping more precise diagnostic tools and therapeutic strategies to address\nEBOV infection in particular and viral infection in general.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08738v2"
    },
    {
        "title": "DNA Sequence Classification with Compressors",
        "authors": [
            "Şükrü Ozan"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Recent studies in DNA sequence classification have leveraged sophisticated\nmachine learning techniques, achieving notable accuracy in categorizing complex\ngenomic data. Among these, methods such as k-mer counting have proven effective\nin distinguishing sequences from varied species like chimpanzees, dogs, and\nhumans, becoming a staple in contemporary genomic research. However, these\napproaches often demand extensive computational resources, posing a challenge\nin terms of scalability and efficiency. Addressing this issue, our study\nintroduces a novel adaptation of Jiang et al.'s compressor-based,\nparameter-free classification method, specifically tailored for DNA sequence\nanalysis. This innovative approach utilizes a variety of compression\nalgorithms, such as Gzip, Brotli, and LZMA, to efficiently process and classify\ngenomic sequences. Not only does this method align with the current\nstate-of-the-art in terms of accuracy, but it also offers a more\nresource-efficient alternative to traditional machine learning methods. Our\ncomprehensive evaluation demonstrates the proposed method's effectiveness in\naccurately classifying DNA sequences from multiple species. We present a\ndetailed analysis of the performance of each algorithm used, highlighting the\nstrengths and limitations of our approach in various genomic contexts.\nFurthermore, we discuss the broader implications of our findings for\nbioinformatics, particularly in genomic data processing and analysis. The\nresults of our study pave the way for more efficient and scalable DNA sequence\nclassification methods, offering significant potential for advancements in\ngenomic research and applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14025v1"
    },
    {
        "title": "Deciphering regulatory architectures from synthetic single-cell\n  expression patterns",
        "authors": [
            "Rosalind Wenshan Pan",
            "Tom Roeschinger",
            "Kian Faizi",
            "Hernan Garcia",
            "Rob Phillips"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  For the vast majority of genes in sequenced genomes, there is limited\nunderstanding of how they are regulated. Without such knowledge, it is not\npossible to perform a quantitative theory-experiment dialogue on how such genes\ngive rise to physiological and evolutionary adaptation. One category of\nhigh-throughput experiments used to understand the sequence-phenotype\nrelationship of the transcriptome is massively parallel reporter assays\n(MPRAs). However, to improve the versatility and scalability of MPRA pipelines,\nwe need a \"theory of the experiment\" to help us better understand the impact of\nvarious biological and experimental parameters on the interpretation of\nexperimental data. To that end, in this paper we create tens of thousands of\nsynthetic single-cell gene expression outputs using both equilibrium and\nout-of-equilibrium models. These models make it possible to imitate the summary\nstatistics (information footprints and expression shift matrices) used to\ncharacterize the output of MPRAs and from this summary statistic to infer the\nunderlying regulatory architecture. Specifically, we use a more refined\nimplementation of the so-called thermodynamic models in which the binding\nenergies of each sequence variant are derived from energy matrices. Our\nsimulations reveal important effects of the parameters on MPRA data and we\ndemonstrate our ability to optimize MPRA experimental designs with the goal of\ngenerating thermodynamic models of the transcriptome with base-pair\nspecificity. Further, this approach makes it possible to carefully examine the\nmapping between mutations in binding sites and their corresponding expression\nprofiles, a tool useful not only for better designing MPRAs, but also for\nexploring regulatory evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.15880v2"
    },
    {
        "title": "A Comparative Analysis of Gene Expression Profiling by Statistical and\n  Machine Learning Approaches",
        "authors": [
            "Myriam Bontonou",
            "Anaïs Haget",
            "Maria Boulougouri",
            "Benjamin Audit",
            "Pierre Borgnat",
            "Jean-Michel Arbona"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Many machine learning models have been proposed to classify phenotypes from\ngene expression data. In addition to their good performance, these models can\npotentially provide some understanding of phenotypes by extracting explanations\nfor their decisions. These explanations often take the form of a list of genes\nranked in order of importance for the predictions, the highest-ranked genes\nbeing interpreted as linked to the phenotype. We discuss the biological and the\nmethodological limitations of such explanations. Experiments are performed on\nseveral datasets gathering cancer and healthy tissue samples from the TCGA,\nGTEx and TARGET databases. A collection of machine learning models including\nlogistic regression, multilayer perceptron, and graph neural network are\ntrained to classify samples according to their cancer type. Gene rankings are\nobtained from explainability methods adapted to these models, and compared to\nthe ones from classical statistical feature selection methods such as mutual\ninformation, DESeq2, and EdgeR. Interestingly, on simple tasks, we observe that\nthe information learned by black-box neural networks is related to the notion\nof differential expression. In all cases, a small set containing the\nbest-ranked genes is sufficient to achieve a good classification. However,\nthese genes differ significantly between the methods and similar classification\nperformance can be achieved with numerous lower ranked genes. In conclusion,\nalthough these methods enable the identification of biomarkers characteristic\nof certain pathologies, our results question the completeness of the selected\ngene sets and thus of explainability by the identification of the underlying\nbiological processes.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.00926v1"
    },
    {
        "title": "PhenoLinker: Phenotype-Gene Link Prediction and Explanation using\n  Heterogeneous Graph Neural Networks",
        "authors": [
            "Jose L. Mellina Andreu",
            "Luis Bernal",
            "Antonio F. Skarmeta",
            "Mina Ryten",
            "Sara Álvarez",
            "Alejandro Cisterna García",
            "Juan A. Botía"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The association of a given human phenotype to a genetic variant remains a\ncritical challenge for biology. We present a novel system called PhenoLinker\ncapable of associating a score to a phenotype-gene relationship by using\nheterogeneous information networks and a convolutional neural network-based\nmodel for graphs, which can provide an explanation for the predictions. This\nsystem can aid in the discovery of new associations and in the understanding of\nthe consequences of human genetic variation.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01809v1"
    },
    {
        "title": "scInterpreter: Training Large Language Models to Interpret scRNA-seq\n  Data for Cell Type Annotation",
        "authors": [
            "Cong Li",
            "Meng Xiao",
            "Pengfei Wang",
            "Guihai Feng",
            "Xin Li",
            "Yuanchun Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Despite the inherent limitations of existing Large Language Models in\ndirectly reading and interpreting single-cell omics data, they demonstrate\nsignificant potential and flexibility as the Foundation Model. This research\nfocuses on how to train and adapt the Large Language Model with the capability\nto interpret and distinguish cell types in single-cell RNA sequencing data. Our\npreliminary research results indicate that these foundational models excel in\naccurately categorizing known cell types, demonstrating the potential of the\nLarge Language Models as effective tools for uncovering new biological\ninsights.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.12405v1"
    },
    {
        "title": "Methylation Operation Wizard (MeOW): Identification of differentially\n  methylated regions in long-read sequencing data",
        "authors": [
            "Miranda PG Zalusky",
            "Danny E Miller"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Long-read sequencing (LRS) is able to simultaneously capture information\nabout both DNA sequence and modifications, such as CpG methylation in a single\nsequencing experiment. Here we present Methylation Operation Wizard (MeOW), a\nprogram to identify and prioritize differentially methylated regions (DMRs)\ngenome-wide using LRS data. MeOW can be run using either a file containing\ncounts of per-nucleotide methylated CpG sites or with a bam file containing\nmodified base tags.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17182v1"
    },
    {
        "title": "Supervised machine learning for microbiomics: bridging the gap between\n  current and best practices",
        "authors": [
            "Natasha K. Dudek",
            "Mariam Chakhvadze",
            "Saba Kobakhidze",
            "Omar Kantidze",
            "Yuriy Gankin"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Machine learning (ML) is poised to drive innovations in clinical\nmicrobiomics, such as in disease diagnostics and prognostics. However, the\nsuccessful implementation of ML in these domains necessitates the development\nof reproducible, interpretable models that meet the rigorous performance\nstandards set by regulatory agencies. This study aims to identify key areas in\nneed of improvement in current ML practices within microbiomics, with a focus\non bridging the gap between existing methodologies and the requirements for\nclinical application. To do so, we analyze 100 peer-reviewed articles from\n2021-2022. Within this corpus, datasets have a median size of 161.5 samples,\nwith over one-third containing fewer than 100 samples, signaling a high\npotential for overfitting. Limited demographic data further raises concerns\nabout generalizability and fairness, with 24% of studies omitting participants'\ncountry of residence, and attributes like race/ethnicity, education, and income\nrarely reported (11%, 2%, and 0%, respectively). Methodological issues are also\ncommon; for instance, for 86% of studies we could not confidently rule out test\nset omission and data leakage, suggesting a strong potential for inflated\nperformance estimates across the literature. Reproducibility is also a concern,\nwith 78% of studies abstaining from sharing their ML code publicly. Based on\nthis analysis, we provide guidance to avoid common pitfalls that can hinder\nmodel performance, generalizability, and trustworthiness. An interactive\ntutorial on applying ML to microbiomics data accompanies the discussion, to\nhelp establish and reinforce best practices within the community.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17621v4"
    },
    {
        "title": "Exploring Gene Regulatory Interaction Networks and predicting\n  therapeutic molecules for Hypopharyngeal Cancer and EGFR-mutated lung\n  adenocarcinoma",
        "authors": [
            "Abanti Bhattacharjya",
            "Md Manowarul Islam",
            "Md Ashraf Uddin",
            "Md. Alamin Talukder",
            "AKM Azad",
            "Sunil Aryal",
            "Bikash Kumar Paul",
            "Wahia Tasnim",
            "Muhammad Ali Abdulllah Almoyad",
            "Mohammad Ali Moni"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  With the advent of Information technology, the Bioinformatics research field\nis becoming increasingly attractive to researchers and academicians. The recent\ndevelopment of various Bioinformatics toolkits has facilitated the rapid\nprocessing and analysis of vast quantities of biological data for human\nperception. Most studies focus on locating two connected diseases and making\nsome observations to construct diverse gene regulatory interaction networks, a\nforerunner to general drug design for curing illness. For instance,\nHypopharyngeal cancer is a disease that is associated with EGFR-mutated lung\nadenocarcinoma. In this study, we select EGFR-mutated lung adenocarcinoma and\nHypopharyngeal cancer by finding the Lung metastases in hypopharyngeal cancer.\nTo conduct this study, we collect Mircorarray datasets from GEO (Gene\nExpression Omnibus), an online database controlled by NCBI. Differentially\nexpressed genes, common genes, and hub genes between the selected two diseases\nare detected for the succeeding move. Our research findings have suggested\ncommon therapeutic molecules for the selected diseases based on 10 hub genes\nwith the highest interactions according to the degree topology method and the\nmaximum clique centrality (MCC). Our suggested therapeutic molecules will be\nfruitful for patients with those two diseases simultaneously.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17807v1"
    },
    {
        "title": "MetaCompass: Reference-guided Assembly of Metagenomes",
        "authors": [
            "Tu Luan",
            "Victoria Cepeda",
            "Bo Liu",
            "Zac Bowen",
            "Ujjwal Ayyangar",
            "Mathieu Almeida",
            "Christopher M. Hill",
            "Sergey Koren",
            "Todd J. Treangen",
            "Adam Porter",
            "Mihai Pop"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Metagenomic studies have primarily relied on de novo assembly for\nreconstructing genes and genomes from microbial mixtures. While\nreference-guided approaches have been employed in the assembly of single\norganisms, they have not been used in a metagenomic context. Here we describe\nthe first effective approach for reference-guided metagenomic assembly that can\ncomplement and improve upon de novo metagenomic assembly methods for certain\norganisms. Such approaches will be increasingly useful as more genomes are\nsequenced and made publicly available.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.01578v1"
    },
    {
        "title": "Machine and deep learning methods for predicting 3D genome organization",
        "authors": [
            "Brydon P. G. Wall",
            "My Nguyen",
            "J. Chuck Harrell",
            "Mikhail G. Dozmorov"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Three-Dimensional (3D) chromatin interactions, such as enhancer-promoter\ninteractions (EPIs), loops, Topologically Associating Domains (TADs), and A/B\ncompartments play critical roles in a wide range of cellular processes by\nregulating gene expression. Recent development of chromatin conformation\ncapture technologies has enabled genome-wide profiling of various 3D\nstructures, even with single cells. However, current catalogs of 3D structures\nremain incomplete and unreliable due to differences in technology, tools, and\nlow data resolution. Machine learning methods have emerged as an alternative to\nobtain missing 3D interactions and/or improve resolution. Such methods\nfrequently use genome annotation data (ChIP-seq, DNAse-seq, etc.), DNA\nsequencing information (k-mers, Transcription Factor Binding Site (TFBS)\nmotifs), and other genomic properties to learn the associations between genomic\nfeatures and chromatin interactions. In this review, we discuss computational\ntools for predicting three types of 3D interactions (EPIs, chromatin\ninteractions, TAD boundaries) and analyze their pros and cons. We also point\nout obstacles of computational prediction of 3D interactions and suggest future\nresearch directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03231v1"
    },
    {
        "title": "Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling",
        "authors": [
            "Yair Schiff",
            "Chia-Hsiang Kao",
            "Aaron Gokaslan",
            "Tri Dao",
            "Albert Gu",
            "Volodymyr Kuleshov"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Large-scale sequence modeling has sparked rapid advances that now extend into\nbiology and genomics. However, modeling genomic sequences introduces challenges\nsuch as the need to model long-range token interactions, the effects of\nupstream and downstream regions of the genome, and the reverse complementarity\n(RC) of DNA. Here, we propose an architecture motivated by these challenges\nthat builds off the long-range Mamba block, and extends it to a BiMamba\ncomponent that supports bi-directionality, and to a MambaDNA block that\nadditionally supports RC equivariance. We use MambaDNA as the basis of\nCaduceus, the first family of RC equivariant bi-directional long-range DNA\nlanguage models, and we introduce pre-training and fine-tuning strategies that\nyield Caduceus DNA foundation models. Caduceus outperforms previous long-range\nmodels on downstream benchmarks; on a challenging long-range variant effect\nprediction task, Caduceus exceeds the performance of 10x larger models that do\nnot leverage bi-directionality or equivariance.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03234v2"
    },
    {
        "title": "CIBRA identifies genomic alterations with a system-wide impact on tumor\n  biology",
        "authors": [
            "Soufyan Lakbir",
            "Caterina Buranelli",
            "Gerrit A. Meijer",
            "Jaap Heringa",
            "Remond J. A. Fijneman",
            "Sanne Abeln"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Background: Genomic instability is a hallmark of cancer, leading to many\nsomatic alterations. Identifying which alterations have a system-wide impact is\na challenging task. Nevertheless, this is an essential first step for\nprioritizing potential biomarkers. We developed CIBRA (Computational\nIdentification of Biologically Relevant Alterations), a method that determines\nthe system-wide impact of genomic alterations on tumor biology by integrating\ntwo distinct omics data types: one indicating genomic alterations (e.g.,\ngenomics), and another defining a system-wide expression response (e.g.,\ntranscriptomics). CIBRA was evaluated with genome-wide screens in 33 cancer\ntypes using primary and metastatic cancer data from the Cancer Genome Atlas and\nHartwig Medical Foundation. Results: We demonstrate the capability of CIBRA by\nsuccessfully confirming the impact of point mutations in experimentally\nvalidated oncogenes and tumor suppressor genes. Surprisingly, many genes\naffected by structural variants were identified to have a strong system-wide\nimpact (30.3%), suggesting that their role in cancer development has thus far\nbeen largely underreported. Additionally, CIBRA can identify impact with only\nten cases and controls, providing a novel way to prioritize genomic alterations\nwith a prominent role in cancer biology. Conclusions: Our findings demonstrate\nthat CIBRA can identify cancer drivers by combining genomics and\ntranscriptomics data. Moreover, our work shows an unexpected substantial\nsystem-wide impact of structural variants in cancer. Hence, CIBRA has the\npotential to preselect and refine current definitions of genomic alterations to\nderive more nuanced biomarkers for diagnostics, disease progression, and\ntreatment response. CIBRA is available at https://github.com/AIT4LIFE-UU/CIBRA\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03829v1"
    },
    {
        "title": "scVGAE: A Novel Approach using ZINB-Based Variational Graph Autoencoder\n  for Single-Cell RNA-Seq Imputation",
        "authors": [
            "Yoshitaka Inoue"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Single-cell RNA sequencing (scRNA-seq) has revolutionized our ability to\nstudy individual cellular distinctions and uncover unique cell characteristics.\nHowever, a significant technical challenge in scRNA-seq analysis is the\noccurrence of \"dropout\" events, where certain gene expressions cannot be\ndetected. This issue is particularly pronounced in genes with low or sparse\nexpression levels, impacting the precision and interpretability of the obtained\ndata. To address this challenge, various imputation methods have been\nimplemented to predict such missing values, aiming to enhance the analysis's\naccuracy and usefulness. A prevailing hypothesis posits that scRNA-seq data\nconforms to a zero-inflated negative binomial (ZINB) distribution.\nConsequently, methods have been developed to model the data according to this\ndistribution. Recent trends in scRNA-seq analysis have seen the emergence of\ndeep learning approaches. Some techniques, such as the variational autoencoder,\nincorporate the ZINB distribution as a model loss function. Graph-based methods\nlike Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) have\nalso gained attention as deep learning methodologies for scRNA-seq analysis.\nThis study introduces scVGAE, an innovative approach integrating GCN into a\nvariational autoencoder framework while utilizing a ZINB loss function. This\nintegration presents a promising avenue for effectively addressing dropout\nevents in scRNA-seq data, thereby enhancing the accuracy and reliability of\ndownstream analyses. scVGAE outperforms other methods in cell clustering, with\nthe best performance in 11 out of 14 datasets. Ablation study shows all\ncomponents of scVGAE are necessary. scVGAE is implemented in Python and\ndownloadable at https://github.com/inoue0426/scVGAE.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08959v2"
    },
    {
        "title": "Cross-modality Matching and Prediction of Perturbation Responses with\n  Labeled Gromov-Wasserstein Optimal Transport",
        "authors": [
            "Jayoung Ryu",
            "Charlotte Bunne",
            "Luca Pinello",
            "Aviv Regev",
            "Romain Lopez"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  It is now possible to conduct large scale perturbation screens with complex\nreadout modalities, such as different molecular profiles or high content cell\nimages. While these open the way for systematic dissection of causal cell\ncircuits, integrated such data across screens to maximize our ability to\npredict circuits poses substantial computational challenges, which have not\nbeen addressed. Here, we extend two Gromov-Wasserstein Optimal Transport\nmethods to incorporate the perturbation label for cross-modality alignment. The\nobtained alignment is then employed to train a predictive model that estimates\ncellular responses to perturbations observed with only one measurement\nmodality. We validate our method for the tasks of cross-modality alignment and\ncross-modality prediction in a recent multi-modal single-cell perturbation\ndataset. Our approach opens the way to unified causal models of cell biology.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.00838v2"
    },
    {
        "title": "sc-OTGM: Single-Cell Perturbation Modeling by Solving Optimal Mass\n  Transport on the Manifold of Gaussian Mixtures",
        "authors": [
            "Andac Demir",
            "Elizaveta Solovyeva",
            "James Boylan",
            "Mei Xiao",
            "Fabrizio Serluca",
            "Sebastian Hoersch",
            "Jeremy Jenkins",
            "Murthy Devarakonda",
            "Bulent Kiziltan"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Influenced by breakthroughs in LLMs, single-cell foundation models are\nemerging. While these models show successful performance in cell type\nclustering, phenotype classification, and gene perturbation response\nprediction, it remains to be seen if a simpler model could achieve comparable\nor better results, especially with limited data. This is important, as the\nquantity and quality of single-cell data typically fall short of the standards\nin textual data used for training LLMs. Single-cell sequencing often suffers\nfrom technical artifacts, dropout events, and batch effects. These challenges\nare compounded in a weakly supervised setting, where the labels of cell states\ncan be noisy, further complicating the analysis. To tackle these challenges, we\npresent sc-OTGM, streamlined with less than 500K parameters, making it\napproximately 100x more compact than the foundation models, offering an\nefficient alternative. sc-OTGM is an unsupervised model grounded in the\ninductive bias that the scRNAseq data can be generated from a combination of\nthe finite multivariate Gaussian distributions. The core function of sc-OTGM is\nto create a probabilistic latent space utilizing a GMM as its prior\ndistribution and distinguish between distinct cell populations by learning\ntheir respective marginal PDFs. It uses a Hit-and-Run Markov chain sampler to\ndetermine the OT plan across these PDFs within the GMM framework. We evaluated\nour model against a CRISPR-mediated perturbation dataset, called CROP-seq,\nconsisting of 57 one-gene perturbations. Our results demonstrate that sc-OTGM\nis effective in cell state classification, aids in the analysis of differential\ngene expression, and ranks genes for target identification through a\nrecommender system. It also predicts the effects of single-gene perturbations\non downstream gene regulation and generates synthetic scRNA-seq data\nconditioned on specific cell states.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.03726v1"
    },
    {
        "title": "Whole Genome Transformer for Gene Interaction Effects in Microbiome\n  Habitat Specificity",
        "authors": [
            "Zhufeng Li",
            "Sandeep S Cranganore",
            "Nicholas Youngblut",
            "Niki Kilbertus"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Leveraging the vast genetic diversity within microbiomes offers unparalleled\ninsights into complex phenotypes, yet the task of accurately predicting and\nunderstanding such traits from genomic data remains challenging. We propose a\nframework taking advantage of existing large models for gene vectorization to\npredict habitat specificity from entire microbial genome sequences. Based on\nour model, we develop attribution techniques to elucidate gene interaction\neffects that drive microbial adaptation to diverse environments. We train and\nvalidate our approach on a large dataset of high quality microbiome genomes\nfrom different habitats. We not only demonstrate solid predictive performance,\nbut also how sequence-level information of entire genomes allows us to identify\ngene associations underlying complex phenotypes. Our attribution recovers known\nimportant interaction networks and proposes new candidates for experimental\nfollow up.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.05998v2"
    },
    {
        "title": "Fine-tuning Protein Language Models with Deep Mutational Scanning\n  improves Variant Effect Prediction",
        "authors": [
            "Aleix Lafita",
            "Ferran Gonzalez",
            "Mahmoud Hossam",
            "Paul Smyth",
            "Jacob Deasy",
            "Ari Allyn-Feuer",
            "Daniel Seaton",
            "Stephen Young"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Protein Language Models (PLMs) have emerged as performant and scalable tools\nfor predicting the functional impact and clinical significance of\nprotein-coding variants, but they still lag experimental accuracy. Here, we\npresent a novel fine-tuning approach to improve the performance of PLMs with\nexperimental maps of variant effects from Deep Mutational Scanning (DMS) assays\nusing a Normalised Log-odds Ratio (NLR) head. We find consistent improvements\nin a held-out protein test set, and on independent DMS and clinical variant\nannotation benchmarks from ProteinGym and ClinVar. These findings demonstrate\nthat DMS is a promising source of sequence diversity and supervised training\ndata for improving the performance of PLMs for variant effect prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.06729v1"
    },
    {
        "title": "VQDNA: Unleashing the Power of Vector Quantization for Multi-Species\n  Genomic Sequence Modeling",
        "authors": [
            "Siyuan Li",
            "Zedong Wang",
            "Zicheng Liu",
            "Di Wu",
            "Cheng Tan",
            "Jiangbin Zheng",
            "Yufei Huang",
            "Stan Z. Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Similar to natural language models, pre-trained genome language models are\nproposed to capture the underlying intricacies within genomes with unsupervised\nsequence modeling. They have become essential tools for researchers and\npractitioners in biology. However, the hand-crafted tokenization policies used\nin these models may not encode the most discriminative patterns from the\nlimited vocabulary of genomic data. In this paper, we introduce VQDNA, a\ngeneral-purpose framework that renovates genome tokenization from the\nperspective of genome vocabulary learning. By leveraging vector-quantized\ncodebooks as learnable vocabulary, VQDNA can adaptively tokenize genomes into\npattern-aware embeddings in an end-to-end manner. To further push its limits,\nwe propose Hierarchical Residual Quantization (HRQ), where varying scales of\ncodebooks are designed in a hierarchy to enrich the genome vocabulary in a\ncoarse-to-fine manner. Extensive experiments on 32 genome datasets demonstrate\nVQDNA's superiority and favorable parameter efficiency compared to existing\ngenome language models. Notably, empirical analysis of SARS-CoV-2 mutations\nreveals the fine-grained pattern awareness and biological significance of\nlearned HRQ vocabulary, highlighting its untapped potential for broader\napplications in genomics.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.10812v2"
    },
    {
        "title": "DYNA: Disease-Specific Language Model for Variant Pathogenicity",
        "authors": [
            "Huixin Zhan",
            "Zijun Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Clinical variant classification of pathogenic versus benign genetic variants\nremains a challenge in clinical genetics. Recently, the proposition of genomic\nfoundation models has improved the generic variant effect prediction (VEP)\naccuracy via weakly-supervised or unsupervised training. However, these VEPs\nare not disease-specific, limiting their adaptation at the point of care. To\naddress this problem, we propose DYNA: Disease-specificity fine-tuning via a\nSiamese neural network broadly applicable to all genomic foundation models for\nmore effective variant effect predictions in disease-specific contexts. We\nevaluate DYNA in two distinct disease-relevant tasks. For coding VEPs, we focus\non various cardiovascular diseases, where gene-disease relationships of\nloss-of-function vs. gain-of-function dictate disease-specific VEP. For\nnon-coding VEPs, we apply DYNA to an essential post-transcriptional regulatory\naxis of RNA splicing, the most common non-coding pathogenic mechanism in\nestablished clinical VEP guidelines. In both cases, DYNA fine-tunes various\npre-trained genomic foundation models on small, rare variant sets. The DYNA\nfine-tuned models show superior performance in the held-out rare variant\ntesting set and are further replicated in large, clinically-relevant variant\nannotations in ClinVAR. Thus, DYNA offers a potent disease-specific variant\neffect prediction method, excelling in intra-gene generalization and\ngeneralization to unseen genetic variants, making it particularly valuable for\ndisease associations and clinical applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.00164v1"
    },
    {
        "title": "GenBench: A Benchmarking Suite for Systematic Evaluation of Genomic\n  Foundation Models",
        "authors": [
            "Zicheng Liu",
            "Jiahui Li",
            "Siyuan Li",
            "Zelin Zang",
            "Cheng Tan",
            "Yufei Huang",
            "Yajing Bai",
            "Stan Z. Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The Genomic Foundation Model (GFM) paradigm is expected to facilitate the\nextraction of generalizable representations from massive genomic data, thereby\nenabling their application across a spectrum of downstream applications.\nDespite advancements, a lack of evaluation framework makes it difficult to\nensure equitable assessment due to experimental settings, model intricacy,\nbenchmark datasets, and reproducibility challenges. In the absence of\nstandardization, comparative analyses risk becoming biased and unreliable. To\nsurmount this impasse, we introduce GenBench, a comprehensive benchmarking\nsuite specifically tailored for evaluating the efficacy of Genomic Foundation\nModels. GenBench offers a modular and expandable framework that encapsulates a\nvariety of state-of-the-art methodologies. Through systematic evaluations of\ndatasets spanning diverse biological domains with a particular emphasis on both\nshort-range and long-range genomic tasks, firstly including the three most\nimportant DNA tasks covering Coding Region, Non-Coding Region, Genome\nStructure, etc. Moreover, We provide a nuanced analysis of the interplay\nbetween model architecture and dataset characteristics on task-specific\nperformance. Our findings reveal an interesting observation: independent of the\nnumber of parameters, the discernible difference in preference between the\nattention-based and convolution-based models on short- and long-range tasks may\nprovide insights into the future design of GFM.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01627v2"
    },
    {
        "title": "Systematic evaluation of the isolated effect of tissue environment on\n  the transcriptome using a single-cell RNA-seq atlas dataset",
        "authors": [
            "Daigo Okada",
            "Jianshen Zhu",
            "Kan Shota",
            "Yuuki Nishimura",
            "Kazuya Haraguchi"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Background: Understanding cellular diversity throughout the body is essential\nfor elucidating the complex functions of biological systems. Recently,\nlarge-scale single-cell omics datasets, known as omics atlases, have become\navailable. These atlases encompass data from diverse tissues and cell-types,\nproviding insights into the landscape of cell-type-specific gene expression.\nHowever, the isolated effect of the tissue environment has not been thoroughly\ninvestigated. Evaluating this isolated effect is challenging due to statistical\nconfounding with cell-type effects, arising from significant biases in the\ncombinations of tissues and cell-types within the body. Results: This study\nintroduces a novel data analysis framework, named the Combinatorial Sub-dataset\nExtraction for Confounding Reduction (COSER), which addresses statistical\nconfounding by using graph theory to enumerate appropriate sub-datasets. COSER\nenables the assessment of isolated effects of discrete variables in single\ncells. Applying COSER to the Tabula Muris Senis single-cell transcriptome\natlas, we characterized the isolated impact of tissue environments. Our\nfindings demonstrate that some of genes are markedly affected by the tissue\nenvironment, particularly in modulating intercellular diversity in immune\nresponses and their age-related changes. Conclusion: COSER provides a robust,\ngeneral-purpose framework for evaluating the isolated effects of discrete\nvariables from large-scale data mining. This approach reveals critical insights\ninto the interplay between tissue environments and gene expression.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.06969v2"
    },
    {
        "title": "AOC: Analysis of Orthologous Collections -- an application for the\n  characterization of natural selection in protein-coding sequences",
        "authors": [
            "Alexander Lucaci",
            "Sergei Pond"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Motivation Modern molecular sequence analysis increasingly relies on\nautomated and robust software tools for interpretation, annotation, and\nbiological insight. The Analysis of Orthologous Collections (AOC) application\nautomates the identification of genomic sites and species/lineages influenced\nby natural selection in coding sequence analysis. AOC quantifies different\ntypes of selection: negative, diversifying or directional positive, or\ndifferential selection between groups of branches. We include all steps\nnecessary to go from unaligned homologous sequences to complete results and\ninteractive visualizations that are designed to aid in the useful\ninterpretation and contextualization. Results We are motivated by a desire to\nmake evolutionary analyses as simple as possible, and to close the disparity in\nthe literature between genes which draw a significant amount of interest and\nthose that are largely overlooked and underexplored. We believe that such\nunderappreciated and understudied genetic datasets can hold rich biological\ninformation and offer substantial insights into the diverse patterns and\nprocesses of evolution, especially if domain experts are able to perform the\nanalyses themselves. Availability and implementation A Snakemake [M\\\"older et\nal., 2021] application implementation is publicly available on GitHub at\nhttps://github.com/aglucaci/AnalysisOfOrthologousCollections and is accompanied\nby software documentation and a tutorial.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.09522v1"
    },
    {
        "title": "Online t-SNE for single-cell RNA-seq",
        "authors": [
            "Hui Ma",
            "Kai Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Due to the sequential sample arrival, changing experiment conditions, and\nevolution of knowledge, the demand to continually visualize evolving structures\nof sequential and diverse single-cell RNA-sequencing (scRNA-seq) data becomes\nindispensable. However, as one of the state-of-the-art visualization and\nanalysis methods for scRNA-seq, t-distributed stochastic neighbor embedding\n(t-SNE) merely visualizes static scRNA-seq data offline and fails to meet the\ndemand well. To address these challenges, we introduce online t-SNE to\nseamlessly integrate sequential scRNA-seq data. Online t-SNE achieves this by\nleveraging the embedding space of old samples, exploring the embedding space of\nnew samples, and aligning the two embedding spaces on the fly. Consequently,\nonline t-SNE dramatically enables the continual discovery of new structures and\nhigh-quality visualization of new scRNA-seq data without retraining from\nscratch. We showcase the formidable visualization capabilities of online t-SNE\nacross diverse sequential scRNA-seq datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14842v1"
    },
    {
        "title": "CGRclust: Chaos Game Representation for Twin Contrastive Clustering of\n  Unlabelled DNA Sequences",
        "authors": [
            "Fatemeh Alipour",
            "Kathleen A. Hill",
            "Lila Kari"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This study proposes CGRclust, a novel combination of unsupervised twin\ncontrastive clustering of Chaos Game Representations (CGR) of DNA sequences,\nwith convolutional neural networks (CNNs). To the best of our knowledge,\nCGRclust is the first method to use unsupervised learning for image\nclassification (herein applied to two-dimensional CGR images) for clustering\ndatasets of DNA sequences. CGRclust overcomes the limitations of traditional\nsequence classification methods by leveraging unsupervised twin contrastive\nlearning to detect distinctive sequence patterns, without requiring DNA\nsequence alignment or biological/taxonomic labels. CGRclust accurately\nclustered twenty-five diverse datasets, with sequence lengths ranging from 664\nbp to 100 kbp, including mitochondrial genomes of fish, fungi, and protists, as\nwell as viral whole genome assemblies and synthetic DNA sequences. Compared\nwith three recent clustering methods for DNA sequences (DeLUCS, iDeLUCS, and\nMeShClust v3.0.), CGRclust is the only method that surpasses 81.70% accuracy\nacross all four taxonomic levels tested for mitochondrial DNA genomes of fish.\nMoreover, CGRclust also consistently demonstrates superior performance across\nall the viral genomic datasets. The high clustering accuracy of CGRclust on\nthese twenty-five datasets, which vary significantly in terms of sequence\nlength, number of genomes, number of clusters, and level of taxonomy,\ndemonstrates its robustness, scalability, and versatility.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.02538v2"
    },
    {
        "title": "MotifbreakR v2: extended capability and database integration",
        "authors": [
            "Simon G. Coetzee",
            "Dennis J. Hazelett"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  MotifbreakR is a software tool that scans genetic variants against position\nweight matrices of transcription factors (TF) to determine the potential for\nthe disruption of TF binding at the site of the variant. It leverages the\nBioconductor suite of software packages and annotations to operate across a\ndiverse array of genomes and motif databases. Initially developed to\ninterrogate the effect of single nucleotide variants (common and rare SNVs) on\npotential TF binding sites, in motifbreakR v2, we have updated the\nfunctionality. New features include the ability to query other types of more\ncomplex genetic variants, such as short insertions and deletions (indels). This\nfunction allows modeling a more extensive array of variants that may have more\nsignificant effects on TF binding. Additionally, while TF binding is based\npartly on sequence preference, predictions of TF binding based on sequence\npreference alone can indicate many more potential binding events than observed.\nAdding information from DNA-binding sequencing datasets lends confidence to\nmotif disruption prediction by demonstrating TF binding in cell lines and\ntissue types. Therefore, motifbreakR implements querying the ReMap2022 database\nfor evidence that a TF matching the disrupted motif binds over the disrupting\nvariant. Finally, in motifbreakR, in addition to the existing interface, we\nhave implemented an R/Shiny graphical user interface to simplify and enhance\naccess to researchers with different skill sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.03441v1"
    },
    {
        "title": "FastImpute: A Baseline for Open-source, Reference-Free Genotype\n  Imputation Methods -- A Case Study in PRS313",
        "authors": [
            "Aaron Ge",
            "Jeya Balasubramanian",
            "Xueyao Wu",
            "Peter Kraft",
            "Jonas S. Almeida"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Genotype imputation enhances genetic data by predicting missing SNPs using\nreference haplotype information. Traditional methods leverage linkage\ndisequilibrium (LD) to infer untyped SNP genotypes, relying on the similarity\nof LD structures between genotyped target sets and fully sequenced reference\npanels. Recently, reference-free deep learning-based methods have emerged,\noffering a promising alternative by predicting missing genotypes without\nexternal databases, thereby enhancing privacy and accessibility. However, these\nmethods often produce models with tens of millions of parameters, leading to\nchallenges such as the need for substantial computational resources to train\nand inefficiency for client-sided deployment. Our study addresses these\nlimitations by introducing a baseline for a novel genotype imputation pipeline\nthat supports client-sided imputation models generalizable across any\ngenotyping chip and genomic region. This approach enhances patient privacy by\nperforming imputation directly on edge devices. As a case study, we focus on\nPRS313, a polygenic risk score comprising 313 SNPs used for breast cancer risk\nprediction. Utilizing consumer genetic panels such as 23andMe, our model\ndemocratizes access to personalized genetic insights by allowing 23andMe users\nto obtain their PRS313 score. We demonstrate that simple linear regression can\nsignificantly improve the accuracy of PRS313 scores when calculated using SNPs\nimputed from consumer gene panels, such as 23andMe. Our linear regression model\nachieved an R^2 of 0.86, compared to 0.33 without imputation and 0.28 with\nsimple imputation (substituting missing SNPs with the minor allele frequency).\nThese findings suggest that popular SNP analysis libraries could benefit from\nintegrating linear regression models for genotype imputation, providing a\nviable and light-weight alternative to reference based imputation.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.09355v1"
    },
    {
        "title": "Bridging Sequence-Structure Alignment in RNA Foundation Models",
        "authors": [
            "Heng Yang",
            "Renzhi Chen",
            "Ke Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The alignment between RNA sequences and structures in foundation models (FMs)\nhas yet to be thoroughly investigated. Existing FMs have struggled to establish\nsequence-structure alignment, hindering the free flow of genomic information\nbetween RNA sequences and structures. In this study, we introduce OmniGenome,\nan RNA FM trained to align RNA sequences with respect to secondary structures\nbased on structure-contextualised modelling. The alignment enables free and\nbidirectional mappings between sequences and structures by utilising the\nflexible RNA modelling paradigm that supports versatile input and output\nmodalities, i.e., sequence and/or structure as input/output. We implement RNA\ndesign and zero-shot secondary structure prediction as case studies to evaluate\nthe Seq2Str and Str2Seq mapping capacity of OmniGenome. Results on the EternaV2\nbenchmark show that OmniGenome solved 74% of puzzles, whereas existing FMs only\nsolved up to 3% of the puzzles due to the oversight of sequence-structure\nalignment. We leverage four comprehensive in-silico genome modelling benchmarks\nto evaluate performance across a diverse set of genome downstream tasks, where\nthe results show that OmniGenome achieves state-of-the-art performance on RNA\nand DNA benchmarks, even without any training on DNA genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.11242v3"
    },
    {
        "title": "A Benchmark Dataset for Multimodal Prediction of Enzymatic Function\n  Coupling DNA Sequences and Natural Language",
        "authors": [
            "Yuchen Zhang",
            "Ratish Kumar Chandrakant Jha",
            "Soumya Bharadwaj",
            "Vatsal Sanjaykumar Thakkar",
            "Adrienne Hoarfrost",
            "Jin Sun"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Predicting gene function from its DNA sequence is a fundamental challenge in\nbiology. Many deep learning models have been proposed to embed DNA sequences\nand predict their enzymatic function, leveraging information in public\ndatabases linking DNA sequences to an enzymatic function label. However, much\nof the scientific community's knowledge of biological function is not\nrepresented in these categorical labels, and is instead captured in\nunstructured text descriptions of mechanisms, reactions, and enzyme behavior.\nThese descriptions are often captured alongside DNA sequences in biological\ndatabases, albeit in an unstructured manner. Deep learning of models predicting\nenzymatic function are likely to benefit from incorporating this multi-modal\ndata encoding scientific knowledge of biological function. There is, however,\nno dataset designed for machine learning algorithms to leverage this\nmulti-modal information. Here we propose a novel dataset and benchmark suite\nthat enables the exploration and development of large multi-modal neural\nnetwork models on gene DNA sequences and natural language descriptions of gene\nfunction. We present baseline performance on benchmarks for both unsupervised\nand supervised tasks that demonstrate the difficulty of this modeling\nobjective, while demonstrating the potential benefit of incorporating\nmulti-modal data types in function prediction compared to DNA sequences alone.\nOur dataset is at: https://hoarfrost-lab.github.io/BioTalk/.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.15888v1"
    },
    {
        "title": "LSTM Autoencoder-based Deep Neural Networks for Barley\n  Genotype-to-Phenotype Prediction",
        "authors": [
            "Guanjin Wang",
            "Junyu Xuan",
            "Penghao Wang",
            "Chengdao Li",
            "Jie Lu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Artificial Intelligence (AI) has emerged as a key driver of precision\nagriculture, facilitating enhanced crop productivity, optimized resource use,\nfarm sustainability, and informed decision-making. Also, the expansion of\ngenome sequencing technology has greatly increased crop genomic resources,\ndeepening our understanding of genetic variation and enhancing desirable crop\ntraits to optimize performance in various environments. There is increasing\ninterest in using machine learning (ML) and deep learning (DL) algorithms for\ngenotype-to-phenotype prediction due to their excellence in capturing complex\ninteractions within large, high-dimensional datasets. In this work, we propose\na new LSTM autoencoder-based model for barley genotype-to-phenotype prediction,\nspecifically for flowering time and grain yield estimation, which could\npotentially help optimize yields and management practices. Our model\noutperformed the other baseline methods, demonstrating its potential in\nhandling complex high-dimensional agricultural datasets and enhancing crop\nphenotype prediction performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16709v1"
    },
    {
        "title": "Pan-cancer gene set discovery via scRNA-seq for optimal deep learning\n  based downstream tasks",
        "authors": [
            "Jong Hyun Kim",
            "Jongseong Jang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The application of machine learning to transcriptomics data has led to\nsignificant advances in cancer research. However, the high dimensionality and\ncomplexity of RNA sequencing (RNA-seq) data pose significant challenges in\npan-cancer studies. This study hypothesizes that gene sets derived from\nsingle-cell RNA sequencing (scRNA-seq) data will outperform those selected\nusing bulk RNA-seq in pan-cancer downstream tasks. We analyzed scRNA-seq data\nfrom 181 tumor biopsies across 13 cancer types. High-dimensional weighted gene\nco-expression network analysis (hdWGCNA) was performed to identify relevant\ngene sets, which were further refined using XGBoost for feature selection.\nThese gene sets were applied to downstream tasks using TCGA pan-cancer RNA-seq\ndata and compared to six reference gene sets and oncogenes from OncoKB\nevaluated with deep learning models, including multilayer perceptrons (MLPs)\nand graph neural networks (GNNs). The XGBoost-refined hdWGCNA gene set\ndemonstrated higher performance in most tasks, including tumor mutation burden\nassessment, microsatellite instability classification, mutation prediction,\ncancer subtyping, and grading. In particular, genes such as DPM1, BAD, and\nFKBP4 emerged as important pan-cancer biomarkers, with DPM1 consistently\nsignificant across tasks. This study presents a robust approach for feature\nselection in cancer genomics by integrating scRNA-seq data and advanced\nanalysis techniques, offering a promising avenue for improving predictive\naccuracy in cancer research.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07233v1"
    },
    {
        "title": "Pretrained-Guided Conditional Diffusion Models for Microbiome Data\n  Analysis",
        "authors": [
            "Xinyuan Shi",
            "Fangfang Zhu",
            "Wenwen Min"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Emerging evidence indicates that human cancers are intricately linked to\nhuman microbiomes, forming an inseparable connection. However, due to limited\nsample sizes and significant data loss during collection for various reasons,\nsome machine learning methods have been proposed to address the issue of\nmissing data. These methods have not fully utilized the known clinical\ninformation of patients to enhance the accuracy of data imputation. Therefore,\nwe introduce mbVDiT, a novel pre-trained conditional diffusion model for\nmicrobiome data imputation and denoising, which uses the unmasked data and\npatient metadata as conditional guidance for imputating missing values. It is\nalso uses VAE to integrate the the other public microbiome datasets to enhance\nmodel performance. The results on the microbiome datasets from three different\ncancer types demonstrate the performance of our methods in comparison with\nexisting methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07709v1"
    },
    {
        "title": "Computational strategies for cross-species knowledge transfer and\n  translational biomedicine",
        "authors": [
            "Hao Yuan",
            "Christopher A. Mancuso",
            "Kayla Johnson",
            "Ingo Braasch",
            "Arjun Krishnan"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Research organisms provide invaluable insights into human biology and\ndiseases, serving as essential tools for functional experiments, disease\nmodeling, and drug testing. However, evolutionary divergence between humans and\nresearch organisms hinders effective knowledge transfer across species. Here,\nwe review state-of-the-art methods for computationally transferring knowledge\nacross species, primarily focusing on methods that utilize transcriptome data\nand/or molecular networks. We introduce the term \"agnology\" to describe the\nfunctional equivalence of molecular components regardless of evolutionary\norigin, as this concept is becoming pervasive in integrative data-driven models\nwhere the role of evolutionary origin can become unclear. Our review addresses\nfour key areas of information and knowledge transfer across species: (1)\ntransferring disease and gene annotation knowledge, (2) identifying agnologous\nmolecular components, (3) inferring equivalent perturbed genes or gene sets,\nand (4) identifying agnologous cell types. We conclude with an outlook on\nfuture directions and several key challenges that remain in cross-species\nknowledge transfer.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.08503v1"
    },
    {
        "title": "Wave-LSTM: Multi-scale analysis of somatic whole genome copy number\n  profiles",
        "authors": [
            "Charles Gadd",
            "Christopher Yau"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Changes in the number of copies of certain parts of the genome, known as copy\nnumber alterations (CNAs), due to somatic mutation processes are a hallmark of\nmany cancers. This genomic complexity is known to be associated with poorer\noutcomes for patients but describing its contribution in detail has been\ndifficult. Copy number alterations can affect large regions spanning whole\nchromosomes or the entire genome itself but can also be localised to only small\nsegments of the genome and no methods exist that allow this multi-scale nature\nto be quantified. In this paper, we address this using Wave-LSTM, a signal\ndecomposition approach designed to capture the multi-scale structure of complex\nwhole genome copy number profiles. Using wavelet-based source separation in\ncombination with deep learning-based attention mechanisms. We show that\nWave-LSTM can be used to derive multi-scale representations from copy number\nprofiles which can be used to decipher sub-clonal structures from single-cell\ncopy number data and to improve survival prediction performance from patient\ntumour profiles.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.12636v1"
    },
    {
        "title": "Discovering Candidate Genes Regulated by GWAS Signals in Cis and Trans",
        "authors": [
            "Samhita Pal",
            "Xinge Jessie Jeng"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Understanding the genetic underpinnings of complex traits and diseases has\nbeen greatly advanced by genome-wide association studies (GWAS). However, a\nsignificant portion of trait heritability remains unexplained, known as\n``missing heritability\". Most GWAS loci reside in non-coding regions, posing\nchallenges in understanding their functional impact. Integrating GWAS with\nfunctional genomic data, such as expression quantitative trait loci (eQTLs),\ncan bridge this gap. This study introduces a novel approach to discover\ncandidate genes regulated by GWAS signals in both cis and trans. Unlike\nexisting eQTL studies that focus solely on cis-eQTLs or consider cis- and\ntrans-QTLs separately, we utilize adaptive statistical metrics that can reflect\nboth the strong, sparse effects of cis-eQTLs and the weak, dense effects of\ntrans-eQTLs. Consequently, candidate genes regulated by the joint effects can\nbe prioritized. We demonstrate the efficiency of our method through theoretical\nand numerical analyses and apply it to adipose eQTL data from the METabolic\nSyndrome in Men (METSIM) study, uncovering genes playing important roles in the\nregulatory networks influencing cardiometabolic traits. Our findings offer new\ninsights into the genetic regulation of complex traits and present a practical\nframework for identifying key regulatory genes based on joint eQTL effects.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.02116v1"
    },
    {
        "title": "CMOB: Large-Scale Cancer Multi-Omics Benchmark with Open Datasets,\n  Tasks, and Baselines",
        "authors": [
            "Ziwei Yang",
            "Rikuto Kotoge",
            "Zheng Chen",
            "Xihao Piao",
            "Yasuko Matsubara",
            "Yasushi Sakurai"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Machine learning has shown great potential in the field of cancer multi-omics\nstudies, offering incredible opportunities for advancing precision medicine.\nHowever, the challenges associated with dataset curation and task formulation\npose significant hurdles, especially for researchers lacking a biomedical\nbackground. Here, we introduce the CMOB, the first large-scale cancer\nmulti-omics benchmark integrates the TCGA platform, making data resources\naccessible and usable for machine learning researchers without significant\npreparation and expertise.To date, CMOB includes a collection of 20 cancer\nmulti-omics datasets covering 32 cancers, accompanied by a systematic data\nprocessing pipeline. CMOB provides well-processed dataset versions to support\n20 meaningful tasks in four studies, with a collection of benchmarks. We also\nintegrate CMOB with two complementary resources and various biological tools to\nexplore broader research avenues.All resources are open-accessible with\nuser-friendly and compatible integration scripts that enable non-experts to\neasily incorporate this complementary information for various tasks. We conduct\nextensive experiments on selected datasets to offer recommendations on suitable\nmachine learning baselines for specific applications. Through CMOB, we aim to\nfacilitate algorithmic advances and hasten the development, validation, and\nclinical translation of machine-learning models for personalized cancer\ntreatments. CMOB is available on GitHub\n(\\url{https://github.com/chenzRG/Cancer-Multi-Omics-Benchmark}).\n",
        "pdf_link": "http://arxiv.org/pdf/2409.02143v1"
    },
    {
        "title": "Machine Learning-Based Prediction of Key Genes Correlated to the\n  Subretinal Lesion Severity in a Mouse Model of Age-Related Macular\n  Degeneration",
        "authors": [
            "Kuan Yan",
            "Yue Zeng",
            "Dai Shi",
            "Ting Zhang",
            "Dmytro Matsypura",
            "Mark C. Gillies",
            "Ling Zhu",
            "Junbin Gao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Age-related macular degeneration (AMD) is a major cause of blindness in older\nadults, severely affecting vision and quality of life. Despite advances in\nunderstanding AMD, the molecular factors driving the severity of subretinal\nscarring (fibrosis) remain elusive, hampering the development of effective\ntherapies. This study introduces a machine learning-based framework to predict\nkey genes that are strongly correlated with lesion severity and to identify\npotential therapeutic targets to prevent subretinal fibrosis in AMD. Using an\noriginal RNA sequencing (RNA-seq) dataset from the diseased retinas of JR5558\nmice, we developed a novel and specific feature engineering technique,\nincluding pathway-based dimensionality reduction and gene-based feature\nexpansion, to enhance prediction accuracy. Two iterative experiments were\nconducted by leveraging Ridge and ElasticNet regression models to assess\nbiological relevance and gene impact. The results highlight the biological\nsignificance of several key genes and demonstrate the framework's effectiveness\nin identifying novel therapeutic targets. The key findings provide valuable\ninsights for advancing drug discovery efforts and improving treatment\nstrategies for AMD, with the potential to enhance patient outcomes by targeting\nthe underlying genetic mechanisms of subretinal lesion development.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05047v1"
    },
    {
        "title": "Gene and RNA Editing: Methods, Enabling Technologies, Applications, and\n  Future Directions",
        "authors": [
            "Mohammed Aledhari",
            "Mohamed Rahouti"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Gene and RNA editing methods, technologies, and applications are emerging as\ninnovative forms of therapy and medicine, offering more efficient\nimplementation compared to traditional pharmaceutical treatments. Current\ntrends emphasize the urgent need for advanced methods and technologies to\ndetect public health threats, including diseases and viral agents. Gene and RNA\nediting techniques enhance the ability to identify, modify, and ameliorate the\neffects of genetic diseases, disorders, and disabilities. Viral detection and\nidentification methods present numerous opportunities for enabling\ntechnologies, such as CRISPR, applicable to both RNA and gene editing through\nthe use of specific Cas proteins. This article explores the distinctions and\nbenefits of RNA and gene editing processes, emphasizing their contributions to\nthe future of medical treatment. CRISPR technology, particularly its adaptation\nvia the Cas13 protein for RNA editing, is a significant advancement in gene\nediting. The article will delve into RNA and gene editing methodologies,\nfocusing on techniques that alter and modify genetic coding. A-to-I and C-to-U\nediting are currently the most predominant methods of RNA modification. CRISPR\nstands out as the most cost-effective and customizable technology for both RNA\nand gene editing. Unlike permanent changes induced by cutting an individual's\nDNA genetic code, RNA editing offers temporary modifications by altering\nnucleoside bases in RNA strands, which can then attach to DNA strands as\ntemporary modifiers.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09057v1"
    },
    {
        "title": "The Future of Decoding Non-Standard Nucleotides: Leveraging Nanopore\n  Sequencing for Expanded Genetic Codes",
        "authors": [
            "Hyunjin Shim"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Expanding genetic codes from natural standard nucleotides to artificial\nnon-standard nucleotides marks a significant advancement in synthetic biology,\nwith profound implications for biotechnology and medicine. Decoding the\nbiological information encoded in these non-standard nucleotides presents new\nchallenges, as traditional sequencing technologies are unable to recognize or\ninterpret novel base pairings. In this perspective, we explore the potential of\nnanopore sequencing, which is uniquely suited to decipher both standard and\nnon-standard nucleotides by directly measuring the biophysical properties of\nnucleic acids. Nanopore technology offers real-time, long-read sequencing\nwithout the need for amplification or synthesis, making it particularly\nadvantageous for expanded genetic systems like Artificially Expanded Genetic\nInformation Systems (AEGIS). We discuss how the adaptability of nanopore\nsequencing and advancements in data processing can unlock the potential of\nthese synthetic genomes and open new frontiers in understanding and utilizing\nexpanded genetic codes.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09314v1"
    },
    {
        "title": "Multivariate Analysis of Gut Microbiota Composition and Prevalence of\n  Gastric Cancer",
        "authors": [
            "Aadhith Shankarnarayanan",
            "Dheeman Gangopadhyay",
            "Ayman Alzaatreh"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The global surge in the cases of gastric cancer has prompted an investigation\ninto the potential of gut microbiota as a predictive marker for the disease.\nThe alterations in gut diversity are suspected to be associated with an\nelevated risk of gastric cancer. This paper delves into finding the correlation\nbetween gut microbiota and gastric cancer, focusing on patients who have\nundergone total and subtotal gastrectomy. Utilizing data mining and statistical\nlearning methods, an analysis was conducted on 16S-RNA sequenced genes obtained\nfrom 96 participants with the aim of identifying specific genera of gut\nmicrobiota associated with gastric cancer. The study reveals several prominent\nbacterial genera that could potentially serve as biomarkers assessing the risk\nof gastric cancer. These findings offer a pathway for early risk assessment and\nprecautionary measures in the diagnosis of gastric cancer. The intricate\nmechanisms through which these gut microbiotas influence gastric cancer\nprogression warrant further investigation. This research significantly aims to\ncontribute to the growing understanding of the gut-cancer axis and its\nimplications in disease prediction and prevention.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12209v1"
    },
    {
        "title": "PRAGA: Prototype-aware Graph Adaptive Aggregation for Spatial\n  Multi-modal Omics Analysis",
        "authors": [
            "Xinlei Huang",
            "Zhiqi Ma",
            "Dian Meng",
            "Yanran Liu",
            "Shiwei Ruan",
            "Qingqiang Sun",
            "Xubin Zheng",
            "Ziyue Qiao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Spatial multi-modal omics technology, highlighted by Nature Methods as an\nadvanced biological technique in 2023, plays a critical role in resolving\nbiological regulatory processes with spatial context. Recently, graph neural\nnetworks based on K-nearest neighbor (KNN) graphs have gained prominence in\nspatial multi-modal omics methods due to their ability to model semantic\nrelations between sequencing spots. However, the fixed KNN graph fails to\ncapture the latent semantic relations hidden by the inevitable data\nperturbations during the biological sequencing process, resulting in the loss\nof semantic information. In addition, the common lack of spot annotation and\nclass number priors in practice further hinders the optimization of spatial\nmulti-modal omics models. Here, we propose a novel spatial multi-modal omics\nresolved framework, termed PRototype-Aware Graph Adaptative Aggregation for\nSpatial Multi-modal Omics Analysis (PRAGA). PRAGA constructs a dynamic graph to\ncapture latent semantic relations and comprehensively integrate spatial\ninformation and feature semantics. The learnable graph structure can also\ndenoise perturbations by learning cross-modal knowledge. Moreover, a dynamic\nprototype contrastive learning is proposed based on the dynamic adaptability of\nBayesian Gaussian Mixture Models to optimize the multi-modal omics\nrepresentations for unknown biological priors. Quantitative and qualitative\nexperiments on simulated and real datasets with 7 competing methods demonstrate\nthe superior performance of PRAGA. Code is available at\nhttps://github.com/Xubin-s-Lab/PRAGA.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12728v5"
    },
    {
        "title": "Uncertainty-aware t-distributed Stochastic Neighbor Embedding for\n  Single-cell RNA-seq Data",
        "authors": [
            "Hui Ma",
            "Kai Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Nonlinear data visualization using t-distributed stochastic neighbor\nembedding (t-SNE) enables the representation of complex single-cell\ntranscriptomic landscapes in two or three dimensions to depict biological\npopulations accurately. However, t-SNE often fails to account for uncertainties\nin the original dataset, leading to misleading visualizations where cell\nsubsets with noise appear indistinguishable. To address these challenges, we\nintroduce uncertainty-aware t-SNE (Ut-SNE), a noise-defending visualization\ntool tailored for uncertain single-cell RNA-seq data. By creating a\nprobabilistic representation for each sample, Our Ut-SNE accurately\nincorporates noise about transcriptomic variability into the visual\ninterpretation of single-cell RNA sequencing data, revealing significant\nuncertainties in transcriptomic variability. Through various examples, we\nshowcase the practical value of Ut-SNE and underscore the significance of\nincorporating uncertainty awareness into data visualization practices. This\nversatile uncertainty-aware visualization tool can be easily adapted to other\nscientific domains beyond single-cell RNA sequencing, making them valuable\nresources for high-dimensional data analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.00473v1"
    },
    {
        "title": "OmniGenBench: Automating Large-scale in-silico Benchmarking for Genomic\n  Foundation Models",
        "authors": [
            "Heng Yang",
            "Jack Cole",
            "Ke Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The advancements in artificial intelligence in recent years, such as Large\nLanguage Models (LLMs), have fueled expectations for breakthroughs in genomic\nfoundation models (GFMs). The code of nature, hidden in diverse genomes since\nthe very beginning of life's evolution, holds immense potential for impacting\nhumans and ecosystems through genome modeling. Recent breakthroughs in GFMs,\nsuch as Evo, have attracted significant investment and attention to genomic\nmodeling, as they address long-standing challenges and transform in-silico\ngenomic studies into automated, reliable, and efficient paradigms. In the\ncontext of this flourishing era of consecutive technological revolutions in\ngenomics, GFM studies face two major challenges: the lack of GFM benchmarking\ntools and the absence of open-source software for diverse genomics. These\nchallenges hinder the rapid evolution of GFMs and their wide application in\ntasks such as understanding and synthesizing genomes, problems that have\npersisted for decades. To address these challenges, we introduce GFMBench, a\nframework dedicated to GFM-oriented benchmarking. GFMBench standardizes\nbenchmark suites and automates benchmarking for a wide range of open-source\nGFMs. It integrates millions of genomic sequences across hundreds of genomic\ntasks from four large-scale benchmarks, democratizing GFMs for a wide range of\nin-silico genomic applications. Additionally, GFMBench is released as\nopen-source software, offering user-friendly interfaces and diverse tutorials,\napplicable for AutoBench and complex tasks like RNA design and structure\nprediction. To facilitate further advancements in genome modeling, we have\nlaunched a public leaderboard showcasing the benchmark performance derived from\nAutoBench. GFMBench represents a step toward standardizing GFM benchmarking and\ndemocratizing GFM applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.01784v1"
    },
    {
        "title": "Comparative Analysis of Multi-Omics Integration Using Advanced Graph\n  Neural Networks for Cancer Classification",
        "authors": [
            "Fadi Alharbi",
            "Aleksandar Vakanski",
            "Boyu Zhang",
            "Murtada K. Elbashir",
            "Mohanad Mohammed"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Multi-omics data is increasingly being utilized to advance computational\nmethods for cancer classification. However, multi-omics data integration poses\nsignificant challenges due to the high dimensionality, data complexity, and\ndistinct characteristics of various omics types. This study addresses these\nchallenges and evaluates three graph neural network architectures for\nmulti-omics (MO) integration based on graph-convolutional networks (GCN),\ngraph-attention networks (GAT), and graph-transformer networks (GTN) for\nclassifying 31 cancer types and normal tissues. To address the\nhigh-dimensionality of multi-omics data, we employed LASSO (Least Absolute\nShrinkage and Selection Operator) regression for feature selection, leading to\nthe creation of LASSO-MOGCN, LASSO-MOGAT, and LASSO-MOTGN models. Graph\nstructures for the networks were constructed using gene correlation matrices\nand protein-protein interaction networks for multi-omics integration of\nmessenger-RNA, micro-RNA, and DNA methylation data. Such data integration\nenables the networks to dynamically focus on important relationships between\nbiological entities, improving both model performance and interpretability.\nAmong the models, LASSO-MOGAT with a correlation-based graph structure achieved\nstate-of-the-art accuracy (95.9%) and outperformed the LASSO-MOGCN and\nLASSO-MOTGN models in terms of precision, recall, and F1-score. Our findings\ndemonstrate that integrating multi-omics data in graph-based architectures\nenhances cancer classification performance by uncovering distinct molecular\npatterns that contribute to a better understanding of cancer biology and\npotential biomarkers for disease progression.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.05325v1"
    },
    {
        "title": "A mechanistically interpretable neural network for regulatory genomics",
        "authors": [
            "Alex M. Tseng",
            "Gokcen Eraslan",
            "Tommaso Biancalani",
            "Gabriele Scalia"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Deep neural networks excel in mapping genomic DNA sequences to associated\nreadouts (e.g., protein-DNA binding). Beyond prediction, the goal of these\nnetworks is to reveal to scientists the underlying motifs (and their syntax)\nwhich drive genome regulation. Traditional methods that extract motifs from\nconvolutional filters suffer from the uninterpretable dispersion of information\nacross filters and layers. Other methods which rely on importance scores can be\nunstable and unreliable. Instead, we designed a novel mechanistically\ninterpretable architecture for regulatory genomics, where motifs and their\nsyntax are directly encoded and readable from the learned weights and\nactivations. We provide theoretical and empirical evidence of our\narchitecture's full expressivity, while still being highly interpretable.\nThrough several experiments, we show that our architecture excels in de novo\nmotif discovery and motif instance calling, is robust to variable sequence\ncontexts, and enables fully interpretable generation of novel functional\nsequences.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.06211v1"
    },
    {
        "title": "A Bioinformatic Approach Validated Utilizing Machine Learning Algorithms\n  to Identify Relevant Biomarkers and Crucial Pathways in Gallbladder Cancer",
        "authors": [
            "Rabea Khatun",
            "Wahia Tasnim",
            "Maksuda Akter",
            "Md Manowarul Islam",
            "Md. Ashraf Uddin",
            "Md. Zulfiker Mahmud",
            "Saurav Chandra Das"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Gallbladder cancer (GBC) is the most frequent cause of disease among biliary\ntract neoplasms. Identifying the molecular mechanisms and biomarkers linked to\nGBC progression has been a significant challenge in scientific research. Few\nrecent studies have explored the roles of biomarkers in GBC. Our study aimed to\nidentify biomarkers in GBC using machine learning (ML) and bioinformatics\ntechniques. We compared GBC tumor samples with normal samples to identify\ndifferentially expressed genes (DEGs) from two microarray datasets (GSE100363,\nGSE139682) obtained from the NCBI GEO database. A total of 146 DEGs were found,\nwith 39 up-regulated and 107 down-regulated genes. Functional enrichment\nanalysis of these DEGs was performed using Gene Ontology (GO) terms and\nREACTOME pathways through DAVID. The protein-protein interaction network was\nconstructed using the STRING database. To identify hub genes, we applied three\nranking algorithms: Degree, MNC, and Closeness Centrality. The intersection of\nhub genes from these algorithms yielded 11 hub genes. Simultaneously, two\nfeature selection methods (Pearson correlation and recursive feature\nelimination) were used to identify significant gene subsets. We then developed\nML models using SVM and RF on the GSE100363 dataset, with validation on\nGSE139682, to determine the gene subset that best distinguishes GBC samples.\nThe hub genes outperformed the other gene subsets. Finally, NTRK2, COL14A1,\nSCN4B, ATP1A2, SLC17A7, SLIT3, COL7A1, CLDN4, CLEC3B, ADCYAP1R1, and MFAP4 were\nidentified as crucial genes, with SLIT3, COL7A1, and CLDN4 being strongly\nlinked to GBC development and prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.14433v1"
    },
    {
        "title": "DNAHLM -- DNA sequence and Human Language mixed large language Model",
        "authors": [
            "Wang Liang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  There are already many DNA large language models, but most of them still\nfollow traditional uses, such as extracting sequence features for\nclassification tasks. More innovative applications of large language models,\nsuch as prompt engineering, RAG, and zero-shot or few-shot prediction, remain\nchallenging for DNA-based models. The key issue lies in the fact that DNA\nmodels and human natural language models are entirely separate; however,\ntechniques like prompt engineering require the use of natural language, thereby\nsignificantly limiting the application of DNA large language models. This paper\nintroduces a pre-trained model trained on the GPT-2 network, combining DNA\nsequences and English text, and uses a unified BPE tokenization method. We then\nconvert classification and other downstream tasks into Alpaca format\ninstruction data, and perform instruction fine-tuning on this pre-trained model\nto create a fine-tuned model capable of handling multiple tasks. The model has\ndemonstrated its effectiveness in DNA related zero-shot prediction and\nmultitask application. This research provides a highly promising direction for\nbuilding a unified DNA sequence task framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.16917v2"
    },
    {
        "title": "Hypothalamic expression analysis of m6A RNA methylation associated genes\n  suggests a potential role of epitransciptomics in sexual maturation of\n  Atlantic salmon",
        "authors": [
            "Ehsan Pashay Ahi",
            "Morgane Frapin",
            "Mikaela Hukkanen",
            "Craig R. Primmer"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Better understanding the molecular processes contributing to variation in\nmaturation timing is important for Atlantic salmon aquaculture, as early\nmaturation causes considerable financial losses. The m6A RNA methylation is a\nconserved and dynamically reversible mechanism controlling gene expression in a\nmyriad of biological processes. The role of m6A methylation in sexual\nmaturation, however, has remained largely unexplored and has never been studied\nin Atlantic salmon. While the maturation process is known to be affected by\nmany genetic and environmental factors, the molecular mechanisms causing\nvariation in the timing of maturation are still poorly understood. Hence,\ninvestigation of whether a widespread mechanism like m6A methylation could be\ninvolved in controlling of the maturation timing is warranted. In salmon, two\ngenes, also associated with age at maturity in humans, vgll3 and six6, have\nbeen shown to play an important role in maturation timing. In this study, we\ninvestigated the expression of 16 genes involved in the regulation of m6A RNA\nmethylation in the hypothalamus of Atlantic salmon with different homozygous\ncombinations of late and early alleles for vgll3 and six6 genes. We found\ndifferential expression of ythdf2.2, an m6A reader promoting mRNA degradation,\nwith higher expression in six6*LL compared to other genotypes as well as in\nimmature compared to mature males. In addition, we found that the expression\nlevels of genes coding for an eraser, alkbh5, and for a reader, ythdf1, were\nhigher in the hypothalamus of females than in males across all the different\ngenotypes studied. However the total m6A levels between the whole hypothalamus\nof males and females were similar. Our results indicate a potential role of the\nm6A methylation process in sexual maturation of salmon, and provide the first\nevidence for such regulatory mechanism in the hypothalamus of any vertebrate\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19508v1"
    },
    {
        "title": "Explainable convolutional neural network model provides an alternative\n  genome-wide association perspective on mutations in SARS-CoV-2",
        "authors": [
            "Parisa Hatami",
            "Richard Annan",
            "Luis Urias Miranda",
            "Jane Gorman",
            "Mengjun Xie",
            "Letu Qingge",
            "Hong Qin"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Identifying mutations of SARS-CoV-2 strains associated with their phenotypic\nchanges is critical for pandemic prediction and prevention. We compared an\nexplainable convolutional neural network (CNN) approach and the traditional\ngenome-wide association study (GWAS) on the mutations associated with WHO\nlabels of SARS-CoV-2, a proxy for virulence phenotypes. We trained a CNN\nclassification model that can predict genomic sequences into Variants of\nConcern (VOCs) and then applied Shapley Additive explanations (SHAP) model to\nidentify mutations that are important for the correct predictions. For\ncomparison, we performed traditional GWAS to identify mutations associated with\nVOCs. Comparison of the two approaches shows that the explainable neural\nnetwork approach can more effectively reveal known nucleotide substitutions\nassociated with VOCs, such as those in the spike gene regions. Our results\nsuggest that explainable neural networks for genomic sequences offer a\npromising alternative to the traditional genome wide analysis approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.22452v2"
    },
    {
        "title": "Assessing Concordance between RNA-Seq and NanoString Technologies in\n  Ebola-Infected Nonhuman Primates Using Machine Learning",
        "authors": [
            "Mostafa Rezapour",
            "Aarthi Narayanan",
            "Wyatt H. Mowery",
            "Metin Nafi Gurcan"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This study evaluates the concordance between RNA sequencing (RNA-Seq) and\nNanoString technologies for gene expression analysis in non-human primates\n(NHPs) infected with Ebola virus (EBOV). We performed a detailed comparison of\nboth platforms, demonstrating a strong correlation between them, with Spearman\ncoefficients for 56 out of 62 samples ranging from 0.78 to 0.88, with a mean of\n0.83 and a median of 0.85. Bland-Altman analysis further confirmed high\nconsistency, with most measurements falling within 95% confidence limits. A\nmachine learning approach, using the Supervised Magnitude-Altitude Scoring\n(SMAS) method trained on NanoString data, identified OAS1 as a key marker for\ndistinguishing RT-qPCR positive from negative samples. Remarkably, when applied\nto RNA-Seq data, OAS1 also achieved 100% accuracy in differentiating infected\nfrom uninfected samples using logistic regression, demonstrating its robustness\nacross platforms. Further differential expression analysis identified 12 common\ngenes including ISG15, OAS1, IFI44, IFI27, IFIT2, IFIT3, IFI44L, MX1, MX2,\nOAS2, RSAD2, and OASL which demonstrated the highest levels of statistical\nsignificance and biological relevance across both platforms. Gene Ontology (GO)\nanalysis confirmed that these genes are directly involved in key immune and\nviral infection pathways, reinforcing their importance in EBOV infection. In\naddition, RNA-Seq uniquely identified genes such as CASP5, USP18, and DDX60,\nwhich play key roles in immune regulation and antiviral defense. This finding\nhighlights the broader detection capabilities of RNA-Seq and underscores the\ncomplementary strengths of both platforms in providing a comprehensive and\naccurate assessment of gene expression changes during Ebola virus infection.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.23433v1"
    },
    {
        "title": "LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
        "authors": [
            "Nicholas Jeon",
            "Xiaoning Qian",
            "Lamin SaidyKhan",
            "Paul de Figueiredo",
            "Byung-Jun Yoon"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.08073v1"
    },
    {
        "title": "Validating GWAS Findings through Reverse Engineering of Contingency\n  Tables",
        "authors": [
            "Yuzhou Jiang",
            "Erman Ayday"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Reproducibility in genome-wide association studies (GWAS) is crucial for\nensuring reliable genomic research outcomes. However, limited access to\noriginal genomic datasets (mainly due to privacy concerns) prevents researchers\nfrom reproducing experiments to validate results. In this paper, we propose a\nnovel method for GWAS reproducibility validation that detects unintentional\nerrors without the need for dataset sharing. Our approach leverages p-values\nfrom GWAS outcome reports to estimate contingency tables for each single\nnucleotide polymorphism (SNP) and calculates the Hamming distance between the\nminor allele frequencies (MAFs) derived from these contingency tables and\npublicly available phenotype-specific MAF data. By comparing the average\nHamming distance, we validate results that fall within a trusted threshold as\nreliable, while flagging those that exceed the threshold for further\ninspection. This approach not only allows researchers to validate the\ncorrectness of GWAS findings of other researchers, but it also provides a\nself-check step for the researchers before they publish their findings. We\nevaluate our approach using three real-life SNP datasets from OpenSNP, showing\nits ability to detect unintentional errors effectively, even when small errors\noccur, such as 1\\% of SNPs being reported incorrectly. This novel validation\ntechnique offers a promising solution to the GWAS reproducibility challenge,\nbalancing the need for rigorous validation with the imperative of protecting\nsensitive genomic data, thereby enhancing trust and accuracy in genetic\nresearch.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11169v1"
    },
    {
        "title": "Phenome-wide causal proteomics enhance systemic lupus erythematosus\n  flare prediction: A study in Asian populations",
        "authors": [
            "Liying Chen",
            "Ou Deng",
            "Ting Fang",
            "Mei Chen",
            "Xvfeng Zhang",
            "Ruichen Cong",
            "Dingqi Lu",
            "Runrun Zhang",
            "Qun Jin",
            "Xinchang Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Objective: Systemic lupus erythematosus (SLE) is a complex autoimmune disease\ncharacterized by unpredictable flares. This study aimed to develop a novel\nproteomics-based risk prediction model specifically for Asian SLE populations\nto enhance personalized disease management and early intervention. Methods: A\nlongitudinal cohort study was conducted over 48 weeks, including 139 SLE\npatients monitored every 12 weeks. Patients were classified into flare (n = 53)\nand non-flare (n = 86) groups. Baseline plasma samples underwent\ndata-independent acquisition (DIA) proteomics analysis, and phenome-wide\nMendelian randomization (PheWAS) was performed to evaluate causal relationships\nbetween proteins and clinical predictors. Logistic regression (LR) and random\nforest (RF) models were used to integrate proteomic and clinical data for flare\nrisk prediction. Results: Five proteins (SAA1, B4GALT5, GIT2, NAA15, and RPIA)\nwere significantly associated with SLE Disease Activity Index-2K (SLEDAI-2K)\nscores and 1-year flare risk, implicating key pathways such as B-cell receptor\nsignaling and platelet degranulation. SAA1 demonstrated causal effects on\nflare-related clinical markers, including hemoglobin and red blood cell counts.\nA combined model integrating clinical and proteomic data achieved the highest\npredictive accuracy (AUC = 0.769), surpassing individual models. SAA1 was\nhighlighted as a priority biomarker for rapid flare discrimination. Conclusion:\nThe integration of proteomic and clinical data significantly improves flare\nprediction in Asian SLE patients. The identification of key proteins and their\ncausal relationships with flare-related clinical markers provides valuable\ninsights for proactive SLE management and personalized therapeutic approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.11915v1"
    },
    {
        "title": "Active learning for efficient discovery of optimal gene combinations in\n  the combinatorial perturbation space",
        "authors": [
            "Jason Qin",
            "Hans-Hermann Wessels",
            "Carlos Fernandez-Granda",
            "Yuhan Hao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The advancement of novel combinatorial CRISPR screening technologies enables\nthe identification of synergistic gene combinations on a large scale. This is\ncrucial for developing novel and effective combination therapies, but the\ncombinatorial space makes exhaustive experimentation infeasible. We introduce\nNAIAD, an active learning framework that efficiently discovers optimal gene\npairs capable of driving cells toward desired cellular phenotypes. NAIAD\nleverages single-gene perturbation effects and adaptive gene embeddings that\nscale with the training data size, mitigating overfitting in small-sample\nlearning while capturing complex gene interactions as more data is collected.\nEvaluated on four CRISPR combinatorial perturbation datasets totaling over\n350,000 genetic interactions, NAIAD, trained on small datasets, outperforms\nexisting models by up to 40\\% relative to the second-best. NAIAD's\nrecommendation system prioritizes gene pairs with the maximum predicted\neffects, resulting in the highest marginal gain in each AI-experiment round and\naccelerating discovery with fewer CRISPR experimental iterations. Our NAIAD\nframework (https://github.com/NeptuneBio/NAIAD) improves the identification of\nnovel, effective gene combinations, enabling more efficient CRISPR library\ndesign and offering promising applications in genomics research and therapeutic\ndevelopment.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.12010v2"
    },
    {
        "title": "Leveraging Gene Expression Data and Explainable Machine Learning for\n  Enhanced Early Detection of Type 2 Diabetes",
        "authors": [
            "Aurora Lithe Roy",
            "Md Kamrul Siam",
            "Nuzhat Noor Islam Prova",
            "Sumaiya Jahan",
            "Abdullah Al Maruf"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Diabetes, particularly Type 2 diabetes (T2D), poses a substantial global\nhealth burden, compounded by its associated complications such as\ncardiovascular diseases, kidney failure, and vision impairment. Early detection\nof T2D is critical for improving healthcare outcomes and optimizing resource\nallocation. In this study, we address the gap in early T2D detection by\nleveraging machine learning (ML) techniques on gene expression data obtained\nfrom T2D patients. Our primary objective was to enhance the accuracy of early\nT2D detection through advanced ML methodologies and increase the model's\ntrustworthiness using the explainable artificial intelligence (XAI) technique.\nAnalyzing the biological mechanisms underlying T2D through gene expression\ndatasets represents a novel research frontier, relatively less explored in\nprevious studies. While numerous investigations have focused on utilizing\nclinical and demographic data for T2D prediction, the integration of molecular\ninsights from gene expression datasets offers a unique and promising avenue for\nunderstanding the pathophysiology of the disease. By employing six ML\nclassifiers on data sourced from NCBI's Gene Expression Omnibus (GEO), we\nobserved promising performance across all models. Notably, the XGBoost\nclassifier exhibited the highest accuracy, achieving 97%. Our study addresses a\nnotable gap in early T2D detection methodologies, emphasizing the importance of\nleveraging gene expression data and advanced ML techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.14471v1"
    },
    {
        "title": "Deciphering genomic codes using advanced NLP techniques: a scoping\n  review",
        "authors": [
            "Shuyan Cheng",
            "Yishu Wei",
            "Yiliang Zhou",
            "Zihan Xu",
            "Drew N Wright",
            "Jinze Liu",
            "Yifan Peng"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Objectives: The vast and complex nature of human genomic sequencing data\npresents challenges for effective analysis. This review aims to investigate the\napplication of Natural Language Processing (NLP) techniques, particularly Large\nLanguage Models (LLMs) and transformer architectures, in deciphering genomic\ncodes, focusing on tokenization, transformer models, and regulatory annotation\nprediction. The goal of this review is to assess data and model accessibility\nin the most recent literature, gaining a better understanding of the existing\ncapabilities and constraints of these tools in processing genomic sequencing\ndata.\n  Methods: Following Preferred Reporting Items for Systematic Reviews and\nMeta-Analyses (PRISMA) guidelines, our scoping review was conducted across\nPubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library.\nStudies were included if they focused on NLP methodologies applied to genomic\nsequencing data analysis, without restrictions on publication date or article\ntype.\n  Results: A total of 26 studies published between 2021 and April 2024 were\nselected for review. The review highlights that tokenization and transformer\nmodels enhance the processing and understanding of genomic data, with\napplications in predicting regulatory annotations like transcription-factor\nbinding sites and chromatin accessibility.\n  Discussion: The application of NLP and LLMs to genomic sequencing data\ninterpretation is a promising field that can help streamline the processing of\nlarge-scale genomic data while also providing a better understanding of its\ncomplex structures. It has the potential to drive advancements in personalized\nmedicine by offering more efficient and scalable solutions for genomic\nanalysis. Further research is also needed to discuss and overcome current\nlimitations, enhancing model transparency and applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.16084v1"
    },
    {
        "title": "Microbial Mat Metagenomes from Waikite Valley, Aotearoa New Zealand",
        "authors": [
            "Beatrice Tauer",
            "Elizabeth Trembath-Reichert",
            "L. M. Ward"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The rise of complex multicellular ecosystems Neoproterozoic time was preceded\nby a microbial Proterozoic biosphere, where productivity may have been largely\nrestricted to microbial mats made up of bacteria including oxygenic\nphotosynthetic Cyanobacteria, anoxygenic phototrophs, and heterotrophs. In\nmodern environments, analogous microbial mats can be found in restricted\nenvironments such as carbonate tidal flats and terrestrial hot springs. Here,\nwe report metagenomic sequence data from an analog in the hot springs of\nWaikite Valley, Aotearoa New Zealand, where carbon-rich, slightly-alkaline\ngeothermal waters support diverse phototrophic microbial mats.\n  The Waikite Valley hot spring in the Taupo Volcanic Zone of Aotearoa New\nZealand was sampled in duplicate at 8 points along a temperature gradient\ntransect of the outflow, from ~62 C (near the source) to ~37 C (~100 meters\ndownstream). ~686 Gb of shotgun metagenomic sequence data was generated by\nIllumina Novaseq. Each sample was assembled using SPAdes, followed by binning\nof metagenome-assembled genomes (MAGs) by MetaBAT. These data are useful for\nthe genomic analysis of novel phototrophic bacteria, as well as for ecological\ncomparisons between thermophilic communities with varying temperatures but\notherwise similar conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.01649v1"
    },
    {
        "title": "Deep Learning in Single-Cell and Spatial Transcriptomics Data Analysis:\n  Advances and Challenges from a Data Science Perspective",
        "authors": [
            "Shuang Ge",
            "Shuqing Sun",
            "Huan Xu",
            "Qiang Cheng",
            "Zhixiang Ren"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The development of single-cell and spatial transcriptomics has revolutionized\nour capacity to investigate cellular properties, functions, and interactions in\nboth cellular and spatial contexts. However, the analysis of single-cell and\nspatial omics data remains challenging. First, single-cell sequencing data are\nhigh-dimensional and sparse, often contaminated by noise and uncertainty,\nobscuring the underlying biological signals. Second, these data often encompass\nmultiple modalities, including gene expression, epigenetic modifications, and\nspatial locations. Integrating these diverse data modalities is crucial for\nenhancing prediction accuracy and biological interpretability. Third, while the\nscale of single-cell sequencing has expanded to millions of cells, high-quality\nannotated datasets are still limited. Fourth, the complex correlations of\nbiological tissues make it difficult to accurately reconstruct cellular states\nand spatial contexts. Traditional feature engineering-based analysis methods\nstruggle to deal with the various challenges presented by intricate biological\nnetworks. Deep learning has emerged as a powerful tool capable of handling\nhigh-dimensional complex data and automatically identifying meaningful\npatterns, offering significant promise in addressing these challenges. This\nreview systematically analyzes these challenges and discusses related deep\nlearning approaches. Moreover, we have curated 21 datasets from 9 benchmarks,\nencompassing 58 computational methods, and evaluated their performance on the\nrespective modeling tasks. Finally, we highlight three areas for future\ndevelopment from a technical, dataset, and application perspective. This work\nwill serve as a valuable resource for understanding how deep learning can be\neffectively utilized in single-cell and spatial transcriptomics analyses, while\ninspiring novel approaches to address emerging challenges.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.03614v2"
    },
    {
        "title": "A Misclassification Network-Based Method for Comparative Genomic\n  Analysis",
        "authors": [
            "Wan He",
            "Tina Eliassi-Rad",
            "Samuel V. Scarpino"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Classifying genome sequences based on metadata has been an active area of\nresearch in comparative genomics for decades with many important applications\nacross the life sciences. Established methods for classifying genomes can be\nbroadly grouped into sequence alignment-based and alignment-free models.\nConventional alignment-based models rely on genome similarity measures\ncalculated based on local sequence alignments or consistent ordering among\nsequences. However, such methods are computationally expensive when dealing\nwith large ensembles of even moderately sized genomes. In contrast,\nalignment-free (AF) approaches measure genome similarity based on summary\nstatistics in an unsupervised setting and are efficient enough to analyze large\ndatasets. However, both alignment-based and AF methods typically assume fixed\nscoring rubrics that lack the flexibility to assign varying importance to\ndifferent parts of the sequences based on prior knowledge. In this study, we\nintegrate AI and network science approaches to develop a comparative genomic\nanalysis framework that addresses these limitations. Our approach, termed the\nGenome Misclassification Network Analysis (GMNA), simultaneously leverages\nmisclassified instances, a learned scoring rubric, and label information to\nclassify genomes based on associated metadata and better understand potential\ndrivers of misclassification. We evaluate the utility of the GMNA using Naive\nBayes and convolutional neural network models, supplemented by additional\nexperiments with transformer-based models, to construct SARS-CoV-2 sampling\nlocation classifiers using over 500,000 viral genome sequences and study the\nresulting network of misclassifications. We demonstrate the global health\npotential of the GMNA by leveraging the SARS-CoV-2 genome misclassification\nnetworks to investigate the role human mobility played in structuring\ngeographic clustering of SARS-CoV-2.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.07051v3"
    },
    {
        "title": "DLSOM: A Deep learning-based strategy for liver cancer subtyping",
        "authors": [
            "Fabio Zamio"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Liver cancer is a leading cause of cancer-related mortality worldwide, with\nits high genetic heterogeneity complicating diagnosis and treatment. This study\nintroduces DLSOM, a deep learning framework utilizing stacked autoencoders to\nanalyze the complete somatic mutation landscape of 1,139 liver cancer samples,\ncovering 20,356 protein-coding genes. By transforming high-dimensional mutation\ndata into three low-dimensional features, DLSOM enables robust clustering and\nidentifies five distinct liver cancer subtypes with unique mutational,\nfunctional, and biological profiles. Subtypes SC1 and SC2 exhibit higher\nmutational loads, while SC3 has the lowest, reflecting mutational\nheterogeneity. Novel and COSMIC-associated mutational signatures reveal\nsubtype-specific molecular mechanisms, including links to hypermutation and\nchemotherapy resistance. Functional analyses further highlight the biological\nrelevance of each subtype. This comprehensive framework advances precision\nmedicine in liver cancer by enabling the development of subtype-specific\ndiagnostics, biomarkers, and therapies, showcasing the potential of deep\nlearning in addressing cancer complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12214v1"
    },
    {
        "title": "Model Decides How to Tokenize: Adaptive DNA Sequence Tokenization with\n  MxDNA",
        "authors": [
            "Lifeng Qiao",
            "Peng Ye",
            "Yuchen Ren",
            "Weiqiang Bai",
            "Chaoqi Liang",
            "Xinzhu Ma",
            "Nanqing Dong",
            "Wanli Ouyang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Foundation models have made significant strides in understanding the genomic\nlanguage of DNA sequences. However, previous models typically adopt the\ntokenization methods designed for natural language, which are unsuitable for\nDNA sequences due to their unique characteristics. In addition, the optimal\napproach to tokenize DNA remains largely under-explored, and may not be\nintuitively understood by humans even if discovered. To address these\nchallenges, we introduce MxDNA, a novel framework where the model autonomously\nlearns an effective DNA tokenization strategy through gradient decent. MxDNA\nemploys a sparse Mixture of Convolution Experts coupled with a deformable\nconvolution to model the tokenization process, with the discontinuous,\noverlapping, and ambiguous nature of meaningful genomic segments explicitly\nconsidered. On Nucleotide Transformer Benchmarks and Genomic Benchmarks, MxDNA\ndemonstrates superior performance to existing methods with less pretraining\ndata and time, highlighting its effectiveness. Finally, we show that MxDNA\nlearns unique tokenization strategy distinct to those of previous methods and\ncaptures genomic functionalities at a token level during self-supervised\npretraining. Our MxDNA aims to provide a new perspective on DNA tokenization,\npotentially offering broad applications in various domains and yielding\nprofound insights.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.13716v1"
    },
    {
        "title": "A CNN Approach to Polygenic Risk Prediction of Kidney Stone Formation",
        "authors": [
            "Amr Salem",
            "Anirban Mondal"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Kidney stones are a common and debilitating health issue, and genetic factors\nplay a crucial role in determining susceptibility. While Genome-Wide\nAssociation Studies (GWAS) have identified numerous single nucleotide\npolymorphisms (SNPs) linked to kidney stone risk, translating these findings\ninto effective clinical tools remains a challenge. In this study, we explore\nthe potential of deep learning techniques, particularly Convolutional Neural\nNetworks (CNNs), to enhance Polygenic Risk Score (PRS) models for predicting\nkidney stone susceptibility. Using a curated dataset of kidney stone-associated\nSNPs from a recent GWAS, we apply CNNs to model non-linear genetic interactions\nand improve prediction accuracy. Our approach includes SNP selection, genotype\nfiltering, and model training using a dataset of 560 individuals, divided into\ntraining and testing subsets. We compare our CNN-based model with traditional\nmachine learning models, including logistic regression, random forest, and\nsupport vector machines, demonstrating that the CNN outperforms these models in\nterms of classification accuracy and ROC-AUC. The proposed model achieved a\nvalidation accuracy of 62%, with an ROC-AUC of 0.68, suggesting its potential\nfor improving genetic-based risk prediction for kidney stones. This study\ncontributes to the growing field of genomics-driven precision medicine and\nhighlights the promise of deep learning in enhancing PRS models for complex\ndiseases.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.17559v1"
    },
    {
        "title": "Revealing the Shape of Genome Space via K-mer Topology",
        "authors": [
            "Yuta Hozumi",
            "Guo-Wei Wei"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Despite decades of effort, understanding the shape of genome space in biology\nremains a challenge due to the similarity, variability, diversity, and\nplasticity of evolutionary relationships among species, genes, or other\nbiological entities. We present a k-mer topology method, the first of its kind,\nto delineate the shape of the genome space. K-mer topology examines the\ntopological persistence and the evolution of the homotopic shape of the\nsequences of k nucleotides in species, organisms, and genes using persistent\nLaplacians, a new multiscale combinatorial approach. We also propose a\ntopological genetic distance between species by their topological invariants\nand non-harmonic spectra over scales. This new metric defines the topological\nphylogenetic trees of genomes, facilitating species classification and\nclustering. K-mer topology substantially outperforms state-of-the-art methods\non a variety of benchmark datasets, including mammalian mitochondrial genomes,\nRhinovirus, SARS-CoV-2 variants, Ebola virus, Hepatitis E virus, Influenza\nhemagglutinin genes, and whole bacterial genomes. K-mer topology reveals the\nintrinsic shapes of the genome space and can be directly applied to the\nrational design of viral vaccines.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.20202v1"
    },
    {
        "title": "Selecting ChIP-Seq Normalization Methods from the Perspective of their\n  Technical Conditions",
        "authors": [
            "Sara Colando",
            "Danae Schulz",
            "Johanna Hardin"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Chromatin immunoprecipitation, followed by high throughput sequencing\nprovides vital insights into locations on the genome with differential DNA\noccupancy between experimental states. However, since ChIP-Seq data is\ncollected experimentally, it must be normalized between samples in order to\nproperly assess which genomic regions have differential DNA occupancy via\ndifferential binding analysis. While between-sample normalization is a crucial\nfor downstream differential binding analysis, the technical conditions\nunderlying between-sample ChIP-Seq normalization methods have yet to be\nspecifically examined. We identify three important technical conditions\nunderlying ChIP-Seq between-sample normalization methods: symmetric\ndifferential DNA occupancy, equal total DNA occupancy, and equal background\nbinding across experimental states. We categorize popular ChIP-Seq\nnormalization methods based on their technical conditions and simulate ChIP-Seq\nread count data to exemplify the importance of satisfying a normalization\nmethod's technical conditions to downstream differential binding analysis. We\nassess the similarity between normalization methods in experimental CUT&RUN\ndata to externally verify our simulation findings. Our simulation and\nexperimental results underscore that satisfying the technical conditions\nunderlying the selected between-sample normalization methods is crucial to\nconducting biologically meaningful downstream differential binding analysis. We\nsuggest that researchers use their understanding of the ChIP-Seq experiment at\nhand to guide their choice of between-sample normalization method when\npossible. Researchers could use the intersection of the differentially bound\npeaksets derived from different normalization methods to determine which\nregions have differential DNA occupancy between experimental states when there\nis uncertainty about which technical conditions are met.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02028v1"
    },
    {
        "title": "iTARGET: Interpretable Tailored Age Regression for Grouped Epigenetic\n  Traits",
        "authors": [
            "Zipeng Wu",
            "Daniel Herring",
            "Fabian Spill",
            "James Andrews"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Accurately predicting chronological age from DNA methylation patterns is\ncrucial for advancing biological age estimation. However, this task is made\nchallenging by Epigenetic Correlation Drift (ECD) and Heterogeneity Among CpGs\n(HAC), which reflect the dynamic relationship between methylation and age\nacross different life stages. To address these issues, we propose a novel\ntwo-phase algorithm. The first phase employs similarity searching to cluster\nmethylation profiles by age group, while the second phase uses Explainable\nBoosting Machines (EBM) for precise, group-specific prediction. Our method not\nonly improves prediction accuracy but also reveals key age-related CpG sites,\ndetects age-specific changes in aging rates, and identifies pairwise\ninteractions between CpG sites. Experimental results show that our approach\noutperforms traditional epigenetic clocks and machine learning models, offering\na more accurate and interpretable solution for biological age estimation with\nsignificant implications for aging research.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02401v1"
    },
    {
        "title": "Knowledge-Guided Biomarker Identification for Label-Free Single-Cell\n  RNA-Seq Data: A Reinforcement Learning Perspective",
        "authors": [
            "Meng Xiao",
            "Weiliang Zhang",
            "Xiaohan Huang",
            "Hengshu Zhu",
            "Min Wu",
            "Xiaoli Li",
            "Yuanchun Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Gene panel selection aims to identify the most informative genomic biomarkers\nin label-free genomic datasets. Traditional approaches, which rely on domain\nexpertise, embedded machine learning models, or heuristic-based iterative\noptimization, often introduce biases and inefficiencies, potentially obscuring\ncritical biological signals. To address these challenges, we present an\niterative gene panel selection strategy that harnesses ensemble knowledge from\nexisting gene selection algorithms to establish preliminary boundaries or prior\nknowledge, which guide the initial search space. Subsequently, we incorporate\nreinforcement learning through a reward function shaped by expert behavior,\nenabling dynamic refinement and targeted selection of gene panels. This\nintegration mitigates biases stemming from initial boundaries while\ncapitalizing on RL's stochastic adaptability. Comprehensive comparative\nexperiments, case studies, and downstream analyses demonstrate the\neffectiveness of our method, highlighting its improved precision and efficiency\nfor label-free biomarker discovery. Our results underscore the potential of\nthis approach to advance single-cell genomics data analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04718v1"
    },
    {
        "title": "Multi-megabase scale genome interpretation with genetic language models",
        "authors": [
            "Frederik Träuble",
            "Lachlan Stuart",
            "Andreas Georgiou",
            "Pascal Notin",
            "Arash Mehrjou",
            "Ron Schwessinger",
            "Mathieu Chevalley",
            "Kim Branson",
            "Bernhard Schölkopf",
            "Cornelia van Duijn",
            "Debora Marks",
            "Patrick Schwab"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Understanding how molecular changes caused by genetic variation drive disease\nrisk is crucial for deciphering disease mechanisms. However, interpreting\ngenome sequences is challenging because of the vast size of the human genome,\nand because its consequences manifest across a wide range of cells, tissues and\nscales -- spanning from molecular to whole organism level. Here, we present\nPhenformer, a multi-scale genetic language model that learns to generate\nmechanistic hypotheses as to how differences in genome sequence lead to\ndisease-relevant changes in expression across cell types and tissues directly\nfrom DNA sequences of up to 88 million base pairs. Using whole genome\nsequencing data from more than 150 000 individuals, we show that Phenformer\ngenerates mechanistic hypotheses about disease-relevant cell and tissue types\nthat match literature better than existing state-of-the-art methods, while\nusing only sequence data. Furthermore, disease risk predictors enriched by\nPhenformer show improved prediction performance and generalisation to diverse\npopulations. Accurate multi-megabase scale interpretation of whole genomes\nwithout additional experimental data enables both a deeper understanding of\nmolecular mechanisms involved in disease and improved disease risk prediction\nat the level of individuals.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.07737v1"
    },
    {
        "title": "Adaptive walks in a gene network model of morphogenesis: insights into\n  the Cambrian explosion",
        "authors": [
            "Ricard V. Sole",
            "Pau Fernandez",
            "Stuart A. Kauffman"
        ],
        "category": "q-bio.GN",
        "published_year": "2003",
        "summary": "  The emergence of complex patterns of organization close to the Cambrian\nboundary is known to have happened over a (geologically) short period of time.\nIt involved the rapid diversification of body plans and stands as one of the\nmajor transitions in evolution. How it took place is a controversial issue.\nHere we explore this problem by considering a simple model of pattern formation\nin multicellular organisms. By modeling gene network-based morphogenesis and\nits evolution through adaptive walks, we explore the question of how\ncombinatorial explosions might have been actually involved in the Cambrian\nevent. Here we show that a small amount of genetic complexity including both\ngene regulation and cell-cell signaling allows one to generate an extraordinary\nrepertoire of stable spatial patterns of gene expression compatible with\nobserved anteroposterior patterns in early development of metazoans. The\nconsequences for the understanding of the tempo and mode of the Cambrian event\nare outlined.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0311013v1"
    },
    {
        "title": "Parametric Inference for Biological Sequence Analysis",
        "authors": [
            "Lior Pachter",
            "Bernd Sturmfels"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  One of the major successes in computational biology has been the unification,\nusing the graphical model formalism, of a multitude of algorithms for\nannotating and comparing biological sequences. Graphical models that have been\napplied towards these problems include hidden Markov models for annotation,\ntree models for phylogenetics, and pair hidden Markov models for alignment. A\nsingle algorithm, the sum-product algorithm, solves many of the inference\nproblems associated with different statistical models. This paper introduces\nthe \\emph{polytope propagation algorithm} for computing the Newton polytope of\nan observation from a graphical model. This algorithm is a geometric version of\nthe sum-product algorithm and is used to analyze the parametric behavior of\nmaximum a posteriori inference calculations for graphical models.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0401033v1"
    },
    {
        "title": "Sublinear Growth of Information in DNA Sequences",
        "authors": [
            "Giulia Menconi"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  We introduce a novel method to analyse complete genomes and recognise some\ndistinctive features by means of an adaptive compression algorithm, which is\nnot DNA-oriented. We study the Information Content as a function of the number\nof symbols encoded by the algorithm. Preliminar results are shown concerning\nregions having a sublinear type of information growth, which is strictly\nconnected to the presence of highly repetitive subregions that might be\nsupposed to have a regulatory function within the genome.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0402046v1"
    },
    {
        "title": "The Importance of DNA Repair in Tumor Suppression",
        "authors": [
            "Yisroel Brumer",
            "Eugene I. Shakhnovich"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  The transition from a normal to cancerous cell requires a number of highly\nspecific mutations that affect cell cycle regulation, apoptosis,\ndifferentiation, and many other cell functions. One hallmark of cancerous\ngenomes is genomic instability, with mutation rates far greater than those of\nnormal cells. In microsatellite instability (MIN tumors), these are often\ncaused by damage to mismatch repair genes, allowing further mutation of the\ngenome and tumor progression. These mutation rates may lie near the error\ncatastrophe found in the quasispecies model of adaptive RNA genomes, suggesting\nthat further increasing mutation rates will destroy cancerous genomes. However,\nrecent results have demonstrated that DNA genomes exhibit an error threshold at\nmutation rates far lower than their conservative counterparts. Furthermore,\nwhile the maximum viable mutation rate in conservative systems increases\nindefinitely with increasing master sequence fitness, the semiconservative\nthreshold plateaus at a relatively low value. This implies a paradox, wherein\ninaccessible mutation rates are found in viable tumor cells. In this paper, we\naddress this paradox, demonstrating an isomorphism between the conservatively\nreplicating (RNA) quasispecies model and the semiconservative (DNA) model with\npost-methylation DNA repair mechanisms impaired. Thus, as DNA repair becomes\ninactivated, the maximum viable mutation rate increases smoothly to that of a\nconservatively replicating system on a transformed landscape, with an upper\nbound that is dependent on replication rates. We postulate that inactivation of\npost-methylation repair mechanisms are fundamental to the progression of a\ntumor cell and hence these mechanisms act as a method for prevention and\ndestruction of cancerous genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0403018v2"
    },
    {
        "title": "Exact Asymptotic Results for a Model of Sequence Alignment",
        "authors": [
            "Satya N. Majumdar",
            "Sergei Nechaev"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Finding analytically the statistics of the longest common subsequence (LCS)\nof a pair of random sequences drawn from c alphabets is a challenging problem\nin computational evolutionary biology. We present exact asymptotic results for\nthe distribution of the LCS in a simpler, yet nontrivial, variant of the\noriginal model called the Bernoulli matching (BM) model which reduces to the\noriginal model in the large c limit. We show that in the BM model, for all c,\nthe distribution of the asymptotic length of the LCS, suitably scaled, is\nidentical to the Tracy-Widom distribution of the largest eigenvalue of a random\nmatrix whose entries are drawn from a Gaussian unitary ensemble. In particular,\nin the large c limit, this provides an exact expression for the asymptotic\nlength distribution in the original LCS problem.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0410012v1"
    },
    {
        "title": "Four basic symmetry types in the universal 7-cluster structure of 143\n  complete bacterial genomic sequences",
        "authors": [
            "A. N. Gorban",
            "T. G. Popova",
            "A. Yu. Zinovyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  Coding information is the main source of heterogeneity (non-randomness) in\nthe sequences of bacterial genomes. This information can be naturally modeled\nby analysing cluster structures in the \"in-phase\" triplet distributions of\nrelatively short genomic fragments (200-400bp). We found a universal 7-cluster\nstructure in bacterial genomic sequences and explained its properties. We show\nthat codon usage of bacterial genomes is a multi-linear function of their\ngenomic G+C-content with high accuracy. Based on the analysis of 143 completely\nsequenced bacterial genomes available in Genbank in August 2004, we show that\nthere are four \"pure\" types of the 7-cluster structure observed. All 143\ncluster animated 3D-scatters are collected in a database and is made available\non our web-site: http://www.ihes.fr/~zinovyev/7clusters The finding can be\nreadily introduced into any software for gene prediction, sequence alignment or\nbacterial genomes classification.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0410033v1"
    },
    {
        "title": "A Field Approach to 3D Gene Expression Pattern Characterization",
        "authors": [
            "L. da F. Costa",
            "B. A. N. Travencolo",
            "A. Azeredo",
            "M. E. Beletti",
            "M. E. Beletti",
            "D. Rasskin-Gutman",
            "G. Sternik",
            "J. C. I. Belmonte",
            "G. B. Mueller"
        ],
        "category": "q-bio.GN",
        "published_year": "2004",
        "summary": "  We present a vector field method for obtaining the spatial organization of 3D\npatterns of gene expression based on gradients and lines of force obtained by\nnumerical integration. The convergence of these lines of force in local maxima\nare centers of gene expression, providing a natural and powerful framework to\ncharacterize the organization and dynamics of biological structures. We apply\nthis novel methodology to analyze the expression pattern of the Enhanced Green\nFluorescent Protein (EGFP) driven by the promoter of light chain myosin II\nduring zebrafish heart formation.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0411020v1"
    },
    {
        "title": "Binding properties and evolution of homodimers in protein-protein\n  interaction networks",
        "authors": [
            "Iaroslav Ispolatov",
            "Anton Yuryev",
            "Ilya Mazo",
            "Sergei Maslov"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  We demonstrate that Protein-Protein Interaction (PPI) networks in several\neucaryotic organisms contain significantly more self-interacting proteins than\nexpected if such homodimers randomly appeared in the course of the evolution.\nWe also show that on average homodimers have twice as many interaction partners\nthan non-self-interacting proteins. More specifically the likelihood of a\nprotein to physically interact with itself was found to be proportional to the\ntotal number of its binding partners. These properties of dimers are are in\nagreement with a phenomenological model in which individual proteins differ\nfrom each other by the degree of their ``stickiness'' or general propensity\ntowards interaction with other proteins including oneself. A duplication of\nself-interacting proteins creates a pair of paralogous proteins interacting\nwith each other. We show that such pairs occur more frequently than could be\nexplained by pure chance alone. Similar to homodimers, proteins involved in\nheterodimers with their paralogs on average have twice as many interacting\npartners than the rest of the network. The likelihood of a pair of paralogous\nproteins to interact with each other was also shown to decrease with their\nsequence similarity. This all points to the conclusion that most of\ninteractions between paralogs are inherited from ancestral homodimeric\nproteins, rather than established de novo after the duplication. We finally\ndiscuss possible implications of our empirical observations from functional and\nevolutionary standpoints.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0501004v1"
    },
    {
        "title": "Brush Effects on DNA Chips: Thermodynamics, Kinetics and Design\n  Guidlines",
        "authors": [
            "A. Halperin",
            "A. Buhot",
            "E. B. Zhulina"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  In biology experiments, oligonucleotide microarrays are contacted with a\nsolution of long nucleic acid (NA) targets. The hybridized probes thus carry\nlong tails. When the surface density of the oligonucleotide probes is high\nenough, the progress of hybridization leads to the formation of a\npolyelectrolyte brush due to mutual crowding of the NA tails. The free energy\npenalty associated with the brush modifies both the hybridization isotherms and\nthe rate equations: the attainable hybridization is lowered significantly as is\nthe hybridization rate. While the equilibrium hybridization fraction, $x_{eq}$,\nis low, the hybridization follows a Langmuir type isotherm, $x_{eq}/(1-x_{eq})\n= c_t K$ where $c_t$ is the target concentration and $K$ is the equilibrium\nconstant smaller than its bulk value by a factor $(n/N)^{2/5}$ due to wall\neffects where $n$ and $N$ denote the number of bases in the probe and the\ntarget. At higher $x_{eq}$, when the brush is formed, the leading correction is\n$x_{eq}/(1-x_{eq}) = c_t K \\exp [ - const' (x_{eq}^{2/3} - x_B^{2/3})]$ where\n$x_B$ corresponds to the onset of the brush regime. The denaturation rate\nconstant in the two regimes are identical. However, the hybridization rate\nconstant in the brush regime is lower, the leading correction being $\\exp [-\nconst' (x^{2/3} - x_B^{2/3})]$.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0504002v1"
    },
    {
        "title": "Bayesian Method for Disease QTL Detection and Mapping, using a Case and\n  Control Design and DNA Pooling",
        "authors": [
            "Toby Johnson"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  This paper describes a Bayesian statistical method for determining the\ngenetic basis of a complex genetic trait. The method uses a sample of unrelated\nindividuals classified into two groups, for example cases and controls. Each\ngroup is assumed to have been genotyped at a battery of marker loci using a\nlaboratory effort efficient technique called DNA pooling. The aim is to detect\nand map a quantitative trait locus (QTL) that is not one of the typed markers.\nThe method works by conducting an exact Bayesian analysis under a number of\nsimplifying population genetic assumptions that are somewhat unrealistic.\nDespite this, the method is shown to perform acceptably on datasets simulated\nunder a more realistic model, and furthermore is shown to outperform classical\nsingle point methods.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0507018v1"
    },
    {
        "title": "Complex Network Approach to Human Promoter Sequences",
        "authors": [
            "Huijie Yang",
            "Fangcui Zhao",
            "Binghong Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  Based upon the correlation matrix of the human promoter sequences, a complex\nnetwork is constructed to capture the principal relationships between these\npromoters. It is a complex network has the properties of the right-skewed\ndegree distribution and the clustering simultaneously, i.e., a hierarchical\nstructure. An eigenvector centrality (EC) based method is used to reconstruct\nthis hierarchical structure.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0508018v1"
    },
    {
        "title": "Parametric Alignment of Drosophila Genomes",
        "authors": [
            "Colin Dewey",
            "Peter Huggins",
            "Kevin Woods",
            "Bernd Sturmfels",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2005",
        "summary": "  The classic algorithms of Needleman--Wunsch and Smith--Waterman find a\nmaximum a posteriori probability alignment for a pair hidden Markov model\n(PHMM). In order to process large genomes that have undergone complex genome\nrearrangements, almost all existing whole genome alignment methods apply fast\nheuristics to divide genomes into small pieces which are suitable for\nNeedleman--Wunsch alignment. In these alignment methods, it is standard\npractice to fix the parameters and to produce a single alignment for subsequent\nanalysis by biologists.\n  Our main result is the construction of a whole genome parametric alignment of\nDrosophila melanogaster and Drosophila pseudoobscura. Parametric alignment\nresolves the issue of robustness to changes in parameters by finding all\noptimal alignments for all possible parameters in a PHMM. Our alignment draws\non existing heuristics for dividing whole genomes into small pieces for\nalignment, and it relies on advances we have made in computing convex polytopes\nthat allow us to parametrically align non-coding regions using biologically\nrealistic models. We demonstrate the utility of our parametric alignment for\nbiological inference by showing that cis-regulatory elements are more conserved\nbetween Drosophila melanogaster and Drosophila pseudoobscura than previously\nthought. We also show how whole genome parametric alignment can be used to\nquantitatively assess the dependence of branch length estimates on alignment\nparameters.\n  The alignment polytopes, software, and supplementary material can be\ndownloaded at http://bio.math.berkeley.edu/parametric/.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0512008v1"
    },
    {
        "title": "Holographic bound and protein linguistics",
        "authors": [
            "Dirson Jian Li",
            "Shengli Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  The holographic bound in physics constrains the complexity of life. The\nfinite storage capability of information in the observable universe requires\nthe protein linguistics in the evolution of life. We find that the evolution of\ngenetic code determines the variance of amino acid frequencies and genomic GC\ncontent among species. The elegant linguistic mechanism is confirmed by the\nexperimental observations based on all known entire proteomes.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.1169v1"
    },
    {
        "title": "Universal power law behaviors in genomic sequences and evolutionary\n  models",
        "authors": [
            "L. Martignetti",
            "M. Caselle"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We study the length distribution of a particular class of DNA sequences known\nas 5'UTR exons. These exons belong to the messanger RNA of protein coding\ngenes, but they are not coding (they are located upstream of the coding portion\nof the mRNA) and are thus less constrained from an evolutionary point of view.\nWe show that both in mouse and in human these exons show a very clean power law\ndecay in their length distribution and suggest a simple evolutionary model\nwhich may explain this finding. We conjecture that this power law behaviour\ncould indeed be a general feature of higher eukaryotes.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.2285v1"
    },
    {
        "title": "Point Mutations Effects on Charge Transport Properties of the\n  Tumor-Suppressor Gene p53",
        "authors": [
            "Chi-Tin Shih",
            "Stephan Roche",
            "Rudolf A. Römer"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  We report on a theoretical study of point mutations effects on charge\ntransfer properties in the DNA sequence of the tumor-suppressor p53 gene. On\nthe basis of effective single-strand or double-strand tight-binding models\nwhich simulate hole propagation along the DNA, a statistical analysis of charge\ntransmission modulations associated with all possible point mutations is\nperformed. We find that in contrast to non-cancerous mutations, mutation\nhotspots tend to result in significantly weaker {\\em changes of transmission\nproperties}. This suggests that charge transport could play a significant role\nfor DNA-repairing deficiency yielding carcinogenesis.\n",
        "pdf_link": "http://arxiv.org/pdf/0708.3181v1"
    },
    {
        "title": "Identifying statistical dependence in genomic sequences via mutual\n  information estimates",
        "authors": [
            "H. M. Aktulga",
            "I. Kontoyiannis",
            "L. A. Lyznik",
            "L. Szpankowski",
            "A. Y. Grama",
            "W. Szpankowski"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Questions of understanding and quantifying the representation and amount of\ninformation in organisms have become a central part of biological research, as\nthey potentially hold the key to fundamental advances. In this paper, we\ndemonstrate the use of information-theoretic tools for the task of identifying\nsegments of biomolecules (DNA or RNA) that are statistically correlated. We\ndevelop a precise and reliable methodology, based on the notion of mutual\ninformation, for finding and extracting statistical as well as structural\ndependencies. A simple threshold function is defined, and its use in\nquantifying the level of significance of dependencies between biological\nsegments is explored. These tools are used in two specific applications. First,\nfor the identification of correlations between different parts of the maize\nzmSRp32 gene. There, we find significant dependencies between the 5'\nuntranslated region in zmSRp32 and its alternatively spliced exons. This\nobservation may indicate the presence of as-yet unknown alternative splicing\nmechanisms or structural scaffolds. Second, using data from the FBI's Combined\nDNA Index System (CODIS), we demonstrate that our approach is particularly well\nsuited for the problem of discovering short tandem repeats, an application of\nimportance in genetic profiling.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.5190v1"
    },
    {
        "title": "Matrix genetics, part 3: the evolution of the genetic code from the\n  viewpoint of the genetic octave Yin-Yang-algebra",
        "authors": [
            "Sergey V. Petoukhov"
        ],
        "category": "q-bio.GN",
        "published_year": "2008",
        "summary": "  The set of known dialects of the genetic code (GC) is analyzed from the\nviewpoint of the genetic octave Yin-Yang-algebra. This algebra was described in\nthe previous author's publications. The algebra was discovered on the basis of\nstructural features of the GC in the matrix form of its presentation (\"matrix\ngenetics\"). The octave Yin-Yang-algebra is considered as the pre-code or as the\nmodel of the GC. From the viewpoint of this algebraic model, for example, the\nsets of 20 amino acids and of 64 triplets consist of sub-sets of \"male\",\n\"female\" and \"androgynous\" molecules, etc. This algebra permits to reveal\nhidden peculiarities of the structure and evolution of the GC and to propose\nthe conception of \"sexual\" relationships among genetic molecules. The first\nresults of the analysis of the GC systems from such algebraic viewpoint say\nabout the close connection between evolution of the GC and this algebra. They\ninclude 8 evolutionary rules of the dialects of the GC. The evolution of the GC\nis appeared as the struggle between male and female beginnings. The hypothesis\nabout new biophysical factor of \"sexual\" interactions among genetic molecules\nis put forward. The matrix forms of presentation of elements of the genetic\noctave Yin-Yang-algebra are connected with Hadamard matrices by means of the\nsimple U-algorithm. Hadamard matrices play a significant role in the theory of\nquantum computers, in particular. It gives new opportunities for possible\nunderstanding the GC systems as quantum computer systems. Revealed algebraic\nproperties of the GC permit to put forward the problem of algebraization of\nbioinformatics on the basis of the algebras of the GC. Our investigation is\nconnected with the question: what is life from the viewpoint of algebra? The\nalgebraic version of the origin of the GC is discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.4692v1"
    },
    {
        "title": "Needles in the Haystack: Identifying Individuals Present in Pooled\n  Genomic Data",
        "authors": [
            "Rosemary Braun",
            "William Rowe",
            "Carl Schaefer",
            "Jinghui Zhang",
            "Kenneth Buetow"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Recent publications have described and applied a novel metric that quantifies\nthe genetic distance of an individual with respect to two population samples,\nand have suggested that the metric makes it possible to infer the presence of\nan individual of known genotype in a sample for which only the marginal allele\nfrequencies are known. However, the assumptions, limitations, and utility of\nthis metric remained incompletely characterized. Here we present an exploration\nof the strengths and limitations of that method. In addition to analytical\ninvestigations of the underlying assumptions, we use both real and simulated\ngenotypes to test empirically the method's accuracy. The results reveal that,\nwhen used as a means by which to identify individuals as members of a\npopulation sample, the specificity is low in several circumstances. We find\nthat the misclassifications stem from violations of assumptions that are\ncrucial to the technique yet hard to control in practice, and we explore the\nfeasibility of several methods to improve the sensitivity. Additionally, we\nfind that the specificity may still be lower than expected even in ideal\ncircumstances. However, despite the metric's inadequacies for identifying the\npresence of an individual in a sample, our results suggest potential avenues\nfor future research on tuning this method to problems of ancestry inference or\ndisease prediction. By revealing both the strengths and limitations of the\nproposed method, we hope to elucidate situations in which this distance metric\nmay be used in an appropriate manner. We also discuss the implications of our\nfindings in forensics applications and in the protection of GWAS participant\nprivacy.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.1506v3"
    },
    {
        "title": "BOOST: A fast approach to detecting gene-gene interactions in\n  genome-wide case-control studies",
        "authors": [
            "Xiang Wan",
            "Can Yang",
            "Qiang Yang",
            "Hong Xue",
            "Xiaodan Fan",
            "Nelson L. S. Tang",
            "Weichuan Yu"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Gene-gene interactions have long been recognized to be fundamentally\nimportant to understand genetic causes of complex disease traits. At present,\nidentifying gene-gene interactions from genome-wide case-control studies is\ncomputationally and methodologically challenging. In this paper, we introduce a\nsimple but powerful method, named `BOolean Operation based Screening and\nTesting'(BOOST). To discover unknown gene-gene interactions that underlie\ncomplex diseases, BOOST allows examining all pairwise interactions in\ngenome-wide case-control studies in a remarkably fast manner. We have carried\nout interaction analyses on seven data sets from the Wellcome Trust Case\nControl Consortium (WTCCC). Each analysis took less than 60 hours on a standard\n3.0 GHz desktop with 4G memory running Windows XP system. The interaction\npatterns identified from the type 1 diabetes data set display significant\ndifference from those identified from the rheumatoid arthritis data set, while\nboth data sets share a very similar hit region in the WTCCC report. BOOST has\nalso identified many undiscovered interactions between genes in the major\nhistocompatibility complex (MHC) region in the type 1 diabetes data set. In the\ncoming era of large-scale interaction mapping in genome-wide case-control\nstudies, our method can serve as a computationally and statistically useful\ntool.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.5130v1"
    },
    {
        "title": "Microbial Life in a Liquid Asphalt Desert",
        "authors": [
            "Dirk Schulze-Makuch",
            "Shirin Haque",
            "Marina Resendes de Sousa Antonio",
            "Denzil Ali",
            "Riad Hosein",
            "Young C. Song",
            "Jinshu Yang",
            "Elena Zaikova",
            "Denise M. Beckles",
            "Edward Guinan",
            "Harry J. Lehto",
            "Steven J. Hallam"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  An active microbiota, reaching up to 10 E+7 cells/g, was found to inhabit a\nnaturally occurring asphalt lake characterized by low water activity and\nelevated temperature. Geochemical and molecular taxonomic approaches revealed\nnovel and deeply branching microbial assemblages mediating anaerobic\nhydrocarbon degradation, metal respiration and C1 utilization pathways. These\nresults open a window into the origin and adaptive evolution of microbial life\nwithin recalcitrant hydrocarbon matrices, and establish the site as a useful\nanalog for the liquid hydrocarbon environments on Saturn's moon Titan.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2047v2"
    },
    {
        "title": "Coverage statistics for sequence census methods",
        "authors": [
            "Steven N. Evans",
            "Valerie Hower",
            "Lior Pachter"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Background: We study the statistical properties of fragment coverage in\ngenome sequencing experiments. In an extension of the classic Lander-Waterman\nmodel, we consider the effect of the length distribution of fragments. We also\nintroduce the notion of the shape of a coverage function, which can be used to\ndetect abberations in coverage. The probability theory underlying these\nproblems is essential for constructing models of current high-throughput\nsequencing experiments, where both sample preparation protocols and sequencing\ntechnology particulars can affect fragment length distributions.\n  Results: We show that regardless of fragment length distribution and under\nthe mild assumption that fragment start sites are Poisson distributed, the\nfragments produced in a sequencing experiment can be viewed as resulting from a\ntwo-dimensional spatial Poisson process. We then study the jump skeleton of the\nthe coverage function, and show that the induced trees are Galton-Watson trees\nwhose parameters can be computed.\n  Conclusions: Our results extend standard analyses of shotgun sequencing that\nfocus on coverage statistics at individual sites, and provide a null model for\ndetecting deviations from random coverage in high-throughput sequence census\nbased experiments. By focusing on fragments, we are also led to a new approach\nfor visualizing sequencing data that should be of independent interest.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.5587v1"
    },
    {
        "title": "How to build a DNA search engine like Google?",
        "authors": [
            "Wang Liang",
            "Fang Bo"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  This paper proposed a new method to build the large scale DNA sequences\nsearch system based on web search engine technology. We give a very brief\nintroduction for the methods used in search engine first. Then how to build a\nDNA search system like Google is illustrated in detail. Since there is no local\nalignment process, this system is able to provide the ms level search services\nfor billions of DNA sequences in a typical server.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4114v4"
    },
    {
        "title": "Presymptomatic risk assessment for chronic non-communicable diseases",
        "authors": [
            "Badri Padhukasahasram",
            "Eran Halperin",
            "Jennifer Wessel",
            "Daryl Thomas",
            "Elana Silver",
            "Heather Trumbower",
            "Michele Cargill",
            "Dietrich Stephan"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The prevalence of common chronic non-communicable diseases (CNCDs) far\novershadows the prevalence of both monogenic and infectious diseases combined.\nAll CNCDs, also called complex genetic diseases, have a heritable genetic\ncomponent that can be used for pre-symptomatic risk assessment. Common single\nnucleotide polymorphisms (SNPs) that tag risk haplotypes across the genome\ncurrently account for a non-trivial portion of the germ-line genetic risk and\nwe will likely continue to identify the remaining missing heritability in the\nform of rare variants, copy number variants and epigenetic modifications. Here,\nwe describe a novel measure for calculating the lifetime risk of a disease,\ncalled the genetic composite index (GCI), and demonstrate its predictive value\nas a clinical classifier. The GCI only considers summary statistics of the\neffects of genetic variation and hence does not require the results of\nlarge-scale studies simultaneously assessing multiple risk factors. Combining\nGCI scores with environmental risk information provides an additional tool for\nclinical decision-making. The GCI can be populated with heritable risk\ninformation of any type, and thus represents a framework for CNCD\npre-symptomatic risk assessment that can be populated as additional risk\ninformation is identified through next-generation technologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4642v5"
    },
    {
        "title": "Limited Lifespan of Fragile Regions in Mammalian Evolution",
        "authors": [
            "Max A. Alekseyev",
            "Pavel A. Pevzner"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  An important question in genome evolution is whether there exist fragile\nregions (rearrangement hotspots) where chromosomal rearrangements are happening\nover and over again. Although nearly all recent studies supported the existence\nof fragile regions in mammalian genomes, the most comprehensive phylogenomic\nstudy of mammals (Ma et al. (2006) Genome Research 16, 1557-1565) raised some\ndoubts about their existence. We demonstrate that fragile regions are subject\nto a \"birth and death\" process, implying that fragility has limited\nevolutionary lifespan. This finding implies that fragile regions migrate to\ndifferent locations in different mammals, explaining why there exist only a few\nchromosomal breakpoints shared between different lineages. The birth and death\nof fragile regions phenomenon reinforces the hypothesis that rearrangements are\npromoted by matching segmental duplications and suggests putative locations of\nthe currently active fragile regions in the human genome.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.0200v1"
    },
    {
        "title": "Gene clusters reflecting macrodomain structure respond to nucleoid\n  perturbations",
        "authors": [
            "Vittore F. Scolari",
            "Bruno Bassetti",
            "Bianca Sclavi",
            "Marco Cosentino Lagomarsino"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Focusing on the DNA-bridging nucleoid proteins Fis and H-NS, and integrating\nseveral independent experimental and bioinformatic data sources, we investigate\nthe links between chromosomal spatial organization and global transcriptional\nregulation. By means of a novel multi-scale spatial aggregation analysis, we\nuncover the existence of contiguous clusters of nucleoid-perturbation sensitive\ngenes along the genome, whose expression is affected by a combination of\ntopological DNA state and nucleoid-shaping protein occupancy. The clusters\ncorrelate well with the macrodomain structure of the genome. The most\nsignificant of them lay symmetrically at the edges of the ter macrodomain and\ninvolve all of the flagellar and chemotaxis machinery, in addition to key\nregulators of biofilm formation, suggesting that the regulation of the physical\nstate of the chromosome by the nucleoid proteins plays an important role in\ncoordinating the transcriptional response leading to the switch between a\nmotile and a biofilm lifestyle.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.1280v1"
    },
    {
        "title": "Weighted genomic distance can hardly impose a bound on the proportion of\n  transpositions",
        "authors": [
            "Shuai Jiang",
            "Max A. Alekseyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Genomic distance between two genomes, i.e., the smallest number of genome\nrearrangements required to transform one genome into the other, is often used\nas a measure of evolutionary closeness of the genomes in comparative genomics\nstudies. However, in models that include rearrangements of significantly\ndifferent \"power\" such as reversals (that are \"weak\" and most frequent\nrearrangements) and transpositions (that are more \"powerful\" but rare), the\ngenomic distance typically corresponds to a transformation with a large\nproportion of transpositions, which is not biologically adequate.\n  Weighted genomic distance is a traditional approach to bounding the\nproportion of transpositions by assigning them a relative weight {\\alpha} > 1.\nA number of previous studies addressed the problem of computing weighted\ngenomic distance with {\\alpha} \\leq 2.\n  Employing the model of multi-break rearrangements on circular genomes, that\ncaptures both reversals (modelled as 2-breaks) and transpositions (modelled as\n3-breaks), we prove that for {\\alpha} \\in (1,2], a minimum-weight\ntransformation may entirely consist of transpositions, implying that the\ncorresponding weighted genomic distance does not actually achieve its purpose\nof bounding the proportion of transpositions. We further prove that for\n{\\alpha} \\in (1,2), the minimum-weight transformations do not depend on a\nparticular choice of {\\alpha} from this interval. We give a complete\ncharacterization of such transformations and show that they coincide with the\ntransformations that at the same time have the shortest length and make the\nsmallest number of breakages in the genomes.\n  Our results also provide a theoretical foundation for the empirical\nobservation that for {\\alpha} < 2, transpositions are favored over reversals in\nthe minimum-weight transformations.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.2422v1"
    },
    {
        "title": "Joint scaling laws in functional and evolutionary categories in\n  prokaryotic genomes",
        "authors": [
            "Jacopo Grilli",
            "Bruno Bassetti",
            "Sergei Maslov",
            "Marco Cosentino Lagomarsino"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  We propose and study a class-expansion/innovation/loss model of genome\nevolution taking into account biological roles of genes and their constituent\ndomains. In our model numbers of genes in different functional categories are\ncoupled to each other. For example, an increase in the number of metabolic\nenzymes in a genome is usually accompanied by addition of new transcription\nfactors regulating these enzymes. Such coupling can be thought of as a\nproportional \"recipe\" for genome composition of the type \"a spoonful of sugar\nfor each egg yolk\". The model jointly reproduces two known empirical laws: the\ndistribution of family sizes and the nonlinear scaling of the number of genes\nin certain functional categories (e.g. transcription factors) with genome size.\nIn addition, it allows us to derive a novel relation between the exponents\ncharacterising these two scaling laws, establishing a direct quantitative\nconnection between evolutionary and functional categories. It predicts that\nfunctional categories that grow faster-than-linearly with genome size to be\ncharacterised by flatter-than-average family size distributions. This relation\nis confirmed by our bioinformatics analysis of prokaryotic genomes. This proves\nthat the joint quantitative trends of functional and evolutionary classes can\nbe understood in terms of evolutionary growth with proportional recipes.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.5814v3"
    },
    {
        "title": "Inferring Disease and Gene Set Associations with Rank Coherence in\n  Networks",
        "authors": [
            "TaeHyun Hwang",
            "Wei Zhang",
            "Maoqiang Xie",
            "Rui Kuang"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  A computational challenge to validate the candidate disease genes identified\nin a high-throughput genomic study is to elucidate the associations between the\nset of candidate genes and disease phenotypes. The conventional gene set\nenrichment analysis often fails to reveal associations between disease\nphenotypes and the gene sets with a short list of poorly annotated genes,\nbecause the existing annotations of disease causative genes are incomplete. We\npropose a network-based computational approach called rcNet to discover the\nassociations between gene sets and disease phenotypes. Assuming coherent\nassociations between the genes ranked by their relevance to the query gene set,\nand the disease phenotypes ranked by their relevance to the hidden target\ndisease phenotypes of the query gene set, we formulate a learning framework\nmaximizing the rank coherence with respect to the known disease phenotype-gene\nassociations. An efficient algorithm coupling ridge regression with label\npropagation, and two variants are introduced to find the optimal solution of\nthe framework. We evaluated the rcNet algorithms and existing baseline methods\nwith both leave-one-out cross-validation and a task of predicting recently\ndiscovered disease-gene associations in OMIM. The experiments demonstrated that\nthe rcNet algorithms achieved the best overall rankings compared to the\nbaselines. To further validate the reproducibility of the performance, we\napplied the algorithms to identify the target diseases of novel candidate\ndisease genes obtained from recent studies of GWAS, DNA copy number variation\nanalysis, and gene expression profiling. The algorithms ranked the target\ndisease of the candidate genes at the top of the rank list in many cases across\nall the three case studies. The rcNet algorithms are available as a webtool for\ndisease and gene set association analysis at\nhttp://compbio.cs.umn.edu/dgsa_rcNet.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.3919v1"
    },
    {
        "title": "Reconstructing Isoform Graphs from RNA-Seq data",
        "authors": [
            "Stefano Beretta",
            "Paola Bonizzoni",
            "Gianluca Della Vedova",
            "Raffaella Rizzi"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Next-generation sequencing (NGS) technologies allow new methodologies for\nalternative splicing (AS) analysis. Current computational methods for AS from\nNGS data are mainly focused on predicting splice site junctions or de novo\nassembly of full-length transcripts. These methods are computationally\nexpensive and produce a huge number of full-length transcripts or splice\njunctions, spanning the whole genome of organisms. Thus summarizing such data\ninto the different gene structures and AS events of the expressed genes is an\nhard task.\n  To face this issue in this paper we investigate the computational problem of\nreconstructing from NGS data, in absence of the genome, a gene structure for\neach gene that is represented by the isoform graph: we introduce such graph and\nwe show that it uniquely summarizes the gene transcripts. We define the\ncomputational problem of reconstructing the isoform graph and provide some\nconditions that must be met to allow such reconstruction.\n  Finally, we describe an efficient algorithmic approach to solve this problem,\nvalidating our approach with both a theoretical and an experimental analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.0047v2"
    },
    {
        "title": "Chargaff's \"Grammar of Biology\": New Fractal-like Rules",
        "authors": [
            "Michel Eduardo Beleza Yamagishi",
            "Roberto H. Herai"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  Chargaff once said that \"I saw before me in dark contours the beginning of a\ngrammar of Biology\". In linguistics, \"grammar\" is the set of natural language\nrules, but we do not know for sure what Chargaff meant by \"grammar\" of Biology.\nNevertheless, assuming the metaphor, Chargaff himself started a \"grammar of\nBiology\" discovering the so called Chargaff's rules. In this work, we further\ndevelop his grammar. Using new concepts, we were able to discovery new genomic\nrules that seem to be invariant across a large set of organisms, and show a\nfractal-like property, since no matter the scale, the same pattern is observed\n(self-similarity). We hope that these new invariant genomic rules may be used\nin different contexts since short read data bias detection to genome assembly\nquality assessment.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.1528v1"
    },
    {
        "title": "Barcoding-free BAC Pooling Enables Combinatorial Selective Sequencing of\n  the Barley Gene Space",
        "authors": [
            "Stefano Lonardi",
            "Denisa Duma",
            "Matthew Alpert",
            "Francesca Cordero",
            "Marco Beccuti",
            "Prasanna R. Bhat",
            "Yonghui Wu",
            "Gianfranco Ciardo",
            "Burair Alsaihati",
            "Yaqin Ma",
            "Steve Wanamaker",
            "Josh Resnik",
            "Timothy J. Close"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  We propose a new sequencing protocol that combines recent advances in\ncombinatorial pooling design and second-generation sequencing technology to\nefficiently approach de novo selective genome sequencing. We show that\ncombinatorial pooling is a cost-effective and practical alternative to\nexhaustive DNA barcoding when dealing with hundreds or thousands of DNA\nsamples, such as genome-tiling gene-rich BAC clones. The novelty of the\nprotocol hinges on the computational ability to efficiently compare hundreds of\nmillion of short reads and assign them to the correct BAC clones so that the\nassembly can be carried out clone-by-clone. Experimental results on simulated\ndata for the rice genome show that the deconvolution is extremely accurate\n(99.57% of the deconvoluted reads are assigned to the correct BAC), and the\nresulting BAC assemblies have very high quality (BACs are covered by contigs\nover about 77% of their length, on average). Experimental results on real data\nfor a gene-rich subset of the barley genome confirm that the deconvolution is\naccurate (almost 70% of left/right pairs in paired-end reads are assigned to\nthe same BAC, despite being processed independently) and the BAC assemblies\nhave good quality (the average sum of all assembled contigs is about 88% of the\nestimated BAC length).\n",
        "pdf_link": "http://arxiv.org/pdf/1112.4438v1"
    },
    {
        "title": "A powerful and efficient set test for genetic markers that handles\n  confounders",
        "authors": [
            "Jennifer Listgarten",
            "Christoph Lippert",
            "Eun Yong Kang",
            "Jing Xiang",
            "Carl M. Kadie",
            "David Heckerman"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Approaches for testing sets of variants, such as a set of rare or common\nvariants within a gene or pathway, for association with complex traits are\nimportant. In particular, set tests allow for aggregation of weak signal within\na set, can capture interplay among variants, and reduce the burden of multiple\nhypothesis testing. Until now, these approaches did not address confounding by\nfamily relatedness and population structure, a problem that is becoming more\nimportant as larger data sets are used to increase power.\n  Results: We introduce a new approach for set tests that handles confounders.\nOur model is based on the linear mixed model and uses two random effects-one to\ncapture the set association signal and one to capture confounders. We also\nintroduce a computational speedup for two-random-effects models that makes this\napproach feasible even for extremely large cohorts. Using this model with both\nthe likelihood ratio test and score test, we find that the former yields more\npower while controlling type I error. Application of our approach to richly\nstructured GAW14 data demonstrates that our method successfully corrects for\npopulation structure and family relatedness, while application of our method to\na 15,000 individual Crohn's disease case-control cohort demonstrates that it\nadditionally recovers genes not recoverable by univariate analysis.\n  Availability: A Python-based library implementing our approach is available\nat http://mscompbio.codeplex.com\n",
        "pdf_link": "http://arxiv.org/pdf/1205.0793v3"
    },
    {
        "title": "Genome Sizes and the Benford Distribution",
        "authors": [
            "James L. Friar",
            "Terrance Goldman",
            "Juan Pérez-Mercader"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Data on the number of Open Reading Frames (ORFs) coded by genomes from the 3\ndomains of Life show some notable general features including essential\ndifferences between the Prokaryotes and Eukaryotes, with the number of ORFs\ngrowing linearly with total genome size for the former, but only\nlogarithmically for the latter. Assuming that the (protein) coding and\nnon-coding fractions of the genome must have different dynamics and that the\nnon-coding fraction must be controlled by a variety of (unspecified)\nprobability distribution functions, we are able to predict that the number of\nORFs for Eukaryotes follows a Benford distribution and has a specific\nlogarithmic form. Using the data for 1000+ genomes available to us in early\n2010, we find excellent fits to the data over several orders of magnitude, in\nthe linear regime for the Prokaryote data, and the full non-linear form for the\nEukaryote data. In their region of overlap the salient features are\nstatistically congruent, which allows us to: interpret the difference between\nProkaryotes and Eukaryotes as the manifestation of the increased demand in the\nbiological functions required for the larger Eukaryotes, estimate some minimal\ngenome sizes, and predict a maximal Prokaryote genome size on the order of 8-12\nmegabasepairs. These results naturally allow a mathematical interpretation in\nterms of maximal entropy and, therefore, most efficient information\ntransmission.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.6512v1"
    },
    {
        "title": "Extraction of Deep Phylogenetic Signal and Improved Resolution of\n  Evolutionary Events within the recA/RAD51 Phylogeny",
        "authors": [
            "Sree V. Chintapalli",
            "Gaurav Bhardwaj",
            "Jagadish Babu",
            "Loukia Hadjiyianni",
            "Yoojin Hong",
            "Zhenhai Zhang",
            "Xiaofan Zhou",
            "Hong Ma",
            "Andriy Anishkin",
            "Damian B. van Rossum",
            "Randen L. Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The recA/RAD51 gene family encodes a diverse set of recombinase proteins that\neffect homologous recombination, DNA-repair, and genome stability. The recA\ngene family is expressed in almost all species of Eubacteria, Archaea, and\nEukaryotes, and even in some viruses. To date, efforts to resolve the deep\nevolutionary origins of this ancient protein family have been hindered, in\npart, by the high sequence divergence between families (i.e. ~30% identity\nbetween paralogous groups). Through (i) large taxon sampling, (ii) the use of a\nphylogenetic algorithm designed for measuring highly divergent paralogs, and\n(iii) novel Evolutionary Spatial Dynamics simulation and analytical tools, we\nobtained a robust, parsimonious and more refined phylogenetic history of the\nrecA/RAD51 superfamily. Taken together, our model for the evolution of\nrecA/RAD51 family provides a better understanding of ancient origin of recA\nproteins and multiple events leading to the diversification of recA homologs in\neukaryotes, including the discovery of additional RAD51 sub-families.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.3340v1"
    },
    {
        "title": "The challenges of statistical patterns of language: the case of\n  Menzerath's law in genomes",
        "authors": [
            "Ramon Ferrer-i-Cancho",
            "Núria Forns",
            "Antoni Hernández-Fernández",
            "Gemma Bel-Enguix",
            "Jaume Baixeries"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The importance of statistical patterns of language has been debated over\ndecades. Although Zipf's law is perhaps the most popular case, recently,\nMenzerath's law has begun to be involved. Menzerath's law manifests in\nlanguage, music and genomes as a tendency of the mean size of the parts to\ndecrease as the number of parts increases in many situations. This statistical\nregularity emerges also in the context of genomes, for instance, as a tendency\nof species with more chromosomes to have a smaller mean chromosome size. It has\nbeen argued that the instantiation of this law in genomes is not indicative of\nany parallel between language and genomes because (a) the law is inevitable and\n(b) non-coding DNA dominates genomes. Here mathematical, statistical and\nconceptual challenges of these criticisms are discussed. Two major conclusions\nare drawn: the law is not inevitable and languages also have a correlate of\nnon-coding DNA. However, the wide range of manifestations of the law in and\noutside genomes suggests that the striking similarities between non-coding DNA\nand certain linguistics units could be anecdotal for understanding the\nrecurrence of that statistical law.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.0689v2"
    },
    {
        "title": "Joint discovery of haplotype blocks and complex trait associations from\n  SNP sequences",
        "authors": [
            "Nebojsa Jojic",
            "Vladimir Jojic",
            "David Heckerman"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Haplotypes, the global patterns of DNA sequence variation, have important\nimplications for identifying complex traits. Recently, blocks of limited\nhaplotype diversity have been discovered in human chromosomes, intensifying the\nresearch on modelling the block structure as well as the transitions or\nco-occurrence of the alleles in these blocks as a way to compress the\nvariability and infer the associations more robustly. The haplotype block\nstructure analysis is typically complicated by the fact that the phase\ninformation for each SNP is missing, i.e., the observed allele pairs are not\ngiven in a consistent order across the sequence. The techniques for\ncircumventing this require additional information, such as family data, or a\nmore complex sequencing procedure. In this paper we present a hierarchical\nstatistical model and the associated learning and inference algorithms that\nsimultaneously deal with the allele ambiguity per locus, missing data, block\nestimation, and the complex trait association. While the blo structure may\ndiffer from the structures inferred by other methods, which use the pedigree\ninformation or previously known alleles, the parameters we estimate, including\nthe learned block structure and the estimated block transitions per locus,\ndefine a good model of variability in the set. The method is completely\ndatadriven and can detect Chron's disease from the SNP data taken from the\nhuman chromosome 5q31 with the detection rate of 80% and a small error\nvariance.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.4145v1"
    },
    {
        "title": "Lossy Compression of Quality Values via Rate Distortion Theory",
        "authors": [
            "Himanshu Asnani",
            "Dinesh Bharadia",
            "Mainak Chowdhury",
            "Idoia Ochoa",
            "Itai Sharon",
            "Tsachy Weissman"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Motivation: Next Generation Sequencing technologies revolutionized many\nfields in biology by enabling the fast and cheap sequencing of large amounts of\ngenomic data. The ever increasing sequencing capacities enabled by current\nsequencing machines hold a lot of promise as for the future applications of\nthese technologies, but also create increasing computational challenges related\nto the analysis and storage of these data. A typical sequencing data file may\noccupy tens or even hundreds of gigabytes of disk space, prohibitively large\nfor many users. Raw sequencing data consists of both the DNA sequences (reads)\nand per-base quality values that indicate the level of confidence in the\nreadout of these sequences. Quality values account for about half of the\nrequired disk space in the commonly used FASTQ format and therefore their\ncompression can significantly reduce storage requirements and speed up analysis\nand transmission of these data.\n  Results: In this paper we present a framework for the lossy compression of\nthe quality value sequences of genomic read files. Numerical experiments with\nreference based alignment using these quality values suggest that we can\nachieve significant compression with little compromise in performance for\nseveral downstream applications of interest, as is consistent with our\ntheoretical analysis. Our framework also allows compression in a regime - below\none bit per quality value - for which there are no existing compressors.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.5184v1"
    },
    {
        "title": "On pairwise distances and median score of three genomes under DCJ",
        "authors": [
            "Sergey Aganezov, Jr.",
            "Max A. Alekseyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  In comparative genomics, the rearrangement distance between two genomes\n(equal the minimal number of genome rearrangements required to transform them\ninto a single genome) is often used for measuring their evolutionary\nremoteness. Generalization of this measure to three genomes is known as the\nmedian score (while a resulting genome is called median genome). In contrast to\nthe rearrangement distance between two genomes which can be computed in linear\ntime, computing the median score for three genomes is NP-hard. This inspires a\nquest for simpler and faster approximations for the median score, the most\nnatural of which appears to be the halved sum of pairwise distances which in\nfact represents a lower bound for the median score.\n  In this work, we study relationship and interplay of pairwise distances\nbetween three genomes and their median score under the model of\nDouble-Cut-and-Join (DCJ) rearrangements. Most remarkably we show that while a\nrearrangement may change the sum of pairwise distances by at most 2 (and thus\nchange the lower bound by at most 1), even the most \"powerful\" rearrangements\nin this respect that increase the lower bound by 1 (by moving one genome\nfarther away from each of the other two genomes), which we call strong, do not\nnecessarily affect the median score. This observation implies that the two\nmeasures are not as well-correlated as one's intuition may suggest.\n  We further prove that the median score attains the lower bound exactly on the\ntriples of genomes that can be obtained from a single genome with strong\nrearrangements. While the sum of pairwise distances with the factor 2/3\nrepresents an upper bound for the median score, its tightness remains unclear.\nNonetheless, we show that the difference of the median score and its lower\nbound is not bounded by a constant.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.0133v2"
    },
    {
        "title": "Using Ciliate Operations to construct Chromosome Phylogenies",
        "authors": [
            "Jacob Herlin",
            "Anna Nelson",
            "Marion Scheepers"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  We develop an algorithm based on three basic DNA editing operations suggested\nby a model for ciliate micronuclear decryption, to transform a given\npermutation into another. The number of ciliate operations performed by our\nalgorithm during such a transformation is taken to be the distance between two\nsuch permutations. Applying well-known clustering methods to such distance\nfunctions enables one to determine phylogenies among the items to which the\ndistance functions apply. As an application of these ideas we explore the\nrelationships among the chromosomes of eight fruitfly (drosophila) species,\nusing the well-known UPGMA algorithm on the distance function provided by our\nalgorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.0234v4"
    },
    {
        "title": "LDx: estimation of linkage disequilibrium from high-throughput pooled\n  resequencing data",
        "authors": [
            "Alison F. Feder",
            "Dmitri A. Petrov",
            "Alan O. Bergland"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  High-throughput pooled resequencing offers significant potential for whole\ngenome population sequencing. However, its main drawback is the loss of\nhaplotype information. In order to regain some of this information, we present\nLDx, a computational tool for estimating linkage disequilibrium (LD) from\npooled resequencing data. LDx uses an approximate maximum likelihood approach\nto estimate LD (r2) between pairs of SNPs that can be observed within and among\nsingle reads. LDx also reports r2 estimates derived solely from observed\ngenotype counts. We demonstrate that the LDx estimates are highly correlated\nwith r2 estimated from individually resequenced strains. We discuss the\nperformance of LDx using more stringent quality conditions and infer via\nsimulation the degree to which performance can improve based on read depth.\nFinally we demonstrate two possible uses of LDx with real and simulated pooled\nresequencing data. First, we use LDx to infer genomewide patterns of decay of\nLD with physical distance in D. melanogaster population resequencing data.\nSecond, we demonstrate that r2 estimates from LDx are capable of distinguishing\nalternative demographic models representing plausible demographic histories of\nD. melanogaster.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2363v2"
    },
    {
        "title": "A mixed model approach for joint genetic analysis of alternatively\n  spliced transcript isoforms using RNA-Seq data",
        "authors": [
            "Barbara Rakitsch",
            "Christoph Lippert",
            "Hande Topa",
            "Karsten Borgwardt",
            "Antti Honkela",
            "Oliver Stegle"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  RNA-Seq technology allows for studying the transcriptional state of the cell\nat an unprecedented level of detail. Beyond quantification of whole-gene\nexpression, it is now possible to disentangle the abundance of individual\nalternatively spliced transcript isoforms of a gene. A central question is to\nunderstand the regulatory processes that lead to differences in relative\nabundance variation due to external and genetic factors. Here, we present a\nmixed model approach that allows for (i) joint analysis and genetic mapping of\nmultiple transcript isoforms and (ii) mapping of isoform-specific effects.\nCentral to our approach is to comprehensively model the causes of variation and\ncorrelation between transcript isoforms, including the genomic background and\ntechnical quantification uncertainty. As a result, our method allows to\naccurately test for shared as well as transcript-specific genetic regulation of\ntranscript isoforms and achieves substantially improved calibration of these\nstatistical tests. Experiments on genotype and RNA-Seq data from 126 human\nHapMap individuals demonstrate that our model can help to obtain a more\nfine-grained picture of the genetic basis of gene expression variation.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2850v1"
    },
    {
        "title": "When is Menzerath-Altmann law mathematically trivial? A new approach",
        "authors": [
            "Ramon Ferrer-i-Cancho",
            "Antoni Hernández-Fernández",
            "Jaume Baixeries",
            "Łukasz Dȩbowski",
            "Ján Mačutek"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Menzerath's law, the tendency of Z, the mean size of the parts, to decrease\nas X, the number of parts, increases is found in language, music and genomes.\nRecently, it has been argued that the presence of the law in genomes is an\ninevitable consequence of the fact that Z = Y/X, which would imply that Z\nscales with X as Z ~ 1/X. That scaling is a very particular case of\nMenzerath-Altmann law that has been rejected by means of a correlation test\nbetween X and Y in genomes, being X the number of chromosomes of a species, Y\nits genome size in bases and Z the mean chromosome size. Here we review the\nstatistical foundations of that test and consider three non-parametric tests\nbased upon different correlation metrics and one parametric test to evaluate if\nZ ~ 1/X in genomes. The most powerful test is a new non-parametric based upon\nthe correlation ratio, which is able to reject Z ~ 1/X in nine out of eleven\ntaxonomic groups and detect a borderline group. Rather than a fact, Z ~ 1/X is\na baseline that real genomes do not meet. The view of Menzerath-Altmann law as\ninevitable is seriously flawed.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.6599v4"
    },
    {
        "title": "Environmental perturbations lift the degeneracy of the genetic code to\n  regulate protein levels in bacteria",
        "authors": [
            "Arvind R. Subramaniam",
            "Tao Pan",
            "Philippe Cluzel"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  The genetic code underlying protein synthesis is a canonical example of a\ndegenerate biological system. Degeneracies in physical and biological systems\ncan be lifted by external perturbations thus allowing degenerate systems to\nexhibit a wide range of behaviors. Here we show that the degeneracy of the\ngenetic code is lifted by environmental perturbations to regulate protein\nlevels in living cells. By measuring protein synthesis rates from a synthetic\nreporter library in Escherichia coli, we find that environmental perturbations,\nsuch as reduction of cognate amino acid supply, lift the degeneracy of the\ngenetic code by splitting codon families into a hierarchy of robust and\nsensitive synonymous codons. Rates of protein synthesis associated with robust\ncodons are up to hundred-fold higher than those associated with sensitive\ncodons under these conditions. We find that the observed hierarchy between\nsynonymous codons is not determined by usual rules associated with tRNA\nabundance and codon usage. Rather, competition among tRNA isoacceptors for\naminoacylation underlies the robustness of protein synthesis. Remarkably, the\nhierarchy established using the synthetic library also explains the measured\nrobustness of synthesis for endogenous proteins in E. coli. We further found\nthat the same hierarchy is reflected in the fitness cost of synonymous\nmutations in amino acid biosynthesis genes and in the transcriptional control\nof sigma factor genes. Our study reveals that the degeneracy of the genetic\ncode can be lifted by environmental perturbations, and it suggests that\norganisms can exploit degeneracy lifting as a general strategy to adapt protein\nsynthesis to their environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.1537v1"
    },
    {
        "title": "easyGWAS: An integrated interspecies platform for performing genome-wide\n  association studies",
        "authors": [
            "Dominik Grimm",
            "Bastian Greshake",
            "Stefan Kleeberger",
            "Christoph Lippert",
            "Oliver Stegle",
            "Bernhard Schölkopf",
            "Detlef Weigel",
            "Karsten Borgwardt"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  Motivation: The rapid growth in genome-wide association studies (GWAS) in\nplants and animals has brought about the need for a central resource that\nfacilitates i) performing GWAS, ii) accessing data and results of other GWAS,\nand iii) enabling all users regardless of their background to exploit the\nlatest statistical techniques without having to manage complex software and\ncomputing resources.\n  Results: We present easyGWAS, a web platform that provides methods, tools and\ndynamic visualizations to perform and analyze GWAS. In addition, easyGWAS makes\nit simple to reproduce results of others, validate findings, and access larger\nsample sizes through merging of public datasets.\n  Availability: Detailed method and data descriptions as well as tutorials are\navailable in the supplementary materials. easyGWAS is available at\nhttp://easygwas.tuebingen.mpg.de/.\n  Contact: dominik.grimm@tuebingen.mpg.de\n",
        "pdf_link": "http://arxiv.org/pdf/1212.4788v1"
    },
    {
        "title": "Google matrix analysis of DNA sequences",
        "authors": [
            "Vivek Kandiah",
            "Dima L. Shepelyansky"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  For DNA sequences of various species we construct the Google matrix G of\nMarkov transitions between nearby words composed of several letters. The\nstatistical distribution of matrix elements of this matrix is shown to be\ndescribed by a power law with the exponent being close to those of outgoing\nlinks in such scale-free networks as the World Wide Web (WWW). At the same time\nthe sum of ingoing matrix elements is characterized by the exponent being\nsignificantly larger than those typical for WWW networks. This results in a\nslow algebraic decay of the PageRank probability determined by the distribution\nof ingoing elements. The spectrum of G is characterized by a large gap leading\nto a rapid relaxation process on the DNA sequence networks. We introduce the\nPageRank proximity correlator between different species which determines their\nstatistical similarity from the view point of Markov chains. The properties of\nother eigenstates of the Google matrix are also discussed. Our results\nestablish scale-free features of DNA sequence networks showing their\nsimilarities and distinctions with the WWW and linguistic networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.1626v1"
    },
    {
        "title": "Biases in the Experimental Annotations of Protein Function and their\n  Effect on Our Understanding of Protein Function Space",
        "authors": [
            "Alexandra M. Schnoes",
            "David C. Ream",
            "Alexander W. Thorman",
            "Patricia C. Babbitt",
            "Iddo Friedberg"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The ongoing functional annotation of proteins relies upon the work of\ncurators to capture experimental findings from scientific literature and apply\nthem to protein sequence and structure data. However, with the increasing use\nof high-throughput experimental assays, a small number of experimental studies\ndominate the functional protein annotations collected in databases. Here we\ninvestigate just how prevalent is the \"few articles -- many proteins\"\nphenomenon. We examine the experimentally validated annotation of proteins\nprovided by several groups in the GO Consortium, and show that the distribution\nof proteins per published study is exponential, with 0.14% of articles\nproviding the source of annotations for 25% of the proteins in the UniProt-GOA\ncompilation. Since each of the dominant articles describes the use of an assay\nthat can find only one function or a small group of functions, this leads to\nsubstantial biases in what we know about the function of many proteins.\nMass-spectrometry, microscopy and RNAi experiments dominate high throughput\nexperiments. Consequently, the functional information derived from these\nexperiments is mostly of the subcellular location of proteins, and of the\nparticipation of proteins in embryonic developmental pathways. For some\norganisms, the information provided by different studies overlap by a large\namount. We also show that the information provided by high throughput\nexperiments is less specific than those provided by low throughput experiments.\nGiven the experimental techniques available, certain biases in protein function\nannotation due to high-throughput experiments are unavoidable. Knowing that\nthese biases exist and understanding their characteristics and extent is\nimportant for database curators, developers of function annotation programs,\nand anyone who uses protein function annotation data to plan experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.1740v4"
    },
    {
        "title": "An Efficient Sufficient Dimension Reduction Method for Identifying\n  Genetic Variants of Clinical Significance",
        "authors": [
            "Momiao Xiong",
            "Long Ma"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Fast and cheaper next generation sequencing technologies will generate\nunprecedentedly massive and highly-dimensional genomic and epigenomic variation\ndata. In the near future, a routine part of medical record will include the\nsequenced genomes. A fundamental question is how to efficiently extract genomic\nand epigenomic variants of clinical utility which will provide information for\noptimal wellness and interference strategies. Traditional paradigm for\nidentifying variants of clinical validity is to test association of the\nvariants. However, significantly associated genetic variants may or may not be\nusefulness for diagnosis and prognosis of diseases. Alternative to association\nstudies for finding genetic variants of predictive utility is to systematically\nsearch variants that contain sufficient information for phenotype prediction.\nTo achieve this, we introduce concepts of sufficient dimension reduction and\ncoordinate hypothesis which project the original high dimensional data to very\nlow dimensional space while preserving all information on response phenotypes.\nWe then formulate clinically significant genetic variant discovery problem into\nsparse SDR problem and develop algorithms that can select significant genetic\nvariants from up to or even ten millions of predictors with the aid of dividing\nSDR for whole genome into a number of subSDR problems defined for genomic\nregions. The sparse SDR is in turn formulated as sparse optimal scoring\nproblem, but with penalty which can remove row vectors from the basis matrix.\nTo speed up computation, we develop the modified alternating direction method\nfor multipliers to solve the sparse optimal scoring problem which can easily be\nimplemented in parallel. To illustrate its application, the proposed method is\napplied to simulation data and the NHLBI's Exome Sequencing Project dataset\n",
        "pdf_link": "http://arxiv.org/pdf/1301.3528v1"
    },
    {
        "title": "Information Measures for Long-Range Correlated Sequences: the Case of\n  the 24 Human Chromosome Sequences",
        "authors": [
            "Anna Carbone"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  A new approach to estimate the Shannon entropy of a long-range correlated\nsequence is proposed. The entropy is written as the sum of two terms\ncorresponding respectively to power-law (\\emph{ordered}) and exponentially\n(\\emph{disordered}) distributed blocks (clusters). The approach is illustrated\non the 24 human chromosome sequences by taking the nucleotide composition as\nthe relevant information to be encoded/decoded. Interestingly, the nucleotide\ncomposition of the \\emph{ordered} clusters is found, on the average, comparable\nto the one of the whole analyzed sequence, while that of the \\emph{disordered}\nclusters fluctuates. From the information theory standpoint, this means that\nthe power-law correlated clusters carry the same information of the whole\nanalysed sequence. Furthermore, the fluctuations of the nucleotide composition\nof the disordered clusters are linked to relevant biological properties, such\nas segmental duplications and gene density.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.0784v2"
    },
    {
        "title": "Beyond position weight matrices: nucleotide correlations in\n  transcription factor binding sites and their description",
        "authors": [
            "Marc Santolini",
            "Thierry Mora",
            "Vincent Hakim"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The identification of transcription factor binding sites (TFBSs) on genomic\nDNA is of crucial importance for understanding and predicting regulatory\nelements in gene networks. TFBS motifs are commonly described by Position\nWeight Matrices (PWMs), in which each DNA base pair independently contributes\nto the transcription factor (TF) binding, despite mounting evidence of\ninterdependence between base pairs positions. The recent availability of\ngenome-wide data on TF-bound DNA regions offers the possibility to revisit this\nquestion in detail for TF binding {\\em in vivo}. Here, we use available fly and\nmouse ChIPseq data, and show that the independent model generally does not\nreproduce the observed statistics of TFBS, generalizing previous observations.\nWe further show that TFBS description and predictability can be systematically\nimproved by taking into account pairwise correlations in the TFBS via the\nprinciple of maximum entropy. The resulting pairwise interaction model is\nformally equivalent to the disordered Potts models of statistical mechanics and\nit generalizes previous approaches to interdependent positions. Its structure\nallows for co-variation of two or more base pairs, as well as secondary motifs.\nAlthough models consisting of mixtures of PWMs also have this last feature, we\nshow that pairwise interaction models outperform them. The significant pairwise\ninteractions are found to be sparse and found dominantly between consecutive\nbase pairs. Finally, the use of a pairwise interaction model for the\nidentification of TFBSs is shown to give significantly different predictions\nthan a model based on independent positions.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.4424v1"
    },
    {
        "title": "Colocalization of coregulated genes: a steered molecular dynamics study\n  of human chromosome 19",
        "authors": [
            "Marco Di Stefano",
            "Angelo Rosa",
            "Vincenzo Belcastro",
            "Diego di Bernardo",
            "Cristian Micheletti"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The connection between chromatin nuclear organization and gene activity is\nvividly illustrated by the observation that transcriptional coregulation of\ncertain genes appears to be directly influenced by their spatial proximity.\nThis fact poses the more general question of whether it is at all feasible that\nthe numerous genes that are coregulated on a given chromosome, especially those\nat large genomic distances, might become proximate inside the nucleus. This\nproblem is studied here using steered molecular dynamics simulations in order\nto enforce the colocalization of thousands of knowledge-based gene sequences on\na model for the gene-rich human chromosome 19. Remarkably, it is found that\nmost (~80%) gene pairs can be brought simultaneously into contact. This is made\npossible by the low degree of intra-chromosome entanglement and the large\nnumber of cliques in the gene coregulatory network, that is the many groups of\ngenes that are all mutually coregulated. The constrained conformations for the\nmodel chromosome 19 are further shown to be organised in spatial macrodomains\nthat are similar to those inferred from recent HiC measurements. The findings\nindicate that gene coregulation and colocalization are largely compatible and\nthat this relationship can be exploited to draft the overall spatial\norganization of the chromosome in vivo. The more general validity and\nimplications of these findings could be investigated by applying to other\neukaryotic chromosomes the general and transferable computational strategy\nintroduced here.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.5118v1"
    },
    {
        "title": "GenomeFingerprinter and universal genome fingerprint analysis for\n  systematic comparative genomics",
        "authors": [
            "Yuncan Ai",
            "Hannan Ai",
            "Fanmei Meng",
            "Lei Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  How to compare whole genome sequences at large scale has not been achieved\nvia conventional methods based on pair-wisely base-to-base comparison;\nnevertheless, no attention was paid to handle in-one-sitting a number of\ngenomes crossing genetic category (chromosome, plasmid, and phage) with farther\ndivergences (much less or no homologous) over large size ranges (from Kbp to\nMbp). We created a new method, GenomeFingerprinter, to unambiguously produce\nthree-dimensional coordinates from a sequence, followed by one\nthree-dimensional plot and six two-dimensional trajectory projections to\nillustrate whole genome fingerprints. We further developed a set of concepts\nand tools and thereby established a new method, universal genome fingerprint\nanalysis. We demonstrated their applications through case studies on over a\nhundred of genome sequences. Particularly, we defined the total genetic\ncomponent configuration (TGCC) (i.e., chromosome, plasmid, and phage) for\ndescribing a strain as a system, and the universal genome fingerprint map\n(UGFM) of TGCC for differentiating a strain as a universal system, as well as\nthe systematic comparative genomics (SCG) for comparing in-one-sitting a number\nof genomes crossing genetic category in diverse strains. By using UGFM,\nUGFM-TGCC, and UGFM-TGCC-SCG, we compared a number of genome sequences with\nfarther divergences (chromosome, plasmid, and phage; bacterium, archaeal\nbacterium, and virus) over large size ranges (6Kbp~5Mbp), giving new insights\ninto critical problematic issues in microbial genomics in the post-genomic era.\nThis paper provided a new method for rapidly computing, geometrically\nvisualizing, and intuitively comparing genome sequences at fingerprint level,\nand hence established a new method of universal genome fingerprint analysis for\nsystematic comparative genomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.2284v1"
    },
    {
        "title": "Concurrent and Accurate RNA Sequencing on Multicore Platforms",
        "authors": [
            "Héctor Martínez",
            "Joaquín Tárraga",
            "Ignacio Medina",
            "Sergio Barrachina",
            "Maribel Castillo",
            "Joaquín Dopazo",
            "Enrique S. Quintana-Ortí"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  In this paper we introduce a novel parallel pipeline for fast and accurate\nmapping of RNA sequences on servers equipped with multicore processors. Our\nsoftware, named HPG-Aligner, leverages the speed of the Burrows-Wheeler\nTransform to map a large number of RNA fragments (reads) rapidly, as well as\nthe accuracy of the Smith-Waterman algorithm, that is employed to deal with\nconflictive reads. The aligner is complemented with a careful strategy to\ndetect splice junctions based on the division of RNA reads into short segments\n(or seeds), which are then mapped onto a number of candidate alignment\nlocations, providing useful information for the successful alignment of the\ncomplete reads.\n  Experimental results on platforms with AMD and Intel multicore processors\nreport the remarkable parallel performance of HPG-Aligner, on short and long\nRNA reads, which excels in both execution time and sensitivity to an\nstate-of-the-art aligner such as TopHat 2 built on top of Bowtie and Bowtie 2.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.0681v1"
    },
    {
        "title": "Improving genetic risk prediction by leveraging pleiotropy",
        "authors": [
            "Cong Li",
            "Can Yang",
            "Joel Gelernter",
            "Hongyu Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  An important task of human genetics studies is to accurately predict disease\nrisks in individuals based on genetic markers, which allows for identifying\nindividuals at high disease risks, and facilitating their disease treatment and\nprevention. Although hundreds of genome-wide association studies (GWAS) have\nbeen conducted on many complex human traits in recent years, there has been\nonly limited success in translating these GWAS data into clinically useful risk\nprediction models. The predictive capability of GWAS data is largely\nbottlenecked by the available training sample size due to the presence of\nnumerous variants carrying only small to modest effects. Recent studies have\nshown that different human traits may share common genetic bases. Therefore, an\nattractive strategy to increase the training sample size and hence improve the\nprediction accuracy is to integrate data of genetically correlated phenotypes.\nYet the utility of genetic correlation in risk prediction has not been explored\nin the literature. In this paper, we analyzed GWAS data for bipolar and related\ndisorders (BARD) and schizophrenia (SZ) with a bivariate ridge regression\nmethod, and found that jointly predicting the two phenotypes could\nsubstantially increase prediction accuracy as measured by the AUC (area under\nthe receiver operating characteristic curve). We also found similar prediction\naccuracy improvements when we jointly analyzed GWAS data for Crohn's disease\n(CD) and ulcerative colitis (UC). The empirical observations were substantiated\nthrough our comprehensive simulation studies, suggesting that a gain in\nprediction accuracy can be obtained by combining phenotypes with relatively\nhigh genetic correlations. Through both real data and simulation studies, we\ndemonstrated pleiotropy as a valuable asset that opens up a new opportunity to\nimprove genetic risk prediction in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7417v3"
    },
    {
        "title": "Gene and Gene-Set Analysis for Genome-Wide Association Studies",
        "authors": [
            "Inti Pedroso"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Genome-wide association studies (GWAS) have identified hundreds of loci at\nvery stringent levels of statistical significance across many different human\ntraits. However, it is now clear that very large samples (n~10^4-10^5) are\nneeded to find the majority of genetic variants underlying risk for most human\ndiseases. Therefore, the field has engaged itself in a race to increase study\nsample sizes with some studies yielding very successful results but also\nstudies which provide little or no new insights. This project started early on\nin this new wave of studies and I decided to use an alternative approach that\nuses prior biological knowledge to improve both interpretation and power of\nGWAS. The project aimed to a) implement and develop new gene-based methods to\nderive gene-level statistics to use GWAS in well established system biology\ntools; b) use of these gene-level statistics in networks and gene-set analyses\nof GWAS data; c) mine GWAS of neuropsychiatric disorders using gene, gene-sets\nand integrative biology analyses with gene-expression studies; and d) explore\nthe ability of these methods to improve the analysis GWAS on disease\nsub-phenotypes which usually suffer of very small sample sizes.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.4102v1"
    },
    {
        "title": "Fast Approximate Inference of Transcript Expression Levels from RNA-seq\n  Data",
        "authors": [
            "James Hensman",
            "Peter Glaus",
            "Antti Honkela",
            "Magnus Rattray"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Motivation: The mapping of RNA-seq reads to their transcripts of origin is a\nfundamental task in transcript expression estimation and differential\nexpression scoring. Where ambiguities in mapping exist due to transcripts\nsharing sequence, e.g. alternative isoforms or alleles, the problem becomes an\ninstance of non-trivial probabilistic inference. Bayesian inference in such a\nproblem is intractable and approximate methods must be used such as Markov\nchain Monte Carlo (MCMC) and Variational Bayes. Standard implementations of\nthese methods can be prohibitively slow for large datasets and complex gene\nmodels.\n  Results: We propose an approximate inference scheme based on Variational\nBayes applied to an existing model of transcript expression inference from\nRNA-seq data. We apply recent advances in Variational Bayes algorithmics to\nimprove the convergence of the algorithm beyond the standard variational\nexpectation-maximisation approach. We apply our algorithm to simulated and\nbiological datasets, demonstrating that the increase in speed requires only a\nsmall trade-off in accuracy of expression level estimation.\n  Availability: The methods were implemented in R and C++, and are available as\npart of the BitSeq project at https://code.google.com/p/bitseq/. The methods\nwill be made available through the BitSeq Bioconductor package at the next\nstable release.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.5953v2"
    },
    {
        "title": "Exploration and retrieval of whole-metagenome sequencing samples",
        "authors": [
            "Sohan Seth",
            "Niko Välimäki",
            "Samuel Kaski",
            "Antti Honkela"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Over the recent years, the field of whole metagenome shotgun sequencing has\nwitnessed significant growth due to the high-throughput sequencing technologies\nthat allow sequencing genomic samples cheaper, faster, and with better coverage\nthan before. This technical advancement has initiated the trend of sequencing\nmultiple samples in different conditions or environments to explore the\nsimilarities and dissimilarities of the microbial communities. Examples include\nthe human microbiome project and various studies of the human intestinal tract.\nWith the availability of ever larger databases of such measurements, finding\nsamples similar to a given query sample is becoming a central operation. In\nthis paper, we develop a content-based exploration and retrieval method for\nwhole metagenome sequencing samples. We apply a distributed string mining\nframework to efficiently extract all informative sequence $k$-mers from a pool\nof metagenomic samples and use them to measure the dissimilarity between two\nsamples. We evaluate the performance of the proposed approach on two human gut\nmetagenome data sets as well as human microbiome project metagenomic samples.\nWe observe significant enrichment for diseased gut samples in results of\nqueries with another diseased sample and very high accuracy in discriminating\nbetween different body sites even though the method is unsupervised. A software\nimplementation of the DSM framework is available at\nhttps://github.com/HIITMetagenomics/dsm-framework\n",
        "pdf_link": "http://arxiv.org/pdf/1308.6074v2"
    },
    {
        "title": "DNA viewed as an out-of-equilibrium structure",
        "authors": [
            "A. Provata",
            "C. Nicolis",
            "G. Nicolis"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The complexity of the primary structure of human DNA is explored using\nmethods from nonequilibrium statistical mechanics, dynamical systems theory and\ninformation theory. The use of chi-square tests shows that DNA cannot be\ndescribed as a low order Markov chain of order up to $r=6$. Although detailed\nbalance seems to hold at the level of purine-pyrimidine notation it fails when\nall four basepairs are considered, suggesting spatial asymmetry and\nirreversibility. Furthermore, the block entropy does not increase linearly with\nthe block size, reflecting the long range nature of the correlations in the\nhuman genomic sequences. To probe locally the spatial structure of the chain we\nstudy the exit distances from a specific symbol, the distribution of recurrence\ndistances and the Hurst exponent, all of which show power law tails and long\nrange characteristics. These results suggest that human DNA can be viewed as a\nnon-equilibrium structure maintained in its state through interactions with a\nconstantly changing environment. Based solely on the exit distance distribution\naccounting for the nonequilibrium statistics and using the Monte Carlo\nrejection sampling method we construct a model DNA sequence. This method allows\nto keep all long range and short range statistical characteristics of the\noriginal sequence. The model sequence presents the same characteristic\nexponents as the natural DNA but fails to capture point-to-point details.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.4441v1"
    },
    {
        "title": "Amino Acid Distributions and the Effect of Optimal Growth Temperature",
        "authors": [
            "Benjamin Greenbaum",
            "Pradeep Kumar",
            "Albert Libchaber"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We perform an exhaustive analysis of genome statistics for organisms,\nparticularly extremophiles, growing in a wide range of physicochemical\nconditions. Specifically, we demonstrate how the correlation between the\nfrequency of amino acids and their molecular weight, preserved on average,\ntypically decreases as optimal growth temperature increases. We show how the\nrelation between codon degeneracy and amino acid mass is enforced across these\norganisms. We assess the occurrence of contiguous amino acids, finding several\nsignificant short words, often containing cysteine, histidine or proline.\nTypically, the significance of these words is independent of growth\ntemperature. In a novel approach, first-passage distributions are used to\ncapture correlations between discontiguous residues. We find a nearly universal\nexponential background that we relate to properties of the aforementioned\nindividual amino acid frequencies. We find this approach reliably extracts\ncorrelations that depend on growth temperature, some of which have not been\npreviously characterized.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.4761v1"
    },
    {
        "title": "Change Point Analysis of Histone Modifications Reveals Epigenetic Blocks\n  Linking to Physical Domains",
        "authors": [
            "Mengjie Chen",
            "Haifan Lin",
            "Hongyu Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Histone modification is a vital epigenetic mechanism for transcriptional\ncontrol in eukaryotes. High-throughput techniques have enabled whole-genome\nanalysis of histone modifications in recent years. However, most studies assume\none combination of histone modification invariantly translates to one\ntranscriptional output regardless of local chromatin environment. In this study\nwe hypothesize that, the genome is organized into local domains that manifest\nsimilar enrichment pattern of histone modification, which leads to orchestrated\nregulation of expression of genes with relevant bio- logical functions. We\npropose a multivariate Bayesian Change Point (BCP) model to segment the\nDrosophila melanogaster genome into consecutive blocks on the basis of\ncombinatorial patterns of histone marks. By modeling the sparse distribution of\nhistone marks across the chromosome with a zero-inflated Gaussian mixture, our\npartitions capture local BLOCKs that manifest relatively homogeneous enrichment\npattern of histone modifications. We further characterized BLOCKs by their\ntranscription levels, distribution of genes, degree of co-regulation and GO\nenrichment. Our results demonstrate that these BLOCKs, although inferred merely\nfrom histone modifications, reveal strong relevance with physical domains,\nwhich suggest their important roles in chromatin organization and coordinated\ngene regulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5337v2"
    },
    {
        "title": "Routes for breaching and protecting genetic privacy",
        "authors": [
            "Yaniv Erlich",
            "Arvind Narayanan"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We are entering the era of ubiquitous genetic information for research,\nclinical care, and personal curiosity. Sharing these datasets is vital for\nrapid progress in understanding the genetic basis of human diseases. However,\none growing concern is the ability to protect the genetic privacy of the data\noriginators. Here, we technically map threats to genetic privacy and discuss\npotential mitigation strategies for privacy-preserving dissemination of genetic\ndata.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3197v1"
    },
    {
        "title": "The Foundations of Genodynamics: The Development of Metrics for\n  Genomic-Environmental Interactions",
        "authors": [
            "James Lindesay",
            "Tshela E. Mason",
            "William Hercules",
            "Georgia M. Dunston"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Single nucleotide polymorphisms (SNPs) represent an important type of dynamic\nsites within the human genome. These common variants often locally correlate\ninto more complex multi-SNP haploblocks that are maintained throughout\ngenerations in a stable population. The information encoded in the structure of\ncommon SNPs and SNP haploblock variation can be characterized through a\nnormalized information content (NIC) metric. Such an intrinsic measure allows\ndisparate regions of individual genomes and the genomes of various populations\nto be quantitatively compared in a meaningful way.\n  Using our defined measures of genomic information, the interplay of\nmaintained statistical variations due to the environmental baths within which\nstable populations exist can be interrogated. We develop the analogous\n\"thermodynamics\" characterizing the state variables for genomic populations\nthat are stable under stochastic environmental stresses. Since living systems\nhave not been found to develop in the absence of environmental influences, we\nfocus on describing the analogous genomic free energy measures in this\ndevelopment.\n  The intensive parameter describing how an environment drives genomic\ndiversity is found to depend inversely upon the NIC of the genome of a stable\npopulation within that environment. Once this environmental potential has been\ndetermined from the whole genome of a population, additive state variables can\nbe directly related to the probabilities of the occurrence of given viable SNP\nbased units (alleles) within that genome. This formulation allows the\ndetermination of both population averaged state variables as well as the\ngenomic energies of individual alleles and their combinations. The\ndetermination of individual allelic potentials then should allow the\nparameterization of specific environmental influences upon shared alleles\nacross populations in varying environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3260v1"
    },
    {
        "title": "The shrinking human protein coding complement: are there now fewer than\n  20,000 genes?",
        "authors": [
            "Iakes Ezkurdia",
            "David Juan",
            "Jose Manuel Rodriguez",
            "Adam Frankish",
            "Mark Diekhans",
            "Jennifer Harrow",
            "Jesus Vazquez",
            "Alfonso Valencia",
            "Michael L. Tress"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  Determining the full complement of protein-coding genes is a key goal of\ngenome annotation. The most powerful approach for confirming protein coding\npotential is the detection of cellular protein expression through peptide mass\nspectrometry experiments. Here we map the peptides detected in 7 large-scale\nproteomics studies to almost 60% of the protein coding genes in the GENCODE\nannotation the human genome. We find that conservation across vertebrate\nspecies and the age of the gene family are key indicators of whether a peptide\nwill be detected in proteomics experiments. We find peptides for most highly\nconserved genes and for practically all genes that evolved before bilateria. At\nthe same time there is almost no evidence of protein expression for genes that\nhave appeared since primates, or for genes that do not have any protein-like\nfeatures or cross-species conservation. We identify 19 non-protein-like\nfeatures such as weak conservation, no protein features or ambiguous\nannotations in major databases that are indicators of low peptide detection\nrates. We use these features to describe a set of 2,001 genes that are\npotentially non-coding, and show that many of these genes behave more like\nnon-coding genes than protein-coding genes. We detect peptides for just 3% of\nthese genes. We suggest that many of these 2,001 genes do not code for proteins\nunder normal circumstances and that they should not be included in the human\nprotein coding gene catalogue. These potential non-coding genes will be revised\nas part of the ongoing human genome annotation effort.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7111v4"
    },
    {
        "title": "Approaching allelic probabilities and Genome-Wide Association Studies\n  from beta distributions",
        "authors": [
            "José Santiago García-Cremades",
            "Angel del Río",
            "José A. García",
            "Javier Gayán",
            "Antonio González-Pérez",
            "Agustín Ruiz",
            "O. Sotolongo-Grau",
            "Manuel Ruiz-Marín"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  In this paper we have proposed a model for the distribution of allelic\nprobabilities for generating populations as reliably as possible. Our objective\nwas to develop such a model which would allow simulating allelic probabilities\nwith different observed truncation and de- gree of noise. In addition, we have\nalso introduced here a complete new approach to analyze a genome-wide\nassociation study (GWAS) dataset, starting from a new test of association with\na statistical distribution and two effect sizes of each genotype. The new\nmethodologi- cal approach was applied to a real data set together with a Monte\nCarlo experiment which showed the power performance of our new method. Finally,\nwe compared the new method based on beta distribution with the conventional\nmethod (based on Chi-Squared distribu- tion) using the agreement Kappa index\nand a principal component analysis (PCA). Both the analyses show found\ndifferences existed between both the approaches while selecting the single\nnucleotide polymorphisms (SNPs) in association.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6151v1"
    },
    {
        "title": "Predicting discovery rates of genomic features",
        "authors": [
            "Simon Gravel",
            "NHLBI GO Exome Sequencing Project"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Successful sequencing experiments require judicious sample selection.\nHowever, this selection must often be performed on the basis of limited\npreliminary data. Predicting the statistical properties of the final sample\nbased on preliminary data can be challenging, because numerous uncertain model\nassumptions may be involved. Here, we ask whether we can predict ``omics\"\nvariation across many samples by sequencing only a fraction of them. In the\ninfinite-genome limit, we find that a pilot study sequencing $5\\%$ of a\npopulation is sufficient to predict the number of genetic variants in the\nentire population within $6\\%$ of the correct value, using an estimator\nagnostic to demography, selection, or population structure. To reach similar\naccuracy in a finite genome with millions of polymorphisms, the pilot study\nwould require about $15\\%$ of the population. We present computationally\nefficient jackknife and linear programming methods that exhibit substantially\nless bias than the state of the art when applied to simulated data and\nsub-sampled 1000 Genomes Project data. Extrapolating based on the NHLBI Exome\nSequencing Project data, we predict that $7.2\\%$ of sites in the capture region\nwould be variable in a sample of $50,000$ African-Americans, and $8.8\\%$ in a\nEuropean sample of equal size. Finally, we show how the linear programming\nmethod can also predict discovery rates of various genomic features, such as\nthe number of transcription factor binding sites across different cell types.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.3414v1"
    },
    {
        "title": "Iterative Learning for Reference-Guided DNA Sequence Assembly from Short\n  Reads: Algorithms and Limits of Performance",
        "authors": [
            "Xiaohu Shen",
            "Manohar Shamaiah",
            "Haris Vikalo"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Recent emergence of next-generation DNA sequencing technology has enabled\nacquisition of genetic information at unprecedented scales. In order to\ndetermine the genetic blueprint of an organism, sequencing platforms typically\nemploy so-called shotgun sequencing strategy to oversample the target genome\nwith a library of relatively short overlapping reads. The order of nucleotides\nin the reads is determined by processing the acquired noisy signals generated\nby the sequencing instrument. Assembly of a genome from potentially erroneous\nshort reads is a computationally daunting task even in the scenario where a\nreference genome exists. Errors and gaps in the reference, and perfect repeat\nregions in the target, further render the assembly challenging and cause\ninaccuracies. In this paper, we formulate the reference-guided sequence\nassembly problem as the inference of the genome sequence on a bipartite graph\nand solve it using a message-passing algorithm. The proposed algorithm can be\ninterpreted as the well-known classical belief propagation scheme under a\ncertain prior. Unlike existing state-of-the-art methods, the proposed algorithm\ncombines the information provided by the reads without needing to know\nreliability of the short reads (so-called quality scores). Relation of the\nmessage-passing algorithm to a provably convergent power iteration scheme is\ndiscussed. To evaluate and benchmark the performance of the proposed technique,\nwe find an analytical expression for the probability of error of a genie-aided\nmaximum a posteriori (MAP) decision scheme. Results on both simulated and\nexperimental data demonstrate that the proposed message-passing algorithm\noutperforms commonly used state-of-the-art tools, and it nearly achieves the\nperformance of the aforementioned MAP decision scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.5686v1"
    },
    {
        "title": "High Performance Solutions for Big-data GWAS",
        "authors": [
            "Elmar Peise",
            "Diego Fabregat-Traver",
            "Paolo Bientinesi"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  In order to associate complex traits with genetic polymorphisms, genome-wide\nassociation studies process huge datasets involving tens of thousands of\nindividuals genotyped for millions of polymorphisms. When handling these\ndatasets, which exceed the main memory of contemporary computers, one faces two\ndistinct challenges: 1) Millions of polymorphisms and thousands of phenotypes\ncome at the cost of hundreds of gigabytes of data, which can only be kept in\nsecondary storage; 2) the relatedness of the test population is represented by\na relationship matrix, which, for large populations, can only fit in the\ncombined main memory of a distributed architecture. In this paper, by using\ndistributed resources such as Cloud or clusters, we address both challenges:\nThe genotype and phenotype data is streamed from secondary storage using a\ndouble buffer- ing technique, while the relationship matrix is kept across the\nmain memory of a distributed memory system. With the help of these solutions,\nwe develop separate algorithms for studies involving only one or a multitude of\ntraits. We show that these algorithms sustain high-performance and allow the\nanalysis of enormous datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.6426v1"
    },
    {
        "title": "Statistical distributions of sequencing by synthesis with probabilistic\n  nucleotide incorporation",
        "authors": [
            "Yong Kong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Sequencing by synthesis is used in many next-generation DNA sequencing\ntechnologies. Some of the technologies, especially those exploring the\nprinciple of single-molecule sequencing, allow incomplete nucleotide\nincorporation in each cycle. We derive statistical distributions for sequencing\nby synthesis by taking into account the possibility that nucleotide\nincorporation may not be complete in each flow cycle. The statistical\ndistributions are expressed in terms of nucleotide probabilities of the target\nsequences and the nucleotide incorporation probabilities for each nucleotide.\nWe give exact distributions both for fixed number of flow cycles and for fixed\nsequence length. Explicit formulas are derived for the mean and variance of\nthese distributions. The results are generalizations of our previous work for\npyrosequencing. Incomplete nucleotide incorporation leads to significant change\nin the mean and variance of the distributions, but still they can be\napproximated by normal distributions with the same mean and variance. The\nresults are also generalized to handle sequence context dependent\nincorporation. The statistical distributions will be useful for instrument and\nsoftware development for sequencing by synthesis platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.2547v1"
    },
    {
        "title": "Length distribution of sequencing by synthesis: fixed flow cycle model",
        "authors": [
            "Yong Kong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Sequencing by synthesis is the underlying technology for many next-generation\nDNA sequencing platforms. We developed a new model, the fixed flow cycle model,\nto derive the distributions of sequence length for a given number of flow\ncycles under the general conditions where the nucleotide incorporation is\nprobabilistic and may be incomplete, as in some single-molecule sequencing\ntechnologies. Unlike the previous model, the new model yields the probability\ndistribution for the sequence length. Explicit closed form formulas are derived\nfor the mean and variance of the distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.2548v1"
    },
    {
        "title": "Distributions of positive signals in pyrosequencing",
        "authors": [
            "Yong Kong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Pyrosequencing is one of the important next-generation sequencing\ntechnologies. We derive the distribution of the number of positive signals in\npyrograms of this sequencing technology as a function of flow cycle numbers and\nnucleotide probabilities of the target sequences. As for the distribution of\nsequence length, we also derive the distribution of positive signals for the\nfixed flow cycle model. Explicit formulas are derived for the mean and variance\nof the distributions. A simple result for the mean of the distribution is that\nthe mean number of positive signals in a pyrogram is approximately twice the\nnumber of flow cycles, regardless of nucleotide probabilities. The statistical\ndistributions will be useful for instrument and software development for\npyrosequencing and other related platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.2549v1"
    },
    {
        "title": "Statistical distributions of pyrosequencing",
        "authors": [
            "Yong Kong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Pyrosequencing is emerging as one of the important next-generation sequencing\ntechnologies. We derive the statistical distributions of this technique in\nterms of nucleotide probabilities of the target sequences. We give exact\ndistributions both for fixed number of flow cycles and for fixed sequence\nlength. Explicit formulas are derived for the mean and variance of these\ndistributions. In both cases, the distributions can be approximated accurately\nby normal distributions with the same mean and variance. The statistical\ndistributions will be useful for instrument and software development for\npyrosequencing platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.2668v1"
    },
    {
        "title": "Detecting Differential Expression from RNA-seq Data with Expression\n  Measurement Uncertainty",
        "authors": [
            "Li Zhang",
            "Xuejun Liu",
            "Songcan Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  High-throughput RNA sequencing (RNA-seq) has emerged as a revolutionary and\npowerful technology for expression profiling. Most proposed methods for\ndetecting differentially expressed (DE) genes from RNA-seq are based on\nstatistics that compare normalized read counts between conditions. However,\nthere are few methods considering the expression measurement uncertainty into\nDE detection. Moreover, most methods are only capable of detecting DE genes,\nand few methods are available for detecting DE isoforms. In this paper, a\nBayesian framework (BDSeq) is proposed to detect DE genes and isoforms with\nconsideration of expression measurement uncertainty. This expression\nmeasurement uncertainty provides useful information which can help to improve\nthe performance of DE detection. Three real RAN-seq data sets are used to\nevaluate the performance of BDSeq and results show that the inclusion of\nexpression measurement uncertainty improves accuracy in detection of DE genes\nand isoforms. Finally, we develop a GamSeq-BDSeq RNA-seq analysis pipeline to\nfacilitate users, which is freely available at the website\nhttp://parnec.nuaa.edu.cn/liux/GSBD/GamSeq-BDSeq.html.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.4108v1"
    },
    {
        "title": "Learning interpretable models of phenotypes from whole genome sequences\n  with the Set Covering Machine",
        "authors": [
            "Alexandre Drouin",
            "Sébastien Giguère",
            "Vladana Sagatovich",
            "Maxime Déraspe",
            "François Laviolette",
            "Mario Marchand",
            "Jacques Corbeil"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  The increased affordability of whole genome sequencing has motivated its use\nfor phenotypic studies. We address the problem of learning interpretable models\nfor discrete phenotypes from whole genomes. We propose a general approach that\nrelies on the Set Covering Machine and a k-mer representation of the genomes.\nWe show results for the problem of predicting the resistance of Pseudomonas\nAeruginosa, an important human pathogen, against 4 antibiotics. Our results\ndemonstrate that extremely sparse models which are biologically relevant can be\nlearnt using this approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.1074v1"
    },
    {
        "title": "Will solid-state drives accelerate your bioinformatics? In-depth\n  profiling, performance analysis, and beyond",
        "authors": [
            "Sungmin Lee",
            "Hyeyoung Min",
            "Sungroh Yoon"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  A wide variety of large-scale data has been produced in bioinformatics. In\nresponse, the need for efficient handling of biomedical big data has been\npartly met by parallel computing. However, the time demand of many\nbioinformatics programs still remains high for large-scale practical uses due\nto factors that hinder acceleration by parallelization. Recently, new\ngenerations of storage devices have emerged, such as NAND flash-based\nsolid-state drives (SSDs), and with the renewed interest in near-data\nprocessing, they are increasingly becoming acceleration methods that can\naccompany parallel processing. In certain cases, a simple drop-in replacement\nof hard disk drives (HDDs) by SSDs results in dramatic speedup. Despite the\nvarious advantages and continuous cost reduction of SSDs, there has been little\nreview of SSD-based profiling and performance exploration of important but\ntime-consuming bioinformatics programs. For an informative review, we perform\nin-depth profiling and analysis of 23 key bioinformatics programs using\nmultiple types of devices. Based on the insight we obtain from this research,\nwe further discuss issues related to design and optimize bioinformatics\nalgorithms and pipelines to fully exploit SSDs. The programs we profile cover\ntraditional and emerging areas of importance, such as alignment, assembly,\nmapping, expression analysis, variant calling, and metagenomics. We explain how\nacceleration by parallelization can be combined with SSDs for improved\nperformance and also how using SSDs can expedite important bioinformatics\npipelines, such as variant calling by the Genome Analysis Toolkit (GATK) and\ntranscriptome analysis using RNA sequencing (RNA-seq). We hope that this review\ncan provide useful directions and tips to accompany future bioinformatics\nalgorithm design procedures that properly consider new generations of powerful\nstorage devices.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.02223v2"
    },
    {
        "title": "Spaced seeds improve k-mer-based metagenomic classification",
        "authors": [
            "Karel Brinda",
            "Maciej Sykulski",
            "Gregory Kucherov"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Metagenomics is a powerful approach to study genetic content of environmental\nsamples that has been strongly promoted by NGS technologies. To cope with\nmassive data involved in modern metagenomic projects, recent tools [4, 39] rely\non the analysis of k-mers shared between the read to be classified and sampled\nreference genomes. Within this general framework, we show in this work that\nspaced seeds provide a significant improvement of classification accuracy as\nopposed to traditional contiguous k-mers. We support this thesis through a\nseries a different computational experiments, including simulations of\nlarge-scale metagenomic projects. Scripts and programs used in this study, as\nwell as supplementary material, are available from\nhttp://github.com/gregorykucherov/spaced-seeds-for-metagenomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.06256v3"
    },
    {
        "title": "Genome-wide modelling of transcription kinetics reveals patterns of RNA\n  production delays",
        "authors": [
            "Antti Honkela",
            "Jaakko Peltonen",
            "Hande Topa",
            "Iryna Charapitsa",
            "Filomena Matarese",
            "Korbinian Grote",
            "Hendrik G. Stunnenberg",
            "George Reid",
            "Neil D. Lawrence",
            "Magnus Rattray"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genes with similar transcriptional activation kinetics can display very\ndifferent temporal mRNA profiles due to differences in transcription time,\ndegradation rate and RNA processing kinetics. Recent studies have shown that a\nsplicing-associated RNA production delay can be significant. We introduce a\njoint model of transcriptional activation and mRNA accumulation which can be\nused for inference of transcription rate, RNA production delay and degradation\nrate given genome-wide data from high-throughput sequencing time course\nexperiments. We combine a mechanistic differential equation model with a\nnon-parametric statistical modelling approach allowing us to capture a broad\nrange of activation kinetics, and use Bayesian parameter estimation to quantify\nthe uncertainty in the estimates of the kinetic parameters. We apply the model\nto data from estrogen receptor (ER-{\\alpha}) activation in the MCF-7 breast\ncancer cell line. We use RNA polymerase II (pol-II) ChIP-Seq time course data\nto characterise transcriptional activation and mRNA-Seq time course data to\nquantify mature transcripts. We find that 11% of genes with a good signal in\nthe data display a delay of more than 20 minutes between completing\ntranscription and mature mRNA production. The genes displaying these long\ndelays are significantly more likely to be short. We also find a statistical\nassociation between high delay and late intron retention in pre-mRNA data,\nindicating significant splicing-associated production delays in many genes.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.01081v2"
    },
    {
        "title": "Modelling Computational Resources for Next Generation Sequencing\n  Bioinformatics Analysis of 16S rRNA Samples",
        "authors": [
            "Matthew J. Wade",
            "Thomas P. Curtis",
            "Russell J. Davenport"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  In the rapidly evolving domain of next generation sequencing and\nbioinformatics analysis, data generation is one aspect that is increasing at a\nconcomitant rate. The burden associated with processing large amounts of\nsequencing data has emphasised the need to allocate sufficient computing\nresources to complete analyses in the shortest possible time with manageable\nand predictable costs. A novel method for predicting time to completion for a\npopular bioinformatics software (QIIME), was developed using key variables\ncharacteristic of the input data assumed to impact processing time. Multiple\nLinear Regression models were developed to determine run time for two denoising\nalgorithms and a general bioinformatics pipeline. The models were able to\naccurately predict clock time for denoising sequences from a naturally\nassembled community dataset, but not an artificial community. Speedup and\nefficiency tests for AmpliconNoise also highlighted that caution was needed\nwhen allocating resources for parallel processing of data. Accurate modelling\nof computational processing time using easily measurable predictors can assist\nNGS analysts in determining resource requirements for bioinformatics software\nand pipelines. Whilst demonstrated on a specific group of scripts, the\nmethodology can be extended to encompass other packages running on multiple\narchitectures, either in parallel or sequentially.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.02974v1"
    },
    {
        "title": "Ultra-large alignments using Phylogeny-aware Profiles",
        "authors": [
            "Nam-phuong Nguyen",
            "Siavash Mirarab",
            "Keerthana Kumar",
            "Tandy Warnow"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Many biological questions, including the estimation of deep evolutionary\nhistories and the detection of remote homology between protein sequences, rely\nupon multiple sequence alignments (MSAs) and phylogenetic trees of large\ndatasets. However, accurate large-scale multiple sequence alignment is very\ndifficult, especially when the dataset contains fragmentary sequences. We\npresent UPP, an MSA method that uses a new machine learning technique - the\nEnsemble of Hidden Markov Models - that we propose here. UPP produces highly\naccurate alignments for both nucleotide and amino acid sequences, even on\nultra-large datasets or datasets containing fragmentary sequences. UPP is\navailable at https://github.com/smirarab/sepp.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.01142v1"
    },
    {
        "title": "Utilizing de Bruijn graph of metagenome assembly for metatranscriptome\n  analysis",
        "authors": [
            "Yuzhen Ye",
            "Haixu Tang"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Metagenomics research has accelerated the studies of microbial organisms,\nproviding insights into the composition and potential functionality of various\nmicrobial communities. Metatranscriptomics (studies of the transcripts from a\nmixture of microbial species) and other meta-omics approaches hold even greater\npromise for providing additional insights into functional and regulatory\ncharacteristics of the microbial communities. Current metatranscriptomics\nprojects are often carried out without matched metagenomic datasets (of the\nsame microbial communities). For the projects that produce both\nmetatranscriptomic and metagenomic datasets, their analyses are often not\nintegrated. Metagenome assemblies are far from perfect, partially explaining\nwhy metagenome assemblies are not used for the analysis of metatranscriptomic\ndatasets. Here we report a reads mapping algorithm for mapping of short reads\nonto a de Bruijn graph of assemblies. A hash table of junction k-mers (k-mers\nspanning branching structures in the de Bruijn graph) is used to facilitate\nfast mapping of reads to the graph. We developed an application of this mapping\nalgorithm: a reference based approach to metatranscriptome assembly using\ngraphs of metagenome assembly as the reference. Our results show that this new\napproach (called TAG) helps to assemble substantially more transcripts that\notherwise would have been missed or truncated because of the fragmented nature\nof the reference metagenome. TAG was implemented in C++ and has been tested\nextensively on the linux platform. It is available for download as open source\nat http://omics.informatics.indiana.edu/TAG.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.01304v1"
    },
    {
        "title": "Binding of transcription factors adapts to resolve information-energy\n  trade-off",
        "authors": [
            "Yonatan Savir Jacob Kagan",
            "Tsvi Tlusty"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We examine the binding of transcription factors to DNA in terms of an\ninformation transfer problem. The input of the noisy channel is the biophysical\nsignal of a factor bound to a DNA site, and the output is a distribution of\nprobable DNA sequences at this site. This task involves an inherent tradeoff\nbetween the information gain and the energetics of the binding interaction -\nhigh binding energies provide higher information gain but hinder the dynamics\nof the system as factors are bound too tightly. We show that adaptation of the\nbinding interaction towards increasing information transfer under a general\nenergy constraint implies that the information gain per specific binding energy\nat each base-pair is maximized. We analyze hundreds of prokaryote and eukaryote\ntranscription factors from various organisms to evaluate the discrimination\nenergies. We find that, in accordance with our theoretical argument, binding\nenergies nearly maximize the information gain per energy. This work suggests\nthe adaptation of information gain as a generic design principle of molecular\nrecognition systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01215v2"
    },
    {
        "title": "Greedy Biomarker Discovery in the Genome with Applications to\n  Antimicrobial Resistance",
        "authors": [
            "Alexandre Drouin",
            "Sébastien Giguère",
            "Maxime Déraspe",
            "François Laviolette",
            "Mario Marchand",
            "Jacques Corbeil"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The Set Covering Machine (SCM) is a greedy learning algorithm that produces\nsparse classifiers. We extend the SCM for datasets that contain a huge number\nof features. The whole genetic material of living organisms is an example of\nsuch a case, where the number of feature exceeds 10^7. Three human pathogens\nwere used to evaluate the performance of the SCM at predicting antimicrobial\nresistance. Our results show that the SCM compares favorably in terms of\nsparsity and accuracy against L1 and L2 regularized Support Vector Machines and\nCART decision trees. Moreover, the SCM was the only algorithm that could\nconsider the full feature space. For all other algorithms, the latter had to be\nfiltered as a preprocessing step.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.06249v1"
    },
    {
        "title": "MSPKmerCounter: A Fast and Memory Efficient Approach for K-mer Counting",
        "authors": [
            "Yang Li",
            " XifengYan"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  A major challenge in next-generation genome sequencing (NGS) is to assemble\nmassive overlapping short reads that are randomly sampled from DNA fragments.\nTo complete assembling, one needs to finish a fundamental task in many leading\nassembly algorithms: counting the number of occurrences of k-mers (length-k\nsubstrings in sequences). The counting results are critical for many components\nin assembly (e.g. variants detection and read error correction). For large\ngenomes, the k-mer counting task can easily consume a huge amount of memory,\nmaking it impossible for large-scale parallel assembly on commodity servers.\n  In this paper, we develop MSPKmerCounter, a disk-based approach, to\nefficiently perform k-mer counting for large genomes using a small amount of\nmemory. Our approach is based on a novel technique called Minimum Substring\nPartitioning (MSP). MSP breaks short reads into multiple disjoint partitions\nsuch that each partition can be loaded into memory and processed individually.\nBy leveraging the overlaps among the k-mers derived from the same short read,\nMSP can achieve astonishing compression ratio so that the I/O cost can be\nsignificantly reduced. For the task of k-mer counting, MSPKmerCounter offers a\nvery fast and memory-efficient solution. Experiment results on large real-life\nshort reads data sets demonstrate that MSPKmerCounter can achieve better\noverall performance than state-of-the-art k-mer counting approaches.\n  MSPKmerCounter is available at http://www.cs.ucsb.edu/~yangli/MSPKmerCounter\n",
        "pdf_link": "http://arxiv.org/pdf/1505.06550v1"
    },
    {
        "title": "Hidden Markov Models for Gene Sequence Classification: Classifying the\n  VSG genes in the Trypanosoma brucei Genome",
        "authors": [
            "Andrea Mesa",
            "Sebastián Basterrech",
            "Gustavo Guerberoff",
            "Fernando Alvarez-Valin"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The article presents an application of Hidden Markov Models (HMMs) for\npattern recognition on genome sequences. We apply HMM for identifying genes\nencoding the Variant Surface Glycoprotein (VSG) in the genomes of Trypanosoma\nbrucei (T. brucei) and other African trypanosomes. These are parasitic protozoa\ncausative agents of sleeping sickness and several diseases in domestic and wild\nanimals. These parasites have a peculiar strategy to evade the host's immune\nsystem that consists in periodically changing their predominant cellular\nsurface protein (VSG). The motivation for using patterns recognition methods to\nidentify these genes, instead of traditional homology based ones, is that the\nlevels of sequence identity (amino acid and DNA sequence) amongst these genes\nis often below of what is considered reliable in these methods. Among pattern\nrecognition approaches, HMM are particularly suitable to tackle this problem\nbecause they can handle more naturally the determination of gene edges. We\nevaluate the performance of the model using different number of states in the\nMarkov model, as well as several performance metrics. The model is applied\nusing public genomic data. Our empirical results show that the VSG genes on T.\nbrucei can be safely identified (high sensitivity and low rate of false\npositives) using HMM.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.05367v2"
    },
    {
        "title": "Detecting Community Structures in Hi-C Genomic Data",
        "authors": [
            "Irineo Cabreros",
            "Emmanuel Abbe",
            "Aristotelis Tsirigos"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Community detection (CD) algorithms are applied to Hi-C data to discover new\ncommunities of loci in the 3D conformation of human and mouse DNA. We find that\nCD has some distinct advantages over pre-existing methods: (1) it is capable of\nfinding a variable number of communities, (2) it can detect communities of DNA\nloci either adjacent or distant in the 1D sequence, and (3) it allows us to\nobtain a principled value of k, the number of communities present. Forcing k =\n2, our method recovers earlier findings of Lieberman-Aiden, et al. (2009), but\nletting k be a parameter, our method obtains as optimal value k = 6,\ndiscovering new candidate communities. In addition to discovering large\ncommunities that partition entire chromosomes, we also show that CD can detect\nsmall-scale topologically associating domains (TADs) such as those found in\nDixon, et al. (2012). CD thus provides a natural and flexible statistical\nframework for understanding the folding structure of DNA at multiple scales in\nHi-C data.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.05121v1"
    },
    {
        "title": "An Entropy-Based Technique for Classifying Bacterial Chromosomes\n  According to Synonymous Codon Usage",
        "authors": [
            "Andrew Hart",
            "Servet Martínez"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We present a framework based on conditional entropy and the Dirichlet\ndistribution for classifying chromosomes based on the degree to which they use\nsynonymous codons uniformly or preferentially, that is, whether or not codons\nthat code for an amino acid appear with the same relative frequency. Applying\nthe approach to a large collection of annotated bacterial chromosomes reveals\nthree distinct groups of bacteria.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.04180v1"
    },
    {
        "title": "Estimation of the True Evolutionary Distance under the Fragile Breakage\n  Model",
        "authors": [
            "Nikita Alexeev",
            "Max A. Alekseyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The ability to estimate the evolutionary distance between extant genomes\nplays a crucial role in many phylogenomic studies. Often such estimation is\nbased on the parsimony assumption, implying that the distance between two\ngenomes can be estimated as the rearrangement distance equal the minimal number\nof genome rearrangements required to transform one genome into the other.\nHowever, in reality the parsimony assumption may not always hold, emphasizing\nthe need for estimation that does not rely on the rearrangement distance. The\ndistance that accounts for the actual (rather than minimal) number of\nrearrangements between two genomes is often referred to as the true\nevolutionary distance. While there exists a method for the true evolutionary\ndistance estimation, it however assumes that genomes can be broken by\nrearrangements equally likely at any position in the course of evolution. This\nassumption, known as the random breakage model, has recently been refuted in\nfavor of the more rigorous fragile breakage model postulating that only certain\n\"fragile\" genomic regions are prone to rearrangements.\n  We propose a new method for estimating the true evolutionary distance between\ntwo genomes under the fragile breakage model. We evaluate the proposed method\non simulated genomes, which show its high accuracy. We further apply the\nproposed method for estimation of evolutionary distances within a set of five\nyeast genomes and a set of two fish genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.08002v2"
    },
    {
        "title": "New Error Tolerant Method to Search Long Repeats in Symbol Sequences",
        "authors": [
            "Sergey Tsarev",
            "Michael Sadovsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  A new method to identify all sufficiently long repeating substrings in one or\nseveral symbol sequences is proposed. The method is based on a specific gauge\napplied to symbol sequences that guarantees identification of the repeating\nsubstrings. It allows the matching of substrings to contain a given level of\nerrors. The gauge is based on the development of a heavily sparse dictionary of\nrepeats, thus drastically accelerating the search procedure. Some genomic\napplications illustrate the method.\n  This paper is the extended and detailed version of the presentation at the\nthird International Conference on Algorithms for Computational Biology to be\nheld at Trujillo, Spain, June 21-22, 2016.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.01317v1"
    },
    {
        "title": "GateKeeper: A New Hardware Architecture for Accelerating Pre-Alignment\n  in DNA Short Read Mapping",
        "authors": [
            "Mohammed Alser",
            "Hasan Hassan",
            "Hongyi Xin",
            "Oğuz Ergin",
            "Onur Mutlu",
            "Can Alkan"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Motivation: High throughput DNA sequencing (HTS) technologies generate an\nexcessive number of small DNA segments -- called short reads -- that cause\nsignificant computational burden. To analyze the entire genome, each of the\nbillions of short reads must be mapped to a reference genome based on the\nsimilarity between a read and \"candidate\" locations in that reference genome.\nThe similarity measurement, called alignment, formulated as an approximate\nstring matching problem, is the computational bottleneck because: (1) it is\nimplemented using quadratic-time dynamic programming algorithms, and (2) the\nmajority of candidate locations in the reference genome do not align with a\ngiven read due to high dissimilarity. Calculating the alignment of such\nincorrect candidate locations consumes an overwhelming majority of a modern\nread mapper's execution time. Therefore, it is crucial to develop a fast and\neffective filter that can detect incorrect candidate locations and eliminate\nthem before invoking computationally costly alignment operations. Results: We\npropose GateKeeper, a new hardware accelerator that functions as a\npre-alignment step that quickly filters out most incorrect candidate locations.\nGateKeeper is the first design to accelerate pre-alignment using\nField-Programmable Gate Arrays (FPGAs), which can perform pre-alignment much\nfaster than software. GateKeeper can be integrated with any mapper that\nperforms sequence alignment for verification. When implemented on a single FPGA\nchip, GateKeeper maintains high accuracy (on average >96%) while providing up\nto 90-fold and 130-fold speedup over the state-of-the-art software\npre-alignment techniques, Adjacency Filter and Shifted Hamming Distance (SHD),\nrespectively. The addition of GateKeeper as a pre-alignment step can reduce the\nverification time of the mrFAST mapper by a factor of 10. Availability:\nhttps://github.com/BilkentCompGen/GateKeeper\n",
        "pdf_link": "http://arxiv.org/pdf/1604.01789v3"
    },
    {
        "title": "Factor Models for Cancer Signatures",
        "authors": [
            "Zura Kakushadze",
            "Willie Yu"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  We present a novel method for extracting cancer signatures by applying\nstatistical risk models (http://ssrn.com/abstract=2732453) from quantitative\nfinance to cancer genome data. Using 1389 whole genome sequenced samples from\n14 cancers, we identify an \"overall\" mode of somatic mutational noise. We give\na prescription for factoring out this noise and source code for fixing the\nnumber of signatures. We apply nonnegative matrix factorization (NMF) to genome\ndata aggregated by cancer subtype and filtered using our method. The resultant\nsignatures have substantially lower variability than those from unfiltered\ndata. Also, the computational cost of signature extraction is cut by about a\nfactor of 10. We find 3 novel cancer signatures, including a liver cancer\ndominant signature (96% contribution) and a renal cell carcinoma signature (70%\ncontribution). Our method accelerates finding new cancer signatures and\nimproves their overall stability. Reciprocally, the methods for extracting\ncancer signatures could have interesting applications in quantitative finance.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.08743v4"
    },
    {
        "title": "Identification of repeats in DNA sequences using nucleotide distribution\n  uniformity",
        "authors": [
            "Changchuan Yin"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Repetitive elements are important in genomic structures, functions and\nregulations, yet effective methods in precisely identifying repetitive elements\nin DNA sequences are not fully accessible, and the relationship between\nrepetitive elements and periodicities of genomes is not clearly understood. We\npresent an $\\textit{ab initio}$ method to quantitatively detect repetitive\nelements and infer the consensus repeat pattern in repetitive elements. The\nmethod uses the measure of the distribution uniformity of nucleotides at\nperiodic positions in DNA sequences or genomes. It can identify periodicities,\nconsensus repeat patterns, copy numbers and perfect levels of repetitive\nelements. The results of using the method on different DNA sequences and\ngenomes demonstrate efficacy and accuracy in identifying repeat patterns and\nperiodicities. The complexity of the method is linear with respect to the\nlengths of the analyzed sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.00567v1"
    },
    {
        "title": "Network-regularized Sparse Logistic Regression Models for Clinical Risk\n  Prediction and Biomarker Discovery",
        "authors": [
            "Wenwen Min",
            "Juan Liu",
            "Shihua Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Molecular profiling data (e.g., gene expression) has been used for clinical\nrisk prediction and biomarker discovery. However, it is necessary to integrate\nother prior knowledge like biological pathways or gene interaction networks to\nimprove the predictive ability and biological interpretability of biomarkers.\nHere, we first introduce a general regularized Logistic Regression (LR)\nframework with regularized term $\\lambda \\|\\bm{w}\\|_1 +\n\\eta\\bm{w}^T\\bm{M}\\bm{w}$, which can reduce to different penalties, including\nLasso, elastic net, and network-regularized terms with different $\\bm{M}$. This\nframework can be easily solved in a unified manner by a cyclic coordinate\ndescent algorithm which can avoid inverse matrix operation and accelerate the\ncomputing speed. However, if those estimated $\\bm{w}_i$ and $\\bm{w}_j$ have\nopposite signs, then the traditional network-regularized penalty may not\nperform well. To address it, we introduce a novel network-regularized sparse LR\nmodel with a new penalty $\\lambda \\|\\bm{w}\\|_1 + \\eta|\\bm{w}|^T\\bm{M}|\\bm{w}|$\nto consider the difference between the absolute values of the coefficients. And\nwe develop two efficient algorithms to solve it. Finally, we test our methods\nand compare them with the related ones using simulated and real data to show\ntheir efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.06480v1"
    },
    {
        "title": "Effective Classification of MicroRNA Precursors Using Combinatorial\n  Feature Mining and AdaBoost Algorithms",
        "authors": [
            "Ling Zhong",
            "Jason T. L. Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  MicroRNAs (miRNAs) are non-coding RNAs with approximately 22 nucleotides (nt)\nthat are derived from precursor molecules. These precursor molecules or\npre-miRNAs often fold into stem-loop hairpin structures. However, a large\nnumber of sequences with pre-miRNA-like hairpins can be found in genomes. It is\na challenge to distinguish the real pre-miRNAs from other hairpin sequences\nwith similar stem-loops (referred to as pseudo pre-miRNAs). Several\ncomputational methods have been developed to tackle this challenge. In this\npaper we propose a new method, called MirID, for identifying and classifying\nmicroRNA precursors. We collect 74 features from the sequences and secondary\nstructures of pre-miRNAs; some of these features are taken from our previous\nstudies on non-coding RNA prediction while others were suggested in the\nliterature. We develop a combinatorial feature mining algorithm to identify\nsuitable feature sets. These feature sets are then used to train support vector\nmachines to obtain classification models, based on which classifier ensemble is\nconstructed. Finally we use an AdaBoost algorithm to further enhance the\naccuracy of the classifier ensemble. Experimental results on a variety of\nspecies demonstrate the good performance of the proposed method, and its\nsuperiority over existing tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.02281v1"
    },
    {
        "title": "*K-means and Cluster Models for Cancer Signatures",
        "authors": [
            "Zura Kakushadze",
            "Willie Yu"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We present *K-means clustering algorithm and source code by expanding\nstatistical clustering methods applied in https://ssrn.com/abstract=2802753 to\nquantitative finance. *K-means is statistically deterministic without\nspecifying initial centers, etc. We apply *K-means to extracting cancer\nsignatures from genome data without using nonnegative matrix factorization\n(NMF). *K-means' computational cost is a fraction of NMF's. Using 1,389\npublished samples for 14 cancer types, we find that 3 cancers (liver cancer,\nlung cancer and renal cell carcinoma) stand out and do not have cluster-like\nstructures. Two clusters have especially high within-cluster correlations with\n11 other cancers indicating common underlying structures. Our approach opens a\nnovel avenue for studying such structures. *K-means is universal and can be\napplied in other fields. We discuss some potential applications in quantitative\nfinance.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.00703v4"
    },
    {
        "title": "SIMLR: A Tool for Large-Scale Genomic Analyses by Multi-Kernel Learning",
        "authors": [
            "Bo Wang",
            "Daniele Ramazzotti",
            "Luca De Sano",
            "Junjie Zhu",
            "Emma Pierson",
            "Serafim Batzoglou"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We here present SIMLR (Single-cell Interpretation via Multi-kernel LeaRning),\nan open-source tool that implements a novel framework to learn a\nsample-to-sample similarity measure from expression data observed for\nheterogenous samples. SIMLR can be effectively used to perform tasks such as\ndimension reduction, clustering, and visualization of heterogeneous populations\nof samples. SIMLR was benchmarked against state-of-the-art methods for these\nthree tasks on several public datasets, showing it to be scalable and capable\nof greatly improving clustering performance, as well as providing valuable\ninsights by making the data more interpretable via better a visualization.\nAvailability and Implementation\n  SIMLR is available on GitHub in both R and MATLAB implementations.\nFurthermore, it is also available as an R package on http://bioconductor.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.07844v2"
    },
    {
        "title": "Family-specific scaling laws in bacterial genomes",
        "authors": [
            "Eleonora de Lazzari",
            "Jacopo Grilli",
            "Sergei Maslov",
            "Marco Cosentino Lagomarsino"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Among several quantitative invariants found in evolutionary genomics, one of\nthe most striking is the scaling of the overall abundance of proteins, or\nprotein domains, sharing a specific functional annotation across genomes of\ngiven size. The size of these functional categories change, on average, as\npower-laws in the total number of protein-coding genes. Here, we show that such\nregularities are not restricted to the overall behavior of high-level\nfunctional categories, but also exist systematically at the level of single\nevolutionary families of protein domains. Specifically, the number of proteins\nwithin each family follows family-specific scaling laws with genome size.\nFunctionally similar sets of families tend to follow similar scaling laws, but\nthis is not always the case. To understand this systematically, we provide a\ncomprehensive classification of families based on their scaling properties.\nAdditionally, we develop a quantitative score for the heterogeneity of the\nscaling of families belonging to a given category or predefined group. Under\nthe common reasonable assumption that selection is driven solely or mainly by\nbiological function, these findings point to fine-tuned and interdependent\nfunctional roles of specific protein domains, beyond our current functional\nannotations. This analysis provides a deeper view on the links between\nevolutionary expansion of protein families and the functional constraints\nshaping the gene repertoire of bacterial genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.09822v1"
    },
    {
        "title": "Multi-Kernel LS-SVM Based Bio-Clinical Data Integration: Applications to\n  Ovarian Cancer",
        "authors": [
            "Jaya Thomas",
            "Lee Sael"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  The medical research facilitates to acquire a diverse type of data from the\nsame individual for particular cancer. Recent studies show that utilizing such\ndiverse data results in more accurate predictions. The major challenge faced is\nhow to utilize such diverse data sets in an effective way. In this paper, we\nintroduce a multiple kernel based pipeline for integrative analysis of\nhigh-throughput molecular data (somatic mutation, copy number alteration, DNA\nmethylation and mRNA) and clinical data. We apply the pipeline on Ovarian\ncancer data from TCGA. After multiple kernels have been generated from the\nweighted sum of individual kernels, it is used to stratify patients and predict\nclinical outcomes. We examine the survival time, vital status, and neoplasm\ncancer status of each subtype to verify how well they cluster. We have also\nexamined the power of molecular and clinical data in predicting dichotomized\noverall survival data and to classify the tumor grade for the cancer samples.\nIt was observed that the integration of various data types yields higher\nlog-rank statistics value. We were also able to predict clinical status with\nhigher accuracy as compared to using individual data types.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.02846v2"
    },
    {
        "title": "Network-based coverage of mutational profiles reveals cancer genes",
        "authors": [
            "Borislav H. Hristov",
            "Mona Singh"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  A central goal in cancer genomics is to identify the somatic alterations that\nunderpin tumor initiation and progression. This task is challenging as the\nmutational profiles of cancer genomes exhibit vast heterogeneity, with many\nalterations observed within each individual, few shared somatically mutated\ngenes across individuals, and important roles in cancer for both frequently and\ninfrequently mutated genes. While commonly mutated cancer genes are readily\nidentifiable, those that are rarely mutated across samples are difficult to\ndistinguish from the large numbers of other infrequently mutated genes. Here,\nwe introduce a method that considers per-individual mutational profiles within\nthe context of protein-protein interaction networks in order to identify small\nconnected subnetworks of genes that, while not individually frequently mutated,\ncomprise pathways that are perturbed across (i.e., \"cover\") a large fraction of\nthe individuals. We devise a simple yet intuitive objective function that\nbalances identifying a small subset of genes with covering a large fraction of\nindividuals. We show how to solve this problem optimally using integer linear\nprogramming and also give a fast heuristic algorithm that works well in\npractice. We perform a large-scale evaluation of our resulting method, nCOP, on\n6,038 TCGA tumor samples across 24 different cancer types. We demonstrate that\nour approach nCOP is more effective in identifying cancer genes than both\nmethods that do not utilize any network information as well as state-of-the-art\nnetwork-based methods that aggregate mutational information across individuals.\nOverall, our work demonstrates the power of combining per-individual mutational\ninformation with interaction networks in order to uncover genes functionally\nrelevant in cancers, and in particular those genes that are less frequently\nmutated.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.08544v1"
    },
    {
        "title": "DeepGO: Predicting protein functions from sequence and interactions\n  using a deep ontology-aware classifier",
        "authors": [
            "Maxat Kulmanov",
            "Mohammed Asif Khan",
            "Robert Hoehndorf"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  A large number of protein sequences are becoming available through the\napplication of novel high-throughput sequencing technologies. Experimental\nfunctional characterization of these proteins is time-consuming and expensive,\nand is often only done rigorously for few selected model organisms.\nComputational function prediction approaches have been suggested to fill this\ngap. The functions of proteins are classified using the Gene Ontology (GO),\nwhich contains over 40,000 classes. Additionally, proteins have multiple\nfunctions, making function prediction a large-scale, multi-class, multi-label\nproblem.\n  We have developed a novel method to predict protein function from sequence.\nWe use deep learning to learn features from protein sequences as well as a\ncross-species protein-protein interaction network. Our approach specifically\noutputs information in the structure of the GO and utilizes the dependencies\nbetween GO classes as background information to construct a deep learning\nmodel. We evaluate our method using the standards established by the\nComputational Assessment of Function Annotation (CAFA) and demonstrate a\nsignificant improvement over baseline methods such as BLAST, with significant\nimprovement for predicting cellular locations.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.05919v1"
    },
    {
        "title": "Accurate Genomic Prediction Of Human Height",
        "authors": [
            "Louis Lello",
            "Steven G. Avery",
            "Laurent Tellier",
            "Ana Vazquez",
            "Gustavo de los Campos",
            "Stephen D. H. Hsu"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We construct genomic predictors for heritable and extremely complex human\nquantitative traits (height, heel bone density, and educational attainment)\nusing modern methods in high dimensional statistics (i.e., machine learning).\nReplication tests show that these predictors capture, respectively, $\\sim$40,\n20, and 9 percent of total variance for the three traits. For example,\npredicted heights correlate $\\sim$0.65 with actual height; actual heights of\nmost individuals in validation samples are within a few cm of the prediction.\nThe variance captured for height is comparable to the estimated SNP\nheritability from GCTA (GREML) analysis, and seems to be close to its\nasymptotic value (i.e., as sample size goes to infinity), suggesting that we\nhave captured most of the heritability for the SNPs used. Thus, our results\nresolve the common SNP portion of the \"missing heritability\" problem -- i.e.,\nthe gap between prediction R-squared and SNP heritability. The $\\sim$20k\nactivated SNPs in our height predictor reveal the genetic architecture of human\nheight, at least for common SNPs. Our primary dataset is the UK Biobank cohort,\ncomprised of almost 500k individual genotypes with multiple phenotypes. We also\nuse other datasets and SNPs found in earlier GWAS for out-of-sample validation\nof our results.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.06489v1"
    },
    {
        "title": "Attention based convolutional neural network for predicting RNA-protein\n  binding sites",
        "authors": [
            "Xiaoyong Pan",
            "Junchi Yan"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  RNA-binding proteins (RBPs) play crucial roles in many biological processes,\ne.g. gene regulation. Computational identification of RBP binding sites on RNAs\nare urgently needed. In particular, RBPs bind to RNAs by recognizing sequence\nmotifs. Thus, fast locating those motifs on RNA sequences is crucial and\ntime-efficient for determining whether the RNAs interact with the RBPs or not.\nIn this study, we present an attention based convolutional neural network,\niDeepA, to predict RNA-protein binding sites from raw RNA sequences. We first\nencode RNA sequences into one-hot encoding. Next, we design a deep learning\nmodel with a convolutional neural network (CNN) and an attention mechanism,\nwhich automatically search for important positions, e.g. binding motifs, to\nlearn discriminant high-level features for predicting RBP binding sites. We\nevaluate iDeepA on publicly gold-standard RBP binding sites derived from\nCLIP-seq data. The results demonstrate iDeepA achieves comparable performance\nwith other state-of-the-art methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.02270v1"
    },
    {
        "title": "Two-Tier Mapper: a user-independent clustering method for global gene\n  expression analysis based on topology",
        "authors": [
            "Rachel Jeitziner",
            "Mathieu Carrière",
            "Jacques Rougemont",
            "Steve Oudot",
            "Kathryn Hess",
            "Cathrin Brisken"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  There is a growing need for unbiased clustering methods, ideally automated.\nWe have developed a topology-based analysis tool called Two-Tier Mapper (TTMap)\nto detect subgroups in global gene expression datasets and identify their\ndistinguishing features. First, TTMap discerns and adjusts for highly variable\nfeatures in the control group and identifies outliers. Second, the deviation of\neach test sample from the control group in a high-dimensional space is computed\nand the test samples are clustered in a global and local network using a new\ntopological algorithm based on Mapper. Validation of TTMap on both synthetic\nand biological datasets shows that it outperforms current clustering methods in\nsensitivity and stability; clustering is not affected by removal of samples\nfrom the control group, choice of normalization nor subselection of data. There\nis no user induced bias because all parameters are data-driven. Datasets can\nreadily be combined into one analysis. TTMap reveals hitherto undetected gene\nexpression changes in mouse mammary glands related to hormonal changes during\nthe estrous cycle. This illustrates the ability to extract information from\nhighly variable biological samples and its potential for personalized medicine.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.01841v1"
    },
    {
        "title": "Drug response prediction by ensemble learning and drug-induced gene\n  expression signatures",
        "authors": [
            "Mehmet Tan",
            "Ozan Fırat Özgül",
            "Batuhan Bardak",
            "Işıksu Ekşioğlu",
            "Suna Sabuncuoğlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Chemotherapeutic response of cancer cells to a given compound is one of the\nmost fundamental information one requires to design anti-cancer drugs. Recent\nadvances in producing large drug screens against cancer cell lines provided an\nopportunity to apply machine learning methods for this purpose. In addition to\ncytotoxicity databases, considerable amount of drug-induced gene expression\ndata has also become publicly available. Following this, several methods that\nexploit omics data were proposed to predict drug activity on cancer cells.\nHowever, due to the complexity of cancer drug mechanisms, none of the existing\nmethods are perfect. One possible direction, therefore, is to combine the\nstrengths of both the methods and the databases for improved performance. We\ndemonstrate that integrating a large number of predictions by the proposed\nmethod improves the performance for this task. The predictors in the ensemble\ndiffer in several aspects such as the method itself, the number of tasks method\nconsiders (multi-task vs. single-task) and the subset of data considered\n(sub-sampling). We show that all these different aspects contribute to the\nsuccess of the final ensemble. In addition, we attempt to use the drug screen\ndata together with two novel signatures produced from the drug-induced gene\nexpression profiles of cancer cell lines. Finally, we evaluate the method\npredictions by in vitro experiments in addition to the tests on data sets.The\npredictions of the methods, the signatures and the software are available from\n\\url{http://mtan.etu.edu.tr/drug-response-prediction/}.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03800v3"
    },
    {
        "title": "SMAGEXP: a galaxy tool suite for transcriptomics data meta-analysis",
        "authors": [
            "Samuel Blanck",
            "Guillemette Marot"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Bakground: With the proliferation of available microarray and high throughput\nsequencing experiments in the public domain, the use of meta-analysis methods\nincreases. In these experiments, where the sample size is often limited,\nmeta-analysis offers the possibility to considerably enhance the statistical\npower and give more accurate results. For those purposes, it combines either\neffect sizes or results of single studies in a appropriate manner. R packages\nmetaMA and metaRNASeq perform meta-analysis on microarray and NGS data,\nrespectively. They are not interchangeable as they rely on statistical modeling\nspecific to each technology.\n  Results: SMAGEXP (Statistical Meta-Analysis for Gene EXPression) integrates\nmetaMA and metaRNAseq packages into Galaxy. We aim to propose a unified way to\ncarry out meta-analysis of gene expression data, while taking care of their\nspecificities. We have developed this tool suite to analyse microarray data\nfrom Gene Expression Omnibus (GEO) database or custom data from affymetrix\nmicroarrays. These data are then combined to carry out meta-analysis using\nmetaMA package. SMAGEXP also offers to combine raw read counts from Next\nGeneration Sequencing (NGS) experiments using DESeq2 and metaRNASeq package. In\nboth cases, key values, independent from the technology type, are reported to\njudge the quality of the meta-analysis. These tools are available on the Galaxy\nmain tool shed. Source code, help and installation instructions are available\non github.\n  Conclusion: The use of Galaxy offers an easy-to-use gene expression\nmeta-analysis tool suite based on the metaMA and metaRNASeq packages.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.08251v1"
    },
    {
        "title": "Routinely quantifying single cell proteomes: A new age in quantitative\n  biology and medicine",
        "authors": [
            "Harrison Specht",
            "Nikolai Slavov"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Many pressing medical challenges - such as diagnosing disease, enhancing\ndirected stem cell differentiation, and classifying cancers - have long been\nhindered by limitations in our ability to quantify proteins in single cells.\nMass-spectrometry (MS) is poised to transcend these limitations by developing\npowerful methods to routinely quantify thousands of proteins and proteoforms\nacross many thousands of single cells. We outline specific technological\ndevelopments and ideas that can increase the sensitivity and throughput of\nsingle cell MS by orders of magnitude and usher in this new age. These advances\nwill transform medicine and ultimately contribute to understanding biological\nsystems on an entirely new level.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.01069v1"
    },
    {
        "title": "Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for\n  Optimizing Protein Functions",
        "authors": [
            "Anvita Gupta",
            "James Zou"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Generative Adversarial Networks (GANs) represent an attractive and novel\napproach to generate realistic data, such as genes, proteins, or drugs, in\nsynthetic biology. Here, we apply GANs to generate synthetic DNA sequences\nencoding for proteins of variable length. We propose a novel feedback-loop\narchitecture, called Feedback GAN (FBGAN), to optimize the synthetic gene\nsequences for desired properties using an external function analyzer. The\nproposed architecture also has the advantage that the analyzer need not be\ndifferentiable. We apply the feedback-loop mechanism to two examples: 1)\ngenerating synthetic genes coding for antimicrobial peptides, and 2) optimizing\nsynthetic genes for the secondary structure of their resulting peptides. A\nsuite of metrics demonstrate that the GAN generated proteins have desirable\nbiophysical properties. The FBGAN architecture can also be used to optimize\nGAN-generated datapoints for useful properties in domains beyond genomics.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.01694v1"
    },
    {
        "title": "Analysis of Extremely Obese Individuals Using Deep Learning Stacked\n  Autoencoders and Genome-Wide Genetic Data",
        "authors": [
            "Casimiro A. Curbelo Montañez",
            "Paul Fergus",
            "Carl Chalmers",
            "Jade Hind"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  The aetiology of polygenic obesity is multifactorial, which indicates that\nlife-style and environmental factors may influence multiples genes to aggravate\nthis disorder. Several low-risk single nucleotide polymorphisms (SNPs) have\nbeen associated with BMI. However, identified loci only explain a small\nproportion of the variation ob-served for this phenotype. The linear nature of\ngenome wide association studies (GWAS) used to identify associations between\ngenetic variants and the phenotype have had limited success in explaining the\nheritability variation of BMI and shown low predictive capacity in\nclassification studies. GWAS ignores the epistatic interactions that less\nsignificant variants have on the phenotypic outcome. In this paper we utilise a\nnovel deep learning-based methodology to reduce the high dimensional space in\nGWAS and find epistatic interactions between SNPs for classification purposes.\nSNPs were filtered based on the effects associations have with BMI. Since\nBonferroni adjustment for multiple testing is highly conservative, an important\nproportion of SNPs involved in SNP-SNP interactions are ignored. Therefore,\nonly SNPs with p-values < 1x10-2 were considered for subsequent epistasis\nanalysis using stacked auto encoders (SAE). This allows the nonlinearity\npresent in SNP-SNP interactions to be discovered through progressively smaller\nhidden layer units and to initialise a multi-layer feedforward artificial\nneural network (ANN) classifier. The classifier is fine-tuned to classify\nextremely obese and non-obese individuals. The best results were obtained with\n2000 compressed units (SE=0.949153, SP=0.933014, Gini=0.949936,\nLo-gloss=0.1956, AUC=0.97497 and MSE=0.054057). Using 50 compressed units it\nwas possible to achieve (SE=0.785311, SP=0.799043, Gini=0.703566,\nLogloss=0.476864, AUC=0.85178 and MSE=0.156315).\n",
        "pdf_link": "http://arxiv.org/pdf/1804.06262v2"
    },
    {
        "title": "FPGA Acceleration of Short Read Alignment",
        "authors": [
            "Nathaniel McVicar",
            "Akina Hoshino",
            "Anna La Torre",
            "Thomas A. Reh",
            "Walter L. Ruzzo",
            "Scott Hauck"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Aligning millions of short DNA or RNA reads, of 75 to 250 base pairs each, to\na reference genome is a significant computation problem in bioinformatics. We\npresent a flexible and fast FPGA-based short read alignment tool. Our aligner\nmakes use of the processing power of FPGAs in conjunction with the greater host\nmemory bandwidth and flexibility of software to improve performance and achieve\na high level of configurability. This flexible design supports a variety of\nreference genome sizes without the performance degradation suffered by other\nsoftware and FPGA-based aligners. It is also better able to support the\nfeatures of new alignment algorithms, which frequently crop up in the rapidly\nevolving field of bioinformatics. We demonstrate these advantages in a case\nstudy where we align RNA-Seq data from a hypothesized mouse / human xenograft.\nIn this case study, our aligner provides a speedup of 5.6x over BWA-SW with\nenergy savings of 21%, while also reducing incorrect short read classification\nby 29%. To demonstrate the flexibility of our system we show that the speedup\ncan be substantially improved while retaining most of the accuracy gains over\nBWA-SW. The speedup can be increased to 71.3x, while still enjoying a 28%\nincorrect classification improvement and 52% improvement in unaligned reads.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.00106v1"
    },
    {
        "title": "Prediction of a Gene Regulatory Network from Gene Expression Profiles\n  With Linear Regression and Pearson Correlation Coefficient",
        "authors": [
            "Md Mehedi Hassan Onik",
            "Shakhawat Ahmmed Nobin",
            "Adnan Ferdous Ashrafi",
            "Tareque Mohmud Chowdhury"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Reconstruction of gene regulatory networks is the process of identifying gene\ndependency from gene expression profile through some computation techniques. In\nour human body, though all cells pose similar genetic material but the\nactivation state may vary. This variation in the activation of genes helps\nresearchers to understand more about the function of the cells. Researchers get\ninsight about diseases like mental illness, infectious disease, cancer disease\nand heart disease from microarray technology, etc. In this study, a\ncancer-specific gene regulatory network has been constructed using a simple and\nnovel machine learning approach. In First Step, linear regression algorithm\nprovided us the significant genes those expressed themselves differently. Next,\nregulatory relationships between the identified genes has been computed using\nPearson correlation coefficient. Finally, the obtained results have been\nvalidated with the available databases and literatures. We can identify the hub\ngenes and can be targeted for the cancer diagnosis.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.01506v1"
    },
    {
        "title": "Mapping the spectrum of 3D communities in human chromosome conformation\n  capture data",
        "authors": [
            "Sang Hoon Lee",
            "Yeonghoon Kim",
            "Sungmin Lee",
            "Xavier Durang",
            "Per Stenberg",
            "Jae-Hyung Jeon",
            "Ludvig Lizana"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Several experiments show that the three dimensional (3D) organization of\nchromosomes affects genetic processes such as transcription and gene\nregulation. To better understand this connection, researchers developed the\nHi-C method that is able to detect the pairwise physical contacts of all\nchromosomal loci. The Hi-C data show that chromosomes are composed of 3D\ncompartments that range over a variety of scales. However, it is challenging to\nsystematically detect these cross-scale structures. Most studies have therefore\ndesigned methods for specific scales to study foremost topologically associated\ndomains (TADs) and A/B compartments. To go beyond this limitation, we tailor a\nnetwork community detection method that finds communities in compact fractal\nglobule polymer systems. Our method allows us to continuously scan through all\nscales with a single resolution parameter. We found: (i) polymer segments\nbelonging to the same 3D community do not have to be in consecutive order along\nthe polymer chain. In other words, several TADs may belong to the same 3D\ncommunity. (ii) CTCF proteins---a loop-stabilizing protein that is ascribed a\nbig role in TAD formation---are well correlated with community borders only at\none level of organization. (iii) TADs and A/B compartments are traditionally\ntreated as two weakly related 3D structures and detected with different\nalgorithms. With our method, we detect both by simply adjusting the resolution\nparameter. We therefore argue that they represent two specific levels of a\ncontinuous spectrum 3D communities, rather than seeing them as different\nstructural entities.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01307v2"
    },
    {
        "title": "PromID: human promoter prediction by deep learning",
        "authors": [
            "Ramzan Umarov",
            "Hiroyuki Kuwahara",
            "Yu Li",
            "Xin Gao",
            "Victor Solovyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Computational identification of promoters is notoriously difficult as human\ngenes often have unique promoter sequences that provide regulation of\ntranscription and interaction with transcription initiation complex. While\nthere are many attempts to develop computational promoter identification\nmethods, we have no reliable tool to analyze long genomic sequences. In this\nwork we further develop our deep learning approach that was relatively\nsuccessful to discriminate short promoter and non-promoter sequences. Instead\nof focusing on the classification accuracy, in this work we predict the exact\npositions of the TSS inside the genomic sequences testing every possible\nlocation. We studied human promoters to find effective regions for\ndiscrimination and built corresponding deep learning models. These models use\nadaptively constructed negative set which iteratively improves the models\ndiscriminative ability. The developed promoter identification models\nsignificantly outperform the previously developed promoter prediction programs\nby considerably reducing the number of false positive predictions. The best\nmodel we have built has recall 0.76, precision 0.77 and MCC 0.76, while the\nnext best tool FPROM achieved precision 0.48 and MCC 0.60 for the recall of\n0.75. Our method is available at http://www.cbrc.kaust.edu.sa/PromID/.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01414v1"
    },
    {
        "title": "Towards the Latent Transcriptome",
        "authors": [
            "Assya Trofimov",
            "Francis Dutil",
            "Claude Perreault",
            "Sebastien Lemieux",
            "Yoshua Bengio",
            "Joseph Paul Cohen"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  In this work we propose a method to compute continuous embeddings for kmers\nfrom raw RNA-seq data, without the need for alignment to a reference genome.\nThe approach uses an RNN to transform kmers of the RNA-seq reads into a 2\ndimensional representation that is used to predict abundance of each kmer. We\nreport that our model captures information of both DNA sequence similarity as\nwell as DNA sequence abundance in the embedding latent space, that we call the\nLatent Transcriptome. We confirm the quality of these vectors by comparing them\nto known gene sub-structures and report that the latent space recovers exon\ninformation from raw RNA-Seq data from acute myeloid leukemia patients.\nFurthermore we show that this latent space allows the detection of genomic\nabnormalities such as translocations as well as patient-specific mutations,\nmaking this representation space both useful for visualization as well as\nanalysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.03442v2"
    },
    {
        "title": "conLSH: Context based Locality Sensitive Hashing for Mapping of noisy\n  SMRT Reads",
        "authors": [
            "Angana Chakraborty",
            "Sanghamitra Bandyopadhyay"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Single Molecule Real-Time (SMRT) sequencing is a recent advancement of Next\nGen technology developed by Pacific Bio (PacBio). It comes with an explosion of\nlong and noisy reads demanding cutting edge research to get most out of it. To\ndeal with the high error probability of SMRT data, a novel contextual Locality\nSensitive Hashing (conLSH) based algorithm is proposed in this article, which\ncan effectively align the noisy SMRT reads to the reference genome. Here,\nsequences are hashed together based not only on their closeness, but also on\nsimilarity of context. The algorithm has $\\mathcal{O}(n^{\\rho+1})$ space\nrequirement, where $n$ is the number of sequences in the corpus and $\\rho$ is a\nconstant. The indexing time and querying time are bounded by $\\mathcal{O}(\n\\frac{n^{\\rho+1} \\cdot \\ln n}{\\ln \\frac{1}{P_2}})$ and $\\mathcal{O}(n^\\rho)$\nrespectively, where $P_2 > 0$, is a probability value. This algorithm is\nparticularly useful for retrieving similar sequences, a widely used task in\nbiology. The proposed conLSH based aligner is compared with rHAT, popularly\nused for aligning SMRT reads, and is found to comprehensively beat it in speed\nas well as in memory requirements. In particular, it takes approximately\n$24.2\\%$ less processing time, while saving about $70.3\\%$ in peak memory\nrequirement for H.sapiens PacBio dataset.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.04925v1"
    },
    {
        "title": "Genomics-guided drawing of malignant regulatory signatures revealed a\n  pivotal role of human stem cell-associated retroviral sequences (SCARS) and\n  functionally-active hESC enhancers",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  From patients and physicians perspectives, the clinical definition of a tumor\nmalignant phenotype could be restricted to the early diagnosis of sub-types of\nmalignancies with the increased risk of existing therapy failure and high\nlikelihood of death from cancer. It is the viewpoint from which the\nunderstanding of malignant regulatory signatures is considered in this\ncontribution. Analyses from this perspective of experimental and clinical\nobservations revealed the pivotal role of human stem cell-associated retroviral\nsequences (SCARS) in the origin and pathophysiology of clinically-lethal\nmalignancies. SCARS represent evolutionary- and biologically-related family of\ngenomic regulatory sequences, the principal physiological function of which is\nto create and maintain the stemness phenotype during human preimplantation\nembryogenesis. SCARS expression must be silenced during cellular\ndifferentiation and SCARS activity remains silent in most\nterminally-differentiated human cells performing specialized functions in the\nhuman body. De-repression and sustained activation of SCARS result in\ndifferentiation-defective phenotypes, tissue- and organ-specific clinical\nmanifestations of which are diagnosed as pathological conditions defined by a\nconsensus of pathomorphological, molecular, and genetic examinations as the\nmalignant growth. Contemporary evidence are presented that high-fidelity\nmolecular signals of continuing activities of SCARS in association with genomic\nregulatory networks of thousands functionally-active enhancers triggering\nengagements of down-stream genetic loci may serve as both reliable diagnostic\ntools and druggable molecular targets readily amenable for diagnosis and\nefficient therapeutic management of clinically-lethal malignancies.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.00687v1"
    },
    {
        "title": "Mutation Clusters from Cancer Exome",
        "authors": [
            "Zura Kakushadze",
            "Willie Yu"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We apply our statistically deterministic machine learning/clustering\nalgorithm *K-means (recently developed in https://ssrn.com/abstract=2908286) to\n10,656 published exome samples for 32 cancer types. A majority of cancer types\nexhibit mutation clustering structure. Our results are in-sample stable. They\nare also out-of-sample stable when applied to 1,389 published genome samples\nacross 14 cancer types. In contrast, we find in- and out-of-sample\ninstabilities in cancer signatures extracted from exome samples via nonnegative\nmatrix factorization (NMF), a computationally costly and non-deterministic\nmethod. Extracting stable mutation structures from exome data could have\nimportant implications for speed and cost, which are critical for early-stage\ncancer diagnostics such as novel blood-test methods currently in development.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.08504v1"
    },
    {
        "title": "Disease State Prediction From Single-Cell Data Using Graph Attention\n  Networks",
        "authors": [
            "Neal G. Ravindra",
            "Arijit Sehanobish",
            "Jenna L. Pappalardo",
            "David A. Hafler",
            "David van Dijk"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Single-cell RNA sequencing (scRNA-seq) has revolutionized biological\ndiscovery, providing an unbiased picture of cellular heterogeneity in tissues.\nWhile scRNA-seq has been used extensively to provide insight into both healthy\nsystems and diseases, it has not been used for disease prediction or\ndiagnostics. Graph Attention Networks (GAT) have proven to be versatile for a\nwide range of tasks by learning from both original features and graph\nstructures. Here we present a graph attention model for predicting disease\nstate from single-cell data on a large dataset of Multiple Sclerosis (MS)\npatients. MS is a disease of the central nervous system that can be difficult\nto diagnose. We train our model on single-cell data obtained from blood and\ncerebrospinal fluid (CSF) for a cohort of seven MS patients and six healthy\nadults (HA), resulting in 66,667 individual cells. We achieve 92 % accuracy in\npredicting MS, outperforming other state-of-the-art methods such as a graph\nconvolutional network and a random forest classifier. Further, we use the\nlearned graph attention model to get insight into the features (cell types and\ngenes) that are important for this prediction. The graph attention model also\nallow us to infer a new feature space for the cells that emphasizes the\ndifferences between the two conditions. Finally we use the attention weights to\nlearn a new low-dimensional embedding that can be visualized. To the best of\nour knowledge, this is the first effort to use graph attention, and deep\nlearning in general, to predict disease state from single-cell data. We\nenvision applying this method to single-cell data for other diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.07128v2"
    },
    {
        "title": "Map of Life: Measuring and Visualizing Species' Relatedness with\n  \"Molecular Distance Maps\"",
        "authors": [
            "Lila Kari",
            "Kathleen A. Hill",
            "Abu Sadat Sayem",
            "Nathaniel Bryans",
            "Katelyn Davis",
            "Nikesh S. Dattani"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We propose a novel combination of methods that (i) portrays quantitative\ncharacteristics of a DNA sequence as an image, (ii) computes distances between\nthese images, and (iii) uses these distances to output a map wherein each\nsequence is a point in a common Euclidean space. In the resulting \"Molecular\nDistance Map\" each point signifies a DNA sequence, and the geometric distance\nbetween any two points reflects the degree of relatedness between the\ncorresponding sequences and species.\n  Molecular Distance Maps present compelling visual representations of\nrelationships between species and could be used for taxonomic clarifications,\nfor species identification, and for studies of evolutionary history. One of the\nadvantages of this method is its general applicability since, as sequence\nalignment is not required, the DNA sequences chosen for comparison can be\ncompletely different regions in different genomes. In fact, this method can be\nused to compare any two DNA sequences. For example, in our dataset of 3,176\nmitochondrial DNA sequences, it correctly finds the mtDNA sequences most\nclosely related to that of the anatomically modern human (the Neanderthal, the\nDenisovan, and the chimp), and it finds that the sequence most different from\nit belongs to a cucumber. Furthermore, our method can be used to compare real\nsequences to artificial, computer-generated, DNA sequences. For example, it is\nused to determine that the distances between a Homo sapiens sapiens mtDNA and\nartificial sequences of the same length and same trinucleotide frequencies can\nbe larger than the distance between the same human mtDNA and the mtDNA of a\nfruit-fly.\n  We demonstrate this method's promising potential for taxonomical\nclarifications by applying it to a diverse variety of cases that have been\nhistorically controversial, such as the genus Polypterus, the family Tarsiidae,\nand the vast (super)kingdom Protista.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3755v1"
    },
    {
        "title": "Bayesian Neural Networks for Genetic Association Studies of Complex\n  Disease",
        "authors": [
            "Andrew L. Beam",
            "Alison Motsinger-Reif",
            "Jon Doyle"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Discovering causal genetic variants from large genetic association studies\nposes many difficult challenges. Assessing which genetic markers are involved\nin determining trait status is a computationally demanding task, especially in\nthe presence of gene-gene interactions. A non-parametric Bayesian approach in\nthe form of a Bayesian neural network is proposed for use in analyzing genetic\nassociation studies. Demonstrations on synthetic and real data reveal they are\nable to efficiently and accurately determine which variants are involved in\ndetermining case-control status. Using graphics processing units (GPUs) the\ntime needed to build these models is decreased by several orders of magnitude.\nIn comparison with commonly used approaches for detecting genetic interactions,\nBayesian neural networks perform very well across a broad spectrum of possible\ngenetic relationships while having the computational efficiency needed to\nhandle large datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3989v2"
    },
    {
        "title": "Algorithms for determining transposons in gene sequences",
        "authors": [
            "Yue Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Some genes can change their relative locations in a genome. Thus for\ndifferent individuals of the same species, the orders of genes might be\ndifferent. Such jumping genes are called transposons. A practical problem is to\ndetermine transposons in given gene sequences. Through an intuitive rule, we\ntransform the biological problem of determining transposons into a rigorous\nmathematical problem of determining the longest common subsequence. Depending\non whether the gene sequence is linear (each sequence has a fixed head and\ntail) or circular (we can choose any gene as the head, and the previous one is\nthe tail), and whether genes have multiple copies, we classify the problem of\ndetermining transposons into four scenarios: (1) linear sequences without\nduplicated genes; (2) circular sequences without duplicated genes; (3) linear\nsequences with duplicated genes; (4) circular sequences with duplicated genes.\nWith the help of graph theory, we design fast algorithms for different\nscenarios. We also derive some results that might be of theoretical interests\nin combinatorics.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.02424v4"
    },
    {
        "title": "CARGO: Effective format-free compressed storage of genomic information",
        "authors": [
            "Łukasz Roguski",
            "Paolo Ribeca"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  The recent super-exponential growth in the amount of sequencing data\ngenerated worldwide has put techniques for compressed storage into the focus.\nMost available solutions, however, are strictly tied to specific bioinformatics\nformats, sometimes inheriting from them suboptimal design choices; this hinders\nflexible and effective data sharing. Here we present CARGO (Compressed\nARchiving for GenOmics), a high-level framework to automatically generate\nsoftware systems optimized for the compressed storage of arbitrary types of\nlarge genomic data collections. Straightforward applications of our approach to\nFASTQ and SAM archives require a few lines of code, produce solutions that\nmatch and sometimes outperform specialized format-tailored compressors, and\nscale well to multi-TB datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.05185v1"
    },
    {
        "title": "Bayesian estimation of Differential Transcript Usage from RNA-seq data",
        "authors": [
            "Panagiotis Papastamoulis",
            "Magnus Rattray"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Next generation sequencing allows the identification of genes consisting of\ndifferentially expressed transcripts, a term which usually refers to changes in\nthe overall expression level. A specific type of differential expression is\ndifferential transcript usage (DTU) and targets changes in the relative within\ngene expression of a transcript. The contribution of this paper is to: (a)\nextend the use of cjBitSeq to the DTU context, a previously introduced Bayesian\nmodel which is originally designed for identifying changes in overall\nexpression levels and (b) propose a Bayesian version of DRIMSeq, a frequentist\nmodel for inferring DTU. cjBitSeq is a read based model and performs fully\nBayesian inference by MCMC sampling on the space of latent state of each\ntranscript per gene. BayesDRIMSeq is a count based model and estimates the\nBayes Factor of a DTU model against a null model using Laplace's approximation.\nThe proposed models are benchmarked against the existing ones using a recent\nindependent simulation study as well as a real RNA-seq dataset. Our results\nsuggest that the Bayesian methods exhibit similar performance with DRIMSeq in\nterms of precision/recall but offer better calibration of False Discovery Rate.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.03095v2"
    },
    {
        "title": "KMC 3: counting and manipulating k-mer statistics",
        "authors": [
            "Marek Kokot",
            "Maciej Długosz",
            "Sebastian Deorowicz"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Summary: Counting all k-mers in a given dataset is a standard procedure in\nmany bioinformatics applications. We introduce KMC3, a significant improvement\nof the former KMC2 algorithm together with KMC tools for manipulating k-mer\ndatabases. Usefulness of the tools is shown on a few real problems.\nAvailability: Program is freely available at\nhttp://sun.aei.polsl.pl/REFRESH/kmc. Contact: sebastian.deorowicz@polsl.pl\n",
        "pdf_link": "http://arxiv.org/pdf/1701.08022v1"
    },
    {
        "title": "Dilated Convolutions for Modeling Long-Distance Genomic Dependencies",
        "authors": [
            "Ankit Gupta",
            "Alexander M. Rush"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  We consider the task of detecting regulatory elements in the human genome\ndirectly from raw DNA. Past work has focused on small snippets of DNA, making\nit difficult to model long-distance dependencies that arise from DNA's\n3-dimensional conformation. In order to study long-distance dependencies, we\ndevelop and release a novel dataset for a larger-context modeling task. Using\nthis new data set we model long-distance interactions using dilated\nconvolutional neural networks, and compare them to standard convolutions and\nrecurrent neural networks. We show that dilated convolutions are effective at\nmodeling the locations of regulatory markers in the human genome, such as\ntranscription factor binding sites, histone modifications, and DNAse\nhypersensitivity sites.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.01278v1"
    },
    {
        "title": "An Extension of Deep Pathway Analysis: A Pathway Route Analysis\n  Framework Incorporating Multi-dimensional Cancer Genomics Data",
        "authors": [
            "Yue Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2017",
        "summary": "  Recent breakthroughs in cancer research have come via the up-and-coming field\nof pathway analysis. By applying statistical methods to prior known gene and\nprotein regulatory information, pathway analysis provides a meaningful way to\ninterpret genomic data. While many gene/protein regulatory relationships have\nbeen studied, never before has such a significant amount data been made\navailable in organized forms of gene/protein regulatory networks and pathways.\nHowever, pathway analysis research is still in its infancy, especially when\napplying it to solve practical problems.\n  In this paper we propose a new method of studying biological pathways, one\nthat cross analyzes mutation information, transcriptome and proteomics data.\nUsing this outcome, we identify routes of aberrant pathways potentially\nresponsible for the etiology of disease. Each pathway route is encoded as a\nbayesian network which is initialized with a sequence of conditional\nprobabilities specifically designed to encode directionality of regulatory\nrelationships encoded in the pathways. Far more complex interactions, such as\nphosphorylation and methylation, among others, in the pathways can be modeled\nusing this approach. The effectiveness of our model is demonstrated through its\nability to distinguish real pathways from decoys on TCGA mRNA-seq, mutation,\nCopy Number Variation and phosphorylation data for both Breast cancer and\nOvarian cancer study. The majority of pathways distinguished can be confirmed\nby biological literature. Moreover, the proportion of correctly indentified\npathways is \\% higher than previous work where only mRNA-seq mutation data is\nincorporated for breast cancer patients. Consequently, such an in-depth pathway\nanalysis incorporating more diverse data can give rise to the accuracy of\nperturbed pathway detection.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.03355v1"
    },
    {
        "title": "Exploring Bayesian approaches to eQTL mapping through probabilistic\n  programming",
        "authors": [
            "Dimitrios V Vavoulis"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The discovery of genomic polymorphisms influencing gene expression (also\nknown as expression quantitative trait loci or eQTLs) can be formulated as a\nsparse Bayesian multivariate/multiple regression problem. An important aspect\nin the development of such models is the implementation of bespoke inference\nmethodologies, a process which can become quite laborious, when multiple\ncandidate models are being considered. We describe automatic, black-box\ninference in such models using Stan, a popular probabilistic programming\nlanguage. The utilisation of systems like Stan can facilitate model prototyping\nand testing, thus accelerating the data modelling process. The code described\nin this chapter can be found at https://github.com/dvav/eQTLBookChapter.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.05150v1"
    },
    {
        "title": "Convolutional neural network models for cancer type prediction based on\n  gene expression",
        "authors": [
            "Milad Mostavi",
            "Yu-Chiao Chiu",
            "Yufei Huang",
            "Yidong Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Background Precise prediction of cancer types is vital for cancer diagnosis\nand therapy. Important cancer marker genes can be inferred through predictive\nmodel. Several studies have attempted to build machine learning models for this\ntask however none has taken into consideration the effects of tissue of origin\nthat can potentially bias the identification of cancer markers. Results In this\npaper, we introduced several Convolutional Neural Network (CNN) models that\ntake unstructured gene expression inputs to classify tumor and non-tumor\nsamples into their designated cancer types or as normal. Based on different\ndesigns of gene embeddings and convolution schemes, we implemented three CNN\nmodels: 1D-CNN, 2D-Vanilla-CNN, and 2D-Hybrid-CNN. The models were trained and\ntested on combined 10,340 samples of 33 cancer types and 731 matched normal\ntissues of The Cancer Genome Atlas (TCGA). Our models achieved excellent\nprediction accuracies (93.9-95.0%) among 34 classes (33 cancers and normal).\nFurthermore, we interpreted one of the models, known as 1D-CNN model, with a\nguided saliency technique and identified a total of 2,090 cancer markers (108\nper class). The concordance of differential expression of these markers between\nthe cancer type they represent and others is confirmed. In breast cancer, for\ninstance, our model identified well-known markers, such as GATA3 and ESR1.\nFinally, we extended the 1D-CNN model for prediction of breast cancer subtypes\nand achieved an average accuracy of 88.42% among 5 subtypes. The codes can be\nfound at https://github.com/chenlabgccri/CancerTypePrediction.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.07794v1"
    },
    {
        "title": "Machine Learning Against Cancer: Accurate Diagnosis of Cancer by Machine\n  Learning Classification of the Whole Genome Sequencing Data",
        "authors": [
            "Arash Hooshmand"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Machine learning can precisely identify different cancer tumors at any stage\nby classifying cancerous and healthy samples based on their genomic profile. We\nhave developed novel methods of MLAC (Machine Learning Against Cancer)\nachieving perfect results with perfect precision, sensitivity, and specificity.\nWe have used the whole genome sequencing data acquired by next-generation RNA\nsequencing techniques in The Cancer Genome Atlas and Genotype-Tissue Expression\nprojects for cancerous and healthy tissues respectively. Moreover, we have\nshown that unsupervised machine learning clustering has great potential to be\nused for cancer diagnosis. Indeed, a creative way to work with data and general\nalgorithms has resulted in perfect classification i.e. all precision,\nsensitivity, and specificity are equal to 1 for most of the different tumor\ntypes even with a modest amount of data, and the same method works well on a\nseries of cancers and results in great clustering of cancerous and healthy\nsamples too. Our system can be used in practice because once the classifier is\ntrained, it can be used to classify any new sample of new potential patients.\nOne advantage of our work is that the aforementioned perfect precision and\nrecall are obtained on samples of all stages including very early stages of\ncancer; therefore, it is a promising tool for diagnosis of cancers in early\nstages. Another advantage of our novel model is that it works with normalized\nvalues of RNA sequencing data, hence people's private sensitive medical data\nwill remain hidden, protected, and safe. This type of analysis will be\nwidespread and economical in the future and people can even learn to receive\ntheir RNA sequencing data and do their own preliminary cancer studies\nthemselves which have the potential to help the healthcare systems. It is a\ngreat step forward toward good health that is the main base of sustainable\nsocieties.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.05847v1"
    },
    {
        "title": "A word recurrence based algorithm to extract genomic dictionaries",
        "authors": [
            "Vincenzo Bonnici",
            "Giuditta Franco",
            "Vincenzo Manca"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genomes may be analyzed from an information viewpoint as very long strings,\ncontaining functional elements of variable length, which have been assembled by\nevolution. In this work an innovative information theory based algorithm is\nproposed, to extract significant (relatively small) dictionaries of genomic\nwords. Namely, conceptual analyses are here combined with empirical studies, to\nopen up a methodology for the extraction of variable length dictionaries from\ngenomic sequences, based on the information content of some factors. Its\napplication to human chromosomes highlights an original inter-chromosomal\nsimilarity in terms of factor distributions.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.10449v1"
    },
    {
        "title": "Efficient and accurate causal inference with hidden confounders from\n  genome-transcriptome variation data",
        "authors": [
            "Lingfei Wang",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Mapping gene expression as a quantitative trait using whole genome-sequencing\nand transcriptome analysis allows to discover the functional consequences of\ngenetic variation. We developed a novel method and ultra-fast software Findr\nfor higly accurate causal inference between gene expression traits using\ncis-regulatory DNA variations as causal anchors, which improves current methods\nby taking into account hidden confounders and weak regulations. Findr\noutperformed existing methods on the DREAM5 Systems Genetics challenge and on\nthe prediction of microRNA and transcription factor targets in human\nlymphoblastoid cells, while being nearly a million times faster. Findr is\npublicly available at https://github.com/lingfeiwang/findr\n",
        "pdf_link": "http://arxiv.org/pdf/1611.01114v3"
    },
    {
        "title": "Large scale modeling of antimicrobial resistance with interpretable\n  classifiers",
        "authors": [
            "Alexandre Drouin",
            "Frédéric Raymond",
            "Gaël Letarte St-Pierre",
            "Mario Marchand",
            "Jacques Corbeil",
            "François Laviolette"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Antimicrobial resistance is an important public health concern that has\nimplications in the practice of medicine worldwide. Accurately predicting\nresistance phenotypes from genome sequences shows great promise in promoting\nbetter use of antimicrobial agents, by determining which antibiotics are likely\nto be effective in specific clinical cases. In healthcare, this would allow for\nthe design of treatment plans tailored for specific individuals, likely\nresulting in better clinical outcomes for patients with bacterial infections.\nIn this work, we present the recent work of Drouin et al. (2016) on using Set\nCovering Machines to learn highly interpretable models of antibiotic resistance\nand complement it by providing a large scale application of their method to the\nentire PATRIC database. We report prediction results for 36 new datasets and\npresent the Kover AMR platform, a new web-based tool allowing the visualization\nand interpretation of the generated models.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.01030v1"
    },
    {
        "title": "Cell Identity Codes: Understanding Cell Identity from Gene Expression\n  Profiles using Deep Neural Networks",
        "authors": [
            "Farzad Abdolhosseini",
            "Behrooz Azarkhalili",
            "Abbas Maazallahi",
            "Aryan Kamal",
            "Seyed Abolfazl Motahari",
            "Ali Sharifi-Zarchi",
            "Hamidreza Chitsaz"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Understanding cell identity is an important task in many biomedical areas.\nExpression patterns of specific marker genes have been used to characterize\nsome limited cell types, but exclusive markers are not available for many cell\ntypes. A second approach is to use machine learning to discriminate cell types\nbased on the whole gene expression profiles (GEPs). The accuracies of simple\nclassification algorithms such as linear discriminators or support vector\nmachines are limited due to the complexity of biological systems. We used deep\nneural networks to analyze 1040 GEPs from 16 different human tissues and cell\ntypes. After comparing different architectures, we identified a specific\nstructure of deep autoencoders that can encode a GEP into a vector of 30\nnumeric values, which we call the cell identity code (CIC). The original GEP\ncan be reproduced from the CIC with an accuracy comparable to technical\nreplicates of the same experiment. Although we use an unsupervised approach to\ntrain the autoencoder, we show different values of the CIC are connected to\ndifferent biological aspects of the cell, such as different pathways or\nbiological processes. This network can use CIC to reproduce the GEP of the cell\ntypes it has never seen during the training. It also can resist some noise in\nthe measurement of the GEP. Furthermore, we introduce classifier autoencoder,\nan architecture that can accurately identify cell type based on the GEP or the\nCIC.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.04863v1"
    },
    {
        "title": "Towards Gene Expression Convolutions using Gene Interaction Graphs",
        "authors": [
            "Francis Dutil",
            "Joseph Paul Cohen",
            "Martin Weiss",
            "Georgy Derevyanko",
            "Yoshua Bengio"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  We study the challenges of applying deep learning to gene expression data. We\nfind experimentally that there exists non-linear signal in the data, however is\nit not discovered automatically given the noise and low numbers of samples used\nin most research. We discuss how gene interaction graphs (same pathway,\nprotein-protein, co-expression, or research paper text association) can be used\nto impose a bias on a deep model similar to the spatial bias imposed by\nconvolutions on an image. We explore the usage of Graph Convolutional Neural\nNetworks coupled with dropout and gene embeddings to utilize the graph\ninformation. We find this approach provides an advantage for particular tasks\nin a low data regime but is very dependent on the quality of the graph used. We\nconclude that more work should be done in this direction. We design experiments\nthat show why existing methods fail to capture signal that is present in the\ndata when features are added which clearly isolates the problem that needs to\nbe addressed.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.06975v1"
    },
    {
        "title": "Apollo: A Sequencing-Technology-Independent, Scalable, and Accurate\n  Assembly Polishing Algorithm",
        "authors": [
            "Can Firtina",
            "Jeremie S. Kim",
            "Mohammed Alser",
            "Damla Senol Cali",
            "A. Ercument Cicek",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Long reads produced by third-generation sequencing technologies are used to\nconstruct an assembly (i.e., the subject's genome), which is further used in\ndownstream genome analysis. Unfortunately, long reads have high sequencing\nerror rates and a large proportion of bps in these long reads are incorrectly\nidentified. These errors propagate to the assembly and affect the accuracy of\ngenome analysis. Assembly polishing algorithms minimize such error propagation\nby polishing or fixing errors in the assembly by using information from\nalignments between reads and the assembly (i.e., read-to-assembly alignment\ninformation). However, assembly polishing algorithms can only polish an\nassembly using reads either from a certain sequencing technology or from a\nsmall assembly. Such technology-dependency and assembly-size dependency require\nresearchers to 1) run multiple polishing algorithms and 2) use small chunks of\na large genome to use all available read sets and polish large genomes. We\nintroduce Apollo, a universal assembly polishing algorithm that scales well to\npolish an assembly of any size (i.e., both large and small genomes) using reads\nfrom all sequencing technologies (i.e., second- and third-generation). Our goal\nis to provide a single algorithm that uses read sets from all available\nsequencing technologies to improve the accuracy of assembly polishing and that\ncan polish large genomes. Apollo 1) models an assembly as a profile hidden\nMarkov model (pHMM), 2) uses read-to-assembly alignment to train the pHMM with\nthe Forward-Backward algorithm, and 3) decodes the trained model with the\nViterbi algorithm to produce a polished assembly. Our experiments with real\nread sets demonstrate that Apollo is the only algorithm that 1) uses reads from\nany sequencing technology within a single run and 2) scales well to polish\nlarge assemblies without splitting the assembly into multiple parts.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.04341v2"
    },
    {
        "title": "PLIT: An alignment-free computational tool for identification of long\n  non-coding RNAs in plant transcriptomic datasets",
        "authors": [
            "S. Deshpande",
            "J. Shuttleworth",
            "J. Yang",
            "S. Taramonli",
            "M. England"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Long non-coding RNAs (lncRNAs) are a class of non-coding RNAs which play a\nsignificant role in several biological processes. RNA-seq based transcriptome\nsequencing has been extensively used for identification of lncRNAs. However,\naccurate identification of lncRNAs in RNA-seq datasets is crucial for exploring\ntheir characteristic functions in the genome as most coding potential\ncomputation (CPC) tools fail to accurately identify them in transcriptomic\ndata. Well-known CPC tools such as CPC2, lncScore, CPAT are primarily designed\nfor prediction of lncRNAs based on the GENCODE, NONCODE and CANTATAdb\ndatabases. The prediction accuracy of these tools often drops when tested on\ntranscriptomic datasets. This leads to higher false positive results and\ninaccuracy in the function annotation process. In this study, we present a\nnovel tool, PLIT, for the identification of lncRNAs in plants RNA-seq datasets.\nPLIT implements a feature selection method based on L1 regularization and\niterative Random Forests (iRF) classification for selection of optimal\nfeatures. Based on sequence and codon-bias features, it classifies the RNA-seq\nderived FASTA sequences into coding or long non-coding transcripts. Using L1\nregularization, 31 optimal features were obtained based on lncRNA and\nprotein-coding transcripts from 8 plant species. The performance of the tool\nwas evaluated on 7 plant RNA-seq datasets using 10-fold cross-validation. The\nanalysis exhibited superior accuracy when evaluated against currently available\nstate-of-the-art CPC tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.05064v1"
    },
    {
        "title": "Analysis of Gene Interaction Graphs as Prior Knowledge for Machine\n  Learning Models",
        "authors": [
            "Paul Bertin",
            "Mohammad Hashir",
            "Martin Weiss",
            "Vincent Frappier",
            "Theodore J. Perkins",
            "Geneviève Boucher",
            "Joseph Paul Cohen"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Gene interaction graphs aim to capture various relationships between genes\nand can represent decades of biology research. When trying to make predictions\nfrom genomic data, those graphs could be used to overcome the curse of\ndimensionality by making machine learning models sparser and more consistent\nwith biological common knowledge. In this work, we focus on assessing how well\nthose graphs capture dependencies seen in gene expression data to evaluate the\nadequacy of the prior knowledge provided by those graphs. We propose a\ncondition graphs should satisfy to provide good prior knowledge and test it\nusing `Single Gene Inference' tasks. We also compare with randomly generated\ngraphs, aiming to measure the true benefit of using biologically relevant\ngraphs in this context, and validate our findings with five clinical tasks. We\nfind some graphs capture relevant dependencies for most genes while being very\nsparse. Our analysis with random graphs finds that dependencies can be captured\nalmost as well at random which suggests that, in terms of gene expression\nlevels, the relevant information about the state of the cell is spread across\nmany genes.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02295v2"
    },
    {
        "title": "Tasks, Techniques, and Tools for Genomic Data Visualization",
        "authors": [
            "Sabrina Nusrat",
            "Theresa Harbig",
            "Nils Gehlenborg"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Genomic data visualization is essential for interpretation and hypothesis\ngeneration as well as a valuable aid in communicating discoveries. Visual tools\nbridge the gap between algorithmic approaches and the cognitive skills of\ninvestigators. Addressing this need has become crucial in genomics, as\nbiomedical research is increasingly data-driven and many studies lack\nwell-defined hypotheses. A key challenge in data-driven research is to discover\nunexpected patterns and to formulate hypotheses in an unbiased manner in vast\namounts of genomic and other associated data. Over the past two decades, this\nhas driven the development of numerous data visualization techniques and tools\nfor visualizing genomic data. Based on a comprehensive literature survey, we\npropose taxonomies for data, visualization, and tasks involved in genomic data\nvisualization. Furthermore, we provide a comprehensive review of published\ngenomic visualization tools in the context of the proposed taxonomies.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02853v1"
    },
    {
        "title": "The Energetics of Molecular Adaptation in Transcriptional Regulation",
        "authors": [
            "Griffin Chure",
            "Manuel Razo-Mejia",
            "Nathan M. Belliveau",
            "Tal Einav",
            "Zofii Kaczmarek",
            "Stephanie L. Barnes",
            "Mitchell Lewis",
            "Rob Phillips"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Mutation is a critical mechanism by which evolution explores the functional\nlandscape of proteins. Despite our ability to experimentally inflict mutations\nat will, it remains difficult to link sequence-level perturbations to\nsystems-level responses. Here, we present a framework centered on measuring\nchanges in the free energy of the system to link individual mutations in an\nallosteric transcriptional repressor to the parameters which govern its\nresponse. We find the energetic effects of the mutations can be categorized\ninto several classes which have characteristic curves as a function of the\ninducer concentration. We experimentally test these diagnostic predictions\nusing the well-characterized LacI repressor of Escherichia coli, probing\nseveral mutations in the DNA binding and inducer binding domains. We find that\nthe change in gene expression due to a point mutation can be captured by\nmodifying only a subset of the model parameters that describe the respective\ndomain of the wild-type protein. These parameters appear to be insulated, with\nmutations in the DNA binding domain altering only the DNA affinity and those in\nthe inducer binding domain altering only the allosteric parameters. Changing\nthese subsets of parameters tunes the free energy of the system in a way that\nis concordant with theoretical expectations. Finally, we show that the\ninduction profiles and resulting free energies associated with pairwise double\nmutants can be predicted with quantitative accuracy given knowledge of the\nsingle mutants, providing an avenue for identifying and quantifying epistatic\ninteractions.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.06360v1"
    },
    {
        "title": "ncRNA Classification with Graph Convolutional Networks",
        "authors": [
            "Emanuele Rossi",
            "Federico Monti",
            "Michael Bronstein",
            "Pietro Liò"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Non-coding RNA (ncRNA) are RNA sequences which don't code for a gene but\ninstead carry important biological functions. The task of ncRNA classification\nconsists in classifying a given ncRNA sequence into its family. While it has\nbeen shown that the graph structure of an ncRNA sequence folding is of great\nimportance for the prediction of its family, current methods make use of\nmachine learning classifiers on hand-crafted graph features. We improve on the\nstate-of-the-art for this task with a graph convolutional network model which\nachieves an accuracy of 85.73% and an F1-score of 85.61% over 13 classes.\nMoreover, our model learns in an end-to-end fashion from the raw RNA graphs and\nremoves the need for expensive feature extraction. To the best of our\nknowledge, this also represents the first successful application of graph\nconvolutional networks to RNA folding data.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.06515v1"
    },
    {
        "title": "Systematic clustering algorithm for chromatin accessibility data and its\n  application to hematopoietic cells",
        "authors": [
            "Azusa Tanaka",
            "Yasuhiro Ishitsuka",
            "Hiroki Ohta",
            "Akihiro Fujimoto",
            "Jun-ichirou Yasunaga",
            "Masao Matsuoka"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The huge amount of data acquired by high-throughput sequencing requires data\nreduction for effective analysis. Here we give a clustering algorithm for\ngenome-wide open chromatin data using a new data reduction method. This method\nregards the genome as a string of $1$s and $0$s based on a set of peaks and\ncalculates the Hamming distances between the strings. This algorithm with the\nsystematically optimized set of peaks enables us to quantitatively evaluate\ndifferences between samples of hematopoietic cells and classify cell types,\npotentially leading to a better understanding of leukemia pathogenesis.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.10641v2"
    },
    {
        "title": "Reconstruction of Gene Regulatory Networks usingMultiple Datasets",
        "authors": [
            "Mehrzad Saremi",
            "Maryam Amirmazlaghani"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Motivation: Laboratory gene regulatory data for a species are sporadic.\nDespite the abundance of gene regulatory network algorithms that employ single\ndata sets, few algorithms can combine the vast but disperse sources of data and\nextract the potential information. With a motivation to compensate for this\nshortage, we developed an algorithm called GENEREF that can accumulate\ninformation from multiple types of data sets in an iterative manner, with each\niteration boosting the performance of the prediction results.\n  Results: The algorithm is examined extensively on data extracted from the\nquintuple DREAM4 networks and DREAM5's Escherichia coli and Saccharomyces\ncerevisiae networks and sub-networks. Many single-dataset and multi-dataset\nalgorithms were compared to test the performance of the algorithm. Results show\nthat GENEREF surpasses non-ensemble state-of-the-art multi-perturbation\nalgorithms on the selected networks and is competitive to present\nmultiple-dataset algorithms. Specifically, it outperforms dynGENIE3 and is on\npar with iRafNet. Also, we argued that a scoring method solely based on the\nAUPR criterion would be more trustworthy than the traditional score.\n  Availability: The Python implementation along with the data sets and results\ncan be downloaded from github.com/msaremi/GENEREF\n",
        "pdf_link": "http://arxiv.org/pdf/1912.10810v2"
    },
    {
        "title": "Review of Single-cell RNA-seq Data Clustering for Cell Type\n  Identification and Characterization",
        "authors": [
            "Shixiong Zhang",
            "Xiangtao Li",
            "Qiuzhen Lin",
            "Ka-Chun Wong"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  In recent years, the advances in single-cell RNA-seq techniques have enabled\nus to perform large-scale transcriptomic profiling at single-cell resolution in\na high-throughput manner. Unsupervised learning such as data clustering has\nbecome the central component to identify and characterize novel cell types and\ngene expression patterns. In this study, we review the existing single-cell\nRNA-seq data clustering methods with critical insights into the related\nadvantages and limitations. In addition, we also review the upstream\nsingle-cell RNA-seq data processing techniques such as quality control,\nnormalization, and dimension reduction. We conduct performance comparison\nexperiments to evaluate several popular single-cell RNA-seq clustering\napproaches on two single-cell transcriptomic datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.01006v1"
    },
    {
        "title": "Supporting supervised learning in fungal Biosynthetic Gene Cluster\n  discovery: new benchmark datasets",
        "authors": [
            "Hayda Almeida",
            "Adrian Tsang",
            "Abdoulaye Baniré Diallo"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Fungal Biosynthetic Gene Clusters (BGCs) of secondary metabolites are\nclusters of genes capable of producing natural products, compounds that play an\nimportant role in the production of a wide variety of bioactive compounds,\nincluding antibiotics and pharmaceuticals. Identifying BGCs can lead to the\ndiscovery of novel natural products to benefit human health. Previous work has\nbeen focused on developing automatic tools to support BGC discovery in plants,\nfungi, and bacteria. Data-driven methods, as well as probabilistic and\nsupervised learning methods have been explored in identifying BGCs. Most\nmethods applied to identify fungal BGCs were data-driven and presented limited\nscope. Supervised learning methods have been shown to perform well at\nidentifying BGCs in bacteria, and could be well suited to perform the same task\nin fungi. But labeled data instances are needed to perform supervised learning.\nOpenly accessible BGC databases contain only a very small portion of previously\ncurated fungal BGCs. Making new fungal BGC datasets available could motivate\nthe development of supervised learning methods for fungal BGCs and potentially\nimprove prediction performance compared to data-driven methods. In this work we\npropose new publicly available fungal BGC datasets to support the BGC discovery\ntask using supervised learning. These datasets are prepared to perform binary\nclassification and predict candidate BGC regions in fungal genomes. In addition\nwe analyse the performance of a well supported supervised learning tool\ndeveloped to predict BGCs.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03260v1"
    },
    {
        "title": "A Pipeline for Integrated Theory and Data-Driven Modeling of Genomic and\n  Clinical Data",
        "authors": [
            "Vineet K Raghu",
            "Xiaoyu Ge",
            "Arun Balajee",
            "Daniel J. Shirer",
            "Isha Das",
            "Panayiotis V. Benos",
            "Panos K. Chrysanthis"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  High throughput genome sequencing technologies such as RNA-Seq and Microarray\nhave the potential to transform clinical decision making and biomedical\nresearch by enabling high-throughput measurements of the genome at a granular\nlevel. However, to truly understand causes of disease and the effects of\nmedical interventions, this data must be integrated with phenotypic,\nenvironmental, and behavioral data from individuals. Further, effective\nknowledge discovery methods that can infer relationships between these data\ntypes are required. In this work, we propose a pipeline for knowledge discovery\nfrom integrated genomic and clinical data. The pipeline begins with a novel\nvariable selection method, and uses a probabilistic graphical model to\nunderstand the relationships between features in the data. We demonstrate how\nthis pipeline can improve breast cancer outcome prediction models, and can\nprovide a biologically interpretable view of sequencing data.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02521v1"
    },
    {
        "title": "Introducing a Probabilistic Structure on Sequential Dynamical Systems,\n  Simulation and Reduction of Probabilistic Sequential Networks",
        "authors": [
            "Maria A. Avino-Diaz"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  A probabilistic structure on sequential dynamical systems is introduced here,\nthe new model will be called Probabilistic Sequential Network, PSN. The\nmorphisms of Probabilistic Sequential Networks are defined using two algebraic\nconditions. It is proved here that two homomorphic Probabilistic Sequential\nNetworks have the same equilibrium or steady state probabilities if the\nmorphism is either an epimorphism or a monomorphism. Additionally, the proof of\nthe set of PSN with its morphisms form the category PSN, having the category of\nsequential dynamical systems SDS, as a full subcategory is given. Several\nexamples of morphisms, subsystems and simulations are given.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.0026v2"
    },
    {
        "title": "p-Adic Degeneracy of the Genetic Code",
        "authors": [
            "Branko Dragovich",
            "Alexandra Dragovich"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Degeneracy of the genetic code is a biological way to minimize effects of the\nundesirable mutation changes. Degeneration has a natural description on the\n5-adic space of 64 codons $\\mathcal{C}_5 (64) = \\{n_0 + n_1 5 + n_2 5^2\n  : n_i = 1, 2, 3, 4 \\} ,$ where $n_i$ are digits related to nucleotides as\nfollows: C = 1, A = 2, T = U = 3, G = 4. The smallest 5-adic distance between\ncodons joins them into 16 quadruplets, which under 2-adic distance decay into\n32 doublets. p-Adically close codons are assigned to one of 20 amino acids,\nwhich are building blocks of proteins, or code termination of protein\nsynthesis. We shown that genetic code multiplets are made of the p-adic nearest\ncodons.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.0764v1"
    },
    {
        "title": "Tight-binding modeling of charge migration in DNA devices",
        "authors": [
            "G. Cuniberti",
            "E. Macia",
            "A. Rodriguez",
            "R. A. Römer"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Long range charge transfer experiments in DNA oligomers and the subsequently\nmeasured -- and very diverse -- transport response of DNA wires in solid state\nexperiments exemplifies the need for a thorough theoretical understanding of\ncharge migration in DNA-based natural and artificial materials. Here we present\na review of tight-binding models for DNA conduction which have the intrinsic\nmerit of containing more structural information than plain rate-equation models\nwhile still retaining sufficient detail of the electronic properties. This\nallows for simulations of transport properties to be more manageable with\nrespect to density functional theory methods or correlated first principle\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.3224v1"
    },
    {
        "title": "Poincaré recurrences of DNA sequence",
        "authors": [
            "K. M. Frahm",
            "D. L. Shepelyansky"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  We analyze the statistical properties of Poincar\\'e recurrences of Homo\nsapiens, mammalian and other DNA sequences taken from Ensembl Genome data base\nwith up to fifteen billions base pairs. We show that the probability of\nPoincar\\'e recurrences decays in an algebraic way with the Poincar\\'e exponent\n$\\beta \\approx 4$ even if oscillatory dependence is well pronounced. The\ncorrelations between recurrences decay with an exponent $\\nu \\approx 0.6$ that\nleads to an anomalous super-diffusive walk. However, for Homo sapiens\nsequences, with the largest available statistics, the diffusion coefficient\nconverges to a finite value on distances larger than million base pairs. We\nargue that the approach based on Poncar\\'e recurrences determines new proximity\nfeatures between different species and shed a new light on their evolution\nhistory.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0436v3"
    },
    {
        "title": "RasBhari: optimizing spaced seeds for database searching, read mapping\n  and alignment-free sequence comparison",
        "authors": [
            "Lars Hahn",
            "Chris-André Leimeister",
            "Rachid Ounit",
            "Stefano Lonardi",
            "Burkhard Morgenstern"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Many algorithms for sequence analysis rely on word matching or word\nstatistics. Often, these approaches can be improved if binary patterns\nrepresenting match and don't-care positions are used as a filter, such that\nonly those positions of words are considered that correspond to the match\npositions of the patterns. The performance of these approaches, however,\ndepends on the underlying patterns. Herein, we show that the overlap complexity\nof a pattern set that was introduced by Ilie and Ilie is closely related to the\nvariance of the number of matches between two evolutionarily related sequences\nwith respect to this pattern set. We propose a modified hill-climbing algorithm\nto optimize pattern sets for database searching, read mapping and\nalignment-free sequence comparison of nucleic-acid sequences; our\nimplementation of this algorithm is called rasbhari. Depending on the\napplication at hand, rasbhari can either minimize the overlap complexity of\npattern sets, maximize their sensitivity in database searching or minimize the\nvariance of the number of pattern-based matches in alignment-free sequence\ncomparison. We show that, for database searching, rasbhari generates pattern\nsets with slightly higher sensitivity than existing approaches. In our Spaced\nWords approach to alignment-free sequence comparison, pattern sets calculated\nwith rasbhari led to more accurate estimates of phylogenetic distances than the\nrandomly generated pattern sets that we previously used. Finally, we used\nrasbhari to generate patterns for short read classification with CLARK-S. Here\ntoo, the sensitivity of the results could be improved, compared to the default\npatterns of the program. We integrated rasbhari into Spaced Words; the source\ncode of rasbhari is freely available at http://rasbhari.gobics.de/\n",
        "pdf_link": "http://arxiv.org/pdf/1511.04001v2"
    },
    {
        "title": "DUDE-Seq: Fast, Flexible, and Robust Denoising for Targeted Amplicon\n  Sequencing",
        "authors": [
            "Byunghan Lee",
            "Taesup Moon",
            "Sungroh Yoon",
            "Tsachy Weissman"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  We consider the correction of errors from nucleotide sequences produced by\nnext-generation targeted amplicon sequencing. The next-generation sequencing\n(NGS) platforms can provide a great deal of sequencing data thanks to their\nhigh throughput, but the associated error rates often tend to be high.\nDenoising in high-throughput sequencing has thus become a crucial process for\nboosting the reliability of downstream analyses. Our methodology, named\nDUDE-Seq, is derived from a general setting of reconstructing finite-valued\nsource data corrupted by a discrete memoryless channel and effectively corrects\nsubstitution and homopolymer indel errors, the two major types of sequencing\nerrors in most high-throughput targeted amplicon sequencing platforms. Our\nexperimental studies with real and simulated datasets suggest that the proposed\nDUDE-Seq not only outperforms existing alternatives in terms of\nerror-correction capability and time efficiency, but also boosts the\nreliability of downstream analyses. Further, the flexibility of DUDE-Seq\nenables its robust application to different sequencing platforms and analysis\npipelines by simple updates of the noise model. DUDE-Seq is available at\nhttp://data.snu.ac.kr/pub/dude-seq.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.04836v3"
    },
    {
        "title": "NASCUP: Nucleic Acid Sequence Classification by Universal Probability",
        "authors": [
            "Sunyoung Kwon",
            "Gyuwan Kim",
            "Byunghan Lee",
            "Jongsik Chun",
            "Sungroh Yoon",
            "Young-Han Kim"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Motivated by the need for fast and accurate classification of unlabeled\nnucleotide sequences on a large scale, we developed NASCUP, a new\nclassification method that captures statistical structures of nucleotide\nsequences by compact context-tree models and universal probability from\ninformation theory. NASCUP achieved BLAST-like classification accuracy\nconsistently for several large-scale databases in orders-of-magnitude reduced\nruntime, and was applied to other bioinformatics tasks such as outlier\ndetection and synthetic sequence generation.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.04944v2"
    },
    {
        "title": "Bayesian identification of bacterial strains from sequencing data",
        "authors": [
            "Aravind Sankar",
            "Brandon Malone",
            "Sion Bayliss",
            "Ben Pascoe",
            "Guillaume Méric",
            "Matthew D. Hitchings",
            "Samuel K. Sheppard",
            "Edward J. Feil",
            "Jukka Corander",
            "Antti Honkela"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Rapidly assaying the diversity of a bacterial species present in a sample\nobtained from a hospital patient or an evironmental source has become possible\nafter recent technological advances in DNA sequencing. For several applications\nit is important to accurately identify the presence and estimate relative\nabundances of the target organisms from short sequence reads obtained from a\nsample. This task is particularly challenging when the set of interest includes\nvery closely related organisms, such as different strains of pathogenic\nbacteria, which can vary considerably in terms of virulence, resistance and\nspread. Using advanced Bayesian statistical modelling and computation\ntechniques we introduce a novel pipeline for bacterial identification that is\nshown to outperform the currently leading pipeline for this purpose. Our\napproach enables fast and accurate sequence-based identification of bacterial\nstrains while using only modest computational resources. Hence it provides a\nuseful tool for a wide spectrum of applications, including rapid clinical\ndiagnostics to distinguish among closely related strains causing nosocomial\ninfections. The software implementation is available at\nhttps://github.com/PROBIC/BIB\n",
        "pdf_link": "http://arxiv.org/pdf/1511.06546v2"
    },
    {
        "title": "Convolutional Neural Networks In Classifying Cancer Through DNA\n  Methylation",
        "authors": [
            "Soham Chatterjee",
            "Archana Iyer",
            "Satya Avva",
            "Abhai Kollara",
            "Malaikannan Sankarasubbu"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  DNA Methylation has been the most extensively studied epigenetic mark.\nUsually a change in the genotype, DNA sequence, leads to a change in the\nphenotype, observable characteristics of the individual. But DNA methylation,\nwhich happens in the context of CpG (cytosine and guanine bases linked by\nphosphate backbone) dinucleotides, does not lead to a change in the original\nDNA sequence but has the potential to change the phenotype. DNA methylation is\nimplicated in various biological processes and diseases including cancer. Hence\nthere is a strong interest in understanding the DNA methylation patterns across\nvarious epigenetic related ailments in order to distinguish and diagnose the\ntype of disease in its early stages. In this work, the relationship between\nmethylated versus unmethylated CpG regions and cancer types is explored using\nConvolutional Neural Networks (CNNs). A CNN based Deep Learning model that can\nclassify the cancer of a new DNA methylation profile based on the learning from\npublicly available DNA methylation datasets is then proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.09617v1"
    },
    {
        "title": "EBIC: an open source software for high-dimensional and big data\n  biclustering analyses",
        "authors": [
            "Patryk Orzechowski",
            "Jason H. Moore"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Motivation: In this paper we present the latest release of EBIC, a\nnext-generation biclustering algorithm for mining genetic data. The major\ncontribution of this paper is adding support for big data, making it possible\nto efficiently run large genomic data mining analyses. Additional enhancements\ninclude integration with R and Bioconductor and an option to remove influence\nof missing value on the final result.\n  Results: EBIC was applied to datasets of different sizes, including a large\nDNA methylation dataset with 436,444 rows. For the largest dataset we observed\nover 6.6 fold speedup in computation time on a cluster of 8 GPUs compared to\nrunning the method on a single GPU. This proves high scalability of the\nalgorithm.\n  Availability: The latest version of EBIC could be downloaded from\nhttp://github.com/EpistasisLab/ebic . Installation and usage instructions are\nalso available online.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.09932v2"
    },
    {
        "title": "Insights into Complex Brain Functions Related to Schizophrenia Disorder\n  through Causal Network Analysis",
        "authors": [
            "Akram Yazdani",
            "Raul Mendez Giraldez",
            "Ahmad Samiei"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Gene expression represents a fundamental interface between genes and\nenvironment in the development and ongoing plasticity of the human organism.\nIndividual differences in gene expression are likely to underpin much of human\ndiversity, including psychiatric illness. Gene expression shows a distinct\nregulatory pattern in different tissues. Therefore, brain tissue analysis\nprovides insights into brain disorder mechanisms. Furthermore, mechanistic\nunderstanding of gene regulatory pattern can be provided through studying the\nunderlying relationships as a complex network. Identification of brain specific\ngene relationships provides a complementary framework in which to tackle the\ncomplex dysregulations that occur in neuropsychiatric and other neurological\ndisorders. Using a systems approach established in Mendelian randomization and\nBayesian Network, we integrated genetic and transcriptomic data from the\ncommon-mind consortium and identified transcriptomic causal networks in\nobservational studies. Focusing on Schizophrenia disorder, we identified high\nimpact genes and revealed their underlying pathways in brain tissue. In\naddition, we generated novel hypotheses including genes as causes of the\nschizophrenia-associated genes and new genes associated with Schizophrenia.\nThis approach may facilitate a better understanding of the disease mechanism\nthat is complementary to molecular experimental studies especially for complex\nsystems and large-scale data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.11654v2"
    },
    {
        "title": "Genome analysis and pleiotropy assessment using causal networks with\n  loss of function mutation and metabolomics",
        "authors": [
            "Azam Yazdani",
            "Akram Yazdani",
            "Sarah H. Elsea",
            "Daniel J. Schaid",
            "Michael R. Kosorok",
            "Gita Dangol",
            "Ahmad Samiei"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Background: Many genome-wide association studies have detected genomic\nregions associated with traits, yet understanding the functional causes of\nassociation often remains elusive. Utilizing systems approaches and focusing on\nintermediate molecular phenotypes might facilitate biologic understanding.\nResults: The availability of exome sequencing of two populations of\nAfrican-Americans and European-Americans from the Atherosclerosis Risk in\nCommunities study allowed us to investigate the effects of annotated\nloss-of-function (LoF) mutations on 122 serum metabolites. To assess the\nfindings, we built metabolomic causal networks for each population separately\nand utilized structural equation modeling. We then validated our findings with\na set of independent samples. By use of methods based on concepts of Mendelian\nrandomization of genetic variants, we showed that some of the affected\nmetabolites are risk predictors in the causal pathway of disease. For example,\nLoF mutations in the gene KIAA1755 were identified to elevate the levels of\neicosapentaenoate (p-value=5E-14), an essential fatty acid clinically\nidentified to increase essential hypertension. We showed that this gene is in\nthe pathway to triglycerides, where both triglycerides and essential\nhypertension are risk factors of metabolomic disorder and heart attack. We also\nidentified that the gene CLDN17, harboring loss-of-function mutations, had\npleiotropic actions on metabolites from amino acid and lipid pathways.\nConclusion: Using systems biology approaches for the analysis of metabolomics\nand genetic data, we integrated several biological processes, which lead to\nfindings that may functionally connect genetic variants with complex diseases.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12652v1"
    },
    {
        "title": "Fusing heterogeneous data sets",
        "authors": [
            "Yipeng Song"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In systems biology, it is common to measure biochemical entities at different\nlevels of the same biological system. One of the central problems for the data\nfusion of such data sets is the heterogeneity of the data. This thesis\ndiscusses two types of heterogeneity. The first one is the type of data, such\nas metabolomics, proteomics and RNAseq data in genomics. These different omics\ndata reflect the properties of the studied biological system from different\nperspectives. The second one is the type of scale, which indicates the\nmeasurements obtained at different scales, such as binary, ordinal, interval\nand ratio-scaled variables. In this thesis, we developed several statistical\nmethods capable to fuse data sets of these two types of heterogeneity. The\nadvantages of the proposed methods in comparison with other approaches are\nassessed using comprehensive simulations as well as the analysis of real\nbiological data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.09653v1"
    },
    {
        "title": "SAERMA: Stacked Autoencoder Rule Mining Algorithm for the Interpretation\n  of Epistatic Interactions in GWAS for Extreme Obesity",
        "authors": [
            "Casimiro Aday Curbelo Montañez",
            "Paul Fergus",
            "Carl Chalmers",
            "Nurul Ahamed Hassain Malim",
            "Basma Abdulaimma",
            "Denis Reilly",
            "Francesco Falciani"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  One of the most important challenges in the analysis of high-throughput\ngenetic data is the development of efficient computational methods to identify\nstatistically significant Single Nucleotide Polymorphisms (SNPs). Genome-wide\nassociation studies (GWAS) use single-locus analysis where each SNP is\nindependently tested for association with phenotypes. The limitation with this\napproach, however, is its inability to explain genetic variation in complex\ndiseases. Alternative approaches are required to model the intricate\nrelationships between SNPs. Our proposed approach extends GWAS by combining\ndeep learning stacked autoencoders (SAEs) and association rule mining (ARM) to\nidentify epistatic interactions between SNPs. Following traditional GWAS\nquality control and association analysis, the most significant SNPs are\nselected and used in the subsequent analysis to investigate epistasis. SAERMA\ncontrols the classification results produced in the final fully connected\nmulti-layer feedforward artificial neural network (MLP) by manipulating the\ninterestingness measures, support and confidence, in the rule generation\nprocess. The best classification results were achieved with 204 SNPs compressed\nto 100 units (77% AUC, 77% SE, 68% SP, 53% Gini, logloss=0.58, and MSE=0.20),\nalthough it was possible to achieve 73% AUC (77% SE, 63% SP, 45% Gini,\nlogloss=0.62, and MSE=0.21) with 50 hidden units - both supported by close\nmodel interpretation.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.10166v1"
    },
    {
        "title": "Deep Learning and Random Forest-Based Augmentation of sRNA Expression\n  Profiles",
        "authors": [
            "Jelena Fiosina",
            "Maksims Fiosins",
            "Stefan Bonn"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The lack of well-structured annotations in a growing amount of RNA expression\ndata complicates data interoperability and reusability. Commonly - used text\nmining methods extract annotations from existing unstructured data descriptions\nand often provide inaccurate output that requires manual curation. Automatic\ndata-based augmentation (generation of annotations on the base of expression\ndata) can considerably improve the annotation quality and has not been\nwell-studied. We formulate an automatic augmentation of small RNA-seq\nexpression data as a classification problem and investigate deep learning (DL)\nand random forest (RF) approaches to solve it. We generate tissue and sex\nannotations from small RNA-seq expression data for tissues and cell lines of\nhomo sapiens. We validate our approach on 4243 annotated small RNA-seq samples\nfrom the Small RNA Expression Atlas (SEA) database. The average prediction\naccuracy for tissue groups is 98% (DL), for tissues - 96.5% (DL), and for sex -\n77% (DL). The \"one dataset out\" average accuracy for tissue group prediction is\n83% (DL) and 59% (RF). On average, DL provides better results as compared to\nRF, and considerably improves classification performance for 'unseen' datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11943v1"
    },
    {
        "title": "Single-cell eQTLGen Consortium: a personalized understanding of disease",
        "authors": [
            "Monique G. P. van der Wijst",
            "Dylan H. de Vries",
            "Hilde E. Groot",
            "Gosia Trynka",
            "Chung-Chau Hon",
            "Martijn C. Nawijn",
            "Youssef Idaghdour",
            "Pim van der Harst",
            "Chun J. Ye",
            "Joseph Powell",
            "Fabian J. Theis",
            "Ahmed Mahfouz",
            "Matthias Heinig",
            "Lude Franke"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In recent years, functional genomics approaches combining genetic information\nwith bulk RNA-sequencing data have identified the downstream expression effects\nof disease-associated genetic risk factors through so-called expression\nquantitative trait locus (eQTL) analysis. Single-cell RNA-sequencing creates\nenormous opportunities for mapping eQTLs across different cell types and in\ndynamic processes, many of which are obscured when using bulk methods. The\nenormous increase in throughput and reduction in cost per cell now allow this\ntechnology to be applied to large-scale population genetics studies. Therefore,\nwe have founded the single-cell eQTLGen consortium (sc-eQTLGen), aimed at\npinpointing disease-causing genetic variants and identifying the cellular\ncontexts in which they affect gene expression. Ultimately, this information can\nenable development of personalized medicine. Here, we outline the goals,\napproach, potential utility and early proofs-of-concept of the sc-eQTLGen\nconsortium. We also provide a set of study design considerations for future\nsingle-cell eQTL studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.12550v1"
    },
    {
        "title": "Netboost: Boosting-supported network analysis improves high-dimensional\n  omics prediction in acute myeloid leukemia and Huntington's disease",
        "authors": [
            "Pascal Schlosser",
            "Jochen Knaus",
            "Maximilian Schmutz",
            "Konstanze Döhner",
            "Christoph Plass",
            "Lars Bullinger",
            "Rainer Claus",
            "Harald Binder",
            "Michael Lübbert",
            "Martin Schumacher"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Background: State-of-the art selection methods fail to identify weak but\ncumulative effects of features found in many high-dimensional omics datasets.\nNevertheless, these features play an important role in certain diseases.\n  Results: We present Netboost, a three-step dimension reduction technique.\nFirst, a boosting-based filter is combined with the topological overlap measure\nto identify the essential edges of the network. Second, sparse hierarchical\nclustering is applied on the selected edges to identify modules and finally\nmodule information is aggregated by the first principal components. The primary\nanalysis is than carried out on these summary measures instead of the original\ndata. We demonstrate the application of the newly developed Netboost in\ncombination with CoxBoost for survival prediction of DNA methylation and gene\nexpression data from 180 acute myeloid leukemia (AML) patients and show, based\non cross-validated prediction error curve estimates, its prediction superiority\nover variable selection on the full dataset as well as over an alternative\nclustering approach. The identified signature related to chromatin modifying\nenzymes was replicated in an independent dataset of AML patients in the phase\nII AMLSG 12-09 study. In a second application we combine Netboost with Random\nForest classification and improve the disease classification error in\nRNA-sequencing data of Huntington's disease mice.\n  Conclusion: Netboost improves definition of predictive variables for survival\nanalysis and classification. It is a freely available Bioconductor R package\nfor dimension reduction and hypothesis generation in high-dimensional omics\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.12551v1"
    },
    {
        "title": "META$^\\mathbf{2}$: Memory-efficient taxonomic classification and\n  abundance estimation for metagenomics with deep learning",
        "authors": [
            "Andreas Georgiou",
            "Vincent Fortuin",
            "Harun Mustafa",
            "Gunnar Rätsch"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Metagenomic studies have increasingly utilized sequencing technologies in\norder to analyze DNA fragments found in environmental samples.One important\nstep in this analysis is the taxonomic classification of the DNA fragments.\nConventional read classification methods require large databases and vast\namounts of memory to run, with recent deep learning methods suffering from very\nlarge model sizes. We therefore aim to develop a more memory-efficient\ntechnique for taxonomic classification. A task of particular interest is\nabundance estimation in metagenomic samples. Current attempts rely on\nclassifying single DNA reads independently from each other and are therefore\nagnostic to co-occurence patterns between taxa. In this work, we also attempt\nto take these patterns into account. We develop a novel memory-efficient read\nclassification technique, combining deep learning and locality-sensitive\nhashing. We show that this approach outperforms conventional mapping-based and\nother deep learning methods for single-read taxonomic classification when\nrestricting all methods to a fixed memory footprint. Moreover, we formulate the\ntask of abundance estimation as a Multiple Instance Learning (MIL) problem and\nwe extend current deep learning architectures with two different types of\npermutation-invariant MIL pooling layers: a) deepsets and b) attention-based\npooling. We illustrate that our architectures can exploit the co-occurrence of\nspecies in metagenomic read sets and outperform the single-read architectures\nin predicting the distribution over taxa at higher taxonomic ranks.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.13146v2"
    },
    {
        "title": "Scaling structural learning with NO-BEARS to infer causal transcriptome\n  networks",
        "authors": [
            "Hao-Chih Lee",
            "Matteo Danieletto",
            "Riccardo Miotto",
            "Sarah T. Cherng",
            "Joel T. Dudley"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Constructing gene regulatory networks is a critical step in revealing disease\nmechanisms from transcriptomic data. In this work, we present NO-BEARS, a novel\nalgorithm for estimating gene regulatory networks. The NO-BEARS algorithm is\nbuilt on the basis of the NOTEARS algorithm with two improvements. First, we\npropose a new constraint and its fast approximation to reduce the computational\ncost of the NO-TEARS algorithm. Next, we introduce a polynomial regression loss\nto handle non-linearity in gene expressions. Our implementation utilizes modern\nGPU computation that can decrease the time of hours-long CPU computation to\nseconds. Using synthetic data, we demonstrate improved performance, both in\nprocessing time and accuracy, on inferring gene regulatory networks from gene\nexpression data.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.00081v1"
    },
    {
        "title": "A Graph Auto-Encoder for Haplotype Assembly and Viral Quasispecies\n  Reconstruction",
        "authors": [
            "Ziqi Ke",
            "Haris Vikalo"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Reconstructing components of a genomic mixture from data obtained by means of\nDNA sequencing is a challenging problem encountered in a variety of\napplications including single individual haplotyping and studies of viral\ncommunities. High-throughput DNA sequencing platforms oversample mixture\ncomponents to provide massive amounts of reads whose relative positions can be\ndetermined by mapping the reads to a known reference genome; assembly of the\ncomponents, however, requires discovery of the reads' origin -- an NP-hard\nproblem that the existing methods struggle to solve with the required level of\naccuracy. In this paper, we present a learning framework based on a graph\nauto-encoder designed to exploit structural properties of sequencing data. The\nalgorithm is a neural network which essentially trains to ignore sequencing\nerrors and infers the posteriori probabilities of the origin of sequencing\nreads. Mixture components are then reconstructed by finding consensus of the\nreads determined to originate from the same genomic component. Results on\nrealistic synthetic as well as experimental data demonstrate that the proposed\nframework reliably assembles haplotypes and reconstructs viral communities,\noften significantly outperforming state-of-the-art techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.05316v1"
    },
    {
        "title": "Deep Discriminative Fine-Tuning for Cancer Type Classification",
        "authors": [
            "Alena Harley"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Determining the primary site of origin for metastatic tumors is one of the\nopen problems in cancer care because the efficacy of treatment often depends on\nthe cancer tissue of origin. Classification methods that can leverage tumor\ngenomic data and predict the site of origin are therefore of great value.\nBecause tumor DNA point mutation data is very sparse, only limited accuracy\n(64.5% for 12 tumor classes) was previously demonstrated by methods that rely\non point mutations as features (1). Tumor classification accuracy can be\ngreatly improved (to over 90% for 33 classes) by relying on gene expression\ndata (2). However, this additional data is often not readily available in\nclinical setting, because point mutations are better profiled and targeted by\nclinical mutational profiling.\n  Here we sought to develop an accurate deep transfer learning and fine-tuning\nmethod for tumor sub-type classification, where predicted class is indicative\nof the primary site of origin. Our method significantly outperforms the\nstate-of-the-art for tumor classification using DNA point mutations, reducing\nthe error by more than 30% at the same time discriminating over many more\nclasses on The Cancer Genome Atlas (TCGA) dataset. Using our method, we achieve\nstate-of-the-art tumor type classification accuracy of 78.3% for 29 tumor\nclasses relying on DNA point mutations in the tumor only.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07654v1"
    },
    {
        "title": "Orienting Ordered Scaffolds: Complexity and Algorithms",
        "authors": [
            "Sergey Aganezov",
            "Pavel Avdeyev",
            "Nikita Alexeev",
            "Yongwu Rong",
            "Max A. Alekseyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Despite the recent progress in genome sequencing and assembly, many of the\ncurrently available assembled genomes come in a draft form. Such draft genomes\nconsist of a large number of genomic fragments (scaffolds), whose order and/or\norientation (i.e., strand) in the genome are unknown. There exist various\nscaffold assembly methods, which attempt to determine the order and orientation\nof scaffolds along the genome chromosomes. Some of these methods (e.g., based\non FISH physical mapping, chromatin conformation capture, etc.) can infer the\norder of scaffolds, but not necessarily their orientation. This leads to a\nspecial case of the scaffold orientation problem (i.e., deducing the\norientation of each scaffold) with a known order of the scaffolds.\n  We address the problem of orientating ordered scaffolds as an optimization\nproblem based on given weighted orientations of scaffolds and their pairs\n(e.g., coming from pair-end sequencing reads, long reads, or homologous\nrelations). We formalize this problem using notion of a scaffold graph (i.e., a\ngraph, where vertices correspond to the assembled contigs or scaffolds and\nedges represent connections between them). We prove that this problem is\nNP-hard, and present a polynomial-time algorithm for solving its special case,\nwhere orientation of each scaffold is imposed relatively to at most two other\nscaffolds. We further develop an FPT algorithm for the general case of the OOS\nproblem.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.11190v1"
    },
    {
        "title": "Effective Sub-clonal Cancer Representation to Predict Tumor Evolution",
        "authors": [
            "Adnan Akbar",
            "Geoffroy Dubourg-Felonneau",
            "Andrey Solovyev",
            "John W Cassidy",
            "Nirmesh Patel",
            "Harry W Clifford"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The majority of cancer treatments end in failure due to Intra-Tumor\nHeterogeneity (ITH). ITH in cancer is represented by clonal evolution where\ndifferent sub-clones compete with each other for resources under conditions of\nDarwinian natural selection. Predicting the growth of these sub-clones within a\ntumour is among the key challenges of modern cancer research. Predicting tumor\nbehavior enables the creation of risk profiles for patients and the\noptimisation of their treatment by therapeutically targeting sub-clones more\nlikely to grow. Current research efforts in this space are focused on\nmathematical modelling of population genetics to quantify the selective\nadvantage of sub-clones, thus enabling predictions of which sub-clones are more\nlikely to grow. These tumor evolution models are based on assumptions which are\nnot valid for real-world tumor micro-environment. Furthermore, these models are\noften fit on a single instance of a tumor, and hence prediction models cannot\nbe validated. This paper presents an alternative approach for predicting cancer\nevolution using a data-driven machine learning method. Our proposed method is\nbased on the intuition that if we can capture the true characteristics of\nsub-clones within a tumor and represent it in the form of features, a\nsophisticated machine learning algorithm can be trained to predict its\nbehavior. The work presented here provides a novel approach to predicting\ncancer evolution, utilizing a data-driver approach. We strongly believe that\nthe accumulation of data from microbiologists, oncologists and machine learning\nresearchers could be used to encapsulate the true essence of tumor sub-clones,\nand can play a vital role in selecting the best cancer treatments for patients.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12774v1"
    },
    {
        "title": "Class-Conditional VAE-GAN for Local-Ancestry Simulation",
        "authors": [
            "Daniel Mas Montserrat",
            "Carlos Bustamante",
            "Alexander Ioannidis"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Local ancestry inference (LAI) allows identification of the ancestry of all\nchromosomal segments in admixed individuals, and it is a critical step in the\nanalysis of human genomes with applications from pharmacogenomics and precision\nmedicine to genome-wide association studies. In recent years, many LAI\ntechniques have been developed in both industry and academic research. However,\nthese methods require large training data sets of human genomic sequences from\nthe ancestries of interest. Such reference data sets are usually limited,\nproprietary, protected by privacy restrictions, or otherwise not accessible to\nthe public. Techniques to generate training samples that resemble real haploid\nsequences from ancestries of interest can be useful tools in such scenarios,\nsince a generalized model can often be shared, but the unique human sample\nsequences cannot. In this work we present a class-conditional VAE-GAN to\ngenerate new human genomic sequences that can be used to train local ancestry\ninference (LAI) algorithms. We evaluate the quality of our generated data by\ncomparing the performance of a state-of-the-art LAI method when trained with\ngenerated versus real data.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.13220v1"
    },
    {
        "title": "Multiclass Disease Predictions Based on Integrated Clinical and Genomics\n  Datasets",
        "authors": [
            "Moeez M. Subhani",
            "Ashiq Anjum"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Clinical predictions using clinical data by computational methods are common\nin bioinformatics. However, clinical predictions using information from\ngenomics datasets as well is not a frequently observed phenomenon in research.\nPrecision medicine research requires information from all available datasets to\nprovide intelligent clinical solutions. In this paper, we have attempted to\ncreate a prediction model which uses information from both clinical and\ngenomics datasets. We have demonstrated multiclass disease predictions based on\ncombined clinical and genomics datasets using machine learning methods. We have\ncreated an integrated dataset, using a clinical (ClinVar) and a genomics (gene\nexpression) dataset, and trained it using instance-based learner to predict\nclinical diseases. We have used an innovative but simple way for multiclass\nclassification, where the number of output classes is as high as 75. We have\nused Principal Component Analysis for feature selection. The classifier\npredicted diseases with 73\\% accuracy on the integrated dataset. The results\nwere consistent and competent when compared with other classification models.\nThe results show that genomics information can be reliably included in datasets\nfor clinical predictions and it can prove to be valuable in clinical\ndiagnostics and precision medicine.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.07879v1"
    },
    {
        "title": "Dynamics of transposable elements generates structure and symmetries in\n  genetic sequences",
        "authors": [
            "Giampaolo Cristadoro",
            "Mirko Degli Esposti",
            "Eduardo G. Altmann"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Genetic sequences are known to possess non-trivial composition together with\nsymmetries in the frequencies of their components. Recently, it has been shown\nthat symmetry and structure are hierarchically intertwined in DNA, suggesting a\ncommon origin for both features. However, the mechanism leading to this\nrelationship is unknown. Here we investigate a biologically motivated dynamics\nfor the evolution of genetic sequences. We show that a metastable (long-lived)\nregime emerges in which sequences have symmetry and structure interlaced in a\nway that matches that of extant genomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.12017v1"
    },
    {
        "title": "Circuits with broken fibration symmetries perform core logic\n  computations in biological networks",
        "authors": [
            "Ian Leifer",
            "Flaviano Morone",
            "Saulo D. S. Reis",
            "Jose S. Andrade Jr.",
            "Mariano Sigman",
            "Hernan A. Makse"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  We show that logic computational circuits in gene regulatory networks arise\nfrom a fibration symmetry breaking in the network structure. From this idea we\nimplement a constructive procedure that reveals a hierarchy of genetic\ncircuits, ubiquitous across species, that are surprising analogues to the\nemblematic circuits of solid-state electronics: starting from the transistor\nand progressing to ring oscillators, current-mirror circuits to toggle switches\nand flip-flops. These canonical variants serve fundamental operations of\nsynchronization and clocks (in their symmetric states) and memory storage (in\ntheir broken symmetry states). These conclusions introduce a theoretically\nprincipled strategy to search for computational building blocks in biological\nnetworks, and present a systematic route to design synthetic biological\ncircuits.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13334v1"
    },
    {
        "title": "RLeave: an in silico cross-validation protocol for transcript\n  differential expression analysis",
        "authors": [
            "Matheus Costa e Silva",
            "Norma Lucena-Silva",
            "Juliana Doblas Massaro",
            "Eduardo Antônio Donadi"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Background and Objective: The massive parallel sequencing technology\nfacilitates new discoveries in terms of transcript differential analysis;\nhowever, all the new findings must be validated, since the diversity of\ntranscript expression may impair the identification of the most relevant ones.\n  Methods: The proposed RLeave algorithm (implemented in the R environment)\nutilizes a combination of conventional analysis (classic edgeR) together with\nother mathematical methods (Leave-one-out sample technique and Decision Trees\nvalidation) to identify more relevant candidates to be in vitro or in silico\nvalidated.\n  Results: The RLeave protocol was tested using miRNome expression analysis of\ntwo sample groups (diabetes mellitus and acute lymphoblastic leukemia), and\nboth had their most important differentially expressed miRNA confirmed by\nRT-qPCR.\n  Conclusion: This protocol is applicable in RNA-SEQ research, highlighting the\nmost relevant transcripts for in silico and/or in vitro validation.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.05421v1"
    },
    {
        "title": "The Gene Mover's Distance: Single-cell similarity via Optimal Transport",
        "authors": [
            "Riccardo Bellazzi",
            "Andrea Codegoni",
            "Stefano Gualandi",
            "Giovanna Nicora",
            "Eleonora Vercesi"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  This paper introduces the Gene Mover's Distance, a measure of similarity\nbetween a pair of cells based on their gene expression profiles obtained via\nsingle-cell RNA sequencing. The underlying idea of the proposed distance is to\ninterpret the gene expression array of a single cell as a discrete probability\nmeasure. The distance between two cells is hence computed by solving an Optimal\nTransport problem between the two corresponding discrete measures. In the\nOptimal Transport model, we use two types of cost function for measuring the\ndistance between a pair of genes. The first cost function exploits a gene\nembedding, called gene2vec, which is used to map each gene to a high\ndimensional vector: the cost of moving a unit of mass of gene expression from a\ngene to another is set to the Euclidean distance between the corresponding\nembedded vectors. The second cost function is based on a Pearson distance among\npairs of genes. In both cost functions, the more two genes are correlated, the\nlower is their distance. We exploit the Gene Mover's Distance to solve two\nclassification problems: the classification of cells according to their\ncondition and according to their type. To assess the impact of our new metric,\nwe compare the performances of a $k$-Nearest Neighbor classifier using\ndifferent distances. The computational results show that the Gene Mover's\nDistance is competitive with the state-of-the-art distances used in the\nliterature.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01218v2"
    },
    {
        "title": "A step toward a reinforcement learning de novo genome assembler",
        "authors": [
            "Kleber Padovani",
            "Roberto Xavier",
            "Rafael Cabral Borges",
            "Andre Carvalho",
            "Anna Reali",
            "Annie Chateau",
            "Ronnie Alves"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  De novo genome assembly is a relevant but computationally complex task in\ngenomics. Although de novo assemblers have been used successfully in several\ngenomics projects, there is still no 'best assembler', and the choice and setup\nof assemblers still rely on bioinformatics experts. Thus, as with other\ncomputationally complex problems, machine learning may emerge as an alternative\n(or complementary) way for developing more accurate and automated assemblers.\nReinforcement learning has proven promising for solving complex activities\nwithout supervision - such games - and there is a pressing need to understand\nthe limits of this approach to 'real' problems, such as the DFA problem. This\nstudy aimed to shed light on the application of machine learning, using\nreinforcement learning (RL), in genome assembly. We expanded upon the sole\nprevious approach found in the literature to solve this problem by carefully\nexploring the learning aspects of the proposed intelligent agent, which uses\nthe Q-learning algorithm, and we provided insights for the next steps of\nautomated genome assembly development. We improved the reward system and\noptimized the exploration of the state space based on pruning and in\ncollaboration with evolutionary computing. We tested the new approaches on 23\nnew larger environments, which are all available on the internet. Our results\nsuggest consistent performance progress; however, we also found limitations,\nespecially concerning the high dimensionality of state and action spaces.\nFinally, we discuss paths for achieving efficient and automated genome assembly\nin real scenarios considering successful RL applications - including deep\nreinforcement learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02649v4"
    },
    {
        "title": "On Utility and Privacy in Synthetic Genomic Data",
        "authors": [
            "Bristena Oprisanu",
            "Georgi Ganev",
            "Emiliano De Cristofaro"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The availability of genomic data is essential to progress in biomedical\nresearch, personalized medicine, etc. However, its extreme sensitivity makes it\nproblematic, if not outright impossible, to publish or share it. As a result,\nseveral initiatives have been launched to experiment with synthetic genomic\ndata, e.g., using generative models to learn the underlying distribution of the\nreal data and generate artificial datasets that preserve its salient\ncharacteristics without exposing it. This paper provides the first evaluation\nof both utility and privacy protection of six state-of-the-art models for\ngenerating synthetic genomic data. We assess the performance of the synthetic\ndata on several common tasks, such as allele population statistics and linkage\ndisequilibrium. We then measure privacy through the lens of membership\ninference attacks, i.e., inferring whether a record was part of the training\ndata. Our experiments show that no single approach to generate synthetic\ngenomic data yields both high utility and strong privacy across the board.\nAlso, the size and nature of the training dataset matter. Moreover, while some\ncombinations of datasets and models produce synthetic data with distributions\nclose to the real data, there often are target data points that are vulnerable\nto membership inference. Looking forward, our techniques can be used by\npractitioners to assess the risks of deploying synthetic genomic data in the\nwild and serve as a benchmark for future work.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03314v3"
    },
    {
        "title": "The unmasking of Mitochondrial Adam and Structural Variants larger than\n  point mutations as stronger candidates for traits, disease phenotype and sex\n  determination",
        "authors": [
            "Abhishek Narain Singh"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: Structural Variations, SVs, in a genome can be linked to a\ndisease or characteristic phenotype. The variations come in many types and it\nis a challenge, not only determining the variations accurately, but also\nconducting the downstream statistical and analytical procedure. Method:\nStructural variations, SVs, with size 1 base-pair to 1000s of base-pairs with\ntheir precise breakpoints and single-nucleotide polymorphisms, SNPs, were\ndetermined for members of a family. The genome was assembled using optimal\nmetrics of ABySS and SOAPdenovo assembly tools using paired-end DNA sequence.\nResults: An interesting discovery was the mitochondrial DNA could have paternal\nleakage of inheritance or that the mutations could be high from maternal\ninheritance. It is also discovered that the mitochondrial DNA is less prone to\nSVs re-arrangements than SNPs, which propose better standards for determining\nancestry and divergence between races and species over a long-time frame. Sex\ndetermination of an individual is found to be strongly confirmed using calls of\nnucleotide bases of SVs to the Y chromosome, more strongly determined than\nSNPs. We note that in general there is a larger variance -and thus the standard\ndeviation, in the sum of SVs nucleotide compared to sum of SNPs of an\nindividual when compared to reference sequence, and thus SVs serve as a\nstronger means to characterize an individual for a given trait or phenotype or\nto determine sex. The SVs and SNPs in HLA loci would also serve as a medical\ntransformation method for determining the success of an organ transplant for a\npatient, and predisposition to diseases apriori.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.13469v1"
    },
    {
        "title": "RNA Alternative Splicing Prediction with Discrete Compositional Energy\n  Network",
        "authors": [
            "Alvin Chan",
            "Anna Korsakova",
            "Yew-Soon Ong",
            "Fernaldo Richtia Winnerdy",
            "Kah Wai Lim",
            "Anh Tuan Phan"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  A single gene can encode for different protein versions through a process\ncalled alternative splicing. Since proteins play major roles in cellular\nfunctions, aberrant splicing profiles can result in a variety of diseases,\nincluding cancers. Alternative splicing is determined by the gene's primary\nsequence and other regulatory factors such as RNA-binding protein levels. With\nthese as input, we formulate the prediction of RNA splicing as a regression\ntask and build a new training dataset (CAPD) to benchmark learned models. We\npropose discrete compositional energy network (DCEN) which leverages the\nhierarchical relationships between splice sites, junctions and transcripts to\napproach this task. In the case of alternative splicing prediction, DCEN models\nmRNA transcript probabilities through its constituent splice junctions' energy\nvalues. These transcript probabilities are subsequently mapped to relative\nabundance values of key nucleotides and trained with ground-truth experimental\nmeasurements. Through our experiments on CAPD, we show that DCEN outperforms\nbaselines and ablation variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.04246v1"
    },
    {
        "title": "GraphBreak: Tool for Network Community based Regulatory Medicine, Gene\n  co-expression, Linkage Disequilibrium analysis, functional annotation and\n  more",
        "authors": [
            "Abhishek Narain Singh"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Graph network science is becoming increasingly popular, notably in big-data\nperspective where understanding individual entities for individual functional\nroles is complex and time consuming. It is likely when a set of genes are\nregulated by a set of genetic variants, the genes set is recruited for a common\nor related functional purpose. Grouping and extracting communities from network\nof associations becomes critical to understand system complexity, thus\nprioritizing genes for dis-ease and functional associations. Workload is\nreduced when studying entities one at a time. For this, we present GraphBreak,\na suite of tools for community detection application, such as for gene\nco-expression, protein interaction, regulation network, etc.Although developed\nfor use case of eQTLs regulatory genomic net-work community study -- results\nshown with our analysis with sample eQTL data. Graphbreak can be deployed for\nother studies if input data has been fed in requisite format, including but not\nlimited to gene co-expression networks, protein-protein interaction network,\nsignaling pathway and metabolic network. Graph-Break showed critical use case\nvalue in its downstream analysis for disease association of communities\ndetected. If all independent steps of community detection and analysis are a\nstep-by-step sub-part of the algorithm, GraphBreak can be considered a new\nalgorithm for community based functional characterization. Combination of\nvarious algorithmic implementation modules into a single script for this\npurpose illustrates GraphBreak novelty. Compared to other similar tools, with\nGraphBreak we can better detect communities with over-representation of its\nmember genes for statistical association with diseases, therefore target genes\nwhich can be prioritized for drug-positioning or drug-re-positioning as the\ncase be.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.06145v1"
    },
    {
        "title": "Brain tumour genetic network signatures of survival",
        "authors": [
            "James K Ruffle",
            "Samia Mohinta",
            "Guilherme Pombo",
            "Robert Gray",
            "Valeriya Kopanitsa",
            "Faith Lee",
            "Sebastian Brandner",
            "Harpreet Hyare",
            "Parashkev Nachev"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Tumour heterogeneity is increasingly recognized as a major obstacle to\ntherapeutic success across neuro-oncology. Gliomas are characterised by\ndistinct combinations of genetic and epigenetic alterations, resulting in\ncomplex interactions across multiple molecular pathways. Predicting disease\nevolution and prescribing individually optimal treatment requires statistical\nmodels complex enough to capture the intricate (epi)genetic structure\nunderpinning oncogenesis. Here, we formalize this task as the inference of\ndistinct patterns of connectivity within hierarchical latent representations of\ngenetic networks. Evaluating multi-institutional clinical, genetic, and outcome\ndata from 4023 glioma patients over 14 years, across 12 countries, we employ\nBayesian generative stochastic block modelling to reveal a hierarchical network\nstructure of tumour genetics spanning molecularly confirmed glioblastoma, IDH-\nwildtype; oligodendroglioma, IDH-mutant and 1p/19q codeleted; and astrocytoma,\nIDH- mutant. Our findings illuminate the complex dependence between features\nacross the genetic landscape of brain tumours, and show that generative network\nmodels reveal distinct signatures of survival with better prognostic fidelity\nthan current gold standard diagnostic categories.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.06111v2"
    },
    {
        "title": "3D genome reconstruction from partially phased Hi-C data",
        "authors": [
            "Diego Cifuentes",
            "Jan Draisma",
            "Oskar Henriksson",
            "Annachiara Korchmaros",
            "Kaie Kubjas"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The 3-dimensional (3D) structure of the genome is of significant importance\nfor many cellular processes. In this paper, we study the problem of\nreconstructing the 3D structure of chromosomes from Hi-C data of diploid\norganisms, which poses additional challenges compared to the better-studied\nhaploid setting. With the help of techniques from algebraic geometry, we prove\nthat a small amount of phased data is sufficient to ensure finite\nidentifiability, both for noiseless and noisy data. In the light of these\nresults, we propose a new 3D reconstruction method based on semidefinite\nprogramming, paired with numerical algebraic geometry and local optimization.\nThe performance of this method is tested on several simulated datasets under\ndifferent noise levels and with different amounts of phased data. We also apply\nit to a real dataset from mouse X chromosomes, and we are then able to recover\npreviously known structural features.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.11764v2"
    },
    {
        "title": "Empirical Bayes estimation of posterior probabilities of enrichment",
        "authors": [
            "Zhenyu Yang",
            "Zuojing Li",
            "David R. Bickel"
        ],
        "category": "q-bio.GN",
        "published_year": "2011",
        "summary": "  To interpret differentially expressed genes or other discovered features,\nresearchers conduct hypothesis tests to determine which biological categories\nsuch as those of the Gene Ontology (GO) are enriched in the sense of having\ndifferential representation among the discovered features. We study application\nof better estimators of the local false discovery rate (LFDR), a probability\nthat the biological category has equivalent representation among the\npreselected features.\n  We identified three promising estimators of the LFDR for detecting\ndifferential representation: a semiparametric estimator (SPE), a normalized\nmaximum likelihood estimator (NMLE), and a maximum likelihood estimator (MLE).\nWe found that the MLE performs at least as well as the SPE for on the order of\n100 of GO categories even when the ideal number of components in its underlying\nmixture model is unknown. However, the MLE is unreliable when the number of GO\ncategories is small compared to the number of PMM components. Thus, if the\nnumber of categories is on the order of 10, the SPE is a more reliable LFDR\nestimator. The NMLE depends not only on the data but also on a specified value\nof the prior probability of differential representation. It is therefore an\nappropriate LFDR estimator only when the number of GO categories is too small\nfor application of the other methods.\n  For enrichment detection, we recommend estimating the LFDR by the MLE given\nat least a medium number (~100) of GO categories, by the SPE given a small\nnumber of GO categories (~10), and by the NMLE given a very small number (~1)\nof GO categories.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.0153v1"
    },
    {
        "title": "Nucleosomes in gene regulation: theoretical approaches",
        "authors": [
            "V. B. Teif",
            "A. V. Shkrabkou",
            "V. P. Egorova",
            "V. I. Krot"
        ],
        "category": "q-bio.GN",
        "published_year": "2012",
        "summary": "  This work reviews current theoretical approaches of biophysics and\nbioinformatics for the description of nucleosome arrangements in chromatin and\ntranscription factor binding to nucleosomal organized DNA. The role of\nnucleosomes in gene regulation is discussed from molecular-mechanistic and\nbiological point of view. In addition to classical problems of this field,\nactual questions of epigenetic regulation are discussed. The authors selected\nfor discussion what seem to be the most interesting concepts and hypotheses.\nMathematical approaches are described in a simplified language to attract\nattention to the most important directions of this field.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.0921v1"
    },
    {
        "title": "A conditional compression distance that unveils insights of the genomic\n  evolution",
        "authors": [
            "Diogo Pratas",
            "Armando J. Pinho"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  We describe a compression-based distance for genomic sequences. Instead of\nusing the usual conjoint information content, as in the classical Normalized\nCompression Distance (NCD), it uses the conditional information content. To\ncompute this Normalized Conditional Compression Distance (NCCD), we need a\nnormal conditional compressor, that we built using a mixture of static and\ndynamic finite-context models. Using this approach, we measured chromosomal\ndistances between Hominidae primates and also between Muroidea (rat and mouse),\nobserving several insights of evolution that so far have not been reported in\nthe literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4134v1"
    },
    {
        "title": "Information profiles for DNA pattern discovery",
        "authors": [
            "Armando J. Pinho",
            "Diogo Pratas",
            "Paulo J. S. G. Ferreira"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Finite-context modeling is a powerful tool for compressing and hence for\nrepresenting DNA sequences. We describe an algorithm to detect genomic\nregularities, within a blind discovery strategy. The algorithm uses information\nprofiles built using suitable combinations of finite-context models. We used\nthe genome of the fission yeast Schizosaccharomyces pombe strain 972 h- for\nillustration, unveilling locations of low information content, which are\nusually associated with DNA regions of potential biological interest.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4725v1"
    },
    {
        "title": "GPU-Accelerated BWT Construction for Large Collection of Short Reads",
        "authors": [
            "Chi-Man Liu",
            "Ruibang Luo",
            "Tak-Wah Lam"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Advances in DNA sequencing technology have stimulated the development of\nalgorithms and tools for processing very large collections of short strings\n(reads). Short-read alignment and assembly are among the most well-studied\nproblems. Many state-of-the-art aligners, at their core, have used the\nBurrows-Wheeler transform (BWT) as a main-memory index of a reference genome\n(typical example, NCBI human genome). Recently, BWT has also found its use in\nstring-graph assembly, for indexing the reads (i.e., raw data from DNA\nsequencers). In a typical data set, the volume of reads is tens of times of the\nsequenced genome and can be up to 100 Gigabases. Note that a reference genome\nis relatively stable and computing the index is not a frequent task. For reads,\nthe index has to computed from scratch for each given input. The ability of\nefficient BWT construction becomes a much bigger concern than before. In this\npaper, we present a practical method called CX1 for constructing the BWT of\nvery large string collections. CX1 is the first tool that can take advantage of\nthe parallelism given by a graphics processing unit (GPU, a relative cheap\ndevice providing a thousand or more primitive cores), as well as simultaneously\nthe parallelism from a multi-core CPU and more interestingly, from a cluster of\nGPU-enabled nodes. Using CX1, the BWT of a short-read collection of up to 100\nGigabases can be constructed in less than 2 hours using a machine equipped with\na quad-core CPU and a GPU, or in about 43 minutes using a cluster with 4 such\nmachines (the speedup is almost linear after excluding the first 16 minutes for\nloading the reads from the hard disk). The previously fastest tool BRC is\nmeasured to take 12 hours to process 100 Gigabases on one machine; it is\nnon-trivial how BRC can be parallelized to take advantage a cluster of\nmachines, let alone GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.7457v1"
    },
    {
        "title": "Topological Features In Cancer Gene Expression Data",
        "authors": [
            "Svetlana Lockwood",
            "Bala Krishnamoorthy"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  We present a new method for exploring cancer gene expression data based on\ntools from algebraic topology. Our method selects a small relevant subset from\ntens of thousands of genes while simultaneously identifying nontrivial higher\norder topological features, i.e., holes, in the data. We first circumvent the\nproblem of high dimensionality by dualizing the data, i.e., by studying genes\nas points in the sample space. Then we select a small subset of the genes as\nlandmarks to construct topological structures that capture persistent, i.e.,\ntopologically significant, features of the data set in its first homology\ngroup. Furthermore, we demonstrate that many members of these loops have been\nimplicated for cancer biogenesis in scientific literature. We illustrate our\nmethod on five different data sets belonging to brain, breast, leukemia, and\novarian cancers.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.3198v1"
    },
    {
        "title": "Btrim: A fast, lightweight adapter and quality trimming program for\n  next-generation sequencing technologies",
        "authors": [
            "Yong Kong"
        ],
        "category": "q-bio.GN",
        "published_year": "2014",
        "summary": "  Btrim is a fast and lightweight software to trim adapters and low quality\nregions in reads from ultra high-throughput next-generation sequencing\nmachines. It also can reliably identify barcodes and assign the reads to the\noriginal samples. Based on a modified Myers's bit-vector dynamic programming\nalgorithm, Btrim can handle indels in adapters and barcodes. It removes low\nquality regions and trims off adapters at both or either end of the reads. A\ntypical trimming of 30M reads with two sets of adapter pairs can be done in\nabout a minute with a small memory footprint. Btrim is a versatile stand-alone\ntool that can be used as the first step in virtually all next-generation\nsequence analysis pipelines. The program is available at\n\\url{http://graphics.med.yale.edu/trim/}.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.6455v1"
    },
    {
        "title": "A Computational Method for the Rate Estimation of Evolutionary\n  Transpositions",
        "authors": [
            "Nikita Alexeev",
            "Rustem Aidagulov",
            "Max A. Alekseyev"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Genome rearrangements are evolutionary events that shuffle genomic\narchitectures. Most frequent genome rearrangements are reversals,\ntranslocations, fusions, and fissions. While there are some more complex genome\nrearrangements such as transpositions, they are rarely observed and believed to\nconstitute only a small fraction of genome rearrangements happening in the\ncourse of evolution. The analysis of transpositions is further obfuscated by\nintractability of the underlying computational problems.\n  We propose a computational method for estimating the rate of transpositions\nin evolutionary scenarios between genomes. We applied our method to a set of\nmammalian genomes and estimated the transpositions rate in mammalian evolution\nto be around 0.26.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.07546v1"
    },
    {
        "title": "Sequence assembly from corrupted shotgun reads",
        "authors": [
            "Shirshendu Ganguly",
            "Elchanan Mossel",
            "Miklos Z. Racz"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  The prevalent technique for DNA sequencing consists of two main steps:\nshotgun sequencing, where many randomly located fragments, called reads, are\nextracted from the overall sequence, followed by an assembly algorithm that\naims to reconstruct the original sequence. There are many different\ntechnologies that generate the reads: widely-used second-generation methods\ncreate short reads with low error rates, while emerging third-generation\nmethods create long reads with high error rates. Both error rates and error\nprofiles differ among methods, so reconstruction algorithms are often tailored\nto specific shotgun sequencing technologies. As these methods change over time,\na fundamental question is whether there exist reconstruction algorithms which\nare robust, i.e., which perform well under a wide range of error distributions.\n  Here we study this question of sequence assembly from corrupted reads. We\nmake no assumption on the types of errors in the reads, but only assume a bound\non their magnitude. More precisely, for each read we assume that instead of\nreceiving the true read with no errors, we receive a corrupted read which has\nedit distance at most $\\epsilon$ times the length of the read from the true\nread. We show that if the reads are long enough and there are sufficiently many\nof them, then approximate reconstruction is possible: we construct a simple\nalgorithm such that for almost all original sequences the output of the\nalgorithm is a sequence whose edit distance from the original one is at most\n$O(\\epsilon)$ times the length of the original sequence.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.07086v1"
    },
    {
        "title": "Modelling the evolution of transcription factor binding preferences in\n  complex eukaryotes",
        "authors": [
            "Antonio Rosanova",
            "Alberto Colliva",
            "Matteo Osella",
            "Michele Caselle"
        ],
        "category": "q-bio.GN",
        "published_year": "2016",
        "summary": "  Transcription factors (TFs) exert their regulatory action by binding to DNA\nwith specific sequence preferences. However, different TFs can partially share\ntheir binding sequences due to their common evolutionary origin. This\n`redundancy' of binding defines a way of organizing TFs in `motif families' by\ngrouping TFs with similar binding preferences. Since these ultimately define\nthe TF target genes, the motif family organization entails information about\nthe structure of transcriptional regulation as it has been shaped by evolution.\nFocusing on the human TF repertoire, we show that a one-parameter evolutionary\nmodel of the Birth-Death-Innovation type can explain the TF empirical\nripartition in motif families, and allows to highlight the relevant\nevolutionary forces at the origin of this organization. Moreover, the model\nallows to pinpoint few deviations from the neutral scenario it assumes: three\nover-expanded families (including HOX and FOX genes), a set of `singleton' TFs\nfor which duplication seems to be selected against, and a higher-than-average\nrate of diversification of the binding preferences of TFs with a Zinc Finger\nDNA binding domain. Finally, a comparison of the TF motif family organization\nin different eukaryotic species suggests an increase of redundancy of binding\nwith organism complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.01219v2"
    },
    {
        "title": "Deep Neural Network for Analysis of DNA Methylation Data",
        "authors": [
            "Hong Yu",
            "Zhanyu Ma"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Many researches demonstrated that the DNA methylation, which occurs in the\ncontext of a CpG, has strong correlation with diseases, including cancer. There\nis a strong interest in analyzing the DNA methylation data to find how to\ndistinguish different subtypes of the tumor. However, the conventional\nstatistical methods are not suitable for analyzing the highly dimensional DNA\nmethylation data with bounded support. In order to explicitly capture the\nproperties of the data, we design a deep neural network, which composes of\nseveral stacked binary restricted Boltzmann machines, to learn the low\ndimensional deep features of the DNA methylation data. Experiments show these\nfeatures perform best in breast cancer DNA methylation data cluster analysis,\ncomparing with some state-of-the-art methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.01359v2"
    },
    {
        "title": "Synergistic Drug Combination Prediction by Integrating Multi-omics Data\n  in Deep Learning Models",
        "authors": [
            "Tianyu Zhang",
            "Liwei Zhang",
            "Philip R. O. Payne",
            "Fuhai Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Drug resistance is still a major challenge in cancer therapy. Drug\ncombination is expected to overcome drug resistance. However, the number of\npossible drug combinations is enormous, and thus it is infeasible to\nexperimentally screen all effective drug combinations considering the limited\nresources. Therefore, computational models to predict and prioritize effective\ndrug combinations is important for combinatory therapy discovery in cancer. In\nthis study, we proposed a novel deep learning model, AuDNNsynergy, to\nprediction drug combinations by integrating multi-omics data and chemical\nstructure data. In specific, three autoencoders were trained using the gene\nexpression, copy number and genetic mutation data of all tumor samples from The\nCancer Genome Atlas. Then the physicochemical properties of drugs combined with\nthe output of the three autoencoders, characterizing the individual cancer\ncell-lines, were used as the input of a deep neural network that predicts the\nsynergy value of given pair-wise drug combinations against the specific cancer\ncell-lines. The comparison results showed the proposed AuDNNsynergy model\noutperforms four state-of-art approaches, namely DeepSynergy, Gradient Boosting\nMachines, Random Forests, and Elastic Nets. Moreover, we conducted the\ninterpretation analysis of the deep learning model to investigate potential\nvital genetic predictors and the underlying mechanism of synergistic drug\ncombinations on specific cancer cell-lines.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07054v1"
    },
    {
        "title": "Inference of the three-dimensional chromatin structure and its temporal\n  behavior",
        "authors": [
            "Bianca-Cristina Cristescu",
            "Zalán Borsos",
            "John Lygeros",
            "María Rodríguez Martínez",
            "Maria Anna Rapsomaniki"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  Understanding the three-dimensional (3D) structure of the genome is essential\nfor elucidating vital biological processes and their links to human disease. To\ndetermine how the genome folds within the nucleus, chromosome conformation\ncapture methods such as HiC have recently been employed. However, computational\nmethods that exploit the resulting high-throughput, high-resolution data are\nstill suffering from important limitations. In this work, we explore the idea\nof manifold learning for the 3D chromatin structure inference and present a\nnovel method, REcurrent Autoencoders for CHromatin 3D structure prediction\n(REACH-3D). Our framework employs autoencoders with recurrent neural units to\nreconstruct the chromatin structure. In comparison to existing methods,\nREACH-3D makes no transfer function assumption and permits dynamic analysis.\nEvaluating REACH-3D on synthetic data indicated high agreement with the ground\ntruth. When tested on real experimental HiC data, REACH-3D recovered most\nfaithfully the expected biological properties and obtained the highest\ncorrelation coefficient with microscopy measurements. Last, REACH-3D was\napplied to dynamic HiC data, where it successfully modeled chromatin\nconformation during the cell cycle.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.09619v1"
    },
    {
        "title": "Interlacing Personal and Reference Genomes for Machine Learning\n  Disease-Variant Detection",
        "authors": [
            "Luke R Harries",
            "Suyi Zhang",
            "Geoffroy Dubourg-Felonneau",
            "James H R Farmery",
            "Jonathan Sinai",
            "Belle Taylor",
            "Nirmesh Patel",
            "John W Cassidy",
            "John Shawe-Taylor",
            "Harry W Clifford"
        ],
        "category": "q-bio.GN",
        "published_year": "2018",
        "summary": "  DNA sequencing to identify genetic variants is becoming increasingly valuable\nin clinical settings. Assessment of variants in such sequencing data is\ncommonly implemented through Bayesian heuristic algorithms. Machine learning\nhas shown great promise in improving on these variant calls, but the input for\nthese is still a standardized \"pile-up\" image, which is not always best suited.\nIn this paper, we present a novel method for generating images from DNA\nsequencing data, which interlaces the human reference genome with personalized\nsequencing output, to maximize usage of sequencing reads and improve machine\nlearning algorithm performance. We demonstrate the success of this in improving\nstandard germline variant calling. We also furthered this approach to include\nsomatic variant calling across tumor/normal data with Siamese networks. These\napproaches can be used in machine learning applications on sequencing data with\nthe hope of improving clinical outcomes, and are freely available for\nnoncommercial use at www.ccg.ai.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.11674v1"
    },
    {
        "title": "Determining Multifunctional Genes and Diseases in Human Using Gene\n  Ontology",
        "authors": [
            "Hisham Al-Mubaid",
            "Sasikanth Potu",
            "M. Shenify"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The study of human genes and diseases is very rewarding and can lead to\nimprovements in healthcare, disease diagnostics and drug discovery. In this\npaper, we further our previous study on gene disease relationship specifically\nwith the multifunctional genes. We investigate the multifunctional gene disease\nrelationship based on the published molecular function annotations of genes\nfrom the Gene Ontology which is the most comprehensive source on gene\nfunctions.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.04847v1"
    },
    {
        "title": "Dual Graph-Laplacian PCA: A Closed-Form Solution for Bi-clustering to\n  Find \"Checkerboard\" Structures on Gene Expression Data",
        "authors": [
            "Jin-Xing Liu",
            "Chun-Mei Feng",
            "Xiang-Zhen Kong",
            "Yong Xu"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  In the context of cancer, internal \"checkerboard\" structures are normally\nfound in the matrices of gene expression data, which correspond to genes that\nare significantly up- or down-regulated in patients with specific types of\ntumors. In this paper, we propose a novel method, called dual\ngraph-regularization principal component analysis (DGPCA). The main innovation\nof this method is that it simultaneously considers the internal geometric\nstructures of the condition manifold and the gene manifold. Specifically, we\nobtain principal components (PCs) to represent the data and approximate the\ncluster membership indicators through Laplacian embedding. This new method is\nendowed with internal geometric structures, such as the condition manifold and\ngene manifold, which are both suitable for bi-clustering. A closed-form\nsolution is provided for DGPCA. We apply this new method to simultaneously\ncluster genes and conditions (e.g., different samples) with the aim of finding\ninternal \"checkerboard\" structures on gene expression data, if they exist.\nThen, we use this new method to identify regulatory genes under the particular\nconditions and to compare the results with those of other state-of-the-art\nPCA-based methods. Promising results on gene expression data have been verified\nby extensive experiments\n",
        "pdf_link": "http://arxiv.org/pdf/1901.06794v1"
    },
    {
        "title": "GeNet: Deep Representations for Metagenomics",
        "authors": [
            "Mateo Rojas-Carulla",
            "Ilya Tolstikhin",
            "Guillermo Luque",
            "Nicholas Youngblut",
            "Ruth Ley",
            "Bernhard Schölkopf"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  We introduce GeNet, a method for shotgun metagenomic classification from raw\nDNA sequences that exploits the known hierarchical structure between labels for\ntraining. We provide a comparison with state-of-the-art methods Kraken and\nCentrifuge on datasets obtained from several sequencing technologies, in which\ndataset shift occurs. We show that GeNet obtains competitive precision and good\nrecall, with orders of magnitude less memory requirements. Moreover, we show\nthat a linear model trained on top of representations learned by GeNet achieves\nrecall comparable to state-of-the-art methods on the aforementioned datasets,\nand achieves over 90% accuracy in a challenging pathogen detection problem.\nThis provides evidence of the usefulness of the representations learned by\nGeNet for downstream biological tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11015v1"
    },
    {
        "title": "Identifying Epigenetic Signature of Breast Cancer with Machine Learning",
        "authors": [
            "Maxim Vaysburd"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The research reported in this paper identifies the epigenetic biomarker\n(methylation beta pattern) of breast cancer. Many cancers are triggered by\nabnormal gene expression levels caused by aberrant methylation of CpG sites in\nthe DNA. In order to develop early diagnostics of cancer-causing methylations\nand to develop a treatment, it is necessary to identify a few dozen key\ncancer-related CpG methylation sites out of the millions of locations in the\nDNA. This research used public TCGA dataset to train a TensorFlow machine\nlearning model to classify breast cancer versus non-breast-cancer tissue\nsamples, based on over 300,000 methylation beta values in each sample. L1\nregularization was applied to identify the CpG methylation sites most important\nfor accurate classification. It was hypothesized that CpG sites with the\nhighest learned model weights correspond to DNA locations most relevant to\nbreast cancer. A reduced model trained on methylation betas of just the 25 CpG\nsites having the highest weights in the full model (trained on methylation\nbetas at over 300,000 CpG sites) has achieved over 94% accuracy on evaluation\ndata, confirming that the identified 25 CpG sites are indeed a biomarker of\nbreast cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.06899v1"
    },
    {
        "title": "SneakySnake: A Fast and Accurate Universal Genome Pre-Alignment Filter\n  for CPUs, GPUs, and FPGAs",
        "authors": [
            "Mohammed Alser",
            "Taha Shahroodi",
            "Juan Gomez-Luna",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Motivation: We introduce SneakySnake, a highly parallel and highly accurate\npre-alignment filter that remarkably reduces the need for computationally\ncostly sequence alignment. The key idea of SneakySnake is to reduce the\napproximate string matching (ASM) problem to the single net routing (SNR)\nproblem in VLSI chip layout. In the SNR problem, we are interested in finding\nthe optimal path that connects two terminals with the least routing cost on a\nspecial grid layout that contains obstacles. The SneakySnake algorithm quickly\nsolves the SNR problem and uses the found optimal path to decide whether or not\nperforming sequence alignment is necessary. Reducing the ASM problem into SNR\nalso makes SneakySnake efficient to implement on CPUs, GPUs, and FPGAs.\nResults: SneakySnake significantly improves the accuracy of pre-alignment\nfiltering by up to four orders of magnitude compared to the state-of-the-art\npre-alignment filters, Shouji, GateKeeper, and SHD. For short sequences,\nSneakySnake accelerates Edlib (state-of-the-art implementation of Myers's\nbit-vector algorithm) and Parasail (state-of-the-art sequence aligner with a\nconfigurable scoring function), by up to 37.7x and 43.9x (>12x on average),\nrespectively, with its CPU implementation, and by up to 413x and 689x (>400x on\naverage), respectively, with FPGA and GPU acceleration. For long sequences, the\nCPU implementation of SneakySnake accelerates Parasail and KSW2 (sequence\naligner of minimap2) by up to 979x (276.9x on average) and 91.7x (31.7x on\naverage), respectively. As SneakySnake does not replace sequence alignment,\nusers can still obtain all capabilities (e.g., configurable scoring functions)\nof the aligner of their choice, unlike existing acceleration efforts that\nsacrifice some aligner capabilities. Availability:\nhttps://github.com/CMU-SAFARI/SneakySnake\n",
        "pdf_link": "http://arxiv.org/pdf/1910.09020v3"
    },
    {
        "title": "Is graph-based feature selection of genes better than random?",
        "authors": [
            "Mohammad Hashir",
            "Paul Bertin",
            "Martin Weiss",
            "Vincent Frappier",
            "Theodore J. Perkins",
            "Geneviève Boucher",
            "Joseph Paul Cohen"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Gene interaction graphs aim to capture various relationships between genes\nand represent decades of biology research. When trying to make predictions from\ngenomic data, those graphs could be used to overcome the curse of\ndimensionality by making machine learning models sparser and more consistent\nwith biological common knowledge. In this work, we focus on assessing whether\nthose graphs capture dependencies seen in gene expression data better than\nrandom. We formulate a condition that graphs should satisfy to provide a good\nprior knowledge and propose to test it using a `Single Gene Inference' (SGI)\ntask. We compare random graphs with seven major gene interaction graphs\npublished by different research groups, aiming to measure the true benefit of\nusing biologically relevant graphs in this context. Our analysis finds that\ndependencies can be captured almost as well at random which suggests that, in\nterms of gene expression levels, the relevant information about the state of\nthe cell is spread across many genes.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.09600v3"
    },
    {
        "title": "Assessment of Multiple-Biomarker Classifiers: fundamental principles and\n  a proposed strategy",
        "authors": [
            "Waleed A. Yousef"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  The multiple-biomarker classifier problem and its assessment are reviewed\nagainst the background of some fundamental principles from the field of\nstatistical pattern recognition, machine learning, or the recently so-called\n\"data science\". A narrow reading of that literature has led many authors to\nneglect the contribution to the total uncertainty of performance assessment\nfrom the finite training sample. Yet the latter is a fundamental indicator of\nthe stability of a classifier; thus its neglect may be contributing to the\nproblematic status of many studies. A three-level strategy is proposed for\nmoving forward in this field. The lowest level is that of construction, where\ncandidate features are selected and the choice of classifier architecture is\nmade. At that point, the effective dimensionality of the classifier is\nestimated and used to size the next level of analysis, a pilot study on\npreviously unseen cases. The total (training and testing) uncertainty resulting\nfrom the pilot study is, in turn, used to size the highest level of analysis, a\npivotal study with a target level of uncertainty. Some resources available in\nthe literature for implementing this approach are reviewed. Although the\nconcepts explained in the present article may be fundamental and\nstraightforward for many researchers in the machine learning community they are\nsubtle for many practitioners, for whom we provided a general advice for the\nbest practice in \\cite{Shi2010MAQCII} and elaborate here in the present paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.14502v1"
    },
    {
        "title": "The C-SHIFT algorithm for normalizing covariances",
        "authors": [
            "Evgenia Chunikhina",
            "Paul Logan",
            "Yevgeniy Kovchegov",
            "Anatoly Yambartsev",
            "Debashis Mondal",
            "Andrey Morgun"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Omics technologies are powerful tools for analyzing patterns in gene\nexpression data for thousands of genes. Due to a number of systematic\nvariations in experiments, the raw gene expression data is often obfuscated by\nundesirable technical noises. Various normalization techniques were designed in\nan attempt to remove these non-biological errors prior to any statistical\nanalysis. One of the reasons for normalizing data is the need for recovering\nthe covariance matrix used in gene network analysis. In this paper, we\nintroduce a novel normalization technique, called the covariance shift\n(C-SHIFT) method. This normalization algorithm uses optimization techniques\ntogether with the blessing of dimensionality philosophy and energy minimization\nhypothesis for covariance matrix recovery under additive noise (in biology,\nknown as the bias). Thus, it is perfectly suited for the analysis of\nlogarithmic gene expression data. Numerical experiments on synthetic data\ndemonstrate the method's advantage over the classical normalization techniques.\nNamely, the comparison is made with Rank, Quantile, cyclic LOESS (locally\nestimated scatterplot smoothing), and MAD (median absolute deviation)\nnormalization methods. We also evaluate the performance of C-SHIFT algorithm on\nreal biological data.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12936v2"
    },
    {
        "title": "DNA Methylation Data to Predict Suicidal and Non-Suicidal Deaths: A\n  Machine Learning Approach",
        "authors": [
            "Rifat Zahan",
            "Ian McQuillan",
            "Nathaniel D. Osgood"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The objective of this study is to predict suicidal and non-suicidal deaths\nfrom DNA methylation data using a modern machine learning algorithm. We used\nsupport vector machines to classify existing secondary data consisting of\nnormalized values of methylated DNA probe intensities from tissues of two\ncortical brain regions to distinguish suicide cases from control cases. Before\nclassification, we employed Principal component analysis (PCA) and\nt-distributed Stochastic Neighbor Embedding (t-SNE) to reduce the dimension of\nthe data. In comparison to PCA, the modern data visualization method t-SNE\nperforms better in dimensionality reduction. t-SNE accounts for the possible\nnon-linear patterns in low-dimensional data. We applied four-fold\ncross-validation in which the resulting output from t-SNE was used as training\ndata for the Support Vector Machine (SVM). Despite the use of cross-validation,\nthe nominally perfect prediction of suicidal deaths for BA11 data suggests\npossible over-fitting of the model. The study also may have suffered from\n'spectrum bias' since the individuals were only studied from two extreme\nscenarios. This research constitutes a baseline study for classifying suicidal\nand non-suicidal deaths from DNA methylation data. Future studies with larger\nsample size, while possibly incorporating methylation data from living\nindividuals, may reduce the bias and improve the accuracy of the results.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01819v1"
    },
    {
        "title": "Analysis of ensemble feature selection for correlated high-dimensional\n  RNA-Seq cancer data",
        "authors": [
            "Aneta Polewko-Klim",
            "Witold R. Rudnicki"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Discovery of diagnostic and prognostic molecular markers is important and\nactively pursued the research field in cancer research. For complex diseases,\nthis process is often performed using Machine Learning. The current study\ncompares two approaches for the discovery of relevant variables: by application\nof a single feature selection algorithm, versus by an ensemble of diverse\nalgorithms. These approaches are used to identify variables that are relevant\ndiscerning of four cancer types using RNA-seq profiles from the Cancer Genome\nAtlas. The comparison is carried out in two directions: evaluating the\npredictive performance of models and monitoring the stability of selected\nvariables. The most informative features are identified using a four feature\nselection algorithms, namely U-test, ReliefF, and two variants of the MDFS\nalgorithm. Discerning normal and tumor tissues is performed using the Random\nForest algorithm. The highest stability of the feature set was obtained when\nU-test was used. Unfortunately, models built on feature sets obtained from the\nensemble of feature selection algorithms were no better than for models\ndeveloped on feature sets obtained from individual algorithms. On the other\nhand, the feature selectors leading to the best classification results varied\nbetween data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.13809v1"
    },
    {
        "title": "Object-Attribute Biclustering for Elimination of Missing Genotypes in\n  Ischemic Stroke Genome-Wide Data",
        "authors": [
            "Dmitry I. Ignatov",
            "Gennady V. Khvorykh",
            "Andrey V. Khrunin",
            "Stefan Nikolić",
            "Makhmud Shaban",
            "Elizaveta A. Petrova",
            "Evgeniya A. Koltsova",
            "Fouzi Takelait",
            "Dmitrii Egurnov"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Missing genotypes can affect the efficacy of machine learning approaches to\nidentify the risk genetic variants of common diseases and traits. The problem\noccurs when genotypic data are collected from different experiments with\ndifferent DNA microarrays, each being characterised by its pattern of uncalled\n(missing) genotypes. This can prevent the machine learning classifier from\nassigning the classes correctly. To tackle this issue, we used well-developed\nnotions of object-attribute biclusters and formal concepts that correspond to\ndense subrelations in the binary relation $\\textit{patients} \\times\n\\textit{SNPs}$. The paper contains experimental results on applying a\nbiclustering algorithm to a large real-world dataset collected for studying the\ngenetic bases of ischemic stroke. The algorithm could identify large dense\nbiclusters in the genotypic matrix for further processing, which in return\nsignificantly improved the quality of machine learning classifiers. The\nproposed algorithm was also able to generate biclusters for the whole dataset\nwithout size constraints in comparison to the In-Close4 algorithm for\ngeneration of formal concepts.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.11641v2"
    },
    {
        "title": "A deep learning classifier for local ancestry inference",
        "authors": [
            "Matthew Aguirre",
            "Jan Sokol",
            "Guhan Venkataraman",
            "Alexander Ioannidis"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Local ancestry inference (LAI) identifies the ancestry of each segment of an\nindividual's genome and is an important step in medical and population genetic\nstudies of diverse cohorts. Several techniques have been used for LAI,\nincluding Hidden Markov Models and Random Forests. Here, we formulate the LAI\ntask as an image segmentation problem and develop a new LAI tool using a deep\nconvolutional neural network with an encoder-decoder architecture. We train our\nmodel using complete genome sequences from 982 unadmixed individuals from each\nof five continental ancestry groups, and we evaluate it using simulated admixed\ndata derived from an additional 279 individuals selected from the same\npopulations. We show that our model is able to learn admixture as a zero-shot\ntask, yielding ancestry assignments that are nearly as accurate as those from\nthe existing gold standard tool, RFMix.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.02081v1"
    },
    {
        "title": "Transcriptome profiling research in urothelial cell carcinoma",
        "authors": [
            "Umar Ahmad",
            "Buhari Ibrahim",
            "Mustapha Mohammed",
            "Ahmed Faris Aldoghachi",
            "Mahmood Usman",
            "Abdulbasit Haliru Yakubu",
            "Abubakar Sadiq Tanko",
            "Khadijat Abubakar Bobbo",
            "Usman Adamu Garkuwa",
            "Abdullahi Adamu Faggo",
            "Sagir Mustapha",
            "Mahmoud Al-Masaeed",
            "Syahril Abdullah",
            "Yong Yoke Keong",
            "Abhi Veerakumarasivam"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  Urothelial cell carcinoma (UCC) is the ninth most common cancer that accounts\nfor 4.7% of all the new cancer cases globally. UCC development and progression\nare due to complex and stochastic genetic programmes. To study the cascades of\nmolecular events underlying the poor prognosis that may lead to limited\ntreatment options for advanced disease and resistance to conventional therapies\nin UCC, transcriptomics technology (RNA-Seq), a method of analysing the RNA\ncontent of a sample using modern high-throughput sequencing platforms has been\nemployed. Here we review the principles of RNA-Seq technology and summarize\nrecent studies on human bladder cancer that employed this technique to unravel\nthe pathogenesis of the disease, identify biomarkers, discover pathways and\nclassify the disease state. We list the commonly used computational platforms\nand software that are publicly available for RNA-Seq analysis. Moreover, we\ndiscussed the future perspectives for RNA-Seq studies on bladder cancer and\nrecommend the application of new technology called single cell sequencing\n(scRNA-Seq) to further understand the disease. Keywords: Transcriptome\nprofiling, RNA-sequencing, genomics, bioinformatics, bladder cancer\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10372v4"
    },
    {
        "title": "Structure learning for zero-inflated counts, with an application to\n  single-cell RNA sequencing data",
        "authors": [
            "Thi Kim Hue Nguyen",
            "Koen Van den Berge",
            "Monica Chiogna",
            "Davide Risso"
        ],
        "category": "q-bio.GN",
        "published_year": "2020",
        "summary": "  The problem of estimating the structure of a graph from observed data is of\ngrowing interest in the context of high-throughput genomic data, and\nsingle-cell RNA sequencing in particular. These, however, are challenging\napplications, since the data consist of high-dimensional counts with high\nvariance and over-abundance of zeros. Here, we present a general framework for\nlearning the structure of a graph from single-cell RNA-seq data, based on the\nzero-inflated negative binomial distribution. We demonstrate with simulations\nthat our approach is able to retrieve the structure of a graph in a variety of\nsettings and we show the utility of the approach on real data.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.12044v3"
    },
    {
        "title": "Interval Type-2 Enhanced Possibilistic Fuzzy C-Means Clustering for Gene\n  Expression Data Analysis",
        "authors": [
            "Shahabeddin Sotudian",
            "Mohammad Hossein Fazel Zarandi"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Both FCM and PCM clustering methods have been widely applied to pattern\nrecognition and data clustering. Nevertheless, FCM is sensitive to noise and\nPCM occasionally generates coincident clusters. PFCM is an extension of the PCM\nmodel by combining FCM and PCM, but this method still suffers from the\nweaknesses of PCM and FCM. In the current paper, the weaknesses of the PFCM\nalgorithm are corrected and the enhanced possibilistic fuzzy c-means (EPFCM)\nclustering algorithm is presented. EPFCM can still be sensitive to noise.\nTherefore, we propose an interval type-2 enhanced possibilistic fuzzy c-means\n(IT2EPFCM) clustering method by utilizing two fuzzifiers $(m_1, m_2)$ for fuzzy\nmemberships and two fuzzifiers $({\\theta}_1, {\\theta}_2)$ for possibilistic\ntypicalities. Our computational results show the superiority of the proposed\napproaches compared with several state-of-the-art techniques in the literature.\nFinally, the proposed methods are implemented for analyzing microarray gene\nexpression data.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00304v2"
    },
    {
        "title": "Identifying 3D Genome Organization in Diploid Organisms via Euclidean\n  Distance Geometry",
        "authors": [
            "Anastasiya Belyaeva",
            "Kaie Kubjas",
            "Lawrence J. Sun",
            "Caroline Uhler"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The spatial organization of the DNA in the cell nucleus plays an important\nrole for gene regulation, DNA replication, and genomic integrity. Through the\ndevelopment of chromosome conformation capture experiments (such as 3C, 4C,\nHi-C) it is now possible to obtain the contact frequencies of the DNA at the\nwhole-genome level. In this paper, we study the problem of reconstructing the\n3D organization of the genome from such whole-genome contact frequencies. A\nstandard approach is to transform the contact frequencies into noisy distance\nmeasurements and then apply semidefinite programming (SDP) formulations to\nobtain the 3D configuration. However, neglected in such reconstructions is the\nfact that most eukaryotes including humans are diploid and therefore contain\ntwo copies of each genomic locus. We prove that the 3D organization of the DNA\nis not identifiable from distance measurements derived from contact frequencies\nin diploid organisms. In fact, there are infinitely many solutions even in the\nnoise-free setting. We then discuss various additional biologically relevant\nand experimentally measurable constraints (including distances between\nneighboring genomic loci and higher-order interactions) and prove\nidentifiability under these conditions. Furthermore, we provide SDP\nformulations for computing the 3D embedding of the DNA with these additional\nconstraints and show that we can recover the true 3D embedding with high\naccuracy from both noiseless and noisy measurements. Finally, we apply our\nalgorithm to real pairwise and higher-order contact frequency data and show\nthat we can recover known genome organization patterns.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05336v1"
    },
    {
        "title": "Explainable Artificial Intelligence Reveals Novel Insight into Tumor\n  Microenvironment Conditions Linked with Better Prognosis in Patients with\n  Breast Cancer",
        "authors": [
            "Debaditya Chakraborty",
            "Cristina Ivan",
            "Paola Amero",
            "Maliha Khan",
            "Cristian Rodriguez-Aguayo",
            "Hakan Başağaoğlu",
            "Gabriel Lopez-Berestein"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We investigated the data-driven relationship between features in the tumor\nmicroenvironment (TME) and the overall and 5-year survival in triple-negative\nbreast cancer (TNBC) and non-TNBC (NTNBC) patients by using Explainable\nArtificial Intelligence (XAI) models. We used clinical information from\npatients with invasive breast carcinoma from The Cancer Genome Atlas and from\ntwo studies from the cbioPortal, the PanCanAtlas project and the GDAC Firehose\nstudy. In this study, we used a normalized RNA sequencing data-driven cohort\nfrom 1,015 breast cancer patients, alive or deceased, from the UCSC Xena data\nset and performed integrated deconvolution with the EPIC method to estimate the\npercentage of seven different immune and stromal cells from RNA sequencing\ndata. Novel insights derived from our XAI model showed that CD4+ T cells and B\ncells are more critical than other TME features for enhanced prognosis for both\nTNBC and NTNBC patients. Our XAI model revealed the critical inflection points\n(i.e., threshold fractions) of CD4+ T cells and B cells above or below which\n5-year survival rates improve. Subsequently, we ascertained the conditional\nprobabilities of $\\geq$ 5-year survival in both TNBC and NTNBC patients under\nspecific conditions inferred from the inflection points. In particular, the XAI\nmodels revealed that a B-cell fraction exceeding 0.018 in the TME could ensure\n100% 5-year survival for NTNBC patients. The findings from this research could\nlead to more accurate clinical predictions and enhanced immunotherapies and to\nthe design of innovative strategies to reprogram the TME of breast cancer\npatients.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.12021v1"
    },
    {
        "title": "XOmiVAE: an interpretable deep learning model for cancer classification\n  using high-dimensional omics data",
        "authors": [
            "Eloise Withnell",
            "Xiaoyu Zhang",
            "Kai Sun",
            "Yike Guo"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The lack of explainability is one of the most prominent disadvantages of deep\nlearning applications in omics. This \"black box\" problem can undermine the\ncredibility and limit the practical implementation of biomedical deep learning\nmodels. Here we present XOmiVAE, a variational autoencoder (VAE) based\ninterpretable deep learning model for cancer classification using\nhigh-dimensional omics data. XOmiVAE is capable of revealing the contribution\nof each gene and latent dimension for each classification prediction, and the\ncorrelation between each gene and each latent dimension. It is also\ndemonstrated that XOmiVAE can explain not only the supervised classification\nbut the unsupervised clustering results from the deep learning network. To the\nbest of our knowledge, XOmiVAE is one of the first activation level-based\ninterpretable deep learning models explaining novel clusters generated by VAE.\nThe explainable results generated by XOmiVAE were validated by both the\nperformance of downstream tasks and the biomedical knowledge. In our\nexperiments, XOmiVAE explanations of deep learning based cancer classification\nand clustering aligned with current domain knowledge including biological\nannotation and academic literature, which shows great potential for novel\nbiomedical knowledge discovery from deep learning models.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.12807v2"
    },
    {
        "title": "Enrichment of gut microbiome strains for cultivation-free genome\n  sequencing using droplet microfluidics",
        "authors": [
            "Anna Pryszlak",
            "Tobias Wenzel",
            "Kiley West Seitz",
            "Falk Hildebrand",
            "Ece Kartal",
            "Marco Raffaele Cosenza",
            "Vladimir Benes",
            "Peer Bork",
            "Christoph Merten"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We report a droplet microfluidic method to target and sort individual cells\ndirectly from complex microbiome samples, and to prepare these cells for bulk\nwhole genome sequencing without cultivation. We characterize this approach by\nrecovering bacteria spiked into human stool samples at a ratio as low as 1:250\nand by successfully enriching endogenous Bacteroides vulgatus to the level\nrequired for de-novo assembly of high-quality genomes. While microbiome strains\nare increasingly demanded for biomedical applications, the vast majority of\nspecies and strains are uncultivated and without reference genomes. We address\nthis shortcoming by encapsulating complex microbiome samples directly into\nmicrofluidic droplets and amplify a target-specific genomic fragment using a\ncustom molecular TaqMan probe. We separate those positive droplets by droplet\nsorting, selectively enriching single target strain cells. Finally, we present\na protocol to purify the genomic DNA while specifically removing amplicons and\ncell debris for high-quality genome sequencing.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.01455v1"
    },
    {
        "title": "Enabling microbiome research on personal devices",
        "authors": [
            "Igor Sfiligoi",
            "Daniel McDonald",
            "Rob Knight"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Microbiome studies have recently transitioned from experimental designs with\na few hundred samples to designs spanning tens of thousands of samples. Modern\nstudies such as the Earth Microbiome Project (EMP) afford the statistics\ncrucial for untangling the many factors that influence microbial community\ncomposition. Analyzing those data used to require access to a compute cluster,\nmaking it both expensive and inconvenient. We show that recent improvements in\nboth hardware and software now allow to compute key bioinformatics tasks on\nEMP-sized data in minutes using a gaming-class laptop, enabling much faster and\nbroader microbiome science insights.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.05397v1"
    },
    {
        "title": "A reinforcement learning approach to resource allocation in genomic\n  selection",
        "authors": [
            "Saba Moeinizade",
            "Guiping Hu",
            "Lizhi Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Genomic selection (GS) is a technique that plant breeders use to select\nindividuals to mate and produce new generations of species. Allocation of\nresources is a key factor in GS. At each selection cycle, breeders are facing\nthe choice of budget allocation to make crosses and produce the next generation\nof breeding parents. Inspired by recent advances in reinforcement learning for\nAI problems, we develop a reinforcement learning-based algorithm to\nautomatically learn to allocate limited resources across different generations\nof breeding. We mathematically formulate the problem in the framework of Markov\nDecision Process (MDP) by defining state and action spaces. To avoid the\nexplosion of the state space, an integer linear program is proposed that\nquantifies the trade-off between resources and time. Finally, we propose a\nvalue function approximation method to estimate the action-value function and\nthen develop a greedy policy improvement technique to find the optimal\nresources. We demonstrate the effectiveness of the proposed method in enhancing\ngenetic gain using a case study with realistic data.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.10901v1"
    },
    {
        "title": "Optimal transport-based machine learning to match specific patterns:\n  application to the detection of molecular regulation patterns in omics data",
        "authors": [
            "Thi Thanh Yen Nguyen",
            "Warith Harchaoui",
            "Lucile Mégret",
            "Cloe Mendoza",
            "Olivier Bouaziz",
            "Christian Neri",
            "Antoine Chambaz"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  We present several algorithms designed to learn a pattern of correspondence\nbetween two data sets in situations where it is desirable to match elements\nthat exhibit a relationship belonging to a known parametric model. In the\nmotivating case study, the challenge is to better understand micro-RNA\nregulation in the striatum of Huntington's disease model mice. The algorithms\nunfold in two stages. First, an optimal transport plan P and an optimal affine\ntransformation are learned, using the Sinkhorn-Knopp algorithm and a mini-batch\ngradient descent. Second, P is exploited to derive either several co-clusters\nor several sets of matched elements. A simulation study illustrates how the\nalgorithms work and perform. The real data application further illustrates\ntheir applicability and interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11192v3"
    },
    {
        "title": "TargetNet: Functional microRNA Target Prediction with Deep Neural\n  Networks",
        "authors": [
            "Seonwoo Min",
            "Byunghan Lee",
            "Sungroh Yoon"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Motivation: MicroRNAs (miRNAs) play pivotal roles in gene expression\nregulation by binding to target sites of messenger RNAs (mRNAs). While\nidentifying functional targets of miRNAs is of utmost importance, their\nprediction remains a great challenge. Previous computational algorithms have\nmajor limitations. They use conservative candidate target site (CTS) selection\ncriteria mainly focusing on canonical site types, rely on laborious and\ntime-consuming manual feature extraction, and do not fully capitalize on the\ninformation underlying miRNA-CTS interactions. Results: In this paper, we\nintroduce TargetNet, a novel deep learning-based algorithm for functional miRNA\ntarget prediction. To address the limitations of previous approaches, TargetNet\nhas three key components: (1) relaxed CTS selection criteria accommodating\nirregularities in the seed region, (2) a novel miRNA-CTS sequence encoding\nscheme incorporating extended seed region alignments, and (3) a deep residual\nnetwork-based prediction model. The proposed model was trained with miRNA-CTS\npair datasets and evaluated with miRNA-mRNA pair datasets. TargetNet advances\nthe previous state-of-the-art algorithms used in functional miRNA target\nclassification. Furthermore, it demonstrates great potential for distinguishing\nhigh-functional miRNA targets.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11381v2"
    },
    {
        "title": "Graph Representation Learning on Tissue-Specific Multi-Omics",
        "authors": [
            "Amine Amor",
            "Pietro Lio'",
            "Vikash Singh",
            "Ramon Viñas Torné",
            "Helena Andres Terre"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Combining different modalities of data from human tissues has been critical\nin advancing biomedical research and personalised medical care. In this study,\nwe leverage a graph embedding model (i.e VGAE) to perform link prediction on\ntissue-specific Gene-Gene Interaction (GGI) networks. Through ablation\nexperiments, we prove that the combination of multiple biological modalities\n(i.e multi-omics) leads to powerful embeddings and better link prediction\nperformances. Our evaluation shows that the integration of gene methylation\nprofiles and RNA-sequencing data significantly improves the link prediction\nperformance. Overall, the combination of RNA-sequencing and gene methylation\ndata leads to a link prediction accuracy of 71% on GGI networks. By harnessing\ngraph representation learning on multi-omics data, our work brings novel\ninsights to the current literature on multi-omics integration in\nbioinformatics.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11856v1"
    },
    {
        "title": "A Global Nucleic Acid Observatory for Biodefense and Planetary Health",
        "authors": [
            "The Nucleic Acid Observatory Consortium"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  The spread of pandemic viruses and invasive species can be catastrophic for\nhuman societies and natural ecosystems. SARS-CoV-2 demonstrated that the speed\nof our response is critical, as each day of delay permitted exponential growth\nand dispersion of the virus. Here we propose a global Nucleic Acid Observatory\n(NAO) to monitor the relative frequency of everything biological through\ncomprehensive metagenomic sequencing of waterways and wastewater. By searching\nfor divergences from historical baseline frequencies at sites throughout the\nworld, NAO could detect any virus or invasive organism undergoing exponential\ngrowth whose nucleic acids end up in the water, even those previously unknown\nto science. Continuously monitoring nucleic acid diversity would provide us\nwith universal early warning, obviate subtle bioweapons, and generate a wealth\nof sequence data sufficient to transform ecology, microbiology, and\nconservation. We call for the immediate construction of a global NAO to defend\nand illuminate planetary health.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02678v1"
    },
    {
        "title": "A systematic evaluation of methods for cell phenotype classification\n  using single-cell RNA sequencing data",
        "authors": [
            "Xiaowen Cao",
            "Li Xing",
            "Elham Majd",
            "Hua He",
            "Junhua Gu",
            "Xuekui Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Background: Single-cell RNA sequencing (scRNA-seq) yields valuable insights\nabout gene expression and gives critical information about complex tissue\ncellular composition. In the analysis of single-cell RNA sequencing, the\nannotations of cell subtypes are often done manually, which is time-consuming\nand irreproducible. Garnett is a cell-type annotation software based the on\nelastic net method. Besides cell-type annotation, supervised machine learning\nmethods can also be applied to predict other cell phenotypes from genomic data.\nDespite the popularity of such applications, there is no existing study to\nsystematically investigate the performance of those supervised algorithms in\nvarious sizes of scRNA-seq data sets.\n  Methods and Results: This study evaluates 13 popular supervised machine\nlearning algorithms to classify cell phenotypes, using published real and\nsimulated data sets with diverse cell sizes. The benchmark contained two parts.\nIn the first part, we used real data sets to assess the popular supervised\nalgorithms' computing speed and cell phenotype classification performance. The\nclassification performances were evaluated using AUC statistics, F1-score,\nprecision, recall, and false-positive rate. In the second part, we evaluated\ngene selection performance using published simulated data sets with a known\nlist of real genes.\n  Conclusion: The study outcomes showed that ElasticNet with interactions\nperformed best in small and medium data sets. NB was another appropriate method\nfor medium data sets. In large data sets, XGB works excellent. Ensemble\nalgorithms were not significantly superior to individual machine learning\nmethods. Adding interactions to ElasticNet can help, and the improvement was\nsignificant in small data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00681v1"
    },
    {
        "title": "Multi-modal Self-supervised Pre-training for Regulatory Genome Across\n  Cell Types",
        "authors": [
            "Shentong Mo",
            "Xi Fu",
            "Chenyang Hong",
            "Yizhen Chen",
            "Yuxuan Zheng",
            "Xiangru Tang",
            "Zhiqiang Shen",
            "Eric P Xing",
            "Yanyan Lan"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  In the genome biology research, regulatory genome modeling is an important\ntopic for many regulatory downstream tasks, such as promoter classification,\ntransaction factor binding sites prediction. The core problem is to model how\nregulatory elements interact with each other and its variability across\ndifferent cell types. However, current deep learning methods often focus on\nmodeling genome sequences of a fixed set of cell types and do not account for\nthe interaction between multiple regulatory elements, making them only perform\nwell on the cell types in the training set and lack the generalizability\nrequired in biological applications. In this work, we propose a simple yet\neffective approach for pre-training genome data in a multi-modal and\nself-supervised manner, which we call GeneBERT. Specifically, we simultaneously\ntake the 1d sequence of genome data and a 2d matrix of (transcription factors x\nregions) as the input, where three pre-training tasks are proposed to improve\nthe robustness and generalizability of our model. We pre-train our model on the\nATAC-seq dataset with 17 million genome sequences. We evaluate our GeneBERT on\nregulatory downstream tasks across different cell types, including promoter\nclassification, transaction factor binding sites prediction, disease risk\nestimation, and splicing sites prediction. Extensive experiments demonstrate\nthe effectiveness of multi-modal and self-supervised pre-training for\nlarge-scale regulatory genomics data.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.05231v2"
    },
    {
        "title": "SGEN: Single-cell Sequencing Graph Self-supervised Embedding Network",
        "authors": [
            "Ziyi Liu",
            "Minghui Liao",
            "Fulin luo",
            "Bo Du"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Single-cell sequencing has a significant role to explore biological processes\nsuch as embryonic development, cancer evolution, and cell differentiation.\nThese biological properties can be presented by a two-dimensional scatter plot.\nHowever, single-cell sequencing data generally has very high dimensionality.\nTherefore, dimensionality reduction should be used to process the high\ndimensional sequencing data for 2D visualization and subsequent biological\nanalysis. The traditional dimensionality reduction methods, which do not\nconsider the structure characteristics of single-cell sequencing data, are\ndifficult to reveal the data structure in the 2D representation. In this paper,\nwe develop a 2D feature representation method based on graph convolutional\nnetworks (GCN) for the visualization of single-cell data, termed single-cell\nsequencing graph embedding networks (SGEN). This method constructs the graph by\nthe similarity relationship between cells and adopts GCN to analyze the\nneighbor embedding information of samples, which makes the similar cell closer\nto each other on the 2D scatter plot. The results show SGEN achieves obvious 2D\ndistribution and preserves the high-dimensional relationship of different\ncells. Meanwhile, similar cell clusters have spatial continuity rather than\nrelying heavily on random initialization, which can reflect the trajectory of\ncell development in this scatter plot.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.09413v1"
    },
    {
        "title": "RZiMM-scRNA: A regularized zero-inflated mixture model framework for\n  single-cell RNA-seq data",
        "authors": [
            "Xinlei Mi",
            "William Bekerman",
            "Peter A. Sims",
            "Peter D. Canoll",
            "Jianhua Hu"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Applications of single-cell RNA sequencing in various biomedical research\nareas have been blooming. This new technology provides unprecedented\nopportunities to study disease heterogeneity at the cellular level. However,\nunique characteristics of scRNA-seq data, including large dimensionality, high\ndropout rates, and possibly batch effects, bring great difficulty into the\nanalysis of such data. Not appropriately addressing these issues obstructs true\nscientific discovery. Herein, we propose a unified Regularized Zero-inflated\nMixture Model framework designed for scRNA-seq data (RZiMM-scRNA) to\nsimultaneously detect cell subgroups and identify gene differential expression\nbased on a developed importance score, accounting for both dropouts and batch\neffects. We conduct extensive simulation studies in which we evaluate the\nperformance of RZiMM-scRNA and compare it with several popular methods,\nincluding Seurat, SC3, K-Means, and Hierarchical Clustering. Simulation results\nshow that RZiMM-scRNA demonstrates superior clustering performance and enhanced\nbiomarker detection accuracy compared to alternative methods, especially when\ncell subgroups are less distinct, verifying the robustness of our method. Our\nempirical investigations focus on two brain tumor studies dealing with\nastrocytoma of various grades, including the most malignant of all brain\ntumors, glioblastoma multiforme (GBM). Our goal is to delineate cell\nheterogeneity and identify driving biomarkers associated with these tumors.\nNotably, RZiMM-scNRA successfully identifies a small group of oligodendrocyte\ncells which has drawn much attention in biomedical literature on brain cancers.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.12964v1"
    },
    {
        "title": "Deciphering the Language of Nature: A transformer-based language model\n  for deleterious mutations in proteins",
        "authors": [
            "Theodore Jiang",
            "Li Fang",
            "Kai Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Various machine-learning models, including deep neural network models, have\nalready been developed to predict deleteriousness of missense (non-synonymous)\nmutations. Potential improvements to the current state of the art, however, may\nstill benefit from a fresh look at the biological problem using more\nsophisticated self-adaptive machine-learning approaches. Recent advances in the\nnatural language processing field show transformer models-a type of deep neural\nnetwork-to be particularly powerful at modeling sequence information with\ncontext dependence. In this study, we introduce MutFormer, a transformer-based\nmodel for the prediction of deleterious missense mutations, which uses\nreference and mutated protein sequences from the human genome as the primary\nfeatures. MutFormer takes advantage of a combination of self-attention layers\nand convolutional layers to learn both long-range and short-range dependencies\nbetween amino acid mutations in a protein sequence. In this study, we first\npre-trained MutFormer on reference protein sequences and mutated protein\nsequences resulting from common genetic variants observed in human populations.\nWe next examined different fine-tuning methods to successfully apply the model\nto deleteriousness prediction of missense mutations. Finally, we evaluated\nMutFormer's performance on multiple testing data sets. We found that MutFormer\nshowed similar or improved performance over a variety of existing tools,\nincluding those that used conventional machine-learning approaches. We conclude\nthat MutFormer successfully considers sequence features that are not explored\nin previous studies and could potentially complement existing computational\npredictions or empirically generated functional scores to improve our\nunderstanding of disease variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.14746v4"
    },
    {
        "title": "High-dimensional multi-trait GWAS by reverse prediction of genotypes",
        "authors": [
            "Muhammad Ammar Malik",
            "Adriaan-Alexander Ludl",
            "Tom Michoel"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Multi-trait genome-wide association studies (GWAS) use multi-variate\nstatistical methods to identify associations between genetic variants and\nmultiple correlated traits simultaneously, and have higher statistical power\nthan independent univariate analyses of traits. Reverse regression, where\ngenotypes of genetic variants are regressed on multiple traits simultaneously,\nhas emerged as a promising approach to perform multi-trait GWAS in\nhigh-dimensional settings where the number of traits exceeds the number of\nsamples. We analyzed different machine learning methods (ridge regression,\nnaive Bayes/independent univariate, random forests and support vector machines)\nfor reverse regression in multi-trait GWAS, using genotypes, gene expression\ndata and ground-truth transcriptional regulatory networks from the DREAM5\nSysGen Challenge and from a cross between two yeast strains to evaluate\nmethods. We found that genotype prediction performance, in terms of root mean\nsquared error (RMSE), allowed to distinguish between genomic regions with high\nand low transcriptional activity. Moreover, model feature coefficients\ncorrelated with the strength of association between variants and individual\ntraits, and were predictive of true trans-eQTL target genes, with complementary\nfindings across methods. Code to reproduce the analysis is available at\nhttps://github.com/michoel-lab/Reverse-Pred-GWAS\n",
        "pdf_link": "http://arxiv.org/pdf/2111.00108v2"
    },
    {
        "title": "Metagenome2Vec: Building Contextualized Representations for Scalable\n  Metagenome Analysis",
        "authors": [
            "Sathyanarayanan N. Aakur",
            "Vineela Indla",
            "Vennela Indla",
            "Sai Narayanan",
            "Arunkumar Bagavathi",
            "Vishalini Laguduva Ramnath",
            "Akhilesh Ramachandran"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Advances in next-generation metagenome sequencing have the potential to\nrevolutionize the point-of-care diagnosis of novel pathogen infections, which\ncould help prevent potential widespread transmission of diseases. Given the\nhigh volume of metagenome sequences, there is a need for scalable frameworks to\nanalyze and segment metagenome sequences from clinical samples, which can be\nhighly imbalanced. There is an increased need for learning robust\nrepresentations from metagenome reads since pathogens within a family can have\nhighly similar genome structures (some more than 90%) and hence enable the\nsegmentation and identification of novel pathogen sequences with limited\nlabeled data. In this work, we propose Metagenome2Vec - a contextualized\nrepresentation that captures the global structural properties inherent in\nmetagenome data and local contextualized properties through self-supervised\nrepresentation learning. We show that the learned representations can help\ndetect six (6) related pathogens from clinical samples with less than 100\nlabeled sequences. Extensive experiments on simulated and clinical metagenome\ndata show that the proposed representation encodes compositional properties\nthat can generalize beyond annotations to segment novel pathogens in an\nunsupervised setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.08001v1"
    },
    {
        "title": "OmiTrans: generative adversarial networks based omics-to-omics\n  translation framework",
        "authors": [
            "Xiaoyu Zhang",
            "Yike Guo"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  With the rapid development of high-throughput experimental technologies,\ndifferent types of omics (e.g., genomics, epigenomics, transcriptomics,\nproteomics, and metabolomics) data can be produced from clinical samples. The\ncorrelations between different omics types attracts a lot of research interest,\nwhereas the stduy on genome-wide omcis data translation (i.e, generation and\nprediction of one type of omics data from another type of omics data) is almost\nblank. Generative adversarial networks and the variants are one of the most\nstate-of-the-art deep learning technologies, which have shown great success in\nimage-to-image translation, text-to-image translation, etc. Here we proposed\nOmiTrans, a deep learning framework adopted the idea of generative adversarial\nnetworks to achieve omics-to-omics translation with promising results. OmiTrans\nwas able to faithfully reconstruct gene expression profiles from DNA\nmethylation data with high accuracy and great model generalisation, as\ndemonstrated in the experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.13785v1"
    },
    {
        "title": "SurvODE: Extrapolating Gene Expression Distribution for Early Cancer\n  Identification",
        "authors": [
            "Tong Chen",
            "Sheng Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  With the increasingly available large-scale cancer genomics datasets, machine\nlearning approaches have played an important role in revealing novel insights\ninto cancer development. Existing methods have shown encouraging performance in\nidentifying genes that are predictive for cancer survival, but are still\nlimited in modeling the distribution over genes. Here, we proposed a novel\nmethod that can simulate the gene expression distribution at any given time\npoint, including those that are out of the range of the observed time points.\nIn order to model the irregular time series where each patient is one\nobservation, we integrated a neural ordinary differential equation (neural ODE)\nwith cox regression into our framework. We evaluated our method on eight cancer\ntypes on TCGA and observed a substantial improvement over existing approaches.\nOur visualization results and further analysis indicate how our method can be\nused to simulate expression at the early cancer stage, offering the possibility\nfor early cancer identification.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.15080v1"
    },
    {
        "title": "AGMI: Attention-Guided Multi-omics Integration for Drug Response\n  Prediction with Graph Neural Networks",
        "authors": [
            "Ruiwei Feng",
            "Yufeng Xie",
            "Minshan Lai",
            "Danny Z. Chen",
            "Ji Cao",
            "Jian Wu"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Accurate drug response prediction (DRP) is a crucial yet challenging task in\nprecision medicine. This paper presents a novel Attention-Guided Multi-omics\nIntegration (AGMI) approach for DRP, which first constructs a Multi-edge Graph\n(MeG) for each cell line, and then aggregates multi-omics features to predict\ndrug response using a novel structure, called Graph edge-aware Network (GeNet).\nFor the first time, our AGMI approach explores gene constraint based\nmulti-omics integration for DRP with the whole-genome using GNNs. Empirical\nexperiments on the CCLE and GDSC datasets show that our AGMI largely\noutperforms state-of-the-art DRP methods by 8.3%--34.2% on four metrics. Our\ndata and code are available at https://github.com/yivan-WYYGDSG/AGMI.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.08366v2"
    },
    {
        "title": "RepBin: Constraint-based Graph Representation Learning for Metagenomic\n  Binning",
        "authors": [
            "Hansheng Xue",
            "Vijini Mallawaarachchi",
            "Yujia Zhang",
            "Vaibhav Rajan",
            "Yu Lin"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  Mixed communities of organisms are found in many environments (from the human\ngut to marine ecosystems) and can have profound impact on human health and the\nenvironment. Metagenomics studies the genomic material of such communities\nthrough high-throughput sequencing that yields DNA subsequences for subsequent\nanalysis. A fundamental problem in the standard workflow, called binning, is to\ndiscover clusters, of genomic subsequences, associated with the unknown\nconstituent organisms. Inherent noise in the subsequences, various biological\nconstraints that need to be imposed on them and the skewed cluster size\ndistribution exacerbate the difficulty of this unsupervised learning problem.\nIn this paper, we present a new formulation using a graph where the nodes are\nsubsequences and edges represent homophily information. In addition, we model\nbiological constraints providing heterophilous signal about nodes that cannot\nbe clustered together. We solve the binning problem by developing new\nalgorithms for (i) graph representation learning that preserves both homophily\nrelations and heterophily constraints (ii) constraint-based graph clustering\nmethod that addresses the problems of skewed cluster size distribution.\nExtensive experiments, on real and synthetic datasets, demonstrate that our\napproach, called RepBin, outperforms a wide variety of competing methods. Our\nconstraint-based graph representation learning and clustering methods, that may\nbe useful in other domains as well, advance the state-of-the-art in both\nmetagenomics binning and graph representation learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.11696v1"
    },
    {
        "title": "Application of Markov Structure of Genomes to Outlier Identification and\n  Read Classification",
        "authors": [
            "Alan F. Karr",
            "Jason Hauzel",
            "Adam A. Porter",
            "Marcel Schaefer"
        ],
        "category": "q-bio.GN",
        "published_year": "2021",
        "summary": "  In this paper we apply the structure of genomes as second-order Markov\nprocesses specified by the distributions of successive triplets of bases to two\nbioinformatics problems: identification of outliers in genome databases and\nread classification in metagenomics, using real coronavirus and adenovirus\ndata.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.13117v1"
    },
    {
        "title": "PWM2Vec: An Efficient Embedding Approach for Viral Host Specification\n  from Coronavirus Spike Sequences",
        "authors": [
            "Sarwan Ali",
            "Babatunde Bello",
            "Prakash Chourasia",
            "Ria Thazhe Punathil",
            "Yijing Zhou",
            "Murray Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  COVID-19 pandemic, is still unknown and is an important open question. There\nare speculations that bats are a possible origin. Likewise, there are many\nclosely related (corona-) viruses, such as SARS, which was found to be\ntransmitted through civets. The study of the different hosts which can be\npotential carriers and transmitters of deadly viruses to humans is crucial to\nunderstanding, mitigating and preventing current and future pandemics. In\ncoronaviruses, the surface (S) protein, or spike protein, is an important part\nof determining host specificity since it is the point of contact between the\nvirus and the host cell membrane. In this paper, we classify the hosts of over\nfive thousand coronaviruses from their spike protein sequences, segregating\nthem into clusters of distinct hosts among avians, bats, camels, swines, humans\nand weasels, to name a few. We propose a feature embedding based on the\nwell-known position-weight matrix (PWM), which we call PWM2Vec, and use to\ngenerate feature vectors from the spike protein sequences of these\ncoronaviruses. While our embedding is inspired by the success of PWMs in\nbiological applications such as determining protein function, or identifying\ntranscription factor binding sites, we are the first (to the best of our\nknowledge) to use PWMs in the context of host classification from viral\nsequences to generate a fixed-length feature vector representation. The results\non the real world data show that in using PWM2Vec, we are able to perform\ncomparably well as compared to baseline models. We also measure the importance\nof different amino acids using information gain to show the amino acids which\nare important for predicting the host of a given coronavirus.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02273v1"
    },
    {
        "title": "Depth Normalization of Small RNA Sequencing: Using Data and Biology to\n  Select a Suitable Method",
        "authors": [
            "Yannick Düren",
            "Johannes Lederer",
            "Li-Xuan Qin"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Deep sequencing has become one of the most popular tools for transcriptome\nprofiling in biomedical studies. While an abundance of computational methods\nexists for \"normalizing\" sequencing data to remove unwanted between-sample\nvariations due to experimental handling, there is no consensus on which\nnormalization is the most suitable for a given data set. To address this\nproblem, we developed \"DANA\" - an approach for assessing the performance of\nnormalization methods for microRNA sequencing data based on biology-motivated\nand data-driven metrics. Our approach takes advantage of well-known biological\nfeatures of microRNAs for their expression pattern and chromosomal clustering\nto simultaneously assess (1) how effectively normalization removes handling\nartifacts, and (2) how aptly normalization preserves biological signals. With\nDANA, we confirm that the performance of eight commonly used normalization\nmethods vary widely across different data sets and provide guidance for\nselecting a suitable method for the data at hand. Hence, it should be adopted\nas a routine preprocessing step (preceding normalization) for microRNA\nsequencing data analysis. DANA is implemented in R and publicly available at\nhttps://github.com/LXQin/DANA.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.05055v1"
    },
    {
        "title": "Fast, Flexible, and Exact Minimum Flow Decompositions via ILP",
        "authors": [
            "Fernando H. C. Dias",
            "Lucia Williams",
            "Brendan Mumey",
            "Alexandru I. Tomescu"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Minimum flow decomposition (MFD) (the problem of finding a minimum set of\npaths that perfectly decomposes a flow) is a classical problem in Computer\nScience, and variants of it are powerful models in multiassembly problems in\nBioinformatics (e.g. RNA assembly). However, because this problem and its\nvariants are NP-hard, practical multiassembly tools either use heuristics or\nsolve simpler, polynomial-time solvable versions of the problem, which may\nyield solutions that are not mini-mal or do not perfectly decompose the flow.\nMany RNA assemblers also use integer linear programming(ILP) formulations of\nsuch practical variants, having the major limitation they need to encode all\nthe potentially exponentially many solution paths. Moreover, the only exact\nsolver for MFD does not scale to large instances and cannot be efficiently\ngeneralized to practical MFD variants. In this work, we provide the first\npractical ILP formulation for MFD (and thus the first fast and exact solver for\nMFD), based on encoding all of the exponentially many solution paths using only\na quadratic number of variables. On both simulated and real flow graphs, our\napproach solves any instance in under 13 seconds. We also show that our ILP\nformulation can be easily and efficiently adapted for many practical variants,\nsuch as incorporating longer or paired-end reads or minimizing flow errors. We\nhope that our results can remove the current tradeoff between the complexity of\na multi assembly model and its tractability and can lie at the core of future\npractical RNA assembly tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.10923v3"
    },
    {
        "title": "A comprehensive survey on computational learning methods for analysis of\n  gene expression data",
        "authors": [
            "Nikita Bhandari",
            "Rahee Walambe",
            "Ketan Kotecha",
            "Satyajeet Khare"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Computational analysis methods including machine learning have a significant\nimpact in the fields of genomics and medicine. High-throughput gene expression\nanalysis methods such as microarray technology and RNA sequencing produce\nenormous amounts of data. Traditionally, statistical methods are used for\ncomparative analysis of gene expression data. However, more complex analysis\nfor classification of sample observations, or discovery of feature genes\nrequires sophisticated computational approaches. In this review, we compile\nvarious statistical and computational tools used in analysis of expression\nmicroarray data. Even though the methods are discussed in the context of\nexpression microarrays, they can also be applied for the analysis of RNA\nsequencing and quantitative proteomics datasets. We discuss the types of\nmissing values, and the methods and approaches usually employed in their\nimputation. We also discuss methods of data normalization, feature selection,\nand feature extraction. Lastly, methods of classification and class discovery\nalong with their evaluation parameters are described in detail. We believe that\nthis detailed review will help the users to select appropriate methods for\npreprocessing and analysis of their data based on the expected outcome.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.02958v5"
    },
    {
        "title": "Numeric Lyndon-based feature embedding of sequencing reads for machine\n  learning approaches",
        "authors": [
            "Paola Bonizzoni",
            "Matteo Costantini",
            "Clelia De Felice",
            "Alessia Petescia",
            "Yuri Pirola",
            "Marco Previtali",
            "Raffaella Rizzi",
            "Jens Stoye",
            "Rocco Zaccagnino",
            "Rosalba Zizza"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Feature embedding methods have been proposed in literature to represent\nsequences as numeric vectors to be used in some bioinformatics investigations,\nsuch as family classification and protein structure prediction. Recent\ntheoretical results showed that the well-known Lyndon factorization preserves\ncommon factors in overlapping strings. Surprisingly, the fingerprint of a\nsequencing read, which is the sequence of lengths of consecutive factors in\nvariants of the Lyndon factorization of the read, is effective in preserving\nsequence similarities, suggesting it as basis for the definition of novels\nrepresentations of sequencing reads. We propose a novel feature embedding\nmethod for Next-Generation Sequencing (NGS) data using the notion of\nfingerprint. We provide a theoretical and experimental framework to estimate\nthe behaviour of fingerprints and of the $k$-mers extracted from it, called\n$k$-fingers, as possible feature embeddings for sequencing reads. As a case\nstudy to assess the effectiveness of such embeddings, we use fingerprints to\nrepresent RNA-Seq reads and to assign them to the most likely gene from which\nthey were originated as fragments of transcripts of the gene. We provide an\nimplementation of the proposed method in the tool lyn2vec, which produces\nLyndon-based feature embeddings of sequencing reads.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13884v2"
    },
    {
        "title": "Packaging, containerization, and virtualization of computational omics\n  methods: Advances, challenges, and opportunities",
        "authors": [
            "Mohammed Alser",
            "Sharon Waymost",
            "Ram Ayyala",
            "Brendan Lawlor",
            "Richard J. Abdill",
            "Neha Rajkumar",
            "Nathan LaPierre",
            "Jaqueline Brito",
            "Andre M. Ribeiro-dos-Santos",
            "Can Firtina",
            "Nour Almadhoun",
            "Varuni Sarwal",
            "Eleazar Eskin",
            "Qiyang Hu",
            "Derek Strong",
            " Byoung-Do",
            " Kim",
            "Malak S. Abedalthagafi",
            "Onur Mutlu",
            "Serghei Mangul"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Omics software tools have reshaped the landscape of modern biology and become\nan essential component of biomedical research. The increasing dependence of\nbiomedical scientists on these powerful tools creates a need for easier\ninstallation and greater usability. Packaging, virtualization, and\ncontainerization are different approaches to satisfy this need by wrapping\nomics tools in additional software that makes the omics tools easier to install\nand use. Here, we systematically review practices across prominent packaging,\nvirtualization, and containerization platforms. We outline the challenges,\nadvantages, and limitations of each approach and some of the most widely used\nplatforms from the perspectives of users, software developers, and system\nadministrators. We also propose principles to make packaging, virtualization,\nand containerization of omics software more sustainable and robust to increase\nthe reproducibility of biomedical and life science research.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.16261v1"
    },
    {
        "title": "Graph Neural Networks for Microbial Genome Recovery",
        "authors": [
            "Andre Lamurias",
            "Alessandro Tibo",
            "Katja Hose",
            "Mads Albertsen",
            "Thomas Dyhre Nielsen"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Microbes have a profound impact on our health and environment, but our\nunderstanding of the diversity and function of microbial communities is\nseverely limited. Through DNA sequencing of microbial communities\n(metagenomics), DNA fragments (reads) of the individual microbes can be\nobtained, which through assembly graphs can be combined into long contiguous\nDNA sequences (contigs). Given the complexity of microbial communities, single\ncontig microbial genomes are rarely obtained. Instead, contigs are eventually\nclustered into bins, with each bin ideally making up a full genome. This\nprocess is referred to as metagenomic binning.\n  Current state-of-the-art techniques for metagenomic binning rely only on the\nlocal features for the individual contigs. These techniques therefore fail to\nexploit the similarities between contigs as encoded by the assembly graph, in\nwhich the contigs are organized. In this paper, we propose to use Graph Neural\nNetworks (GNNs) to leverage the assembly graph when learning contig\nrepresentations for metagenomic binning. Our method, VaeG-Bin, combines\nvariational autoencoders for learning latent representations of the individual\ncontigs, with GNNs for refining these representations by taking into account\nthe neighborhood structure of the contigs in the assembly graph. We explore\nseveral types of GNNs and demonstrate that VaeG-Bin recovers more high-quality\ngenomes than other state-of-the-art binners on both simulated and real-world\ndatasets.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.12270v1"
    },
    {
        "title": "Coupling Deep Imputation with Multitask Learning for Downstream Tasks on\n  Genomics Data",
        "authors": [
            "Sophie Peacock",
            "Etai Jacob",
            "Nikolay Burlutskiy"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Genomics data such as RNA gene expression, methylation and micro RNA\nexpression are valuable sources of information for various clinical predictive\ntasks. For example, predicting survival outcomes, cancer histology type and\nother patients' related information is possible using not only clinical data\nbut molecular data as well. Moreover, using these data sources together, for\nexample in multitask learning, can boost the performance. However, in practice,\nthere are many missing data points which leads to significantly lower patient\nnumbers when analysing full cases, which in our setting refers to all\nmodalities being present.\n  In this paper we investigate how imputing data with missing values using deep\nlearning coupled with multitask learning can help to reach state-of-the-art\nperformance results using combined genomics modalities, RNA, micro RNA and\nmethylation. We propose a generalised deep imputation method to impute values\nwhere a patient has all modalities present except one. Interestingly enough,\ndeep imputation alone outperforms multitask learning alone for the\nclassification and regression tasks across most combinations of modalities. In\ncontrast, when using all modalities for survival prediction we observe that\nmultitask learning alone outperforms deep imputation alone with statistical\nsignificance (adjusted p-value 0.03). Thus, both approaches are complementary\nwhen optimising performance for downstream predictive tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.13705v2"
    },
    {
        "title": "Going From Molecules to Genomic Variations to Scientific Discovery:\n  Intelligent Algorithms and Architectures for Intelligent Genome Analysis",
        "authors": [
            "Mohammed Alser",
            "Joel Lindegger",
            "Can Firtina",
            "Nour Almadhoun",
            "Haiyu Mao",
            "Gagandeep Singh",
            "Juan Gomez-Luna",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  We now need more than ever to make genome analysis more intelligent. We need\nto read, analyze, and interpret our genomes not only quickly, but also\naccurately and efficiently enough to scale the analysis to population level.\nThere currently exist major computational bottlenecks and inefficiencies\nthroughout the entire genome analysis pipeline, because state-of-the-art genome\nsequencing technologies are still not able to read a genome in its entirety. We\ndescribe the ongoing journey in significantly improving the performance,\naccuracy, and efficiency of genome analysis using intelligent algorithms and\nhardware architectures. We explain state-of-the-art algorithmic methods and\nhardware-based acceleration approaches for each step of the genome analysis\npipeline and provide experimental evaluations. Algorithmic approaches exploit\nthe structure of the genome as well as the structure of the underlying\nhardware. Hardware-based acceleration approaches exploit specialized\nmicroarchitectures or various execution paradigms (e.g., processing inside or\nnear memory) along with algorithmic changes, leading to new hardware/software\nco-designed systems. We conclude with a foreshadowing of future challenges,\nbenefits, and research directions triggered by the development of both very low\ncost yet highly error prone new sequencing technologies and specialized\nhardware chips for genomics. We hope that these efforts and the challenges we\ndiscuss provide a foundation for future work in making genome analysis more\nintelligent. The analysis script and data used in our experimental evaluation\nare available at: https://github.com/CMU-SAFARI/Molecules2Variations\n",
        "pdf_link": "http://arxiv.org/pdf/2205.07957v1"
    },
    {
        "title": "Spatial Transcriptomics Dimensionality Reduction using Wavelet Bases",
        "authors": [
            "Zhuoyan Xu",
            "Kris Sankaran"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Spatially resolved transcriptomics (ST) measures gene expression along with\nthe spatial coordinates of the measurements. The analysis of ST data involves\nsignificant computation complexity. In this work, we propose gene expression\ndimensionality reduction algorithm that retains spatial structure. We combine\nthe wavelet transformation with matrix factorization to select\nspatially-varying genes. We extract a low-dimensional representation of these\ngenes. We consider Empirical Bayes setting, imposing regularization through the\nprior distribution of factor genes. Additionally, We provide visualization of\nextracted representation genes capturing the global spatial pattern. We\nillustrate the performance of our methods by spatial structure recovery and\ngene expression reconstruction in simulation. In real data experiments, our\nmethod identifies spatial structure of gene factors and outperforms regular\ndecomposition regarding reconstruction error. We found the connection between\nthe fluctuation of gene patterns and wavelet technique, providing smoother\nvisualization. We develop the package and share the workflow generating\nreproducible quantitative results and gene visualization. The package is\navailable at https://github.com/OliverXUZY/waveST.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.11243v1"
    },
    {
        "title": "N-ACT: An Interpretable Deep Learning Model for Automatic Cell Type and\n  Salient Gene Identification",
        "authors": [
            "A. Ali Heydari",
            "Oscar A. Davalos",
            "Katrina K. Hoyer",
            "Suzanne S. Sindi"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Single-cell RNA sequencing (scRNAseq) is rapidly advancing our understanding\nof cellular composition within complex tissues and organisms. A major\nlimitation in most scRNAseq analysis pipelines is the reliance on manual\nannotations to determine cell identities, which are time consuming, subjective,\nand require expertise. Given the surge in cell sequencing, supervised\nmethods-especially deep learning models-have been developed for automatic cell\ntype identification (ACTI), which achieve high accuracy and scalability.\nHowever, all existing deep learning frameworks for ACTI lack interpretability\nand are used as \"black-box\" models. We present N-ACT (Neural-Attention for Cell\nType identification): the first-of-its-kind interpretable deep neural network\nfor ACTI utilizing neural-attention to detect salient genes for use in\ncell-type identification. We compare N-ACT to conventional annotation methods\non two previously manually annotated data sets, demonstrating that N-ACT\naccurately identifies marker genes and cell types in an unsupervised manner,\nwhile performing comparably on multiple data sets to current state-of-the-art\nmodel in traditional supervised ACTI.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.04047v1"
    },
    {
        "title": "Stacked Autoencoder Based Multi-Omics Data Integration for Cancer\n  Survival Prediction",
        "authors": [
            "Xing Wu",
            "Qiulian Fang"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Cancer survival prediction is important for developing personalized\ntreatments and inducing disease-causing mechanisms. Multi-omics data\nintegration is attracting widespread interest in cancer research for providing\ninformation for understanding cancer progression at multiple genetic levels.\nMany works, however, are limited because of the high dimensionality and\nheterogeneity of multi-omics data. In this paper, we propose a novel method to\nintegrate multi-omics data for cancer survival prediction, called Stacked\nAutoEncoder-based Survival Prediction Neural Network (SAEsurv-net). In the\ncancer survival prediction for TCGA cases, SAEsurv-net addresses the curse of\ndimensionality with a two-stage dimensionality reduction strategy and handles\nmulti-omics heterogeneity with a stacked autoencoder model. The two-stage\ndimensionality reduction strategy achieves a balance between computation\ncomplexity and information exploiting. The stacked autoencoder model removes\nmost heterogeneities such as data's type and size in the first group of\nautoencoders, and integrates multiple omics data in the second autoencoder. The\nexperiments show that SAEsurv-net outperforms models based on a single type of\ndata as well as other state-of-the-art methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.04878v1"
    },
    {
        "title": "COEM: Cross-Modal Embedding for MetaCell Identification",
        "authors": [
            "Haiyi Mao",
            "Minxue Jia",
            "Jason Xiaotian Dou",
            "Haotian Zhang",
            "Panayiotis V. Benos"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Metacells are disjoint and homogeneous groups of single-cell profiles,\nrepresenting discrete and highly granular cell states. Existing metacell\nalgorithms tend to use only one modality to infer metacells, even though\nsingle-cell multi-omics datasets profile multiple molecular modalities within\nthe same cell. Here, we present \\textbf{C}ross-M\\textbf{O}dal\n\\textbf{E}mbedding for \\textbf{M}etaCell Identification (COEM), which utilizes\nan embedded space leveraging the information of both scATAC-seq and scRNA-seq\nto perform aggregation, balancing the trade-off between fine resolution and\nsufficient sequencing coverage. COEM outperforms the state-of-the-art method\nSEACells by efficiently identifying accurate and well-separated metacells\nacross datasets with continuous and discrete cell types. Furthermore, COEM\nsignificantly improves peak-to-gene association analyses, and facilitates\ncomplex gene regulatory inference tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07734v2"
    },
    {
        "title": "Redundancy-aware unsupervised ranking based on game theory --\n  application to gene enrichment analysis",
        "authors": [
            "Chiara Balestra",
            "Carlo Maj",
            "Emmanuel Mueller",
            "Andreas Mayr"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Gene set collections are a common ground to study the enrichment of genes for\nspecific phenotypic traits. Gene set enrichment analysis aims to identify genes\nthat are over-represented in gene sets collections and might be associated with\na specific phenotypic trait. However, as this involves a massive number of\nhypothesis testing, it is often questionable whether a pre-processing step to\nreduce gene sets collections' sizes is helpful. Moreover, the often highly\noverlapping gene sets and the consequent low interpretability of gene sets'\ncollections demand for a reduction of the included gene sets. Inspired by this\nbioinformatics context, we propose a method to rank sets within a family of\nsets based on the distribution of the singletons and their size. We obtain\nsets' importance scores by computing Shapley values without incurring into the\nusual exponential number of evaluations of the value function. Moreover, we\naddress the challenge of including a redundancy awareness in the rankings\nobtained where, in our case, sets are redundant if they show prominent\nintersections. We finally evaluate our approach for gene sets collections; the\nrankings obtained show low redundancy and high coverage of the genes. The\nunsupervised nature of the proposed ranking does not allow for an evident\nincrease in the number of significant gene sets for specific phenotypic traits\nwhen reducing the size of the collections. However, we believe that the\nrankings proposed are of use in bioinformatics to increase interpretability of\nthe gene sets collections and a step forward to include redundancy into Shapley\nvalues computations.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.12184v1"
    },
    {
        "title": "Isoform Function Prediction Using a Deep Neural Network",
        "authors": [
            "Sara Ghazanfari",
            "Ali Rasteh",
            "Seyed Abolfazl Motahari",
            "Mahdieh Soleymani Baghshah"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Isoforms are mRNAs produced from the same gene site in the phenomenon called\nAlternative Splicing. Studies have shown that more than 95% of human multi-exon\ngenes have undergone alternative splicing. Although there are few changes in\nmRNA sequence, They may have a systematic effect on cell function and\nregulation. It is widely reported that isoforms of a gene have distinct or even\ncontrasting functions. Most studies have shown that alternative splicing plays\na significant role in human health and disease. Despite the wide range of gene\nfunction studies, there is little information about isoforms' functionalities.\nRecently, some computational methods based on Multiple Instance Learning have\nbeen proposed to predict isoform function using gene function and gene\nexpression profile. However, their performance is not desirable due to the lack\nof labeled training data. In addition, probabilistic models such as Conditional\nRandom Field (CRF) have been used to model the relation between isoforms. This\nproject uses all the data and valuable information such as isoform sequences,\nexpression profiles, and gene ontology graphs and proposes a comprehensive\nmodel based on Deep Neural Networks. The UniProt Gene Ontology (GO) database is\nused as a standard reference for gene functions. The NCBI RefSeq database is\nused for extracting gene and isoform sequences, and the NCBI SRA database is\nused for expression profile data. Metrics such as Receiver Operating\nCharacteristic Area Under the Curve (ROC AUC) and Precision-Recall Under the\nCurve (PR AUC) are used to measure the prediction accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03325v3"
    },
    {
        "title": "I-GWAS: Privacy-Preserving Interdependent Genome-Wide Association\n  Studies",
        "authors": [
            "Túlio Pascoal",
            "Jérémie Decouchant",
            "Antoine Boutet",
            "Marcus Völp"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Genome-wide Association Studies (GWASes) identify genomic variations that are\nstatistically associated with a trait, such as a disease, in a group of\nindividuals. Unfortunately, careless sharing of GWAS statistics might give rise\nto privacy attacks. Several works attempted to reconcile secure processing with\nprivacy-preserving releases of GWASes. However, we highlight that these\napproaches remain vulnerable if GWASes utilize overlapping sets of individuals\nand genomic variations. In such conditions, we show that even when relying on\nstate-of-the-art techniques for protecting releases, an adversary could\nreconstruct the genomic variations of up to 28.6% of participants, and that the\nreleased statistics of up to 92.3% of the genomic variations would enable\nmembership inference attacks. We introduce I-GWAS, a novel framework that\nsecurely computes and releases the results of multiple possibly interdependent\nGWASes. I-GWAS continuously releases privacy-preserving and noise-free GWAS\nresults as new genomes become available.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.08361v2"
    },
    {
        "title": "PRIME: Uncovering Circadian Oscillation Patterns and Associations with\n  AD in Untimed Genome-wide Gene Expression across Multiple Brain Regions",
        "authors": [
            "Xinxing Wu",
            "Chong Peng",
            "Gregory Jicha",
            "Donna Wilcock",
            "Qiang Cheng"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  The disruption of circadian rhythm is a cardinal symptom for Alzheimer's\ndisease (AD) patients. The full circadian rhythm orchestration of gene\nexpression in the human brain and its inherent associations with AD remain\nlargely unknown. We present a novel comprehensive approach, PRIME, to detect\nand analyze rhythmic oscillation patterns in untimed high-dimensional gene\nexpression data across multiple datasets. To demonstrate the utility of PRIME,\nfirstly, we validate it by a time course expression dataset from mouse liver as\na cross-species and cross-organ validation. Then, we apply it to study\noscillation patterns in untimed genome-wide gene expression from 19 human brain\nregions of controls and AD patients. Our findings reveal clear, synchronized\noscillation patterns in 15 pairs of brain regions of control, while these\noscillation patterns either disappear or dim for AD. It is worth noting that\nPRIME discovers the circadian rhythmic patterns without requiring the sample's\ntimestamps. The codes for PRIME, along with codes to reproduce the figures in\nthis paper, are available at https://github.com/xinxingwu-uk/PRIME.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12811v1"
    },
    {
        "title": "Typesafe Coordinate Systems in High-Throughput Sequencing Applications",
        "authors": [
            "Charles Thomas Gregory",
            "James S. Blachly"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  High-throughput sequencing file formats and tools encode coordinate intervals\nwith respect to a reference sequence in at least four distinct, incompatible\nways. Integrating data from and moving data between different formats has the\npotential to introduce subtle off-by-one errors. Here, we introduce the notion\nof typesafe coordinates: coordinate intervals are not only an integer pair, but\nmembers of a type class comprising four types: the Cartesian product of a zero\nor one basis, and an open or closed interval end. By leveraging the type system\nof statically and strongly-typed, compiled languages we can provide static\nguarantees that an entire class of error is eliminated. We provide a reference\nimplementation in D as part of a larger work (dhtslib), and proofs of concept\nin Rust, OCaml, and Python. Exploratory implementations are available at\nhttps://github.com/blachlylab/typesafe-coordinates.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.06603v1"
    },
    {
        "title": "Identifying Selections Operating on HIV-1 Reverse Transcriptase via\n  Uniform Manifold Approximation and Projection",
        "authors": [
            "Shefali Qamar",
            "Manel Camps",
            "Jay Kim"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  We analyze 14,651 HIV1 reverse transcriptase (HIV RT) sequences from the\nStanford HIV Drug Resistance Database labeled with treatment regimen in order\nto study the evolution this enzyme under drug selection in the clinic. Our goal\nis to identify distinct sectors of HIV RT's sequence space that are undergoing\nevolution as a way to identify individual selections and/or evolutionary\nsolutions. We utilize Uniform Manifold Approximation and Projection (UMAP), a\ngraph-based dimensionality reduction technique uniquely suited for the\ndetection of non-linear dependencies and visualize the results using an\nunsupervised clustering algorithm based on density analysis. Our analysis\nproduced 21 distinct clusters of sequences. Supporting the biological\nsignificance of these clusters, they tend to represent phylogenetically related\nsequences with strong correspondence to distinct treatment regimens. Thus, this\nmethod for visualization of areas of HIV RT undergoing evolution can help infer\ninformation about selective pressures, although it is correlative. The mutation\nsignatures associated with each cluster may represent the higher-order\nepistatic context facilitating these evolutionary pathways, information that is\ngenerally not accessible by other types of mutational co-dependence analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00345v1"
    },
    {
        "title": "Genomics Data Analysis via Spectral Shape and Topology",
        "authors": [
            "Erik J. Amézquita",
            "Farzana Nasrin",
            "Kathleen M. Storey",
            "Masato Yoshizawa"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Mapper, a topological algorithm, is frequently used as an exploratory tool to\nbuild a graphical representation of data. This representation can help to gain\na better understanding of the intrinsic shape of high-dimensional genomic data\nand to retain information that may be lost using standard dimension-reduction\nalgorithms. We propose a novel workflow to process and analyze RNA-seq data\nfrom tumor and healthy subjects integrating Mapper and differential gene\nexpression. Precisely, we show that a Gaussian mixture approximation method can\nbe used to produce graphical structures that successfully separate tumor and\nhealthy subjects, and produce two subgroups of tumor subjects. A further\nanalysis using DESeq2, a popular tool for the detection of differentially\nexpressed genes, shows that these two subgroups of tumor cells bear two\ndistinct gene regulations, suggesting two discrete paths for forming lung\ncancer, which could not be highlighted by other popular clustering methods,\nincluding t-SNE. Although Mapper shows promise in analyzing high-dimensional\ndata, building tools to statistically analyze Mapper graphical structures is\nlimited in the existing literature. In this paper, we develop a scoring method\nusing heat kernel signatures that provides an empirical setting for statistical\ninferences such as hypothesis testing, sensitivity analysis, and correlation\nanalysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.00938v1"
    },
    {
        "title": "Using Signal Processing in Tandem With Adapted Mixture Models for\n  Classifying Genomic Signals",
        "authors": [
            "Saish Jaiswal",
            "Shreya Nema",
            "Hema A Murthy",
            "Manikandan Narayanan"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Genomic signal processing has been used successfully in bioinformatics to\nanalyze biomolecular sequences and gain varied insights into DNA structure,\ngene organization, protein binding, sequence evolution, etc. But challenges\nremain in finding the appropriate spectral representation of a biomolecular\nsequence, especially when multiple variable-length sequences need to be handled\nconsistently. In this study, we address this challenge in the context of the\nwell-studied problem of classifying genomic sequences into different taxonomic\nunits (strain, phyla, order, etc.). We propose a novel technique that employs\nsignal processing in tandem with Gaussian mixture models to improve the\nspectral representation of a sequence and subsequently the taxonomic\nclassification accuracies. The sequences are first transformed into spectra,\nand projected to a subspace, where sequences belonging to different taxons are\nbetter distinguishable. Our method outperforms a similar state-of-the-art\nmethod on established benchmark datasets by an absolute margin of 6.06%\naccuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.01603v1"
    },
    {
        "title": "Uncertainty Quantification for Atlas-Level Cell Type Transfer",
        "authors": [
            "Jan Engelmann",
            "Leon Hetzel",
            "Giovanni Palla",
            "Lisa Sikkema",
            "Malte Luecken",
            "Fabian Theis"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Single-cell reference atlases are large-scale, cell-level maps that capture\ncellular heterogeneity within an organ using single cell genomics. Given their\nsize and cellular diversity, these atlases serve as high-quality training data\nfor the transfer of cell type labels to new datasets. Such label transfer,\nhowever, must be robust to domain shifts in gene expression due to measurement\ntechnique, lab specifics and more general batch effects. This requires methods\nthat provide uncertainty estimates on the cell type predictions to ensure\ncorrect interpretation. Here, for the first time, we introduce uncertainty\nquantification methods for cell type classification on single-cell reference\natlases. We benchmark four model classes and show that currently used models\nlack calibration, robustness, and actionable uncertainty scores. Furthermore,\nwe demonstrate how models that quantify uncertainty are better suited to detect\nunseen cell types in the setting of atlas-level cell type transfer.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03793v1"
    },
    {
        "title": "TargetCall: Eliminating the Wasted Computation in Basecalling via\n  Pre-Basecalling Filtering",
        "authors": [
            "Meryem Banu Cavlak",
            "Gagandeep Singh",
            "Mohammed Alser",
            "Can Firtina",
            "Joël Lindegger",
            "Mohammad Sadrosadati",
            "Nika Mansouri Ghiasi",
            "Can Alkan",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling computationally\ninefficient and memory-hungry, bottlenecking the entire genome analysis\npipeline. However, for many applications, the majority of reads do no match the\nreference genome of interest (i.e., target reference) and thus are discarded in\nlater steps in the genomics pipeline, wasting the basecalling computation. To\novercome this issue, we propose TargetCall, the first pre-basecalling filter to\neliminate the wasted computation in basecalling. TargetCall's key idea is to\ndiscard reads that will not match the target reference (i.e., off-target reads)\nprior to basecalling. TargetCall consists of two main components: (1)\nLightCall, a lightweight neural network basecaller that produces noisy reads;\nand (2) Similarity Check, which labels each of these noisy reads as on-target\nor off-target by matching them to the target reference. Our thorough\nexperimental evaluations show that TargetCall 1) improves the end-to-end\nbasecalling runtime performance of the state-of-the-art basecaller by 3.31x\nwhile maintaining high (98.88%) recall in keeping on-target reads, 2) maintains\nhigh accuracy in downstream analysis, and 3) achieves better runtime\nperformance, throughput, recall, precision, and generality compared to prior\nworks. TargetCall is available at https://github.com/CMU-SAFARI/TargetCall.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.04953v3"
    },
    {
        "title": "Information retrieval in single cell chromatin analysis using TF-IDF\n  transformation methods",
        "authors": [
            "Mehrdad Zandigohar",
            "Yang Dai"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Single-cell sequencing assay for transposase-accessible chromatin\n(scATAC-seq) assesses genome-wide chromatin accessibility in thousands of cells\nto reveal regulatory landscapes in high resolutions. However, the analysis\npresents challenges due to the high dimensionality and sparsity of the data.\nSeveral methods have been developed, including transformation techniques of\nterm-frequency inverse-document frequency (TF-IDF), dimension reduction methods\nsuch as singular value decomposition (SVD), factor analysis, and autoencoders.\nYet, a comprehensive study on the mentioned methods has not been fully\nperformed. It is not clear what is the best practice when analyzing scATAC-seq\ndata. We compared several scenarios for transformation and dimension reduction\nas well as the SVD-based feature analysis to investigate potential enhancements\nin scATAC-seq information retrieval. Additionally, we investigate if\nautoencoders benefit from the TF-IDF transformation. Our results reveal that\nthe TF-IDF transformation generally leads to improved clustering and\nbiologically relevant feature extraction.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.05184v1"
    },
    {
        "title": "Utilizing Mutations to Evaluate Interpretability of Neural Networks on\n  Genomic Data",
        "authors": [
            "Utku Ozbulak",
            "Solha Kang",
            "Jasper Zuallaert",
            "Stephen Depuydt",
            "Joris Vankerschaver"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Even though deep neural networks (DNNs) achieve state-of-the-art results for\na number of problems involving genomic data, getting DNNs to explain their\ndecision-making process has been a major challenge due to their black-box\nnature. One way to get DNNs to explain their reasoning for prediction is via\nattribution methods which are assumed to highlight the parts of the input that\ncontribute to the prediction the most. Given the existence of numerous\nattribution methods and a lack of quantitative results on the fidelity of those\nmethods, selection of an attribution method for sequence-based tasks has been\nmostly done qualitatively. In this work, we take a step towards identifying the\nmost faithful attribution method by proposing a computational approach that\nutilizes point mutations. Providing quantitative results on seven popular\nattribution methods, we find Layerwise Relevance Propagation (LRP) to be the\nmost appropriate one for translation initiation, with LRP identifying two\nimportant biological features for translation: the integrity of Kozak sequence\nas well as the detrimental effects of premature stop codons.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.06151v1"
    },
    {
        "title": "Neural Networks beyond explainability: Selective inference for sequence\n  motifs",
        "authors": [
            "Antoine Villié",
            "Philippe Veber",
            "Yohann de Castro",
            "Laurent Jacob"
        ],
        "category": "q-bio.GN",
        "published_year": "2022",
        "summary": "  Over the past decade, neural networks have been successful at making\npredictions from biological sequences, especially in the context of regulatory\ngenomics. As in other fields of deep learning, tools have been devised to\nextract features such as sequence motifs that can explain the predictions made\nby a trained network. Here we intend to go beyond explainable machine learning\nand introduce SEISM, a selective inference procedure to test the association\nbetween these extracted features and the predicted phenotype. In particular, we\ndiscuss how training a one-layer convolutional network is formally equivalent\nto selecting motifs maximizing some association score. We adapt existing\nsampling-based selective inference procedures by quantizing this selection over\nan infinite set to a large but finite grid. Finally, we show that sampling\nunder a specific choice of parameters is sufficient to characterize the\ncomposite null hypothesis typically used for selective inference-a result that\ngoes well beyond our particular framework. We illustrate the behavior of our\nmethod in terms of calibration, power and speed and discuss its power/speed\ntrade-off with a simpler data-split strategy. SEISM paves the way to an easier\nanalysis of neural networks used in regulatory genomics, and to more powerful\nmethods for genome wide association studies (GWAS).\n",
        "pdf_link": "http://arxiv.org/pdf/2212.12542v1"
    },
    {
        "title": "Single Cells Are Spatial Tokens: Transformers for Spatial Transcriptomic\n  Data Imputation",
        "authors": [
            "Hongzhi Wen",
            "Wenzhuo Tang",
            "Wei Jin",
            "Jiayuan Ding",
            "Renming Liu",
            "Xinnan Dai",
            "Feng Shi",
            "Lulu Shang",
            "Hui Liu",
            "Yuying Xie"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Spatially resolved transcriptomics brings exciting breakthroughs to\nsingle-cell analysis by providing physical locations along with gene\nexpression. However, as a cost of the extremely high spatial resolution, the\ncellular level spatial transcriptomic data suffer significantly from missing\nvalues. While a standard solution is to perform imputation on the missing\nvalues, most existing methods either overlook spatial information or only\nincorporate localized spatial context without the ability to capture long-range\nspatial information. Using multi-head self-attention mechanisms and positional\nencoding, transformer models can readily grasp the relationship between tokens\nand encode location information. In this paper, by treating single cells as\nspatial tokens, we study how to leverage transformers to facilitate spatial\ntanscriptomics imputation. In particular, investigate the following two key\nquestions: (1) $\\textit{how to encode spatial information of cells in\ntransformers}$, and (2) $\\textit{ how to train a transformer for transcriptomic\nimputation}$. By answering these two questions, we present a transformer-based\nimputation framework, SpaFormer, for cellular-level spatial transcriptomic\ndata. Extensive experiments demonstrate that SpaFormer outperforms existing\nstate-of-the-art imputation algorithms on three large-scale datasets while\nmaintaining superior computational efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03038v2"
    },
    {
        "title": "Revolutionizing Genomics with Reinforcement Learning Techniques",
        "authors": [
            "M. Karami",
            "K. Jahanian",
            "R. Alizadehsani",
            "A. Argha",
            "I. Dehzangi",
            "J. M. Gorriz",
            "Y. Zhang",
            "F. Hajati",
            "M. Yang",
            "H. Alinejad-Rokny"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In recent years, Reinforcement Learning (RL) has emerged as a powerful tool\nfor solving a wide range of problems, including decision-making and genomics.\nThe exponential growth of raw genomic data over the past two decades has\nexceeded the capacity of manual analysis, leading to a growing interest in\nautomatic data analysis and processing. RL algorithms are capable of learning\nfrom experience with minimal human supervision, making them well-suited for\ngenomic data analysis and interpretation. One of the key benefits of using RL\nis the reduced cost associated with collecting labeled training data, which is\nrequired for supervised learning. While there have been numerous studies\nexamining the applications of Machine Learning (ML) in genomics, this survey\nfocuses exclusively on the use of RL in various genomics research fields,\nincluding gene regulatory networks (GRNs), genome assembly, and sequence\nalignment. We present a comprehensive technical overview of existing studies on\nthe application of RL in genomics, highlighting the strengths and limitations\nof these approaches. We then discuss potential research directions that are\nworthy of future exploration, including the development of more sophisticated\nreward functions as RL heavily depends on the accuracy of the reward function,\nthe integration of RL with other machine learning techniques, and the\napplication of RL to new and emerging areas in genomics research. Finally, we\npresent our findings and conclude by summarizing the current state of the field\nand the future outlook for RL in genomics.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.13268v6"
    },
    {
        "title": "A New Deep Learning and XAI-Based Algorithm for Features Selection in\n  Genomics",
        "authors": [
            "Carlo Adornetto",
            "Gianluigi Greco"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In the field of functional genomics, the analysis of gene expression profiles\nthrough Machine and Deep Learning is increasingly providing meaningful insight\ninto a number of diseases. The paper proposes a novel algorithm to perform\nFeature Selection on genomic-scale data, which exploits the reconstruction\ncapabilities of autoencoders and an ad-hoc defined Explainable Artificial\nIntelligence-based score in order to select the most informative genes for\ndiagnosis, prognosis, and precision medicine. Results of the application on a\nChronic Lymphocytic Leukemia dataset evidence the effectiveness of the\nalgorithm, by identifying and suggesting a set of meaningful genes for further\nmedical investigation.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16914v1"
    },
    {
        "title": "Virus2Vec: Viral Sequence Classification Using Machine Learning",
        "authors": [
            "Sarwan Ali",
            "Babatunde Bello",
            "Prakash Chourasia",
            "Ria Thazhe Punathil",
            "Pin-Yu Chen",
            "Imdad Ullah Khan",
            "Murray Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Understanding the host-specificity of different families of viruses sheds\nlight on the origin of, e.g., SARS-CoV-2, rabies, and other such zoonotic\npathogens in humans. It enables epidemiologists, medical professionals, and\npolicymakers to curb existing epidemics and prevent future ones promptly. In\nthe family Coronaviridae (of which SARS-CoV-2 is a member), it is well-known\nthat the spike protein is the point of contact between the virus and the host\ncell membrane. On the other hand, the two traditional mammalian orders,\nCarnivora (carnivores) and Chiroptera (bats) are recognized to be responsible\nfor maintaining and spreading the Rabies Lyssavirus (RABV). We propose\nVirus2Vec, a feature-vector representation for viral (nucleotide or amino acid)\nsequences that enable vector-space-based machine learning models to identify\nviral hosts. Virus2Vec generates numerical feature vectors for unaligned\nsequences, allowing us to forego the computationally expensive sequence\nalignment step from the pipeline. Virus2Vec leverages the power of both the\n\\emph{minimizer} and position weight matrix (PWM) to generate compact feature\nvectors. Using several classifiers, we empirically evaluate Virus2Vec on\nreal-world spike sequences of Coronaviridae and rabies virus sequence data to\npredict the host (identifying the reservoirs of infection). Our results\ndemonstrate that Virus2Vec outperforms the predictive accuracies of baseline\nand state-of-the-art methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12328v1"
    },
    {
        "title": "Cancer-inspired Genomics Mapper Model for the Generation of Synthetic\n  DNA Sequences with Desired Genomics Signatures",
        "authors": [
            "Teddy Lazebnik",
            "Liron Simon-Keren"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Genome data are crucial in modern medicine, offering significant potential\nfor diagnosis and treatment. Thanks to technological advancements, many\nmillions of healthy and diseased genomes have already been sequenced; however,\nobtaining the most suitable data for a specific study, and specifically for\nvalidation studies, remains challenging with respect to scale and access.\nTherefore, in silico genomics sequence generators have been proposed as a\npossible solution. However, the current generators produce inferior data using\nmostly shallow (stochastic) connections, detected with limited computational\ncomplexity in the training data. This means they do not take the appropriate\nbiological relations and constraints, that originally caused the observed\nconnections, into consideration. To address this issue, we propose\ncancer-inspired genomics mapper model (CGMM), that combines genetic algorithm\n(GA) and deep learning (DL) methods to tackle this challenge. CGMM mimics\nprocesses that generate genetic variations and mutations to transform readily\navailable control genomes into genomes with the desired phenotypes. We\ndemonstrate that CGMM can generate synthetic genomes of selected phenotypes\nsuch as ancestry and cancer that are indistinguishable from real genomes of\nsuch phenotypes, based on unsupervised clustering. Our results show that CGMM\noutperforms four current state-of-the-art genomics generators on two different\ntasks, suggesting that CGMM will be suitable for a wide range of purposes in\ngenomic medicine, especially for much-needed validation studies.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.01475v1"
    },
    {
        "title": "Complexity and Enumeration in Models of Genome Rearrangement",
        "authors": [
            "Lora Bailey",
            "Heather Smith Blake",
            "Garner Cochran",
            "Nathan Fox",
            "Michael Levet",
            "Reem Mahmoud",
            "Elizabeth Matson",
            "Inne Singgih",
            "Grace Stadnyk",
            "Xinyi Wang",
            "Alexander Wiedemann"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  In this paper, we examine the computational complexity of enumeration in\ncertain genome rearrangement models. We first show that the Pairwise\nRearrangement problem in the Single Cut-and-Join model (Bergeron, Medvedev, &\nStoye, J. Comput. Biol. 2010) is $\\#\\textsf{P}$-complete under polynomial-time\nTuring reductions. Next, we show that in the Single Cut or Join model (Feijao &\nMeidanis, IEEE ACM Trans. Comp. Biol. Bioinf. 2011), the problem of enumerating\nall medians ($\\#$Median) is logspace-computable ($\\textsf{FL}$), improving upon\nthe previous polynomial-time ($\\textsf{FP}$) bound of Mikl\\'os & Smith (RECOMB\n2015).\n",
        "pdf_link": "http://arxiv.org/pdf/2305.01851v4"
    },
    {
        "title": "Gene Set Summarization using Large Language Models",
        "authors": [
            "Marcin P. Joachimiak",
            "J. Harry Caufield",
            "Nomi L. Harris",
            "Hyeongsik Kim",
            "Christopher J. Mungall"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Molecular biologists frequently interpret gene lists derived from\nhigh-throughput experiments and computational analysis. This is typically done\nas a statistical enrichment analysis that measures the over- or\nunder-representation of biological function terms associated with genes or\ntheir properties, based on curated assertions from a knowledge base (KB) such\nas the Gene Ontology (GO). Interpreting gene lists can also be framed as a\ntextual summarization task, enabling the use of Large Language Models (LLMs),\npotentially utilizing scientific texts directly and avoiding reliance on a KB.\n  We developed SPINDOCTOR (Structured Prompt Interpolation of Natural Language\nDescriptions of Controlled Terms for Ontology Reporting), a method that uses\nGPT models to perform gene set function summarization as a complement to\nstandard enrichment analysis. This method can use different sources of gene\nfunctional information: (1) structured text derived from curated ontological KB\nannotations, (2) ontology-free narrative gene summaries, or (3) direct model\nretrieval.\n  We demonstrate that these methods are able to generate plausible and\nbiologically valid summary GO term lists for gene sets. However, GPT-based\napproaches are unable to deliver reliable scores or p-values and often return\nterms that are not statistically significant. Crucially, these methods were\nrarely able to recapitulate the most precise and informative term from standard\nenrichment, likely due to an inability to generalize and reason using an\nontology. Results are highly nondeterministic, with minor variations in prompt\nresulting in radically different term lists. Our results show that at this\npoint, LLM-based methods are unsuitable as a replacement for standard term\nenrichment analysis and that manual curation of ontological assertions remains\nnecessary.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13338v3"
    },
    {
        "title": "GenSpectrum Chat: Data Exploration in Public Health Using Large Language\n  Models",
        "authors": [
            "Chaoran Chen",
            "Tanja Stadler"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Introduction: The COVID-19 pandemic highlighted the importance of making\nepidemiological data and scientific insights easily accessible and explorable\nfor public health agencies, the general public, and researchers.\nState-of-the-art approaches for sharing data and insights included regularly\nupdated reports and web dashboards. However, they face a trade-off between the\nsimplicity and flexibility of data exploration. With the capabilities of recent\nlarge language models (LLMs) such as GPT-4, this trade-off can be overcome.\n  Results: We developed the chatbot \"GenSpectrum Chat\"\n(https://cov-spectrum.org/chat) which uses GPT-4 as the underlying large\nlanguage model (LLM) to explore SARS-CoV-2 genomic sequencing data. Out of 500\ninputs from real-world users, the chatbot provided a correct answer for 453\nprompts; an incorrect answer for 13 prompts, and no answer although the\nquestion was within scope for 34 prompts. We also tested the chatbot with\ninputs from 10 different languages, and despite being provided solely with\nEnglish instructions and examples, it successfully processed prompts in all\ntested languages.\n  Conclusion: LLMs enable new ways of interacting with information systems. In\nthe field of public health, GenSpectrum Chat can facilitate the analysis of\nreal-time pathogen genomic data. With our chatbot supporting interactive\nexploration in different languages, we envision quick and direct access to the\nlatest evidence for policymakers around the world.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13821v1"
    },
    {
        "title": "Integrative analysis of ATAC-seq and RNA-seq for cells infected by human\n  T-cell leukemia virus type 1",
        "authors": [
            "Azusa Tanaka",
            "Yasuhiro Ishitsuka",
            "Hiroki Ohta",
            "Norihiro Takenouchi",
            "Masanori Nakagawa",
            "Ki-Ryang Koh",
            "Chiho Onishi",
            "Hiromitsu Tanaka",
            "Akihiro Fujimoto",
            "Jun-ichirou Yasunaga",
            "Masao Matsuoka"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Human T-cell leukemia virus type 1 (HTLV-1) causes adult T-cell leukemia\n(ATL) and HTLV-1-associated myelopathy (HAM) after a long latent period in a\nfraction of infected individuals. These HTLV-1-infected cells typically have\nphenotypes similar to that of CD4${^+}$ T cells, but the cell status is not\nwell understood. To extract the inherent information of HTLV-1-infected CD4$^+$\ncells, we integratively analyzed the ATAC-seq and RNA-seq data of infected\ncells. Compared to CD4${^+}$ T cells from healthy donors, we found anomalous\nchromatin accessibility in HTLV-1-infected CD4${^+}$ cells derived from ATL\ncases in terms of location and sample-to-sample fluctuations in open chromatin\nregions. Further, by focusing on systematically selected genes near the open\nchromatin regions, all the gene expressions in ATL cases were found to be\ndistinct from those of healthy CD4$^+$ T cells. Based on a further analysis of\nchromatin accessibility, we detected TLL1 (Tolloid Like 1) as one of the key\ngenes that exhibit unique gene expressions in ATL cases. A luciferase assay\nindicated that TLL1 has a strong regulatory effect on TGF-$\\beta$. Overall,\nthis study provides results about the status of HTLV-1 infected cells, which\nare qualitatively consistent across the different scales of chromatin\naccessibility, transcription, and immunophenotype.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.11841v1"
    },
    {
        "title": "DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species\n  Genome",
        "authors": [
            "Zhihan Zhou",
            "Yanrong Ji",
            "Weijian Li",
            "Pratik Dutta",
            "Ramana Davuluri",
            "Han Liu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Decoding the linguistic intricacies of the genome is a crucial problem in\nbiology, and pre-trained foundational models such as DNABERT and Nucleotide\nTransformer have made significant strides in this area. Existing works have\nlargely hinged on k-mer, fixed-length permutations of A, T, C, and G, as the\ntoken of the genome language due to its simplicity. However, we argue that the\ncomputation and sample inefficiencies introduced by k-mer tokenization are\nprimary obstacles in developing large genome foundational models. We provide\nconceptual and empirical insights into genome tokenization, building on which\nwe propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a\nstatistics-based data compression algorithm that constructs tokens by\niteratively merging the most frequent co-occurring genome segment in the\ncorpus. We demonstrate that BPE not only overcomes the limitations of k-mer\ntokenization but also benefits from the computational efficiency of\nnon-overlapping tokenization. Based on these insights, we introduce DNABERT-2,\na refined genome foundation model that adapts an efficient tokenizer and\nemploys multiple strategies to overcome input length constraints, reduce time\nand memory expenditure, and enhance model capability. Furthermore, we identify\nthe absence of a comprehensive and standardized benchmark for genome\nunderstanding as another significant impediment to fair comparative analysis.\nIn response, we propose the Genome Understanding Evaluation (GUE), a\ncomprehensive multi-species genome classification dataset that amalgamates $36$\ndistinct datasets across $9$ tasks, with input lengths ranging from $70$ to\n$10000$. Through comprehensive experiments on the GUE benchmark, we demonstrate\nthat DNABERT-2 achieves comparable performance to the state-of-the-art model\nwith $21 \\times$ fewer parameters and approximately $92 \\times$ less GPU time\nin pre-training.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.15006v2"
    },
    {
        "title": "Generative Language Models on Nucleotide Sequences of Human Genes",
        "authors": [
            "Musa Nuri Ihtiyar",
            "Arzucan Ozgur"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Language models, primarily transformer-based ones, obtained colossal success\nin NLP. To be more precise, studies like BERT in NLU and works such as GPT-3\nfor NLG are very crucial. DNA sequences are very close to natural language in\nterms of structure, so if the DNA-related bioinformatics domain is concerned,\ndiscriminative models, like DNABert, exist. Yet, the generative side of the\ncoin is mainly unexplored to the best of our knowledge. Consequently, we\nfocused on developing an autoregressive generative language model like GPT-3\nfor DNA sequences. Because working with whole DNA sequences is challenging\nwithout substantial computational resources, we decided to carry out our study\non a smaller scale, focusing on nucleotide sequences of human genes, unique\nparts in DNA with specific functionalities, instead of the whole DNA. This\ndecision did not change the problem structure a lot due to the fact that both\nDNA and genes can be seen as 1D sequences consisting of four different\nnucleotides without losing much information and making too much simplification.\nFirst of all, we systematically examined an almost entirely unexplored problem\nand observed that RNNs performed the best while simple techniques like N-grams\nwere also promising. Another beneficial point was learning how to work with\ngenerative models on languages we do not understand, unlike natural language.\nHow essential using real-life tasks beyond the classical metrics such as\nperplexity is observed. Furthermore, checking whether the data-hungry nature of\nthese models can be changed through selecting a language with minimal\nvocabulary size, four owing to four different types of nucleotides, is\nexamined. The reason for reviewing this was that choosing such a language might\nmake the problem easier. However, what we observed in this study was it did not\nprovide that much of a change in the amount of data needed.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.10634v1"
    },
    {
        "title": "MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive\n  Learning with Omics-Inference Modeling",
        "authors": [
            "Ziwei Yang",
            "Zheng Chen",
            "Yasuko Matsubara",
            "Yasushi Sakurai"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Precision medicine fundamentally aims to establish causality between\ndysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer\nsubtyping has emerged as a revolutionary approach, as different level of omics\nrecords the biochemical products of multistep processes in cancers. This paper\nfocuses on fully exploiting the potential of multi-omics data to improve cancer\nsubtyping outcomes, and hence developed MoCLIM, a representation learning\nframework. MoCLIM independently extracts the informative features from distinct\nomics modalities. Using a unified representation informed by contrastive\nlearning of different omics modalities, we can well-cluster the subtypes, given\ncancer, into a lower latent space. This contrast can be interpreted as a\nprojection of inter-omics inference observed in biological networks.\nExperimental results on six cancer datasets demonstrate that our approach\nsignificantly improves data fit and subtyping performance in fewer\nhigh-dimensional cancer instances. Moreover, our framework incorporates various\nmedical evaluations as the final component, providing high interpretability in\nmedical analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09725v2"
    },
    {
        "title": "Automated Bioinformatics Analysis via AutoBA",
        "authors": [
            "Juexiao Zhou",
            "Bin Zhang",
            "Xiuying Chen",
            "Haoyang Li",
            "Xiaopeng Xu",
            "Siyuan Chen",
            "Xin Gao"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  With the fast-growing and evolving omics data, the demand for streamlined and\nadaptable tools to handle the analysis continues to grow. In response to this\nneed, we introduce Auto Bioinformatics Analysis (AutoBA), an autonomous AI\nagent based on a large language model designed explicitly for conventional\nomics data analysis. AutoBA simplifies the analytical process by requiring\nminimal user input while delivering detailed step-by-step plans for various\nbioinformatics tasks. Through rigorous validation by expert bioinformaticians,\nAutoBA's robustness and adaptability are affirmed across a diverse range of\nomics analysis cases, including whole genome sequencing (WGS), RNA sequencing\n(RNA-seq), single-cell RNA-seq, ChIP-seq, and spatial transcriptomics. AutoBA's\nunique capacity to self-design analysis processes based on input data\nvariations further underscores its versatility. Compared with online\nbioinformatic services, AutoBA deploys the analysis locally, preserving data\nprivacy. Moreover, different from the predefined pipeline, AutoBA has\nadaptability in sync with emerging bioinformatics tools. Overall, AutoBA\nrepresents a convenient tool, offering robustness and adaptability for complex\nomics data analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.03242v1"
    },
    {
        "title": "Evaluation of large language models for discovery of gene set function",
        "authors": [
            "Mengzhou Hu",
            "Sahar Alkhairy",
            "Ingoo Lee",
            "Rudolf T. Pillich",
            "Dylan Fong",
            "Kevin Smith",
            "Robin Bachelder",
            "Trey Ideker",
            "Dexter Pratt"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Gene set analysis is a mainstay of functional genomics, but it relies on\ncurated databases of gene functions that are incomplete. Here we evaluate five\nLarge Language Models (LLMs) for their ability to discover the common\nbiological functions represented by a gene set, substantiated by supporting\nrationale, citations and a confidence assessment. Benchmarking against\ncanonical gene sets from the Gene Ontology, GPT-4 confidently recovered the\ncurated name or a more general concept (73% of cases), while benchmarking\nagainst random gene sets correctly yielded zero confidence. Gemini-Pro and\nMixtral-Instruct showed ability in naming but were falsely confident for random\nsets, whereas Llama2-70b had poor performance overall. In gene sets derived\nfrom 'omics data, GPT-4 identified novel functions not reported by classical\nfunctional enrichment (32% of cases), which independent review indicated were\nlargely verifiable and not hallucinations. The ability to rapidly synthesize\ncommon gene functions positions LLMs as valuable 'omics assistants.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04019v2"
    },
    {
        "title": "Tackling the dimensions in imaging genetics with CLUB-PLS",
        "authors": [
            "Andre Altmann",
            "Ana C Lawry Aguila",
            "Neda Jahanshad",
            "Paul M Thompson",
            "Marco Lorenzi"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  A major challenge in imaging genetics and similar fields is to link\nhigh-dimensional data in one domain, e.g., genetic data, to high dimensional\ndata in a second domain, e.g., brain imaging data. The standard approach in the\narea are mass univariate analyses across genetic factors and imaging\nphenotypes. That entails executing one genome-wide association study (GWAS) for\neach pre-defined imaging measure. Although this approach has been tremendously\nsuccessful, one shortcoming is that phenotypes must be pre-defined.\nConsequently, effects that are not confined to pre-selected regions of interest\nor that reflect larger brain-wide patterns can easily be missed. In this work\nwe introduce a Partial Least Squares (PLS)-based framework, which we term\nCluster-Bootstrap PLS (CLUB-PLS), that can work with large input dimensions in\nboth domains as well as with large sample sizes. One key factor of the\nframework is to use cluster bootstrap to provide robust statistics for single\ninput features in both domains. We applied CLUB-PLS to investigating the\ngenetic basis of surface area and cortical thickness in a sample of 33,000\nsubjects from the UK Biobank. We found 107 genome-wide significant\nlocus-phenotype pairs that are linked to 386 different genes. We found that a\nvast majority of these loci could be technically validated at a high rate:\nusing classic GWAS or Genome-Wide Inferred Statistics (GWIS) we found that 85\nlocus-phenotype pairs exceeded the genome-wide suggestive (P<1e-05) threshold.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.07352v2"
    },
    {
        "title": "Multi-View Variational Autoencoder for Missing Value Imputation in\n  Untargeted Metabolomics",
        "authors": [
            "Chen Zhao",
            "Kuan-Jui Su",
            "Chong Wu",
            "Xuewei Cao",
            "Qiuying Sha",
            "Wu Li",
            "Zhe Luo",
            "Tian Qin",
            "Chuan Qiu",
            "Lan Juan Zhao",
            "Anqi Liu",
            "Lindong Jiang",
            "Xiao Zhang",
            "Hui Shen",
            "Weihua Zhou",
            "Hong-Wen Deng"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Background: Missing data is a common challenge in mass spectrometry-based\nmetabolomics, which can lead to biased and incomplete analyses. The integration\nof whole-genome sequencing (WGS) data with metabolomics data has emerged as a\npromising approach to enhance the accuracy of data imputation in metabolomics\nstudies. Method: In this study, we propose a novel method that leverages the\ninformation from WGS data and reference metabolites to impute unknown\nmetabolites. Our approach utilizes a multi-view variational autoencoder to\njointly model the burden score, polygenetic risk score (PGS), and linkage\ndisequilibrium (LD) pruned single nucleotide polymorphisms (SNPs) for feature\nextraction and missing metabolomics data imputation. By learning the latent\nrepresentations of both omics data, our method can effectively impute missing\nmetabolomics values based on genomic information. Results: We evaluate the\nperformance of our method on empirical metabolomics datasets with missing\nvalues and demonstrate its superiority compared to conventional imputation\ntechniques. Using 35 template metabolites derived burden scores, PGS and\nLD-pruned SNPs, the proposed methods achieved R^2-scores > 0.01 for 71.55% of\nmetabolites. Conclusion: The integration of WGS data in metabolomics imputation\nnot only improves data completeness but also enhances downstream analyses,\npaving the way for more comprehensive and accurate investigations of metabolic\npathways and disease associations. Our findings offer valuable insights into\nthe potential benefits of utilizing WGS data for metabolomics data imputation\nand underscore the importance of leveraging multi-modal data integration in\nprecision medicine research.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.07990v2"
    },
    {
        "title": "Predicting Transcription Factor Binding Sites using Transformer based\n  Capsule Network",
        "authors": [
            "Nimisha Ghosh",
            "Daniele Santoni",
            "Indrajit Saha",
            "Giovanni Felici"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Prediction of binding sites for transcription factors is important to\nunderstand how they regulate gene expression and how this regulation can be\nmodulated for therapeutic purposes. Although in the past few years there are\nsignificant works addressing this issue, there is still space for improvement.\nIn this regard, a transformer based capsule network viz. DNABERT-Cap is\nproposed in this work to predict transcription factor binding sites mining\nChIP-seq datasets. DNABERT-Cap is a bidirectional encoder pre-trained with\nlarge number of genomic DNA sequences, empowered with a capsule layer\nresponsible for the final prediction. The proposed model builds a predictor for\ntranscription factor binding sites using the joint optimisation of features\nencompassing both bidirectional encoder and capsule layer, along with\nconvolutional and bidirectional long-short term memory layers. To evaluate the\nefficiency of the proposed approach, we use a benchmark ChIP-seq datasets of\nfive cell lines viz. A549, GM12878, Hep-G2, H1-hESC and Hela, available in the\nENCODE repository. The results show that the average area under the receiver\noperating characteristic curve score exceeds 0.91 for all such five cell lines.\nDNABERT-Cap is also compared with existing state-of-the-art deep learning based\npredictors viz. DeepARC, DeepTF, CNN-Zeng and DeepBind, and is seen to\noutperform them.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.15202v2"
    },
    {
        "title": "SequenceLab: A Comprehensive Benchmark of Computational Methods for\n  Comparing Genomic Sequences",
        "authors": [
            "Maximilian-David Rumpf",
            "Mohammed Alser",
            "Arvid E. Gollwitzer",
            "Joel Lindegger",
            "Nour Almadhoun",
            "Can Firtina",
            "Serghei Mangul",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Computational complexity is a key limitation of genomic analyses. Thus, over\nthe last 30 years, researchers have proposed numerous fast heuristic methods\nthat provide computational relief. Comparing genomic sequences is one of the\nmost fundamental computational steps in most genomic analyses. Due to its high\ncomputational complexity, optimized exact and heuristic algorithms are still\nbeing developed. We find that these methods are highly sensitive to the\nunderlying data, its quality, and various hyperparameters. Despite their wide\nuse, no in-depth analysis has been performed, potentially falsely discarding\ngenetic sequences from further analysis and unnecessarily inflating\ncomputational costs. We provide the first analysis and benchmark of this\nheterogeneity. We deliver an actionable overview of the 11 most widely used\nstate-of-the-art methods for comparing genomic sequences. We also inform\nreaders about their advantages and downsides using thorough experimental\nevaluation and different real datasets from all major manufacturers (i.e.,\nIllumina, ONT, and PacBio). SequenceLab is publicly available at\nhttps://github.com/CMU-SAFARI/SequenceLab.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.16908v4"
    },
    {
        "title": "MetaTrinity: Enabling Fast Metagenomic Classification via Seed Counting\n  and Edit Distance Approximation",
        "authors": [
            "Arvid E. Gollwitzer",
            "Mohammed Alser",
            "Joel Bergtholdt",
            "Joel Lindegger",
            "Maximilian-David Rumpf",
            "Can Firtina",
            "Serghei Mangul",
            "Onur Mutlu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Metagenomics, the study of genome sequences of diverse organisms cohabiting\nin a shared environment, has experienced significant advancements across\nvarious medical and biological fields. Metagenomic analysis is crucial, for\ninstance, in clinical applications such as infectious disease screening and the\ndiagnosis and early detection of diseases such as cancer. A key task in\nmetagenomics is to determine the species present in a sample and their relative\nabundances. Currently, the field is dominated by either alignment-based tools,\nwhich offer high accuracy but are computationally expensive, or alignment-free\ntools, which are fast but lack the needed accuracy for many applications. In\nresponse to this dichotomy, we introduce MetaTrinity, a tool based on\nheuristics, to achieve a fundamental improvement in accuracy-runtime tradeoff\nover existing methods. We benchmark MetaTrinity against two leading metagenomic\nclassifiers, each representing different ends of the performance-accuracy\nspectrum. On one end, Kraken2, a tool optimized for performance, shows modest\naccuracy yet a rapid runtime. The other end of the spectrum is governed by\nMetalign, a tool optimized for accuracy. Our evaluations show that MetaTrinity\nachieves an accuracy comparable to Metalign while gaining a 4x speedup without\nany loss in accuracy. This directly equates to a fourfold improvement in\nruntime-accuracy tradeoff. Compared to Kraken2, MetaTrinity requires a 5x\nlonger runtime yet delivers a 17x improvement in accuracy. This demonstrates a\n3.4x enhancement in the accuracy-runtime tradeoff for MetaTrinity. This dual\ncomparison positions MetaTrinity as a broadly applicable solution for\nmetagenomic classification, combining advantages of both ends of the spectrum:\nspeed and accuracy. MetaTrinity is publicly available at\nhttps://github.com/CMU-SAFARI/MetaTrinity.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02029v4"
    },
    {
        "title": "scBeacon: single-cell biomarker extraction via identifying paired cell\n  clusters across biological conditions with contrastive siamese networks",
        "authors": [
            "Chenyu Liu",
            "Yong Jin Kweon",
            "Jun Ding"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Despite the breakthroughs in biomarker discovery facilitated by differential\ngene analysis, challenges remain, particularly at the single-cell level.\nTraditional methodologies heavily rely on user-supplied cell annotations,\nfocusing on individually expressed data, often neglecting the critical\ninteractions between biological conditions, such as healthy versus diseased\nstates. In response, here we introduce scBeacon, an innovative framework built\nupon a deep contrastive siamese network. scBeacon pioneers an unsupervised\napproach, adeptly identifying matched cell populations across varied\nconditions, enabling a refined differential gene analysis. By utilizing a\nVQ-VAE framework, a contrastive siamese network, and a greedy iterative\nstrategy, scBeacon effectively pinpoints differential genes that hold potential\nas key biomarkers. Comprehensive evaluations on a diverse array of datasets\nvalidate scBeacon's superiority over existing single-cell differential gene\nanalysis tools. Its precision and adaptability underscore its significant role\nin enhancing diagnostic accuracy in biomarker discovery. With the emphasis on\nthe importance of biomarkers in diagnosis, scBeacon is positioned to be a\npivotal asset in the evolution of personalized medicine and targeted\ntreatments.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02594v2"
    },
    {
        "title": "ProPath: Disease-Specific Protein Language Model for Variant\n  Pathogenicity",
        "authors": [
            "Huixin Zhan",
            "Zijun Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Clinical variant classification of pathogenic versus benign genetic variants\nremains a pivotal challenge in clinical genetics. Recently, the proposition of\nprotein language models has improved the generic variant effect prediction\n(VEP) accuracy via weakly-supervised or unsupervised training. However, these\nVEPs are not disease-specific, limiting their adaptation at point-of-care. To\naddress this problem, we propose a disease-specific \\textsc{pro}tein language\nmodel for variant \\textsc{path}ogenicity, termed ProPath, to capture the\npseudo-log-likelihood ratio in rare missense variants through a siamese\nnetwork. We evaluate the performance of ProPath against pre-trained language\nmodels, using clinical variant sets in inherited cardiomyopathies and\narrhythmias that were not seen during training. Our results demonstrate that\nProPath surpasses the pre-trained ESM1b with an over $5\\%$ improvement in AUC\nacross both datasets. Furthermore, our model achieved the highest performances\nacross all baselines for both datasets. Thus, our ProPath offers a potent\ndisease-specific variant effect prediction, particularly valuable for disease\nassociations and clinical applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03429v2"
    },
    {
        "title": "Identifying DNA Sequence Motifs Using Deep Learning",
        "authors": [
            "Asmita Poddar",
            "Vladimir Uzun",
            "Elizabeth Tunbridge",
            "Wilfried Haerty",
            "Alejo Nevado-Holgado"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Splice sites play a crucial role in gene expression, and accurate prediction\nof these sites in DNA sequences is essential for diagnosing and treating\ngenetic disorders. We address the challenge of splice site prediction by\nintroducing DeepDeCode, an attention-based deep learning sequence model to\ncapture the long-term dependencies in the nucleotides in DNA sequences. We\nfurther propose using visualization techniques for accurate identification of\nsequence motifs, which enhance the interpretability and trustworthiness of\nDeepDeCode. We compare DeepDeCode to other state-of-the-art methods for splice\nsite prediction and demonstrate its accuracy, explainability and efficiency.\nGiven the results of our methodology, we expect that it can used for healthcare\napplications to reason about genomic processes and be extended to discover new\nsplice sites and genomic regulatory elements.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12884v1"
    },
    {
        "title": "mvlearnR and Shiny App for multiview learning",
        "authors": [
            "Elise F. Palzer",
            "Sandra E. Safo"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The package mvlearnR and accompanying Shiny App is intended for integrating\ndata from multiple sources or views or modalities (e.g. genomics, proteomics,\nclinical and demographic data). Most existing software packages for multiview\nlearning are decentralized and offer limited capabilities, making it difficult\nfor users to perform comprehensive integrative analysis. The new package wraps\nstatistical and machine learning methods and graphical tools, providing a\nconvenient and easy data integration workflow. For users with limited\nprogramming language, we provide a Shiny Application to facilitate data\nintegration anywhere and on any device. The methods have potential to offer\ndeeper insights into complex disease mechanisms.\n  Availability and Implementation: mvlearnR is available from the following\nGitHub repository: https://github.com/lasandrall/mvlearnR. The web application\nis hosted on shinyapps.io and available at:\nhttps://multi-viewlearn.shinyapps.io/MultiView_Modeling/\n",
        "pdf_link": "http://arxiv.org/pdf/2311.16181v1"
    },
    {
        "title": "Single-cell Multi-view Clustering via Community Detection with Unknown\n  Number of Clusters",
        "authors": [
            "Dayu Hu",
            "Zhibin Dong",
            "Ke Liang",
            "Jun Wang",
            "Siwei Wang",
            "Xinwang Liu"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Single-cell multi-view clustering enables the exploration of cellular\nheterogeneity within the same cell from different views. Despite the\ndevelopment of several multi-view clustering methods, two primary challenges\npersist. Firstly, most existing methods treat the information from both\nsingle-cell RNA (scRNA) and single-cell Assay of Transposase Accessible\nChromatin (scATAC) views as equally significant, overlooking the substantial\ndisparity in data richness between the two views. This oversight frequently\nleads to a degradation in overall performance. Additionally, the majority of\nclustering methods necessitate manual specification of the number of clusters\nby users. However, for biologists dealing with cell data, precisely determining\nthe number of distinct cell types poses a formidable challenge. To this end, we\nintroduce scUNC, an innovative multi-view clustering approach tailored for\nsingle-cell data, which seamlessly integrates information from different views\nwithout the need for a predefined number of clusters. The scUNC method\ncomprises several steps: initially, it employs a cross-view fusion network to\ncreate an effective embedding, which is then utilized to generate initial\nclusters via community detection. Subsequently, the clusters are automatically\nmerged and optimized until no further clusters can be merged. We conducted a\ncomprehensive evaluation of scUNC using three distinct single-cell datasets.\nThe results underscored that scUNC outperforms the other baseline methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17103v1"
    },
    {
        "title": "Longitudinal prediction of DNA methylation to forecast epigenetic\n  outcomes",
        "authors": [
            "Arthur Leroy",
            "Ai Ling Teh",
            "Frank Dondelinger",
            "Mauricio A. Alvarez",
            "Dennis Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Interrogating the evolution of biological changes at early stages of life\nrequires longitudinal profiling of molecules, such as DNA methylation, which\ncan be challenging with children. We introduce a probabilistic and longitudinal\nmachine learning framework based on multi-mean Gaussian processes (GPs),\naccounting for individual and gene correlations across time. This method\nprovides future predictions of DNA methylation status at different individual\nages while accounting for uncertainty. Our model is trained on a birth cohort\nof children with methylation profiled at ages 0-4, and we demonstrated that the\nstatus of methylation sites for each child can be accurately predicted at ages\n5-7. We show that methylation profiles predicted by multi-mean GPs can be used\nto estimate other phenotypes, such as epigenetic age, and enable comparison to\nother health measures of interest. This approach encourages epigenetic studies\nto move towards longitudinal design for investigating epigenetic changes during\ndevelopment, ageing and disease progression.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.13302v1"
    },
    {
        "title": "Single-Cell RNA-seq Synthesis with Latent Diffusion Model",
        "authors": [
            "Yixuan Wang",
            "Shuangyin Li",
            "Shimin DI",
            "Lei Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  The single-cell RNA sequencing (scRNA-seq) technology enables researchers to\nstudy complex biological systems and diseases with high resolution. The central\nchallenge is synthesizing enough scRNA-seq samples; insufficient samples can\nimpede downstream analysis and reproducibility. While various methods have been\nattempted in past research, the resulting scRNA-seq samples were often of poor\nquality or limited in terms of useful specific cell subpopulations. To address\nthese issues, we propose a novel method called Single-Cell Latent Diffusion\n(SCLD) based on the Diffusion Model. This method is capable of synthesizing\nlarge-scale, high-quality scRNA-seq samples, including both 'holistic' or\ntargeted specific cellular subpopulations within a unified framework. A\npre-guidance mechanism is designed for synthesizing specific cellular\nsubpopulations, while a post-guidance mechanism aims to enhance the quality of\nscRNA-seq samples. The SCLD can synthesize large-scale and high-quality\nscRNA-seq samples for various downstream tasks. Our experimental results\ndemonstrate state-of-the-art performance in cell classification and data\ndistribution distances when evaluated on two scRNA-seq benchmarks.\nAdditionally, visualization experiments show the SCLD's capability in\nsynthesizing specific cellular subpopulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14220v1"
    },
    {
        "title": "Deep Learning for Efficient GWAS Feature Selection",
        "authors": [
            "Kexuan Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Genome-Wide Association Studies (GWAS) face unique challenges in the era of\nbig genomics data, particularly when dealing with ultra-high-dimensional\ndatasets where the number of genetic features significantly exceeds the\navailable samples. This paper introduces an extension to the feature selection\nmethodology proposed by Mirzaei et al. (2020), specifically tailored to tackle\nthe intricacies associated with ultra-high-dimensional GWAS data. Our extended\napproach enhances the original method by introducing a Frobenius norm penalty\ninto the student network, augmenting its capacity to adapt to scenarios\ncharacterized by a multitude of features and limited samples. Operating\nseamlessly in both supervised and unsupervised settings, our method employs two\nkey neural networks. The first leverages an autoencoder or supervised\nautoencoder for dimension reduction, extracting salient features from the\nultra-high-dimensional genomic data. The second network, a regularized\nfeed-forward model with a single hidden layer, is designed for precise feature\nselection. The introduction of the Frobenius norm penalty in the student\nnetwork significantly boosts the method's resilience to the challenges posed by\nultra-high-dimensional GWAS datasets. Experimental results showcase the\nefficacy of our approach in feature selection for GWAS data. The method not\nonly handles the inherent complexities of ultra-high-dimensional settings but\nalso demonstrates superior adaptability to the nuanced structures present in\ngenomics data. The flexibility and versatility of our proposed methodology are\nunderscored by its successful performance across a spectrum of experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.15055v1"
    },
    {
        "title": "scRNA-seq Data Clustering by Cluster-aware Iterative Contrastive\n  Learning",
        "authors": [
            "Weikang Jiang",
            "Jinxian Wang",
            "Jihong Guan",
            "Shuigeng Zhou"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Single-cell RNA sequencing (scRNA-seq) enables researchers to analyze gene\nexpression at single-cell level. One important task in scRNA-seq data analysis\nis unsupervised clustering, which helps identify distinct cell types, laying\ndown the foundation for other downstream analysis tasks. In this paper, we\npropose a novel method called Cluster-aware Iterative Contrastive Learning\n(CICL in short) for scRNA-seq data clustering, which utilizes an iterative\nrepresentation learning and clustering framework to progressively learn the\nclustering structure of scRNA-seq data with a cluster-aware contrastive loss.\nCICL consists of a Transformer encoder, a clustering head, a projection head\nand a contrastive loss module. First, CICL extracts the feature vectors of the\noriginal and augmented data by the Transformer encoder. Then, it computes the\nclustering centroids by K-means and employs the student t-distribution to\nassign pseudo-labels to all cells in the clustering head. The projection-head\nuses a Multi-Layer Perceptron (MLP) to obtain projections of the augmented\ndata. At last, both pseudo-labels and projections are used in the contrastive\nloss to guide the model training. Such a process goes iteratively so that the\nclustering result becomes better and better. Extensive experiments on 25 real\nworld scRNA-seq datasets show that CICL outperforms the SOTA methods.\nConcretely, CICL surpasses the existing methods by from 14% to 280%, and from\n5% to 133% on average in terms of performance metrics ARI and NMI respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.16600v1"
    },
    {
        "title": "Integrate Any Omics: Towards genome-wide data integration for patient\n  stratification",
        "authors": [
            "Shihao Ma",
            "Andy G. X. Zeng",
            "Benjamin Haibe-Kains",
            "Anna Goldenberg",
            "John E Dick",
            "Bo Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  High-throughput omics profiling advancements have greatly enhanced cancer\npatient stratification. However, incomplete data in multi-omics integration\npresents a significant challenge, as traditional methods like sample exclusion\nor imputation often compromise biological diversity and dependencies.\nFurthermore, the critical task of accurately classifying new patients with\npartial omics data into existing subtypes is commonly overlooked. To address\nthese issues, we introduce IntegrAO (Integrate Any Omics), an unsupervised\nframework for integrating incomplete multi-omics data and classifying new\nsamples. IntegrAO first combines partially overlapping patient graphs from\ndiverse omics sources and utilizes graph neural networks to produce unified\npatient embeddings. Our systematic evaluation across five cancer cohorts\ninvolving six omics modalities demonstrates IntegrAO's robustness to missing\ndata and its accuracy in classifying new samples with partial profiles. An\nacute myeloid leukemia case study further validates its capability to uncover\nbiological and clinical heterogeneity in incomplete datasets. IntegrAO's\nability to handle heterogeneous and incomplete data makes it an essential tool\nfor precision oncology, offering a holistic approach to patient\ncharacterization.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07937v1"
    },
    {
        "title": "TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled\n  Zero-shot Genome Classification",
        "authors": [
            "Sathyanarayanan Aakur",
            "Vishalini R. Laguduva",
            "Priyadharsini Ramamurthy",
            "Akhilesh Ramachandran"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  A species' genetic code or genome encodes valuable evolutionary, biological,\nand phylogenetic information that aids in species recognition, taxonomic\nclassification, and understanding genetic predispositions like drug resistance\nand virulence. However, the vast number of potential species poses significant\nchallenges in developing a general-purpose whole genome classification tool.\nTraditional bioinformatics tools have made notable progress but lack\nscalability and are computationally expensive. Machine learning-based\nframeworks show promise but must address the issue of large classification\nvocabularies with long-tail distributions. In this study, we propose addressing\nthis problem through zero-shot learning using TEPI, Taxonomy-aware Embedding\nand Pseudo-Imaging. We represent each genome as pseudo-images and map them to a\ntaxonomy-aware embedding space for reasoning and classification. This embedding\nspace captures compositional and phylogenetic relationships of species,\nenabling predictions in extensive search spaces. We evaluate TEPI using two\nrigorous zero-shot settings and demonstrate its generalization capabilities\nqualitatively on curated, large-scale, publicly sourced data.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.13219v1"
    },
    {
        "title": "Predicting loss-of-function impact of genetic mutations: a machine\n  learning approach",
        "authors": [
            "Arshmeet Kaur",
            "Morteza Sarmadi"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The innovation of next-generation sequencing (NGS) techniques has\nsignificantly reduced the price of genome sequencing, lowering barriers to\nfuture medical research; it is now feasible to apply genome sequencing to\nstudies where it would have previously been cost-inefficient. Identifying\ndamaging or pathogenic mutations in vast amounts of complex, high-dimensional\ngenome sequencing data may be of particular interest to researchers. Thus, this\npaper's aims were to train machine learning models on the attributes of a\ngenetic mutation to predict LoFtool scores (which measure a gene's intolerance\nto loss-of-function mutations). These attributes included, but were not limited\nto, the position of a mutation on a chromosome, changes in amino acids, and\nchanges in codons caused by the mutation. Models were built using the\nunivariate feature selection technique f-regression combined with K-nearest\nneighbors (KNN), Support Vector Machine (SVM), Random Sample Consensus\n(RANSAC), Decision Trees, Random Forest, and Extreme Gradient Boosting\n(XGBoost). These models were evaluated using five-fold cross-validated averages\nof r-squared, mean squared error, root mean squared error, mean absolute error,\nand explained variance. The findings of this study include the training of\nmultiple models with testing set r-squared values of 0.97.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.00054v1"
    },
    {
        "title": "Unlocking the Power of Multi-institutional Data: Integrating and\n  Harmonizing Genomic Data Across Institutions",
        "authors": [
            "Yuan Chen",
            "Ronglai Shen",
            "Xiwen Feng",
            "Katherine Panageas"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Cancer is a complex disease driven by genomic alterations, and tumor\nsequencing is becoming a mainstay of clinical care for cancer patients. The\nemergence of multi-institution sequencing data presents a powerful resource for\nlearning real-world evidence to enhance precision oncology. GENIE BPC, led by\nthe American Association for Cancer Research, establishes a unique database\nlinking genomic data with clinical information for patients treated at multiple\ncancer centers. However, leveraging such multi-institutional sequencing data\npresents significant challenges. Variations in gene panels result in loss of\ninformation when the analysis is conducted on common gene sets. Additionally,\ndifferences in sequencing techniques and patient heterogeneity across\ninstitutions add complexity. High data dimensionality, sparse gene mutation\npatterns, and weak signals at the individual gene level further complicate\nmatters. Motivated by these real-world challenges, we introduce the Bridge\nmodel. It uses a quantile-matched latent variable approach to derive integrated\nfeatures to preserve information beyond common genes and maximize the\nutilization of all available data while leveraging information sharing to\nenhance both learning efficiency and the model's capacity to generalize. By\nextracting harmonized and noise-reduced lower-dimensional latent variables, the\ntrue mutation pattern unique to each individual is captured. We assess the\nmodel's performance and parameter estimation through extensive simulation\nstudies. The extracted latent features from the Bridge model consistently excel\nin predicting patient survival across six cancer types in GENIE BPC data.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.00077v2"
    },
    {
        "title": "Pairwise Rearrangement is Fixed-Parameter Tractable in the Single\n  Cut-and-Join Model",
        "authors": [
            "Lora Bailey",
            "Heather Smith Blake",
            "Garner Cochran",
            "Nathan Fox",
            "Michael Levet",
            "Reem Mahmoud",
            "Inne Singgih",
            "Grace Stadnyk",
            "Alexander Wiedemann"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Genome rearrangement is a common model for molecular evolution. In this\npaper, we consider the Pairwise Rearrangement problem, which takes as input two\ngenomes and asks for the number of minimum-length sequences of permissible\noperations transforming the first genome into the second. In the Single\nCut-and-Join model (Bergeron, Medvedev, & Stoye, J. Comput. Biol. 2010),\nPairwise Rearrangement is $\\#\\textsf{P}$-complete (Bailey, et. al., COCOON\n2023), which implies that exact sampling is intractable. In order to cope with\nthis intractability, we investigate the parameterized complexity of this\nproblem. We exhibit a fixed-parameter tractable algorithm with respect to the\nnumber of components in the adjacency graph that are not cycles of length $2$\nor paths of length $1$. As a consequence, we obtain that Pairwise Rearrangement\nin the Single Cut-and-Join model is fixed-parameter tractable by distance. Our\nresults suggest that the number of nontrivial components in the adjacency graph\nserves as the key obstacle for efficient sampling.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01942v4"
    },
    {
        "title": "Machine learning applied to omics data",
        "authors": [
            "Aida Calviño",
            "Almudena Moreno-Ribera",
            "Silvia Pineda"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  In this chapter we illustrate the use of some Machine Learning techniques in\nthe context of omics data. More precisely, we review and evaluate the use of\nRandom Forest and Penalized Multinomial Logistic Regression for integrative\nanalysis of genomics and immunomics in pancreatic cancer. Furthermore, we\npropose the use of association rules with predictive purposes to overcome the\nlow predictive power of the previously mentioned models. Finally, we apply the\nreviewed methods to a real data set from TCGA made of 107 tumoral pancreatic\nsamples and 117,486 germline SNPs, showing the good performance of the proposed\nmethods to predict the immunological infiltration in pancreatic cancer.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.05543v1"
    },
    {
        "title": "DiscDiff: Latent Diffusion Model for DNA Sequence Generation",
        "authors": [
            "Zehui Li",
            "Yuhao Ni",
            "William A V Beardall",
            "Guoxuan Xia",
            "Akashaditya Das",
            "Guy-Bart Stan",
            "Yiren Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This paper introduces a novel framework for DNA sequence generation,\ncomprising two key components: DiscDiff, a Latent Diffusion Model (LDM)\ntailored for generating discrete DNA sequences, and Absorb-Escape, a\npost-training algorithm designed to refine these sequences. Absorb-Escape\nenhances the realism of the generated sequences by correcting `round errors'\ninherent in the conversion process between latent and input spaces. Our\napproach not only sets new standards in DNA sequence generation but also\ndemonstrates superior performance over existing diffusion models, in generating\nboth short and long DNA sequences. Additionally, we introduce EPD-GenDNA, the\nfirst comprehensive, multi-species dataset for DNA generation, encompassing\n160,000 unique sequences from 15 species. We hope this study will advance the\ngenerative modelling of DNA, with potential implications for gene therapy and\nprotein production.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.06079v2"
    },
    {
        "title": "Highly Accurate Disease Diagnosis and Highly Reproducible Biomarker\n  Identification with PathFormer",
        "authors": [
            "Zehao Dong",
            "Qihang Zhao",
            "Philip R. O. Payne",
            "Michael A Province",
            "Carlos Cruchaga",
            "Muhan Zhang",
            "Tianyu Zhao",
            "Yixin Chen",
            "Fuhai Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Biomarker identification is critical for precise disease diagnosis and\nunderstanding disease pathogenesis in omics data analysis, like using fold\nchange and regression analysis. Graph neural networks (GNNs) have been the\ndominant deep learning model for analyzing graph-structured data. However, we\nfound two major limitations of existing GNNs in omics data analysis, i.e.,\nlimited-prediction (diagnosis) accuracy and limited-reproducible biomarker\nidentification capacity across multiple datasets. The root of the challenges is\nthe unique graph structure of biological signaling pathways, which consists of\na large number of targets and intensive and complex signaling interactions\namong these targets. To resolve these two challenges, in this study, we\npresented a novel GNN model architecture, named PathFormer, which\nsystematically integrate signaling network, priori knowledge and omics data to\nrank biomarkers and predict disease diagnosis. In the comparison results,\nPathFormer outperformed existing GNN models significantly in terms of highly\naccurate prediction capability ( 30% accuracy improvement in disease diagnosis\ncompared with existing GNN models) and high reproducibility of biomarker\nranking across different datasets. The improvement was confirmed using two\nindependent Alzheimer's Disease (AD) and cancer transcriptomic datasets. The\nPathFormer model can be directly applied to other omics data analysis studies.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07268v1"
    },
    {
        "title": "Efficient and Scalable Fine-Tune of Language Models for Genome\n  Understanding",
        "authors": [
            "Huixin Zhan",
            "Ying Nian Wu",
            "Zijun Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Although DNA foundation models have advanced the understanding of genomes,\nthey still face significant challenges in the limited scale and diversity of\ngenomic data. This limitation starkly contrasts with the success of natural\nlanguage foundation models, which thrive on substantially larger scales.\nFurthermore, genome understanding involves numerous downstream genome\nannotation tasks with inherent data heterogeneity, thereby necessitating more\nefficient and robust fine-tuning methods tailored for genomics. Here, we\npresent \\textsc{Lingo}: \\textsc{L}anguage prefix f\\textsc{In}e-tuning for\n\\textsc{G}en\\textsc{O}mes. Unlike DNA foundation models, \\textsc{Lingo}\nstrategically leverages natural language foundation models' contextual cues,\nrecalibrating their linguistic knowledge to genomic sequences. \\textsc{Lingo}\nfurther accommodates numerous, heterogeneous downstream fine-tune tasks by an\nadaptive rank sampling method that prunes and stochastically reintroduces\npruned singular vectors within small computational budgets. Adaptive rank\nsampling outperformed existing fine-tuning methods on all benchmarked 14 genome\nunderstanding tasks, while requiring fewer than 2\\% of trainable parameters as\ngenomic-specific adapters. Impressively, applying these adapters on natural\nlanguage foundation models matched or even exceeded the performance of DNA\nfoundation models. \\textsc{Lingo} presents a new paradigm of efficient and\nscalable genome understanding via genomic-specific adapters on language models.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.08075v1"
    },
    {
        "title": "DNABERT-S: Pioneering Species Differentiation with Species-Aware DNA\n  Embeddings",
        "authors": [
            "Zhihan Zhou",
            "Weimin Wu",
            "Harrison Ho",
            "Jiayi Wang",
            "Lizhen Shi",
            "Ramana V Davuluri",
            "Zhong Wang",
            "Han Liu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  We introduce DNABERT-S, a tailored genome model that develops species-aware\nembeddings to naturally cluster and segregate DNA sequences of different\nspecies in the embedding space. Differentiating species from genomic sequences\n(i.e., DNA and RNA) is vital yet challenging, since many real-world species\nremain uncharacterized, lacking known genomes for reference. Embedding-based\nmethods are therefore used to differentiate species in an unsupervised manner.\nDNABERT-S builds upon a pre-trained genome foundation model named DNABERT-2. To\nencourage effective embeddings to error-prone long-read DNA sequences, we\nintroduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes\nthe hidden representations of DNA sequences at randomly selected layers and\ntrains the model to recognize and differentiate these mixed proportions at the\noutput layer. We further enhance it with the proposed Curriculum Contrastive\nLearning (C$^2$LR) strategy. Empirical results on 23 diverse datasets show\nDNABERT-S's effectiveness, especially in realistic label-scarce scenarios. For\nexample, it identifies twice more species from a mixture of unlabeled genomic\nsequences, doubles the Adjusted Rand Index (ARI) in species clustering, and\noutperforms the top baseline's performance in 10-shot species classification\nwith just a 2-shot training. Model, codes, and data are publicly available at\n\\url{https://github.com/MAGICS-LAB/DNABERT_S}.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.08777v3"
    },
    {
        "title": "Data Smoothing Filling Method based on ScRNA-Seq Data Zero-Value\n  Identification",
        "authors": [
            "Linfeng Jiang",
            "Yuan Zhu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Single-cell RNA sequencing (scRNA-seq) determines RNA expression at\nsingle-cell resolution. It provides a powerful tool for studying immunity,\nregulation, and other life activities of cells. However, due to the limitations\nof the sequencing technique, the scRNA-seq data are represented with sparsity,\nwhichcontains missing gene values, i.e., zero values, called dropout.\nTherefore, it is necessary to impute missing values before analyzing scRNA-seq\ndata. However, existing imputation computation methods often only focus on the\nidentification of technical zeros or imputing all zeros based on cell\nsimilarity. This study proposes a new method (SFAG) to reconstruct the gene\nexpression relationship matrix by usinggraph regularization technology to\npreserve the high-dimensional manifold information of the data, andto mine the\nrelationship between genes and cells in the data, and then uses a method of\naveraging the clustering results to fill in the identified technical zeros.\nExperimental results show that SFAGcan helpimprove downstream analysis and\nreconstruct cell trajectory\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09755v1"
    },
    {
        "title": "Toward a Team of AI-made Scientists for Scientific Discovery from Gene\n  Expression Data",
        "authors": [
            "Haoyang Liu",
            "Yijiang Li",
            "Jinglin Jian",
            "Yuxuan Cheng",
            "Jianrong Lu",
            "Shuyi Guo",
            "Jinglei Zhu",
            "Mianchen Zhang",
            "Miantong Zhang",
            "Haohan Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Machine learning has emerged as a powerful tool for scientific discovery,\nenabling researchers to extract meaningful insights from complex datasets. For\ninstance, it has facilitated the identification of disease-predictive genes\nfrom gene expression data, significantly advancing healthcare. However, the\ntraditional process for analyzing such datasets demands substantial human\neffort and expertise for the data selection, processing, and analysis. To\naddress this challenge, we introduce a novel framework, a Team of AI-made\nScientists (TAIS), designed to streamline the scientific discovery pipeline.\nTAIS comprises simulated roles, including a project manager, data engineer, and\ndomain expert, each represented by a Large Language Model (LLM). These roles\ncollaborate to replicate the tasks typically performed by data scientists, with\na specific focus on identifying disease-predictive genes. Furthermore, we have\ncurated a benchmark dataset to assess TAIS's effectiveness in gene\nidentification, demonstrating our system's potential to significantly enhance\nthe efficiency and scope of scientific exploration. Our findings represent a\nsolid step towards automating scientific discovery through large language\nmodels.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.12391v2"
    },
    {
        "title": "FGBERT: Function-Driven Pre-trained Gene Language Model for Metagenomics",
        "authors": [
            "ChenRui Duan",
            "Zelin Zang",
            "Yongjie Xu",
            "Hang He",
            "Zihan Liu",
            "Siyuan Li",
            "Zijia Song",
            "Ju-Sheng Zheng",
            "Stan Z. Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Metagenomic data, comprising mixed multi-species genomes, are prevalent in\ndiverse environments like oceans and soils, significantly impacting human\nhealth and ecological functions. However, current research relies on K-mer,\nwhich limits the capture of structurally and functionally relevant gene\ncontexts. Moreover, these approaches struggle with encoding biologically\nmeaningful genes and fail to address the One-to-Many and Many-to-One\nrelationships inherent in metagenomic data. To overcome these challenges, we\nintroduce FGBERT, a novel metagenomic pre-trained model that employs a\nprotein-based gene representation as a context-aware and structure-relevant\ntokenizer. FGBERT incorporates Masked Gene Modeling (MGM) to enhance the\nunderstanding of inter-gene contextual relationships and Triplet Enhanced\nMetagenomic Contrastive Learning (TMC) to elucidate gene sequence-function\nrelationships. Pre-trained on over 100 million metagenomic sequences, FGBERT\ndemonstrates superior performance on metagenomic datasets at four levels,\nspanning gene, functional, bacterial, and environmental levels and ranging from\n1k to 213k input sequences. Case studies of ATP Synthase and Gene Operons\nhighlight FGBERT's capability for functional recognition and its biological\nrelevance in metagenomic research.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.16901v2"
    },
    {
        "title": "Advancing Gene Selection in Oncology: A Fusion of Deep Learning and\n  Sparsity for Precision Gene Selection",
        "authors": [
            "Akhila Krishna",
            "Ravi Kant Gupta",
            "Pranav Jeevan",
            "Amit Sethi"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Gene selection plays a pivotal role in oncology research for improving\noutcome prediction accuracy and facilitating cost-effective genomic profiling\nfor cancer patients. This paper introduces two gene selection strategies for\ndeep learning-based survival prediction models. The first strategy uses a\nsparsity-inducing method while the second one uses importance based gene\nselection for identifying relevant genes. Our overall approach leverages the\npower of deep learning to model complex biological data structures, while\nsparsity-inducing methods ensure the selection process focuses on the most\ninformative genes, minimizing noise and redundancy. Through comprehensive\nexperimentation on diverse genomic and survival datasets, we demonstrate that\nour strategy not only identifies gene signatures with high predictive power for\nsurvival outcomes but can also streamlines the process for low-cost genomic\nprofiling. The implications of this research are profound as it offers a\nscalable and effective tool for advancing personalized medicine and targeted\ncancer therapies. By pushing the boundaries of gene selection methodologies,\nour work contributes significantly to the ongoing efforts in cancer genomics,\npromising improved diagnostic and prognostic capabilities in clinical settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.01927v1"
    },
    {
        "title": "stMCDI: Masked Conditional Diffusion Model with Graph Neural Network for\n  Spatial Transcriptomics Data Imputation",
        "authors": [
            "Xiaoyu Li",
            "Wenwen Min",
            "Shunfang Wang",
            "Changmiao Wang",
            "Taosheng Xu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Spatially resolved transcriptomics represents a significant advancement in\nsingle-cell analysis by offering both gene expression data and their\ncorresponding physical locations. However, this high degree of spatial\nresolution entails a drawback, as the resulting spatial transcriptomic data at\nthe cellular level is notably plagued by a high incidence of missing values.\nFurthermore, most existing imputation methods either overlook the spatial\ninformation between spots or compromise the overall gene expression data\ndistribution. To address these challenges, our primary focus is on effectively\nutilizing the spatial location information within spatial transcriptomic data\nto impute missing values, while preserving the overall data distribution. We\nintroduce \\textbf{stMCDI}, a novel conditional diffusion model for spatial\ntranscriptomics data imputation, which employs a denoising network trained\nusing randomly masked data portions as guidance, with the unmasked data serving\nas conditions. Additionally, it utilizes a GNN encoder to integrate the spatial\nposition information, thereby enhancing model performance. The results obtained\nfrom spatial transcriptomics datasets elucidate the performance of our methods\nrelative to existing approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.10863v1"
    },
    {
        "title": "F5C-finder: An Explainable and Ensemble Biological Language Model for\n  Predicting 5-Formylcytidine Modifications on mRNA",
        "authors": [
            "Guohao Wang",
            "Ting Liu",
            "Hongqiang Lyu",
            "Ze Liu"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  As a prevalent and dynamically regulated epigenetic modification,\n5-formylcytidine (f5C) is crucial in various biological processes. However,\ntraditional experimental methods for f5C detection are often laborious and\ntime-consuming, limiting their ability to map f5C sites across the\ntranscriptome comprehensively. While computational approaches offer a\ncost-effective and high-throughput alternative, no recognition model for f5C\nhas been developed to date. Drawing inspiration from language models in natural\nlanguage processing, this study presents f5C-finder, an ensemble neural\nnetwork-based model utilizing multi-head attention for the identification of\nf5C. Five distinct feature extraction methods were employed to construct five\nindividual artificial neural networks, and these networks were subsequently\nintegrated through ensemble learning to create f5C-finder. 10-fold\ncross-validation and independent tests demonstrate that f5C-finder achieves\nstate-of-the-art (SOTA) performance with AUC of 0.807 and 0.827, respectively.\nThe result highlights the effectiveness of biological language model in\ncapturing both the order (sequential) and functional meaning (semantics) within\ngenomes. Furthermore, the built-in interpretability allows us to understand\nwhat the model is learning, creating a bridge between identifying key\nsequential elements and a deeper exploration of their biological functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.13265v1"
    },
    {
        "title": "GRAMEP: an alignment-free method based on the Maximum Entropy Principle\n  for identifying SNPs",
        "authors": [
            "Matheus Henrique Pimenta-Zanon",
            "André Yoshiaki Kashiwabara",
            "André Luís Laforga Vanzela",
            "Fabricio Martins Lopes"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Background: Advances in high throughput sequencing technologies provide a\nhuge number of genomes to be analyzed. Thus, computational methods play a\ncrucial role in analyzing and extracting knowledge from the data generated.\nInvestigating genomic mutations is critical because of their impact on\nchromosomal evolution, genetic disorders, and diseases. It is common to adopt\naligning sequences for analyzing genomic variations. However, this approach can\nbe computationally expensive and restrictive in scenarios with large datasets.\nResults: We present a novel method for identifying single nucleotide\npolymorphisms (SNPs) in DNA sequences from assembled genomes. This study\nproposes GRAMEP, an alignment-free approach that adopts the principle of\nmaximum entropy to discover the most informative k-mers specific to a genome or\nset of sequences under investigation. The informative k-mers enable the\ndetection of variant-specific mutations in comparison to a reference genome or\nother set of sequences. In addition, our method offers the possibility of\nclassifying novel sequences with no need for organism-specific information.\nGRAMEP demonstrated high accuracy in both in silico simulations and analyses of\nviral genomes, including Dengue, HIV, and SARS-CoV-2. Our approach maintained\naccurate SARS-CoV-2 variant identification while demonstrating a lower\ncomputational cost compared to methods with the same purpose. Conclusions:\nGRAMEP is an open and user-friendly software based on maximum entropy that\nprovides an efficient alignment-free approach to identifying and classifying\nunique genomic subsequences and SNPs with high accuracy, offering advantages\nover comparative methods. The instructions for use, applicability, and\nusability of GRAMEP are open access at\nhttps://github.com/omatheuspimenta/GRAMEP\n",
        "pdf_link": "http://arxiv.org/pdf/2405.01715v2"
    },
    {
        "title": "LangCell: Language-Cell Pre-training for Cell Identity Understanding",
        "authors": [
            "Suyuan Zhao",
            "Jiahuan Zhang",
            "Yushuai Wu",
            "Yizhen Luo",
            "Zaiqing Nie"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Cell identity encompasses various semantic aspects of a cell, including cell\ntype, pathway information, disease information, and more, which are essential\nfor biologists to gain insights into its biological characteristics.\nUnderstanding cell identity from the transcriptomic data, such as annotating\ncell types, has become an important task in bioinformatics. As these semantic\naspects are determined by human experts, it is impossible for AI models to\neffectively carry out cell identity understanding tasks without the supervision\nsignals provided by single-cell and label pairs. The single-cell pre-trained\nlanguage models (PLMs) currently used for this task are trained only on a\nsingle modality, transcriptomics data, lack an understanding of cell identity\nknowledge. As a result, they have to be fine-tuned for downstream tasks and\nstruggle when lacking labeled data with the desired semantic labels. To address\nthis issue, we propose an innovative solution by constructing a unified\nrepresentation of single-cell data and natural language during the pre-training\nphase, allowing the model to directly incorporate insights related to cell\nidentity. More specifically, we introduce $\\textbf{LangCell}$, the first\n$\\textbf{Lang}$uage-$\\textbf{Cell}$ pre-training framework. LangCell utilizes\ntexts enriched with cell identity information to gain a profound comprehension\nof cross-modal knowledge. Results from experiments conducted on different\nbenchmarks show that LangCell is the only single-cell PLM that can work\neffectively in zero-shot cell identity understanding scenarios, and also\nsignificantly outperforms existing models in few-shot and fine-tuning cell\nidentity understanding scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.06708v5"
    },
    {
        "title": "QuST-LLM: Integrating Large Language Models for Comprehensive Spatial\n  Transcriptomics Analysis",
        "authors": [
            "Chao Hui Huang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  In this paper, we introduce QuST-LLM, an innovative extension of QuPath that\nutilizes the capabilities of large language models (LLMs) to analyze and\ninterpret spatial transcriptomics (ST) data. In addition to simplifying the\nintricate and high-dimensional nature of ST data by offering a comprehensive\nworkflow that includes data loading, region selection, gene expression\nanalysis, and functional annotation, QuST-LLM employs LLMs to transform complex\nST data into understandable and detailed biological narratives based on gene\nontology annotations, thereby significantly improving the interpretability of\nST data. Consequently, users can interact with their own ST data using natural\nlanguage. Hence, QuST-LLM provides researchers with a potent functionality to\nunravel the spatial and functional complexities of tissues, fostering novel\ninsights and advancements in biomedical research. QuST-LLM is a part of QuST\nproject. The source code is hosted on GitHub and documentation is available at\n(https://github.com/huangch/qust).\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14307v2"
    },
    {
        "title": "SeqMate: A Novel Large Language Model Pipeline for Automating RNA\n  Sequencing",
        "authors": [
            "Devam Mondal",
            "Atharva Inamdar"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  RNA sequencing techniques, like bulk RNA-seq and Single Cell (sc) RNA-seq,\nare critical tools for the biologist looking to analyze the genetic\nactivity/transcriptome of a tissue or cell during an experimental procedure.\nPlatforms like Illumina's next-generation sequencing (NGS) are used to produce\nthe raw data for this experimental procedure. This raw FASTQ data must then be\nprepared via a complex series of data manipulations by bioinformaticians. This\nprocess currently takes place on an unwieldy textual user interface like a\nterminal/command line that requires the user to install and import multiple\nprogram packages, preventing the untrained biologist from initiating data\nanalysis. Open-source platforms like Galaxy have produced a more user-friendly\npipeline, yet the visual interface remains cluttered and highly technical,\nremaining uninviting for the natural scientist. To address this, SeqMate is a\nuser-friendly tool that allows for one-click analytics by utilizing the power\nof a large language model (LLM) to automate both data preparation and analysis\n(differential expression, trajectory analysis, etc). Furthermore, by utilizing\nthe power of generative AI, SeqMate is also capable of analyzing such findings\nand producing written reports of upregulated/downregulated/user-prompted genes\nwith sources cited from known repositories like PubMed, PDB, and Uniprot.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.03381v1"
    },
    {
        "title": "Single-cell 3D genome reconstruction in the haploid setting using\n  rigidity theory",
        "authors": [
            "Sean Dewar",
            "Georg Grasegger",
            "Kaie Kubjas",
            "Fatemeh Mohammadi",
            "Anthony Nixon"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  This article considers the problem of 3-dimensional genome reconstruction for\nsingle-cell data, and the uniqueness of such reconstructions in the setting of\nhaploid organisms. We consider multiple graph models as representations of this\nproblem, and use techniques from graph rigidity theory to determine\nidentifiability. Biologically, our models come from Hi-C data, microscopy data,\nand combinations thereof. Mathematically, we use unit ball and sphere packing\nmodels, as well as models consisting of distance and inequality constraints. In\neach setting, we describe and/or derive new results on realisability and\nuniqueness. We then propose a 3D reconstruction method based on semidefinite\nprogramming and apply it to synthetic and real data sets using our models.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.10700v1"
    },
    {
        "title": "Genomic Language Models: Opportunities and Challenges",
        "authors": [
            "Gonzalo Benegas",
            "Chengzhong Ye",
            "Carlos Albors",
            "Jianan Canal Li",
            "Yun S. Song"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Large language models (LLMs) are having transformative impacts across a wide\nrange of scientific fields, particularly in the biomedical sciences. Just as\nthe goal of Natural Language Processing is to understand sequences of words, a\nmajor objective in biology is to understand biological sequences. Genomic\nLanguage Models (gLMs), which are LLMs trained on DNA sequences, have the\npotential to significantly advance our understanding of genomes and how DNA\nelements at various scales interact to give rise to complex functions. To\nshowcase this potential, we highlight key applications of gLMs, including\nfunctional constraint prediction, sequence design, and transfer learning.\nDespite notable recent progress, however, developing effective and efficient\ngLMs presents numerous challenges, especially for species with large, complex\ngenomes. Here, we discuss major considerations for developing and evaluating\ngLMs.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.11435v2"
    },
    {
        "title": "Dy-mer: An Explainable DNA Sequence Representation Scheme using Sparse\n  Recovery",
        "authors": [
            "Zhiyuan Peng",
            "Yuanbo Tang",
            "Yang Li"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  DNA sequences encode vital genetic and biological information, yet these\nunfixed-length sequences cannot serve as the input of common data mining\nalgorithms. Hence, various representation schemes have been developed to\ntransform DNA sequences into fixed-length numerical representations. However,\nthese schemes face difficulties in learning high-quality representations due to\nthe complexity and sparsity of DNA data. Additionally, DNA sequences are\ninherently noisy because of mutations. While several schemes have been proposed\nfor their effectiveness, they often lack semantic structure, making it\ndifficult for biologists to validate and leverage the results. To address these\nchallenges, we propose \\textbf{Dy-mer}, an explainable and robust DNA\nrepresentation scheme based on sparse recovery. Leveraging the underlying\nsemantic structure of DNA, we modify the traditional sparse recovery to capture\nrecurring patterns indicative of biological functions by representing frequent\nK-mers as basis vectors and reconstructing each DNA sequence through simple\nconcatenation. Experimental results demonstrate that \\textbf{Dy-mer} achieves\nstate-of-the-art performance in DNA promoter classification, yielding a\nremarkable \\textbf{13\\%} increase in accuracy. Moreover, its inherent\nexplainability facilitates DNA clustering and motif detection, enhancing its\nutility in biological research.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.12051v1"
    },
    {
        "title": "Interpreting artificial neural networks to detect genome-wide\n  association signals for complex traits",
        "authors": [
            "Burak Yelmen",
            "Maris Alver",
            "Estonian Biobank Research Team",
            "Flora Jay",
            "Lili Milani"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Investigating the genetic architecture of complex diseases is challenging due\nto the highly polygenic and interactive landscape of genetic and environmental\nfactors. Although genome-wide association studies (GWAS) have identified\nthousands of variants for multiple complex phenotypes, conventional statistical\napproaches can be limited by simplified assumptions such as linearity and lack\nof epistasis models. In this work, we trained artificial neural networks for\npredicting complex traits using both simulated and real genotype/phenotype\ndatasets. We extracted feature importance scores via different post hoc\ninterpretability methods to identify potentially associated loci (PAL) for the\ntarget phenotype. Simulations we performed with various parameters demonstrated\nthat associated loci can be detected with good precision using strict selection\ncriteria, but downstream analyses are required for fine-mapping the exact\nvariants due to linkage disequilibrium, similarly to conventional GWAS. By\napplying our approach to the schizophrenia cohort in the Estonian Biobank, we\nwere able to detect multiple PAL related to this highly polygenic and heritable\ndisorder. We also performed enrichment analyses with PAL in genic regions,\nwhich predominantly identified terms associated with brain morphology. With\nfurther improvements in model optimization and confidence measures, artificial\nneural networks can enhance the identification of genomic loci associated with\ncomplex diseases, providing a more comprehensive approach for GWAS and serving\nas initial screening tools for subsequent functional studies.\n  Keywords: Deep learning, interpretability, genome-wide association studies,\ncomplex diseases\n",
        "pdf_link": "http://arxiv.org/pdf/2407.18811v1"
    },
    {
        "title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell\n  RNA-seq Data",
        "authors": [
            "Wenwen Min",
            "Zhen Wang",
            "Fangfang Zhu",
            "Taosheng Xu",
            "Shunfang Wang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Single-cell RNA sequencing (scRNA-seq) data analysis is pivotal for\nunderstanding cellular heterogeneity. However, the high sparsity and complex\nnoise patterns inherent in scRNA-seq data present significant challenges for\ntraditional clustering methods. To address these issues, we propose a deep\nclustering method, Attention-Enhanced Structural Deep Embedding Graph\nClustering (scASDC), which integrates multiple advanced modules to improve\nclustering accuracy and robustness.Our approach employs a multi-layer graph\nconvolutional network (GCN) to capture high-order structural relationships\nbetween cells, termed as the graph autoencoder module. To mitigate the\noversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module that\nextracts content information from the data and learns latent representations of\ngene expression. These modules are further integrated through an attention\nfusion mechanism, ensuring effective combination of gene expression and\nstructural information at each layer of the GCN. Additionally, a\nself-supervised learning module is incorporated to enhance the robustness of\nthe learned embeddings. Extensive experiments demonstrate that scASDC\noutperforms existing state-of-the-art methods, providing a robust and effective\nsolution for single-cell clustering tasks. Our method paves the way for more\naccurate and meaningful analysis of single-cell RNA sequencing data,\ncontributing to better understanding of cellular heterogeneity and biological\nprocesses. All code and public datasets used in this paper are available at\n\\url{https://github.com/wenwenmin/scASDC} and\n\\url{https://zenodo.org/records/12814320}.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.05258v1"
    },
    {
        "title": "Masked Graph Autoencoders with Contrastive Augmentation for Spatially\n  Resolved Transcriptomics Data",
        "authors": [
            "Donghai Fang",
            "Fangfang Zhu",
            "Dongting Xie",
            "Wenwen Min"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  With the rapid advancement of Spatial Resolved Transcriptomics (SRT)\ntechnology, it is now possible to comprehensively measure gene transcription\nwhile preserving the spatial context of tissues. Spatial domain identification\nand gene denoising are key objectives in SRT data analysis. We propose a\nContrastively Augmented Masked Graph Autoencoder (STMGAC) to learn\nlow-dimensional latent representations for domain identification. In the latent\nspace, persistent signals for representations are obtained through\nself-distillation to guide self-supervised matching. At the same time, positive\nand negative anchor pairs are constructed using triplet learning to augment the\ndiscriminative ability. We evaluated the performance of STMGAC on five\ndatasets, achieving results superior to those of existing baseline methods. All\ncode and public datasets used in this paper are available at\nhttps://github.com/wenwenmin/STMGAC and https://zenodo.org/records/13253801.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.06377v1"
    },
    {
        "title": "Quantum Annealing for Enhanced Feature Selection in Single-Cell RNA\n  Sequencing Data Analysis",
        "authors": [
            "Selim Romero",
            "Shreyan Gupta",
            "Victoria Gatlin",
            "Robert S. Chapkin",
            "James J. Cai"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Feature selection is vital for identifying relevant variables in\nclassification and regression models, especially in single-cell RNA sequencing\n(scRNA-seq) data analysis. Traditional methods like LASSO often struggle with\nthe nonlinearities and multicollinearities in scRNA-seq data due to complex\ngene expression and extensive gene interactions. Quantum annealing, a form of\nquantum computing, offers a promising solution. In this study, we apply quantum\nannealing-empowered quadratic unconstrained binary optimization (QUBO) for\nfeature selection in scRNA-seq data. Using data from a human cell\ndifferentiation system, we show that QUBO identifies genes with nonlinear\nexpression patterns related to differentiation time, many of which play roles\nin the differentiation process. In contrast, LASSO tends to select genes with\nmore linear expression changes. Our findings suggest that the QUBO method,\npowered by quantum annealing, can reveal complex gene expression patterns that\ntraditional methods might overlook, enhancing scRNA-seq data analysis and\ninterpretation.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.08867v2"
    },
    {
        "title": "Identification of Prognostic Biomarkers for Stage III Non-Small Cell\n  Lung Carcinoma in Female Nonsmokers Using Machine Learning",
        "authors": [
            "Huili Zheng",
            "Qimin Zhang",
            "Yiru Gong",
            "Zheyan Liu",
            "Shaohan Chen"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Lung cancer remains a leading cause of cancer-related deaths globally, with\nnon-small cell lung cancer (NSCLC) being the most common subtype. This study\naimed to identify key biomarkers associated with stage III NSCLC in non-smoking\nfemales using gene expression profiling from the GDS3837 dataset. Utilizing\nXGBoost, a machine learning algorithm, the analysis achieved a strong\npredictive performance with an AUC score of 0.835. The top biomarkers\nidentified - CCAAT enhancer binding protein alpha (C/EBP-alpha), lactate\ndehydrogenase A4 (LDHA), UNC-45 myosin chaperone B (UNC-45B), checkpoint kinase\n1 (CHK1), and hypoxia-inducible factor 1 subunit alpha (HIF-1-alpha) - have\nbeen validated in the literature as being significantly linked to lung cancer.\nThese findings highlight the potential of these biomarkers for early diagnosis\nand personalized therapy, emphasizing the value of integrating machine learning\nwith molecular profiling in cancer research.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.16068v2"
    },
    {
        "title": "Nearest Neighbor CCP-Based Molecular Sequence Analysis",
        "authors": [
            "Sarwan Ali",
            "Prakash Chourasia",
            "Bipin Koirala",
            "Murray Patterson"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Molecular sequence analysis is crucial for comprehending several biological\nprocesses, including protein-protein interactions, functional annotation, and\ndisease classification. The large number of sequences and the inherently\ncomplicated nature of protein structures make it challenging to analyze such\ndata. Finding patterns and enhancing subsequent research requires the use of\ndimensionality reduction and feature selection approaches. Recently, a method\ncalled Correlated Clustering and Projection (CCP) has been proposed as an\neffective method for biological sequencing data. The CCP technique is still\ncostly to compute even though it is effective for sequence visualization.\nFurthermore, its utility for classifying molecular sequences is still\nuncertain. To solve these two problems, we present a Nearest Neighbor\nCorrelated Clustering and Projection (CCP-NN)-based technique for efficiently\npreprocessing molecular sequence data. To group related molecular sequences and\nproduce representative supersequences, CCP makes use of sequence-to-sequence\ncorrelations. As opposed to conventional methods, CCP doesn't rely on matrix\ndiagonalization, therefore it can be applied to a range of machine-learning\nproblems. We estimate the density map and compute the correlation using a\nnearest-neighbor search technique. We performed molecular sequence\nclassification using CCP and CCP-NN representations to assess the efficacy of\nour proposed approach. Our findings show that CCP-NN considerably improves\nclassification task accuracy as well as significantly outperforms CCP in terms\nof computational runtime.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.04922v1"
    },
    {
        "title": "Hierarchical novel class discovery for single-cell transcriptomic\n  profiles",
        "authors": [
            "Malek Senoussi",
            "Thierry Artières",
            "Paul Villoutreix"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  One of the major challenges arising from single-cell transcriptomics\nexperiments is the question of how to annotate the associated single-cell\ntranscriptomic profiles. Because of the large size and the high dimensionality\nof the data, automated methods for annotation are needed. We focus here on\ndatasets obtained in the context of developmental biology, where the\ndifferentiation process leads to a hierarchical structure. We consider a\nfrequent setting where both labeled and unlabeled data are available at\ntraining time, but the sets of the labels of labeled data on one side and of\nthe unlabeled data on the other side, are disjoint. It is an instance of the\nNovel Class Discovery problem. The goal is to achieve two objectives,\nclustering the data and mapping the clusters with labels. We propose extensions\nof k-Means and GMM clustering methods for solving the problem and report\ncomparative results on artificial and experimental transcriptomic datasets. Our\napproaches take advantage of the hierarchical nature of the data.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05937v1"
    },
    {
        "title": "Highly conserved sequence-specific double-stranded DNA binding networks\n  contributing to divergent genomic evolution of human and chimpanzee brain\n  development",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Emergence during mammalian evolution of concordant and divergent traits of\ngenomic regulatory networks encompassing ubiquitous, qualitatively nearly\nidentical yet quantitatively distinct arrays of sequences of transcription\nfactor binding sites (TFBS) for 716 proteins is reported. A vast majority of\nTFs (770 of 716; 98%) comprising protein constituents of these networks appear\nto share common Gene Ontology (GO) features of sequence-specific\ndouble-stranded DNA binding (GO: 1990837). Genome-wide and individual\nchromosome-level analyses of 17,935 ATAC-seq-defined brain development\nregulatory regions (BDRRs) revealed nearly universal representations of TFBS\nfor TF-constituents of these networks, TFBS densities of which appear\nconsistently higher within thousands BDRRs of Modern Humans compare to\nChimpanzee. Transposable elements (TE), including LTR/HERV, SINE/Alu, SVA, and\nLINE families, appear to harbor and spread genome-wide consensus regulatory\nnodes of identified herein highly conserved sequence-specific double-stranded\nDNA binding networks, selections of TFBS panels of which manifest individual\nchromosome-specific profiles and species-specific divergence patterns.\nCollectively, observations reported in this contribution highlight a previously\nunrecognized essential function of human genomic DNA sequences encoded by TE in\nproviding genome-wide regulatory seed templates of highly conserved\nsequence-specific double-stranded DNA binding networks likely contributing to\ncontinuing divergent genomic evolution of human and chimpanzee brain\ndevelopment.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.07812v1"
    },
    {
        "title": "dnaGrinder: a lightweight and high-capacity genomic foundation model",
        "authors": [
            "Qihang Zhao",
            "Chi Zhang",
            "Weixiong Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The task of understanding and interpreting the complex information encoded\nwithin genomic sequences remains a grand challenge in biological research and\nclinical applications. In this context, recent advancements in large language\nmodel research have led to the development of both encoder-only and\ndecoder-only foundation models designed to decode intricate information in DNA\nsequences. However, several issues persist, particularly regarding the\nefficient management of long-range dependencies inherent in genomic sequences,\nthe effective representation of nucleotide variations, and the considerable\ncomputational costs associated with large model architectures and extensive\npretraining datasets. Current genomic foundation models often face a critical\ntradeoff: smaller models with mediocre performance versus large models with\nimproved performance. To address these challenges, we introduce dnaGrinder, a\nunique and efficient genomic foundation model. dnaGrinder excels at managing\nlong-range dependencies within genomic sequences while minimizing computational\ncosts without compromising performance. It achieves results that are not just\ncomparable but often superior to leading DNA models such as Nucleotide\nTransformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy\nfine-tuning on workstation-grade GPUs, accommodating input lengths exceeding\n17,000 tokens. On a single high-performance GPU, it supports sequences longer\nthan 140,000 tokens, making it a highly efficient and accessible tool for both\nbasic biological research and clinical applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.15697v1"
    },
    {
        "title": "Evaluating Deep Regression Models for WSI-Based Gene-Expression\n  Prediction",
        "authors": [
            "Fredrik K. Gustafsson",
            "Mattias Rantalainen"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Prediction of mRNA gene-expression profiles directly from routine whole-slide\nimages (WSIs) using deep learning models could potentially offer cost-effective\nand widely accessible molecular phenotyping. While such WSI-based\ngene-expression prediction models have recently emerged within computational\npathology, the high-dimensional nature of the corresponding regression problem\noffers numerous design choices which remain to be analyzed in detail. This\nstudy provides recommendations on how deep regression models should be trained\nfor WSI-based gene-expression prediction. For example, we conclude that\ntraining a single model to simultaneously regress all 20530 genes is a\ncomputationally efficient yet very strong baseline.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.00945v1"
    },
    {
        "title": "Beyond the Alphabet: Deep Signal Embedding for Enhanced DNA Clustering",
        "authors": [
            "Hadas Abraham",
            "Barak Gahtan",
            "Adir Kobovich",
            "Orian Leitersdorf",
            "Alex M. Bronstein",
            "Eitan Yaakobi"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The emerging field of DNA storage employs strands of DNA bases (A/T/C/G) as a\nstorage medium for digital information to enable massive density and\ndurability. The DNA storage pipeline includes: (1) encoding the raw data into\nsequences of DNA bases; (2) synthesizing the sequences as DNA \\textit{strands}\nthat are stored over time as an unordered set; (3) sequencing the DNA strands\nto generate DNA \\textit{reads}; and (4) deducing the original data. The DNA\nsynthesis and sequencing stages each generate several independent error-prone\nduplicates of each strand which are then utilized in the final stage to\nreconstruct the best estimate for the original strand. Specifically, the reads\nare first \\textit{clustered} into groups likely originating from the same\nstrand (based on their similarity to each other), and then each group\napproximates the strand that led to the reads of that group. This work improves\nthe DNA clustering stage by embedding it as part of the DNA sequencing.\nTraditional DNA storage solutions begin after the DNA sequencing process\ngenerates discrete DNA reads (A/T/C/G), yet we identify that there is untapped\npotential in using the raw signals generated by the Nanopore DNA sequencing\nmachine before they are discretized into bases, a process known as\n\\textit{basecalling}, which is done using a deep neural network. We propose a\ndeep neural network that clusters these signals directly, demonstrating\nsuperior accuracy, and reduced computation times compared to current approaches\nthat cluster after basecalling.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.06188v1"
    },
    {
        "title": "BSM: Small but Powerful Biological Sequence Model for Genes and Proteins",
        "authors": [
            "Weixi Xiang",
            "Xueting Han",
            "Xiujuan Chai",
            "Jing Bai"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Modeling biological sequences such as DNA, RNA, and proteins is crucial for\nunderstanding complex processes like gene regulation and protein synthesis.\nHowever, most current models either focus on a single type or treat multiple\ntypes of data separately, limiting their ability to capture cross-modal\nrelationships. We propose that by learning the relationships between these\nmodalities, the model can enhance its understanding of each type. To address\nthis, we introduce BSM, a small but powerful mixed-modal biological sequence\nfoundation model, trained on three types of data: RefSeq, Gene Related\nSequences, and interleaved biological sequences from the web. These datasets\ncapture the genetic flow, gene-protein relationships, and the natural\nco-occurrence of diverse biological data, respectively. By training on\nmixed-modal data, BSM significantly enhances learning efficiency and\ncross-modal representation, outperforming models trained solely on unimodal\ndata. With only 110M parameters, BSM achieves performance comparable to much\nlarger models across both single-modal and mixed-modal tasks, and uniquely\ndemonstrates in-context learning capability for mixed-modal tasks, which is\nabsent in existing models. Further scaling to 270M parameters demonstrates even\ngreater performance gains, highlighting the potential of BSM as a significant\nadvancement in multimodal biological sequence modeling.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.11499v1"
    },
    {
        "title": "Explainable AI Methods for Multi-Omics Analysis: A Survey",
        "authors": [
            "Ahmad Hussein",
            "Mukesh Prasad",
            "Ali Braytee"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Advancements in high-throughput technologies have led to a shift from\ntraditional hypothesis-driven methodologies to data-driven approaches.\nMulti-omics refers to the integrative analysis of data derived from multiple\n'omes', such as genomics, proteomics, transcriptomics, metabolomics, and\nmicrobiomics. This approach enables a comprehensive understanding of biological\nsystems by capturing different layers of biological information. Deep learning\nmethods are increasingly utilized to integrate multi-omics data, offering\ninsights into molecular interactions and enhancing research into complex\ndiseases. However, these models, with their numerous interconnected layers and\nnonlinear relationships, often function as black boxes, lacking transparency in\ndecision-making processes. To overcome this challenge, explainable artificial\nintelligence (xAI) methods are crucial for creating transparent models that\nallow clinicians to interpret and work with complex data more effectively. This\nreview explores how xAI can improve the interpretability of deep learning\nmodels in multi-omics research, highlighting its potential to provide\nclinicians with clear insights, thereby facilitating the effective application\nof such models in clinical settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.11910v1"
    },
    {
        "title": "Absorb & Escape: Overcoming Single Model Limitations in Generating\n  Genomic Sequences",
        "authors": [
            "Zehui Li",
            "Yuhao Ni",
            "Guoxuan Xia",
            "William Beardall",
            "Akashaditya Das",
            "Guy-Bart Stan",
            "Yiren Zhao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Abstract Recent advances in immunology and synthetic biology have accelerated\nthe development of deep generative methods for DNA sequence design. Two\ndominant approaches in this field are AutoRegressive (AR) models and Diffusion\nModels (DMs). However, genomic sequences are functionally heterogeneous,\nconsisting of multiple connected regions (e.g., Promoter Regions, Exons, and\nIntrons) where elements within each region come from the same probability\ndistribution, but the overall sequence is non-homogeneous. This heterogeneous\nnature presents challenges for a single model to accurately generate genomic\nsequences. In this paper, we analyze the properties of AR models and DMs in\nheterogeneous genomic sequence generation, pointing out crucial limitations in\nboth methods: (i) AR models capture the underlying distribution of data by\nfactorizing and learning the transition probability but fail to capture the\nglobal property of DNA sequences. (ii) DMs learn to recover the global\ndistribution but tend to produce errors at the base pair level. To overcome the\nlimitations of both approaches, we propose a post-training sampling method,\ntermed Absorb & Escape (A&E) to perform compositional generation from AR models\nand DMs. This approach starts with samples generated by DMs and refines the\nsample quality using an AR model through the alternation of the Absorb and\nEscape steps. To assess the quality of generated sequences, we conduct\nextensive experiments on 15 species for conditional and unconditional DNA\ngeneration. The experiment results from motif distribution, diversity checks,\nand genome integration tests unequivocally show that A&E outperforms\nstate-of-the-art AR models and DMs in genomic sequence generation.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21345v1"
    },
    {
        "title": "eDOC: Explainable Decoding Out-of-domain Cell Types with Evidential\n  Learning",
        "authors": [
            "Chaochen Wu",
            "Meiyun Zuo",
            "Lei Xie"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Single-cell RNA-seq (scRNA-seq) technology is a powerful tool for unraveling\nthe complexity of biological systems. One of essential and fundamental tasks in\nscRNA-seq data analysis is Cell Type Annotation (CTA). In spite of tremendous\nefforts in developing machine learning methods for this problem, several\nchallenges remains. They include identifying Out-of-Domain (OOD) cell types,\nquantifying the uncertainty of unseen cell type annotations, and determining\ninterpretable cell type-specific gene drivers for an OOD case. OOD cell types\nare often associated with therapeutic responses and disease origins, making\nthem critical for precision medicine and early disease diagnosis. Additionally,\nscRNA-seq data contains tens thousands of gene expressions. Pinpointing gene\ndrivers underlying CTA can provide deep insight into gene regulatory mechanisms\nand serve as disease biomarkers. In this study, we develop a new method, eDOC,\nto address aforementioned challenges. eDOC leverages a transformer architecture\nwith evidential learning to annotate In-Domain (IND) and OOD cell types as well\nas to highlight genes that contribute both IND cells and OOD cells in a single\ncell resolution. Rigorous experiments demonstrate that eDOC significantly\nimproves the efficiency and effectiveness of OOD cell type and gene driver\nidentification compared to other state-of-the-art methods. Our findings suggest\nthat eDOC may provide new insights into single-cell biology.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00054v1"
    },
    {
        "title": "Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
        "authors": [
            "Wei Wang",
            "Zhichao Hou",
            "Xiaorui Liu",
            "Xinxia Peng"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03522v1"
    },
    {
        "title": "Integrating Large Language Models for Genetic Variant Classification",
        "authors": [
            "Youssef Boulaimen",
            "Gabriele Fossi",
            "Leila Outemzabet",
            "Nathalie Jeanray",
            "Oleksandr Levenets",
            "Stephane Gerart",
            "Sebastien Vachenc",
            "Salvatore Raieli",
            "Joanna Giemza"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05055v1"
    },
    {
        "title": "LA4SR: illuminating the dark proteome with generative AI",
        "authors": [
            "David R. Nelson",
            "Ashish Kumar Jaiswal",
            "Noha Ismail",
            "Alexandra Mystikou",
            "Kourosh Salehi-Ashtiani"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  AI language models (LMs) show promise for biological sequence analysis. We\nre-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,\nranging from 70M to 12B parameters) for microbial sequence classification. The\nmodels achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the\nrecall of BLASTP. They effectively classified the algal dark proteome -\nuncharacterized proteins comprising about 65% of total proteins - validated on\nnew data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger\n(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%\nof available data, rapidly achieving strong generalization capacity. High\naccuracy was achieved when training data had intact or scrambled terminal\ninformation, demonstrating robust generalization to incomplete sequences.\nFinally, we provide custom AI explainability software tools for attributing\namino acid patterns to AI generative processes and interpret their outputs in\nevolutionary and biophysical contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06798v2"
    },
    {
        "title": "GeneSUM: Large Language Model-based Gene Summary Extraction",
        "authors": [
            "Zhijian Chen",
            "Chuan Hu",
            "Min Wu",
            "Qingqing Long",
            "Xuezhi Wang",
            "Yuanchun Zhou",
            "Meng Xiao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Emerging topics in biomedical research are continuously expanding, providing\na wealth of information about genes and their function. This rapid\nproliferation of knowledge presents unprecedented opportunities for scientific\ndiscovery and formidable challenges for researchers striving to keep abreast of\nthe latest advancements. One significant challenge is navigating the vast\ncorpus of literature to extract vital gene-related information, a\ntime-consuming and cumbersome task. To enhance the efficiency of this process,\nit is crucial to address several key challenges: (1) the overwhelming volume of\nliterature, (2) the complexity of gene functions, and (3) the automated\nintegration and generation. In response, we propose GeneSUM, a two-stage\nautomated gene summary extractor utilizing a large language model (LLM). Our\napproach retrieves and eliminates redundancy of target gene literature and then\nfine-tunes the LLM to refine and streamline the summarization process. We\nconducted extensive experiments to validate the efficacy of our proposed\nframework. The results demonstrate that LLM significantly enhances the\nintegration of gene-specific information, allowing more efficient\ndecision-making in ongoing research.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18154v1"
    },
    {
        "title": "scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
        "authors": [
            "Cong Li",
            "Qingqing Long",
            "Yuanchun Zhou",
            "Meng Xiao"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18156v1"
    },
    {
        "title": "METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring",
        "authors": [
            "Ollie Liu",
            "Sami Jaghouar",
            "Johannes Hagemann",
            "Shangshang Wang",
            "Jason Wiemels",
            "Jeff Kaufman",
            "Willie Neiswanger"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer\nmodel, which we refer to as a metagenomic foundation model, on a novel corpus\nof diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base\npairs. This dataset is sourced from a large collection of human wastewater\nsamples, processed and sequenced using deep metagenomic (next-generation)\nsequencing methods. Unlike genomic models that focus on individual genomes or\ncurated sets of specific species, the aim of METAGENE-1 is to capture the full\ndistribution of genomic information present within this wastewater, to aid in\ntasks relevant to pandemic monitoring and pathogen detection. We carry out\nbyte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic\nsequences, and then pretrain our model. In this paper, we first detail the\npretraining dataset, tokenization strategy, and model architecture,\nhighlighting the considerations and design choices that enable the effective\nmodeling of metagenomic data. We then show results of pretraining this model on\nour metagenomic dataset, providing details about our losses, system metrics,\nand training stability over the course of pretraining. Finally, we demonstrate\nthe performance of METAGENE-1, which achieves state-of-the-art results on a set\nof genomic benchmarks and new evaluations focused on human-pathogen detection\nand genomic sequence embedding, showcasing its potential for public health\napplications in pandemic monitoring, biosurveillance, and early detection of\nemerging health threats.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02045v1"
    },
    {
        "title": "Explainable AI model reveals disease-related mechanisms in single-cell\n  RNA-seq data",
        "authors": [
            "Mohammad Usman",
            "Olga Varea",
            "Petia Radeva",
            "Josep Canals",
            "Jordi Abante",
            "Daniel Ortiz"
        ],
        "category": "q-bio.GN",
        "published_year": "2025",
        "summary": "  Neurodegenerative diseases (NDDs) are complex and lack effective treatment\ndue to their poorly understood mechanism. The increasingly used data analysis\nfrom Single nucleus RNA Sequencing (snRNA-seq) allows to explore transcriptomic\nevents at a single cell level, yet face challenges in interpreting the\nmechanisms underlying a disease. On the other hand, Neural Network (NN) models\ncan handle complex data to offer insights but can be seen as black boxes with\npoor interpretability. In this context, explainable AI (XAI) emerges as a\nsolution that could help to understand disease-associated mechanisms when\ncombined with efficient NN models. However, limited research explores XAI in\nsingle-cell data. In this work, we implement a method for identifying\ndisease-related genes and the mechanistic explanation of disease progression\nbased on NN model combined with SHAP. We analyze available Huntington's disease\n(HD) data to identify both HD-altered genes and mechanisms by adding Gene Set\nEnrichment Analysis (GSEA) comparing two methods, differential gene expression\nanalysis (DGE) and NN combined with SHAP approach. Our results show that DGE\nand SHAP approaches offer both common and differential sets of altered genes\nand pathways, reinforcing the usefulness of XAI methods for a broader\nperspective of disease.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.03923v1"
    },
    {
        "title": "Probabilistic sequence alignments: realistic models with efficient\n  algorithms",
        "authors": [
            "E. Yeramian",
            "E. Debonneuil"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Alignment algorithms usually rely on simplified models of gaps for\ncomputational efficiency. Based on an isomorphism between alignments and\nphysical helix-coil models, we show in statistical mechanics that alignments\nwith realistic laws for gaps can be computed with fast algorithms. Improved\nperformances of probabilistic alignments with realistic models of gaps are\nillustrated. Probabilistic and optimization formulations are compared, with\npotential implications in many fields and perspectives for computationally\nefficient extensions to Markov models with realistic long-range interactions.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0606010v1"
    },
    {
        "title": "Does the dynamics of sine-Gordon solitons predict active regions of DNA?",
        "authors": [
            "Sara Cuenda",
            "Angel Sanchez",
            "Niurka R. Quintero"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  In this work we analyze the possibility that soliton dynamics in a simple\nnonlinear model allows functionally relevant predictions of the behaviour of\nDNA. This suggestion was first put forward by Salerno [Phys. Rev. A, vol. 44,\np. 5292 (1991)] by showing results indicating that sine-Gordon kinks were set\nin motion at certain regions of a DNA sequence that include promoters. We\nrevisit that system and show that the observed behaviour has nothing to do with\npromoters; on the contrary, it originates from the bases at the boundary, which\nare not part of the studied genome. We explain this phenomenology in terms of\nan effective potential for the kink center. This is further extended to\ndisprove recent claims that the dynamics of kinks [Lenholm and H\\\"ornquist,\nPhysica D, vol. 177, p. 233 (2003)] or breathers [Bashford, J. Biol. Phys.,\nvol. 32, p. 27 (2006)] has functional significance. We conclude that no such\ninformation can be extracted from this simple nonlinear model or its associated\neffective potential.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0606028v1"
    },
    {
        "title": "Theory of genomic dark matter and biological relativity",
        "authors": [
            "Mark Ya. Azbel"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Significant fraction (about 98.5% in humans, 24% in microbe Rickettsia\nprowazekii) of most animal genomes is non-coding DNA. Although recent studies\nestablished functions of its certain portions, it remains genomic dark matter.\nThe paper unravels its unusual nature with time reversal approach. Any genome\nemerged in evolutionary selection of the fittest survivors. Survivability of\nmodern species is extensively quantified. Accurate analysis establishes that\nunder specified conditions it is dominated by the same law in species from\nhuman to single-cell yeast. Since all violators of the law perished in the\nprevious evolution, it presents the exact law of unanticipated universal\n(rather than species specific natural) evolutionary selection of survivors. The\nlaw implies their rapid hereditary, thus genetic, adaptation which is navigated\nby operating system of non-coding DNA. Such adaptation to drastic environmental\nchanges was a must for survival, thus evolved, in otherwise lethal major mass\nextinctions. Navigator genome allows for rapid, artificial included, biological\nchanges (e.g., Methuselah lifespan). Universal law establishes biological\nrelativity to age transformation in any species; quantifies applicability of\nanimal models to humans; implies certain universality in biological complexity\nand reduces it to exact science problem. Evolutionary and experimental data\ncorroborate all above conclusions. Further theoretical study and test-stone\nexperiments are suggested.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0611027v4"
    },
    {
        "title": "Towards Understanding the Origin of Genetic Languages",
        "authors": [
            "Apoorva D. Patel"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Molecular biology is a nanotechnology that works--it has worked for billions\nof years and in an amazing variety of circumstances. At its core is a system\nfor acquiring, processing and communicating information that is universal, from\nviruses and bacteria to human beings. Advances in genetics and experience in\ndesigning computers have taken us to a stage where we can understand the\noptimisation principles at the root of this system, from the availability of\nbasic building blocks to the execution of tasks. The languages of DNA and\nproteins are argued to be the optimal solutions to the information processing\ntasks they carry out. The analysis also suggests simpler predecessors to these\nlanguages, and provides fascinating clues about their origin. Obviously, a\ncomprehensive unraveling of the puzzle of life would have a lot to say about\nwhat we may design or convert ourselves into.\n",
        "pdf_link": "http://arxiv.org/pdf/0705.3895v2"
    },
    {
        "title": "Optimal Assembly for High Throughput Shotgun Sequencing",
        "authors": [
            "Guy Bresler",
            "Ma'ayan Bresler",
            "David Tse"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  We present a framework for the design of optimal assembly algorithms for\nshotgun sequencing under the criterion of complete reconstruction. We derive a\nlower bound on the read length and the coverage depth required for\nreconstruction in terms of the repeat statistics of the genome. Building on\nearlier works, we design a de Brujin graph based assembly algorithm which can\nachieve very close to the lower bound for repeat statistics of a wide range of\nsequenced genomes, including the GAGE datasets. The results are based on a set\nof necessary and sufficient conditions on the DNA sequence and the reads for\nreconstruction. The conditions can be viewed as the shotgun sequencing analogue\nof Ukkonen-Pevzner's necessary and sufficient conditions for Sequencing by\nHybridization.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.0068v3"
    },
    {
        "title": "A network approach to analyzing highly recombinant malaria parasite\n  genes",
        "authors": [
            "Daniel B. Larremore",
            "Aaron Clauset",
            "Caroline O. Buckee"
        ],
        "category": "q-bio.GN",
        "published_year": "2013",
        "summary": "  The var genes of the human malaria parasite Plasmodium falciparum present a\nchallenge to population geneticists due to their extreme diversity, which is\ngenerated by high rates of recombination. These genes encode a primary antigen\nprotein called PfEMP1, which is expressed on the surface of infected red blood\ncells and elicits protective immune responses. Var gene sequences are\ncharacterized by pronounced mosaicism, precluding the use of traditional\nphylogenetic tools that require bifurcating tree-like evolutionary\nrelationships. We present a new method that identifies highly variable regions\n(HVRs), and then maps each HVR to a complex network in which each sequence is a\nnode and two nodes are linked if they share an exact match of significant\nlength. Here, networks of var genes that recombine freely are expected to have\na uniformly random structure, but constraints on recombination will produce\nnetwork communities that we identify using a stochastic block model. We\nvalidate this method on synthetic data, showing that it correctly recovers\npopulations of constrained recombination, before applying it to the Duffy\nBinding Like-{\\alpha} (DBL{\\alpha}) domain of var genes. We find nine HVRs\nwhose network communities map in distinctive ways to known DBL{\\alpha}\nclassifications and clinical phenotypes. We show that the recombinational\nconstraints of some HVRs are correlated, while others are independent. These\nfindings suggest that this micromodular structuring facilitates independent\nevolutionary trajectories of neighboring mosaic regions, allowing the parasite\nto retain protein function while generating enormous sequence diversity. Our\napproach therefore offers a rigorous method for analyzing evolutionary\nconstraints in var genes, and is also flexible enough to be easily applied more\ngenerally to any highly recombinant sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.5254v1"
    },
    {
        "title": "Unsupervised Learning in Genome Informatics",
        "authors": [
            "Ka-Chun Wong",
            "Yue Li",
            "Zhaolei Zhang"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  With different genomes available, unsupervised learning algorithms are\nessential in learning genome-wide biological insights. Especially, the\nfunctional characterization of different genomes is essential for us to\nunderstand lives. In this book chapter, we review the state-of-the-art\nunsupervised learning algorithms for genome informatics from DNA to MicroRNA.\n  DNA (DeoxyriboNucleic Acid) is the basic component of genomes. A significant\nfraction of DNA regions (transcription factor binding sites) are bound by\nproteins (transcription factors) to regulate gene expression at different\ndevelopment stages in different tissues. To fully understand genetics, it is\nnecessary of us to apply unsupervised learning algorithms to learn and infer\nthose DNA regions. Here we review several unsupervised learning methods for\ndeciphering the genome-wide patterns of those DNA regions.\n  MicroRNA (miRNA), a class of small endogenous non-coding RNA (RiboNucleic\nacid) species, regulate gene expression post-transcriptionally by forming\nimperfect base-pair with the target sites primarily at the 3$'$ untranslated\nregions of the messenger RNAs. Since the 1993 discovery of the first miRNA\n\\emph{let-7} in worms, a vast amount of studies have been dedicated to\nfunctionally characterizing the functional impacts of miRNA in a network\ncontext to understand complex diseases such as cancer. Here we review several\nrepresentative unsupervised learning frameworks on inferring miRNA regulatory\nnetwork by exploiting the static sequence-based information pertinent to the\nprior knowledge of miRNA targeting and the dynamic information of miRNA\nactivities implicated by the recently available large data compendia, which\ninterrogate genome-wide expression profiles of miRNAs and/or mRNAs across\nvarious cell conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.00459v1"
    },
    {
        "title": "Post-transcriptional regulation across human tissues",
        "authors": [
            "Alexander Franks",
            "Edoardo Airoldi",
            "Nikolai Slavov"
        ],
        "category": "q-bio.GN",
        "published_year": "2015",
        "summary": "  Transcriptional and post-transcriptional regulation shape\ntissue-type-specific proteomes, but their relative contributions remain\ncontested. Estimates of the factors determining protein levels in human tissues\ndo not distinguish between (i) the factors determining the variability between\nthe abundances of different proteins, i.e., mean-level-variability and, (ii)\nthe factors determining the physiological variability of the same protein\nacross different tissue types, i.e., across-tissues variability. We sought to\nestimate the contribution of transcript levels to these two orthogonal sources\nof variability, and found that scaled mRNA levels can account for most of the\nmean-level-variability but not necessarily for across-tissues variability. The\nreliable quantification of the latter estimate is limited by substantial\nmeasurement noise. However, protein-to-mRNA ratios exhibit substantial\nacross-tissues variability that is functionally concerted and reproducible\nacross different datasets, suggesting extensive post-transcriptional\nregulation. These results caution against estimating protein fold-changes from\nmRNA fold-changes between different cell-types, and highlight the contribution\nof post-transcriptional regulation to shaping tissue-type-specific proteomes.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.00219v2"
    },
    {
        "title": "Prediction approaches for partly missing multi-omics covariate data: A\n  literature review and an empirical comparison study",
        "authors": [
            "Roman Hornung",
            "Frederik Ludwigs",
            "Jonas Hagenberg",
            "Anne-Laure Boulesteix"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  As the availability of omics data has increased in the last few years, more\nmulti-omics data have been generated, that is, high-dimensional molecular data\nconsisting of several types such as genomic, transcriptomic, or proteomic data,\nall obtained from the same patients. Such data lend themselves to being used as\ncovariates in automatic outcome prediction because each omics type may\ncontribute unique information, possibly improving predictions compared to using\nonly one omics data type. Frequently, however, in the training data and the\ndata to which automatic prediction rules should be applied, the test data, the\ndifferent omics data types are not available for all patients. We refer to this\ntype of data as block-wise missing multi-omics data. First, we provide a\nliterature review on existing prediction methods applicable to such data.\nSubsequently, using a collection of 13 publicly available multi-omics data\nsets, we compare the predictive performances of several of these approaches for\ndifferent block-wise missingness patterns. Finally, we discuss the results of\nthis empirical comparison study and draw some tentative conclusions.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03991v1"
    },
    {
        "title": "Genomic regulatory architecture of human embryo retroviral LTR elements\n  affecting evolution, development, and pathophysiology of Modern Humans",
        "authors": [
            "Gennadi Glinsky"
        ],
        "category": "q-bio.GN",
        "published_year": "2023",
        "summary": "  Two distinct families of pan-primate endogenous retroviruses, namely HERVL\nand HERVH, infected primates germline, colonized host genomes, and evolved into\nthe global retroviral genomic regulatory dominion (GRD) operating during human\nembryogenesis (HE). HE retroviral GRD constitutes 8839 highly conserved fixed\nLTR elements linked to 5444 down-stream target genes forged by evolution into a\nfunctionally-consonant constellation of 26 genome-wide multimodular genomic\nregulatory networks (GRNs), each of which is defined by significant enrichment\nof numerous single gene ontology (GO)-specific traits. Locations of GRNs appear\nscattered across chromosomes to occupy from 5.5%-15.09% of human genome. Each\nGRN harbors from 529-1486 retroviral LTRs derived from LTR7, MLT2A1, and MLT2A2\nsequences that are quantitatively balanced according to their genome-wide\nabundance. GRNs integrate activities from 199-805 down-stream target genes,\nincluding transcription factors, chromatin-state remodelers, signal-sensing and\nsignal-transduction mediators, enzymatic and receptor binding effectors,\nintracellular complexes and extracellular matrix elements, and cell-cell\nadhesion molecules. GRNs compositions consist of several hundred to thousands\nsmaller GO enrichment-defined genomic regulatory modules (GRMs) combining from\na dozen to hundreds LTRs and down-stream target genes, which appear to operate\non individuals life-span timescale along specific phenotypic avenues to exert\nprofound effects on patterns of transcription, protein-protein interactions,\ndevelopmental phenotypes, physiological traits, and pathological conditions of\nModern Humans. Overall, this study identifies 69,573 statistically significant\nretroviral LTR-linked GRMs (Binominal FDR q-value threshold of 0.001),\nincluding 27,601 GRMs validated by the single GO-specific directed acyclic\ngraph (DAG) analyses across six GO annotations.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.16439v1"
    },
    {
        "title": "Toward Capturing Genetic Epistasis From Multivariate Genome-Wide\n  Association Studies Using Mixed-Precision Kernel Ridge Regression",
        "authors": [
            "Hatem Ltaief",
            "Rabab Alomairy",
            "Qinglei Cao",
            "Jie Ren",
            "Lotfi Slim",
            "Thorsten Kurth",
            "Benedikt Dorschner",
            "Salim Bougouffa",
            "Rached Abdelkhalak",
            "David E. Keyes"
        ],
        "category": "q-bio.GN",
        "published_year": "2024",
        "summary": "  We exploit the widening margin in tensor-core performance between\n[FP64/FP32/FP16/INT8,FP64/FP32/FP16/FP8/INT8] on NVIDIA [Ampere,Hopper] GPUs to\nboost the performance of output accuracy-preserving mixed-precision computation\nof Genome-Wide Association Studies (GWAS) of 305K patients from the UK BioBank,\nthe largest-ever GWAS cohort studied for genetic epistasis using a multivariate\napproach. Tile-centric adaptive-precision linear algebraic techniques motivated\nby reducing data motion gain enhanced significance with low-precision GPU\narithmetic. At the core of Kernel Ridge Regression (KRR) techniques for GWAS\nlie compute-bound cubic-complexity matrix operations that inhibit scaling to\naspirational dimensions of the population, genotypes, and phenotypes. We\naccelerate KRR matrix generation by redesigning the computation for Euclidean\ndistances to engage INT8 tensor cores while exploiting symmetry.We accelerate\nsolution of the regularized KRR systems by deploying a new four-precision\nCholesky-based solver, which, at 1.805 mixed-precision ExaOp/s on a nearly full\nAlps system, outperforms the state-of-the-art CPU-only REGENIE GWAS software by\nfive orders of magnitude.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.01712v1"
    },
    {
        "title": "A p-Adic Model of DNA Sequence and Genetic Code",
        "authors": [
            "Branko Dragovich",
            "Alexandra Dragovich"
        ],
        "category": "q-bio.GN",
        "published_year": "2006",
        "summary": "  Using basic properties of p-adic numbers, we consider a simple new approach\nto describe main aspects of DNA sequence and genetic code. Central role in our\ninvestigation plays an ultrametric p-adic information space which basic\nelements are nucleotides, codons and genes. We show that a 5-adic model is\nappropriate for DNA sequence. This 5-adic model, combined with 2-adic distance,\nis also suitable for genetic code and for a more advanced employment in\ngenomics. We find that genetic code degeneracy is related to the p-adic\ndistance between codons.\n",
        "pdf_link": "http://arxiv.org/pdf/q-bio/0607018v1"
    },
    {
        "title": "Non-coding DNA programs express adaptation and its universal law",
        "authors": [
            "Mark Ya. Azbel"
        ],
        "category": "q-bio.GN",
        "published_year": "2007",
        "summary": "  Significant fraction (98.5% in humans) of most animal genomes is non- coding\ndark matter. Its largely unknown function (1-5) is related to programming\n(rather than to spontaneous mutations) of accurate adaptation to rapidly\nchanging environment. Programmed adaptation to the same universal law for\nnon-competing animals from anaerobic yeast to human is revealed in the study of\ntheir extensively quantified mortality (6-21). Adaptation of animals with\nremoved non-coding DNA fractions may specify their contribution to genomic\nprogramming. Emergence of new adaptation programs and their (non-Mendelian)\nheredity may be studied in antibiotic mini-extinctions (22-24). On a large\nevolutionary scale rapid universal adaptation was vital for survival, and\nevolved, in otherwise lethal for diverse species major mass extinctions\n(25-28). Evolutionary and experimental data corroborate these conclusions\n(6-21, 29-32). Universal law implies certain biological universality of diverse\nspecies, thus quantifies applicability of animal models to humans). Genomic\nadaptation programming calls for unusual approach to its study and implies\nunanticipated perspectives, in particular, directed biological changes.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.3826v2"
    },
    {
        "title": "Rare-Allele Detection Using Compressed Se(que)nsing",
        "authors": [
            "Noam Shental",
            "Amnon Amir",
            "Or Zuk"
        ],
        "category": "q-bio.GN",
        "published_year": "2009",
        "summary": "  Detection of rare variants by resequencing is important for the\nidentification of individuals carrying disease variants. Rapid sequencing by\nnew technologies enables low-cost resequencing of target regions, although it\nis still prohibitive to test more than a few individuals. In order to improve\ncost trade-offs, it has recently been suggested to apply pooling designs which\nenable the detection of carriers of rare alleles in groups of individuals.\nHowever, this was shown to hold only for a relatively low number of individuals\nin a pool, and requires the design of pooling schemes for particular cases.\n  We propose a novel pooling design, based on a compressed sensing approach,\nwhich is both general, simple and efficient. We model the experimental\nprocedure and show via computer simulations that it enables the recovery of\nrare allele carriers out of larger groups than were possible before, especially\nin situations where high coverage is obtained for each individual.\n  Our approach can also be combined with barcoding techniques to enhance\nperformance and provide a feasible solution based on current resequencing\ncosts. For example, when targeting a small enough genomic region (~100\nbase-pairs) and using only ~10 sequencing lanes and ~10 distinct barcodes, one\ncan recover the identity of 4 rare allele carriers out of a population of over\n4000 individuals.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.0400v1"
    },
    {
        "title": "Bacterial Community Reconstruction Using A Single Sequencing Reaction",
        "authors": [
            "Amnon Amir",
            "Or Zuk"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  Bacteria are the unseen majority on our planet, with millions of species and\ncomprising most of the living protoplasm. While current methods enable in-depth\nstudy of a small number of communities, a simple tool for breadth studies of\nbacterial population composition in a large number of samples is lacking. We\npropose a novel approach for reconstruction of the composition of an unknown\nmixture of bacteria using a single Sanger-sequencing reaction of the mixture.\nThis method is based on compressive sensing theory, which deals with\nreconstruction of a sparse signal using a small number of measurements.\nUtilizing the fact that in many cases each bacterial community is comprised of\na small subset of the known bacterial species, we show the feasibility of this\napproach for determining the composition of a bacterial mixture. Using\nsimulations, we show that sequencing a few hundred base-pairs of the 16S rRNA\ngene sequence may provide enough information for reconstruction of mixtures\ncontaining tens of species, out of tens of thousands, even in the presence of\nrealistic measurement noise. Finally, we show initial promising results when\napplying our method for the reconstruction of a toy experimental mixture with\nfive species. Our approach may have a potential for a practical and efficient\nway for identifying bacterial species compositions in biological samples.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.3424v1"
    },
    {
        "title": "A colorful origin for the genetic code: Information theory, statistical\n  mechanics and the emergence of molecular codes",
        "authors": [
            "Tsvi Tlusty"
        ],
        "category": "q-bio.GN",
        "published_year": "2010",
        "summary": "  The genetic code maps the sixty-four nucleotide triplets (codons) to twenty\namino-acids. While the biochemical details of this code were unraveled long\nago, its origin is still obscure. We review information-theoretic approaches to\nthe problem of the code's origin and discuss the results of a recent work that\ntreats the code in terms of an evolving, error-prone information channel. Our\nmodel - which utilizes the rate-distortion theory of noisy communication\nchannels - suggests that the genetic code originated as a result of the\ninterplay of the three conflicting evolutionary forces: the needs for diverse\namino-acids, for error-tolerance and for minimal cost of resources. The\ndescription of the code as an information channel allows us to mathematically\nidentify the fitness of the code and locate its emergence at a second-order\nphase transition when the mapping of codons to amino-acids becomes nonrandom.\nThe noise in the channel brings about an error-graph, in which edges connect\ncodons that are likely to be confused. The emergence of the code is governed by\nthe topology of the error-graph, which determines the lowest modes of the\ngraph-Laplacian and is related to the map coloring problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.3906v1"
    },
    {
        "title": "Somatic mutations render human exome and pathogen DNA more similar",
        "authors": [
            "Ehsan Ebrahimzadeh",
            "Maggie Engler",
            "David Tse",
            "Razvan Cristescu",
            "Aslan Tchamkerten"
        ],
        "category": "q-bio.GN",
        "published_year": "2019",
        "summary": "  Immunotherapy has recently shown important clinical successes in a\nsubstantial number of oncology indications. Additionally, the tumor somatic\nmutation load has been shown to associate with response to these therapeutic\nagents, and specific mutational signatures are hypothesized to improve this\nassociation, including signatures related to pathogen insults. We sought to\nstudy in silico the validity of these observations and how they relate to each\nother. We first addressed whether somatic mutations typically involved in\ncancer may increase, in a statistically meaningful manner, the similarity\nbetween common pathogens and the human exome. Our study shows that common\nmutagenic processes increase, in the upper range of biologically plausible\nfrequencies, the similarity between cancer exomes and pathogen DNA at a scale\nof 12-16 nucleotide sequences and established that this increased similarity is\ndue to the specific mutation distribution of the considered mutagenic\nprocesses. Next, we studied the impact of mutation rate and showed that\nincreasing mutation rate generally results in an increased similarity between\nthe cancer exome and pathogen DNA, at a scale of 4-5 amino acids. Finally, we\ninvestigated whether the considered mutational processes result in amino-acid\nchanges with functional relevance that are more likely to be immunogenic. We\nshowed that functional tolerance to mutagenic processes across species\ngenerally suggests more resilience to mutagenic processes that are due to\nexposure to elements of nature than to mutagenic processes that are due to\nexposure to cancer-causing artificial substances. These results support the\nidea that recognition of pathogen sequences as well as differential functional\ntolerance to mutagenic processes may play an important role in the immune\nrecognition process involved in tumor infiltration by lymphocytes.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03138v1"
    }
]